{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-10-19 10:07:46","updatedTime":"2020-10-19 10:07:46","title":"挑战新物体描述问题，视觉词表解决方案超越人类表现","link":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","description":"<div><div><div id=\"media\" class=\"rich_media_thumb_wrp\">\n\n            <img class=\"rich_media_thumb\" src=\"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MEQiaiawTsPxb35M4vrInZ2UNib5fWJ4MSnIS1C5eHjzdobBS2cYsheCnA?imageView2/1/w/600\">\n        </div>\n    \n\n    \n\n    <div class=\"rich_media_content\" id=\"js_content\">\n                    \n\n                    \n\n                    \n                    \n                    <section style=\"display:none;\" data-tools=\"新媒体管家\" data-label=\"powered by xmt.cn\"><br></section><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;\"><img class=\"__bg_gif\" data-cropselx1=\"0\" data-cropselx2=\"578\" data-cropsely1=\"0\" data-cropsely2=\"116\" data-ratio=\"0.17896389324960754\" data-type=\"gif\" data-w=\"637\" style=\"box-sizing: border-box; color: rgb(62, 62, 62); max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif\"></section><p style=\"white-space: normal;\"><br></p><section style=\"margin: 10px 8px;white-space: normal;\"><section style=\"border-width: 2px;border-style: dashed;border-color: rgb(160, 219, 239);box-sizing: border-box;\"><section style=\"margin: 15px;\"><p style=\"color: rgb(181, 180, 180);font-size: 14px;\"><span style=\"color: rgb(136, 136, 136);\">编者按：</span><span style=\"color: rgb(136, 136, 136);\">最近，研究者们发布了 </span><span style=\"color: rgb(136, 136, 136);\">nocaps </span><span style=\"color: rgb(136, 136, 136);\">挑战，用以测量在没有对应的训练数据的情况下，模型能否准确描述测试图像中新出现的各种类别的物体。</span><span style=\"color: rgb(136, 136, 136);\">针对挑战中的问题，</span><span style=\"color: rgb(136, 136, 136);\">微软 </span><span style=\"color: rgb(136, 136, 136);\">Azure </span><span style=\"color: rgb(136, 136, 136);\">认知服务</span><span style=\"color: rgb(136, 136, 136);\">团队</span><span style=\"color: rgb(136, 136, 136);\">和微软研究院的研究员</span><span style=\"color: rgb(136, 136, 136);\">提出了全新解决方案</span><span style=\"color: rgb(136, 136, 136);\">视觉词表预训练</span><span style=\"color: rgb(136, 136, 136);\"> (Visual Vocabulary Pre-training)</span><span style=\"color: rgb(136, 136, 136);\">。</span><span style=\"color: rgb(136, 136, 136);\">该方法在 </span><span style=\"color: rgb(136, 136, 136);\">nocaps </span><span style=\"color: rgb(136, 136, 136);\">挑战中取得了新的 </span><span style=\"color: rgb(136, 136, 136);\">SOTA</span><span style=\"color: rgb(136, 136, 136);\">，并首次超越人类表现。</span></p></section></section></section><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages\" data-cropselx1=\"0\" data-cropselx2=\"40\" data-cropsely1=\"0\" data-cropsely2=\"40\" data-ratio=\"1.118421052631579\" data-s=\"300,640\" data-type=\"png\" data-w=\"76\" style=\"height: 35px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPMhaNuospc1FrHVRVv0cGu9TicyLQdiaAAET8gXokXUcaQ3JGpyrZpaj7ajY2HRYGW3v4icv66VKcYg/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">看图说话“新”问题</span></section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(160, 219, 239);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">图像描述或看图说话（Image Captioning）是计算机根据图片自动生成一句话来描述其中的内容，由于其潜在的应用价值（例如人机交互和图像语言理解）而受到了广泛的关注。这项工作既需要视觉系统对图片中的物体进行识别，也需要语言系统对识别的物体进行描述，因此存在很多复杂且极具挑战的问题。其中，</span><span style=\"color: rgb(0, 0, 0);font-size: 15px;background-color: rgb(160, 219, 239);\">最具挑战的一个问题就是新物体描述</span><span style=\"color: rgb(0, 0, 0);font-size: 15px;background-color: rgb(160, 219, 239);\">（Novel object captioning）</span><span style=\"font-size: 15px;\">，即描述没有出现在训练数据中的新物体。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">最近，研究者们发布了 nocaps 挑战（</span><span style=\"font-size: 15px;\">https://nocaps.org/</span><span style=\"font-size: 15px;\">），以测量在即使没有对应的训练数据的情况下，模型能否准确描述测试图像中新出现的各种类别的物体。在这个挑战中，虽然没有配对的图像和文本描述（caption）进行模型训练，但是可以借助计算机视觉的技术来识别各类物体。例如在一些之前的工作中，模型可以先生成一个句式模板，然后用识别的物体进行填空。然而，这类方法的表现并不尽如人意。由于只能利用单一模态的图像或文本数据，所以模型无法充分利用图像和文字之间的联系。另一类方法则使用基于 Transformer 的模型进行图像和文本交互的预训练（Vision and Language Pre-training）。这类模型在多模态（cross-modal）的特征学习中取得了有效的进展，从而使得后续在图像描述任务上的微调（fine-tuning）获益于预训练中学到的特征向量。但是，这类方法依赖于海量的训练数据，在这个比赛中无法发挥作用。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">针对这些问题，</span><span style=\"color: rgb(0, 0, 0);font-size: 15px;background-color: rgb(160, 219, 239);\">微软 Azure 认知服务团队和微软研究院的研究员们提出了全新的解决方案  Visual Vocabulary Pre-training（视觉词表预训练，简称VIVO)，该方法在没有文本标注的情况下也能进行图像和文本的多模态预训练。这使得训练不再依赖于配对的图像和文本标注，而是可以利用大量的计算机视觉数据集</span><span style=\"font-size: 15px;\">，如用于图像识别问题的类别标签（tag）。借助这个方法，模型可以通过大规模数据学习建立多种物体的视觉外表和语义名称之间的联系，即视觉词表（Visual Vocabulary）的建立。目前，VIVO 方法在 nocaps 挑战中取得了新的 SOTA（即当前最优表现），并且首次超越了人类表现。（了解更多细节，请点击阅读原文参考相关论文）</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages\" data-cropselx1=\"0\" data-cropselx2=\"40\" data-cropsely1=\"0\" data-cropsely2=\"40\" data-ratio=\"1.118421052631579\" data-s=\"300,640\" data-type=\"png\" data-w=\"76\" style=\"height: 35px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPMhaNuospc1FrHVRVv0cGu9TicyLQdiaAAET8gXokXUcaQ3JGpyrZpaj7ajY2HRYGW3v4icv66VKcYg/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">视觉词表成为解决问题的关键</span></section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(160, 219, 239);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 15px;background-color: rgb(160, 219, 239);\">VIVO 方法取得成功的关键在于视觉词表（visual vocabulary）的建立</span><span style=\"font-size: 15px;\">。如图1所示，研究人员把视觉词表定义为一个图像和文字的联合特征空间（joint embedding space），其中语义相近的词汇，例如男人和人、手风琴和乐器，会被映射到距离更近的特征向量上。在预训练学习建立了视觉词表以后，模型还会在有对应的文本描述的小数据集上进行微调。微调时，训练数据只需要涵盖少量的共同物体，例如人、狗、沙发，模型就能学习如何根据图片和识别到的物体来生成一个通用的句式模板，并且把物体填入模板中相应的位置，例如，“人抱着狗”。在测试阶段，即使图片中出现了微调时没有见过的物体，例如手风琴，模型依然可以使用微调时学到的句式，加上预训练建立的视觉词表进行造句，从而得到了“人抱着手风琴”这句描述。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"317\" data-ratio=\"0.5792079207920792\" data-s=\"300,640\" data-type=\"png\" data-w=\"1212\" style=\"width: 562px; height: 326px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MTAia5kzmw1fYTiaJfUrTicsmfuG4f5RXiaziaqLgjIYgxmCkFbfnUHZRQJQ/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图1：VIVO 预训练使用大量的图片标签标注来建立视觉词表，其中语义相近的词汇与对应的图像区域特征会被映射到距离相近的向量上。微调使用只涵盖一部分物体（蓝色背景）的少量文本描述标注进行训练。在测试推理时，模型能够推广生成新物体（黄色背景）的语言描述，得益于预训练时见过的丰富物体类型。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">通过这样的方法，研究员们结合了预训练中识别图片物体的能力，以及微调中用自然语言造句的能力，从而做到了在推理测试时举一反三，使用更丰富的词汇量来描述图片中新出现的各种物体。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages\" data-cropselx1=\"0\" data-cropselx2=\"40\" data-cropsely1=\"0\" data-cropsely2=\"40\" data-ratio=\"1.118421052631579\" data-s=\"300,640\" data-type=\"png\" data-w=\"76\" style=\"height: 35px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPMhaNuospc1FrHVRVv0cGu9TicyLQdiaAAET8gXokXUcaQ3JGpyrZpaj7ajY2HRYGW3v4icv66VKcYg/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">VIVO 训练流程</span></section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(160, 219, 239);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><img class=\"rich_pages\" data-ratio=\"0.5705128205128205\" data-s=\"300,640\" data-type=\"png\" data-w=\"624\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOavZVEm7xKDfEicWic2fom1szrFRuyhT9uKdNaGX110LmLiaoyA82638K20Qxb6reNSlLk9sPPqJREQ/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图2：训练和推理流程总览（a）在VIVO 预训练中，Transformer 模型在图片标签的训练数据上做标签预测，从而针对丰富的视觉概念进行多模态特征学习。（b）在微调中，模型在有文本描述标注的训练数据上学习如何基于图片和识别出来的物体生成一句话。（c）在推理时，对于给定的图片和识别的物体，模型以自回归的方式生成一系列字符，从而构成描述新物体的句子。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">如图2所示，VIVO 训练流程采用了两阶段的训练。第一阶段为预训练，使用多层的 Transformer 模型进行图像分类的预测。具体来说，先给定图片和对应的一些标签（tag），然后随机地抹去其中一部分标签，让模型来预测这些被抹去的标签原本是什么。由于这些标签之间的顺序是可以互换的，因此需要使用匈牙利算法（Hungarian matching<span style=\"font-size: 15px;\">）</span>来找到预测结果和目标标签之间的一一对应，然后计算交叉熵损失（cross entropy loss）函数。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">预训练之后，第二阶段为微调。Transformer 模型会在有文本描述标注的小数据集上训练，例如 COCO。微调时使用的物体标签可以来自数据集本身的标注，也可以由其他已经训练好的图像分类或物体识别模型自动生成。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在测试阶段，对于给定图片和识别出来的物体标签，模型采用了自回归（auto-regressive）的方式生成字符序列，从而获得描述图片的一句话。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages\" data-cropselx1=\"0\" data-cropselx2=\"40\" data-cropsely1=\"0\" data-cropsely2=\"40\" data-ratio=\"1.118421052631579\" data-s=\"300,640\" data-type=\"png\" data-w=\"76\" style=\"height: 35px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPMhaNuospc1FrHVRVv0cGu9TicyLQdiaAAET8gXokXUcaQ3JGpyrZpaj7ajY2HRYGW3v4icv66VKcYg/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">SOTA 首次超越人类</span></section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(160, 219, 239);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究员们将 VIVO 与 nocaps 挑战中一些领先的方法，如 UpDown 、 OSCAR 等做了对比（这些方法使用的训练数据也是 COCO）。另外，遵循之前的方法，添加了使用 SCST 和 Constrained Beam Search (CBS)之后的结果。在 nocaps 的校验集（validation）和测试集（test）上的结果显示在表1中。可以看到，相比于之前的方法，VIVO 的结果表现有了显著的提高。仅仅使用 VIVO 预训练就取得了远超过 UpDown+ELMo+CBS 和 OSCAR 的结果。最终，</span><span style=\"color: rgb(0, 0, 0);font-size: 15px;background-color: rgb(160, 219, 239);\">VIVO 方法的结果达到了新的 SOTA，并且首次在 nocaps 挑战中超过了人类表现的 CIDEr 得分</span><span style=\"font-size: 15px;\">。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><img class=\"rich_pages\" data-ratio=\"0.4941118743866536\" data-s=\"300,640\" data-type=\"png\" data-w=\"2038\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MfxkdCB9gP9CogdHOEm66me2BXZCDCAzoOvKhTd54D6fdm4uIb3g8xw/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">表1：各种方法在 nocaps 的校验和测试数据集上的结果</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">为了进一步理解 VIVO 预训练中学习视觉词表所产生的作用，即在图像和文字的共同特征空间中对准图像与相应的语义标签，研究员们展示了如何根据这些新物体的标签找到它们在图片中的位置（grounding to image regions）。对于每个图片区域和每个物体标签的两两配对，VIVO 都计算了它们对应特征向量之间的相似度（cosine similarity）。图3高亮了其中得分高的配对。可以看出，VIVO 的模型能够准确地在众多区域中确定这些物体所在的位置。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"318\" data-ratio=\"0.6463878326996197\" data-s=\"300,640\" data-type=\"png\" data-w=\"1841\" style=\"width: 562px; height: 363px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MaCPJictjBIria727kkMdMh3aC73vjT1hCyodGWvFYx9FAf0WyhmktnibA/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图3：模型对 nocaps 图片的描述结果。B：没有做 VIVO 预训练的模型。V：有 VIVO 预训练的模型。红色文字显示了描述中出现的新物体。图中还显示了各个图片区域和描述中出现的新物体对应特征向量之间的相似度，相似度越高的组合颜色亮度越高。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">VIVO 展示了视觉词表对描述图片中新出现的物体的重要作用。作为第一个不依赖于图片文本标注（paired image-sentence data）的图像与文本交互的预训练（Vision-Language Pre-training）方法，VIVO 成功运用了计算机视觉研究中已经标注的大规模图片标签数据（image tagging data）来进行全新模式的图像与文本交互预训练。值得注意的是，如果可以利用模型自动给图片生成标签，而不需要人工标注文本描述，那么可以在训练时加入可能无限多的无标注图片，从而进一步提高模型的表现，微软的研究人员也将在未来的后续工作中对此进行更多探索。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><section data-role=\"paragraph\" style=\"white-space: normal;\"><section style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;background-color: rgb(255, 255, 255);\"><section style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"margin-top: 10px;margin-bottom: 10px;text-align: center;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"margin-bottom: -3px;padding-top: 3px;width: 677px;border-bottom: 1px dotted rgb(160, 160, 160);max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><br style=\"box-sizing: border-box;max-width: 100%;overflow-wrap: break-word;\"></section><section style=\"height: 5px;line-height: 5px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"vertical-align: top;display: inline-block;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><span style=\"margin-left: 5px;border-color: rgb(160, 160, 160);border-radius: 50%;border-style: solid;border-width: 1px;box-sizing: border-box;float: left;height: 5px;max-width: 100%;overflow-wrap: break-word;width: 5px;\"><br style=\"box-sizing: border-box;max-width: 100%;overflow-wrap: break-word;\"></span></section><section style=\"clear: both;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><br></section></section></section></section></section><section style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;background-color: rgb(255, 255, 255);\"><section style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"margin-top: 10px;margin-bottom: 10px;text-align: center;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"height: 5px;line-height: 5px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"clear: both;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><br style=\"box-sizing: border-box;max-width: 100%;overflow-wrap: break-word;\"></section></section></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;min-height: 1em;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;background-color: rgb(255, 255, 255);\"><strong style=\"box-sizing: border-box;color: rgb(46, 87, 151);font-size: 15px;letter-spacing: 1px;max-width: 100%;overflow-wrap: break-word;\">你也许还想看</strong><strong style=\"box-sizing: border-box;color: rgb(46, 87, 151);font-size: 15px;letter-spacing: 1px;max-width: 100%;overflow-wrap: break-word;\">：</strong></p><p style=\"white-space: normal;\"><br></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649456101&amp;idx=1&amp;sn=4a79b1a8bfe1bc0a4f5e224970f928ab&amp;chksm=82c09461b5b71d7723980d903ad5977fb4af37e31c12beda3f63567c01dbbebfef07e7a7dbd4&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729Mr6JqsbibRXsfDSGEibHeFX61un0lN2icoAnCKiaGGdiaKfKdOPbicKlHZMkw/640?wx_fmt=png\"></span></a></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455851&amp;idx=1&amp;sn=f7bc0f5ad93ac8fe95c4e352835a67ab&amp;chksm=82c0956fb5b71c7907877b3adf8a247cc17ca4a97229a1a20dff2a19b0c0a02d19e35ce2fe24&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729Mvh4qGf2Oyb6iaUwZKqj3ZdJQiaeVQ0zhOuLGmLXMaNM4NZ9aFnic4IocQ/640?wx_fmt=png\"></span></a></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455452&amp;idx=1&amp;sn=724935f743db375fba21af541167a8d4&amp;chksm=82c092d8b5b71bce8b72ca903bd8abd3b38b5cabf5f56013a1821c14eb0a12f0d098badf9d17&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MARddbia4nR6PFTKczcaCZpJiaIQe5TsZqwgJg5L2tqtg4wuBnlXHS4Mg/640?wx_fmt=png\"></span></a></section><section style=\"margin: 20px 8px;white-space: normal;display: flex;justify-content: center;align-items: center;\"><section data-width=\"90%\" style=\"background: rgb(137, 137, 137);width: 562px;height: 2px;\"><br></section></section><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 15px;letter-spacing: 1px;\"><img class=\"__bg_gif\" data-copyright=\"0\" data-ratio=\"0.5\" data-type=\"gif\" data-w=\"750\" style=\"box-sizing: border-box; color: rgb(51, 51, 51); max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif\"></span></section><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages\" data-ratio=\"0.41379310344827586\" data-type=\"gif\" data-w=\"638\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNMMrKApwKS4eEP6EC9NIpYiaLvqtet8icWZqrHsFqWkWrN99RVkkGGEOOCCj9XPXW5H1ZhwOQulrxZg/640?wx_fmt=gif\" style=\"max-width: 600px\"></section>\n                </div>\n\n    \n        <br>\n        <div id=\"js_toobar3\" class=\"rich_media_tool\">\n            <a target=\"_blank\" href=\"https://arxiv.org/abs/2009.13682\" id=\"js_view_source\" class=\"media_tool_meta meta_primary\">阅读原文</a>\n        </div>\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649456511&amp;idx=1&amp;sn=7f456f5648b99cf5105a7b3662210701&amp;chksm=82c096fbb5b71fed45165480eff920b7211b972dcd23657a76b9c9624d8b5f59a3011965e8a9&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/5416/izzA37Vnts\"></div></div>","descriptionType":"html","publishedDate":"Wed, 14 Oct 2020 10:00:00 +0000","feedId":1700,"bgimg":"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MEQiaiawTsPxb35M4vrInZ2UNib5fWJ4MSnIS1C5eHjzdobBS2cYsheCnA?imageView2/1/w/600","linkMd5":"cc976fb8d1951dbafe084242e404c1dc","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn8@2020_3/2020/10/19/02-07-50-085_098a59bd01fb9aec.webp","destWidth":600,"destHeight":383,"sourceBytes":42795,"destBytes":36438,"author":"","articleImgCdnMap":{"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MEQiaiawTsPxb35M4vrInZ2UNib5fWJ4MSnIS1C5eHjzdobBS2cYsheCnA?imageView2/1/w/600":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn8@2020_3/2020/10/19/02-07-50-085_098a59bd01fb9aec.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn46@2020_5/2020/10/19/02-07-55-717_d8f757d4d88b52d6.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPMhaNuospc1FrHVRVv0cGu9TicyLQdiaAAET8gXokXUcaQ3JGpyrZpaj7ajY2HRYGW3v4icv66VKcYg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn52@2020_5/2020/10/19/02-07-51-691_f61698ba2e51c308.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MTAia5kzmw1fYTiaJfUrTicsmfuG4f5RXiaziaqLgjIYgxmCkFbfnUHZRQJQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn44@2020_6/2020/10/19/02-08-05-240_9078890fe2660f5c.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOavZVEm7xKDfEicWic2fom1szrFRuyhT9uKdNaGX110LmLiaoyA82638K20Qxb6reNSlLk9sPPqJREQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn24@2020_3/2020/10/19/02-07-58-940_f32425327883d918.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MfxkdCB9gP9CogdHOEm66me2BXZCDCAzoOvKhTd54D6fdm4uIb3g8xw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn30@2020_2/2020/10/19/02-08-00-118_4f53918f65d3c8fe.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MaCPJictjBIria727kkMdMh3aC73vjT1hCyodGWvFYx9FAf0WyhmktnibA/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729Mr6JqsbibRXsfDSGEibHeFX61un0lN2icoAnCKiaGGdiaKfKdOPbicKlHZMkw/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729Mvh4qGf2Oyb6iaUwZKqj3ZdJQiaeVQ0zhOuLGmLXMaNM4NZ9aFnic4IocQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MARddbia4nR6PFTKczcaCZpJiaIQe5TsZqwgJg5L2tqtg4wuBnlXHS4Mg/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNMMrKApwKS4eEP6EC9NIpYiaLvqtet8icWZqrHsFqWkWrN99RVkkGGEOOCCj9XPXW5H1ZhwOQulrxZg/640?wx_fmt=gif":null,"http://www.jintiankansha.me/rss_static/5416/izzA37Vnts":null},"publishedOrCreatedDate":1603073266932}],"record":{"createdTime":"2020-10-19 10:07:46","updatedTime":"2020-10-19 10:07:46","feedId":1700,"fetchDate":"Mon, 19 Oct 2020 02:07:46 +0000","fetchMs":355,"handleMs":32,"totalMs":127891,"newArticles":0,"totalArticles":5,"status":1,"type":0,"ip":"c52038f4f02d4346eb87a3f21493621d","hostName":"europe64*","requestId":"2f5db18cfbf2441fa8d238536000e3b6_1700","contentType":"application/rss+xml","totalBytes":237984,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":13,"articlesImgsGithubTotal":6,"successGithubMap":{"myreaderx25":1,"myreaderx27":1,"myreaderx21":1,"myreaderx4":1,"myreaderx2":1,"myreaderx13":1},"failGithubMap":{"myreaderx23":1}},"feed":{"createdTime":"2020-08-24 21:31:32","updatedTime":"2020-09-01 09:51:25","id":1700,"name":"微软研究院AI头条","url":"http://feedmaker.kindle4rss.com/feeds/MSRAsia.weixin.xml","subscriber":null,"website":null,"icon":"http://www.sogou.com/images/logo/new/favicon.ico?v=4","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn60@2020_1/2020/09/01/01-51-26-423_d24121c9beed1de6.ico","description":"专注科研18年，盛产黑科技","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2020-10-19 10:09:54","updatedTime":"2020-10-19 10:09:54","id":null,"feedId":1700,"linkMd5":"cc976fb8d1951dbafe084242e404c1dc"}],"tmpCommonImgCdnBytes":36438,"tmpBodyImgCdnBytes":201546,"tmpBgImgCdnBytes":0,"extra4":{"start":1603073266244,"total":0,"statList":[{"spend":656,"msg":"获取xml内容"},{"spend":32,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":1,"msg":"修正封面图上传失败重新上传"},{"spend":123138,"msg":"正文链接上传到cdn"}]},"extra5":13,"extra6":8,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5416/izzA37Vnts","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":435,"convertSpendMs":0,"createdTime":"2020-10-19 10:07:51","host":"us-003*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MfxkdCB9gP9CogdHOEm66me2BXZCDCAzoOvKhTd54D6fdm4uIb3g8xw/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":999,"convertSpendMs":0,"createdTime":"2020-10-19 10:07:51","host":"europe66*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5416/izzA37Vnts","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":2017,"convertSpendMs":0,"createdTime":"2020-10-19 10:07:51","host":"europe-60*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729Mr6JqsbibRXsfDSGEibHeFX61un0lN2icoAnCKiaGGdiaKfKdOPbicKlHZMkw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"sourceBytes":201969,"destBytes":27996,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":6034,"convertSpendMs":21,"createdTime":"2020-10-19 10:07:51","host":"us-039*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn13/contents/2020/10/19/02-07-57-126_42a5688a3b6e8254.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 19 Oct 2020 02:07:57 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["C81E:5A0B:2149190:35A7201:5F8CF4FA"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1603076645"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn13/contents/2020/10/19/02-07-57-126_42a5688a3b6e8254.webp","historyStatusCode":[],"spendMs":42},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"197.2 KB","destSize":"27.3 KB","compressRate":"13.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729Mr6JqsbibRXsfDSGEibHeFX61un0lN2icoAnCKiaGGdiaKfKdOPbicKlHZMkw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"sourceBytes":201969,"destBytes":27996,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5387,"convertSpendMs":28,"createdTime":"2020-10-19 10:07:57","host":"us-039*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn13/contents/2020/10/19/02-08-02-580_42a5688a3b6e8254.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 19 Oct 2020 02:08:02 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["D14C:4362:A0E366:1889909:5F8CF502"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1603076645"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn13/contents/2020/10/19/02-08-02-580_42a5688a3b6e8254.webp","historyStatusCode":[],"spendMs":56},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"197.2 KB","destSize":"27.3 KB","compressRate":"13.9%"},null,null,null,null,null,null,null,null,null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-039.herokuapp.com/":{"failCount":1,"successCount":2,"resultList":[200,200,null]},"http://us-028.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://europe61.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe66.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://europe-60.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://us-020.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-54.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe21.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-019.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-003.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://us-51.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://europe67.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-008.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-040.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MEQiaiawTsPxb35M4vrInZ2UNib5fWJ4MSnIS1C5eHjzdobBS2cYsheCnA?imageView2/1/w/600","sourceStatusCode":200,"destWidth":600,"destHeight":383,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn8@2020_3/2020/10/19/02-07-50-085_098a59bd01fb9aec.webp","sourceBytes":42795,"destBytes":36438,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":3885,"convertSpendMs":77,"createdTime":"2020-10-19 10:07:47","host":"us-012*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc,cc976fb8d1951dbafe084242e404c1dc","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.8 KB","destSize":"35.6 KB","compressRate":"85.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPMhaNuospc1FrHVRVv0cGu9TicyLQdiaAAET8gXokXUcaQ3JGpyrZpaj7ajY2HRYGW3v4icv66VKcYg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":76,"destHeight":85,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn52@2020_5/2020/10/19/02-07-51-691_f61698ba2e51c308.webp","sourceBytes":1776,"destBytes":2060,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":1435,"convertSpendMs":3,"createdTime":"2020-10-19 10:07:51","host":"us-008*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc,cc976fb8d1951dbafe084242e404c1dc,cc976fb8d1951dbafe084242e404c1dc,cc976fb8d1951dbafe084242e404c1dc","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.7 KB","destSize":"2 KB","compressRate":"116%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif","sourceStatusCode":200,"destWidth":637,"destHeight":114,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn46@2020_5/2020/10/19/02-07-55-717_d8f757d4d88b52d6.webp","sourceBytes":21989,"destBytes":14032,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5527,"convertSpendMs":58,"createdTime":"2020-10-19 10:07:51","host":"us-020*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.5 KB","destSize":"13.7 KB","compressRate":"63.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOavZVEm7xKDfEicWic2fom1szrFRuyhT9uKdNaGX110LmLiaoyA82638K20Qxb6reNSlLk9sPPqJREQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":624,"destHeight":356,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn24@2020_3/2020/10/19/02-07-58-940_f32425327883d918.webp","sourceBytes":158652,"destBytes":34336,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":8656,"convertSpendMs":25,"createdTime":"2020-10-19 10:07:51","host":"us-028*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"154.9 KB","destSize":"33.5 KB","compressRate":"21.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MfxkdCB9gP9CogdHOEm66me2BXZCDCAzoOvKhTd54D6fdm4uIb3g8xw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":534,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn30@2020_2/2020/10/19/02-08-00-118_4f53918f65d3c8fe.webp","sourceBytes":238884,"destBytes":73094,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":8835,"convertSpendMs":37,"createdTime":"2020-10-19 10:07:52","host":"us-51*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"233.3 KB","destSize":"71.4 KB","compressRate":"30.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNMwdIAPMCjYyC3E1Y3q729MTAia5kzmw1fYTiaJfUrTicsmfuG4f5RXiaziaqLgjIYgxmCkFbfnUHZRQJQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":626,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn44@2020_6/2020/10/19/02-08-05-240_9078890fe2660f5c.webp","sourceBytes":490881,"destBytes":78024,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":15119,"convertSpendMs":121,"createdTime":"2020-10-19 10:07:51","host":"us-019*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E6%8C%91%E6%88%98%E6%96%B0%E7%89%A9%E4%BD%93%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A1%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0","linkMd5ListStr":"cc976fb8d1951dbafe084242e404c1dc","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"479.4 KB","destSize":"76.2 KB","compressRate":"15.9%"}],"successGithubMap":{"myreaderx25":1,"myreaderx27":1,"myreaderx21":1,"myreaderx4":1,"myreaderx2":1,"myreaderx13":1},"failGithubMap":{"myreaderx23":1}}