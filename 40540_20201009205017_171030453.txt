{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-10-10 04:48:15","updatedTime":"2020-10-10 04:48:15","title":"The Google Assistant for Android developers – PART 1","link":"https://blog.octo.com/?p=85660","description":"<div align=\"justify\">\n<p>Everybody knows about the <a href=\"https://assistant.google.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Google Assistant</a>, available on most Android and iPhone devices. As for <em>“Hey Siri”</em>, the well known <em>“Ok Google”</em> has entered common language. We probably all have already used it at least once if only to try it.</p>\n<p>However, the scope of its field of action and implementation seems to be mysterious for us developers. At least, it was for me until recently.</p>\n<p>Is it only a mobile feature? Can we use it in our application? What are the possibilities of interactions?</p>\n<p>We will answer these questions and more through this article and we will then focus on what interest us here: how to build an interaction with our Android application through the Assistant.</p>\n</div>\n<h2>The Google Assistant?</h2>\n<div align=\"justify\">\n<p>The Google Assistant is a conversational interface that we interact with, mainly using our voice. Though popular on smartphones, it is present on more than a billion different devices such has speakers, smart screens, cars, TVs and connected watches. Its main goal is to improve the discoverability and the interactions of our applications and websites.</p>\n<p>We can for instance use it by a long press on the &#8220;Home&#8221; button of our smartphone or simply by saying <em>“Ok Google”</em> or <em>“Hey Google”</em>.</p>\n<p>It is based on Natural Language Processing (NLP) and artificial intelligence in order to transform a vocal input into a request that a computer program can interpret. To put it simply, when the request of a user matches a specific grammar, the Assistant extracts the request parameters into <a href=\"https://schema.org/\" target=\"_blank\" rel=\"noopener noreferrer\">schema.org</a> entities and generate <a href=\"https://developer.android.com/training/app-links\" target=\"_blank\" rel=\"noopener noreferrer\">Android Deep Link</a> URLs using the mapping given into the <code>actions.xml</code> file.</p>\n<p>A lot of interactions, that we know of, already exist such as launching a video on YouTube or a song on Spotify, the displaying of an itinerary on Google Maps, the setting of a timer in our Clock application or the simple triggering of an internet search.</p>\n</div>\n<p><img class=\"aligncenter wp-image-85641\" src=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-300x296.png\" alt=\"\" width=\"600\" height=\"592\" srcset=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-300x296.png 300w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-1024x1010.png 1024w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-160x158.png 160w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example.png 1308w\" sizes=\"(max-width: 600px) 100vw, 600px\" /></p>\n<div align=\"justify\">But there are way more possibilities.</div>\n<h2>Implementation on Android</h2>\n<div align=\"justify\">\n<p>But then, can I, Android developper, build my own interactions on the Assistant? The answer is yes, but to a certain extent.</p>\n<p>Google offers to the developers the possibility to build their own interactions by using actions called <a href=\"https://developers.google.com/actions/appactions/overview\" target=\"_blank\" rel=\"noopener noreferrer\">App Actions</a> that are intents holding a request to establish a link with our application.</p>\n<p>There are many possibilities to build these actions. We will focus on the two that are relative to the Android development for our application:</p>\n<ul>\n<li>The “<strong>Solutions</strong>” part which contains actions provided by Google to simplify everything for us. These actions are built-in intents that will allow us to build interactions in no time. However, they will not let us build conversations with the Assistant. See them as triggers, simple orders. Also, they can only be used to launch features in our applications with very few visual responses.</li>\n</ul>\n<ul>\n<li>The “<strong>Custom Conversations</strong>” part, way more interesting from a developer perspective. These actions are build by the developer through DialogFlow and allow us to create &#8220;real&#8221; conversations with the Assistant. They can also provide visual interactions that will never require the launching of the application.</li>\n</ul>\n<p>First, we will focus on the &#8220;Solutions&#8221; part in order to understand the concept of a simple App Action through its implementation in an application. Then, we will see the &#8220;Custom Conversations&#8221; part in a later article.</p>\n</div>\n<h2>Implementation of a simple App Action</h2>\n<div align=\"justify\">\n<p>Before starting, it is important to know that by now, App Actions are still in developer preview. We will thus be able to build and test our actions but it will be impossible to trigger it through voice command in the Assistant. But don’t worry, we will still be able to visualize the result of our work into it.</p>\n<p>We will create a simple application that will be launched using one of the build-in intents provided by Google. The goal is to launch a feature by specifying its name.</p>\n<p>It will look like this:</p>\n<ul>\n<li>a <strong>main activity</strong> which is a hub leading to 3 features through 3 buttons</li>\n<li>one <strong>activity per feature</strong> displaying a title, a subtitle and an image</li>\n</ul>\n</div>\n<p><img class=\"aligncenter wp-image-85638\" src=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi-300x238.png\" alt=\"\" width=\"750\" height=\"595\" srcset=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi-300x238.png 300w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi-1024x812.png 1024w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi-160x127.png 160w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi.png 1123w\" sizes=\"(max-width: 750px) 100vw, 750px\" /></p>\n<div align=\"justify\">\n<p>Finally, we will improve our interaction with the Assistant by displaying a Slice holding the information of the requested feature.</p>\n<p>Let&#8217;s do this!</p>\n</div>\n<h2>Prerequisite</h2>\n<div align=\"justify\">In order to build an App Action for our application, we need to setup a few things. First, it is important to know that App Actions are only available <strong>starting Android 5</strong> (API 21).<br />\nAlso, it is necessary to <strong>implement deep links</strong> into our application to allow Google to link our actions to our activities. We will not cover this part here, but it is easy and quick to generate these deep links through the App Links Assistant accessible from the &#8220;Tools&#8221; tab of Android Studio.<br />\nFinally, it is primordial to have our application <strong>uploaded on the Google Play Console</strong> (a draft is enough) in order to be able to test our actions, and to be <strong>logged with the same account</strong> on the Console, in Android Studio and on our device / emulator.</div>\n<h2>The application</h2>\n<div align=\"justify\">\n<p>First, let’s build a basic application. The code being very simple and of no specific interest, it is not shown here but <a href=\"https://github.com/NicolasTelera/AppActionsApp\" target=\"_blank\" rel=\"noopener noreferrer\">the code</a> is available on GitHub. You will find there an <code>AppActionsActivity</code> which sets 3 listeners on 3 buttons allowing the launching of each feature. You will also notice the presence of an <code>intent-filter</code> in the manifest to handle deep links.</p>\n<h2>Adding of an App Action</h2>\n<p>Among the <a href=\"https://developers.google.com/actions/reference/built-in-intents/app-actions\" target=\"_blank\" rel=\"noopener noreferrer\">built-in intents</a> provided by Google, we can find a lot of generic actions such as <code><strong>START_EXERCISE</strong></code>, <code><strong>CREATE_TAXI_RESERVATION</strong></code> or <code><strong>GET_ACCOUNT</strong></code>, each one enabling the launching of a specific feature in our application with the appropriate parameters.</p>\n<p>We will use here the most generic of them all: <code><strong>OPEN_APP_FEATURE</strong></code>.</p>\n<p>In order to do that, we need to create a new &#8220;xml&#8221; package into the &#8220;res&#8221; directory of our application and add a new <code>actions.xml</code> file there. This file will hold the structure of the actions that will be in our application and the different ways to access them (deep link or Slice) with the accepted and / or necessary parameters.</p>\n<p>So let’s add our action to the <code>actions.xm</code>l file:</p>\n<p><script src=\"https://gist.github.com/NicolasTelera/9c30f8653ec0729153c776a40707f299.js\"></script></p>\n<div align=\"justify\">You can notice the different parts:</div>\n<p>&#160;</p>\n<table border=\"1\">\n<tbody>\n<tr>\n<td><code><strong>intentName</strong></code></td>\n<td>the name of the used built-in intent</td>\n</tr>\n<tr>\n<td><code><strong>fullfilmentMode</strong></code></td>\n<td>the mode to fulfill the action, here a deep link</td>\n</tr>\n<tr>\n<td><code><strong>urlTemplate</strong></code></td>\n<td>the URL template to use for our deep link with its parameters</td>\n</tr>\n<tr>\n<td><code><strong>intentParameter</strong></code></td>\n<td>the name of the parameter taken from the URL that will be passed to the intent sent to our application</td>\n</tr>\n<tr>\n<td><code><strong>urlParameter</strong></code></td>\n<td>the name of the parameter to map in the URL</td>\n</tr>\n</tbody>\n</table>\n<p>&#160;</p>\n<div align=\"justify\">We now need to point to this file in our <code>AndroidManifest.xml</code>:</div>\n<p><script src=\"https://gist.github.com/NicolasTelera/989aab72519c8c38a685dc1490c62afb.js\"></script></p>\n<div align=\"justify\">\n<p><em><span style=\"color: #6d6d6d;\"><u><strong>Warning</strong></u>: at the moment, it is impossible to upload an APK or an AAB containing an <code>AndroidManifest.xml</code> pointing to an <code>actions.xml</code> file on the Google Play Console. You just need to remove it from the manifest before uploading it and then put it back locally to be able to test your App Actions.</span></em></p>\n<p>We still need to handle the received intent within our application. To do this, let’s create a private method in the <code>AppActionsActivity</code>, called from <code>onCreate</code>, to extract the data from the intent in order to check that its type is <code>Intent.ACTION_VIEW</code>, that it contains the necessary parameters if needed and, in our case, redirect to the specified feature.</p>\n</div>\n<p><script src=\"https://gist.github.com/NicolasTelera/bbc2d9b8e294fd8addee99c3a835ed8b.js\"></script></p>\n<div align=\"justify\">\n<p>For the sake of this article, we decided to handle the redirection from the <code>AppActionsActivity</code>, but we could have decided to create one deep link per feature to avoid this redirection. Built-in intents only are pre-formatted entry points but the behavior resulting in the application is the responsibility of the developer, which offers great freedom.</p>\n<p>It is time to test our App Action. To do so, you need to install the &#8220;App Actions Test Tool&#8221; plugin and launch it from the &#8220;Tools&#8221; tab in Android Studio. By clicking the &#8220;Create Preview&#8221; button, Google checks the presence of an application sharing the same application ID on the Google Play Console and then generates the necessary deep links automatically.</p>\n</div>\n<p><img class=\"aligncenter wp-image-85644\" src=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool-1024x618.png\" alt=\"\" width=\"768\" height=\"464\" srcset=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool-1024x618.png 1024w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool-300x181.png 300w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool-160x97.png 160w, https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool.png 1756w\" sizes=\"(max-width: 768px) 100vw, 768px\" /></p>\n<div align=\"justify\">You can notice that our <code>OPEN_APP_FEATURE</code> App Action has been configured and that all we have left to do is type the name of the feature we want to launch before clicking &#8220;Run&#8221;. You can now see that the Assistant launches on your device / emulator and redirects us to our application then to the right feature.</div>\n<p>&#160;</p>\n<p><img class=\"aligncenter size-full wp-image-85647\" src=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_deeplink.gif\" alt=\"\" width=\"360\" height=\"760\" /></p>\n<div align=\"justify\">Note that if the asked feature doesn’t exist, the application will still be launched by default.</div>\n<h2>Displaying of a Slice</h2>\n<div align=\"justify\">\n<p>In order to make our interaction with the Assistant more visual, we are now going to add a step between the request to the Assistant and the launching of our application through the implementation of the <a href=\"https://developer.android.com/guide/slices\" target=\"_blank\" rel=\"noopener noreferrer\">Android Slices</a>.</p>\n<p>Without going into the details of implementing Slices, we are going to see the configuration to use so that the Slice is sent to the Assistant.</p>\n<p>We need to add one entry point into our <code>actions.xml</code>:</p>\n</div>\n<p><script src=\"https://gist.github.com/NicolasTelera/c4a5c368ed2180a53801091926a7c965.js\"></script></p>\n<div align=\"justify\">\n<p>As previously with the DEEPLINK entry point, we can see:</p>\n<table border=\"1\">\n<tbody>\n<tr>\n<td><code><strong>fullfilmentMode</strong></code></td>\n<td>the mode to fulfill the action, here a deep link</td>\n</tr>\n<tr>\n<td><code><strong>urlTemplate</strong></code></td>\n<td>the URL template to use for our deep link with its parameters (it must respect this format: &#8220;content://{slice_authority}/…&#8221;, the slice authority being declared in the manifest)</td>\n</tr>\n<tr>\n<td><code><strong>intentParameter</strong></code></td>\n<td>the name of the parameter taken from the URL that will be passed to the intent sent to our application</td>\n</tr>\n<tr>\n<td><code><strong>urlParameter</strong></code></td>\n<td>the name of the parameter to map in the URL</td>\n</tr>\n</tbody>\n</table>\n<p>&#160;</p>\n<p>Thus, when you run the App Action from the test tool, the application will send a Slice holding the information of the requested feature (title, subtitle and image) to the Assistant and that will redirect us to the specified feature when clicked.</p>\n</div>\n<p><img class=\"aligncenter wp-image-85650\" src=\"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_slice.gif\" alt=\"\" width=\"360\" height=\"760\" /></p>\n<div align=\"justify\">It will also be necessary to grant the permission to access Slices to the Assistant at launch by asking the permission in an <code>Application</code> class:</div>\n<p><script src=\"https://gist.github.com/NicolasTelera/2a2ec10e04140c580975f355aa779bf3.js\"></script></p>\n<h2>Conclusion</h2>\n<div align=\"justify\">\n<p>In this article, we have seen what is the Google Assistant, mainly from the Android perspective. We have built a small application allowing, in the first place, to access a specific feature and then to display a Slice into the Assistant redirecting to the displayed feature when clicked. And all of this very easily using the &#8220;Solutions&#8221; part offered by Google and providing built-in intents that can automatically handle deep links.</p>\n<p>We will see the &#8220;Custom Conversations&#8221; part in a coming article in which we will focus on DialogFlow.</p>\n<p>During my research, I encountered some difficulties to which I still don’t have answers. For instance, I wanted to use only one FeatureActivity that would be configured with an extra holding the requested feature. But my activity always stayed configured on the first invocation (cache system?). Also, I had many instabilities with the Assistant on an emulator. For the time being, I would advise to test your App Actions directly on your device (you may need to configure its locale to en-US).</p>\n<p>Note that, when you App Action is ready, it is possible to submit it to Google through a <a href=\"https://developers.google.com/actions/appactions/deployment-request\" target=\"_blank\" rel=\"noopener noreferrer\">form</a> in order to be able to deploy it to production.</p>\n<p>Finally, I would like to remind <a href=\"https://twitter.com/elainedbatista\" target=\"_blank\" rel=\"noopener noreferrer\">Elaine Batista Dias</a>’s message, which I thank for her help, from <a href=\"https://www.youtube.com/watch?v=kqIRTUZcQ6M\" target=\"_blank\" rel=\"noopener noreferrer\">her talk</a> during the 2019 edition of Android Makers:</p>\n<blockquote><p><em>“Google Assistant is still new, think outside the box.”</em></p></blockquote>\n<p>See you in <a href=\"https://blog.octo.com/en/the-google-assistant-for-android-developers-part-2/\" target=\"_blank\" rel=\"noopener noreferrer\">the next article</a>.</p>\n</div>\n</div>\n","descriptionType":"html","publishedDate":"Mon, 07 Oct 2019 06:00:47 +0000","feedId":40540,"bgimg":"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-300x296.png","linkMd5":"608aeab3bf2d3a7fb6f7b08c4598e40f","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx/cdn59@2020_2/2020/10/09/20-48-15-852_a122ef72cb4daa7a.webp","destWidth":300,"destHeight":296,"sourceBytes":74367,"destBytes":10138,"author":"Nicolas Telera","articleImgCdnMap":{"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-300x296.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn59@2020_2/2020/10/09/20-48-15-852_a122ef72cb4daa7a.webp","https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi-300x238.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn72@2020_4/2020/10/09/20-48-17-271_c87ab9c752a6ef13.webp","https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool-1024x618.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn73@2020_4/2020/10/09/20-48-17-432_001deaf5e0fbe6b3.webp","https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_deeplink.gif":null,"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_slice.gif":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn68@2020_4/2020/10/09/20-48-40-048_39409e5b993670dd.webp"},"publishedOrCreatedDate":1602276495082}],"record":{"createdTime":"2020-10-10 04:48:15","updatedTime":"2020-10-10 04:48:15","feedId":40540,"fetchDate":"Fri, 09 Oct 2020 20:48:15 +0000","fetchMs":559,"handleMs":34,"totalMs":122762,"newArticles":0,"totalArticles":10,"status":1,"type":0,"ip":"6c4fdaffa870bf29ab6ae46cdf2a9527","hostName":"us-037*","requestId":"0cf802bd2c5a4b8bb28f81d9381349eb_40540","contentType":"application/rss+xml; charset=UTF-8","totalBytes":4043026,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":5,"articlesImgsGithubTotal":4,"successGithubMap":{"myreaderx16":1,"myreaderx10":1,"myreaderx33":1,"myreaderx":1},"failGithubMap":{}},"feed":{"createdTime":"2020-09-07 03:21:04","updatedTime":"2020-09-07 05:37:30","id":40540,"name":"OCTO Talks !","url":"https://blog.octo.com/en/feed/","subscriber":79,"website":null,"icon":"https://blog.octo.com/favicon.ico","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn73@2020_5/2020/09/06/21-37-26-928_efafc319af022c4d.jpg","description":"Le blog d'OCTO Technology, cabinet de conseil et de réalisation IT","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2020-10-10 04:50:17","updatedTime":"2020-10-10 04:50:17","id":null,"feedId":40540,"linkMd5":"608aeab3bf2d3a7fb6f7b08c4598e40f"}],"tmpCommonImgCdnBytes":10138,"tmpBodyImgCdnBytes":4032888,"tmpBgImgCdnBytes":0,"extra4":{"start":1602276494299,"total":0,"statList":[{"spend":750,"msg":"获取xml内容"},{"spend":34,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":120452,"msg":"正文链接上传到cdn"}]},"extra5":5,"extra6":4,"extra7ImgCdnFailResultVector":[null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-006.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe69.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-033.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_example-300x296.png","sourceStatusCode":200,"destWidth":300,"destHeight":296,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn59@2020_2/2020/10/09/20-48-15-852_a122ef72cb4daa7a.webp","sourceBytes":74367,"destBytes":10138,"targetWebpQuality":75,"feedId":40540,"totalSpendMs":1503,"convertSpendMs":13,"createdTime":"2020-10-10 04:48:15","host":"us-018*","referer":"https://blog.octo.com/?p=85660","linkMd5ListStr":"608aeab3bf2d3a7fb6f7b08c4598e40f,608aeab3bf2d3a7fb6f7b08c4598e40f","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"compressRate":"13.6%","sourceSize":"72.6 KB","destSize":"9.9 KB"},{"code":1,"isDone":false,"source":"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_archi-300x238.png","sourceStatusCode":200,"destWidth":300,"destHeight":238,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn72@2020_4/2020/10/09/20-48-17-271_c87ab9c752a6ef13.webp","sourceBytes":44387,"destBytes":9392,"targetWebpQuality":75,"feedId":40540,"totalSpendMs":1473,"convertSpendMs":10,"createdTime":"2020-10-10 04:48:16","host":"us-033*","referer":"https://blog.octo.com/?p=85660","linkMd5ListStr":"608aeab3bf2d3a7fb6f7b08c4598e40f","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"compressRate":"21.2%","sourceSize":"43.3 KB","destSize":"9.2 KB"},{"code":1,"isDone":false,"source":"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_test_tool-1024x618.png","sourceStatusCode":200,"destWidth":1024,"destHeight":618,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn73@2020_4/2020/10/09/20-48-17-432_001deaf5e0fbe6b3.webp","sourceBytes":95865,"destBytes":17924,"targetWebpQuality":75,"feedId":40540,"totalSpendMs":1646,"convertSpendMs":48,"createdTime":"2020-10-10 04:48:16","host":"us-034*","referer":"https://blog.octo.com/?p=85660","linkMd5ListStr":"608aeab3bf2d3a7fb6f7b08c4598e40f","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"compressRate":"18.7%","sourceSize":"93.6 KB","destSize":"17.5 KB"},{"code":1,"isDone":false,"source":"https://blog.octo.com/wp-content/uploads/2019/10/google_assistant_part1_slice.gif","sourceStatusCode":200,"destWidth":1080,"destHeight":2280,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn68@2020_4/2020/10/09/20-48-40-048_39409e5b993670dd.webp","sourceBytes":16792822,"destBytes":4005572,"targetWebpQuality":4,"feedId":40540,"totalSpendMs":26043,"convertSpendMs":22679,"createdTime":"2020-10-10 04:48:16","host":"europe69*","referer":"https://blog.octo.com/?p=85660","linkMd5ListStr":"608aeab3bf2d3a7fb6f7b08c4598e40f","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"compressRate":"23.9%","sourceSize":"16 MB","destSize":"3.8 MB"}],"successGithubMap":{"myreaderx16":1,"myreaderx10":1,"myreaderx33":1,"myreaderx":1},"failGithubMap":{}}