{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2022-03-14 19:44:59","updatedTime":"2022-03-14 19:44:59","title":"DeepMind两篇新论文研究用神经网络做关系推理，探索人类智慧核心","link":"http://it.sohu.com/20170607/n496011492.shtml","description":"<p align=\"right\">[ <a href=\"http://comment.news.sohu.com/comment/topic.jsp?id=496011492\">comments</a> ]</p><div>\n    <h1>\n                    DeepMind两篇新论文研究用神经网络做关系推理，探索人类智慧核心\n    </h1>\n</div>\n<article id=\"mp-editor\">\n      <p>原标题：DeepMind两篇新论文研究用神经网络做关系推理，探索人类智慧核心</p>\n                    <p>陈桦 编译自 DeepMind官方博客</p>\n<p>作者 Adam Santoro, David Raposo, Nick Watters</p>\n<p>量子位 报道 | 公众号 QbitAI</p>\n<p><span>关系推理是什么？DeepMind举了这么几个例子：</span></p>\n<p><span>阿加莎·克里斯蒂小说的读者一点点地拼凑证据猜测犯人；小朋友追到球的前边防止它滚进河里；在市场上买东西的人做各方面的比较，挑选猕猴桃或者芒果。</span></p>\n<p><span>最近，这家公司发表了两篇论文，探讨了神经网络如何用非结构化数据进行复杂关系推理，并在官方博客上对这个研究课题和两篇论文进行了介绍。</span></p>\n<p><span>以下是DeepMind官方博客上的文章，量子位编译：</span></p>\n<p>我们会将世界分割成事物之间的关系。通过对不同事物，例如实体对象、语句，甚至抽象概念之间的关系得出逻辑结论，我们就可以理解世界的运转方式。这种能力被称作关系推理，是人类智慧的核心。</p>\n<p>通过每天获得的非结构化感官信息，我们建立起这样的关系。例如，我们的眼睛接受了大量光子，而大脑则将这些混乱的信息组成为我们需要关联在一起的特定实体。</p>\n<p>如果希望人工智能系统具备类似人类认知能力的灵活性和效率，那么关键挑战在于，从非结构化数据中推断出实体及其之间的关系。这个问题的解决将使系统可以生成新的实体组合，基于有限的方法获得无限的用途。</p>\n<p>当代深度学习方法已经在处理非结构化数据方面取得了巨大进展。然而，这些方法往往没有明确考虑对象之间的关系。</p>\n<p>在两篇新论文中，DeepMind探讨了深度神经网络利用非结构化数据进行复杂关系推理的能力。在第一篇论文，《用于简单关系推理的神经网络模块》中，我们描述了一种关系网络（RN），并证明其可以在具有挑战性的任务中实现超人的水平。在第二篇论文，《视觉交互网络》中，我们描述了一种通用模型，可基于视觉观察来预测实体对象的未来状态。</p>\n<p>用于简单关系推理的神经网络模块</p>\n<p>为了更深入地探索关系推理的概念，并测试能否以简单的方式将其集成至现有系统中，我们创建了一个简单的、即插即用的RN模块，并将其添加到现有神经网络体系结构中。一个经过RN增强的网络可以接受非结构化的数据输入，例如图片或语句，并推断其中所包含对象的关系。</p>\n<p>例如，一个带RN的网络可能会看到包含不同形状的场景，例如球体和立方体。为了研究它们之间的关系（例如球体比立方体更大），网络必须从图像中获取非结构化的像素流，并指出在场景中哪些像素构成了对象。神经网络并没有被告知对象的定义，必须自己得出结论。随后，这些对象的展示经过了分组（例如球体和立方体），并由RN模块进行处理。RN模块比较这些对象，建立“关系”（例如球体比立方体更大）。这些关系并不是硬编码的，必须由RN来学习，RN对所有可能的配对进行了比较。最终，RN将这些关系综合在一起，为场景中的所有图形对生成输出。</p>            <div>\n                <section>\n                    <a href=\"\" id=\"showMore\">\n                        <em>展开全文</em>\n                    </a>\n                </section>\n            </div>\n            <div>\n                <p>我们在几种任务中测试了这个模型，包括CLEVR，一个视觉问答任务。CLEVR设计用于研究模型完成不同类型推理，例如计数、比较和查询的能力。CLEVR由以下这样的图片构成：</p>\n<p><img src=\"http://img.mp.itc.cn/upload/20170607/e6817f057c534c00baa152de65df71c4_th.jpg\" alt=\"\"></p>\n<p>每张图片都有其关联的问题，专注于场景中对象的关系。例如，关于上图的问题或许是：“这里有个小橡胶品，和大圆柱体的颜色一样，它是什么形状？”</p>\n<p>基于标准视觉问答架构，CLEVR取得的最佳成绩是正确率68.5%，而人类的成绩为92.5%。然而，通过由RN增强的网络，我们取得了超人的水平：95.5%。</p>\n<p>为了检查RN的普适性，我们还在不同的语言任务中测试了RN。具体来说，我们使用了bAbI套件，即一系列基于文字的问答任务。bAbI由许多故事组成，这些故事包含许多不同语句，最后引出一个问题。例如，句子可能是“桑德拉拿起足球”和“桑德拉去办公室”，问题可能是“足球在哪里？”答案当然是：办公室。</p>\n<p>在20个bAbI任务中的18个中，经过RN增强的网络得分超过95%，类似于当前最强大的模型。值得注意的是，在某些特定任务，例如归纳方面，这种网络的得分更高。而这是那些成熟模型所无法做到的。</p>\n<p>完整的测试结果和更多信息可以参阅这篇论文。</p>\n<p>视觉交互网络</p>\n<p>关系推理的另一个关键部分涉及到在现实场景中预测未来。简单来说，人类不仅可以推断出对象在哪里，还能判断接下来几秒钟、几分钟、甚至更长时间里会发生什么。举个例子，如果你对着墙踢足球，那么大脑会预测，当球撞到墙之后，将会有什么样的运动方式（球的反弹速度和你踢的力度成正比，而在大部分情况下，墙都会纹丝不动）。</p>\n<p>这样的预测由复杂的认知系统来指导，可以实现对象及其互动过程的推理。</p>\n<p>在这方面，我们开发了视觉交互网络（VIN），这种模型模仿了人类的这一能力。VIN能从几帧视频中推断出多个实体对象的状态，随后预测这些对象接下来的变化。这与生成模型不同，后者可以直观地“想象”视频接下来的几帧。相反，VIN关于对象的预测基于状态如何演化。</p>\n<p><img src=\"http://img.mp.itc.cn/upload/20170607/81261331bb104ce4a560e8635d745893_th.jpg\" alt=\"\"></p>\n<p>VIN包含两种机制：视觉模块和物理推理模块。它们可以将可视场景处理为一系列离散的对象，并学习其中的物理规则系统，从而预测这些对象未来会发生什么。</p>\n<p>我们测试了VIN在各种系统上的能力，包括球的弹跳、连接至弹簧的重物，以及存在重力作用的行星系统。结果表明，VIN能准确预测，未来数百步之后对象将会发生什么。</p>\n<p>与此前公开发表的模型，以及关系推理机制被移除的VIN相比，可以看到完整的VIN有明显更好的表现。</p>\n<p>这两篇论文都展示了有前景的方式，来理解关系推理的挑战。它们展示了神经网络如何将世界分解成对象，判断其关系，从而获得强大的推理能力。这使得神经网络可以生成新的对象组合，对表面上看起来不同，但实际有着潜在共同关系的场景进行推理。</p>\n<p>我们认为，这些方法是可扩展的，可应用于更多任务，有助于建立更复杂的推理模型，使我们更好地理解通用人类智力的关键组成部分，尽管我们认为这些能力是理所当然的。</p>\n<p>相关链接</p>\n<p>DeepMind博客原文：</p>\n<p>https://deepmind.com/blog/neural-approach-relational-reasoning/</p>\n<p>用于简单关系推理的神经网络模块：</p>\n<p>https://arxiv.org/abs/1706.01427</p>\n<p>视觉交互网络：</p>\n<p>https://arxiv.org/abs/1706.01433</p>\n<p>CLEVR：</p>\n<p>http://cs.stanford.edu/people/jcjohns/clevr/</p>\n<p>bAbl：</p>\n<p>https://research.fb.com/downloads/babi/</p>\n<p>【完】</p>\n<p>招聘</p>\n<p>量子位正在招募编辑记者、运营、产品等岗位，工作地点在北京中关村。相关细节，请在公众号对话界面，回复：“招聘”。</p>\n<p>One More Thing…</p>\n<p>今天AI界还有哪些事值得关注？在量子位（QbitAI）公众号对话界面回复“今天”，看我们全网搜罗的AI行业和研究动态。笔芯~</p>\n<p>另外，欢迎加量子位小助手的微信：qbitbot，如果你研究或者从事AI领域，小助手会把你带入量子位的交流群里。</p>\n<p>追踪人工智能领域最劲内容<a href=\"https://www.sohu.com/?strategyid=00001\" target=\"_blank\" title=\"点击进入搜狐首页\" id=\"backsohucom\" rel=\"nofollow\"><span>返回搜狐，查看更多</span></a></p>            </div>\n        <p>责任编辑：</p>\n</article>\n  <div>声明：该文观点仅代表作者本人，搜狐号系信息发布平台，搜狐仅提供信息存储空间服务。</div><p align=\"right\">[ <a href=\"http://comment.news.sohu.com/comment/topic.jsp?id=496011492\">comments</a> ]</p>","descriptionType":"text/html","publishedDate":"Mon, 14 Mar 2022 02:46:51 +0000","feedId":18910,"bgimg":"http://img.mp.itc.cn/upload/20170607/e6817f057c534c00baa152de65df71c4_th.jpg","linkMd5":"c2925d35fdf590867d4011902d5fcdfb","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn67@2020_4/2022/03/14/11-45-03-012_be7724539b44f415.webp","destWidth":1280,"destHeight":783,"sourceBytes":27632,"destBytes":20448,"author":"sohu.com","articleImgCdnMap":{"http://img.mp.itc.cn/upload/20170607/e6817f057c534c00baa152de65df71c4_th.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn67@2020_4/2022/03/14/11-45-03-012_be7724539b44f415.webp","http://img.mp.itc.cn/upload/20170607/81261331bb104ce4a560e8635d745893_th.jpg":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn71@2020_5/2022/03/14/11-46-15-382_baa6212d70795b21.webp"},"publishedOrCreatedDate":1647258299899}],"record":{"createdTime":"2022-03-14 19:44:59","updatedTime":"2022-03-14 19:44:59","feedId":18910,"fetchDate":"Mon, 14 Mar 2022 11:44:59 +0000","fetchMs":598,"handleMs":5,"totalMs":76718,"newArticles":0,"totalArticles":5,"status":1,"type":0,"ip":"79b59b7ab14b8d981e3d8a220e20848a","hostName":"us-030*","requestId":"ff18808ddb034eea98d5631b46bb266d_18910","contentType":"application/xml","totalBytes":2154040,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":2,"articlesImgsGithubTotal":2,"successGithubMap":{"myreaderx25":1,"myreaderx24":1},"failGithubMap":{}},"feed":{"createdTime":"2020-09-07 02:18:38","updatedTime":"2020-09-07 02:52:53","id":18910,"name":"科学频道 [expanded by feedex.net]","url":"https://feedex.net/feed/rss.it.sohu.com/rss/kexue.xml","subscriber":175,"website":null,"icon":"http://zmt.itc.cn/static/images/pic/sohu-logo/logo-57.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx61/cdn47@2020_3/2020/09/06/18-52-46-885_09fc37d6cd06f788.png","description":"科学的诡异与神秘，给猎奇的人们以新鲜、刺激感的同时，也让其学到不少科普知识。在这里，我们详尽提供天文地理、生命医学、历史考古等领域最新资讯","weekly":null,"link":null},"noPictureArticleList":[],"tmpCommonImgCdnBytes":20448,"tmpBodyImgCdnBytes":2133592,"tmpBgImgCdnBytes":0,"extra4":{"start":1647258299198,"total":0,"statList":[{"spend":696,"msg":"获取xml内容"},{"spend":5,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":72472,"msg":"正文链接上传到cdn"}]},"extra5":2,"extra6":2,"extra7ImgCdnFailResultVector":[null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-001.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe61.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://img.mp.itc.cn/upload/20170607/e6817f057c534c00baa152de65df71c4_th.jpg","sourceStatusCode":200,"destWidth":1280,"destHeight":783,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn67@2020_4/2022/03/14/11-45-03-012_be7724539b44f415.webp","sourceBytes":27632,"destBytes":20448,"targetWebpQuality":75,"feedId":18910,"totalSpendMs":3391,"convertSpendMs":58,"createdTime":"2022-03-14 19:45:00","host":"europe-23*","referer":"http://it.sohu.com/20170607/n496011492.shtml","linkMd5ListStr":"c2925d35fdf590867d4011902d5fcdfb,c2925d35fdf590867d4011902d5fcdfb","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27 KB","destSize":"20 KB","compressRate":"74%"},{"code":1,"isDone":false,"source":"http://img.mp.itc.cn/upload/20170607/81261331bb104ce4a560e8635d745893_th.jpg","sourceStatusCode":200,"destWidth":460,"destHeight":259,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn71@2020_5/2022/03/14/11-46-15-382_baa6212d70795b21.webp","sourceBytes":1989105,"destBytes":2133592,"targetWebpQuality":75,"feedId":18910,"totalSpendMs":11184,"convertSpendMs":9639,"createdTime":"2022-03-14 19:46:04","host":"us-001*","referer":"http://it.sohu.com/20170607/n496011492.shtml","linkMd5ListStr":"c2925d35fdf590867d4011902d5fcdfb","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.9 MB","destSize":"2 MB","compressRate":"107.3%"}],"successGithubMap":{"myreaderx25":1,"myreaderx24":1},"failGithubMap":{}}