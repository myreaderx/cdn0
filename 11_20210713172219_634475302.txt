{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MongoDB Multi-Document Transaction Fails When getLastErrorDefaults is Changed","link":"https://www.percona.com/blog/?p=77061","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MongoDB getLastErrorDefaults\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77080\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-300x157.png\" alt=\"MongoDB getLastErrorDefaults\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In every new version of <strong>MongoDB</strong>, there have been a lot of changes and newly introduced features. One such change is the introduction of </span><a target=\"_blank\" href=\"https://docs.mongodb.com/v5.0/reference/command/setDefaultRWConcern/#setdefaultrwconcern\"><b><i>setDefaultRWConcern</i></b></a><span> command from <strong><em>MongoDB 4.4</em></strong>. This feature has caused <em>multi-document transaction</em> writes to fail for one of my customers. In this blog post, we will look into the problem and how to resolve it.</span></p>\n<h2>Introduction</h2>\n<p><span>When you want to set the default common </span><strong><i>writeConcern</i></strong><span> for your <em>replicaSet</em> to use if </span><i><span>writeConcern</span></i><span> is not specified explicitly in the command, then you can set it via </span><b><i>rs.conf().settings.</i></b><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/replica-configuration/#mongodb-rsconf-rsconf.settings.getLastErrorDefaults\"><b><i>getLastErrorDefaults</i></b></a> <span>values. The default value is </span><b><i>{w: 1, wtimeout: 0}</i></b><span> i.e. requires an acknowledgment from PRIMARY member alone and this has been there for a long time in MongoDB. After upgrading to MongoDB 4.4, the customer was facing issues with multi-document transactions and the writes failed causing application downtime. </span></p>\n<h2>Issue</h2>\n<p><span>The cluster/replicaset wide </span><b><i>writeConcern</i></b><span> could be changed via </span><i><span>rs.conf().settings.</span></i><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/replica-configuration/#mongodb-rsconf-rsconf.settings.getLastErrorDefaults\"><i><span>getLastErrorDefaults</span></i></a><span> value till <strong><em>MongoDB 4.2</em></strong>. But from <strong><em>MongoDB 4.4</em></strong>, if you are using a multi-document transaction with the non-default values of </span><b><i>getLastErrorDefaults</i></b><span>, then it will eventually fail with the below message:</span></p><pre class=\"crayon-plain-tag\"> \"errmsg\" : \"writeConcern is not allowed within a multi-statement transaction\",</pre><p><span>This is because changing the default value of </span><b><i>getLastErrorDefaults</i></b><span> was deprecated from <em>MongoDB v4.4</em> and to change the global </span><i><span>writeConcern</span></i><span>/</span><i><span>readConcern</span></i><i><span>, </span></i><span>it needs to be done via the new method &#8211; </span><a target=\"_blank\" href=\"https://docs.mongodb.com/v5.0/reference/command/setDefaultRWConcern/#setdefaultrwconcern\"><i><span>setDefaultRWConcern</span></i></a><span> which was introduced in MongoDB 4.4.</span></p>\n<h2>Test Case</h2>\n<p><span>The default value of </span><b><i>getLastErrorDefaults</i></b><span> is </span><b><i>{w: 1, wtimeout: 0}</i></b><span>. Let&#8217;s change it to different values &#8211; <strong><em>{ &#8220;w&#8221; : &#8220;majority&#8221;, &#8220;wtimeout&#8221; : 3600 }</em></strong>:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; cfg = rs.conf()\nreplset:PRIMARY&#62; cfg.settings.getLastErrorDefaults.w = \"majority\"\nmajority\nreplset:PRIMARY&#62; cfg.settings.getLastErrorDefaults.wtimeout = 3600\n3600\nreplset:PRIMARY&#62; \nreplset:PRIMARY&#62; rs.reconfig(cfg)\n{\n \"ok\" : 1,\n \"$clusterTime\" : {\n  \"clusterTime\" : Timestamp(1624733172, 1),\n  \"signature\" : {\n   \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n   \"keyId\" : NumberLong(0)\n  }\n },\n \"operationTime\" : Timestamp(1624733172, 1)\n}\n\nreplset:PRIMARY&#62; rs.conf().settings.getLastErrorDefaults\n{ \"w\" : \"majority\", \"wtimeout\" : 3600 }</pre><p><span>When running a transaction into a collection </span><b><i>percona.people</i></b><span>, the error occurs and complains that writes could not be written with the changed </span><b><i>getLastErrorDefaults</i></b><span> value:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; session = db.getMongo().startSession()\nsession { \"id\" : UUID(\"3ae288d5-b793-4505-ab5b-5e37d289414a\") }\nreplset:PRIMARY&#62; session.startTransaction()\nreplset:PRIMARY&#62; session.getDatabase(\"percona\").people.insert([{_id: 1 , name : \"George\"},{_id: 2, name: \"Tom\"}])\nWriteCommandError({\n \"operationTime\" : Timestamp(1623235947, 1),\n \"ok\" : 0,\n \"errmsg\" : \"writeConcern is not allowed within a multi-statement transaction\",\n \"code\" : 72,\n \"codeName\" : \"InvalidOptions\",\n \"$clusterTime\" : {\n  \"clusterTime\" : Timestamp(1623235947, 1),\n  \"signature\" : {\n   \"hash\" : BinData(0,\"XPcHTqxG4/LNyaScd/M3ZV6yM3g=\"),\n   \"keyId\" : NumberLong(\"6952046137905774595\")\n  }\n }\n})</pre><p></p>\n<h2>How to Resolve It</h2>\n<p><span>To resolve this issue, revert </span><b><i>getLastErrorDefaults</i></b><span> to its default value if changed. Let&#8217;s change it to the default value as follows:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; cfg = rs.conf()\nreplset:PRIMARY&#62; cfg.settings.getLastErrorDefaults.w = 1\n1\nreplset:PRIMARY&#62; cfg.settings.getLastErrorDefaults.wtimeout = 0\n0\n\nreplset:PRIMARY&#62; rs.reconfig(cfg)\n{\n \"ok\" : 1,\n \"$clusterTime\" : {\n  \"clusterTime\" : Timestamp(1623236051, 1),\n  \"signature\" : {\n   \"hash\" : BinData(0,\"gZwK9B08VTiEUcLq2/1wvxW5RJI=\"),\n   \"keyId\" : NumberLong(\"6952046137905774595\")\n  }\n },\n \"operationTime\" : Timestamp(1623236051, 1)\n}\n\nreplset:PRIMARY&#62; rs.conf().settings.getLastErrorDefaults\n{ \"w\" : 1, \"wtimeout\" : 0 }</pre><p><span>Then mention the required default </span><i><span>writeConcern, readConcern</span></i><span> via the command </span><a target=\"_blank\" href=\"https://docs.mongodb.com/v5.0/reference/command/setDefaultRWConcern/#setdefaultrwconcern\"><b><i>setDefaultRWConcern</i></b></a> <span>as follows:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; db.adminCommand({ \"setDefaultRWConcern\" : 1, \"defaultWriteConcern\" : { \"w\" : \"majority\", \"wtimeout\": 3600 } })\n{\n \"defaultWriteConcern\" : {\n  \"w\" : \"majority\",\n  \"wtimeout\" : 3600\n },\n \"updateOpTime\" : Timestamp(1624786369, 1),\n \"updateWallClockTime\" : ISODate(\"2021-06-27T09:32:57.906Z\"),\n \"localUpdateWallClockTime\" : ISODate(\"2021-06-27T09:32:57.956Z\"),\n \"ok\" : 1,\n \"$clusterTime\" : {\n  \"clusterTime\" : Timestamp(1624786377, 2),\n  \"signature\" : {\n   \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n   \"keyId\" : NumberLong(0)\n  }\n },\n \"operationTime\" : Timestamp(1624786377, 2)\n}</pre><p><span>Then write with a transaction into the collection </span><b><i>percona.people</i></b><span>:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; session2 = db.getMongo().startSession()\nsession { \"id\" : UUID(\"aedf3139-08a4-466d-b1df-d8ced97abd9d\") }\nreplset:PRIMARY&#62;<strong> session2.startTransaction()</strong>\nreplset:PRIMARY&#62; session2.getDatabase(\"percona\").people.find()\nreplset:PRIMARY&#62; session2.getDatabase(\"percona\").people.insert([{_id: 4 , name : \"George\"},{_id: 5, name: \"Tom\"}])\nBulkWriteResult({\n \"writeErrors\" : [ ],\n \"writeConcernErrors\" : [ ],\n \"nInserted\" : 2,\n \"nUpserted\" : 0,\n \"nMatched\" : 0,\n \"nModified\" : 0,\n \"nRemoved\" : 0,\n \"upserted\" : [ ]\n})\nreplset:PRIMARY&#62; session2.getDatabase(\"percona\").people.find()\n{ \"_id\" : 4, \"name\" : \"George\" }\n{ \"_id\" : 5, \"name\" : \"Tom\" }\nreplset:PRIMARY&#62; session2.commitTransaction()\nreplset:PRIMARY&#62;</pre><p><span>Check the data with the different sessions to validate the writes:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; use percona\nswitched to db percona\n\nreplset:PRIMARY&#62; db.people.find()\n{ \"_id\" : 4, \"name\" : \"George\" }\n{ \"_id\" : 5, \"name\" : \"Tom\" }</pre><p></p>\n<h3><span>Note:</span></h3>\n<p><span>Here note that normal writes (non-transaction writes) are not affected by changing defaults for </span><b><i>getLastErrorDefaults.</i></b><span> So if you have an application that doesn’t use transactions, then you don’t need to act immediately to remove non-default values in </span><b><i>getLastErrorDefaults </i></b><span>though it is not recommended. </span></p>\n<h2>How <em>setDefaultRWConcern</em> Works</h2>\n<p><span>Here, we will also verify a case, whether the default </span><i><span>writeConcern</span></i><span> set via </span><b><i>setDefaultRWConcern</i></b><span> is working as expected. For testing, let’s take down a member from the 3 nodes replicaSet:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; rs.status().members.forEach(function(doc){printjson(doc.name+\" - \"+doc.stateStr)})\n\"localhost:37040 - PRIMARY\"\n\"localhost:37041 - SECONDARY\"\n\"localhost:37042 - (not reachable/healthy)\"</pre><p><span>Then test it via a </span><strong><i>insert</i></strong><span> command with </span><strong><i>writeConcern</i></strong><span> mentioned in it explicitly. It should fail as there are only 2 members alive and </span><b><i>{w:3}</i></b><span> needs acknowledgement from 3 members of the <em>replicaSet</em>:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; rs.conf().settings.getLastErrorDefaults\n{ \"w\" : 1, \"wtimeout\" : 0 }\nreplset:PRIMARY&#62; db.people.insert({\"_id\" : 6, \"name\" : \"F\"}, { writeConcern: { w: 3, wtimeout: 50 } })\nWriteResult({\n\t\"nInserted\" : 1,\n\t\"writeConcernError\" : {\n\t\t\"code\" : 64,\n\t\t\"codeName\" : \"WriteConcernFailed\",\n\t\t\"errmsg\" : \"waiting for replication timed out\",\n\t\t\"errInfo\" : {\n\t\t\t\"wtimeout\" : true,\n\t\t\t\"writeConcern\" : {\n\t\t\t\t\"w\" : 3,\n\t\t\t\t\"wtimeout\" : 50,\n\t\t\t\t\"provenance\" : \"clientSupplied\"\n\t\t\t}\n\t\t}\n\t}\n})</pre><p><span>Let&#8217;s now test by setting </span><b><i>setDefaultRWConcern</i></b><span> to </span><b><i>{ &#8220;w&#8221; : 3, &#8220;wtimeout&#8221;: 30 }</i></b><span> as follows:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; db.adminCommand({ \"setDefaultRWConcern\" : 1, \"defaultWriteConcern\" : { \"w\" : 3, \"wtimeout\": 30 } })\n{\n\t\"defaultWriteConcern\" : {\n\t\t\"w\" : 3,\n\t\t\"wtimeout\" : 30\n\t},\n\t\"updateOpTime\" : Timestamp(1624787659, 1),\n\t\"updateWallClockTime\" : ISODate(\"2021-06-27T09:54:26.332Z\"),\n\t\"localUpdateWallClockTime\" : ISODate(\"2021-06-27T09:54:26.332Z\"),\n\t\"ok\" : 1,\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1624787666, 1),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t},\n\t\"operationTime\" : Timestamp(1624787666, 1)\n}</pre><p><span>Now try the write within a transaction or normally without specifying the </span><b><i>writeConcern</i></b><span> explicitly:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; db.people.insert({\"_id\" : 7, \"name\" : \"G\"})\nWriteResult({\n\t\"nInserted\" : 1,\n\t\"writeConcernError\" : {\n\t\t\"code\" : 64,\n\t\t\"codeName\" : \"WriteConcernFailed\",\n\t\t\"errmsg\" : \"waiting for replication timed out\",\n\t\t\"errInfo\" : {\n\t\t\t\"wtimeout\" : true,\n\t\t\t\"writeConcern\" : {\n\t\t\t\t\"w\" : 3,\n\t\t\t\t\"wtimeout\" : 30,\n\t\t\t\t\"provenance\" : \"customDefault\"\n\t\t\t}\n\t\t}\n\t}\n})</pre><p><span>With Transaction, the error occurs on </span><b><i>commitTransaction()</i></b><span> as follows:</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; session = db.getMongo().startSession()\nsession { \"id\" : UUID(\"9aa75ea2-e03f-4ee6-abfb-8969334c9d98\") }\nreplset:PRIMARY&#62; \nreplset:PRIMARY&#62; session.startTransaction()\nreplset:PRIMARY&#62; \nreplset:PRIMARY&#62; session.getDatabase(\"percona\").people.insert([{_id: 8 , name : \"H\"},{_id: 9, name: \"I\"}])\nBulkWriteResult({\n\t\"writeErrors\" : [ ],\n\t\"writeConcernErrors\" : [ ],\n\t\"nInserted\" : 2,\n\t\"nUpserted\" : 0,\n\t\"nMatched\" : 0,\n\t\"nModified\" : 0,\n\t\"nRemoved\" : 0,\n\t\"upserted\" : [ ]\n})\nreplset:PRIMARY&#62; \nreplset:PRIMARY&#62; session.commitTransaction()\nuncaught exception: Error: command failed: {\n\t\"writeConcernError\" : {\n\t\t\"code\" : 64,\n\t\t\"codeName\" : \"WriteConcernFailed\",\n\t\t\"errmsg\" : \"waiting for replication timed out\",\n\t\t\"errInfo\" : {\n\t\t\t\"wtimeout\" : true,\n\t\t\t\"writeConcern\" : {\n\t\t\t\t\"w\" : 3,\n\t\t\t\t\"wtimeout\" : 30,\n\t\t\t\t\"provenance\" : \"customDefault\"\n\t\t\t}\n\t\t}\n\t},\n\t\"ok\" : 1,\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1624787808, 2),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t},\n\t\"operationTime\" : Timestamp(1624787808, 1)\n} :\n_getErrorWithCode@src/mongo/shell/utils.js:25:13\ndoassert@src/mongo/shell/assert.js:18:14\n_assertCommandWorked@src/mongo/shell/assert.js:639:17\nassert.commandWorked@src/mongo/shell/assert.js:729:16\ncommitTransaction@src/mongo/shell/session.js:966:17\n@(shell):1:1\nreplset:PRIMARY&#62;</pre><p></p>\n<h2>How to Check <em>DefaultRWConcern</em></h2>\n<p><span>You can get the current value of read/write concerns via </span><b><i>getDefaultRWConcern </i></b><span>command.</span></p><pre class=\"crayon-plain-tag\">replset:PRIMARY&#62; db.adminCommand( { getDefaultRWConcern : 1 } )\n{\n\t\"defaultWriteConcern\" : {\n\t\t\"w\" : 3,\n\t\t\"wtimeout\" : 30\n\t},\n\t\"updateOpTime\" : Timestamp(1624793719, 1),\n\t\"updateWallClockTime\" : ISODate(\"2021-06-27T11:35:22.552Z\"),\n\t\"localUpdateWallClockTime\" : ISODate(\"2021-06-27T11:35:22.552Z\"),\n\t\"ok\" : 1,\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1624793821, 1),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t},\n\t\"operationTime\" : Timestamp(1624793821, 1)\n}</pre><p></p>\n<h3>Conclusion</h3>\n<p><span>From 4.4.0, the workaround for the said problem is to use the defaults for </span><b><i>getLastErrorDefaults</i></b><span> until 4.4.6 and if needed after 4.4.6, set the cluster/replicaset wide write/read concerns via </span><a target=\"_blank\" href=\"https://docs.mongodb.com/v5.0/reference/command/setDefaultRWConcern/#setdefaultrwconcern\"><i><span>setDefaultRWConcern</span></i></a><span> command instead. The version MongoDB 4.4 honors any write concern value that you specify in </span><b><i>getLastErrorDefaults</i></b><span>, however, it is not allowable from v5.0 (refer </span><a target=\"_blank\" href=\"https://jira.mongodb.org/browse/SERVER-56241\"><span>SERVER-56241</span></a><span>). This behavior was reported in JIRA </span><a target=\"_blank\" href=\"https://jira.mongodb.org/browse/SERVER-54896\"><span>SERVER-54896</span></a><span>, </span><a target=\"_blank\" href=\"https://jira.mongodb.org/browse/SERVER-55701\"><span>SERVER-55701</span></a><span> and got fixed from the version 4.4.7 to ignore the value of </span><b><i>getLastErrorDefaults</i></b><span> as per the bug fix. </span></p>\n<p><span>Also, when you do MongoDB 4.4 upgrade, you can note this and if needed change your default </span><i><span>read/write concern</span></i><span> settings through </span><b><i>setDefaultRWConcern </i></b><span>method.</span></p>\n<p><span>Hope this helps you!</span></p>\n","descriptionType":"html","publishedDate":"Wed, 30 Jun 2021 14:35:39 +0000","feedId":11,"bgimg":"","linkMd5":"c802e2177f7f34c39ce8e41b2d24b46d","bgimgJsdelivr":"","metaImg":"","author":"Vinodh Krishnaswamy","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn100@2020_6/2021/07/13/17-22-08-053_1f4f00a42e4f14e5.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn27@2020_2/2021/07/13/17-21-55-195_72505bd1828b52b1.webp"},"publishedOrCreatedDate":1626196914586},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Percona Monthly Bug Report: June 2021","link":"https://www.percona.com/blog/?p=77064","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona June 2021 Bug Report\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><strong><img loading=\"lazy\" class=\"alignright size-medium wp-image-77065\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-300x157.png\" alt=\"Percona June 2021 Bug Report\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Here at Percona, we operate on the premise that full transparency makes a product better.</strong> We strive to build the best open-source database products, but also to help you manage any issues that arise in any of the databases that we support. And, in true open-source form, report back on any issues or bugs you might encounter along the way.</span></p>\n<p><span>We constantly update our </span><a target=\"_blank\" href=\"https://jira.percona.com/\"><span>bug reports</span></a><span> and monitor </span><a target=\"_blank\" href=\"https://bugs.mysql.com/\"><span>other boards</span></a><span> to ensure we have the latest information, but we wanted to make it a little easier for you to keep track of the most critical ones. These posts are a central place to get information on the most noteworthy open and recently resolved bugs. </span></p>\n<p><span>In this June 2021 edition of our monthly bug report, we have the following list of bugs:</span></p>\n<h2>Percona Server for MySQL/MySQL Bugs</h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=83263\">MySQL#83263</a>: If multiple columns have an ON DELETE constraint set to the same foreign table in that case not all constraints are executed and this will result in data inconsistency.</strong></p>\n<p><span>Example Case: When having ON DELETE SET NULL constraint on one column and an ON DELETE CASCADE constraint on another column. </span></p>\n<p><span>In a row where both reference columns refer to the same foreign table id the ON DELETE CASCADE operation is not executed. The row is not removed as expected. But the column with ON DELETE SET NULL constraint gets the null value as expected.</span></p>\n<p><span>As per the latest update on bug from one of the community use issues is not reproducible anymore with 5.7.21 version. I also tested with the 5.7.33 version and don’t see this issue anymore.</span></p>\n<p><span>Affects Version/s: 5.7  [Tested/Reported version 5.7.15]</span></p>\n<p><span>Fixed Version: 5.7.21 as per user report and my test.</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=102586\">MySQL#102586</a>:  When doing a multiple-table DELETE that is anticipating a foreign key ON DELETE CASCADE, the statements work on the primary but it breaks row-based replication.</strong></p>\n<p><span>Affects Version/s: 8.0, 5.7  [Tested/Reported version 8.0.23, 5.7.33]</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-7485\">PS-7485</a> (MySQL#<a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=102094&#38;thanks=4\">102094</a>): MySQL Crash can be seen in the following cases after running store procedures.</strong></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Execution of a prepared statement that performed a multi-table UPDATE or DELETE was not always done correctly.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Prepared SET statements containing subqueries in stored procedures could raise an assertion.</span></li>\n</ul>\n<p><span>Affects Version/s: 8.0.22  [Tested/Reported version 8.0.22]</span></p>\n<p><span>Fixed Version/s: 8.0.23</span></p>\n<p>&#160;</p>\n<h2>Percona XtraDB Cluster</h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3248\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69263\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3645\">PXC-3645</a>: When using RSU as wsrep_OSU_method, there is an issue of resolving metadata locks which results in deadlock.</strong></p>\n<p><span>In earlier PXC 5.7.x, both TOI and RSU DDLs don&#8217;t wait for the MDL lock, and if there is any ongoing (or just not yet committed) transaction on the same table, it will be immediately aborted and rollback. </span></p>\n<p><span>However, the same scenario in PXC 8.0 leads to an unexpected lock &#8211; neither the transaction gets aborted nor it is allowed to commit, while DDL is waiting on MDL lock.</span></p>\n<p><span>Affects Version/s: 8.0  [Tested/Reported version 8.0.21]</span></p>\n<p><span>Fixed Version/s: 8.0.23</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3248\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69263\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3449\">PXC-3449</a>: When ALTER TABLE (TOI) is executed in a user session, sometimes it happens that it conflicts (MDL) with high priority transaction, which causes BF-BF abort and server termination.</strong></p>\n<p><span>Affects Version/s: 8.0  [Tested/Reported version 8.0.21]</span></p>\n<p><span>Fixed Version/s: 8.0.25</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3248\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69263\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3631\">PXC-3631</a>: In PXC cluster running ALTER TABLE can be stuck waiting for table metadata lock state.</strong></p>\n<p><span>The issue with this bug is that normally, in TOI mode, when ALTER TABLE comes, the master node finishes already running INSERTs first, then it finishes quickly and does not affect the performance of SELECT queries on reader nodes at all.</span></p>\n<p><span>However, sometimes it hangs for a long time and blocks other queries. With a high number of wsrep_slave_threads, the pxc node also crashed.</span></p>\n<p><span>Affects Version/s:  5.7 [Tested/Reported version 5.7.33]</span></p>\n<p>&#160;</p>\n<h2>Percona XtraBackup</h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2162\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69262\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2486\">PXB-2486</a>: When using xtrabackup &#8211;encrypt and &#8211;parallel  with xbcloud, it doesn&#8217;t handle broken pipe correctly.The backup will hang in an infinite loop if xbcloud fails.</strong></p>\n<p><span>Affects Version/s: 2.4  [Tested/Reported version 2.4.22]</span></p>\n<p><span>Fixed Version/s: 2.4.22</span></p>\n<p><strong> </strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2162\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69262\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2375\">PXB-2375</a>:  In some cases, xtrabackup will write the wrong binlog filename, pos, and GTID combination info in xtrabackup_binlog_info. </strong></p>\n<p><span>If we are using this backup with GTID position details in xtrabackup_binlog_info to create a new replica, then most likely replication will break due to incorrect GTID position.</span></p>\n<p><span>Looks like the GTID position is not consistent with binlog file pos, they are captured differently and later printed together in xtrabackup_binlog_info  file.</span></p>\n<p><span>Affects Version/s:  8.0 [Tested/Reported version 8.0.14]</span></p>\n<p>&#160;</p>\n<h2>Percona Toolkit</h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1747\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69264\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1889\">PT-1889</a>: Incorrect output when using pt-show-grants for users based on MySQL roles and as a result, they can not be applied back properly on MySQL server.</strong></p>\n<p><span>Affects Version/s:  3.2.1</span></p>\n<p><strong> </strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1747\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69264\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1747\">PT-1747</a>: pt-online-schema-change was bringing the database into a broken state when applying the &#8220;rebuild_constraints&#8221; foreign keys modification method if any of the child tables were blocked by the metadata lock.</strong></p>\n<p><span>Affects Version/s:  3.0.13</span></p>\n<p><span>Fixed Version: 3.3.2</span></p>\n<p>&#160;</p>\n<h2>PMM  [Percona Monitoring and Management]</h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-5364\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69261\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png\" alt=\"\" width=\"75\" height=\"76\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-7846\">PMM-7846</a>:  Adding mongodb instance via pmm-admin with tls option not working and failing with error Connection check failed: timeout (context deadline exceeded)</strong></p>\n<p><span>Affects Version/s: 2.x  [Tested/Reported version 2.13, 2.16]</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-5364\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69261\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png\" alt=\"\" width=\"75\" height=\"76\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-7941\">PMM-7941</a>:  mongodb_exporter provides a wrong replication status value on MongoDB ReplicaSet Summary dashboard, all replication servers have got status PRIMARY. This status is provided by metric mongodb_mongod_replset_my_state.</strong></p>\n<p><span>Affects Version/s: 2.x  [Tested/Reported version  2.16.0]</span></p>\n<p><span>Fixed Version: 2.18.0</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-5364\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69261\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png\" alt=\"\" width=\"75\" height=\"76\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-4665\">PMM-4665</a>: Frequent error messages in pmm-agent.log for components like tokudb storage engine which are not supported by upstream MySQL. As a result, it increases the overall log file size due to these additional messages.</strong></p>\n<p><span>Affects Version/s:  2.x  [Tested/Reported version 2.0.13]</span></p>\n<p><span>Fixed version: 2.0.19</span></p>\n<p>&#160;</p>\n<h2>Percona Kubernetes Operator for Percona XtraDB Cluster</h2>\n<p><span><img loading=\"lazy\" class=\"alignleft size-full wp-image-77068\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/bug.png\" alt=\"\" width=\"75\" height=\"76\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2021/06/bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2021/06/bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /><strong>New Feature in PXC-operator 1.8.0:</strong></span></p>\n<p><a target=\"_blank\" href=\"https://jira.percona.com/browse/K8SPXC-442\"><span>K8SPXC-442</span></a><span>: </span><span>The Operator can now automatically remove old backups from S3 storage if the retention period is set</span></p>\n<p>&#160;</p>\n<h2><span>Summary</span></h2>\n<p><span>We welcome community input and feedback on all our products. If you find a bug or would like to suggest an improvement or a feature, learn how in our post, </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2019/06/12/report-bugs-improvements-new-feature-requests-for-percona-products/\"><span>How to Report Bugs, Improvements, New Feature Requests for Percona Products</span></a><span>.</span></p>\n<p><span>For the most up-to-date information, be sure to follow us on </span><a target=\"_blank\" href=\"https://twitter.com/percona\"><span>Twitter</span></a><span>, </span><a target=\"_blank\" href=\"https://www.linkedin.com/company/percona\"><span>LinkedIn</span></a><span>, and </span><a target=\"_blank\" href=\"https://www.facebook.com/Percona?fref=ts\"><span>Facebook</span></a><span>.</span></p>\n<p><b>Quick References:</b></p>\n<p><a target=\"_blank\" href=\"https://jira.percona.com\"><span>Percona JIRA </span></a><span> </span></p>\n<p><a target=\"_blank\" href=\"https://bugs.mysql.com/\"><span>MySQL Bug Report</span></a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2019/06/12/report-bugs-improvements-new-feature-requests-for-percona-products/\"><span>Report a Bug in a Percona Product</span></a></p>\n<p><a target=\"_blank\" href=\"https://dev.mysql.com/doc/relnotes/mysql/8.0/en/news-8-0-24.html\"><span>MySQL 8.0.24 Release notes</span></a></p>\n<p><span>___</span></p>\n<p><b>About Percona:</b></p>\n<p><span>As the only provider of distributions for all three of the most popular open source databases—PostgreSQL, MySQL, and MongoDB—Percona provides </span><a target=\"_blank\" href=\"https://www.percona.com/services/consulting\"><span>expertise</span></a><span>, </span><a target=\"_blank\" href=\"https://www.percona.com/software\"><span>software</span></a><span>, </span><a target=\"_blank\" href=\"https://www.percona.com/services/support/mysql-support\"><span>support</span></a><span>, and </span><a target=\"_blank\" href=\"https://www.percona.com/services/managed-services\"><span>services</span></a><span> no matter the technology.</span></p>\n<p><span>Whether it&#8217;s enabling developers or DBAs to realize value faster with tools, advice, and guidance, or making sure applications can scale and handle peak loads, Percona is here to help.</span></p>\n<p><span>Percona is committed to being open source and preventing vendor lock-in. Percona contributes all changes to the upstream community for possible inclusion in future product releases.</span></p>\n","descriptionType":"html","publishedDate":"Wed, 30 Jun 2021 12:09:02 +0000","feedId":11,"bgimg":"","linkMd5":"8b7578f4fbd3d552208d32b52e79fc5c","bgimgJsdelivr":"","metaImg":"","author":"Lalit Choudhary","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn20@2020_6/2021/07/13/17-22-09-955_dbc136ad5c1b1d67.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn84@2020_3/2021/07/13/17-22-10-823_2e6296d971c567e9.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn5@2020_5/2021/07/13/17-22-07-089_2826482aac8c233a.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn31@2020_6/2021/07/13/17-22-05-913_8d1760662c65eda5.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn27@2020_5/2021/07/13/17-22-05-092_147c67c11b518b52.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn23@2020_6/2021/07/13/17-22-08-280_abb43840edeeeb7b.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn48@2020_2/2021/07/13/17-22-06-079_8f6b725a02096785.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/bug.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn60@2020_6/2021/07/13/17-22-08-452_b03caa950c617134.webp"},"publishedOrCreatedDate":1626196914591},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"How To Recover Percona XtraDB Cluster 5.7 Node Without SST","link":"https://www.percona.com/blog/?p=77286","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Recover Percona XtraDB Cluster 5.7 Node Without SST\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2>The Problem</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/5.7/manual/state_snapshot_transfer.html\"><img loading=\"lazy\" class=\"alignright size-medium wp-image-77317\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-300x168.png\" alt=\"Recover Percona XtraDB Cluster 5.7 Node Without SST\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />State Snapshot Transfer</a> can be a very long and expensive process, depending on the size of your <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtradb-cluster\">Percona XtraDB Cluster</a> (PXC)/Galera cluster, as well as network and disk bandwidth. There are situations where it is needed though, like after long enough node separation, where the gcache on other members was too small to keep all the needed transactions.</p>\n<p>Let’s see how we can avoid SST, yet recover fast and without even the need for doing a full backup from another node.</p>\n<p>Below, I will present a simple scenario, where one of the cluster nodes was having a broken network for long enough that it will make<a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/5.7/glossary.html#term-ist\"> Incremental State Transfer (IST) </a>no longer possible.</p>\n<p>For this solution to work, I am assuming that the cluster has binary logs with GTID mode enabled, and logs with missing transactions were not purged yet. Though it would be still possible without GTID, just slightly more complex.</p>\n<p>My example PXC member, node3, gets separated from the cluster due to a network outage. Its last applied transaction status is:</p><pre class=\"crayon-plain-tag\">node3 &#62; show global variables like 'gtid_executed';\n+---------------+----------------------------------------------+\n| Variable_name | Value                                        |\n+---------------+----------------------------------------------+\n| gtid_executed | 2cd15721-261a-ee14-4166-00c9b4945b0b:1-28578 |\n+---------------+----------------------------------------------+\n1 row in set (0.01 sec)\n\nnode3 &#62; show status like 'wsrep_last_committed';\n+----------------------+-------+\n| Variable_name        | Value |\n+----------------------+-------+\n| wsrep_last_committed | 28610 |\n+----------------------+-------+\n1 row in set (0.00 sec)</pre><p>However, other available active nodes in the cluster have already rotated the gcache further:</p><pre class=\"crayon-plain-tag\">node1 &#62; show status like 'wsrep_local_cached_downto';\n+---------------------------+-------+\n| Variable_name             | Value |\n+---------------------------+-------+\n| wsrep_local_cached_downto | 42629 |\n+---------------------------+-------+\n1 row in set (0.00 sec)</pre><p>Hence, after the network is restored, it fails to re-join the cluster due to IST failure:</p>\n<p>DONOR error log:</p><pre class=\"crayon-plain-tag\">2021-06-30T21:52:02.199697Z 2 [Note] WSREP: IST request: d32ea8de-d9e5-11eb-be99-ff364b6ba4f4:28610-83551|tcp://127.0.0.1:27172\n2021-06-30T21:52:02.199743Z 2 [Note] WSREP: IST first seqno 28611 not found from cache, falling back to SST</pre><p>JOINER error log:</p><pre class=\"crayon-plain-tag\">2021-06-30T21:52:02.139242Z 0 [Note] WSREP: Shifting OPEN -&#62; PRIMARY (TO: 83551)\n2021-06-30T21:52:02.139408Z 4 [Note] WSREP: State transfer required:\nGroup state: d32ea8de-d9e5-11eb-be99-ff364b6ba4f4:83551\nLocal state: d32ea8de-d9e5-11eb-be99-ff364b6ba4f4:28610\n...\n2021-06-30T21:52:02.200137Z 0 [Warning] WSREP: 1.0 (node1): State transfer to 0.0 (node3) failed: -61 (No data available)\n2021-06-30T21:52:02.200171Z 0 [ERROR] WSREP: gcs/src/gcs_group.cpp:gcs_group_handle_join_msg():805: State transfer request failed unrecoverably because the donor seqno had gone forward during IST, but SST request was not prepared from our side due to selected state transfer method (which do not supports SST during node operation). Restart required.\n2021-06-30T21:52:02.200191Z 0 [Note] WSREP: gcomm: terminating thread</pre><p>And node3 shuts down its service as a result.</p>\n<h2>The Solution</h2>\n<p>To avoid using full backup transfer from the donor, let’s try asynchronous replication here, to let the failed node catch up with the others so that IST should be possible later.</p>\n<p>To achieve that, let’s modify the configuration file first on the separated node, and add these to avoid accidental writes during the operation:</p><pre class=\"crayon-plain-tag\">super_read_only = 1\nskip_networking</pre><p>and to disable PXC mode for the time, comment out the provider:</p><pre class=\"crayon-plain-tag\">#wsrep-provider=/usr/lib64/libgalera_smm.so</pre><p>Now, after a restart, node3 becomes a standalone MySQL node, without Galera replication enabled. So, let’s configure async replication channel (repl user was created already on all nodes):</p><pre class=\"crayon-plain-tag\">node3 &#62; CHANGE MASTER TO MASTER_HOST='localhost', MASTER_USER='repl', MASTER_PASSWORD='replpassword', MASTER_AUTO_POSITION=1, MASTER_PORT=27037;\nQuery OK, 0 rows affected, 2 warnings (0.03 sec)\n\nnode3 &#62; start slave;\nQuery OK, 0 rows affected (0.00 sec)</pre><p>And then wait for it to catch up with the source node. Once this replica is fully up to date, let’s stop it, remove async channel configuration, and note its new GTID position:</p><pre class=\"crayon-plain-tag\">node3 &#62; stop slave;\nQuery OK, 0 rows affected (0.00 sec)\n\nnode3 &#62; reset slave all;\nQuery OK, 0 rows affected (0.01 sec)\n\nnode3 &#62; show global variables like 'gtid_executed';\n+---------------+----------------------------------------------+\n| Variable_name | Value                                        |\n+---------------+----------------------------------------------+\n| gtid_executed | 2cd15721-261a-ee14-4166-00c9b4945b0b:1-83553 |\n+---------------+----------------------------------------------+\n1 row in set (0.00 sec)</pre><p>Now, we have to find the corresponding cluster’s wsrep sequence, in the source binary log, like this:</p><pre class=\"crayon-plain-tag\">$ mysqlbinlog mysql-bin.000005|grep -A1000 '2cd15721-261a-ee14-4166-00c9b4945b0b:83553'|grep Xid|head -1\n#210701  0:19:06 server id 100  end_log_pos 1010 CRC32 0x212d2592  Xid = 83557</pre><p>With this position, the grastate.dat file on the failed node has to be updated, as follows:</p><pre class=\"crayon-plain-tag\">$ cat pxc_msb_pxc5_7_33/node3/data/grastate.dat\n# GALERA saved state\nversion: 2.1\nuuid:    d32ea8de-d9e5-11eb-be99-ff364b6ba4f4\nseqno:   83557\nsafe_to_bootstrap: 0</pre><p>The previous configuration file modifications must be now reverted, and the service restarted again.</p>\n<p>This time, IST was finally possible:</p><pre class=\"crayon-plain-tag\">2021-06-30T22:26:10.563512Z 2 [Note] WSREP: State transfer required:\nGroup state: d32ea8de-d9e5-11eb-be99-ff364b6ba4f4:85668\nLocal state: d32ea8de-d9e5-11eb-be99-ff364b6ba4f4:83557\n...\n2021-06-30T22:26:28.860555Z 2 [Note] WSREP: Receiving IST: 2111 writesets, seqnos 83557-85668\n2021-06-30T22:26:28.860812Z 0 [Note] WSREP: Receiving IST...  0.0% (   0/2111 events) complete.\n2021-06-30T22:26:29.247313Z 0 [Note] WSREP: Receiving IST...100.0% (2111/2111 events) complete.\n2021-06-30T22:26:29.247713Z 2 [Note] WSREP: IST received: d32ea8de-d9e5-11eb-be99-ff364b6ba4f4:85668\n2021-06-30T22:26:29.247902Z 0 [Note] WSREP: 0.0 (node3): State transfer from 1.0 (node1) complete.\n...\n2021-06-30T22:26:29.248074Z 0 [Note] WSREP: Shifting JOINED -&#62; SYNCED (TO: 85668)</pre><p>And node3 joins back the cluster properly:</p><pre class=\"crayon-plain-tag\">node3 &#62; show global variables like 'gtid_executed';\n+---------------+----------------------------------------------+\n| Variable_name | Value                                        |\n+---------------+----------------------------------------------+\n| gtid_executed | 2cd15721-261a-ee14-4166-00c9b4945b0b:1-85664 |\n+---------------+----------------------------------------------+\n1 row in set (0.00 sec)\n\nnode3 &#62; show status like 'wsrep_last_committed';\n+----------------------+-------+\n| Variable_name        | Value |\n+----------------------+-------+\n| wsrep_last_committed | 85668 |\n+----------------------+-------+\n1 row in set (0.01 sec)</pre><p></p>\n<h2>Summary</h2>\n<p>With the help of traditional asynchronous replication, we were able to restore the failed node back to the cluster faster and without all the overhead related to a full backup made by SST.</p>\n<p>The only requirement for such a method to work is an enabled binary log, with a long enough rotation policy.</p>\n<p>I have tested this on version:</p><pre class=\"crayon-plain-tag\">node3 &#62; select @@version,@@version_comment\\G\n*************************** 1. row ***************************\n        @@version: 5.7.33-36-49-log\n@@version_comment: Percona XtraDB Cluster binary (GPL) 5.7.33-rel36-49, Revision a1ed9c3, wsrep_31.49\n1 row in set (0.00 sec)</pre><p>Unfortunately, a similar solution does not work with Percona XtraDB Cluster 8.0.x, due to the modified way wsrep positions are kept in the storage engine, hence the trick with updating grastate.dat does not work as expected there.</p>\n<p>I would like to also remind here, that in case some node is expected to stay separated from the cluster for too long, there is a way to preserve longer galera cache history for it. So by doing this, the solution I presented may not even be needed &#8211; check the relevant article: <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/02/13/no-sst-node-rejoins/\">Want IST Not SST for Node Rejoins? We Have a Solution!</a></p>\n","descriptionType":"html","publishedDate":"Mon, 12 Jul 2021 12:47:13 +0000","feedId":11,"bgimg":"","linkMd5":"68431c88494742c3568392793d179467","bgimgJsdelivr":"","metaImg":"","author":"Przemysław Malkowski","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn3@2020_6/2021/07/13/17-22-17-751_18f0788d48f39970.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn48@2020_3/2021/07/13/17-22-11-465_b34ad7e6f637e65d.webp"},"publishedOrCreatedDate":1626196914557},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Refining Shard Keys in MongoDB 4.4 and Above","link":"https://www.percona.com/blog/?p=77242","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Refining Shard Keys in MongoDB 4.4\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-1024x575.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><em><strong><img loading=\"lazy\" class=\"alignright size-medium wp-image-77267\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-300x169.png\" alt=\"Refining Shard Keys in MongoDB 4.4\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-1024x575.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />A 1st Stab at Correcting Bad Shard Key Selections</strong></em></p>\n<p><span>MongoDB is designed to scale and handle very large data sets. You can scale vertically in your replica sets by adding resources such as CPUs, RAM, and disks. However, many applications today require more resources than can be added to a single server. </span></p>\n<p><span>The next level of scaling in MongoDB happens with </span><b><i>sharding.</i></b><span> Sharding allows for very large data sets and/or high throughput and is accomplished by spreading the data and the associated resource needs across multiple hosts.</span></p>\n<p><span>Those data sets often include a variety of data types &#8211; from structured, to semi-structured, to unstructured. The ability to handle this variety and scale, provide redundancy and high availability, AND continue to be developer-friendly is why MongoDB has grown into the most used NoSQL database in the market. Let’s face it, developers love its </span><i><span>schemaless</span></i><span> nature and ease of use.</span></p>\n<p><span>But that schemaless nature can sometimes cause problems with the ability to scale in a way that provides the high performance today’s applications demand. When selecting shard keys, one must think about the data (as it exists now and as it may become), the access patterns, and the expected growth of the collections to be sharded. Therefore MongoDB users should consider those schema-like elements when selecting shard keys in order to architect the system optimally from the start.  </span></p>\n<p><span>The issues that arise when bad shard keys are selected can at best be considered suboptimal, and at worst, downright terrible for performance. There are many blogs and webinars about choosing the best possible shard keys. See the bottom of this blog for links to a few of those. </span></p>\n<p><span><strong>Now we’ll talk about how to refine your shard key for collections that already exist and already have data</strong>. </span></p>\n<p><span>Most of the time, this is important when you have very large collections that are critical to the overall performance of your application (and thus to your business). After all, if there is no data or not that much data, you could drop and recreate the collection using a different shard key and reload the data with just a little downtime. So let’s go ahead and take a look at how you can refine a shard key. </span></p>\n<p><span>In earlier versions of MongoDB, once a shard key was chosen and implemented, you were stuck with it &#8211; for better or worse. You could not change that shard key at all. </span></p>\n<p><span>Until MongoDB v4.2 you could not even run an update CRUD operation that changed the values of the field or fields that the shard key included. The shard key and its values were </span><i><span>immutable</span></i><span>. Luckily, with MongoDB 4.2 this changed and shard key field values can now be changed.</span></p>\n<p><span>Despite this, bad shard keys continued to cause performance problems for applications and developers, and others. Users have long wished for a way to change their shard key and avoid the difficult situations and performance problems that come along with bad shard keys.</span></p>\n<h2>MongoDB 4.4 Refinable Shard Keys</h2>\n<p><span>So, along comes MongoDB 4.4 and for the first time, there was something to help mitigate the effects of bad shard keys. MongoDB 4.4 included a new feature that allowed you to </span><b>refine</b><span> your existing shard keys for a collection. This was done via the new </span><b><i>refineCollectionShardKey</i></b><span> command. Additional fields could be added to the existing shard key, thus creating a new shard key. By doing this, chunks of data (that previously did not have enough distinctiveness or had too much frequency) could now use the additional data from the added fields to be subdivided.  </span></p>\n<p><span>One of the biggest problems bad shard keys cause is the creation of jumbo chunks. These are chunks that grow beyond the 64 M default chunk size and are indivisible and. </span></p>\n<p><span>Those jumbo chunks cannot be split and so they will not be moved by the balancer.  This can create situations where operations all go to the same shard (hotspotting) and where more data resides on some shards than others, causing disk size imbalances. </span></p>\n<p><span>Both of these situations negatively impact performance. By refining existing shard keys, data and existing chunks can become more divisible &#8211; broken down into smaller chunks. This can help relieve the pressure caused by hotspotting and disk imbalances.</span></p>\n<h2>Requirements for Refining Shard Keys</h2>\n<p><span>In order to use the </span><b><i>refineCollectionShardKey</i></b><span> command, the following prerequisites must be met:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Your cluster must at least be version 4.4 and also have a feature compatibility version of 4.4.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The new shard key must still have the same prefix &#8211;  that is, it must start with the existing shard key.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The new fields added to the shard key can only be added as suffixes.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>A new index must be created to support the modified shard key.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Before issuing the </span><b><i>refineCollectionShardKey</i></b><span> command the balancer must be stopped.</span></li>\n</ol>\n<h2>Steps and Commands for Refining Shard Keys</h2>\n<p><span>Let’s take a look at the steps and commands required to refine a shard key.  Then we will take a look at a simple example with commands and results.</span></p>\n<p><b>Step 1. Check the current database version. The required version is v4.4 or greater.</b></p><pre class=\"crayon-plain-tag\">db.version()</pre><p><b>Step 2. Check the current feature compatibility version (fCV). The required version is v4.4 or greater.</b></p><pre class=\"crayon-plain-tag\">db.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } )</pre><p><b>*Note* </b><span>To check the fCV, the above command must be run on a </span><b>mongod</b><span> node &#8211; connect to a member of the shard replica set as a local user.</span></p>\n<p><b>Step 3. Stop the Balancer  (on mongos)</b></p><pre class=\"crayon-plain-tag\">sh.getBalancerState()      # check state             (assuming “true”)\nsh.isBalancerRunning()     # check if running      (assuming “true”)\nsh.stopBalancer()          # stop the balancer\nsh.getBalancerState()      # check state             (assuming “false”)      \nsh.isBalancerRunning()     # check if running      (assuming “false”)</pre><p><b>Step 4. Set the feature compatibility version (fCV) if needed</b></p><pre class=\"crayon-plain-tag\">db.adminCommand( { setFeatureCompatibilityVersion: \"4.4\" } )</pre><p><b>*Note* </b><span>Setting the fCV for a sharded cluster must happen on the mongos.</span></p>\n<p><b>Step 5. Create the index to support the desired REFINED shard key</b></p><pre class=\"crayon-plain-tag\">db.&#60;collection&#62;.createIndex(keys, options)</pre><p><span>Confirm that the index was created as desired:</span></p><pre class=\"crayon-plain-tag\">db.&#60;collection&#62;.getIndexes();</pre><p><b>Step 6. Run the </b><b><i>refineCollectionShardKey</i></b><b>  command to modify the existing shard key</b></p><pre class=\"crayon-plain-tag\">db.adminCommand( {\n   refineCollectionShardKey: \"&#60;database&#62;.&#60;collection&#62;\",\n   key: { &#60;existing key specification&#62;, &#60;suffix1&#62;: &#60;1|\"hashed\"&#62;, ... }\n} )</pre><p><b>1</b><span> indicates range sharding<br />\n</span><b>hashed </b><span>use for a hashed shard key &#8211; </span><b>*IF*</b><span> shard key does not already include a hashed field </span></p>\n<p><b>Step 7. Check shard status to ensure that the shard key has changed</b></p><pre class=\"crayon-plain-tag\">sh.status()</pre><p><b>Step 8. Restart the Balancer  (on mongos)</b></p><pre class=\"crayon-plain-tag\">use config\nsh.startBalancer()         # start the balancer\nsh.getBalancerState()      # check state             (assuming “true”)\nsh.isBalancerRunning()     # check if running      (assuming “true”)</pre><p></p>\n<h2>Now Let’s Look at a Simple Example</h2>\n<p><b>Collection Name</b><span>: <pre class=\"crayon-plain-tag\">test.mailbox</pre> </span></p>\n<p><b>Current Shard Key</b><span>: <pre class=\"crayon-plain-tag\">shard key: { \"index\" : \"hashed\" }</pre> </span></p>\n<p><b>Desired Shard Key</b><span>: <pre class=\"crayon-plain-tag\">{ \"index\" : \"hashed\", \"_id\" : 1 }</pre> </span></p>\n<p><b>Why</b><span>:  Assume that the current shard key has too much frequency and is not distinct enough &#8211; similar to “Smith” as a last name &#8211; and is therefore creating jumbo chunks and causing severe disk imbalances. This is causing performance to tank.</span></p>\n<p><b>Sample Documents in the “mailbox” collection</b><span>:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.mailbox.findOne();\n{\n\t\"_id\" : ObjectId(\"607d123000ea55fa00116b0d\"),\n\t\"index\" : -344122283,\n\t\"batch\" : NumberLong(1618809392),\n\t\"sn\" : 0\n}\n\n= = = &#62;&#62; last doc\n\n{\n\t\"_id\" : ObjectId(\"60880d08431c575efe6a376f\"),\n\t\"index\" : -1433889568,\n\t\"batch\" : NumberLong(1619528550),\n\t\"thr\" : 5,\n\t\"txn\" : 3122,\n\t\"doc\" : 2\n}</pre><p><b>Background:</b><span> Currently only “index” and&#8221;_id&#8221; appear to be common fields in all docs. Therefore we will make our new shard key a combination of the original shard key {&#8220;index&#8221;: &#8220;hashed&#8221;} and then add a suffix of &#8220;_id&#8221; as a regular field &#8211; </span><b>not a hashed field</b><span> because you can only have a single hashed field in your compound index.</span></p>\n<p><b>Step 1. Check the current version</b><span> </span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.version()\n4.4.6</pre><p><b>Step 2. Check  the current feature compatibility version (fCV)</b></p><pre class=\"crayon-plain-tag\">testrs:PRIMARY&#62; db.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } )\n{\n\t\"featureCompatibilityVersion\" : {\n\t\t\"version\" : \"4.2\"\n\t},\n\t\"ok\" : 1,\n\t\"$gleStats\" : {\n\t\t\"lastOpTime\" : Timestamp(0, 0),\n\t\t\"electionId\" : ObjectId(\"7fffffff0000000000000075\")\n\t},\n\t\"lastCommittedOpTime\" : Timestamp(1620879883, 1),\n\t\"$configServerState\" : {\n\t\t\"opTime\" : {\n\t\t\t\"ts\" : Timestamp(1620879876, 1),\n\t\t\t\"t\" : NumberLong(134)\n\t\t}\n\t},\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1620879883, 1),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t},\n\t\"operationTime\" : Timestamp(1620879883, 1)\n}</pre><p><b>Step 3. Stop the Balancer    (on mongos)</b></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.getBalancerState()\ntrue\nmongos&#62; sh.isBalancerRunning()\ntrue\nmongos&#62; sh.stopBalancer()\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1620881100, 8),\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1620881100, 8),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t}\n}\nmongos&#62; sh.getBalancerState()\nfalse\nmongos&#62; sh.isBalancerRunning()\nfalse\nmongos&#62;\n\n= = = = = = = &#62;&#62; Balancer is now stopped</pre><p><b>Step 4. Set the feature compatibility version (fCV) if needed</b></p><pre class=\"crayon-plain-tag\">mongos&#62; db.adminCommand( { setFeatureCompatibilityVersion: \"4.4\" } )\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1620881106, 2078),\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1620881106, 2078),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t}\n}</pre><p><b>*Remember* </b><span>Setting the fCV for a sharded cluster must happen on the mongos.</span></p>\n<p><b>Confirm that fCV changed &#8211; </b></p>\n<p><span>= = =  == &#62;&#62; And now let&#8217;s check the fCV value in the MongoD PRIMARY again</span></p><pre class=\"crayon-plain-tag\">testrs:PRIMARY&#62; db.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } )\n{\n\t\"featureCompatibilityVersion\" : {\n\t\t\"version\" : \"4.4\"\n\t},\n\t\"ok\" : 1,\n\t\"$gleStats\" : {\n\t\t\"lastOpTime\" : Timestamp(0, 0),\n\t\t\"electionId\" : ObjectId(\"7fffffff0000000000000075\")\n\t},\n\t\"lastCommittedOpTime\" : Timestamp(1620881294, 2),\n\t\"$configServerState\" : {\n\t\t\"opTime\" : {\n\t\t\t\"ts\" : Timestamp(1620881309, 2),\n\t\t\t\"t\" : NumberLong(134)\n\t\t}\n\t},\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1620881309, 2),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t},\n\t\"operationTime\" : Timestamp(1620881294, 2)\n}\ntestrs:PRIMARY&#62;</pre><p><b>Step 5. Create the index to support the desired REFINED shard key</b></p><pre class=\"crayon-plain-tag\">db.getSiblingDB(\"test\").mailbox.createIndex( { \"index\" : \"hashed\", \"_id\" : 1 } )\n\n\nmongos&#62; db.getSiblingDB(\"test\").mailbox.createIndex( { \"index\" : \"hashed\", \"_id\" : 1 } );\n{\n\t\"raw\" : {\n\t\t\"testrs/yoda-x1:27101,yoda-x1:27102,yoda-x1:27103\" : {\n\t\t\t\"createdCollectionAutomatically\" : false,\n\t\t\t\"numIndexesBefore\" : 2,\n\t\t\t\"numIndexesAfter\" : 3,\n\t\t\t\"commitQuorum\" : \"votingMembers\",\n\t\t\t\"ok\" : 1\n\t\t},\n\t\t\"s2rs/yoda-x1:27201,yoda-x1:27202\" : {\n\t\t\t\"createdCollectionAutomatically\" : false,\n\t\t\t\"numIndexesBefore\" : 2,\n\t\t\t\"numIndexesAfter\" : 3,\n\t\t\t\"commitQuorum\" : \"votingMembers\",\n\t\t\t\"ok\" : 1\n\t\t}\n\t},\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1620881524, 5),\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1620881524, 5),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t}\n}</pre><p><b>Confirm that the index was created as desired</b></p><pre class=\"crayon-plain-tag\">db.&#60;collection&#62;.getIndexes();\n\nmongos&#62; db.mailbox.getIndexes();\n[\n\t{\n\t\t\"v\" : 2,\n\t\t\"key\" : {\n\t\t\t\"_id\" : 1\n\t\t},\n\t\t\"name\" : \"_id_\"\n\t},\n\t{\n\t\t\"v\" : 2,\n\t\t\"key\" : {\n\t\t\t\"index\" : \"hashed\"\n\t\t},\n\t\t\"name\" : \"index_hashed\"\n\t},\n\t{\n\t\t\"v\" : 2,\n\t\t\"key\" : {\n\t\t\t\"index\" : \"hashed\",  &#60;&#60;&#60;=  New index refined shard key\n\t\t\t\"_id\" : 1\n\t\t},\n\t\t\"name\" : \"index_hashed__id_1\" \n\t}\n]</pre><p><b>Step 6. Run the </b><b><i>refineCollectionShardKey</i></b><b>  command to modify the existing shard key</b></p><pre class=\"crayon-plain-tag\">db.adminCommand( {\n   refineCollectionShardKey: \"test.mailbox\",\n   key: { \"index\" : \"hashed\", \"_id\" : 1 }\n} )\n\nmongos&#62; db.adminCommand( {\n...    refineCollectionShardKey: \"test.mailbox\",\n...    key: { \"index\" : \"hashed\", \"_id\" : 1 }\n... } )\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1620882237, 11),\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1620882237, 11),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t}\n}\nmongos&#62;</pre><p><b>Step 7. Check shard status to ensure that the shard key has changed</b></p><pre class=\"crayon-plain-tag\">sh.status()\n\n\nmongos&#62; sh.status()\n--- Sharding Status ---\n  sharding version: {\n  \t\"_id\" : 1,\n  \t\"minCompatibleVersion\" : 5,\n  \t\"currentVersion\" : 6,\n  \t\"clusterId\" : ObjectId(\"5d31339ff33e970d492c7bdd\")\n  }\n  shards:\n        {  \"_id\" : \"s2rs\",  \"host\" : \"s2rs/yoda-x1:27201,yoda-x1:27202\",  \"state\" : 1 }\n        {  \"_id\" : \"testrs\",  \"host\" : \"testrs/yoda-x1:27101,yoda-x1:27102,yoda-x1:27103\",  \"state\" : 1 }\n  active mongoses:\n        \"4.4.6\" : 1\n  autosplit:\n        Currently enabled: no\n  balancer:\n        Currently enabled:  no\n        Currently running:  no\n        Failed balancer rounds in last 5 attempts:  0\n        Migration Results for the last 24 hours:\n&#60;&#60;skip&#62;&#62;\n&#60;&#60;Skip&#62;&#62;\n&#60;&#60;Skip&#62;&#62;\n                test.mailbox\n                        shard key: { \"index\" : \"hashed\", \"_id\" : 1 }\n                        unique: false\n                        balancing: true\n                        chunks:\n                                s2rs\t2\n                                testrs\t2\n                        { \"index\" : { \"$minKey\" : 1 }, \"_id\" : { \"$minKey\" : 1 } } --&#62;&#62; { \"index\" : NumberLong(\"-4611686018427387902\"), \"_id\" : { \"$minKey\" : 1 } } on : s2rs Timestamp(1, 0)\n                        { \"index\" : NumberLong(\"-4611686018427387902\"), \"_id\" : { \"$minKey\" : 1 } } --&#62;&#62; { \"index\" : NumberLong(0), \"_id\" : { \"$minKey\" : 1 } } on : s2rs Timestamp(1, 1)\n                        { \"index\" : NumberLong(0), \"_id\" : { \"$minKey\" : 1 } } --&#62;&#62; { \"index\" : NumberLong(\"4611686018427387902\"), \"_id\" : { \"$minKey\" : 1 } } on : testrs Timestamp(1, 2)\n                        { \"index\" : NumberLong(\"4611686018427387902\"), \"_id\" : { \"$minKey\" : 1 } } --&#62;&#62; { \"index\" : { \"$maxKey\" : 1 }, \"_id\" : { \"$maxKey\" : 1 } } on : testrs Timestamp(1, 3)\nmongos&#62;</pre><p><b>Step 8. Restart the Balancer   (on mongos)</b></p><pre class=\"crayon-plain-tag\">use config\nsh.startBalancer()         # start the balancer\nsh.getBalancerState()      # check state             (assuming “true”)\nsh.isBalancerRunning()     # check if running      (assuming “true”)</pre><p></p>\n<h2>Sample Expected mongod and mongos Log Entries Related to Resharding</h2>\n<p><span><strong>*note*</strong> Just putting a couple here from the mongod and the mongod:</span></p>\n<p><b>=mongod</b></p><pre class=\"crayon-plain-tag\">&#60;&#60;&#60;date, more, more&#62;&#62;&#62; … ...\n“SHARDING”, “id: &#60;&#60;number&#62;&#62;, “ctx”:”ReplicaSetMonitor-TaskExecutor”, “msg”:“Updating the shard registry with confirmed replica set” ……&#60;&#60;&#60;more, more, more&#62;&#62;&#62;\n\n&#60;&#60;&#60;date, more, more&#62;&#62;&#62; … …\n“SHARDING”, “id: &#60;&#60;number&#62;&#62;, “ctx”:”updateShardIdentityConfigString”, “msg”:“Updating shard identity config string with confirmed replica set” ……&#60;&#60;&#60;more, more, more&#62;&#62;&#62;</pre><p><b>=mongos</b></p><pre class=\"crayon-plain-tag\">&#60;&#60;&#60;date, more, more&#62;&#62;&#62; … …\n“SHARDING”, “id: &#60;&#60;number&#62;&#62;, “ctx”:”Uptime-reporter”, “msg”:”Refreshed RWC defaults”. “attr”:{“newDefaults”:{}}} ……&#60;&#60;&#60;more, more, more&#62;&#62;&#62;\n\n&#60;&#60;&#60;date, more, more&#62;&#62;&#62; … …\n“NETWORK”, “id: &#60;&#60;number&#62;&#62;, “ctx”:”ReplicaSetMonitor-TaskExecutor”, “msg”:“RSM Topology Change”,  “attr”:{“replicaSet”:”config …”  ……&#60;&#60;&#60;more, more, more&#62;&#62;&#62;</pre><p></p>\n<h2>Tips For Refining Shard Keys</h2>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Refining shard keys involves adding a field or fields to the existing shard key as a suffix. This requires. This means any index that supports the new shard key is a Compound Shard Key.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Starting in MongoDB 4.4 you can shard using a Compound Hashed Index</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You can only have a single hashed field in your compound index.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Know your data and your collection “structure”  Do a findOne().  Look at older data (1st 5 docs) and latest data (last 5 docs) to make sure that the structure of your data has not changed significantly over time. Oops, not always “schemaless” after all, is it? </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Prior to 4.4, all shard key fields must be populated. In 4.4 and above, sharded collections can have documents with missing shard key fields. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>In general, select fields that will be used in the majority of your operations and queries.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>When selecting fields to add as suffixes to your existing shard keys, remember to take into account the main tenets that are important to effective and performant sharding. Those are cardinality, frequency, and non-monotonically increasing.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Missing Shard Key Field Values &#8211; Sometimes you may need to add fields to the shard key which do not have values for those fields populated in all documents. In MongoDB 4.4 and above, that is ok. However, it is best to populate those fields as soon as possible in order to avoid situations that might compromise the desired data to be returned. An example would be write operations that target documents with missing shard key field values.</span></li>\n</ol>\n<h2>Summary</h2>\n<p><span>So, this was the 1st step towards making it easier to correct sharding mistakes that may be negatively impacting your performance. In the upcoming MongoDB 5.0 release, an expected new feature is fully changeable shard keys &#8211; aka RESHARDING. </span></p>\n<p><span>Many are eagerly awaiting the ability to change the shard key completely and reshard. Looking forward to trying that out and digging more into all of the changes that are required at the code level to make this cloning-type operation occur.</span></p>\n<h2>What’s Next?</h2>\n<p><span>We are offering MongoDB enthusiasts a unique opportunity to get a sneak peek into MongoDB 5.0 at </span><b>11 am EDT TODAY!</b><span> Tune in live to watch, and ask questions, at </span><a target=\"_blank\" href=\"http://youtube.com/percona/live\"><span>YouTube</span></a><span>, </span><a target=\"_blank\" href=\"https://www.twitch.tv/perconalive\"><span>Twitch</span></a>,<span> and </span><a target=\"_blank\" href=\"https://www.linkedin.com/company/percona\"><span>LinkedIn</span></a><span>.</span></p>\n<p><span>Join our live stream event as Percona experts Akira Kurogane (MongoDB Product Owner) and Kimberly Wilkins (MongoDB Tech Lead) provide an advanced look at the production release of MongoDB 5.0. </span></p>\n<p><span>This release has been rumored to include several exciting new features, especially one particularly long-awaited improvement to sharding. </span><b>We hope to see you there!</b></p>\n<p><span>You can also keep an eye on our blog and social channels for upcoming sharding insight, or if you just can’t wait, check out our recent sharding presentations: </span></p>\n<ul>\n<li style=\"list-style-type: none;\">\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=TAH1fIf3f7c\"><span>A Sharding Tale: Then, Now, There, and Back Again (Percona Live 2021)</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=Od16iXmZ6QI\"><span>Unlocking the Mystery of MongoDB Shard Key Selection</span></a></li>\n</ul>\n</li>\n</ul>\n<p><strong>Sources:</strong></p>\n<p><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/core/sharding-shard-key/#missing-shard-key\"><span>https://docs.mongodb.com/manual/core/sharding-shard-key/#missing-shard-key</span></a></p>\n<p><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/command/refineCollectionShardKey/#mongodb-dbcommand-dbcmd.refineCollectionShardKey\"><span>https://docs.mongodb.com/manual/reference/command/refineCollectionShardKey/#mongodb-dbcommand-dbcmd.refineCollectionShardKey</span></a></p>\n","descriptionType":"html","publishedDate":"Thu, 08 Jul 2021 12:35:23 +0000","feedId":11,"bgimg":"","linkMd5":"8bb05fd9b53b2b68f0a0e5757c0c898a","bgimgJsdelivr":"","metaImg":"","author":"Kimberly Wilkins","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn56@2020_1/2021/07/13/17-22-10-681_a4a11e9cd4041bfd.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn15@2020_2/2021/07/13/17-22-10-158_ba8ee8f7102be27f.webp"},"publishedOrCreatedDate":1626196914558},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Sharding With Zones Based on Compound Shard-Keys on MongoDB 4.4","link":"https://www.percona.com/blog/?p=77143","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Compound Shard-Keys on MongoDB 4.4\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77229\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-300x168.png\" alt=\"Compound Shard-Keys on MongoDB 4.4\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />This article was written with the main purpose of showing you how to determine zones on a shard when using compound shard keys.</span></p>\n<p><span>Defining Zones in Shards means pre-defining where certain chunks will be stored and amongst which set of particular shards they will be balanced according to the shard key definition. </span></p>\n<p><span>MongoDB 4.4 brings the possibility to shard a collection and determine zones by compound keys, including mixing a hash key with non-hashed keys.  Hashed keys may be placed in the prefix of the index (shard key) or not. Depending on the method chosen, different settings must be in compliance with the balancer and this article will also show you a couple of examples.</span></p>\n<h2>Defining the Index Prior to Sharding</h2>\n<p><span>Even though it is not always required to create indexes in advance of running the &#8220;shardCollection&#8221; command, I am defining it to better illustrate the procedure</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The collections </span><b>colltest1</b><span> will be sharded based on a key containing the hashed key in the prefix</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; db.getSiblingDB(\"dbtest\").colltest1.createIndex({_id:\"hashed\",\"location\":1},{unique:false})\n{\n\t\"raw\" : {\n\t\t\"shard02/localhost:40003\" : {\n\t\t\t\"createdCollectionAutomatically\" : true,\n\t\t\t\"numIndexesBefore\" : 1,\n\t\t\t\"numIndexesAfter\" : 2,\n\t\t\t\"commitQuorum\" : \"votingMembers\",\n\t\t\t\"ok\" : 1\n\t\t}\n\t},\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624357456, 7),\n\t\"$clusterTime\" : { ... }\n}</pre><p></p>\n<ul>\n<li><span>The collections </span><b>colltest2</b><span> will be sharded based on a key containing the non-hashed key in the prefix</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; db.getSiblingDB(\"dbtest\").colltest2.createIndex({\"location\":1,_id:\"hashed\"},{unique:false})\n{\n\t\"raw\" : {\n\t\t\"shard02/localhost:40003\" : {\n\t\t\t\"createdCollectionAutomatically\" : true,\n\t\t\t\"numIndexesBefore\" : 1,\n\t\t\t\"numIndexesAfter\" : 2,\n\t\t\t\"commitQuorum\" : \"votingMembers\",\n\t\t\t\"ok\" : 1\n\t\t}\n\t},\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624357534, 2),\n\t\"$clusterTime\" : { ... }\n}</pre><p><span>It is important to highlight  a couple of important points about creating the indexes for the shard keys:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Once the collection is empty or if it is a new one, the command used to get a collection sharded will automatically create the indexes if they are not present yet. This will be described in the upcoming sections.</span></li>\n<li><span>If the shard key prefix will not be a hashed value, the indexes shall be created with the option </span><b>{unique:false}</b></li>\n</ul>\n<h2>Creating the Initial Chunks Based on Hashed Key as a Prefix</h2>\n<p><span>There are, basically, a couple of requirements to ensure that the collection will be in compliance with the balancer and the initial chunk distribution will be optimally performed. </span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>For each non-hashed value, a range of the hashed key must be defined with upper and lower boundaries. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The collection must be sharded with the option </span><b>presplitHashedZones: true </b><span>if there is a hashed field.</span></li>\n</ul>\n<p><span>The below example shows how to shard the collection colltest1.</span></p>\n<h3>Defining the Zones and Assigning to the Shards (To make things brief, only one zone &#8220;LATAM&#8221; is used in this example.)</h3>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.addShardToZone(\"shard01\", \"LATAM\")\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624359227, 38),\n\t\"$clusterTime\" : { ... }\n}\nmongos&#62; sh.addShardToZone(\"shard02\", \"LATAM\")\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624359231, 1),\n\t\"$clusterTime\" : {... }\n}</pre><p><span>If you check the output of the <strong>sh.status()</strong>, you will notice that tags were created and assigned to the shards according to the zones definition:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.status()\n--- Sharding Status --- \n  sharding version: {\n  \t\"_id\" : 1,\n  \t\"minCompatibleVersion\" : 5,\n  \t\"currentVersion\" : 6,\n  \t\"clusterId\" : ObjectId(\"60d1be52be9f36000b01a9f0\")\n  }\n  shards:\n        {  \"_id\" : \"shard01\",  \"host\" : \"shard01/localhost:40002\",  \"state\" : 1,  \"tags\" : [ \"LATAM\" ] }\n        {  \"_id\" : \"shard02\",  \"host\" : \"shard02/localhost:40003\",  \"state\" : 1,  \"tags\" : [ \"LATAM\" ] }        \n&#60;&#60;the rest of status output was intentionally truncated to avoid unnecessary verbosity&#62;&#62;</pre><p></p>\n<h3>Creating the Zone Ranges</h3>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.updateZoneKeyRange(\"dbtest.colltest1\",{ \"_id\" : MinKey, \"location\" : MinKey },{ _id:MaxKey,\"location\" : MaxKey },\"LATAM\");\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624361452, 1),\n\t\"$clusterTime\" : { ... }\n}</pre><p></p>\n<h3>Enabling Shard</h3>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.enableSharding(\"dbtest\")\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624361047, 6),\n\t\"$clusterTime\" : { ... }\n}\nmongos&#62; sh.shardCollection(\"dbtest.colltest1\",{_id:\"hashed\",\"location\":1},false,{ presplitHashedZones: true })\n{\n\t\"collectionsharded\" : \"dbtest.colltest1\",\n\t\"collectionUUID\" : UUID(\"30b2efff-2e2e-4c72-9a82-9593f227002f\"),\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624361528, 31),\n\t\"$clusterTime\" : { ... }\n}</pre><p><span>In this example, the namespace </span><b>dbtest.colltest1</b><span> will be evenly distributed according to the zone LATAM which will reach the shards </span><b>shard01 and shard02</b><span>. Looking at the sh.status() again, you will see that the initial chunks were created following the range defined above.</span></p>\n<h2>Creating the Initial Chunks Based on Non-Hashed Key as a Prefix</h2>\n<p><span>This example section will be a little bit more complicated to make the shard key compliant with the balancer for the initial chunk distribution.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You need to specify MinKey for each field in the shard key, which defines the lower boundary of each zone range.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Every zone must comprise a range, so at least one of the fields in the shard key must have an upper-boundary value larger than its MinKey</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Every combination of values for the fields of the shard key will fall within the range of one of the defined zones. </span> <span> </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>At the moment of sharding the collection, presplitHashedZones must be set to true.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Not required, but likely desirable: One of the zones should define its upper boundary as MaxKey so it acts as a catchall for out-of-range values.</span></li>\n</ul>\n<h3>Defining the Zones and Assigning Them to the Shards</h3>\n<p><span>The zones were defined differently for this example:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.status()\n--- Sharding Status --- \n  sharding version: {\n  \t\"_id\" : 1,\n  \t\"minCompatibleVersion\" : 5,\n  \t\"currentVersion\" : 6,\n  \t\"clusterId\" : ObjectId(\"60d1be52be9f36000b01a9f0\")\n  }\n  shards:\n        {  \"_id\" : \"shard01\",  \"host\" : \"shard01/localhost:40002\",  \"state\" : 1,  \"tags\" : [ \"EU\" ] }\n        {  \"_id\" : \"shard02\",  \"host\" : \"shard02/localhost:40003\",  \"state\" : 1,  \"tags\" : [ \"LATAM\" ] }\n        {  \"_id\" : \"shard03\",  \"host\" : \"shard03/localhost:40004\",  \"state\" : 1,  \"tags\" : [ \"AMER\" ] }\n        {  \"_id\" : \"shard04\",  \"host\" : \"shard04/localhost:40005\",  \"state\" : 1,  \"tags\" : [ \"APAC\" ] }</pre><p></p>\n<h3>Creating the Zone Ranges</h3>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.updateZoneKeyRange(\"dbtest2.colltest2\",{ \"location\": \"DC01\", \"_id\" : MinKey },{ \"location\": \"DC02\", \"_id\" : MinKey },\"LATAM\");\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624364375, 1),\n\t\"$clusterTime\" : { ... }\n}\nmongos&#62; sh.updateZoneKeyRange(\"dbtest2.colltest2\",{ \"location\": \"DC02\", \"_id\" : MinKey },{ \"location\": MaxKey, \"_id\" : MinKey },\"EU\");\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624364430, 1),\n\t\"$clusterTime\" : { ... }\n}</pre><p></p>\n<h3>Enabling Shard</h3>\n<p></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.enableSharding(\"dbtest2\")\n{\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624366057, 5),\n\t\"$clusterTime\" : { ... }\n}\nmongos&#62; sh.shardCollection(\"dbtest2.colltest2\",{\"location\":1,_id:\"hashed\"},false,{ presplitHashedZones: true })\n{\n\t\"collectionsharded\" : \"dbtest2.colltest2\",\n\t\"collectionUUID\" : UUID(\"b8a64972-97df-4791-8019-9526d2f8d405\"),\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1624366085, 37),\n\t\"$clusterTime\" : { ... }\n}\nmongos&#62;</pre><p><span>The above example basically describes how to use a non-hashed field on the prefix of a shard key to ensure that certain values of that field will reach certain zones (determined as tags on shards) and the boundaries applied on the hashed field will ensure even distribution. In that case, all the docs of the namespace </span><b>dbtest2.colltest2</b><span> with the minimum _id of location DC01 and the minimum _id of the location DC02, will be placed on the zone LATAM (shard02). And the next docs from the minimum _id of the location DC02 until the rest will be placed on the zone EU (shard 01)</span></p>\n<p><span>It is very important to highlight that if the collection is not in compliance with the balancer, the migration of the chunks will never happen, though all the chunks will stay on the Primary Shard. It is possible to predict that situation right after enabling the sharding on the collection by looking at the output of the command </span><b>sh.balancerCollectionStatus</b></p><pre class=\"crayon-plain-tag\">mongos&#62; sh.balancerCollectionStatus(\"dbtest.colltest1\")\n{\n\t\"balancerCompliant\" : true,\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1623691376, 1),\n\t\"$clusterTime\" : { ... }\n}</pre><p><span>If the </span><b>balancerCompliant is true, </b><span>means that the balancer will be able to split and migrate the chunks.</span></p>\n<h3>Conclusion</h3>\n<p><span>Defining the shard key is the most important step of deploying a healthy sharded cluster. Having a field on the shard key which contains a few distinct values would compromise the shard distribution, and as consequence, the performance. Hence, this is a great improvement coming along in MongoDB 4.4 which makes it possible to have keys with low cardinality defining the boundaries, yet still ensuring that the shard will rely on a hashed distribution based on a very selective key.</span></p>\n","descriptionType":"html","publishedDate":"Tue, 06 Jul 2021 15:06:38 +0000","feedId":11,"bgimg":"","linkMd5":"edeb191ea230adfca668add5f1768361","bgimgJsdelivr":"","metaImg":"","author":"Rafael Galinari","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn88@2020_5/2021/07/13/17-22-10-893_acb157c6804c35bc.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn96@2020_3/2021/07/13/17-22-10-792_8bac5969ca8dba9d.webp"},"publishedOrCreatedDate":1626196914559},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Enabling SSL/TLS Sessions In PgBouncer","link":"https://www.percona.com/blog/?p=76592","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Enabling SSL:TLS Sessions In PgBouncer\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76951\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-300x157.png\" alt=\"Enabling SSL:TLS Sessions In PgBouncer\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />PgBouncer is a great piece of technology! Over the years I&#8217;ve put it to good use in any number of situations requiring a particular type of control over application processes connecting to a postgres data cluster. However, sometimes it&#8217;s been a bit of a challenge when it comes to configuration.</p>\n<p>Today, I want to demonstrate one way of conducting a connection session using the Secure Socket Layer, SSL/TLS.</p>\n<p>For our purposes we&#8217;re going to make the following assumptions:</p>\n<ul>\n<li>We are using a typical installation found on CENTOS-7.</li>\n<li>PostgreSQL version 13 is used, but essentially any currently supported version of postgres will work.</li>\n</ul>\n<p>Here are the steps enabling SSL connection sessions:</p>\n<ol>\n<li>Setup postgres\n<ul>\n<li>install RPM packages</li>\n<li>setup remote access</li>\n<li>create a ROLE with remote login privileges</li>\n</ul>\n</li>\n<li>Setup pgbouncer\n<ul>\n<li>install RPM packages</li>\n<li>setup the minimal configuration permitting remote login <em>without</em> SSL</li>\n</ul>\n</li>\n<li>Generate SSL/TSL private keys and certificates\n<ul>\n<li>TLS certificate for postgres</li>\n<li>TLS certificate for pgbouncer</li>\n<li>Create a Certificate Authority (CA) capable of signing the aforementioned certificates</li>\n</ul>\n</li>\n<li>Configure for SSL encrypted sessions\n<ol>\n<li>postgres</li>\n<li>pgbouncer</li>\n</ol>\n</li>\n</ol>\n<h2>Step 1: Setup Postgres</h2>\n<p>Setting up your postgres server is straightforward:</p>\n<ul>\n<li>Add the appropriate <a target=\"_blank\" href=\"https://www.postgresql.org/download/\">repository</a> for postgres version 13.\n<pre class=\"crayon-plain-tag\">yum install openssl\nyum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm\nyum update -y\nyum install -y postgresql13-server</pre>\n</li>\n<li>The datacluster is initialized.\n<pre class=\"crayon-plain-tag\">/usr/pgsql-12/bin/postgresql-12-setup initdb</pre>\n</li>\n<li>The datacluster configuration files &#8220;pg_hba.conf&#8221; and &#8220;postgresql.auto.conf&#8221; are edited. Note that both IPv4 and IPv6 protocols have been configured.<br /><br />\n<pre class=\"crayon-plain-tag\">echo \"\n##############################################################\n#PG_HBA.CONF\n#\n# TYPE DATABASE USER ADDRESS METHOD\n# \"local\" is for Unix domain socket connections only\nlocal all all trust\n# IPv4 local connections:\nhost all all 127.0.0.1/32 md5\nhost all all 0.0.0.0/0 md5\n# IPv6 local connections:\nhost all all ::1/128 md5\nhost all all ::0/0 md5\n# Allow replication connections from localhost, by a user with the\n# replication privilege.\nlocal replication all trust\nhost replication all 127.0.0.1/32 md5\nhost replication all ::1/128 md5\n#\n##############################################################\" &#62; /var/lib/pgsql/12/data/pg_hba.conf</pre>\n&#8212;\n<pre class=\"crayon-plain-tag\"># update runtime variable \"listen_addresses\"\necho \"listen_addresses='*' \" &#62;&#62; /var/lib/pgsql/12/data/postgresql.auto.conf</pre>\n&#8212;\n<pre class=\"crayon-plain-tag\"># as root: server start\nsystemctl start postgresql-12</pre>\n</li>\n</ul>\n<h2>2: Setup PgBouncer</h2>\n<pre class=\"crayon-plain-tag\"># Install the postgres community package connection pooler\nyum install -y pgbouncer\n# Configure pgbouncer for non-SSL access\nmv /etc/pgbouncer/pgbouncer.ini /etc/pgbouncer/pgbouncer.ini_backup</pre>\n<p>There&#8217;s not much to this first iteration configuring pgbouncer. All that is required is to validate that a connection can be made before updating the SSL configuration.</p>\n<pre class=\"crayon-plain-tag\"># edit pgbouncer.ini\necho \"\n[databases]\n* = host=localhost\n\n[pgbouncer]\nlogfile = /var/log/pgbouncer/pgbouncer.log\npidfile = var/run/pgbouncer/pgbouncer.pid\nlisten_addr = *\nlisten_port = 6432\n;;any, trust, plain, md5, cert, hba, pam\nauth_type = plain\nauth_file = /etc/pgbouncer/userlist.txt<br />admin_users = postgres\n\" &#62; /etc/pgbouncer/pgbouncer.ini</pre>\n<p>NOTE: best practice recommends hashing the passwords when editing the file <em>userlist.txt</em>,. But for our purposes, keeping things simple, we&#8217;ll leave the passwords in the clear.</p>\n<pre class=\"crayon-plain-tag\"># edit userlist.txt \necho \" \n\\\"usr1\\\" \\\"usr1\\\" \n\\\"postgres\\\" \\\"postgres\\\" \n\" &#62; /etc/pgbouncer/userlist.txt</pre>\n<p>&#8212;</p>\n<pre class=\"crayon-plain-tag\"># as root: server start \nsystemctl start pgbouncer</pre>\n<p>&#8212;</p>\n<pre class=\"crayon-plain-tag\"># test connectivity to the postgres server\npsql 'host=localhost dbname=postgres user=postgres password=postgres' -c 'select now()' \npsql 'host=localhost dbname=postgres user=usr1 password=usr1' -c 'select now()' \n\n# test connectivity to pgbouncer \npsql 'host=localhost dbname=postgres user=postgres password=postgres port=6432' -c 'select now()' \npsql 'host=localhost dbname=postgres user=usr1 password=usr1 port=6432' -c 'select now()'</pre>\n<h2>Step 3: Setup SSL/TSL Certificates</h2>\n<p>Create a root certificate fit for signing certificate requests:</p>\n<pre class=\"crayon-plain-tag\">#!/bin/bash\nset -e\n#################\nHOST='blog'\nROOT='root'\nOPENSSL_CNF='/etc/pki/tls/openssl.cnf'\n#################\n\n# GENERATE CERTIFICATE REQUEST\nopenssl req -new -nodes -text -out $ROOT.pem -keyout $ROOT.key -subj \"/CN=$ROOT.$HOST\"\n\n# SIGN THE REQUEST WITH THE KEY TO CREATE A ROOT CERTIFICATE AUTHORITY\nopenssl x509 -req -in $ROOT.pem -text -days 3650 -extfile $OPENSSL_CNF -extensions v3_ca -signkey $ROOT.key -out $ROOT.crt\n\nchmod 600 root.key\nchmod 664 root.crt root.pem</pre>\n<p>Create two sets of keys and certificate requests, one for pgbouncer and postgres respectively. The certificate requests are signed with the newly created root certificate:</p>\n<pre class=\"crayon-plain-tag\">#!/bin/bash\n#\n# usage\n# ./02.mkcert.sh &#60;key name&#62;\n#\nset -e\n#################\nHOST='blog'\nSUBJ=\"/C=US/ST=Washington/L=Seattle/O=Percona/OU=Professional Services/CN=$HOST/emailAddress=robert.bernier@percona.com\"\nREQ=\"$1.pem\"\nKEY=\"$1.key\"\nCRT=\"$1.crt\"\n\nROOT=\"root\"\n#################\n# GENERATE PRIVATE KEY\nopenssl genrsa -out $KEY 2048\n\n# GENERATE CERTIFICATE REQUEST\nopenssl req -new -sha256 -key $KEY -out $REQ -subj \"$SUBJ\"\n\n#\n# CERTIFICATE SIGNED BY ROOT CA\n# which was generated by script \"mkcert_root.sh\"\n#\nopenssl x509 -req -in $REQ -text -days 365 -CA $ROOT.crt -CAkey $ROOT.key -CAcreateserial -out $CRT\n\nchmod 600 $KEY\nchmod 664 $REQ\nchmod 664 $CRT</pre>\n<p>Validate the signed certificates:</p>\n<pre class=\"crayon-plain-tag\">#!/bin/bash\nset -e\n# check: private key\nfor u in $(ls *.key)\ndo\n echo -e \"\\n==== PRIVATE KEY: $u ====\\n\"\n openssl rsa -in $u -check\ndone\n\n# check: certificate request\nfor u in $(ls *.pem)\ndo\n echo -e \"\\n==== CERTIFICATE REQUEST: $u ====\\n\"\n openssl req -text -noout -verify -in $u\ndone\n\n# check: signed certificate\nfor u in $(ls *.crt)\ndo\n echo -e \"\\n==== SIGNED CERTIFICATE: $u ====\\n\"\n openssl req -text -noout -verify -in $u\ndone</pre>\n<h2>Step 4: Install Certificates and Configure Servers For SSL Connectivity</h2>\n<p>Update ownership for keys and certificates:</p>\n<pre class=\"crayon-plain-tag\">#!/bin/bash\nset -e\nchown pgbouncer:pgbouncer pgbouncer.*\nchown postgres:postgres server.*</pre>\n<p>Move keys and certificates into their respective locations:</p>\n<pre class=\"crayon-plain-tag\">#!/bin/bash\nset -e\n# pgbouncer\nmv pgbouncer.* /etc/pgbouncer\ncp root.crt /etc/pgbouncer\n\n# postgres\nmv server.* /var/lib/pgsql/13/data\ncp root.crt /var/lib/pgsql/13/data</pre>\n<p>Update pgbouncer.ini:</p>\n<pre class=\"crayon-plain-tag\">echo \"\n;;;\n;;; TLS settings for connecting to backend databases\n;;;\n;server_tls_sslmode = prefer | require | verify-ca | verify-full\nserver_tls_sslmode = require\nserver_tls_ca_file = /etc/pgbouncer/root.crt\nserver_tls_key_file = /etc/pgbouncer/pgbouncer.key\nserver_tls_cert_file = /etc/pgbouncer/pgbouncer.crt\n\n;;;\n;;; TLS settings for accepting client connections\n;;;\n;client_tls_sslmode = prefer | require | verify-ca | verify-full\nclient_tls_sslmode = require\nclient_tls_ca_file = /etc/pgbouncer/root.crt\nclient_tls_key_file = /etc/pgbouncer/pgbouncer.key\nclient_tls_cert_file = /etc/pgbouncer/pgbouncer.crt\n\" &#62;&#62; /etc/pgbouncer/pgbouncer.ini</pre>\n<p>Update postgresql.auto.conf: </p>\n<pre class=\"crayon-plain-tag\">echo \"\nssl = 'on'\nssl_ca_file = 'root.crt'\n\" &#62;&#62; /var/lib/pgsql/12/data/postgresql.auto.conf</pre>\n<p>&#8212;</p>\n<pre class=\"crayon-plain-tag\"># update runtime parameters by restarting the postgres server\nsystemctl restart postgresql-13\n\n# restarting connection pooler\nsystemctl restart pgbouncer</pre>\n<p>And validate SSL connectivity:</p>\n<pre class=\"crayon-plain-tag\">#<br /># validate ssl connectivity, note the use of \"sslmode\"\n#\n\n# connect to pgbouncer\npsql 'host=blog dbname=postgres user=postgres password=postgres port=6432 sslmode=require'&#60;&#60;&#60;\"select 'hello world' as greetings\"\n\n/*\n greetings\n-------------\n hello world\n*/\n\n# connect to postgres server\npsql 'host=blog dbname=postgres user=usr1 password=usr1 port=5432 sslmode=require' \\\n &#60;&#60;&#60;\"select datname,usename, ssl, client_addr\n     from pg_stat_ssl\n     join pg_stat_activity\n        on pg_stat_ssl.pid = pg_stat_activity.pid\n     where datname is not null\n     and usename is not null\n     order by 2;\"</pre>\n<pre class=\"crayon-plain-tag\">/* ATTENTION:\n-- host name resolution is via IPv6\n-- 1st row is a server connection from pgbouncer established by the previous query\n-- 2nd row is connection generating the results of this query\n\n datname | usename | ssl | client_addr\n---------+----------+-----+--------------------------\npostgres | postgres | t | ::1\npostgres | postgres | t | fe80::216:3eff:fec4:7769\n*/</pre>\n<h2>CAVEAT: A Few Words About Those Certificates</h2>\n<p>Using certificates signed by a Certificate Authority offers one the ability to yet go even further than simply enabling SSL sessions. For example, although not covered here, you can dispense using passwords and instead rely on the certificate&#8217;s identity as the main authentication mechanism.</p>\n<p>Remember: you can still conduct SSL sessions via the use of <em>self-signed</em> certificates, it&#8217;s just that you can&#8217;t leverage the other cool validation methods in postgres.</p>\n<p><span style=\"font-size: 9px;\"><span style=\"font-size: 12px;\"># #######################################################</span><br /><span style=\"font-size: 12px;\"># PGBOUNCER.INI</span><br /><span style=\"font-size: 12px;\"># Only try an SSL connection. If a root CA file is present,</span><br /><span style=\"font-size: 12px;\"># verify the certificate in the same way as if verify-ca was specified</span><br /><span style=\"font-size: 12px;\">#</span><br /><span style=\"font-size: 12px;\">client_tls_sslmode = require</span><br /><span style=\"font-size: 12px;\">server_tls_sslmode = require</span><br /><span style=\"font-size: 12px;\">#</span><br /><span style=\"font-size: 12px;\"># Only try an SSL connection, and verify that the server certificate</span><br /><span style=\"font-size: 12px;\"># is issued by a trusted certificate authority (CA)</span><br /><span style=\"font-size: 12px;\">#</span><br /><span style=\"font-size: 12px;\">client_tls_sslmode = verify-ca</span><br /><span style=\"font-size: 12px;\">server_tls_sslmode = verify-ca</span><br /><span style=\"font-size: 12px;\">#</span><br /><span style=\"font-size: 12px;\"># Only try an SSL connection, verify that the server certificate</span><br /><span style=\"font-size: 12px;\"># is issued by a trusted CA and</span><br /><span style=\"font-size: 12px;\"># that the requested server host name</span><br /><span style=\"font-size: 12px;\"># matches that in the certificate</span><br /><span style=\"font-size: 12px;\">#</span><br /><span style=\"font-size: 12px;\">client_tls_sslmode = verify-full</span><br /></span></p>\n<p>And finally; don&#8217;t forget to save the root certificate&#8217;s private key, <em>root.key</em>, in a safe place!</p>\n","descriptionType":"html","publishedDate":"Mon, 28 Jun 2021 14:45:09 +0000","feedId":11,"bgimg":"","linkMd5":"4ac6a00baf384d4228bb0850832721e0","bgimgJsdelivr":"","metaImg":"","author":"Robert Bernier","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn72@2020_6/2021/07/13/17-22-06-738_dbd7b67d94a3fce8.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn100@2020_6/2021/07/13/17-22-08-745_82f8714a760d4806.webp"},"publishedOrCreatedDate":1626196914580},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MySQL Static and Dynamic Privileges (Part 1)","link":"https://www.percona.com/blog/?p=76691","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL Static and Dynamic Privileges\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-76731\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-300x157.png\" alt=\"MySQL Static and Dynamic Privileges\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" /><em>When trying to make things better, make it very complicated.</em></span></p>\n<p><span>I was working on a Security Threat Tool script when I had to learn more about the interaction between </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/privileges-provided.html\"><span>static and dynamic privileges in MySQL 8</span></a><span>.</span></p>\n<p><span>Dynamic privileges is a “new” thing added in MySQL 8 to easily extend the privileges definition, and at the same time to provide more granularity. For instance, the FLUSH operation now has dedicated Privileges and by scope. </span></p>\n<p><span>Dynamic privileges are assigned at runtime. Most of them are active when the server starts. But they can also change with respect to the components or plugin when activated. (<a target=\"_blank\" href=\"https://dev.mysql.com/doc/mysql-security-excerpt/8.0/en/privileges-provided.html#privileges-provided-dynamic\">https://dev.mysql.com/doc/mysql-security-excerpt/8.0/en/privileges-provided.html#privileges-provided-dynamic</a>)</span></p>\n<p><span>Static privileges are the classical privileges available in MySQL. (<a target=\"_blank\" href=\"https://dev.mysql.com/doc/mysql-security-excerpt/8.0/en/privileges-provided.html#privileges-provided-static\">https://dev.mysql.com/doc/mysql-security-excerpt/8.0/en/privileges-provided.html#privileges-provided-static</a>)</span></p>\n<p><span>Those are built into the server and cannot be changed.</span></p>\n<p><span><em><strong>So far, all is good</strong></em>. If we can give more flexibility to the security mechanism existing in MySQL, well, I am all for it.</span></p>\n<p><span>My first step was to deal with the abuse of SUPER. </span></p>\n<p><span>About that &#8211;  the manual comes to help with a section called <a target=\"_blank\" href=\"https://dev.mysql.com/doc/mysql-security-excerpt/8.0/en/privileges-provided.html#dynamic-privileges-migration-from-super\">Migrating Accounts from SUPER to Dynamic Privileges</a>. </span></p>\n<p><span>Woo perfect!</span></p>\n<p><span>Let us play a bit. First, let me create a user:</span></p><pre class=\"crayon-plain-tag\">create user secure_test@'localhost' identified by 'secret';\nDC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user();\n+-------------------------------------------------+\n| Grants for secure_test@localhost                |\n+-------------------------------------------------+\n| GRANT USAGE ON *.* TO `secure_test`@`localhost` |\n+-------------------------------------------------+</pre><p><span>As you can see I can connect, but have no permissions.</span></p>\n<p><span>On another terminal with an administrative account, let us do the classical operation to create a DBA:</span></p><pre class=\"crayon-plain-tag\">GRANT ALL on *.* to secure_test@'localhost' WITH GRANT OPTION;</pre><p><span>And now I have:</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user()\\G\n*************************** 1. row ***************************\nGrants for secure_test@localhost: GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE, CREATE ROLE, DROP ROLE ON *.* TO `secure_test`@`localhost` WITH GRANT OPTION\n*************************** 2. row ***************************\nGrants for secure_test@localhost: GRANT APPLICATION_PASSWORD_ADMIN,AUDIT_ADMIN,BACKUP_ADMIN,BINLOG_ADMIN,BINLOG_ENCRYPTION_ADMIN,CLONE_ADMIN,CONNECTION_ADMIN,ENCRYPTION_KEY_ADMIN,FLUSH_OPTIMIZER_COSTS,FLUSH_STATUS,FLUSH_TABLES,FLUSH_USER_RESOURCES,GROUP_REPLICATION_ADMIN,INNODB_REDO_LOG_ARCHIVE,INNODB_REDO_LOG_ENABLE,PERSIST_RO_VARIABLES_ADMIN,REPLICATION_APPLIER,REPLICATION_SLAVE_ADMIN,RESOURCE_GROUP_ADMIN,RESOURCE_GROUP_USER,ROLE_ADMIN,SERVICE_CONNECTION_ADMIN,SESSION_VARIABLES_ADMIN,SET_USER_ID,SHOW_ROUTINE,SYSTEM_USER,SYSTEM_VARIABLES_ADMIN,TABLE_ENCRYPTION_ADMIN,XA_RECOVER_ADMIN ON *.* TO `secure_test`@`localhost` WITH GRANT OPTION</pre><p><span>As you can see, I have a bunch of privileges assigned. </span></p>\n<p><span>To be honest, to have to identify exactly what each privilege does and how it interacts with the others is challenging.</span></p>\n<p><span> </span><span>Anyhow, the manual tells us:</span></p>\n<p><span>&#8220;</span><i><span>For each account identified by the preceding query, determine the operations for which it needs SUPER. Then grant the dynamic privileges corresponding to those operations, and revoke SUPER.</span></i><span>&#8220;</span></p>\n<p><span>In our case:</span></p><pre class=\"crayon-plain-tag\">revoke SUPER on *.* from secure_test@'localhost';</pre><p><span>Which will remove the SUPER privileges, but what else will remain active?  </span><span>Let us try one of the easiest things, let us modify the variable </span><i><span>super_read_only</span></i><span>.</span></p>\n<p><span>With super I can change the value of the variable without problems, but if I remove the SUPER privileges, what will happen? </span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user()\\G\n*************************** 1. row ***************************\nGrants for secure_test@localhost: GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE, CREATE ROLE, DROP ROLE ON *.* TO `secure_test`@`localhost` WITH GRANT OPTION\n*************************** 2. row ***************************\nGrants for secure_test@localhost: GRANT APPLICATION_PASSWORD_ADMIN,AUDIT_ADMIN,BACKUP_ADMIN,BINLOG_ADMIN,BINLOG_ENCRYPTION_ADMIN,CLONE_ADMIN,CONNECTION_ADMIN,ENCRYPTION_KEY_ADMIN,FLUSH_OPTIMIZER_COSTS,FLUSH_STATUS,FLUSH_TABLES,FLUSH_USER_RESOURCES,GROUP_REPLICATION_ADMIN,INNODB_REDO_LOG_ARCHIVE,INNODB_REDO_LOG_ENABLE,PERSIST_RO_VARIABLES_ADMIN,REPLICATION_APPLIER,REPLICATION_SLAVE_ADMIN,RESOURCE_GROUP_ADMIN,RESOURCE_GROUP_USER,ROLE_ADMIN,SERVICE_CONNECTION_ADMIN,SESSION_VARIABLES_ADMIN,SET_USER_ID,SHOW_ROUTINE,SYSTEM_USER,SYSTEM_VARIABLES_ADMIN,TABLE_ENCRYPTION_ADMIN,XA_RECOVER_ADMIN ON *.* TO `secure_test`@`localhost` WITH GRANT OPTION</pre><p><span>As you can see SUPER is gone. </span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;set global super_read_only=0;\nQuery OK, 0 rows affected (0.00 sec)</pre><p><span>And I can still modify the global variable. WHY?  </span></p>\n<p><span>The manual says that </span><span>SYSTEM_VARIABLES_ADMIN </span><span>from the dynamic privileges allow us to modify &#8220;</span><i><span>Enables system variable changes at runtime</span></i><span>&#8220;. Well, what if I revoke it? </span></p><pre class=\"crayon-plain-tag\">revoke SYSTEM_VARIABLES_ADMIN on *.* from  secure_test@'localhost';\n\nDC2-2(secure_test@localhost) [(none)]&gt;set global super_read_only=0;\nERROR 1227 (42000): Access denied; you need (at least one of) the SUPER or SYSTEM_VARIABLES_ADMIN privilege(s) for this operation</pre><p><span>Great! So in order to really remove/limit super, I need to also remove </span><span>SYSTEM_VARIABLES_ADMIN</span><span>. But is that all?</span></p>\n<p><span>Well to make it short, <strong>no it is not</strong>. </span></p>\n<p><span>Checking the manual you can see that SUPER is affecting all these:</span></p>\n<ul>\n<li><span>BINLOG_ADMIN,</span></li>\n<li><span>CONNECTION_ADMIN,</span></li>\n<li><span>ENCRYPTION_KEY_ADMIN,</span></li>\n<li><span>GROUP_REPLICATION_ADMIN,</span></li>\n<li><span>REPLICATION_SLAVE_ADMIN,</span></li>\n<li><span>SESSION_VARIABLES_ADMIN,</span></li>\n<li><span>SET_USER_ID,</span></li>\n<li><span>SYSTEM_VARIABLES_ADMIN</span></li>\n</ul>\n<p><span>And these are the ones by default. But we can also have others depending on the plugins we have active. </span></p>\n<p><span>So in theory to be sure we are removing all SUPER related privileges, we should:</span></p><pre class=\"crayon-plain-tag\">REVOKE SUPER, BINLOG_ADMIN, CONNECTION_ADMIN, ENCRYPTION_KEY_ADMIN, GROUP_REPLICATION_ADMIN, REPLICATION_SLAVE_ADMIN, SESSION_VARIABLES_ADMIN, SET_USER_ID, SYSTEM_VARIABLES_ADMIN on *.* from secure_test@'localhost';</pre><p><span>This should leave us with the equivalent of a user without SUPER:</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user()\\G\n*************************** 1. row ***************************\nGrants for secure_test@localhost: GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE, CREATE ROLE, DROP ROLE ON *.* TO `secure_test`@`localhost` WITH GRANT OPTION\n*************************** 2. row ***************************\nGrants for secure_test@localhost: GRANT APPLICATION_PASSWORD_ADMIN,AUDIT_ADMIN,BACKUP_ADMIN,BINLOG_ENCRYPTION_ADMIN,CLONE_ADMIN,FLUSH_OPTIMIZER_COSTS,FLUSH_STATUS,FLUSH_TABLES,FLUSH_USER_RESOURCES,INNODB_REDO_LOG_ARCHIVE,INNODB_REDO_LOG_ENABLE,PERSIST_RO_VARIABLES_ADMIN,REPLICATION_APPLIER,RESOURCE_GROUP_ADMIN,RESOURCE_GROUP_USER,ROLE_ADMIN,SERVICE_CONNECTION_ADMIN,SHOW_ROUTINE,SYSTEM_USER,TABLE_ENCRYPTION_ADMIN,XA_RECOVER_ADMIN ON *.* TO `secure_test`@`localhost` WITH GRANT OPTION</pre><p></p>\n<h3>CONCLUSION</h3>\n<p><span>In this first blog, we have started to explore the usage of Dynamic privileges, and what we need to do to remove the SUPER privilege. </span></p>\n<p><span>Nevertheless, the list above is still a bit chaotic and unsafe. We still have SHUTDOWN or RELOAD or FILE, all of them are insecure and should be assigned with great care. In the next article in this series, we see <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/15/mysql-static-and-dynamic-privileges-part-2/\">how to deal with Dynamic and Static privileges by Role</a> and we also try to have clearer how they affect one another.</span></p>\n","descriptionType":"html","publishedDate":"Tue, 15 Jun 2021 14:00:06 +0000","feedId":11,"bgimg":"","linkMd5":"d0b3cc26c8b6425f9fa81b97d17f434d","bgimgJsdelivr":"","metaImg":"","author":"Marco Tusa","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn95@2020_4/2021/07/13/17-22-07-018_8aee64af66262ce0.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn76@2020_1/2021/07/13/17-22-17-679_43d87dca1f3ec8dd.webp"},"publishedOrCreatedDate":1626196914579},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MySQL/ZFS Performance Update","link":"https://www.percona.com/blog/?p=77189","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL/ZFS Performance Update\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-77302\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-300x168.png\" alt=\"MySQL/ZFS Performance Update\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />As some of you likely know, I have a favorable view of ZFS and especially of MySQL on ZFS. As I <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/05/15/about-zfs-performance/\">published</a> a few years ago, the argument for ZFS was less about performance than its useful features like data compression and snapshots. At the time, ZFS was significantly slower than xfs and ext4 except when the L2ARC was used.</p>\n<p>Since then, however, ZFS on Linux has progressed a lot and I also learned how to better tune it. Also, I found out the sysbench benchmark I used at the time was not a fair choice since the dataset it generates compresses much less than a realistic one. For all these reasons, I believe that it is time to revisit the performance aspect of MySQL on ZFS.</p>\n<h2>ZFS Evolution</h2>\n<p>In 2018, I reported ZFS performance results based on version 0.6.5.6, the default version available in Ubuntu Xenial. The present post is using version 0.8.6-1 of ZFS, the default one available on Debian Buster. Between the two versions, there are in excess of 3600 commits adding a number of new features like support for <em>trim</em> operations and the addition of the efficient <em>zstd</em> compression algorithm.</p>\n<p>ZFS 0.8.6-1 is not bleeding edge, there have been more than 1700 commits since and after 0.8.6, the ZFS release number jumped to 2.0. The big addition included in the 2.0 release is native encryption.</p>\n<h2>Benchmark Tools</h2>\n<p>The classic sysbench MySQL database benchmarks have a dataset containing mostly random data. Such datasets don’t compress much, less than most real-world datasets I worked with. The compressibility of the dataset is important since ZFS caches, the ARC and L2ARC, store compressed data. A better compression ratio essentially means more data is cached and fewer IO operations will be needed.</p>\n<p>A well-known tool to benchmark a transactional workload is TPCC. Furthermore, the dataset created by TPCC compresses rather well making it more realistic in the context of this post. The <a target=\"_blank\" href=\"https://github.com/Percona-Lab/sysbench-tpcc\">sysbench TPCC implementation</a> was used.</p>\n<h2>Test Environment</h2>\n<p>Since I am already familiar with AWS and Google cloud, I decided to try Azure for this project. I launched these two virtual machines:</p>\n<p>tpcc:</p>\n<ul>\n<li>benchmark host</li>\n<li>Standard D2ds_v4 instance</li>\n<li>2 vCpu, 8GB of Ram and 75 GB of temporary storage</li>\n<li>Debian Buster</li>\n</ul>\n<p>db:</p>\n<ul>\n<li>Database host</li>\n<li>Standard E4-2ds-v4 instance</li>\n<li>2 vCpu, 32GB of Ram and 150GB of temporary storage</li>\n<li>256GB SSD Premium (SSD Premium LRS P15 &#8211; 1100 IOPS (3500 burst), 125 MB/s)</li>\n<li>Debian Buster</li>\n<li>Percona server 8.0.22-13</li>\n</ul>\n<h2>Configuration</h2>\n<p>By default and unless specified, the ZFS filesystems are created with:</p><pre class=\"crayon-plain-tag\">zpool create bench /dev/sdc\nzfs set compression=lz4 atime=off logbias=throughput bench\nzfs create -o mountpoint=/var/lib/mysql/data -o recordsize=16k \\\n           -o primarycache=metadata bench/data\nzfs create -o mountpoint=/var/lib/mysql/log bench/log</pre><p>There are two ZFS filesystems. <em>bench/data </em>is optimized for the InnoDB dataset while <em>bench/log</em> is tuned for the InnoDB log files. Both are compressed using lz4 and the <em>logbias</em> parameter is set to <em>throughput</em> which changes the way the ZIL is used. With ext4, the <em>noatime</em> option is used.</p>\n<p>ZFS has also a number of kernel parameters, the ones set to non-default values are:</p><pre class=\"crayon-plain-tag\">zfs_arc_max=2147483648\nzfs_async_block_max_blocks=5000\nzfs_delete_blocks=1000</pre><p>Essentially, the above settings limit the ARC size to 2GB and they throttle down the aggressiveness of ZFS for deletes. Finally, the database configuration is slightly different between ZFS and ext4. There is a common section:</p><pre class=\"crayon-plain-tag\">[mysqld]\npid-file = /var/run/mysqld/mysqld.pid\nsocket = /var/run/mysqld/mysqld.sock\nlog-error = /var/log/mysql/error.log\nskip-log-bin\ndatadir = /var/lib/mysql/data\ninnodb_buffer_pool_size = 26G\ninnodb_flush_log_at_trx_commit = 1 # TPCC reqs.\ninnodb_log_file_size = 1G\ninnodb_log_group_home_dir = /var/lib/mysql/log\ninnodb_flush_neighbors = 0\ninnodb_fast_shutdown = 2</pre><p>and when ext4 is used:</p><pre class=\"crayon-plain-tag\">innodb_flush_method = O_DIRECT</pre><p>and when ZFS is used:</p><pre class=\"crayon-plain-tag\">innodb_flush_method = fsync\ninnodb_doublewrite = 0 # ZFS is transactional\ninnodb_use_native_aio = 0\ninnodb_read_io_threads = 10\ninnodb_write_io_threads = 10</pre><p>ZFS doesn’t support <em>O_DIRECT</em> but it is ignored with a message in the error log. I chose to explicitly set the flush method to <em>fsync</em>. The doublewrite buffer is not needed with ZFS and I was under the impression that the Linux native asynchronous IO implementation was not well supported by ZFS so I disabled it and increased the number of IO threads. We&#8217;ll revisit the asynchronous IO question in a future post.</p>\n<h2>Dataset</h2>\n<p>I use the following command to create the dataset:</p><pre class=\"crayon-plain-tag\">./tpcc.lua --mysql-host=10.3.0.6 --mysql-user=tpcc --mysql-password=tpcc --mysql-db=tpcc \\\n--threads=8 --tables=10 --scale=200 --db-driver=mysql prepare</pre><p>The resulting dataset has a size of approximately 200GB. The dataset is much larger than the buffer pool so the database performance is essentially IO-bound.</p>\n<h2>Test Procedure</h2>\n<p>The execution of every benchmark was scripted and followed these steps:</p>\n<ol>\n<li>Stop MySQL</li>\n<li>Remove all datafiles</li>\n<li>Adjust the filesystem</li>\n<li>Copy the dataset</li>\n<li>Adjust the MySQL configuration</li>\n<li>Start MySQL</li>\n<li>Record the configuration</li>\n<li>Run the benchmark</li>\n</ol>\n<h2>Results</h2>\n<p>For the benchmark, I used the following invocation:</p><pre class=\"crayon-plain-tag\">./tpcc.lua --mysql-host=10.3.0.6 --mysql-user=tpcc --mysql-password=tpcc --mysql-db=tpcc \\\n--threads=16 --time=7200 --report-interval=10 --tables=10 --scale=200 --db-driver=mysql ru</pre><p>The TPCC benchmark uses 16 threads for a duration of 2 hours. The duration is sufficiently long to allow for a steady state and to exhaust the storage burst capacity. Sysbench returns the total number of TPCC transactions per second every 10s. This number includes not only the <em>New Order</em> transactions but also the other transaction types like <em>payment</em>, <em>order status</em>, etc. Be aware of that if you want to compare these results with other TPCC benchmarks.</p>\n<p>In those conditions, the figure below presents the rates of TPCC transactions over time for ext4 and ZFS.</p>\n<div id=\"attachment_77190\" style=\"width: 766px\" class=\"wp-caption aligncenter\"><img aria-describedby=\"caption-attachment-77190\" loading=\"lazy\" class=\"wp-image-77190 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs.png\" alt=\"TPCC transactions ZFS\" width=\"756\" height=\"425\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs.png 756w, https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs-367x206.png 367w\" sizes=\"(max-width: 756px) 100vw, 756px\" /><p id=\"caption-attachment-77190\" class=\"wp-caption-text\">MySQL TPCC results for ext4 and ZFS</p></div>\n<p>During the initial 15 minutes, the buffer pool warms up but at some point, the workload shifts between an IO read bound to an IO write and CPU bound. Then, at around 3000s the SSD Premium burst capacity is exhausted and the workload is only IO-bound. I have been a bit surprised by the results, enough to rerun the benchmarks to make sure. The results for both ext4 and ZFS <strong>are qualitatively similar</strong>. Any difference is within the margin of error. That essentially means if you configure ZFS properly, it can be as IO efficient as ext4.</p>\n<p>What is interesting is the amount of storage used. While the dataset on ext4 consumed 191GB, the lz4 compression of ZFS yielded a dataset of only 69GB. That’s a huge difference, a factor of 2.8, which could save a decent amount of money over time for large datasets.</p>\n<h2>Conclusion</h2>\n<p>It appears that it was indeed a good time to revisit the performance of MySQL with ZFS. In a fairly realistic use case, ZFS is on par with ext4 regarding performance while still providing the extra benefits of data compression, snapshots, etc. In a future post, I’ll examine the use of cloud ephemeral storage with ZFS and see how this can further improve performance.</p>\n","descriptionType":"html","publishedDate":"Fri, 09 Jul 2021 12:14:38 +0000","feedId":11,"bgimg":"","linkMd5":"402545669a4da5bf8fdcb39f91435884","bgimgJsdelivr":"","metaImg":"","author":"Yves Trudeau","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn51@2020_2/2021/07/13/17-22-10-715_bdc7f822668d31fb.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn44@2020_2/2021/07/13/17-22-11-585_da03720aaa7ba4fd.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn24@2020_2/2021/07/13/17-22-10-738_c9764d721ac171b4.webp"},"publishedOrCreatedDate":1626196914555},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Move Percona Monitoring and Management Server Data From One Instance Type to Another","link":"https://www.percona.com/blog/?p=76991","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Move Percona Monitoring and Management Server Data\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-77185\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-300x157.png\" alt=\"Move Percona Monitoring and Management Server Data\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" /><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM2) Server runs as a Docker container, a Virtual appliance, or as an instance on Amazon or Azure cloud services. Here I&#8217;ll show how to move the PMM Server and its data from one type to another.</p>\n<p><strong>Note, this is only for PMM2 to PMM2—you can&#8217;t migrate data from PMM Server version 1 to version 2 because of significant architectural differences.</strong></p>\n<p>For this exercise, imagine that your PMM server:</p>\n<ul>\n<li>Is running on an <strong>Amazon EC2 instance</strong> (<em>Server A</em>) from an AMI,</li>\n<li>You want to move it to a dedicated server (<em>Server B</em>) running as a <strong>Docker container</strong>.</li>\n<li>Server A monitors one client instance (<em>node1</em>) with a MongoDB service (<em>mongodb1</em>).</li>\n</ul>\n<p><span style=\"font-size: 16px;\">Here&#8217;s the output of <span style=\"background-color: #f4f4f4; font-family: 'Courier 10 Pitch', Courier, monospace;\">pmm-admin status</span> for this instance.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77004 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-1024x399.png\" alt=\"pmm-admin status\" width=\"900\" height=\"351\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-1024x399.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-300x117.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-200x78.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-1536x599.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-1140x445.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-367x143.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900.png 1547w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h2>Export Data</h2>\n<p>PMM2 data is stored in the <code>/srv</code> folder for all types of installations. So first make a backup archive of it.</p><pre class=\"crayon-plain-tag\">tar -cv /srv | gzip &#62; pmm-data.tar.gz</pre><p>Copy this archive to <i>Server B</i>.</p><pre class=\"crayon-plain-tag\">scp pmm-data.tar.gz user1@172.17.0.2:~/</pre><p></p>\n<h2>Prepare New Server</h2>\n<p>Connect to Server B run all further commands on this server. Prepare the Docker container.</p><pre class=\"crayon-plain-tag\">docker create -v /srv --name pmm-data percona/pmm-server:2 /bin/true</pre><p>Next extract exported data from the archive.</p><pre class=\"crayon-plain-tag\">tar -zxvf pmm-data.tar.gz -C /tmp</pre><p>Create a container for the new PMM Server with a <pre class=\"crayon-plain-tag\">/srv</pre> partition on a separate container (<pre class=\"crayon-plain-tag\">pmm-data</pre>).</p><pre class=\"crayon-plain-tag\">docker run -d -p 443:443 --volumes-from pmm-data --name pmm-server --restart always percona/pmm-server:2</pre><p>Stop all services and copy the exported data into the container.</p><pre class=\"crayon-plain-tag\">docker exec -it pmm-server supervisorctl stop all\ndocker exec -it pmm-server sh -c 'cd /; rm -rf /srv/victoriametrics/data'\ndocker cp /tmp/srv pmm-data:/</pre><p>Restore permissions for migrated data folders.</p><pre class=\"crayon-plain-tag\">docker exec -it pmm-server chown -R root:pmm /srv/clickhouse /srv/ia /srv/nginx /srv/pmm-distribution /srv/update\ndocker exec -it pmm-server chown -R pmm:pmm /srv/logs /srv/victoriametrics /srv/alertmanager /srv/prometheus\ndocker exec -it pmm-server chown -R grafana:grafana /srv/grafana\ndocker exec -it pmm-server chown -R postgres:postgres /srv/postgres /srv/logs/postgresql.log</pre><p>Restart PMM Server so that it reloads files with the correct permissions.</p><pre class=\"crayon-plain-tag\">docker restart pmm-server</pre><p></p>\n<h2>Switch Services to New Server</h2>\n<p>That&#8217;s it! Now you can switch your monitored <em>node1</em> to use the new server (<em>Server B</em>).</p>\n<p>Edit the the PMM agent configuration file <pre class=\"crayon-plain-tag\">/usr/local/percona/pmm2/config/pmm-agent.yaml</pre> .</p>\n<p>Set the IP address of Server B (<pre class=\"crayon-plain-tag\">172.17.0.2</pre> ) and restart <pre class=\"crayon-plain-tag\">pmm-agent</pre>.</p>\n<p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-77013\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241.png\" alt=\"\" width=\"539\" height=\"201\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241.png 539w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241-300x112.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241-200x75.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241-367x137.png 367w\" sizes=\"(max-width: 539px) 100vw, 539px\" /></p><pre class=\"crayon-plain-tag\">systemctl restart pmm-agent</pre><p></p>\n<h2>Check Status</h2>\n<p>Check the status of <pre class=\"crayon-plain-tag\">pmm-agent</pre> and monitored services with <pre class=\"crayon-plain-tag\">pmm-admin status</pre>.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77014 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-1024x370.png\" alt=\"Check Status PMM\" width=\"900\" height=\"325\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-1024x370.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-300x108.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-200x72.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-1536x555.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-367x133.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545.png 1546w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\nThe agent is now connected to your new server.</p>\n<p>In the Grafana UI, you can see the migrated data of Server B. (The time gap in the data is how long it took to run the import and switch <em>node1</em> to the new server.)</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77015 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-1024x381.png\" alt=\"Grafana UI\" width=\"900\" height=\"335\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-1024x381.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-300x112.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-200x74.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-1536x572.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-367x137.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749.png 1826w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>If historical data is here then we are done. Otherwise, please follow the commands that are provided in the next section.</p>\n<h2>Export/Import VictoriaMetrics Data</h2>\n<p>Copy the metrics in the <a target=\"_blank\" href=\"https://victoriametrics.com/\">VictoriaMetrics</a> time-series database using an API request for <a target=\"_blank\" href=\"http://export the data via /api/v1/export\">export</a>/<a target=\"_blank\" href=\"https://victoriametrics.github.io/#how-to-import-time-series-data\">import</a> data. (You can do the export remotely and run all further commands on <em>Server B</em>.)</p><pre class=\"crayon-plain-tag\">curl -k -G -u admin:admin https://3.86.222.201/prometheus/api/v1/export/native -d 'match={__name__!=\"\"}' &#62; exported_data.dump</pre><p>Next import the VictoriaMetrics data.</p><pre class=\"crayon-plain-tag\">curl -k -u admin:admin -X POST https://172.17.0.2/prometheus/api/v1/import/native -T exported_data.dump</pre><p>By default, the maximum allowed size of the client request body for PMM Server&#8217;s Nginx service is 10Mb. If <pre class=\"crayon-plain-tag\">exported_data.dump</pre> is bigger than this you must increase the limit and repeat the import.</p><pre class=\"crayon-plain-tag\">docker exec -it pmm-server bash -c \"sed -i 's/client_max_body_size 10m;/client_max_body_size 1000m;/g' /etc/nginx/conf.d/pmm.conf\"\ndocker exec -it pmm-server bash -c \"supervisorctl restart nginx\"</pre><p></p>\n<h3>Conclusion</h3>\n<p>You can use the same process to move from any instance type to another. Also, we have got a separate <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/06/19/percona-monitoring-and-management-2-docker-created-without-pmm-data-no-problem/\">blog post</a> about how to migrate if the pmm-data container isn&#8217;t used. Check it out!</p>\n","descriptionType":"html","publishedDate":"Tue, 06 Jul 2021 13:02:42 +0000","feedId":11,"bgimg":"","linkMd5":"7baf993af9e188b6b137ed5a280af57b","bgimgJsdelivr":"","metaImg":"","author":"Vadim Yalovets","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn4@2020_4/2021/07/13/17-22-07-462_c20ee83c787966f1.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn55@2020_6/2021/07/13/17-21-56-924_e7a791854fbac14c.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-1024x399.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn68@2020_3/2021/07/13/17-22-07-829_de5f7c698e0b3104.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn16@2020_6/2021/07/13/17-22-11-262_b98502938f7e3459.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-1024x370.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn88@2020_1/2021/07/13/17-22-07-702_8ecaeb5255f19ac4.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-1024x381.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn48@2020_5/2021/07/13/17-22-10-971_ca04cee4a6f6430d.webp"},"publishedOrCreatedDate":1626196914563},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MySQL Shell 101 – System Log","link":"https://www.percona.com/blog/?p=77025","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL Shell 101 - System Log\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77168\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-300x157.png\" alt=\"MySQL Shell 101 - System Log\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />One of the new features introduced in MySQL 8.0.24 was the ability to log all SQL statements that are issued in the MySQL Shell to the system log. This is a useful feature that can greatly assist in tracking who did what on the system. </span></p>\n<h2>Usage</h2>\n<p>The simplest way to utilize the new Shell logging feature is to simply start the MySQL Shell with the <strong>syslog</strong> option enabled like so:</p><pre class=\"crayon-plain-tag\">$&#62; mysqlsh --syslog --sql root@localhost</pre><p>From this point forward all SQL entered in the MySQL Shell will be logged to the system log. For example, the following SQL is entered into the Shell:</p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  SQL &#62; show databases;\n\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n+--------------------+</pre><p>We can now check the system log and verify that the statement above was indeed logged as expected, along with the system user and MySQL user that was used:</p><pre class=\"crayon-plain-tag\">$&#62; journalctl $(which mysqlsh)\nJun 28 10:01:11 localhost mysqlsh[9558]: SYSTEM_USER=brian MYSQL_USER=root CONNECTION_ID=16 DB_SERVER=localhost DB='--' QUERY='show databases;'</pre><p></p>\n<h2>Exclusions</h2>\n<p>As per the MySQL user manual, not all statements will be logged to the system log. Basically, any statements that would normally be excluded from the MySQL Shell code history for security reasons will also be excluded from the system log. We can verify what will be excluded by checking the MySQL Shell options in JS mode:</p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; shell.options</pre><p>This will list all current options for the shell, and the key one here is the <strong>history.sql.ignorePattern</strong> option. In our case, it is set as follows:</p><pre class=\"crayon-plain-tag\">\"history.sql.ignorePattern\": \"*IDENTIFIED*:*PASSWORD*\"</pre><p>So any SQL statement containing the words <strong>IDENTIFIED</strong> or <strong>PASSWORD</strong> will be ignored, and will not be logged into the MySQL Shell history, nor the system log even with logging enabled. This alleviates any security concerns about passwords being set in plain text in the system log.</p>\n<h2>Logging By Default</h2>\n<p>To automatically enable system logging from the MySQL Shell without having to specify it at each runtime, it is possible to set the option to persist. From the MySQL Shell, enter JS mode and set the following option:</p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; shell.options.setPersist(\"history.sql.syslog\",1)</pre><p>From this point forward all SQL that is entered in the MySQL shell will be logged to the system log by default.</p>\n<h2>Wrapping Up</h2>\n<p><span>Knowing who executed what in the MySQL Shell is a very useful administrative tool, and can help when tracking down issues or finding out who issued a particular statement at a given time. While not an entirely foolproof method of auditing (logging can still be disabled on a per-session basis), it is just another item for the DBA toolbox that can ease the administrative burden of today&#8217;s large database installations.</span></p>\n","descriptionType":"html","publishedDate":"Mon, 05 Jul 2021 13:29:58 +0000","feedId":11,"bgimg":"","linkMd5":"8eb8e92d03bfcaf9d9e4eb5dff2f513d","bgimgJsdelivr":"","metaImg":"","author":"Brian Sumpter","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn8@2020_3/2021/07/13/17-22-09-891_86da49f5abdf766d.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn79@2020_6/2021/07/13/17-22-05-445_75c6012e9faf2084.webp"},"publishedOrCreatedDate":1626196914564},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"WiredTiger File Forensics Part 3: Viewing all the MongoDB Data","link":"https://www.percona.com/blog/?p=76750","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"WiredTiger MongoDB\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-76797\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-300x168.png\" alt=\"WiredTiger MongoDB\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />This article continues on from </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/05/18/wiredtiger-file-forensics-part-1-building-wt/\"><i><span>Part 1: Building &#8220;wt&#8221;</span></i></a><i><span> and  &#8220;</span></i><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/05/18/wiredtiger-file-forensics-part-2-wt-dump/\"><i><span>Part 2: wt dump</span></i></a><span>&#8221; to show how to extract any of your MongoDB documents directly from WiredTiger&#8217;s raw data files. It&#8217;ll also show how to take a peek into the index files. Lastly, it&#8217;ll show how to also look in the WT transaction log to see updates made since the latest checkpoint.</span></p>\n<p><div class=\"porto-content-box featured-boxes wpb_content_element \"><div class=\"featured-box  align-left\" style=\"\"><div class=\"box-content\" style=\"\"><span style=\"color: #ff6600;\"><b><img src=\"https://s.w.org/images/core/emoji/13.0.1/72x72/26a0.png\" alt=\"⚠\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /> Warning</b></span><span>: the wt dump tool usually opens files in read-write mode, even for commands you&#8217;d think would be read-only. It will automatically step through its normal recovery process most of the time, so it may change files.</span><span><br />\n</span><span>Until you know its effects on data files do not use it on your </span><i><span>only</span></i><span> copy of precious data &#8211; make a copy of the data directory and learn with the copy first.</span></div></div></div></p>\n<h2>List up the Collections and Indexes</h2>\n<p><span>WiredTiger doesn&#8217;t name any of its data files according to the MongoDB object names, so as a first step you&#8217;ll have to extract a table of </span><b>WT idents</b><span> (=identifiers) vs. collection and index names.</span></p>\n<p><span>The </span><i><span>_mdb_catalog.wt</span></i><span> file is not the top table in the WiredTiger storage engine&#8217;s own hierarchy of data sources. To the MongoDB layer of code though it is the complete definition of collection and index objects in the database. This includes both MongoDB system and user-made collections and indexes.</span></p>\n<h3>Dump WT ident vs Collections</h3>\n<p><span>As explained in the previous </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/05/18/wiredtiger-file-forensics-part-2-wt-dump/\"><span>Part 2: wt dump</span></a><span> blog post, you should reuse this command to save a tab-delimited file of WiredTiger ident(ifier)s vs collection names. I&#8217;ll call this file </span><i><span>wt_ident_vs_collection_ns.tsv</span></i><span> in this article.</span></p><pre class=\"crayon-plain-tag\">$ #cd to a copy of a MongoDB data directory\n$ wt dump -x table:_mdb_catalog | tail -n +7 | awk 'NR%2 == 0 { print }' | xxd -r -p | bsondump --quiet | jq -r 'select(. | has(\"md\")) | [.ident, .ns] | @tsv' | sort &#62; wt_ident_vs_collection_ns.tsv\n$ \n$ head -n 5 wt_ident_vs_collection_ns.tsv\ncollection-0--4131298130356306083\tconfig.cache.chunks.test.bar\ncollection-0-5834121039240263510\tlocal.replset.initialSyncId\ncollection-0-5841128870485063129\tlocal.startup_log\ncollection-0--6422702119521843596\tconfig.system.sessions\ncollection-10--4131298130356306083\tconfig.cache.chunks.test.foo</pre><p><span>Eg. if an ident is &#8220;collection-4-5841128870485063129&#8221; then there will be a file collection-4-5841128870485063129.wt that has the data of a MongoDB collection.</span></p>\n<p><span>In case you have a vague memory of seeing strings like these somewhere whilst using the mongo shell, you probably have. These idents are the same as the ones shown in the &#8220;wiredTiger.uri&#8221; field of the </span><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/command/collStats/\"><i><span>db.collection.stats()</span></i></a> <span>command output.</span></p>\n<h3>Optional: Dump WT ident vs Indexes</h3>\n<p><span>The index WT idents can be dumped as well. The example below will save them to </span><i><span>wt_vs_index_ns.tsv</span></i><span> in three columns [WT ident, collection name, index name].</span></p><pre class=\"crayon-plain-tag\">$ wt dump -x table:_mdb_catalog | tail -n +7 | awk 'NR%2 == 0 { print }' | xxd -r -p | bsondump --quiet | jq -r 'select(. | has(\"idxIdent\")) | .ns as $nsT | .idxIdent | to_entries[] | [.value, $nsT, .key] | @tsv' | sort &#62; wt_ident_vs_index_ns.tsv\n$\n$ head -n 5 wt_vs_index_ns.tsv\nindex-11--4131298130356306083\tconfig.cache.chunks.test.foo\t_id_\nindex-12--4131298130356306083\tconfig.cache.chunks.test.foo\tlastmod_1\nindex-12-5841128870485063129\tlocal.system.replset\t_id_\nindex-1--4131298130356306083\tconfig.cache.chunks.test.bar\t_id_\nindex-14-5841128870485063129\tadmin.system.version\t_id_</pre><p></p>\n<h2>Looking at the Application (= MongoDB) Table Data</h2>\n<p><b><i>collection-*.wt</i></b><span> and </span><b><i>index-*.wt</i></b><span> files contain the data of the MongoDB collections and indexes that you observe as a client connected to a MongoDB instance. Once you&#8217;ve identified the WT ident value for the collection or index you want to inspect you can use that in the URI argument to the </span><i><span>wt dump</span></i><span> command.</span></p>\n<h3><em>wt dump </em>collections to *.bson files</h3>\n<p><span>The </span><i><span>wt dump</span></i><span> output of </span><i><span>collection-*</span></i><span> tables has a basic numeric type key and BSON data as the values.</span></p>\n<p><span>Use wt dump -x in your terminal on the WT file for a collection and you will see, after the header section, records of the WT table in alternating lines of key and value.</span></p>\n<p><span>Eg. in the example below the first key is numeric/binary value 0x81 and the first value is the one starting with binary bytes 0xce000000025f6964001e. The second key is 0x82, and its value starts with 0xce000000025f69640021. The values are BSON which were much longer in reality, I only trimmed it for readability at the moment.</span></p><pre class=\"crayon-plain-tag\">$ wt dump -x collection-X-XXXXXXXXXX\nWiredTiger Dump (WiredTiger Version 10.0.0)\nFormat=hex\nHeader\nfile:WiredTiger.wt\naccess_pattern_hint=none,allocation_size=4KB,app.....\nData\n81\n68000000025f6964001e000000424d50524f442d425a41342d31...\n82\n6b000000025f69640021000000424d50524f442d574f524b4552...\n...</pre><p><span>FYI Using the alternative URI argument syntax &#8220;wt dump -x </span><strong>table:</strong><i><span>collection-X-XXXXXXXXXX</span></i><span>&#8221; or &#8220;wt dump -x </span><strong>file:</strong><i><span>collection-X-XXXXXXXXXX</span></i><strong>.wt</strong><span>&#8221; will produce the same.</span></p>\n<p><span>The key value in the </span><i><span>collection-*</span></i><span> tables isn&#8217;t needed to see the document content so print only every second line for the values using the following command:</span></p><pre class=\"crayon-plain-tag\">$ wt dump -x collection-X-XXXXXXXXXX | tail -n +7 | awk 'NR%2 == 0 { print }'\n68000000025f6964001e000000424d50524f442d425a41342d31...\n6b000000025f69640021000000424d50524f442d574f524b4552....\n66000000025f6964001c000000424d50524f442d574f524b4552...\n6b000000025f69640021000000424d50524f442d574f524b4552...\n64000000025f6964001a000000424d50524f442d44415441312d...</pre><p><span>The command above prints binary BSON in a hex string format with a newline separating each record. We can translate that hexadecimal back to the original binary using the xxd command utility with the &#8220;-r&#8221; and &#8220;-p&#8221; flags. (</span><b>Note: </b><span>Don&#8217;t combine as one &#8220;-rp&#8221; flag. It doesn&#8217;t work like most unix command&#8217;s short options.)</span></p><pre class=\"crayon-plain-tag\">$ #Look for the WT ident of my test.customerOrder collection\n$ grep customerOrder wt_ident_vs_collection_ns.tsv\ncollection-14--3398103177079662761\ttest.customerOrder\n$ \n$ ls -lh collection-14--3398103177079662761.wt\n-rw------- 1 akira akira 40K Jun 10 15:12 collection-14--3398103177079662761.wt\n$\n$ #dump and convert its values to a plain BSON file:\n$ wt dump -x collection-14--3398103177079662761 | tail -n +7 | awk 'NR%2 == 0 { print }' | xxd -r -p &#62; test.customerOrder.bson\n$ \n$ #Confirm the content using bsondump\n$ bsondump --quiet test.customerOrder.bson\n{\"_id\":\"123456\",\"_class\":\"model.customer_order.CustomerOrder\",\"orderReference\":{\"businessInteractionId\":\"str ... \"orderAttributeValue\":\"string\"}]}]}]}]}}\n{\"_id\":\"ORN-billingissue01\",\"_class\":\"com.ctl.bm.servi ... startDate\":\"2018-02-02T00:00:00.000Z\"}],\"existingTN\":[]}\n2021-06-10T15:12:16.627+0900\t2 objects found</pre><p></p>\n<h3>&#8220;wt read&#8221; a single record?</h3>\n<p><span>Sorry, you can&#8217;t read your MongoDB collection data with the &#8220;wt read&#8221; shell command. The blocker is trivial &#8211; as of WT v10.0.0 the &#8220;</span><a target=\"_blank\" href=\"http://source.wiredtiger.com/10.0.0/command_line.html#util_read\"><span>wt read</span></a><span>&#8221; command only accepts plain text or its own &#8220;r&#8221; recordid numeric value as the lookup key value. The keys for the mongodb collections and indexes however are &#8216;q&#8217; and &#8216;u&#8217; types respectively. (Documentation: </span><a target=\"_blank\" href=\"https://source.wiredtiger.com/2.8.0/schema.html#schema_format_types\"><span>WT Schema Format types</span></a><span>.)</span></p>\n<p><span>In MongoDB, you might know you can use a </span><i><span>showRecordId</span></i><span> cursor option so it&#8217;s tempting to think that this is the same &#8220;r&#8221; type that wt read can currently accept, but unfortunately it is not. See the </span><i><span>key_format=X</span></i><span> value in the header of wt dump output samples to confirm.</span></p>\n<p><span>If wt read (code = </span><a target=\"_blank\" href=\"https://github.com/wiredtiger/wiredtiger/blob/develop/src/utilities/util_read.c\"><span>utilities/util_read.c</span></a><span>) was modified to accept an -x argument so we could pass the hex strings we already see in wt dump output this issue would be solved. But as it isn&#8217;t, for now, you have to dump all records even if you just want one.</span></p>\n<p><span>This is only a limitation in the shell. If you use the API from within a programming language, including the Python SWIG binding available, you should be able to read just a single record.</span></p>\n<h2>Looking at MongoDB&#8217;s Index Files</h2>\n<h3><em>wt dump</em> index-*.wt files</h3>\n<p><i><span>index-*</span></i><span> WiredTiger tables have two different formats that are easy to see when using </span><i><span>wt dump</span></i><span> to look inside them &#8211; one with just keys, and one with both keys and values. The WT keys are binary values generated from MongoDB&#8217;s </span><b>KeyString</b><span> structure.</span></p>\n<p><span>Below is an example of an index on </span><i><span>{state: 1, process: 1}</span></i><span> on a collection called </span><i><span>config.locks</span></i><span>. This is a case where there are no values in the WT table for the index. </span></p><pre class=\"crayon-plain-tag\">$ grep index-15--749209957533832251 wt_ident_vs_index_ns.tsv \nindex-15--7492099575338322516\tconfig.locks\tstate_1_process_1\n$ \n$ wt dump -x index-15--7492099575338322516 | tail -n +7\n293c436f6e66696753657276657200040008    &#60;keys on odd-numbered line&#62;\n   &#60;these even-numbered lines are where the WT value would be&#62;\n293c436f6e66696753657276657200040040\n\n293c7072642d6d6f6e2d7065722d73686172642d6130333a32373031383a313538363938343138383a3139393331363932353337323937373139383300040028\n\n....\n\n293c70726f642d6d6f6e676f2d73686172642d6d6f6e676f732d302e6d6f6e676f2e706572636f6e612e636f6d3a32373031373a313535343633323838333a38363534383239393034393534383037333200040078\n\n2b043c436f6e66696753657276657200040060\n\n$</pre><p><span>Below is an example of an </span><i><span>{_id: 1} </span></i><span>index on the collection </span><i><span>test.rlru</span></i><span>. This is a case when there are both WT keys and values.</span></p><pre class=\"crayon-plain-tag\">$ grep index-1-2871579003788456567 wt_ident_vs_index_ns.tsv \nindex-1-2871579003788456567\ttest.rlru\t_id_\n$\n$ wt dump -x index-1-287157900378845656 | tail -n +7\n2904\n0008\n2b0204\n0010\n2b0404\n0018\n...\n...\n2c0faa04\n203eb1\n2c0fac04\n203eb9\n...</pre><p><span>Given the point of an index record lookup is to have a value that points to a record in the </span><i><span>collection-X-XXXX</span></i><span> WT table, you should be asking &#8220;How can that first index above be useful without values?&#8221;</span></p>\n<p><span>The answer is the recordid is packed on the end of the key. You&#8217;ll notice in the first example they all have 0x04 as the third-last byte. This is how MongoDB packs a recordId when the value is between 0 and 2^10 &#8211; 1 I believe. See </span><a target=\"_blank\" href=\"https://github.com/mongodb/mongo/blob/60ab9d0e6e9b4d8dddeec16f14d8637e8802d1db/src/mongo/db/storage/key_string.cpp#L451\"><span>KeyString appendRecordId()</span></a><span> if you want to get into it further.</span></p>\n<p><span>By the way, an index&#8217;s field names are constant and thus irrelevant to sort order, so they&#8217;re not part of the keystrings.</span></p>\n<p><span>Writing about the KeyString format even in just the shortest summary would take a whole blog post. So I&#8217;ll just punch out some translations of the binary above as a teaser and stop there.</span></p>\n<p><span>Keystring 293c436f6e66696753657276657200040008 =&#62;</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x29</b><span> = type marker for numeric value 0.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x3c</b><span> type marker for (UTF-8?) string</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>36f6e66696753657276657200 hex of string &#8220;ConfigServer&#8221; plus tailing null</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x04</b><span> type marker for a recordId</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>0x0008 =&#62; binary 000 + binary 0000000001 + binary 000 = (recordId) value 1</span></li>\n</ul>\n<p><span>Keystring 2b043c436f6e66696753657276657200040060 =&#62;</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x2b</b><span> = type marker, positive integer in small range (&#60; 2^7?)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>04 = binary 0000010 + bit 0 = value 2</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x3c</b><span> type marker for (UTF-8?) string</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>36f6e66696753657276657200 hex of string &#8220;ConfigServer&#8221; plus tailing null</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x04</b><span> type marker for a recordId</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>0x0060 =&#62; binary 000 + binary 00.0000.1100 + binary 000 = (recordId) value 12</span></li>\n</ul>\n<p><span>Keystring 2b0404 =&#62;</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x2b</b><span> = type marker, positive integer in small range (&#60; 2^7?)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>04 = binary 000010 + 00 = value 2, not sure what the tailing two bytes are for.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>0x04</b><span> type marker to indicate the following value is recordId?</span></li>\n</ul>\n<p><span>Value 001001 =&#62;</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>0018 = binary 000 + binary value 00 0000 0011 = 3, plus 3 bits 000 on the end. T.b.h. I don&#8217;t always know how to translate this one, but commonly 3 bits at the beginning and end of the recordId format are used as a byte size indicator.</span></li>\n</ul>\n<p><span>If looking for matching records in the </span><i><span>collection-X-XXX</span></i><span> table look for key (0x80 + the recordid) value from the index file. Eg. 2 -&#62; 0x82; 12 -&#62; 0x9c. For some reason 0x0 &#8211; 0x80 seems to be reserved and so key values in the </span><i><span>collection-X-XXX.wt</span></i><span> files are all incremented by 0x80 higher than the recordId value in the </span><i><span>index-X-XXX.wt</span></i><span> records.</span></p>\n<p><span>In the end though, as we don&#8217;t have an ability to use </span><i><span>wt read</span></i><span>, all this poking around in the indexes from a shell command can only be for satisfying curiosity. Not for making single-record access fast.</span></p>\n<h2>Looking at the WT Transaction Log</h2>\n<p><span>A WiredTiger checkpoint saves a copy of documents in all collections and indexes as they were at one exact point in time (the time the checkpoint is started). MongoDB will call for a checkpoint to be made once per minute by default.</span></p>\n<p><span>Without something else being saved to disk, a sudden crash would mean that restores/restarts could only revert to the last checkpoint. The classic database concept of write-ahead log is the solution to this of course. In WiredTiger this is provided by the transaction log, often just called &#8220;log&#8221; in its own documentation. Or as the documentation also says it adds </span><a target=\"_blank\" href=\"http://source.wiredtiger.com/10.0.0/durability.html\"><span>&#8220;commit-level&#8221; durability</span></a><span> to checkpoint durability.</span></p>\n<p><span>At restart, whether it is after a perfectly normal shutdown or a crash, WiredTiger will read and replay the writes it finds in its transaction log onto the tables, in memory. In time, when the MongoDB layer requests a new checkpoint be created, the in-memory restored data will be saved to disk.</span></p>\n<p><span>When you use </span><i><span>wt dump</span></i><span> it&#8217;s not easy to say if you&#8217;re looking at the collection (or index) restored as of the last checkpoint or with the transaction log &#8220;recovered&#8221; (read and applied) as well. If the &#8220;-R&#8221; </span><a target=\"_blank\" href=\"http://source.wiredtiger.com/10.0.0/command_line.html#util_global_options\"><span>global option</span></a><span> of the wt command is used then yes log is recovered; if the opposite &#8220;-r&#8221; option is used then no. But which is in effect if you specify neither is unclear. Also, I&#8217;ve seen comments or diagnostic messages that suggest the -r option isn&#8217;t perfect.</span></p>\n<h3>Two Layers of Recovery</h3>\n<p><span>WiredTiger would, by default, keep no transaction log for the tables it manages for the application embedding it. It&#8217;s only the request of the application that engages it.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>If you are using a standalone </b><span>mongod MongoDB code will enable WT log for every collection and index created</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>Unless the &#8220;recoverFromOplogAsStandalone&#8221; server parameter is used. This is a trick that is part of point-in-time recovery of hot backups.</span></li>\n</ul>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>When replication is enabled (the typical case) only the WT tables for &#8220;local&#8221; db collections and indexes</b><span> get &#8220;</span><i><span>log=(enabled=true)&#8221;</span></i><span> in their WT config string made by </span><a target=\"_blank\" href=\"https://github.com/mongodb/mongo/blob/v4.4/src/mongo/db/storage/wiredtiger/wiredtiger_record_store.cpp#L797-L806\"><span>WiredTigerRecordStore::generateCreateString()</span></a><span> in wiredtiger_record_store.cpp, and something similar in wiredtiger_index.cpp.</span></li>\n</ul>\n<p><span>When a mongod node restarts with an existing data directory the WiredTiger library will run recovery. It can&#8217;t be stopped (at least not by the MongoDB user). This is not the end of the story though. When replication was used it means only the &#8220;local&#8221; db collections, in particular the oplog, is restored. The replication system code has a </span><b>ReplicationRecovery</b><span> class that is used next, and this will apply updates made since the last durable checkpoint time from the oplog to the user and system collections they&#8217;re supposed to be in. Only after that occurs will recovery be complete and the db server will make the data available to clients.</span></p>\n<p><span>ReplicationRecovery allows MongoDB to do rollbacks (at least to the checkpoint time) and also to trim off ops in the last replication batch application. It&#8217;s an ugly point but MongoDB applies replication ops in small batches in parallel to improve performance; this only happens on secondaries usually of course, but also after a restart. If all the writes in the batch finish that is fine, but if they don&#8217;t some writes may be missing which is a clear consistency violation. So the unfinished batch&#8217;s writes should all be cleared, back to the last saved </span><i><span>oplogTruncateAfterPoint</span></i><span> value. </span><i><span>repl.oplogTruncateAfterPoint</span></i><span> is a single-document collection in the local db. It exists only for this purpose as far as I know.</span></p>\n<h3>Diagram for Typical Restart Recovery</h3>\n<p><span>&#8220;Typical&#8221; = restarting a node that is a replica. Doesn&#8217;t matter if it was a primary or secondary, or even the only node in the replica set.</span></p>\n<p style=\"text-align: center;\"><span>WiredTiger&#8217;s recovery</span></p>\n<p style=\"text-align: center;\"><span> ⇓</span></p>\n<p style=\"text-align: center;\"><span>WT table for </span><i><span>local.oplog.rs</span></i><span> updated</span></p>\n<p style=\"text-align: center;\"><span> ⇓</span></p>\n<p style=\"text-align: center;\"><span>ReplicationRecovery</span></p>\n<p style=\"text-align: center;\">⇓</p>\n<p style=\"text-align: center;\"><span>Trim oplog docs where &#8220;ts&#8221; &#62; oplogTruncateAfterPoint</span></p>\n<p style=\"text-align: center;\">⇓</p>\n<p style=\"text-align: center;\"><span>oplog application</span></p>\n<p style=\"text-align: left; padding-left: 160px;\"><i><span>Pseudo code:<br />\n</span></i><i>db.oplog.rs.find({ts &#62; durable checkpoint time}).forEach(function(d) {<br />\n</i><i><span>     //re-apply write to intended collection in &#8220;test&#8221;, &#8220;mydb&#8221;, &#8220;admin&#8221;, etc. db<br />\n</span></i><i><span>     applyOps(opdoc);<br />\n</span></i><i>}</i></p>\n<p style=\"text-align: center;\"><span> ⇓</span></p>\n<p style=\"text-align: center;\"><span>Ready!</span></p>\n<h2>wt printlog</h2>\n<p><span>You can use the </span><i><span>wt printlog</span></i><span> command to see what is in the log currently in the WiredTigerLog.&#60;nnnnnn&#62; files in the journal/ subdirectory. If you decode the write ops in there you can understand what document versions will be restored by MongoDB when it restarts.</span></p>\n<h3>Preparation to Using wt printlog &#8211; Map WT idents to fileid</h3>\n<p><span>Until now you&#8217;ve learned that every MongoDB collection and index is in its own WT table file, which means needing to learn what the WT ident(ifier) is to find the right raw WT file to look into.</span></p>\n<p><span>There&#8217;s another small integer </span><i><span>id</span></i><span> value, a.k.a. </span><i><span>fileid</span></i><span>, in WT metadata / WT table config strings for each file too. I suppose it saves space; at any rate, the WT transaction log references files only by this number. This means you&#8217;ll have to build a handy mapping or list of which WT ident is which fileid. Use the following command to create a file I call </span><i><span>wt_ident_vs_fileid.tsv</span></i><span>.</span></p><pre class=\"crayon-plain-tag\">$ wt dump file:WiredTiger.wt | grep -B 1 ',id=' | sed 's/^file:\\(.*\\)\\.wt\\\\00/\\1\\t/; s/.*,id=\\([0-9][0-9]*\\),.*/\\1/' | paste -d\" \" - - &#62; wt_ident_vs_fileid.tsv\n\n$ cat wt_ident_vs_fileid.tsv\nWiredTigerHS\t 268\n_mdb_catalog\t 3\ncollection-0--7000593926523175565\t 269\ncollection-0--7468664482515188034\t 196\ncollection-0--9200920937255444113\t 79\n...\ncollection-8-2787176720526139723\t 12\ncollection-83--6694766911154494072\t 194\nindex-1--7000593926523175565\t 270\nindex-1--7468664482515188034\t 197\nindex-1-2787176720526139723\t 5\n...\nindex-9--7468664482515188034\t 205\nindex-9-2787176720526139723\t 13\nsizeStorer\t 2</pre><p><span>WT idents don&#8217;t suggest to the human reader which MongoDB collection or index is involved though, so after that use this shell command to join </span><i><span>wt_ident_vs_fileid.tsv</span></i><span> to the </span><i><span>wt_ident_vs_collection_ns.tsv</span></i><span> and </span><i><span>wt_ident_vs_index_ns.tsv</span></i><span> files made earlier.</span></p><pre class=\"crayon-plain-tag\">$ join &#60;(sort wt_ident_vs_fileid.tsv) &#60;(cat wt_ident_vs_collection_ns.tsv wt_ident_vs_index_ns.tsv | sort) | sort -n -k 2 | sed 's/ /\\t/g' &#62; wt_ident_vs_sorted_fileid_and_mdb_name.tsv\n$ cat wt_ident_vs_sorted_fileid_and_mdb_name.tsv\ncollection-0-2787176720526139723\t4\tlocal.startup_log\nindex-1-2787176720526139723\t5\tlocal.startup_log\t_id_\ncollection-2-2787176720526139723\t6\tlocal.replset.oplogTruncateAfterPoint\nindex-3-2787176720526139723\t7\tlocal.replset.oplogTruncateAfterPoint\t_id_\ncollection-4-2787176720526139723\t8\tlocal.replset.minvalid\nindex-5-2787176720526139723\t9\tlocal.replset.minvalid\t_id_\n...\ncollection-16-2787176720526139723\t20\tlocal.oplog.rs\ncollection-17-2787176720526139723\t21\tadmin.system.version\nindex-18-2787176720526139723\t22\tadmin.system.version\t_id_\n...</pre><p><span>Not shown: WiredTiger&#8217;s own metadata table </span><b>WiredTiger.wt is fileid 0</b><span>. I presume this is hardcoded.</span></p>\n<h3>Transaction Log Files</h3>\n<p><span>In a brutally trimmed summary, the content of the transaction log is something like this:</span></p><pre class=\"crayon-plain-tag\">{ checkpoint marker }\n...\n...\n{ lsn : [42, 7424], ops: [ {fileid: i, key: x1, value: y1 } ] }\n{ lsn : [42, 8448], ops: [ {fileid: i, key: x2, value: y2 }, {...}, {...} ] }\n{ lsn : [42, 8960], ops: [ {fileid: j, key: x6, value: y6 } ] }\n{ lsn : [43,    0], ops: [ {fileid: i, key: x7, value: y7 }, {...} ] }\n{ lsn : [42,  256], ops: [ {fileid: i, key: x9, value: y9 } ] }\n...</pre><p><span>Going into details:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The files are WiredTiger table files.</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>The inserts to the WT table for the MongoDB </span><i><span>local.oplog.rs</span></i><span> collection are responsible for most of the log by size.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><b>When replication is used only </b><b><i>&#8220;local&#8221;</i></b><b> db collection and index writes are saved in the WT log</b><span>. This is saying: WT transaction log will only restore the </span><i><span>local</span></i><span> db data to what it should be. The replication system in MongoDB, above the storage engine, has a recovery process that reflects those post-last-checkpoint oplog writes to their respective collections outside of the &#8220;local&#8221; db.</span></li>\n</ul>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The </span><i><span>fileid</span></i><span> number is an internal one of WiredTiger. It is a simple integer that starts from 1, so you&#8217;ll probably only see this as a one or two- or three-digit value. Which WT </span><i><span>ident(ifier)</span></i><span> (eg. &#8220;collection-99-8595782607099944640&#8221;) it is for, and then which MongoDB collection (or index) that is for, can be determined by looking in the WiredTiger metadata. (See &#8220;Output a tab-delimited table of WT ident(ifier) values vs. collection namespace&#8221; in</span><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/05/18/wiredtiger-file-forensics-part-2-wt-dump/\"><span> WiredTiger File Forensics Part 2: wt dump</span></a><span>. Once you know the ident, use wt dump on that table and look for the &#8220;id=&#8230;&#8221; value in its config string in the header section.)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>There are no timestamps here that the WiredTiger library uses. It will follow the order exactly whilst replaying these writes though. And that order is as the application (= MongoDB) committed them before.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>MongoDB writes the oplog &#8220;ts&#8221; timestamp into the wiredtiger </span><i><span>key</span></i><span> value shown above when it writes oplog docs. The &#8220;ts&#8221; value used is transformed from the BSON timestamp value binary format by </span><a target=\"_blank\" href=\"https://github.com/mongodb/mongo/blob/5bbadc66ed462aed3cc4f5635c5003da6171c25d/src/mongo/db/record_id_helpers.cpp#L69\"><span>record_id_helpers::extractKeyOptime(&#8230;)</span></a><span>. (</span><a target=\"_blank\" href=\"https://github.com/mongodb/mongo/blob/a83b7f8120c16b346e45a47a39cdf2543f94838a/src/mongo/db/storage/oplog_hack.cpp#L67\"><span>oploghack::extractKey()</span></a><span> in &#60;= v4.2).</span><span><br />\n</span><span>This is an exception to what MongoDB puts into the key values of WT tables for other collections (and indexes).</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The </span><i><span>value</span></i><span> shown above is just a binary blob to WiredTiger</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>For the tables that hold MongoDB collections, those blobs hold the raw BSON object you can see as a MongoDB user.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>The blob for mongodb indexes will be a MongoDB KeyString.</span></li>\n</ul>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>&#8220;lsn&#8221; field is transaction log file number (eg. 43 is &#8220;WiredTigerLog.0000000043&#8221;) plus byte offset. So it is an ever-increasing tuple value, a simple definition of order.</span></li>\n</ul>\n<p><span>With that explained, let&#8217;s look at a real sample now:</span></p><pre class=\"crayon-plain-tag\">$ #To use wt printlog the WiredTiger config string definitely needs to be set.\n$ #  See the part 1 of this blog series for details. In this example I'll do it by \n$ #  the -C option, but there are two other ways as well\n$\n$ wt -C \"log=(compressor=snappy,path=journal)\" printlog -xu | head -n 100\n[\n  { \"lsn\" : [55,128],\n    \"hdr_flags\" : \"\",\n    \"rec_len\" : 128,\n    \"mem_len\" : 128,\n    \"type\" : \"system\",\n    \"ops\": [\n      { \"optype\": \"prev_lsn\",\n        \"prev_lsn\": [54, 98566272]\n      }\n    ]\n  },\n  { \"lsn\" : [55,256],\n    \"hdr_flags\" : \"\",\n    \"rec_len\" : 384,\n    \"mem_len\" : 384,\n    \"type\" : \"commit\",\n    \"txnid\" : 812443,\n    \"ops\": [\n      { \"optype\": \"row_put\",\n        \"fileid\": 20 0x14,\n        \"key\": \"\\u00e8`\\u0088\\u000b\\u00c2\\u00ff\\u00ff\\u00e0\\u00e7\",\n        \"key-hex\": \"e860880bc2ffffe0e7\",\n        \"value\": \"\\u00f3\\u0000\\u0000\\u0000\\u0002op\\u0000\\u0002\\u0000\\u0000\\u0000d\\u0000\\u0002ns\\u0000 \\u0000\\u0000\\u0000config.transaction_coordinators\\u0000\\u0005ui\\u0000\\u0010\\u0000\\u0000\\u0000\\u0004\\u00f7z\\u001082\\u00c6A\\r\\u0089\\nx\\u00cb(\\u00edD\\u0080\\u0003o\\u0000p\\u0000\\u0000\\u0000\\u0003_id\\u0000f\\u0000\\u0000\\u0000\\u0003lsid\\u0000H\\u0000\\u0000\\u0000\\u0005id\\u0000\\u0010\\u0000\\u0000\\u0000\\u0004\\u00d4\\u00dc\\u00ac\\u00ef\\u00e7\\u0087@\\u00a7\\u009d\\u00df\\u00c6.\\u00d6\\u00f4\\u00f0\\u00ec\\u0005uid\\u0000 \\u0000\\u0000\\u0000\\u0000\\u00e3\\u00b0\\u00c4B\\u0098\\u00fc\\u001c\\u0014\\u009a\\u00fb\\u00f4\\u00c8\\u0099o\\u00b9$'\\u00aeA\\u00e4d\\u009b\\u0093L\\u00a4\\u0095\\u0099\\u001bxR\\u00b8U\\u0000\\u0012txnNumber\\u0000s\\u0004\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0011ts\\u0000'\\u0001\\u0000\\u0000\\u00c3\\u000b\\u0088`\\u0012t\\u0000i\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\twall\\u0000(\\u00f5m\\u0013y\\u0001\\u0000\\u0000\\u0012v\\u0000\\u0002\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\",\n        \"value-hex\": \"f3000000026f7000020000006400026e730020000000636f6e6669672e7472616e73616374696f6e5f636f6f7264696e61746f727300057569001000000004f77a103832c6410d890a78cb28ed4480036f0070000000035f69640066000000036c7369640048000000056964001000000004d4dcacefe78740a79ddfc62ed6f4f0ec05756964002000000000e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855001274786e4e756d62657200730400000000000000001174730027010000c30b886012740069000000000000000977616c6c0028f56d1379010000127600020000000000000000\"\n      }\n    ]\n  },\n  { ....</pre><p>&#160;</p>\n<p><span>The plain &#8220;key&#8221; and &#8220;value&#8221; fields are a mixture of printable chars and hex encoding for non-printable chars, unfortunately, encoded as UTF-16 rather than ascii or UTF-8. This is too hard to work with, so I add the -x option to also print the hex strings the same as </span><i><span>wt dump -x</span></i><span> does.</span></p>\n<p><span>In this sample fileid 20 is for </span><i><span>local.oplog.rs</span></i><span> and this typical content for the WT log with MongoDB. Using xxd -r -p we can see what is going into the value:</span></p><pre class=\"crayon-plain-tag\">$ echo  \"f3000000026f7000020000006400026e730020000000636f6e6669672e7472616e73616374696f6e5f636f6f7264696e61746f727300057569001000000004f77a103832c6410d890a78cb28ed4480036f0070000000035f69640066000000036c7369640048000000056964001000000004d4dcacefe78740a79ddfc62ed6f4f0ec05756964002000000000e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855001274786e4e756d62657200730400000000000000001174730027010000c30b886012740069000000000000000977616c6c0028f56d1379010000127600020000000000000000\" | xxd -r -p | bsondump --quiet | jq  .\n{\n  \"op\": \"d\",\n  \"ns\": \"config.transaction_coordinators\",\n  \"ui\": {\n    \"$binary\": {  \"base64\": \"93oQODLGQQ2JCnjLKO1EgA==\", \"subType\": \"04\" }\n  },\n  \"o\": {\n    \"_id\": {\n      \"lsid\": {\n        \"id\": {  \"$binary\": { \"base64\": \"1Nys7+eHQKed38Yu1vTw7A==\", \"subType\": \"04\" } },\n        \"uid\": {\n          \"$binary\": { \"base64\": \"47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\", \"subType\": \"00\" }\n        }\n      },\n      \"txnNumber\": {  \"$numberLong\": \"1139\" }\n    }\n  },\n  \"ts\": {  \"$timestamp\": {\"t\": 1619528643, \"i\": 295 } },\n  \"t\": { \"$numberLong\": \"105\" },\n  \"wall\": { \"$date\": { \"$numberLong\": \"1619528643880\" } },\n  \"v\": { \"$numberLong\": \"2\" }\n}</pre><p><span>An insert to the oplog that is for a d(elete) of the document in &#8220;config.transaction_coordinators&#8221; with </span><i><span>&#8220;id&#8221;: {  &#8220;$binary&#8221;: { &#8220;base64&#8221;: &#8220;1Nys7+eHQKed38Yu1vTw7A==&#8221;, &#8220;subType&#8221;: &#8220;04&#8221; } }</span></i><span>.</span></p>\n<h3>Summary</h3>\n<p><span>To look at the MongoDB collections, indexes, and the transaction log (a.k.a. the mongodb journal) you can use the </span><i><span>wt dump</span></i><span> and </span><i><span>wt printlog</span></i><span> commands. Before doing any of that you&#8217;ll have to make a mapping of WT table ident(ifier)s vs. MongoDB collection and index names, and also a list of fileids for the log. This information can be extracted using </span><i><span>wt dump</span></i><span> on WiredTiger.wt and _mdb_catalog.wt tables. Well, that and a medium amount of grep, sed, awk, etc.</span></p>\n<p><span>The collection-*.wt files have key-value pairs of [recordId, BSON binary]. The </span><i><span>index-*.wt</span></i><span> files can also be read, where you can see the binary of the MongoDB-defined &#8220;keystrings&#8221;. Due to limitations with </span><i><span>wt read</span></i><span> described above in the article, there is no practical way currently with the &#8220;wt&#8221; util command to do index lookups.</span></p>\n<p><span>Looking at the transaction log with </span><i><span>wt printlog</span></i><span> command will show the operations that will be applied during restart to progress the data from the state it was at the last durable checkpoint to the moment the last journal commit happened before shutdown.</span></p>\n","descriptionType":"html","publishedDate":"Tue, 22 Jun 2021 10:47:07 +0000","feedId":11,"bgimg":"","linkMd5":"cdfcb5a1c0777a46246dc7777fb49e82","bgimgJsdelivr":"","metaImg":"","author":"Akira Kurogane","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn47@2020_4/2021/07/13/17-22-17-870_df0ed1f5dc48e0ef.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn59@2020_1/2021/07/13/17-22-07-774_3eb00843401a95f2.webp","https://s.w.org/images/core/emoji/13.0.1/72x72/26a0.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn23@2020_2/2021/07/13/17-22-11-250_36dd853bf8881a1b.webp"},"publishedOrCreatedDate":1626196914590},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Streaming MySQL Binlogs to S3 (or Any Object Storage)","link":"https://www.percona.com/blog/?p=77226","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Streaming MySQL Binlogs to S3\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright size-medium wp-image-77311\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-300x157.png\" alt=\"Streaming MySQL Binlogs to S3\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Problem Statement</h2>\n<p>Having backups of binary logs is fairly normal these days. The more recent binary logs are copied offsite, the better RPO (Recovery Point Objective) can be achieved. I was asked multiple times recently if something could be done to “stream” the binary logs to S3 as close to real-time as possible. Unfortunately, there is no readily available solution that would do that. Here, I show what can be done and also show a proof of concept implementation, which is not suitable for production use.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77227 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/binlog.png\" alt=\"MySQL Bin\" width=\"171\" height=\"201\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/binlog.png 171w, https://www.percona.com/blog/wp-content/uploads/2021/07/binlog-128x150.png 128w\" sizes=\"(max-width: 171px) 100vw, 171px\" /></p>\n<p>In this example, the instance has two binary log files (mysql-bin.000001 and mysql-bin.000002) already closed and mysql-bin.000003 being written. A trivial solution for backing up these binary log files would be to back up just the closed ones (the one that is not written). The default size of the binary log file is 1 GB. This means with this solution we would have a 1 GB binlog not backed up in the worst-case scenario. On average, we would have 500M binary logs not backed up. These numbers can be made better by lowering the max_binlog_size parameter, but that will lead to a slew of files and frequent rotation.</p>\n<h2>Uploading to Object Storage</h2>\n<p>It is possible to upload files to S3 in chunks using <a target=\"_blank\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html\">multipart uploads</a>. With this the file can be uploaded in chunks, the minimum chunk size is 5 MB. This means that a binlog can be read by another process while it’s written, and uploaded to S3 in 5 MB chunks. That’s definitely better than the 500 MB of the file copying or setting the max_binlog_size to 5M. Another thing that our backup solution could do is stream the binary logs to a remote location before it uploads them to S3.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77228 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3.png\" alt=\"MySQL Bin\" width=\"521\" height=\"465\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3.png 521w, https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3-300x268.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3-168x150.png 168w, https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3-367x328.png 367w\" sizes=\"(max-width: 521px) 100vw, 521px\" /></p>\n<p>The chunks are assembled together again on S3 when the multipart upload is finished.</p>\n<p>The files produced by the mysqlbinlog command can be read and if we have 5M, they can be uploaded to S3. The last chunk of a multipart upload can be less than 5M. With this, it’s guaranteed that the file can be uploaded. The file is read in chunks while it’s written.</p>\n<h2>Proof of Concept Implementation</h2>\n<p>The flow of the proof of concept implementation is the following.</p>\n<ul>\n<li>Start a mysqlbinlog process to stream the backup to a temporary directory. This is in the background.</li>\n<li>Read the files in chunks in the temporary directory. It might happen that a read() call will return with less than 5MB worth of data. In order to handle this case, there is a buffer for the read call. If the buffer reaches the minimum chunk size (5M) for multipart upload, we will upload it. This means that it can happen that 4.5M is already read with several small reads to the buffer, and the next read() call will be able to read 5M. In this case, the size of that chunk will be 9.5M. This is totally fine, the chunks can be variable in size. The goal is to upload the data as soon as possible, so it’s better to do it in one request. This means that in this proof of concept implementation, the chunk sizes will be between 5M and 10M.</li>\n<li>Once the end of the file is reached, the final part is uploaded regardless of size, and the file will be closed, a chunk from the next file will be read next. The final part in a multipart upload can be less than 5M. After a file is successfully uploaded to S3 in full, the file is deleted from the local temp directory. So, the local temp directory holds files that are either being uploaded, or they didn’t start to upload yet.</li>\n<li>If the reader is on the last, not closed file, it will just wait for more data, when the buffer fills, it will continue to upload parts.</li>\n</ul>\n<h3>Example</h3>\n<p>In this example, I have a server with two binlogs:</p><pre class=\"crayon-plain-tag\">mysql&#62; show binary logs;\n+------------------+-----------+-----------+\n| Log_name | File_size | Encrypted |\n+------------------+-----------+-----------+\n| mysql-bin.000001 | 105775625 | No |\n| mysql-bin.000002 | 85147151 | No |\n+------------------+-----------+-----------+\n2 rows in set (0.00 sec)</pre><p>The max_binlog_size is 100M for the sake of convenience.</p><pre class=\"crayon-plain-tag\">$ binlog2s3 --binary /usr/local/bin/mysqlbinlog --hostname db1.172.17.17.12.nip.io --port 3306 --username repl --password repl --start-file mysql-bin.000001 --tempdir /Users/pboros/tmpdir --bucket_name pboros-binlogtest\nWaiting for binlog files to appear\n2021-07-01 17:45:41.672730 Creating multipart uploader for mysql-bin.000001\n2021-07-01 17:45:42.460344 Uploading part 1 for mysql-bin.000001 size 5242880\n2021-07-01 17:45:51.465913 Uploading part 2 for mysql-bin.000001 size 5242880</pre><p>The temporary directory has the binary logs:</p><pre class=\"crayon-plain-tag\">$ ls -la\ntotal 372896\ndrwxr-xr-x 4 pboros staff 128 Jul 1 17:45 .\ndrwxr-xr-x+ 73 pboros staff 2336 Jun 30 18:04 ..\n-rw-r----- 1 pboros staff 105256799 Jul 1 17:45 mysql-bin.000001\n-rw-r----- 1 pboros staff 85663391 Jul 1 17:45 mysql-bin.000002</pre><p>In this case, streaming the binary logs from the beginning is much faster than uploading them to S3 (because I am streaming from a virtual machine locally, and I am uploading to S3 on a home internet connection).</p>\n<p>Soon enough the binlog will be uploaded:</p><pre class=\"crayon-plain-tag\">2021-07-01 17:48:23.865630 Uploading part 19 for mysql-bin.000001 size 5242880\n2021-07-01 17:48:33.350739 Uploading part 20 for mysql-bin.000001 size 5242880\n2021-07-01 17:48:41.708166 Uploading part 21 for mysql-bin.000001 size 399199\n2021-07-01 17:48:42.160303 Finishing multipart upload for mysql-bin.000001\n2021-07-01 17:48:42.407308 Creating multipart uploader for mysql-bin.000002\n2021-07-01 17:48:43.521756 Uploading part 1 for mysql-bin.000002 size 5242880\n2021-07-01 17:48:52.517424 Uploading part 2 for mysql-bin.000002 size 5242880</pre><p>Part 17 will be bigger because it has less than a 5M buffer from the time when there were new binary logs, and when new data became available. It could read an additional 5M on top of that.</p><pre class=\"crayon-plain-tag\">$ ls -la\ntotal 593496\ndrwxr-xr-x 5 pboros staff 160 Jul 1 17:52 .\ndrwxr-xr-x+ 73 pboros staff 2336 Jun 30 18:04 ..\n-rw-r----- 1 pboros staff 105267370 Jul 1 17:52 mysql-bin.000002\n-rw-r----- 1 pboros staff 105255295 Jul 1 17:52 mysql-bin.000003\n-rw-r----- 1 pboros staff 66061395 Jul 1 17:52 mysql-bin.000004</pre><p></p><pre class=\"crayon-plain-tag\">$ aws s3 ls s3://pboros-binlogtest/\n2021-07-01 17:45:43 105256799 mysql-bin.000001\n2021-07-01 17:48:43 105267370 mysql-bin.000002</pre><p>The uploaded parts are accessible with the S3 API (and they can be assembled to binlogs):</p><pre class=\"crayon-plain-tag\">$ aws s3api list-multipart-uploads --bucket pboros-binlogtest</pre><p>The S3 bucket can have a policy to auto-delete not finished multipart uploads periodically (for example unfinished multipart uploads that are older than 7 days).</p>\n<p>The proof of concept code is available at <a target=\"_blank\" href=\"https://github.com/pboros/binlog2s3\">https://github.com/pboros/binlog2s3</a>.</p>\n","descriptionType":"html","publishedDate":"Fri, 09 Jul 2021 13:34:07 +0000","feedId":11,"bgimg":"","linkMd5":"2519f01c262c6c14e723ec0fc147c6c1","bgimgJsdelivr":"","metaImg":"","author":"Peter Boros","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn24@2020_5/2021/07/13/17-22-13-004_4eda573d4f45b300.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn12@2020_2/2021/07/13/17-22-07-422_cdb95707f2ca7ddb.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/binlog.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn48@2020_1/2021/07/13/17-22-09-439_e62585814c6ffa21.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn23@2020_5/2021/07/13/17-21-55-064_685b7d8fb4a1c380.webp"},"publishedOrCreatedDate":1626196914556},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Using MySQL 8 Dual Passwords","link":"https://www.percona.com/blog/?p=77006","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Using MySQL 8 Dual Passwords\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77144\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-300x157.png\" alt=\"Using MySQL 8 Dual Passwords\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />MySQL 8 brought many highly anticipated features, with support for user roles, a new shell, a more robust data dictionary, and better SQL support, just to name a few. There are lesser-known new features, however, that aim to reduce overall DBA workload and streamline management processes – and one of these is support for dual passwords, first implemented in MySQL 8.0.14. User accounts are now permitted to have dual passwords, with a designated primary and secondary. This makes it possible to seamlessly perform user credential changes even with a large number of servers, or with multiple applications connecting to different MySQL servers.</span></p>\n<p><span>Historically, a MySQL credential change had to be timed so that when the password change was made and propagated throughout the database nodes, all applications that use that account for connections had to be updated at the same time. This is problematic for many reasons, but with database and application server counts as high as they are today, it becomes especially burdensome at the modern enterprise scale.</span></p>\n<h2>Overview</h2>\n<p><span>With dual passwords, credential changes can be made easily without requiring any coordination or downtime. The process would work something like this:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>For each account to be updated, establish a new primary password on the server(s) while retaining the current password as secondary. </span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>At this point, the servers will recognize both passwords (primary and secondary) and all applications can continue connecting with the old password the same as before.</span></li>\n</ul>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Once the password change has been done on the database side, the applications can be updated to connect using the new primary password. </span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Note that this can be done over a period of time, utilizing existing downtime maintenance windows if necessary.</span></li>\n</ul>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>After all the applications have been migrated to the new primary password, the secondary password is no longer needed on the database side and can be discarded. </span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Once discarded, only the new primary password can be used, and the credential change is now complete.</span></li>\n</ul>\n</li>\n</ul>\n<h2>Usage &#38; Example</h2>\n<p><span>To accomplish this dual password capability, the following new syntax will save and discard secondary passwords:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><strong>RETAIN CURRENT PASSWORD</strong> clause for the <strong>ALTER USER</strong> and <strong>SET PASSWORD</strong> statements saves the current password as a secondary password when a new primary is assigned.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><strong>DISCARD OLD PASSWORD</strong> clause for <strong>ALTER USER</strong> will discard a secondary password, leaving only the primary password in play.</span></li>\n</ul>\n<p><span>As an example, let’s use the dual password feature to update the password for a theoretical user (‘appuser’@’percona.com’). For this example, assume that application(s) will connect to the database with this user and that we will be changing the password from ‘oldpass’ to ‘newpass’.</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>On each server (that isn’t a replica), we’ll first set ‘newpass’ as the new primary password for ‘appuser’@&#8217;percona.com&#8217; while retaining the current password as secondary:</span><span><br />\n</span><br />\n<pre class=\"crayon-plain-tag\">mysql&#62; ALTER USER ‘appuser’@’percona.com’ IDENTIFIED BY ‘newpass’ RETAIN CURRENT PASSWORD;</pre>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><span>Once the password change has propagated through all the replica nodes, we can now begin changing the application(s) that are using the ‘appuser’@&#8217;percona.com&#8217; account to begin connecting with the new password (newpass) rather than the original password (oldpass). This can be done over a period of time, during existing downtime maintenance windows if necessary to minimize impact. Remember, at this point both passwords are valid.</span></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>With the application changes made, the secondary (old) password is no longer needed. On each server (that isn’t a replica), discard the secondary password:</span><span><br />\n</span><br />\n<pre class=\"crayon-plain-tag\">mysql&#62; ALTER USER ‘appuser’@’percona.com’ DISCARD OLD PASSWORD;</pre>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Once this has propagated through all replicas, the credential change is now complete.</span></li>\n</ol>\n<p><span>There are a few caveats you may want to be aware of in using the dual password feature:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>If you use <strong>RETAIN CURRENT PASSWORD</strong> for an account that has an empty primary password, the statement will fail.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>If an account has a secondary password, and you change the primary password without specifying<strong> RETAIN CURRENT PASSWORD</strong>, the secondary password remains unchanged.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>If you use <strong>ALTER USER</strong> and change the authentication plugin assigned to the account, the secondary password is discarded.</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>If you change the authentication plugin and also specify <strong>RETAIN CURRENT PASSWORD</strong>, the statement fails.</span></li>\n</ul>\n</li>\n</ul>\n<h2>Required Privileges</h2>\n<p><span>For modifying your own user account(s), the <strong>APPLICATION PASSWORD ADMIN</strong> privilege is required in order to use <strong>RETAIN CURRENT PASSWORD</strong> or <strong>DISCARD OLD PASSWORD</strong> clause for both the <strong>ALTER USER</strong> and <strong>SET PASSWORD</strong> statements.</span></p>\n<p><span>For modifying the secondary password for any (or all) accounts at an administrative level, the <strong>CREATE USER</strong> privilege is needed rather than the <strong>APPLICATION PASSWORD ADMIN</strong> privilege as above.</span></p>\n<h3>In Closing</h3>\n<p><span>While this is a very simple new feature, it can have a fairly significant impact on how your company manages the security aspects of frequent password changes, minimizing or possibly eliminating downtime from password updates altogether.</span></p>\n","descriptionType":"html","publishedDate":"Thu, 01 Jul 2021 15:17:38 +0000","feedId":11,"bgimg":"","linkMd5":"9146dc7aa938ba3a63c1166880042b5c","bgimgJsdelivr":"","metaImg":"","author":"Brian Sumpter","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn27@2020_2/2021/07/13/17-22-11-275_6d23508aeb2341c3.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn20@2020_5/2021/07/13/17-22-09-107_7cf47b307f072e1e.webp"},"publishedOrCreatedDate":1626196914564},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MySQL Static and Dynamic Privileges (Part 2)","link":"https://www.percona.com/blog/?p=76698","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL Dynamic and Static Privileges\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><em><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-76736\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-300x157.png\" alt=\"MySQL Dynamic and Static Privileges\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />When organizing things helps to simplify life.</span></em></p>\n<p><span>In the <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/15/mysql-static-and-dynamic-privileges-part-1/\">previous article</a>, we start to explore dynamic privileges and the interaction with static ones. We also saw how to remove SUPER privilege from a DBA account. </span></p>\n<p><span>What we did was go by subtraction. But in real life, we should act differently. We should ADD only what is really needed for the account to work correctly.</span></p>\n<p><span>Adding privilege one by one, and for each user is problematic given the level of interaction they may have, and also prone to mistakes. </span></p>\n<p><span>Instead, we can use ROLES to group, assign, and revoke the correct privileges in a much easier way.</span></p>\n<p><span>This is becoming even more important in MySQL with the advent of dynamic privileges.</span></p>\n<p><span>What should we do to correctly use ROLES? Well first of all design.  </span></p>\n<p><span>The first step is to identify the ROLES, in doing so we need to keep a basic principle, make it simple, as such let us try to avoid having too many ROLES, or ROLE with too many cross-functional privileges.</span></p>\n<p><span>My proposal: </span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>DBA (The lord of the databases who can do all)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>MaintenanceAdmin (DBA minions <img src=\"https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png\" alt=\"🙂\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /> they can perform only some action on the server, and server only)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>UserAdmin (Can create users assign grants and so on)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>MonitorUser (See all process and read from performance_schema)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>DBManager (Can add/drop/modify schemas/tables/triggers/view/routines etc )</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>DBDesigner (Can modify specific objects mostly with clear identification by schema/table)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>ReplicationAdmin (Can add/change/remove start/stop replication also GR)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>BackupAdmin (Can take backup, cannot restore)</span></li>\n</ul>\n<p><span>We have eight administrative ROLES and they should cover ALL we need for administrative tasks.</span></p>\n<p><span>Now let us create them:</span></p><pre class=\"crayon-plain-tag\">CREATE ROLE 'DBA', 'MaintenanceAdmin', 'UserAdmin', 'MonitorUser', 'DBManager', 'DBDesigner', 'ReplicationAdmin', 'BackupAdmin'\n\nDC2-1(root@localhost) [mysql]&gt;Select user,host from mysql.user where account_locked ='Y' and password_expired='Y' order by 1;\n+------------------+------+\n| user             | host |\n+------------------+------+\n| BackupAdmin      | %    |\n| DBA              | %    |\n| DBDesigner       | %    |\n| DBManager        | %    |\n| MaintenanceAdmin | %    |\n| MonitorUser      | %    |\n| ReplicationAdmin | %    |\n| UserAdmin        | %    |\n+------------------+------+\n8 rows in set (0.00 sec)</pre><p><span>Let us check the roles one by one and see what privileges we need to assign.</span></p>\n<p><span>Our test user does not have any grant:</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user()\\G\n*************************** 1. row ***************************\nGrants for secure_test@localhost: GRANT USAGE ON *.* TO `secure_test`@`localhost`</pre><p></p>\n<h3>DBA</h3>\n<p><span>Well, you may say .. easy GRANT ALL. </span></p>\n<p><span>Wrong! As already indicated in the previous article, doing that will also assign SUPER, which is deprecated </span><span>from MySQL 8.0.x. Let us start with the right foot and add ONLY what we need:</span></p><pre class=\"crayon-plain-tag\">GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE, CREATE ROLE, DROP ROLE ON *.* TO `DBA`@`%` WITH GRANT OPTION;\n   \nGRANT APPLICATION_PASSWORD_ADMIN,AUDIT_ADMIN,BACKUP_ADMIN,BINLOG_ADMIN,BINLOG_ENCRYPTION_ADMIN,CLONE_ADMIN,CONNECTION_ADMIN,ENCRYPTION_KEY_ADMIN,FLUSH_OPTIMIZER_COSTS,FLUSH_STATUS,FLUSH_TABLES,FLUSH_USER_RESOURCES,GROUP_REPLICATION_ADMIN,INNODB_REDO_LOG_ARCHIVE,INNODB_REDO_LOG_ENABLE,PERSIST_RO_VARIABLES_ADMIN,REPLICATION_APPLIER,REPLICATION_SLAVE_ADMIN,RESOURCE_GROUP_ADMIN,RESOURCE_GROUP_USER,ROLE_ADMIN,SERVICE_CONNECTION_ADMIN,SESSION_VARIABLES_ADMIN,SET_USER_ID,SHOW_ROUTINE,SYSTEM_USER,SYSTEM_VARIABLES_ADMIN,TABLE_ENCRYPTION_ADMIN,XA_RECOVER_ADMIN ON *.* TO `DBA`@`%` WITH GRANT OPTION;</pre><p><span>That should be exactly the same as GRANT ALL but without SUPER. </span></p>\n<p><span>To assign the ROLE to our test user:</span></p><pre class=\"crayon-plain-tag\">GRANT `DBA`@`%` TO `secure_test`@`localhost`</pre><p><span>Now our user has:</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user()\\G\n*************************** 1. row ***************************\nGrants for secure_test@localhost: GRANT USAGE ON *.* TO `secure_test`@`localhost`\n*************************** 2. row ***************************\nGrants for secure_test@localhost: GRANT `DBA`@`%` TO `secure_test`@`localhost`</pre><p><span>Correct you now see DBA as grant but that is not active:</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for DBA@'%'\\G\nERROR 1142 (42000): SELECT command denied to user 'secure_test'@'localhost' for table 'user'</pre><p><span>To ACTIVATE a role you need to do it explicitly:</span></p><pre class=\"crayon-plain-tag\"> SET DEFAULT ROLE DBA TO  secure_test@'localhost';</pre><p><span>And have the user reconnect!</span></p>\n<p><span>Once a role is activated we can also use:</span></p><pre class=\"crayon-plain-tag\">show grants for current_user()\\G</pre><p><span>To check which privileges are now active for a specific user.</span></p>\n<p><span>We can also control which role is active for which user querying the table mysql.default_roles. </span></p>\n<p><span>To remove the active role:</span></p><pre class=\"crayon-plain-tag\">SET DEFAULT ROLE NONE TO  secure_test@'localhost';</pre><p><span>Anyhow, NOW we have our DBA role available for all DBA and if we need to change something we can do it just there on the ROLE and not on every single user. </span></p>\n<h3>MaintenanceAdmin</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT EVENT, LOCK TABLES, RELOAD, SELECT, SHOW DATABASES, RELOAD, SHUTDOWN ON *.* TO `MaintenanceAdmin`@`%`;\nGRANT BINLOG_ADMIN, CONNECTION_ADMIN, ENCRYPTION_KEY_ADMIN, GROUP_REPLICATION_ADMIN, REPLICATION_SLAVE_ADMIN, SESSION_VARIABLES_ADMIN, SET_USER_ID, SYSTEM_VARIABLES_ADMIN ON *.* TO `MaintenanceAdmin`@`%`;\nGRANT `MaintenanceAdmin`@`%` TO `secure_test`@`localhost` ;</pre><p></p>\n<h3>UserAdmin</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT CREATE USER, GRANT OPTION, RELOAD, SHOW DATABASES ON *.* TO `UserAdmin`@`%`;\nGRANT ROLE_ADMIN  ON *.* TO `UserAdmin`@`%`;\nGRANT `UserAdmin`@`%` TO `secure_test`@`localhost` ;</pre><p></p>\n<h3>MonitorUser</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT PROCESS, REPLICATION CLIENT ON *.* TO `MonitorUser`@`%`;\nGRANT SELECT ON performance_schema.* TO `MonitorUser`@`%`;\nGRANT `MonitorUser`@`%` TO `secure_test`@`localhost` ;</pre><p></p>\n<h3>DBManager</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT ALTER, ALTER ROUTINE, CREATE, CREATE ROUTINE, CREATE TABLESPACE, CREATE TEMPORARY TABLES, CREATE VIEW, DELETE, DROP, DROP ROLE, EVENT, INDEX, INSERT, LOCK TABLES, RELOAD, SELECT, SHOW DATABASES, SHOW VIEW, TRIGGER, UPDATE  ON *.* TO `DBManager`@`%`;\nGRANT SET_USER_ID, SHOW_ROUTINE ON *.* TO `DBManager`@`%`;\nGRANT `DBManager`@`%` TO `secure_test`@`localhost` ;</pre><p></p>\n<h3>DBDesigner</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT ALTER, ALTER ROUTINE, CREATE, CREATE ROUTINE, CREATE VIEW, INDEX, SELECT, SHOW DATABASES, SHOW VIEW, TRIGGER ON *.* TO `DBDesigner`@`%`;\nGRANT `DBDesigner`@`%` TO `secure_test`@`localhost` ;</pre><p></p>\n<h3>ReplicationAdmin</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT REPLICATION CLIENT ON *.* TO `ReplicationAdmin`@`%`;\nGRANT REPLICATION_APPLIER, REPLICATION_SLAVE_ADMIN, GROUP_REPLICATION_ADMIN, SERVICE_CONNECTION_ADMIN ON *.* TO `ReplicationAdmin`@`%`;\nGRANT SELECT on performance_schema.* TO `ReplicationAdmin`@`%`;\nGRANT SELECT on mysql.* TO `ReplicationAdmin`@`%`;\nGRANT `ReplicationAdmin`@`%` TO `secure_test`@`localhost` ;</pre><p></p>\n<h3>BackupAdmin</h3>\n<p></p><pre class=\"crayon-plain-tag\">GRANT EVENT, LOCK TABLES, SELECT, SHOW DATABASES ON *.* TO `BackupAdmin`@`%`;\nGRANT BACKUP_ADMIN ON *.* TO `BackupAdmin`@`%`;\nGRANT `BackupAdmin`@`%` TO `secure_test`@`localhost` ;</pre><p><span>Once all our ROLES are in, we can test them. For instance, we can check our </span><i><span>ReplicationAdmin</span></i><span> checking the Binary Logs and stopping/starting our Group Replication (or normal Replication):</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show binary logs;\nERROR 1227 (42000): Access denied; you need (at least one of) the SUPER, REPLICATION CLIENT privilege(s) for this operation\n\nDC2-2(secure_test@localhost) [(none)]&gt;stop group_replication;\nERROR 1227 (42000): Access denied; you need (at least one of) the SUPER or GROUP_REPLICATION_ADMIN privilege(s) for this operation</pre><p><span>Also if created and assigned the role is not active. Let us now enable the role for the user:</span></p><pre class=\"crayon-plain-tag\">SET DEFAULT ROLE ReplicationAdmin  TO  secure_test@'localhost';</pre><p><span>Remember to reconnect!</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show binary logs;\n+---------------+-----------+-----------+\n| Log_name      | File_size | Encrypted |\n+---------------+-----------+-----------+\n| binlog.000011 | 113802321 | No        |\n| binlog.000012 |     19278 | No        |\n+---------------+-----------+-----------+\n2 rows in set (0.00 sec)\n\nDC2-2(secure_test@localhost) [(none)]&gt;stop group_replication;\nQuery OK, 0 rows affected (5.25 sec)\n\nDC2-2(secure_test@localhost) [(none)]&gt;select * from  performance_schema.replication_group_members;\n+---------------------------+--------------------------------------+-------------+-------------+--------------+-------------+----------------+\n| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |\n+---------------------------+--------------------------------------+-------------+-------------+--------------+-------------+----------------+\n| group_replication_applier | 7fddf04f-9797-11eb-a193-08002734ed50 | gr5         |        3306 | OFFLINE      |             |                |\n+---------------------------+--------------------------------------+-------------+-------------+--------------+-------------+----------------+\n1 row in set (0.00 sec)\n\nDC2-2(secure_test@localhost) [(none)]&gt;start group_replication;\nQuery OK, 0 rows affected (3.70 sec)\n\nDC2-2(secure_test@localhost) [(none)]&gt;select * from  performance_schema.replication_group_members;\n+---------------------------+--------------------------------------+-------------+-------------+--------------+-------------+----------------+\n| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |\n+---------------------------+--------------------------------------+-------------+-------------+--------------+-------------+----------------+\n| group_replication_applier | 79ede65d-9797-11eb-9963-08002734ed50 | gr4         |        3306 | ONLINE       | PRIMARY     | 8.0.23         |\n| group_replication_applier | 7e214802-9797-11eb-a0cf-08002734ed50 | gr6         |        3306 | ONLINE       | SECONDARY   | 8.0.23         |\n| group_replication_applier | 7fddf04f-9797-11eb-a193-08002734ed50 | gr5         |        3306 | ONLINE       | SECONDARY   | 8.0.23         |\n+---------------------------+--------------------------------------+-------------+-------------+--------------+-------------+----------------+\n3 rows in set (0.01 sec)</pre><p><span>And these are the privileges active:</span></p><pre class=\"crayon-plain-tag\">DC2-2(secure_test@localhost) [(none)]&gt;show grants for current_user()\\G\n*************************** 1. row ***************************\nGrants for secure_test@localhost: GRANT REPLICATION CLIENT ON *.* TO `secure_test`@`localhost`\n*************************** 2. row ***************************\nGrants for secure_test@localhost: GRANT GROUP_REPLICATION_ADMIN,REPLICATION_APPLIER,REPLICATION_SLAVE_ADMIN,SERVICE_CONNECTION_ADMIN ON *.* TO `secure_test`@`localhost`\n*************************** 3. row ***************************\nGrants for secure_test@localhost: GRANT SELECT ON `mysql`.* TO `secure_test`@`localhost`\n*************************** 4. row ***************************\nGrants for secure_test@localhost: GRANT SELECT ON `performance_schema`.* TO `secure_test`@`localhost`\n*************************** 5. row ***************************\nGrants for secure_test@localhost: GRANT `BackupAdmin`@`%`,`DBA`@`%`,`DBDesigner`@`%`,`DBManager`@`%`,`MaintenanceAdmin`@`%`,`MonitorUser`@`%`,`ReplicationAdmin`@`%`,`UserAdmin`@`%` TO `secure_test`@`localhost`\n5 rows in set (0.00 sec)</pre><p></p>\n<h3>Conclusion</h3>\n<p><span>Using the ROLES allows us to modify the needed privileges in one place, and at the same time will allow us to keep under control the possible proliferation of dynamic privileges due to the use of components or plugins, significantly reducing the complexity of having multiple privileges sources.</span></p>\n<p><span>Roles are normally used in the most common databases and MySQL had implemented them quite late. But using roles is the natural evolution of how we should deal with user grants when moving from small platforms to medium/large. </span></p>\n<p><span>The time when we assign single user privileges IS GONE, welcome to 2021 MySQLers!</span></p>\n<p><span>For your convenience, I am distributing a simple <a target=\"_blank\" href=\"https://github.com/Tusamarco/blogs/blob/master/roles_security/roles.sql\">SQL</a> file with all commands to create the Roles as described in this article.</span></p>\n<h3>References</h3>\n<p><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/roles.html\">https://dev.mysql.com/doc/refman/8.0/en/roles.html</a></p>\n<blockquote class=\"wp-embedded-content\" data-secret=\"wDyms7JFa6\"><p><a target=\"_blank\" href=\"https://lefred.be/content/some-queries-related-to-mysql-roles/\">Some queries related to MySQL Roles</a></p></blockquote>\n<p><iframe class=\"wp-embedded-content\" sandbox=\"allow-scripts\" security=\"restricted\" title=\"&#8220;Some queries related to MySQL Roles&#8221; &#8212; lefred&#039;s blog: tribulations of a MySQL Evangelist\" src=\"https://lefred.be/content/some-queries-related-to-mysql-roles/embed/#?secret=wDyms7JFa6\" data-secret=\"wDyms7JFa6\" width=\"600\" height=\"338\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe></p>\n<blockquote class=\"wp-embedded-content\" data-secret=\"gHvJqqDACd\"><p><a target=\"_blank\" href=\"https://lefred.be/content/mysql-8-0-listing-roles/\">MySQL 8.0: Listing Roles</a></p></blockquote>\n<p><iframe class=\"wp-embedded-content\" sandbox=\"allow-scripts\" security=\"restricted\" title=\"&#8220;MySQL 8.0: Listing Roles&#8221; &#8212; lefred&#039;s blog: tribulations of a MySQL Evangelist\" src=\"https://lefred.be/content/mysql-8-0-listing-roles/embed/#?secret=gHvJqqDACd\" data-secret=\"gHvJqqDACd\" width=\"600\" height=\"338\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe></p>\n<p>&#160;</p>\n<blockquote class=\"wp-embedded-content\" data-secret=\"jGliA9x5zI\"><p><a target=\"_blank\" href=\"https://lefred.be/content/mysql-8-0-roles-and-graphml/\">MySQL 8.0 Roles and Graphml</a></p></blockquote>\n<p><iframe class=\"wp-embedded-content\" sandbox=\"allow-scripts\" security=\"restricted\" title=\"&#8220;MySQL 8.0 Roles and Graphml&#8221; &#8212; lefred&#039;s blog: tribulations of a MySQL Evangelist\" src=\"https://lefred.be/content/mysql-8-0-roles-and-graphml/embed/#?secret=jGliA9x5zI\" data-secret=\"jGliA9x5zI\" width=\"600\" height=\"338\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe></p>\n","descriptionType":"html","publishedDate":"Tue, 15 Jun 2021 15:59:04 +0000","feedId":11,"bgimg":"","linkMd5":"85a323760676897ee72aca146fd55b44","bgimgJsdelivr":"","metaImg":"","author":"Marco Tusa","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn32@2020_4/2021/07/13/17-22-11-281_b4795f79cab3dc8a.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn4@2020_1/2021/07/13/17-22-07-647_fdc7ce35b993fd0e.webp","https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn60@2020_5/2021/07/13/17-21-54-848_2d9b14cc3bc762a6.webp"},"publishedOrCreatedDate":1626196914578},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Installing Percona Server for MySQL on Rocky Linux 8","link":"https://www.percona.com/blog/?p=77108","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL on Rocky Linux 8\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-77132\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-300x157.png\" alt=\"MySQL on Rocky Linux 8\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />With the CentOS project <a target=\"_blank\" href=\"https://centos.org/distro-faq/\">switching its focus</a> to CentOS Stream, one of the <a target=\"_blank\" href=\"https://www.zdnet.com/article/centos-replacement-rocky-linux-8-4-arrives-and-proves-instantly-popular/\">alternatives</a> that aim to function as a downstream build (building and releasing packages after they&#8217;re released by Red Hat) is <a target=\"_blank\" href=\"https://rockylinux.org/\">Rocky Linux</a>. This how-to shows how to install <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL 8.0</a> on the Rocky Linux distribution.</p>\n<p>You can get the information on the distribution release version by checking the <code>/etc/redhat-release</code> file:</p><pre class=\"crayon-plain-tag\">[root@rocky ~]# cat /etc/redhat-release\nRocky Linux release 8.4 (Green Obsidian)</pre><p></p>\n<h2>Installing and Setting up the Percona Server for MySQL 8.0  Repository</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-repo-config/percona-release.html#red-hat-enterprise-linux-and-centos\">Downloading and Installing</a> the percona-release repository package for Red Hat Linux and derivatives:</p><pre class=\"crayon-plain-tag\">[root@rocky ~]# yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm</pre><p>This should result in:</p><pre class=\"crayon-plain-tag\">…\n\nVerifying        : percona-release-1.0-26.noarch                                                                                                                                                                                                                                   1/1\nInstalled:\n\n  percona-release-1.0-26.noarch\n\nComplete!</pre><p>Once the repository package is installed, you should set up the Percona Server for MySQL 8.0 repository by running:</p><pre class=\"crayon-plain-tag\">[root@rocky ~]#  percona-release setup ps80</pre><p>Please note that you’ll be prompted to disable the mysql module to install Percona Server packages:</p><pre class=\"crayon-plain-tag\">* Disabling all Percona Repositories\n\nOn RedHat 8 systems it is needed to disable dnf mysql module to install Percona-Server\n\nDo you want to disable it? [y/N] y\n\nDisabling dnf module...\n\nPercona Release release/noarch YUM repository    6.3 kB/s | 1.6 kB     00:00\n\nDependencies resolved.\n\n=============================================================================\n\nPackage        Architecture       Version      Repository           Size\n\n=============================================================================\nDisabling modules:\n\nmysql\n\n\n\n\nTransaction Summary\n\n==============================================================================\nComplete!\n\ndnf mysql module was disabled\n\n* Enabling the Percona Server 8.0 repository\n\n* Enabling the Percona Tools repository\n\n&#60;*&#62; All done!</pre><p></p>\n<h2>Installing and Setting up the Percona Server for MySQL 8.0 Binaries</h2>\n<p>This part is also covered in the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/LATEST/installation/yum_repo.html#installing-percona-server-from-percona-yum-repository\">Percona Server for MySQL documentation</a>.</p>\n<p>1. Installing the latest Percona Server 8.0 binaries:</p><pre class=\"crayon-plain-tag\">[root@rocky ~]# yum -y install percona-server-server</pre><p>This will also install all the required dependencies:</p><pre class=\"crayon-plain-tag\">Installed:\n\ncompat-openssl10-1:1.0.2o-3.el8.x86_64           \nlibaio-0.3.112-1.el8.x86_64           \npercona-server-client-8.0.23-14.1.el8.x86_64           \npercona-server-server-8.0.23-14.1.el8.x86_64           \npercona-server-shared-8.0.23-14.1.el8.x86_64           \npercona-server-shared-compat-8.0.23-14.1.el8.x86_64\n\nComplete!</pre><p>2. After installation is done, you can start the mysqld service:</p><pre class=\"crayon-plain-tag\">[root@rocky ~]# systemctl start mysqld</pre><p>3. Once the service is running you can check the status by running:</p><pre class=\"crayon-plain-tag\">[root@rocky ~]# systemctl status mysqld</pre><p>You should get similar output to:</p><pre class=\"crayon-plain-tag\">● mysqld.service - MySQL Server   \nLoaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)\n\n Active: active (running) since Mon 2021-06-28 10:23:22 UTC; 6s ago\n Docs: man:mysqld(8)\n\nhttp://dev.mysql.com/doc/refman/en/using-systemd.html\nProcess: 37616 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS)\nMain PID: 37698 (mysqld)\nStatus: \"Server is operational\"\nTasks: 39 (limit: 23393)\nMemory: 450.7M\nCGroup: /system.slice/mysqld.service\n└─37698 /usr/sbin/mysqld\n\nJun 28 10:23:12 rocky systemd[1]: Starting MySQL Server...\nJun 28 10:23:22 rocky systemd[1]: Started MySQL Server</pre><p>From this process, we can see that the installation on RockyLinux is the same as installing <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/LATEST/installation/yum_repo.html\">Percona Server for MySQL on CentOS/Red Hat</a>.</p>\n","descriptionType":"html","publishedDate":"Thu, 01 Jul 2021 13:32:48 +0000","feedId":11,"bgimg":"","linkMd5":"9ba979ce53fbf99b863b800a7e3fa275","bgimgJsdelivr":"","metaImg":"","author":"Hrvoje Matijakovic","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn11@2020_4/2021/07/13/17-22-10-195_036acfc60d0360ed.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn80@2020_1/2021/07/13/17-22-11-601_f87d824be697d745.webp"},"publishedOrCreatedDate":1626196914565},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MySQL on Kubernetes with GitOps","link":"https://www.percona.com/blog/?p=76815","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL on Kubernetes with GitOps\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><a target=\"_blank\" href=\"https://www.weave.works/blog/kubernetes-anti-patterns-let-s-do-gitops-not-ciops\"><span>GitOps</span></a><span> workflow was introduced by WeaveWorks as a way to implement Continuous Deployment for cloud-native applications. This technique quickly found its way into devops and developer&#8217;s hearts as it greatly simplifies the application delivery pipeline: the change in the manifests in the git repository is reflected in Kubernetes right away. With GitOps there is no need to provide access to the cluster for the developer as all the actions are executed by the Operator.</span></p>\n<p><span>This blog post is a guide on how to deploy </span><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database\"><span>Percona Distribution for MySQL</span></a><span> on Kubernetes with </span><a target=\"_blank\" href=\"https://github.com/fluxcd/flux\"><span>Flux</span></a><span> &#8211; GitOps Operator that keeps your cluster state in sync with the Git repository.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76816 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-1024x517.png\" alt=\"Percona Distribution for MySQL on Kubernetes with Flux\" width=\"900\" height=\"454\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-1024x517.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-300x151.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-200x101.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-367x185.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31.png 1030w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p><span>In a nutshell, the flow is the following:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Developer triggers the change in the GitHub repository</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Flux Operator:</span>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>detects the change</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>deploys </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\"><span>Percona Distribution for MySQL Operator</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>creates the Custom Resource, which triggers the creation of Percona XtraDB Cluster and HAProxy pods</span></li>\n</ol>\n</li>\n</ol>\n<p><span>The result is a fully working MySQL service deployed without talking to Kubernetes API directly.</span></p>\n<h2>Preparation</h2>\n<p><span>Prerequisites:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Kubernetes cluster</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Github user and account</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>For this blog post, I used the manifests from </span><a target=\"_blank\" href=\"https://github.com/spron-in/blog-data/tree/master/gitops-mysql\"><span>this</span></a><span> repository </span></li>\n</ul>\n</li>\n</ul>\n<p><span>It is a good practice to create a separate namespace for Flux:</span></p><pre class=\"crayon-plain-tag\">$ kubectl create namespace gitops</pre><p><span>Installing and managing Flux is easier with <pre class=\"crayon-plain-tag\">fluxctl</pre>. In Ubuntu, I use snap to install tools, for other operating systems please refer to the manual </span><a target=\"_blank\" href=\"https://docs.fluxcd.io/en/latest/tutorials/get-started/\"><span>here</span></a><span>.</span></p><pre class=\"crayon-plain-tag\">$ sudo snap install fluxctl --classic</pre><p><span>Install Flux operator to your Kubernetes cluster:</span></p><pre class=\"crayon-plain-tag\">$ fluxctl install --git-email=your@email.com --git-url=git@github.com:spron-in/blog-data.git --git-path=gitops-mysql --manifest-generation=true --git-branch=master --namespace=gitops | kubectl apply -f -</pre><p></p>\n<h3>GitHub Sync</h3>\n<p><span>As per configuration, Flux will monitor the changes in the </span><a target=\"_blank\" href=\"https://github.com/spron-in/blog-data/tree/master/gitops-mysql\"><span>spron-in/blog-data</span></a><span> repository continuously and sync the state. It is required to grant access to Flux to the repo.</span></p>\n<p><span>Get the public key that was generated during the installation:</span></p><pre class=\"crayon-plain-tag\">$ fluxctl identity --k8s-fwd-ns gitops</pre><p><span>Copy the key, add it as Deploy key with write access in GitHub. Go to </span><b>Settings -&#62; Deploy keys -&#62; Add deploy key:</b></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76817 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key.png\" alt=\"\" width=\"967\" height=\"562\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key.png 967w, https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key-300x174.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key-200x116.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key-367x213.png 367w\" sizes=\"(max-width: 967px) 100vw, 967px\" /></p>\n<h2>Action</h2>\n<p><span>All set. Flux reconcile loops check the state for changes every five minutes. To trigger synchronization right away run:</span></p><pre class=\"crayon-plain-tag\">$ fluxctl sync --k8s-fwd-ns gitops</pre><p><span>In my case I have two YAMLs in the repo:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><pre class=\"crayon-plain-tag\">bundle.yaml</pre> &#8211; installs the Operator, creates the Custom Resource Definitions (CRDs)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><pre class=\"crayon-plain-tag\">cr.yaml</pre> &#8211; deploys PXC and HAProxy pods</span></li>\n</ul>\n<p><span>Flux is going to deploy them both.</span></p><pre class=\"crayon-plain-tag\">$ kubectl get pods\nNAME                                               READY   STATUS    RESTARTS   AGE\ncluster1-haproxy-0                                 2/2     Running   0          26m\ncluster1-haproxy-1                                 2/2     Running   0          25m\ncluster1-pxc-0                                     1/1     Running   0          26m\ncluster1-pxc-1                                     1/1     Running   0          25m\ncluster1-pxc-2                                     1/1     Running   0          23m\npercona-xtradb-cluster-operator-79966668bd-95plv   1/1     Running   0          26m</pre><p><span>Now let&#8217;s add one more HAProxy Pod by changing <pre class=\"crayon-plain-tag\">spec.haproxy.size</pre> from 2 to 3 in <pre class=\"crayon-plain-tag\">cr.yaml</pre>. After that commit and push the changes. In a production-grade scenario, the Pull Request will go through a thorough review, in my case I push directly to the main branch.</span></p><pre class=\"crayon-plain-tag\">$ git commit cr.yaml -m 'increase haproxy size from 2 to 3'\n$ git push\nEnumerating objects: 7, done.\nCounting objects: 100% (7/7), done.\nDelta compression using up to 2 threads\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 385 bytes | 385.00 KiB/s, done.\nTotal 4 (delta 2), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/spron-in/blog-data\n   e1a27b8..d555c77  master -&#62; master</pre><p><span>Either trigger the sync with <pre class=\"crayon-plain-tag\">fluxctl sync</pre> </span><span>command or wait for approximately 5 minutes for Flux reconcile loop to detect the changes. In the logs of the Flux Operator you will see the event:</span></p><pre class=\"crayon-plain-tag\">ts=2021-06-15T12:59:08.267469963Z caller=loop.go:134 component=sync-loop event=refreshed url=ssh://git@github.com/spron-in/blog-data.git branch=master HEAD=d555c77c19ea9d1685392680186e1491905401cc\nts=2021-06-15T12:59:08.270678093Z caller=sync.go:61 component=daemon info=\"trying to sync git changes to the cluster\" old=e1a27b8a81e640d3bee9bc2e2c31f9c4189e898a new=d555c77c19ea9d1685392680186e1491905401cc\nts=2021-06-15T12:59:08.844068322Z caller=sync.go:540 method=Sync cmd=apply args= count=9\nts=2021-06-15T12:59:09.097835721Z caller=sync.go:606 method=Sync cmd=\"kubectl apply -f -\" took=253.684342ms err=null output=\"serviceaccount/percona-xtradb-cluster-operator unchanged\\nrole.rbac.authorization.k8s.io/percona-xtradb-cluster-operator unchanged\\ncustomresourcedefinition.apiextensions.k8s.io/perconaxtradbbackups.pxc.percona.com configured\\ncustomresourcedefinition.apiextensions.k8s.io/perconaxtradbclusterbackups.pxc.percona.com unchanged\\ncustomresourcedefinition.apiextensions.k8s.io/perconaxtradbclusterrestores.pxc.percona.com unchanged\\ncustomresourcedefinition.apiextensions.k8s.io/perconaxtradbclusters.pxc.percona.com unchanged\\nrolebinding.rbac.authorization.k8s.io/service-account-percona-xtradb-cluster-operator unchanged\\ndeployment.apps/percona-xtradb-cluster-operator unchanged\\nperconaxtradbcluster.pxc.percona.com/cluster1 configured\"\nts=2021-06-15T12:59:09.099258988Z caller=daemon.go:701 component=daemon event=\"Sync: d555c77, default:perconaxtradbcluster/cluster1\" logupstream=false\nts=2021-06-15T12:59:11.387525662Z caller=loop.go:236 component=sync-loop state=\"tag flux\" old=e1a27b8a81e640d3bee9bc2e2c31f9c4189e898a new=d555c77c19ea9d1685392680186e1491905401cc\nts=2021-06-15T12:59:12.122386802Z caller=loop.go:134 component=sync-loop event=refreshed url=ssh://git@github.com/spron-in/blog-data.git branch=master HEAD=d555c77c19ea9d1685392680186e1491905401cc</pre><p><span>The log indicates that the main CR was configured: <pre class=\"crayon-plain-tag\">perconaxtradbcluster.pxc.percona.com/cluster1 configured</pre> </span></p>\n<p><span>Now we have three HAProxy Pods:</span></p><pre class=\"crayon-plain-tag\">$ kubectl get pods\nNAME                                               READY   STATUS    RESTARTS   AGE\ncluster1-haproxy-0                                 2/2     Running   1          50m\ncluster1-haproxy-1                                 2/2     Running   0          48m\ncluster1-haproxy-2                                 2/2     Running   0          4m45s</pre><p><span>It is important to note that GitOps maintains the sync between Kubernetes and GitHub. It means that if the user manually changes the object on Kubernetes, Flux, or any other GitOps Operator will revert the changes and sync them with GitHub.</span></p>\n<p><span>GitOps also comes in handy when users want to take the backup or perform the restoration. To do that the user just creates YAML manifests in the GitHub repo and Flux creates corresponding Kubernetes objects. The Database Operator does the rest.</span></p>\n<h3>Conclusion</h3>\n<p><span>GitOps is a simple approach to deploy and manage applications on Kubernetes:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Change Management is provided by git version-control and code reviews</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Direct access to Kubernetes API is limited which increases security</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Infrastructure-as-a-Code is here, there is no need to integrate Terraform, Ansible, or any other tool</span></li>\n</ul>\n<p><span>All </span><a target=\"_blank\" href=\"https://www.percona.com/software/percona-kubernetes-operators\"><span>Percona Operators</span></a><span> can be deployed and managed with GitOps. As a result, you will get production-grade MySQL, MongoDB, or PostgreSQL cluster which just works.</span></p>\n","descriptionType":"html","publishedDate":"Wed, 23 Jun 2021 12:13:04 +0000","feedId":11,"bgimg":"","linkMd5":"41274bddba64661f4cc18887e083ce09","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn44@2020_5/2021/07/13/17-22-09-193_b29b187aee2664ed.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-1024x517.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn8@2020_4/2021/07/13/17-22-05-821_1f8b36d6894c0213.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn91@2020_6/2021/07/13/17-22-08-715_575957c8aa084c95.webp"},"publishedOrCreatedDate":1626196914584},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Percona XtraBackup for Windows","link":"https://www.percona.com/blog/?p=76919","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona XtraBackup for Windows\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright wp-image-76998 size-medium\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-300x157.png\" alt=\"Percona XtraBackup for Windows\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Don&#8217;t Try This at Home!</h2>\n<p><strong>Disclaimer:</strong> The procedure described in this blog post is not officially supported by <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtrabackup\">Percona XtraBackup</a>. Use it under your responsibility. I tested and used it successfully, but your mileage may vary.</p>\n<p><strong>Note from the author:</strong> <em>Wikipedia defines clickbait as text (or a link) that is designed to attract attention and to entice users to read that online content, with a defining characteristic of being deceptive. Maybe the headline of this post is a bit deceptive, as there is no Percona XtraBackup for Windows, but I hope you will not feel deceived after reading this blog post, I just felt that it was funny to use a clickbait-style while writing it.</em></p>\n<h2>He Couldn&#8217;t Believe it When He Read That Post!</h2>\n<p>Pep had to migrate a client database from Windows to Linux and was considering all the available options to move the database with the minimal downtime possible. He found this blog post, <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/03/20/running-percona-xtrabackup-windows-docker/\" target=\"_blank\" rel=\"noopener\">Running Percona XtraBackup on Windows … in Docker</a> from Vadim Tkachenko that describes a procedure to backup a Windows database using Percona XtraBackup and Docker.</p>\n<p>There is also the post <a target=\"_blank\" href=\"http://patg.net/mysql,windows/10,wsl,backups/2017/09/03/xtrabackup-wsl/\" target=\"_blank\" rel=\"noopener\">Running XtraBackup on Windows using WSL</a>, which describes a similar process using Windows Services for Linux.</p>\n<p>Out of an old version, compiled using Cygwin, and an inactive effort to build a Windows version <a target=\"_blank\" href=\"https://www.percona.com/blog/2011/04/21/percona-xtrabackup-1-6-for-windows-try-me-edition/\" target=\"_blank\" rel=\"noopener\">Percona XtraBackup 1.6 for Windows “try me” edition</a>, the only way to use XtraBackup to copy a database running on Windows involved some sort of virtualization. Was it possible to use Percona XtraBackup without involving virtualization?</p>\n<h2>Datafiles Then And Now: How They&#8217;ve Changed!</h2>\n<p>To perform a backup, XtraBackup does a lot of different things.</p>\n<p>It connects to the database and retrieves information about it, and executes commands that are required during the process.</p>\n<p>Then it copies all the datafiles and InnoDB redo logs. As the contents of the datafiles change during the backup, the copy is inconsistent. This is why the contents of redo logs are copied also. They are used to turn the inconsistent backup copy into a consistent one during the &#8220;prepare&#8221; stage.</p>\n<p>A detailed description of this process is beyond the scope of this post, you just need to know that XtraBackup needs logical access to the database and physical access to the database files. Feel free to look at the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtrabackup/LATEST/how_xtrabackup_works.html\">documentation</a> or watch my recent Percona Live talks about Percona XtraBackup if you need more information:</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/resources/videos/dr-xtrabackup-or-how-i-learned-stop-worrying-and-love-backups-i\" target=\"_blank\" rel=\"noopener\">Dr. XtraBackup or: How I Learned to Stop Worrying and Love Backups I</a><br />\n<a target=\"_blank\" href=\"https://www.percona.com/resources/videos/dr-xtrabackup-or-how-i-learned-stop-worrying-and-love-backups-ii\" target=\"_blank\" rel=\"noopener\">Dr. XtraBackup or: How I Learned to Stop Worrying and Love Backups II</a></p>\n<h2>This DBA Wanted to Make a Backup and Did The Most Incredible Thing!</h2>\n<p>Could we execute XtraBackup from a remote Linux box to perform a backup of a Windows database? Regarding the database connection, you don&#8217;t need to connect locally to the database to perform a backup, it can be done remotely.</p>\n<p>Could we access the database files remotely? The answer is yes, of course. You just need to create network shares for the folders that contain the database files. And then mount them on Linux to execute the backup there.</p>\n<h2>This cute network share will melt your heart!</h2>\n<p>Usually, you need to share only the &#8220;datadir&#8221; but, if the database you want to backup has the redo log files located in a different directory, then you&#8217;ll need to share that directory also.</p>\n<p>If binary logging is enabled, XtraBackup also needs access to the directory where binary logs are located. So, in the best case, you need to create only one network share, otherwise, you will need to share every directory that contains database files.</p>\n<p>My recommendation is that you create the Windows shares with read-only permissions, to avoid writing to them by mistake.</p>\n<p>Once you create the network shares, you need to mount them on the Linux box that will effectively run the backup, for example:</p><pre class=\"crayon-plain-tag\">mount -t cifs -o vers=3.11,cache=none,actimeo=0,ro //&#60;server&#62;/&#60;folder /&#60;mount_point&#62;</pre><p>The filesystem type is <strong>CIFS</strong>. Use the highest version supported by your server. You should see something like this if you run the mount command without parameters:</p><pre class=\"crayon-plain-tag\">//&#60;server&#62;/datadir on /winbox/datadir type cifs (ro,relatime,vers=3,cache=none,username=&#60;username&#62;,domain=&#60;domain&#62;,uid=0,noforceuid,gid=0,noforcegid,addr=&#60;ip_address&#62;,file_mode=0755,dir_mode=0755,soft,nounix,serverino,mapposix,rsize=8388608,wsize=1048576,echo_interval=60,actimeo=0)</pre><p>Check the mount options for the credential file and other parameters. Do not include the credentials in the mount command!</p>\n<h2>This is Why Configuration Parameters Exist!</h2>\n<p>Now we have access to the database, using database credentials. And we have access to the files, using the shared folders. But we need to tell XtraBackup how to access them.</p>\n<p>To perform a backup you need a database user with the following privileges:</p>\n<ul>\n<li><strong>RELOAD</strong> and <strong>LOCK TABLES</strong> (unless the &#8211;no-lock option is specified) to be able to execute &#8220;FLUSH TABLES WITH READ LOCK&#8221; and &#8220;FLUSH ENGINE LOGS&#8221; before starting to copy the files.</li>\n<li><strong> LOCK TABLES FOR BACKUP</strong> and <strong>LOCK BINLOG FOR BACKUP</strong> are privileges required to use backup locks.</li>\n<li><strong>REPLICATION CLIENT</strong> to obtain the binary log position.</li>\n<li><strong>CREATE TABLESPACE</strong> to import tables.</li>\n<li><strong>PROCESS</strong> to run <strong>SHOW ENGINE INNODB STATUS</strong> and to see all the threads running on the server.</li>\n<li><strong>SUPER</strong> to start/stop the replica threads in a replication environment (optional), and create, delete and select privileges on the PERCONA_SCHEMA (if it exists) to store incremental and history data.</li>\n</ul>\n<p>Usually, we tend to grant all privileges to the user that will connect to the database to run the backup.</p>\n<p>You can tell XtraBackup how to connect to the database using these parameters:</p><pre class=\"crayon-plain-tag\">--user=&#60;database_user&#62;\n--password=&#60;database_password&#62;\n--host=&#60;ip_address or hostname&#62;\n--datadir=&#60;local mount point for remote share&#62;\n--log-bin-index=&#60;location of log-bin index file&#62;\n--log-bin=&#60;local mount point for remote share&#62;</pre><p>For example:</p><pre class=\"crayon-plain-tag\">xtrabackup --user=root --password=&#60;password&#62; --host=192.168.0.1 --backup --datadir=/mnt/data --log-bin-index=/mnt/data/binlog.index --log-bin=/mnt/data --target-dir=&#60;dest_dir&#62; --innodb_log_file_size=&#60;log_file_size&#62; --strict</pre><p>Remember to always use the <em>&#8211;strict</em> option, this will make xtrabackup fail if you make a typo and a parameter is not specified properly. And if there is any relevant InnoDB parameter that has been modified, then you can add it also as a parameter to xtrabackup (<em>&#8211;innodb_log_file_size</em> in the example)</p>\n<h2>He Thought It Was Over, but It Was Not!</h2>\n<p>Once we have the backup stored in the Linux server, we can prepare it following the standard procedure:</p><pre class=\"crayon-plain-tag\">xtrabackup --prepare --target-dir=&#60;dest-dir&#62;</pre><p>But now that we have a backup prepared and stored in Linux, is it possible to start that database on Linux? Yes! It is possible!</p>\n<p>You only need to make sure that the database starts with lower_case_table_names enabled as the database comes from a case-insensitive filesystem.</p>\n<p>And, if you enable binary logging in the new server, you may need to manually edit the binlog index file to replace the \\ by a / as this is the directory delimiter on Linux.</p>\n<p>I hope you will be able to use this procedure successfully and, as always, test restoring your backups frequently!</p>\n","descriptionType":"html","publishedDate":"Fri, 25 Jun 2021 12:48:21 +0000","feedId":11,"bgimg":"","linkMd5":"f6f45ae8f099380d94dafe7f3ce05c64","bgimgJsdelivr":"","metaImg":"","author":"Pep Pla","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn11@2020_6/2021/07/13/17-22-18-436_d14e7b15feed9c3e.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn3@2020_3/2021/07/13/17-22-08-980_d698798f84e9f24c.webp"},"publishedOrCreatedDate":1626196914574},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Percona Monitoring and Management – MySQL Semi-Sync Summary Dashboard","link":"https://www.percona.com/blog/?p=77091","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Monitoring and Management - MySQL Semi-Sync Summary Dashboard\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77128\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-300x168.png\" alt=\"Percona Monitoring and Management - MySQL Semi-Sync Summary Dashboard\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Some of you may use MySQL&#8217;s asynchronous replication feature called </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/en/replication-semisync.html\"><span>Semisynchronous Replication</span></a><span> (aka semi-sync), and now with the MySQL Semi-Sync Summary Dashboard + <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM), you can see the most important metrics! Refer to the Install &#38; Usage steps for deployment details (note you need Replication Set defined!).</span></p>\n<h2>What is Semisynchronous Replication</h2>\n<p><span>When enabled, Semisynchronous Replication instructs the Primary to wait until at least one replica has received and logged the event to the replica&#8217;s local relay log before completing the COMMIT on a transaction. This provides a higher level of data integrity because now it is known that the data exists in two places. This feature ensures a balance between data integrity (number of replicas acknowledging receipt of a transaction) vs the </span><b>speed of commits, which will be slower since they need to wait on replica acknowledgment</b><span>. Also, keep in mind that semi-sync does not wait for COMMIT on the replica; it only waits until the transaction is queued in the relay log. The actual execution of the transaction from the relay log is still asynchronous.</span></p>\n<h2>Dashboard Layout</h2>\n<p><span>Now that we know we can improve data integrity but pay a penalty on writes, I want to display the following information:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Replica semi-sync status &#8211; enabled or not</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Waits by type, on Network or on Transactions</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How much total time was spent waiting on Transactions &#8211; what&#8217;s my penalty due to writes slowing down</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How much average time was spent waiting per transaction</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Commit acknowledgments &#8211; what&#8217;s my replication throughput</span></li>\n</ol>\n<h3>Replica Status</h3>\n<p><span>This lists the states that each replica has been in, whether the Replica semi-sync was enabled or disabled:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77094 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-1024x147.png\" alt=\"Percona Monitoring and Management\" width=\"900\" height=\"129\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-1024x147.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-300x43.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-200x29.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-1536x220.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-367x53.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1.png 1586w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h3>Waits by Net &#38; TX</h3>\n<p><span>How many waits on the Network and on Transactions. Since the Primary is only waiting on one successful acknowledgment even though there could be multiple semi-sync replicas (the fastest one wins), your count of TX waits should be the same as TX commits on the Primary, but the wait on Network can be much higher.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77093 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2.png\" alt=\"Waits by Net &#38; TX\" width=\"787\" height=\"299\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2.png 787w, https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2-300x114.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2-200x76.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2-367x139.png 367w\" sizes=\"(max-width: 787px) 100vw, 787px\" /></p>\n<h3>Time Spent Waiting on Transactions</h3>\n<p><span>This is the contribution to query latency that semi-sync incurs on the Primary related to waits on transactions.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77096 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image5.png\" alt=\"Time spent waiting on Transactions\" width=\"790\" height=\"303\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image5.png 790w, https://www.percona.com/blog/wp-content/uploads/2021/06/image5-300x115.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/image5-200x77.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/image5-367x141.png 367w\" sizes=\"(max-width: 790px) 100vw, 790px\" /></p>\n<h3>Average Wait Time per Transaction</h3>\n<p><span>This is the overhead of waiting on a single transaction acknowledgment.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77092 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2.png\" alt=\"Average wait time per transaction\" width=\"787\" height=\"296\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2.png 787w, https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2-300x113.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2-200x75.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2-367x138.png 367w\" sizes=\"(max-width: 787px) 100vw, 787px\" /></p>\n<h3>Commit Acknowledgments</h3>\n<p><span>The semi-synchronous replication feature considers the possibility that Replicas may be unavailable, and is controlled by the </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/en/replication-options-source.html#sysvar_rpl_semi_sync_master_timeout\"><span>rpl_semi_sync_master_timeout</span></a><span>.  This controls how long the Primary will wait on a commit for acknowledgment from a Replica before timing out and reverting to asynchronous replication. Was the commit acknowledged by semi-sync (Yes) or did the Primary lose all semi-sync replicas and did not acknowledge the commit (No) aka running in asynchronous mode.  You should be seeing Acknowledged only when things are working smoothly.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77097 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image6.png\" alt=\"Commit Acknowledgements\" width=\"786\" height=\"305\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image6.png 786w, https://www.percona.com/blog/wp-content/uploads/2021/06/image6-300x116.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/image6-200x78.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/image6-367x142.png 367w\" sizes=\"(max-width: 786px) 100vw, 786px\" /></p>\n<h2>Installation &#38; Usage</h2>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Download the dashboard definition in JSON from </span><a target=\"_blank\" href=\"https://grafana.com/grafana/dashboards/14636/\"><span>https://grafana.com/grafana/dashboards/14636/</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Import into PMM Server (tested on 2.18 but should work on older 2.x versions)</span></li>\n</ol>\n<p><span>I built the dashboard to leverage the Replication Set (&#8211;replication-set) variable (which can be set to any string you want), so you will need this enabled for all servers that you want to view statistics, for example, your </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/client/mysql.html\"><span>pmm-admin add mysql statement</span></a><span> should look like:</span></p><pre class=\"crayon-plain-tag\"><span style=\"font-weight: 400;\">pmm-admin add mysql … --replication-set=semi-sync</span></pre><p><span>You can check to see whether the </span><span>Replication Set</span><span> variable is defined by referencing the PMM Inventory dashboard, in the last column called Other Details:</span></p>\n<p><img loading=\"lazy\" class=\"size-medium wp-image-77095 aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image4-1.png\" alt=\"\" width=\"172\" height=\"77\" /></p>\n<p><span>When you have the dashboard loaded, select your Replication Set from the drop-down:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77098 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image7.png\" alt=\"\" width=\"529\" height=\"150\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/image7.png 529w, https://www.percona.com/blog/wp-content/uploads/2021/06/image7-300x85.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/image7-200x57.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/image7-367x104.png 367w\" sizes=\"(max-width: 529px) 100vw, 529px\" /></p>\n<h2>New to Percona Monitoring and Management (PMM)?</h2>\n<p>Check out the <a target=\"_blank\" href=\"https://www.percona.com/software/pmm/quickstart\">PMM Quickstart</a> guide, which helps you deploy docker for <a target=\"_blank\" href=\"https://hub.docker.com/r/percona/pmm-server\">PMM Server</a>, and <a target=\"_blank\" href=\"https://www.percona.com/downloads/pmm2/\">pmm2-client</a> package from the Percona Repositories, to have you up and <strong>monitoring in minutes</strong>!</p>\n<p><span>I hope you find this dashboard useful! Feel free to let me know if there are missing fields or other features you&#8217;d like to see included!</span></p>\n","descriptionType":"html","publishedDate":"Thu, 01 Jul 2021 12:15:21 +0000","feedId":11,"bgimg":"","linkMd5":"2c3200cea35dd4d441cb3b1a51abc531","bgimgJsdelivr":"","metaImg":"","author":"Michael Coburn","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn68@2020_2/2021/07/13/17-22-10-571_d497f421be5428c6.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn8@2020_3/2021/07/13/17-22-11-325_cb3a671bda874208.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-1024x147.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn52@2020_4/2021/07/13/17-22-06-234_0981ea59f51e821c.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn92@2020_2/2021/07/13/17-22-17-689_00f5d0cb262b3f57.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image5.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn72@2020_3/2021/07/13/17-22-04-090_0511d79263a41116.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn12@2020_4/2021/07/13/17-22-11-008_96776a83f5240b1e.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image6.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn88@2020_3/2021/07/13/17-22-10-715_3365f471cde1c493.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image4-1.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn63@2020_4/2021/07/13/17-22-09-439_fb4b644f056af65f.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/image7.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn64@2020_1/2021/07/13/17-22-06-639_e041fb9784bee107.webp"},"publishedOrCreatedDate":1626196914587},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MongoDB 5.0 Is Coming in Hot! What Do Database Experts Across the Community Think?","link":"https://www.percona.com/blog/?p=77170","description":"<img width=\"200\" height=\"113\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-200x113.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MongoDB 5.0 Percona\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-200x113.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-300x169.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-1024x576.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-367x206.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona.jpg 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><strong><img loading=\"lazy\" class=\"alignright size-medium wp-image-77175\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-300x169.jpg\" alt=\"MongoDB 5.0 Percona\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-300x169.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-1024x576.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-200x113.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-367x206.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona.jpg 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />If you love using MongoDB databases, you’ll want to tune in to this live-stream event ‘Percona and Friends React to MongoDB live’ at 11:00 AM EDT on July 15.</strong></p>\n<p>Watch or listen as industry experts from Percona, Southbank Software, and Qarbine respond to MongoDB’s conference announcements. The team will consider:</p>\n<ul>\n<li aria-level=\"1\">New features and other announcements</li>\n<li aria-level=\"1\">The importance of new MongoDB 5.0 features for applications</li>\n<li aria-level=\"1\">What this might mean for the Community Edition</li>\n<li aria-level=\"1\">The impact MongoDB 5.0 will have on users and the Community</li>\n</ul>\n<p><strong>This is a live event.</strong> So please bring your questions or concerns, and raise your voice to give your thoughts on the latest product news.</p>\n<p>Or, if you’re feeling shy, you could just listen in!</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://learn.percona.com/percona-and-friends-react-mongodb-live\" rel=\"noopener\">Register Today</a></p>\n<h2>Our Community-based panel has a wide variety of expertise and experience.</h2>\n<h2>Akira Kurogane</h2>\n<p><strong>MongoDB Product Owner for Percona’s Enterprise MongoDB product additions and tools</strong></p>\n<p><span>Akira is an expert in MongoDB symptom-to-code defect analysis, diagnostics, and performance. He has helped countless distributed database clients overcome obstacles and adjust to the changing landscape. Since getting his start as a search engine and RDBMS-based developer, Akira describes himself as, “</span><i><span>All MongoDB, all the time</span></i><span>.”</span></p>\n<h2>Kimberly Wilkins</h2>\n<p><strong>MongoDB Technical Lead with 20+ years of experience managing and architecting databases</strong></p>\n<p><span>Kimberly has been a DBA, a Principal Engineer, an architect, and has built out and managed expert database teams across multiple data store offerings over her database years. She has worked with MongoDB customers of all sizes in many industries and helped them architect, deploy, troubleshoot, and tune their databases to handle heavy workloads and keep their applications running. She specializes in MongoDB sharding to help customers scale and thrive as their businesses grow in today’s big data world. Kimberly enjoys sharing her experiences at technical conferences in the US and abroad. Why? Because after all, “</span><i><span>there is no perfect shard key</span></i><span>.”</span></p>\n<h2>Guy Harrison</h2>\n<p><b>CTO, ProvenDB and Southbank Software </b></p>\n<p><b>Author, MongoDB Performance Tuning</b></p>\n<p><span>Not only is Guy a founder and CTO, he is also an IT professional with experience in a range of disciplines, technologies and practices but probably best known both for his longstanding involvement in relational databases (Oracle and MySQL) and for emerging database technologies such as MongoDB and Blockchain.  Guy is also an expert on performance tuning and has written several books on that subject </span><span>including “MongoDB Performance Tuning”, “Next Generation Databases” and “MySQL Stored Procedure Programming”.  He also writes the “MongoDB Matters” column for Database Trends and Applications </span></p>\n<h2>Bill Reynolds</h2>\n<p><b>CTO/Co-founder of Qarbine specializing in BI solutions for enterprise investments in NoSQL databases like MongoDB</b></p>\n<p><span>Bill has led product teams who have integrated with 23 different database APIs across many favors of NoSQL such as MongoDB to pure object oriented, to legacy SQL.</span></p>\n<p><span>His companies have licensed database and reporting software to most of the Fortune 500 and many others worldwide. </span><span>For over 3 years he has been applying that experience developing a native MongoDB detailed reporting and analysis suite.</span></p>\n<h2>Join Percona and Friends as they react to MongoDB.live!</h2>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://learn.percona.com/percona-and-friends-react-mongodb-live\" rel=\"noopener\">Register For Free</a></p>\n","descriptionType":"html","publishedDate":"Mon, 05 Jul 2021 14:37:31 +0000","feedId":11,"bgimg":"","linkMd5":"546cf3627d4d586dfdef81692a954802","bgimgJsdelivr":"","metaImg":"","author":"Kimberly Wilkins","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-200x113.jpg":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn71@2020_3/2021/07/13/17-22-10-556_7d3a2e717cf8f303.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-300x169.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn63@2020_1/2021/07/13/17-22-10-612_3e12e9163d017270.webp"},"publishedOrCreatedDate":1626196914567},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Complex Archival with Percona Toolkit’s pt-archiver","link":"https://www.percona.com/blog/?p=77071","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Complex Archival with Percona Toolkit pt-archiver\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright size-medium wp-image-77085\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-300x157.png\" alt=\"Complex Archival with Percona Toolkit pt-archiver\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />The Problem</h2>\n<p><span>I recently worked on a customer engagement where the customer needed to archive a high amount of rows from different tables into another server (in this example for simplicity I am just archiving the results into a file). </span></p>\n<p><span>As explained in </span><span>this other blog post, &#8220;<a target=\"_blank\" href=\"https://www.percona.com/blog/2013/08/12/want-to-archive-tables-use-pt-archiver/\">Want to archive tables? Use Percona Toolkit’s pt-archiver</a>&#8220;, </span><span>you can use pt-archiver to purge/archive rows from a table that match any “WHERE” condition, but this case was not that easy as the archive/delete condition was complex and involved joining many tables…</span></p>\n<p><span>The archive conditions involved four tables with the following query and the following table schema. In the example, there are no foreign keys, but this method can be used also with foreign keys by reordering the table archive/purge.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77076 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver.png\" alt=\"Percona Toolkit's pt-archiver\" width=\"946\" height=\"521\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver.png 946w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver-300x165.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver-200x110.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver-367x202.png 367w\" sizes=\"(max-width: 946px) 100vw, 946px\" /></p>\n<p><span>And the delete condition is the following:</span></p><pre class=\"crayon-plain-tag\">DELETE table1, table2, table3, table4\nFROM table1\nINNER JOIN table3 ON table1.id = table3.table1_id\nINNER JOIN table2 ON table1.table2_id = table2.id\nINNER JOIN table4 ON (table3.table4_id = table4.id AND table4.cond = 'Value1')\nWHERE table1.created_at &#60; '2020-01-01 00:00:00';</pre><p><span>It can be seen that for a row to be archived, it depends on the existence and condition of other rows in other tables. Trying to purge/archive one table at a time is not a possible solution, because once a row has been purged/archived, it is not possible to find the other referenced rows that need to be purged/archived together with that one.</span></p>\n<p><span>So, how do we proceed in this case?</span></p>\n<h2>The Solution</h2>\n<p><span>For tackling the above problem, the best is to set up a transient table containing all the pairs of rows to be purged/archived, i.e:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from tmp_ids_to_remove ; \n+-----------+-----------+-----------+-----------+\n| table1_id | table2_id | table3_id | table4_id |\n+-----------+-----------+-----------+-----------+\n|         1 |         1 |         1 |         1 |\n|         1 |         1 |         2 |         1 |\n|         1 |         1 |         3 |         1 |\n|         3 |         3 |         5 |         3 |\n+-----------+-----------+-----------+-----------+</pre><p><span>For the above example, the following rows from each table have to be purged:</span></p>\n<ul>\n<li><span>Table1: ids = {1,3}</span></li>\n<li><span>Table2: ids = {1,3}</span></li>\n<li><span>Table3: ids = {1,2,3,5}</span></li>\n<li><span>Table4: ids = {1,3}</span></li>\n</ul>\n<p><span>Then the </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-toolkit/3.0/pt-archiver.html\"><span>pt-archiver</span></a><span> from <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-toolkit\">Percona Toolkit</a> can be used to purge/archive one table at a time, checking that the row to be purged does exist on “tmp_ids_to_remove”. The pt-archiver expression would be similar to:</span></p><pre class=\"crayon-plain-tag\">--where 'EXISTS(SELECT tableX_id FROM percona.tmp_ids_to_remove purge_t WHERE id=purge_t.tableX_id)'</pre><p><span>And the query for populating table should be something similar to <em>INSERT INTO </em></span><em><span>tmp_ids_to_remove </span></em><span><em>( SELECT &#60;query with the delete condition&#62;)</em> i.e:</span></p><pre class=\"crayon-plain-tag\">INSERT INTO percona.tmp_ids_to_remove ( SELECT table1.id, table2.id, table3.id, table4.id\nFROM table1\nINNER JOIN table3 ON table1.id = table3.table1_id\nINNER JOIN table2 ON table1.table2_id = table2.id\nINNER JOIN table4 ON (table3.table4_id = table4.id AND table4.cond = 'Value1')\nWHERE table1.created_at &#60; '2020-01-01 00:00:00');</pre><p><span>Things to consider:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><span>Instead of creating one “big” table containing all the rows, multiple smaller tables can be created. For simplicity and easier data view, one big table was used in this example.</span></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><span>The above insert might lock a lot of rows which can impact server performance depending on transaction size and current server load. Either run the query out of business hours or if not possible and to keep referential integrity, SELECT …. INTO OUTFILE and then load into another table; the select part would be faster and non-locking.</span></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The table with the </span><span>tmp_ids_to_remove</span><span><span> should have an index for each column since pt-archiver will need the index to fast check the row to be removed</span></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>If the amount of rows you need to purge/archive is in the various GB, you should adjust the “WHERE” condition to only process a few million rows at a time and process the rows in batches. Trying to execute a huge transaction (by either populating a big enough </span><span>tmp_ids_to_remove </span><span>or purge/archive all rows at once) will be performance detrimental.  </span></li>\n</ul>\n<p><span>Note: The above solution aims for data consistency at the cost of performance. If for whatever reason the purge/archive gets stopped halfway through, you will still know which rows ids are meant for purging since they are kept on </span><span>tmp_ids_to_remove </span><span>table.</span></p>\n<p><span>On my GitHub repository, you can find an </span><a target=\"_blank\" href=\"https://raw.githubusercontent.com/ctutte/blog_complex_archive/master/setup.sql\"><span>example scenario file</span></a><span> and an </span><a target=\"_blank\" href=\"https://github.com/ctutte/blog_complex_archive/blob/master/archiver_script.sh\"><span>example script</span></a><span> for doing a test archive. The script is POC (proof of concept) and you should execute on a test env:</span></p>\n<p><span>Instructions for usage are:</span></p>\n<ul>\n<li><span>Download  the scripts:</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">curl https://raw.githubusercontent.com/ctutte/blog_complex_archive/master/setup.sql &#62; setup.sql\ncurl https://github.com/ctutte/blog_complex_archive/blob/master/archiver_script.sh &#62; archiver_script.sh</pre><p></p>\n<ul>\n<li><span> Create the test env:</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">mysql -u root -p &#60; setup.sql</pre><p></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Configure the script:</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">chmod a+x archiver_script.sh</pre><p></p>\n<ul>\n<li><span><span> On archiver_script.sh configure various parameters at the top (USER/PASS/SOURCE_DSN)</span></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Finally, execute the script:</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">./archiver_script.sh</pre><p><span>The archived rows are deleted from the DB, and the archived rows are written to </span><span>/tmp/table_name.out</span><span> file.</span></p>\n<h3>Conclusion</h3>\n<p><span>Trying to purge/archive rows for complex conditions or when trying to keep data consistency can be hard. The above solution will generate an intermediate table and be based on pt-archiver for purging/archiving rows in a tidy way and can be automated to be able to purge/archive millions of rows that otherwise would not be possible to do manually.</span></p>\n<p><span><strong>Note</strong>: This example is from a real case scenario but was obfuscated and simplified. It might still seem “unnecessarily complex” but it was kept like that so that the proposed solution makes sense. </span></p>\n<p><span>Under similar scenarios, a much easier/faster solution might be suitable, but other times due to business logic or other restrictions, a more complex solution must be implemented.  </span></p>\n","descriptionType":"html","publishedDate":"Wed, 30 Jun 2021 17:19:38 +0000","feedId":11,"bgimg":"","linkMd5":"e34a79158454ed17846ac7be9c87726b","bgimgJsdelivr":"","metaImg":"","author":"Carlos Tutte","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn83@2020_6/2021/07/13/17-22-09-630_b409e890035a0615.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn32@2020_1/2021/07/13/17-22-08-247_e46d8e34698f3686.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn76@2020_3/2021/07/13/17-22-07-377_a4192c56825a4b8b.webp"},"publishedOrCreatedDate":1626196914567},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"ProxySQL-Admin 2.x: Encryption of Credential Information","link":"https://www.percona.com/blog/?p=72932","description":"<img width=\"200\" height=\"107\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-200x107.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"ProxySQL-Admin 2.x Encryption of Credential Information\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-200x107.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-300x160.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-1024x546.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-367x196.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76787\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-300x160.png\" alt=\"ProxySQL-Admin 2.x Encryption of Credential Information\" width=\"300\" height=\"160\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-300x160.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-1024x546.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-200x107.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-367x196.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Starting with the release of proxysql-admin 2.0.15,  the <code>proxysql-admin</code> 2.x series can now encrypt the credentials needed to access proxysql and cluster nodes. This only applies to the <code>proxysql-admin</code> configuration, this does <strong>not</strong> change the ProxySQL config, so those credentials are still unencrypted.</p>\n<p>The <strong>credentials file</strong> is the unencrypted file containing the usernames, passwords, hostnames, and ports needed to connect to ProxySQL and PXC (Percona XtraDB Cluster).</p>\n<p>The <code>proxysql-login-file</code> tool is used to encrypt the <strong>credentials file</strong>. This encrypted file is known as a <strong>login-file</strong>. This login-file can then be used by the <code>proxysql-admin</code> and <code>proxysql-status</code> scripts.</p>\n<p><strong>Note</strong>: This feature requires OpenSSL v1.1.1 and above (with the exception of Ubuntu 16.04). Please see the <strong>supported platforms</strong> topic below.</p>\n<h3>Configuration Precedence</h3>\n<ol>\n<li>command-line options</li>\n<li>the encrypted login-file options (if the login-file is used)</li>\n<li>the unencrypted proxysql-admin configuration file values</li>\n</ol>\n<h3>Example Usage</h3>\n<p></p><pre class=\"crayon-plain-tag\"># create the credentials file\n$ echo \"monitor.user=monitor\" &#62; credentials.cnf\n$ echo \"monitor.password=password\" &#62;&#62; credentials.cnf\n\n# Choose a password\n$ passwd=\"secret\"\n\n# Method (1) : Encrypt this data with --password\n$ proxysql-login-file --in credentials.cnf --out login-file.cnf --password=${passwd}\n\n# Method (2a) : Encrypt the data with --password-file\n# Sending the password via the command-line is insecure,\n# it's better to use --password-file so that the\n# password doesn't show up in the command-line\n$ proxysql-login-file --in credentials.cnf --out login-file.cnf \\\n--password-file=&#60;(echo \"${passwd}\")\n\n# Method (2b) : Running the command using sudo will not work with\n# bash's process substition. In this case, sending the\n# password via stdin is another option.\n$ sudo echo \"${passwd}\" | proxysql-login-file --in credentials.cnf --out login-file.cnf \\\n--password-file=/dev/stdin\n\n# Method (3) : The script will prompt for the password\n# if no password is provided via the command-line options.\n$ proxysql-login-file --in credentials.cnf --out login-file.cnf\nEnter the password:\n\n# Remove the unencrypted credentials file\n$ rm credentials.cnf\n\n# Call the proxysql-admin script with the login-file\n$ proxysql-admin --enable --login-file=login-file.cnf \\\n--login-password-file=&#60;(echo \"${passwd}\")\n\nThis script will assist with configuring ProxySQL for use with\nPercona XtraDB Cluster (currently only PXC in combination\nwith ProxySQL is supported)\n\n...\n\n# Call proxysql-status with the login-file\n$ proxysql-status --login-file=login-file.cnf \\\n--login-password-file=&#60;(echo \"${passwd}\")\n\n............ DUMPING MAIN DATABASE ............\n***** DUMPING global_variables *****\n+--------------------------------------------------------------+-----------------------------+\n| variable_name                                                | variable_value              |\n+--------------------------------------------------------------+-----------------------------+\n| mysql-default_charset                                        | utf8                        |\n|\n...</pre><p></p>\n<h3></h3>\n<h3>Credentials File Format</h3>\n<p></p><pre class=\"crayon-plain-tag\"># --------------------------------\n# This file is constructed as a set of \"name=value\" pairs.\n# Notes:\n# (1) Comment lines start with '#' and must be on separate lines\n# (2) the name part\n# - The only acceptable names are shown below in this example.\n# Other values will be ignored.\n# (3) The value part:\n# - This does NOT use quotes, so any quote character will be part of the value\n# - The entire line will be used (be careful with spaces)\n#\n# If a value is not specified here, than the default value from the\n# configuration file will be used.\n# --------------------------------\n\n# --------------------------------\n# proxysql admin interface credentials.\n# --------------------------------\nproxysql.user=admin\nproxysql.password=admin\nproxysql.host=localhost\nproxysql.port=6032\n\n# --------------------------------\n# PXC admin credentials for connecting to a PXC node.\n# --------------------------------\ncluster.user=admin\ncluster.password=admin\ncluster.host=localhost\ncluster.port=4110\n\n# --------------------------------\n# proxysql monitoring user. proxysql admin script will create\n# this user in PXC to monitor a PXC node.\n# --------------------------------\nmonitor.user=monitor\nmonitor.password=monitor\n\n# --------------------------------\n# Application user to connect to a PXC node through proxysql\n# --------------------------------\ncluster-app.user=cluster_one\ncluster-app.password=passw0rd</pre><p>&#160;</p>\n<h3>Requirements and Supported Platforms</h3>\n<p>OpenSSL 1.1.1 (and higher) is an installation requirement (with the exception of Ubuntu 16.04 (xenial), see the comment below).</p>\n<ul>\n<li><strong>Centos 7</strong></li>\n</ul>\n<p>The OpenSSL 1.1.1+ package must be installed. This can be installed with</p><pre class=\"crayon-plain-tag\">yum install openssl11</pre><p>This command will install OpenSSL 1.1 alongside the system installation and the script will use the <code>openssl11</code> binary.</p>\n<ul>\n<li><strong> Centos 8</strong></li>\n</ul>\n<p>The default version of OpenSSL is v1.1.1</p>\n<ul>\n<li><strong>Ubuntu 16.04 (xenia</strong>l)</li>\n</ul>\n<p>For Ubuntu xenial (16.04), installation of OpenSSL v1.1.1+ is not required, a purpose-built binary used for the encryption/decryption (<code>proxysql-admin-openssl</code>) will be installed alongside the proxysql-admin scripts.</p>\n<ul>\n<li><strong>Ubuntu 18.04 (bionic)</strong></li>\n</ul>\n<p>The default version of OpenSSL is v1.1.1</p>\n","descriptionType":"html","publishedDate":"Fri, 18 Jun 2021 12:34:02 +0000","feedId":11,"bgimg":"","linkMd5":"6e38e7442976ba487e13a16608f61402","bgimgJsdelivr":"","metaImg":"","author":"Kenn Takara","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-200x107.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn8@2020_2/2021/07/13/17-22-09-027_aadd37e328f4c549.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-300x160.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn36@2020_5/2021/07/13/17-22-10-560_7004f02505a926c3.webp"},"publishedOrCreatedDate":1626196914572},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Inspecting MySQL Servers Part 5: Percona Monitoring and Management","link":"https://www.percona.com/blog/?p=77196","description":"<img width=\"200\" height=\"113\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-200x113.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Inspecting MySQL Servers PMM\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM.png 1280w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77238\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-300x169.png\" alt=\"Inspecting MySQL Servers PMM\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM.png 1280w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In the previous posts of this series, I presented how the Percona Support team approaches the analysis and troubleshooting of a MySQL server using a tried-and-tested method supported by specific tools found in the Percona Toolkit:</span></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/01/inspecting-mysql-servers-part-1-the-percona-support-way/\">Inspecting MySQL Servers Part 1: The Percona Support Way</a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/02/inspecting-mysql-servers-part-2-knowing-the-server/\">Inspecting MySQL Servers Part 2: Knowing the Server</a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/03/inspecting-mysql-servers-part-3-what-mysql/\">Inspecting MySQL Servers Part 3: What MySQL?</a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/04/inspecting-mysql-servers-part-4-an-engine-in-motion/\"><span>Inspecting MySQL Servers Part 4: An Engine in Motion</span></a></p>\n<p><span> A drawback from such an approach is that data collection is done in a “reactive” way and (part of) it needs to be processed before we can interpret it. Enters </span><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\"><i><span>Percona Monitoring and Management (PMM)</span></i></a><span>: PMM continually collects MySQL status variables and plots the metrics in easy-to-interpret Grafana graphs and panels. Plus, it includes a rich</span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/using/query-analytics.html\"> <i><span>Query Analytics</span></i></a><span> dashboard that helps identify the top slow queries and show how they are executing. It makes for an excellent complement to the approach we presented. In fact, many times it takes the central role: we analyze the data available on PMM and, if necessary, look at complementing it with </span><i><span>pt-stalk</span></i><span> samples. In this post, I will show you how we can obtain much of the same information we got from the Percona Toolkit tools (and sometimes more) from PMM.</span></p>\n<p><span>* As was the case in the previous posts in this series, data, and graphs used to illustrate this post does not come from a single server and have been captured using different versions of PMM.</span></p>\n<h2>Know the Server</h2>\n<p><span>Once you are connected to PMM, you can select the target server under the </span><i><span>Node Name</span></i><span> field in the menu located on the top-left side of the interface, then select </span><i><span>PMM dashboards</span></i><span> on the left menu, </span><i><span>System (Node)</span></i><span>, and, finally, </span><i><span>Node Summary</span></i><span>, as shown in the screenshot below:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77197 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image15.png\" alt=\"PMM Dashboard\" width=\"594\" height=\"553\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image15.png 594w, https://www.percona.com/blog/wp-content/uploads/2021/07/image15-300x279.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image15-161x150.png 161w, https://www.percona.com/blog/wp-content/uploads/2021/07/image15-367x342.png 367w\" sizes=\"(max-width: 594px) 100vw, 594px\" /></p>\n<p><span>The header section of the </span><i><span>Node Summary</span></i><span> page shows the basic hard</span>ware specs of the server as well as a few metrics and projections. You will find on the right side of this section the full output of <i>pt-summary</i>, which we have scrutinized extensively in <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/02/inspecting-mysql-servers-part-2-knowing-the-server/\">the second post of this series</a>, there, waiting for you:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77198 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image3-1024x453.png\" alt=\"MySQL Node Summary\" width=\"900\" height=\"398\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image3-1024x453.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/image3-300x133.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image3-200x88.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image3-367x162.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/image3.png 1194w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\n<span>Below the header section, there are four panels dedicated to </span><b>CPU</b><span>, </span><b>Memory</b><span>, </span><b>Disk</b><span>, and </span><b>Network</b><span>, each containing graphics with specific metrics on each of these areas. It makes it easy, for example, to look at overall CPU utilization:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77199 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image4.png\" alt=\"CPU utilization\" width=\"1178\" height=\"344\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image4.png 1178w, https://www.percona.com/blog/wp-content/uploads/2021/07/image4-300x88.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image4-1024x299.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/image4-200x58.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image4-367x107.png 367w\" sizes=\"(max-width: 1178px) 100vw, 1178px\" /></p>\n<p><span>Recent spikes in I/O activity:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77200 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image20.png\" alt=\"\" width=\"558\" height=\"288\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image20.png 558w, https://www.percona.com/blog/wp-content/uploads/2021/07/image20-300x155.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image20-200x103.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image20-450x231.png 450w, https://www.percona.com/blog/wp-content/uploads/2021/07/image20-367x189.png 367w\" sizes=\"(max-width: 558px) 100vw, 558px\" /></p>\n<p><span>And memory usage:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77201 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image14.png\" alt=\"\" width=\"607\" height=\"239\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image14.png 607w, https://www.percona.com/blog/wp-content/uploads/2021/07/image14-300x118.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image14-200x79.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image14-367x145.png 367w\" sizes=\"(max-width: 607px) 100vw, 607px\" /></p>\n<p><span>Note the graphs cover the last 12 hours of activity by default but you can select a different time range in the top-right menu:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77202 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image7.png\" alt=\"\" width=\"402\" height=\"51\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image7.png 402w, https://www.percona.com/blog/wp-content/uploads/2021/07/image7-300x38.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image7-200x25.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image7-367x47.png 367w\" sizes=\"(max-width: 402px) 100vw, 402px\" /></p>\n<h2>What MySQL?</h2>\n<p><span>Taking a slightly different route by selecting </span><i><span>MySQL </span></i><span>instead of </span><i><span>System (Node)</span></i><span> and then </span><i><span>MySQL Summary</span></i><span>, we get to access a dashboard that displays MySQL-specific metrics for the selected instance:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77203 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image1.png\" alt=\"MySQL Summary\" width=\"417\" height=\"344\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image1.png 417w, https://www.percona.com/blog/wp-content/uploads/2021/07/image1-300x247.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image1-182x150.png 182w, https://www.percona.com/blog/wp-content/uploads/2021/07/image1-367x303.png 367w\" sizes=\"(max-width: 417px) 100vw, 417px\" /></p>\n<p><span>Under the </span><i><span>Service Summary</span></i><span> panel, you will find the full output of </span><i><span>pt-mysql-summary</span></i><span>, which we reviewed in detail in </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2021/06/03/inspecting-mysql-servers-part-3-what-mysql/\"><span>the third post of this series</span></a><span>:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77204 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image13.png\" alt=\"\" width=\"754\" height=\"795\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image13.png 754w, https://www.percona.com/blog/wp-content/uploads/2021/07/image13-285x300.png 285w, https://www.percona.com/blog/wp-content/uploads/2021/07/image13-142x150.png 142w, https://www.percona.com/blog/wp-content/uploads/2021/07/image13-367x387.png 367w\" sizes=\"(max-width: 754px) 100vw, 754px\" /></p>\n<p><span>The main goal of the </span><i><span>pt-mysql-summary</span></i><span> is to provide a sneak-peek into how MySQL is configured, at a single point in time.  With PMM you get instant access to most of the MySQL trends and status variables we only get a glance from in the report. We can go and look straight under the hood to look at the engine characteristics while it is under load, over the last 5 minutes to the last 30 days or more!</span></p>\n<h2>An Engine in Motion</h2>\n<p><span>There is so much we can look at at this point. If we go and more or less follow the sequence observed in the previous posts we can start by checking if the </span><b>table cache</b><span> is big enough. The example below shows it to be just right, if we base ourselves in the limited time frame this particular sample covers, with an </span><b>average hit ratio close to 100%</b><span>:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77205 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image21.png\" alt=\"MySQL Table Open Cache Status\" width=\"583\" height=\"322\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image21.png 583w, https://www.percona.com/blog/wp-content/uploads/2021/07/image21-300x166.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image21-200x110.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image21-367x203.png 367w\" sizes=\"(max-width: 583px) 100vw, 583px\" /></p>\n<p><span>Or we can look for a disruption in the pattern, such as a peak in </span><b>threads connected</b><span>:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77206 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image16.png\" alt=\"\" width=\"585\" height=\"273\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image16.png 585w, https://www.percona.com/blog/wp-content/uploads/2021/07/image16-300x140.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image16-200x93.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image16-367x171.png 367w\" sizes=\"(max-width: 585px) 100vw, 585px\" /></p>\n<p><span>And then investigate the effects it caused on the server (or was it already a consequence of something else that occurred?), for example, a change in the rate of </span><b>temporary tables</b><span> created at that time for both in-memory and on-disk tables:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77207 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image2.png\" alt=\"\" width=\"629\" height=\"260\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image2.png 629w, https://www.percona.com/blog/wp-content/uploads/2021/07/image2-300x124.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image2-200x83.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image2-367x152.png 367w\" sizes=\"(max-width: 629px) 100vw, 629px\" /></p>\n<p><span>The </span><i><span>MySQL Instance Summary</span></i><span> is just one of many dashboards available for MySQL:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77208 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image10.png\" alt=\"\" width=\"320\" height=\"390\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image10.png 320w, https://www.percona.com/blog/wp-content/uploads/2021/07/image10-246x300.png 246w, https://www.percona.com/blog/wp-content/uploads/2021/07/image10-123x150.png 123w\" sizes=\"(max-width: 320px) 100vw, 320px\" /></p>\n<p><span>Under the </span><i><span>MySQL InnoDB Details</span></i><span> dashboard we find many InnoDB-specific metrics plotted as a multitude of different graphs, providing a visual insight into things such as the number of requests that can be satisfied from </span><b>data that is already loaded in the Buffer Pool</b><span> versus those that must be first read from disk (</span><i><span>does my hot data fit in memory?</span></i><span>):</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77209 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image12.png\" alt=\"InnoDB Buffer Pool Requests\" width=\"589\" height=\"300\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image12.png 589w, https://www.percona.com/blog/wp-content/uploads/2021/07/image12-300x153.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image12-200x102.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image12-367x187.png 367w\" sizes=\"(max-width: 589px) 100vw, 589px\" /></p>\n<p><span>Besides MySQL status variables metrics, there is also data filtered directly from SHOW ENGINE INNODB STATUS. For instance, we can find </span><b>long-running transactions</b><span> based on increasing values of InnoDB’s </span><b>history length list</b><span>:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77210 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image17.png\" alt=\"\" width=\"583\" height=\"293\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image17.png 583w, https://www.percona.com/blog/wp-content/uploads/2021/07/image17-300x151.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image17-200x101.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image17-367x184.png 367w\" sizes=\"(max-width: 583px) 100vw, 583px\" /></p>\n<p><span>Another perk of PMM is the ability to easily evaluate whether </span><b>redo log space</b><span> is big enough based on the rate of writes versus the size of the log files:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77211 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image8.png\" alt=\"\" width=\"591\" height=\"316\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image8.png 591w, https://www.percona.com/blog/wp-content/uploads/2021/07/image8-300x160.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image8-200x107.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image8-367x196.png 367w\" sizes=\"(max-width: 591px) 100vw, 591px\" /></p>\n<p><span>And thus observe </span><b>checkpoint age</b><span>, a concept that is explained in detail for PMM in </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2017/10/18/chose-mysql-innodb_log_file_size/\"><i><span>How to Choose the MySQL innodb_log_file_size</span></i></a><span>:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77212 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image18.png\" alt=\"\" width=\"596\" height=\"329\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image18.png 596w, https://www.percona.com/blog/wp-content/uploads/2021/07/image18-300x166.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image18-200x110.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image18-367x203.png 367w\" sizes=\"(max-width: 596px) 100vw, 596px\" /></p>\n<p><span>Another evaluation made easy with PMM is whether a server’s workload is benefitting from having InnoDB’s </span><b>Adaptive Hash Index</b><span> (AHI) enabled. The example below shows an AHI hit-ratio close to 100% up to a certain point, from which the number of searches increased and the situation inverted:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77213 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image6.png\" alt=\"\" width=\"597\" height=\"270\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image6.png 597w, https://www.percona.com/blog/wp-content/uploads/2021/07/image6-300x136.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image6-200x90.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image6-367x166.png 367w\" sizes=\"(max-width: 597px) 100vw, 597px\" /></p>\n<p><span>The evaluation of settings like the size of the redo log space and the efficiency of AHI should be done at a macro level, spanning days: we should be looking for what is the best general configuration for these. However, when we are investigating a particular event, it is important to zoom in on the time frame where it occurred to better analyze the data captured at the time. Once you do this, change the data resolution from the default of </span><i><span>auto</span></i><span> to 1s or 5s interval/granularity so you can better see spikes and overall variation: </span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77214 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image19.png\" alt=\"\" width=\"351\" height=\"224\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image19.png 351w, https://www.percona.com/blog/wp-content/uploads/2021/07/image19-300x191.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image19-200x128.png 200w\" sizes=\"(max-width: 351px) 100vw, 351px\" /></p>\n<h2>QAN: Query Analytics</h2>\n<p><span>Query analysis is something I only hinted at but didn’t explore in the first articles in this series. The “manual” way requires processing the slow query log with a tool such as </span><i><span>pt-query-digest</span></i><span> and then going for details about a particular query by connecting to the server to obtain the execution plan and schema details. A really strong feature of PMM is the </span><i><span>Query Analytics</span></i><span> dashboard, which provides a general overview of query execution and captures all information about it for you. </span></p>\n<p>The example below comes from a simple <i>sysbench</i> read-write workload on my test server:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-77215 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image11.png\" alt=\"PMM Query Analytics\" width=\"1267\" height=\"634\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image11.png 1267w, https://www.percona.com/blog/wp-content/uploads/2021/07/image11-300x150.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image11-1024x512.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/image11-200x100.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image11-367x184.png 367w\" sizes=\"(max-width: 1267px) 100vw, 1267px\" />We can select an individual query on the list and check the details of its execution:</p>\n<p><img loading=\"lazy\" class=\"wp-image-77216 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image9.png\" alt=\"\" width=\"937\" height=\"797\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image9.png 937w, https://www.percona.com/blog/wp-content/uploads/2021/07/image9-300x255.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image9-176x150.png 176w, https://www.percona.com/blog/wp-content/uploads/2021/07/image9-367x312.png 367w\" sizes=\"(max-width: 937px) 100vw, 937px\" /></p>\n<p><span>The query’s  EXPLAIN plan is also available, both in </span><i><span>classic</span></i><span> and JSON formats:</span></p>\n<p><img loading=\"lazy\" class=\"wp-image-77217 size-full aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image5.png\" alt=\"\" width=\"902\" height=\"396\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/image5.png 902w, https://www.percona.com/blog/wp-content/uploads/2021/07/image5-300x132.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/image5-200x88.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/image5-367x161.png 367w\" sizes=\"(max-width: 902px) 100vw, 902px\" /></p>\n<p><span>You can read more about QAN on </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/using/query-analytics.html\"><span>our website</span></a><span> as well as in other posts on our blog platform, such as </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2020/10/07/how-to-find-query-slowdowns-using-percona-monitoring-and-management/\"><i><span>How to Find Query Slowdowns Using Percona Monitoring and Management</span></i></a><span>.</span></p>\n<h2>What PMM Does Not Include</h2>\n<p><span>There remains information/data we cannot obtain from PMM, such as the full output of SHOW ENGINE INNODB STATUS. For situations when obtaining this information is important, we resort back to </span><i><span>pt-stalk</span></i><span>. It is not one or the other, we see them as complementary tools in our job of inspecting MySQL servers. </span></p>\n<p><span>If you are curious about PMM and would like to see how it works in practice, check our demo website at</span><a target=\"_blank\" href=\"https://pmmdemo.percona.com/\"> <span>https://pmmdemo.percona.com/</span></a><span>. To get up and running with PMM quickly, refer to our </span><a target=\"_blank\" href=\"https://www.percona.com/software/pmm/quickstart\"><span>quickstart</span></a><span> guide.</span></p>\n<h2>Tuning the Engine for the Race Track</h2>\n<p><span>There you have it! It certainly isn’t all there is but we’ve got a lot packed in this series, enough to get you moving in the right direction when it comes to inspecting and troubleshooting MySQL servers. I hope you have enjoyed the journey and learned a few new tricks along the way <img src=\"https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png\" alt=\"🙂\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /></span></p>\n","descriptionType":"html","publishedDate":"Wed, 07 Jul 2021 12:00:34 +0000","feedId":11,"bgimg":"","linkMd5":"fce4f389c5abef783c23818e0dd4dc08","bgimgJsdelivr":"","metaImg":"","author":"Fernando Laudares Camargos","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-200x113.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn4@2020_4/2021/07/13/17-22-17-940_67d272f6b5762395.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn11@2020_3/2021/07/13/17-22-11-276_771ca0496fb9e8fe.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image15.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn15@2020_5/2021/07/13/17-22-11-052_dcabfbab179fd855.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image3-1024x453.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn79@2020_4/2021/07/13/17-22-07-833_ff2dea52c68e4060.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image4.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn52@2020_3/2021/07/13/17-22-07-553_eb93dd75d340cac9.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image20.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn96@2020_3/2021/07/13/17-22-06-861_041c1fc88e6c3d0d.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image14.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn55@2020_4/2021/07/13/17-22-09-387_c7e9249848ee350c.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image7.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn60@2020_2/2021/07/13/17-22-10-519_12c8b5c584fe1482.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image1.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn100@2020_4/2021/07/13/17-21-57-603_94f2481f94b27fff.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image13.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn60@2020_4/2021/07/13/17-22-10-949_b30f12a5078705de.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image21.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn67@2020_1/2021/07/13/17-22-07-558_f93551bf17324f48.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image16.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn71@2020_3/2021/07/13/17-22-08-574_83e9bf0ee0289d4a.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image2.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn16@2020_3/2021/07/13/17-22-07-460_593060b76fd9c572.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image10.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn44@2020_2/2021/07/13/17-22-05-070_7ba795f2e7eb45ae.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image12.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn98@2020_5/2021/07/13/17-22-10-991_dc07a64d6552c7e0.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image17.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn43@2020_6/2021/07/13/17-22-08-537_6ac77f06ff08656f.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image8.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn4@2020_4/2021/07/13/17-22-09-871_0d1e4b3127d93cd2.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image18.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn20@2020_4/2021/07/13/17-22-11-503_1dd16ac5fe329ea8.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image6.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn76@2020_1/2021/07/13/17-22-08-916_bca0e92b24b750c2.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image19.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn100@2020_4/2021/07/13/17-22-11-189_0d89a3bb4ab93c65.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image11.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn52@2020_4/2021/07/13/17-22-07-283_f8f2a2bec44bb7eb.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image9.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn39@2020_1/2021/07/13/17-22-11-662_e5429016721a38c6.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/image5.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn32@2020_3/2021/07/13/17-22-07-195_aaa191b45a584e45.webp","https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn60@2020_5/2021/07/13/17-21-54-848_2d9b14cc3bc762a6.webp"},"publishedOrCreatedDate":1626196914564},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Distributed Grant Management Using MongoDBAuthorizationGrant","link":"https://www.percona.com/blog/?p=75470","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MongoDBAuthorizationGrant\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76569\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-300x168.png\" alt=\"MongoDBAuthorizationGrant\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />MongoDB supports multiple authentication mechanisms, including the default one SCRAM, LDAP, Kerberos, and x.509 Certificate Authentication.</p>\n<p>In the X.509 system, which will be the main point of this blog post, an organization can identify its entities using a pair of certificates and private keys signed and trusted by some Certificate Authority (CA).</p>\n<p>This model is well-known in the industry, and it&#8217;s quite popular for delegating authentication to 3rd party services. The other, similar way of delegating authentication is LDAP, which is also part of the same X.500 standard group called directory services.</p>\n<p>While authentication works fine for MongoDB &#8211; and in general for every database system &#8211; the problem with authorization remains. A MongoDB cluster still needs to obtain information about resources to which a given user has access. Roles help a lot here, but in a zero-trust model, the practice requires having information duplicated: authentication data is stored in LDAP, X.509, or any other system, and authorization models residing in MongoDB.</p>\n<p>And here, a cool feature of X.509 and&#8230; an undocumented feature of MongoDB comes into play.</p>\n<p>An X.509 certificate is de facto a serialized object. It uses Abstract Syntax Notation One (ASN.1), which is a standard interface description language for defining data structures that can be serialized and deserialized in a cross-platform way. It is broadly used in cryptography.</p>\n<p>A sample deserialized certificate looks like below:</p><pre class=\"crayon-plain-tag\"># openssl asn1parse -in client.crt \n    0:d=0 hl=4 l= 957 cons: SEQUENCE          \n    4:d=1 hl=4 l= 677 cons: SEQUENCE          \n    8:d=2 hl=2 l= 3 cons: cont [ 0 ]        \n   10:d=3 hl=2 l= 1 prim: INTEGER :02\n   13:d=2 hl=2 l= 20 prim: INTEGER :22BC2E27B24B5A47123C6CB2FA0904B4F3663322\n   35:d=2 hl=2 l= 13 cons: SEQUENCE          \n   37:d=3 hl=2 l= 9 prim: OBJECT :sha256WithRSAEncryption\n   48:d=3 hl=2 l= 0 prim: NULL              \n   50:d=2 hl=2 l= 82 cons: SEQUENCE          \n   52:d=3 hl=2 l= 11 cons: SET               \n   54:d=4 hl=2 l= 9 cons: SEQUENCE          \n   56:d=5 hl=2 l= 3 prim: OBJECT :countryName\n   61:d=5 hl=2 l= 2 prim: PRINTABLESTRING :AU\n…</pre><p>The main advantage of the above is that almost any piece of information can be stored inside a certificate. As the Certificate Authority needs to sign it, a user that&#8217;s presenting the certificate can&#8217;t modify it. That makes it secure. It also allows storing authorization information inside it.</p>\n<h2>How to Use It?</h2>\n<h3>1) Let&#8217;s Start with Preparing the Certificate Authority</h3>\n<p></p><pre class=\"crayon-plain-tag\"># openssl req -x509 -new -newkey rsa:2048 -nodes -keyout myCA.key -sha256 -days 1825 -out myCA.pem\n…</pre><p></p>\n<h3>2) Let&#8217;s Create a Server Certificate</h3>\n<p>OpenSSL Configuration:</p><pre class=\"crayon-plain-tag\">[ req ]\ndefault_bits = 2048\ndefault_keyfile = server.key\nencrypt_key = no\ndefault_md = sha256\nprompt = no\nutf8 = yes\ndistinguished_name = server_req_distinguished_name\nreq_extensions = server_extensions\n\n\n[ server_req_distinguished_name ]\nC = AU\nST = Some-State\nO = Percona\nOU = NA\nCN = server\n\n[ server_extensions ]\nbasicConstraints=CA:FALSE\nsubjectKeyIdentifier = hash\nkeyUsage = keyEncipherment, digitalSignature\nextendedKeyUsage = serverAuth, clientAuth\n\n# openssl req -config server.cnf -new -newkey rsa:2048 -out server.csr\n# openssl x509 -req -in server.csr -CA myCA.pem -CAkey myCA.key -CAcreateserial -out server.crt -days 825 -sha256 -extensions server_extensions -extfile server.cnf\n# cat server.crt server.key &#62; server.pem</pre><p></p>\n<h3>3) Let&#8217;s Create a Client Certificate</h3>\n<p></p><pre class=\"crayon-plain-tag\">[ req ]\ndefault_bits = 2048\ndefault_keyfile = client.key\nencrypt_key = no\ndefault_md = sha256\nprompt = no\nutf8 = yes\ndistinguished_name = client_req_distinguished_name\nreq_extensions = client_extensions\nx509_extensions = client_extensions\n\n\n[ client_req_distinguished_name ]\nC = AU\nST = Some-State\nL = X\nO = Percona\nOU = Clients\nCN = client\n\n[ client_extensions ]\nbasicConstraints=CA:FALSE\nsubjectKeyIdentifier = hash\nkeyUsage = digitalSignature\nextendedKeyUsage = clientAuth\n1.3.6.1.4.1.34601.2.1.1= ASN1:SET:grants\n\n\n[ grants ]\ngrant.1 = SEQUENCE:MongoDBRole\ngrant.2 = SEQUENCE:MongoDBRole2\n\n[ MongoDBRole ]\nrole = UTF8:backup\ndatabase = UTF8:admin\n\n[ MongoDBRole2 ]\nrole = UTF8:readAnyDatabase\ndatabase = UTF8:admin</pre><p>The above configuration will use <a target=\"_blank\" href=\"https://github.com/percona/percona-server-mongodb/blob/master/src/mongo/util/net/ssl_manager.h#L144\">MongoDBAuthorizationGrant OID 1.3.6.1.4.1.34601.2.1.1</a> and will grant the user that&#8217;s presenting the certificate two roles: backup for database admin and readAnyDatabase for database admin.</p>\n<p>It&#8217;s important to remember that a client x.509 certificate&#8217;s subject, which contains the Distinguished Name (DN), must differ from that of a Member x.509 Certificate. Also, at least one of the Organization (O), Organizational Unit (OU), or Domain Component (DC) attributes in the client certificate must differ from those in the <span><code>net.tls.clusterFile</code> and <code>net.tls.certificateKeyFile</code> </span>server certificates.</p>\n<p>Moreover, a client certificate must contain the following fields:</p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><code>keyUsage = digitalSignature</code></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><code>extendedKeyUsage = clientAuth</code></span></li>\n</ul>\n<p>If the above requirements are not met, MongoDB will refuse any client x509 authentication with an error:</p><pre class=\"crayon-plain-tag\">AuthenticationFailed: The provided certificate can only be used for cluster authentication, not client authentication. The current configuration does not allow x.509 cluster authentication, check the --clusterAuthMode flag</pre><p>Let&#8217;s continue generating the request and signing the certificate:</p><pre class=\"crayon-plain-tag\"># openssl req -config client.cnf -new -newkey rsa:2048 -out client.csr\n# openssl x509 -req -in client.csr -CA myCA.pem -CAkey myCA.key -CAcreateserial -out client.crt -days 825 -sha256 -extensions client_extensions -extfile client.cnf\n# cat client.crt client.key &#62; client.pem</pre><p></p>\n<h3>4) Let&#8217;s Try it Out</h3>\n<p>At this stage MongoDB should allow authentication and authorization using the previously generated certificates:</p><pre class=\"crayon-plain-tag\">$ mongo --tls --tlsCertificateKeyFile client.pem --tlsCAFile ./myCA.pem --authenticationDatabase '$external' --authenticationMechanism MONGODB-X509 server/\n\n&#62; db.runCommand({ connectionStatus: 1, showPrivileges: false });\n{\n\t\"authInfo\" : {\n\t\t\"authenticatedUsers\" : [\n\t\t\t{\n\t\t\t\t\"user\" : \"CN=client,OU=Clients,O=Percona,L=X,ST=Some-State,C=AU\",\n\t\t\t\t\"db\" : \"$external\"\n\t\t\t}\n\t\t],\n\t\t\"authenticatedUserRoles\" : [\n\t\t\t{\n\t\t\t\t\"role\" : \"backup\",\n\t\t\t\t\"db\" : \"admin\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"role\" : \"readAnyDatabase\",\n\t\t\t\t\"db\" : \"admin\"\n\t\t\t}\n\t\t]\n\t},\n\t\"ok\" : 1\n}</pre><p>It works without adding a single user!</p>\n<h2>Conclusion</h2>\n<ul>\n<li aria-level=\"1\">MongoDB allows embedding grants in an x.509 certificate file.</li>\n<li aria-level=\"1\">It&#8217;s useful especially in cloud environments because it moves the authorization layer out of MongoDB.</li>\n<li aria-level=\"1\">The certificates can be reused for different clusters.</li>\n<li aria-level=\"1\">It forces using PKI, which is much more secure than just passwords.</li>\n</ul>\n","descriptionType":"html","publishedDate":"Thu, 10 Jun 2021 13:54:03 +0000","feedId":11,"bgimg":"","linkMd5":"f477311e2b6a8ed038663178f8ea1c46","bgimgJsdelivr":"","metaImg":"","author":"IP","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn9@2020_3/2021/07/13/17-21-55-121_203d68e483ab8dba.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn8@2020_3/2021/07/13/17-22-08-063_057f62f2acea9afe.webp"},"publishedOrCreatedDate":1626196914582},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Cluster Statuses in Percona Kubernetes Operators","link":"https://www.percona.com/blog/?p=77277","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Cluster Statuses in Percona Kubernetes Operators\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77364\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-300x168.png\" alt=\"Cluster Statuses in Percona Kubernetes Operators\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In Kubernetes, all resources have a status field separated from their spec. The </span><span>status field is an interface both for humans or applications to </span><span>read the perceived state of the resource.</span></p>\n<p><span>When you deploy our <a target=\"_blank\" href=\"https://www.percona.com/software/percona-kubernetes-operators\">Percona Kubernetes Operators</a> &#8211;  </span><a target=\"_blank\" href=\"https://github.com/percona/percona-server-mongodb-operator\">Percona Distribution for MongoDB Operator</a> <span>or </span><a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster-operator\">Percona Distribution for MySQL Operator</a><span> &#8211; in your Kubernetes cluster, you&#8217;re </span><span>creating a custom resource (CR for short) and it has its own status, too. Since </span><span>Kubernetes operators mimic the human operator and aim to have the required expertise to run software in a Kubernetes cluster; the status of the custom resources should be smart.</span></p>\n<p><span>You can get cluster status with the commands below, or via (Kubernetes API) for Percona Distribution for MySQL Operator:</span></p><pre class=\"crayon-plain-tag\">% kubectl get pxc\nNAME            ENDPOINT                                   STATUS   PXC   PROXYSQL   HAPROXY   AGE\nlisette-18537   lisette-18537-haproxy.subjectivism-22940   ready    3                3         87m\n\n% kubectl get pxc &#60;cluster-name&#62; -o jsonpath='{.status}'\n{\n  \"backup\": {\n    \"version\": \"8.0.23\"\n  },\n  \"conditions\": [\n    {\n      \"lastTransitionTime\": \"2021-07-12T13:13:46Z\",\n      \"status\": \"True\",\n      \"type\": \"initializing\"\n    }\n  ],\n  \"haproxy\": {\n    \"labelSelectorPath\": \"...\",\n    \"ready\": 3,\n    \"size\": 3,\n    \"status\": \"ready\"\n  },\n  \"host\": \"lisette-18537-haproxy.subjectivism-22940\",\n  \"logcollector\": {\n    \"version\": \"1.8.0\"\n  },\n  \"observedGeneration\": 2,\n  \"pmm\": {\n    \"version\": \"2.12.0\"\n  },\n  \"proxysql\": {},\n  \"pxc\": {\n    \"image\": \"percona/percona-xtradb-cluster:8.0.22-13.1\",\n    \"labelSelectorPath\": \"...\",\n    \"ready\": 2,\n    \"size\": 3,\n    \"status\": \"initializing\",\n    \"version\": \"8.0.22-13.1\"\n  },\n  \"ready\": 5,\n  \"size\": 6,\n  \"state\": \"initializing\"\n}</pre><p><span>And for Percona Distribution for MongoDB Operator:</span></p><pre class=\"crayon-plain-tag\">% kubectl get psmdb\nNAME             ENDPOINT                                                     STATUS   AGE\ncynodont-26997   cynodont-26997-mongos.subjectivism-22940.svc.cluster.local   ready    85m\n\n\n% kubectl get psmdb &#60;cluster-name&#62; -o jsonpath='{.status}'\n{\n  \"conditions\": [\n    {\n      \"lastTransitionTime\": \"2021-07-12T13:13:39Z\",\n      \"status\": \"True\",\n      \"type\": \"initializing\"\n    }\n  ],\n  \"host\": \"cynodont-26997-mongos.subjectivism-22940.svc.cluster.local\",\n  \"mongoImage\": \"percona/percona-server-mongodb:4.4.6-8\",\n  \"mongoVersion\": \"4.4.6-8\",\n  \"mongos\": {\n    \"ready\": 1,\n    \"size\": 3,\n    \"status\": \"initializing\"\n  },\n  \"observedGeneration\": 2,\n  \"ready\": 3,\n  \"replsets\": {\n    \"cfg\": {\n      \"ready\": 1,\n      \"size\": 3,\n      \"status\": \"initializing\"\n    },\n    \"rs0\": {\n      \"initialized\": true,\n      \"ready\": 2,\n      \"size\": 3,\n      \"status\": \"initializing\"\n    }\n  },\n  \"size\": 6,\n  \"state\": \"initializing\"\n}</pre><p><span>As you can see there are several fields in the output: conditions, cluster size, number of ready cluster members, statuses and versions of different components, and the &#8220;state&#8221;. In the following sections, we&#8217;ll take a look at every possible value of the state field.</span></p>\n<h3>Initializing</h3>\n<p><span>While the cluster is progressing to readiness, CR status is “initializing”. It </span><span>includes creating the cluster, scaling it up or down, and updating the CR that </span><span>triggers a rolling restart of pods (for instance updating Percona Distribution for MySQL Operator memory limits).</span></p>\n<p><span> Percona Distribution for MongoDB Operator also reconfigures the replica set config if necessary (for instance </span><span>it adds the new pods as members to replset or removes terminated ones). Replica set in MongoDB is a set of servers that implements replication and automatic failover. Although they have the same name, it’s different from the Kubernetes replica set. While </span><span>this configuration is happening or if there is an unknown/unpredicted error during it, the status is </span><span>also “initializing”.</span></p>\n<p><span>Since version 1.7.0, the Percona Distribution for MySQL Operator can handle full crash recovery if necessary. If a pod </span><span>waits for the recovery, the cluster status is “initializing”.</span></p>\n<h3>Ready</h3>\n<p><span>The operator keeps track of the status of each component in the cluster. Percona Distribution for MongoDB Operator</span><span> has the following components:</span></p>\n<ol>\n<li><span> mongod stateful set</span></li>\n<li><span> configsvr stateful set if sharding is enabled</span></li>\n<li><span> mongos deployment if sharding is enabled</span></li>\n</ol>\n<p><span>Percona Distribution for MySQL Operator components:</span></p>\n<ol>\n<li><span> PXC stateful set</span></li>\n<li><span> HAProxy stateful set if enabled</span></li>\n<li><span> ProxySQL stateful set if enabled</span></li>\n</ol>\n<p><span>All components need to be in “ready” status for CR to be “ready”. If the number of </span><span>ready pods controlled by the stateful set reaches the desired number, the operator </span><span>marks the component as ready. The readiness of the pods is tracked by Kubernetes using readiness probes for each container in the pod. For example, for a Percona XtraDB Cluster container to be ready &#8220;wsrep_cluster_status&#8221; needs to be &#8220;Primary&#8221; and &#8220;wsrep_local_state&#8221; should be &#8220;Synced&#8221; or &#8220;Donor&#8221;. For a Percona Server for MongoDB container to be ready, accepting TCP connections on 27017 is enough.</span></p>\n<p><span>But ready as the CR status means more than that. </span><span>CR “ready” means the cluster (Percona Server for MongoDB or Percona XtraDB Cluster) is up and running and ready to </span><span>receive traffic. So, even if all components are ready, the cluster status can be </span><span>“initializing”. In the Percona Distribution for MongoDB Operator, the replica set needs to be initialized and </span><span>its config up-to-date. Also, with the 1.9.0 release of both operators, the load </span><span>balancer needs to be ready if the cluster is exposed with <code></span>exposeType: LoadBalancer</code>.</p>\n<h3>Stopping</h3>\n<p><span>Version 1.9.0 introduced two new statuses:</span></p>\n<ol>\n<li><span> Stopping</span></li>\n<li><span> Paused</span></li>\n</ol>\n<p><span>Stopping means the cluster is paused or deleted and its pods are terminating right now.</span></p>\n<p><span>If you run <code>kubectl delete psmdb &#60;cluster-name&#62;</code> or <code>kubectl delete pxc </span><span>&#60;cluster-name&#62;</code> the resource can be deleted quickly without a chance to see </span><span>“stopping” status. If you had finalizers (for example &#8220;delete-pxc-pods-in-order&#8221; in Percona Distribution for MySQL Operator</span><span>) deletion will be blocked until the finalizer list is exhausted and </span><span>you can observe “stopping” status.</span></p>\n<h3>Paused</h3>\n<p><span>Once the cluster is paused and all pods are terminated, the CR status becomes “paused”.</span></p>\n<p><span>To pause the cluster:</span> <code>kubectl patch &#60;psmdb|pxc&#62; &#60;cluster-name&#62; --type=merge -p '{\"spec\": {\"pause\": true}}'</code></p>\n<p><span>Keep in mind, </span><span>when the cluster</span><span> is paused and </span><span>exposeType is LoadBalancer &#8211;</span><span> Load balancers are </span><span>still</span><span> there and you continue to pay for them.</span></p>\n<h3>Error</h3>\n<p><span>Before 1.9.0, “error” status could mean two different things:</span></p>\n<ol>\n<li><span> An error occurred in the operator during the reconciliation of the CR</span></li>\n<li><span> One or more pods in a component are not schedulable</span></li>\n</ol>\n<p><span>With 1.9.0, the “error” status means only the operator errors. If there is an </span><span>unschedulable pod, the cluster’s status will be initializing. If the cluster is stuck in initializing for too long, it’s better to check the operator logs to investigate.</span></p><pre class=\"crayon-plain-tag\">% kubectl logs &#60;operator-pod-name&#62;\n...\n{\"level\":\"info\",\"ts\":1626095618.9982307,\"logger\":\"controller_psmdb\",\"msg\":\"Created a new mongo key\",\"Request.Namespace\":\"subjectivism-22940\",\"Request.Name\":\"cynodont-26997\",\"KeyName\":\"cynodont-26997-mongodb-keyfile\"}\n{\"level\":\"info\",\"ts\":1626095619.0032709,\"logger\":\"controller_psmdb\",\"msg\":\"Created a new mongo key\",\"Request.Namespace\":\"subjectivism-22940\",\"Request.Name\":\"cynodont-26997\",\"KeyName\":\"cynodont-26997-mongodb-encryption-key\"}\n{\"level\":\"info\",\"ts\":1626095687.3783236,\"logger\":\"controller_psmdb\",\"msg\":\"initiating replset\",\"replset\":\"rs0\",\"pod\":\"cynodont-26997-rs0-1\"}\n{\"level\":\"info\",\"ts\":1626095694.020591,\"logger\":\"controller_psmdb\",\"msg\":\"replset was initialized\",\"replset\":\"rs0\",\"pod\":\"cynodont-26997-rs0-1\"}\n{\"level\":\"error\",\"ts\":1626095694.622869,\"logger\":\"controller_psmdb\",\"msg\":\"failed to reconcile cluster\",\"Request.Namespace\":\"subjectivism-22940\",\"Request.Name\":\"cynodont-26997\",\"replset\":\"rs0\",\"error\":\"undefined state of the replset member cynodont-26997-rs0-0.cynodont-26997-rs0.subjectivism-22940.svc.cluster.local:27017: 6\",\"errorVerbose\":\"undefined state of the replset member cynodont-26997-rs0-0.cynodont-26997-rs0.subjectivism-22940.svc.cluster.local:27017: 6\\ngithub.com/percona/percona-server-mongodb-operator/pkg/controller/perconaservermongodb.(*ReconcilePerconaServerMongoDB).reconcileCluster\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/pkg/controller/perconaservermongodb/mgo.go:210\\ngithub.com/percona/percona-server-mongodb-operator/pkg/controller/perconaservermongodb.(*ReconcilePerconaServerMongoDB).Reconcile\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/pkg/controller/perconaservermongodb/psmdb_controller.go:449\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:256\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:232\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:211\\nk8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:152\\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:153\\nk8s.io/apimachinery/pkg/util/wait.Until\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1371\",\"stacktrace\":\"github.com/go-logr/zapr.(*zapLogger).Error\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/github.com/go-logr/zapr/zapr.go:128\\ngithub.com/percona/percona-server-mongodb-operator/pkg/controller/perconaservermongodb.(*ReconcilePerconaServerMongoDB).Reconcile\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/pkg/controller/perconaservermongodb/psmdb_controller.go:451\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:256\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:232\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/sigs.k8s.io/controller-runtime/pkg/internal/controller/controller.go:211\\nk8s.io/apimachinery/pkg/util/wait.JitterUntil.func1\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:152\\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:153\\nk8s.io/apimachinery/pkg/util/wait.Until\\n\\t/go/src/github.com/percona/percona-server-mongodb-operator/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:88\"}</pre><p><span>You can try new statuses in version 1.9.0 of both Percona Distribution for MongoDB Operator and Percona Distribution for MySQL Operator. </span><a target=\"_blank\" href=\"https://github.com/percona/percona-server-mongodb-operator/releases/tag/v1.9.0\"><span>Percona Distribution for MongoDB Operator</span></a><span> was released in June and </span><a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster-operator/releases\"><span>Percona Distribution for MySQL Operator</span></a><span> is on the way.</span></p>\n","descriptionType":"html","publishedDate":"Tue, 13 Jul 2021 12:50:49 +0000","feedId":11,"bgimg":"","linkMd5":"2dc117d7342c9f205c16c18da003bc11","bgimgJsdelivr":"","metaImg":"","author":"Ege Gunes","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn6@2020_3/2021/07/13/17-22-05-063_a3954661b658bb9d.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn83@2020_4/2021/07/13/17-21-56-926_094ce172264714ae.webp"},"publishedOrCreatedDate":1626196914554},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"BREAKING NEWS: Take a Sneak Peek Into MongoDB 5.0 With Percona!","link":"https://www.percona.com/blog/?p=77254","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-200x105.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Sneak Peek Into Mongo 5.0 With Percona\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-200x105.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-300x157.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-1024x536.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-1140x595.jpg 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-367x192.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona.jpg 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><strong><img loading=\"lazy\" class=\"alignright size-medium wp-image-77271\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-300x157.jpg\" alt=\"Sneak Peek Into Mongo 5.0 With Percona\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-300x157.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-1024x536.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-200x105.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-1140x595.jpg 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-367x192.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona.jpg 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Calling all MongoDB users and enthusiasts! </strong></p>\n<p>MongoDB 5.0 has been out as a release candidate for a short while, and the production release should be coming soon. Take advantage of a unique opportunity to get the scoop on what’s in MongoDB 5.0 at <strong>11 am EDT</strong> TODAY!</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"http://youtube.com/percona/live\" rel=\"noopener\">Join The Discussion</a></p>\n<p>Join our live stream event as Percona experts Akira Kurogane (MongoDB Product Owner) and Kimberly Wilkins (MongoDB Tech Lead) preview the upcoming release of MongoDB 5.0.</p>\n<p><strong>This will be the first time we discuss the new features we expect to see in MongoDB 5.0!</strong></p>\n<p>This release is rumored to include several exciting new features, including a long-anticipated improvement to sharding. Listen in and find out!</p>\n<p>We will be running a live stream and interactive chat over multiple platforms, so join us to discover how the new changes and features might impact your business and database environment.</p>\n<p><strong>We hope to see you there!</strong></p>\n<p>Join any of our live streams, and don’t forget to post questions!</p>\n<p><strong><a target=\"_blank\" href=\"http://youtube.com/percona/live\">YouTube</a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://www.twitch.tv/perconalive\">Twitch</a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://www.linkedin.com/company/percona\">LinkedIn</a></strong></p>\n","descriptionType":"html","publishedDate":"Thu, 08 Jul 2021 09:07:37 +0000","feedId":11,"bgimg":"","linkMd5":"bb5d1e7fbccb0048b24243fb98524994","bgimgJsdelivr":"","metaImg":"","author":"Rachel Pescador","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-200x105.jpg":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn19@2020_4/2021/07/13/17-21-56-943_c6d4a900673af131.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-300x157.jpg":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn14@2020_1/2021/07/13/17-22-13-495_1e8c0801e300a4fe.webp"},"publishedOrCreatedDate":1626196914551},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Migrating Into Kubernetes Running the Percona Distribution for MySQL Operator","link":"https://www.percona.com/blog/?p=76660","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Migrating Into k8s Running the Percona Distribution for MySQL Operator\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span>The practice of running databases in containers continues to grow in popularity.  As a Technical Account Manager at Percona, I get asked regularly about our <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\" target=\"_blank\" rel=\"noopener\">Percona Distribution for MySQL Operator</a></span><span>.  Additionally, I’m asked what I’m seeing in the industry in terms of adoption.  In most cases, the questions stem around new deployments.  Our </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/server/dbaas.html\"><span>DBaaS</span></a><span> tool (currently in Technical Preview) makes launching a new cluster in a Kubernetes deployment trivial.  </span></p>\n<p><span>Once the operator completes and verifies the setup, the UI displays the endpoint and credentials and you are on your way.  Voila!  You now have a cluster, behind a load balancer, that you can access from within your k8s cluster or externally:  </span></p>\n<p><span><img loading=\"lazy\" class=\"aligncenter wp-image-76661 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-1024x351.png\" alt=\" Percona Distribution for MySQL Operator\" width=\"900\" height=\"308\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-1024x351.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-300x103.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-200x68.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-367x126.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM.png 1428w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></span></p>\n<p><span>This is all well and good, giving developers the opportunity to quickly build new applications.  However, a new question recently came up in a client call: how can I migrate an existing database into Kubernetes?  This got me thinking, so I decided to spin up some test servers and experiment with the backup and restore functionality of the operator.</span></p>\n<h2>General Migration Process</h2>\n<p><span>For my testing, I wanted to follow the standard process:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Take a binary snapshot of the primary server</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Restore that snapshot into the new cluster</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Start replication from the primary server to the new cluster</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Cutover the application after replication is caught up</span></li>\n</ol>\n<p><span>Looking through the operator documentation, I wanted to leverage the </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/backups.html#restoring-without-point-in-time-recovery\"><span>existing restore functionality</span></a><span> in my testing.  Through some manual updates to the service created by the DBaaS tool, I defined my S3 credentials and details:</span></p><pre class=\"crayon-plain-tag\">kubectl edit perconaxtradbcluster.pxc.percona.com/mbenshoof-pxc-cluster</pre><p><span>Next, I verified that I could take and restore backups from the command line (using the kubectl tool).  So far, so good.  </span></p>\n<p><span>Finally, it was time to test the main step of a generic migration.  I had a test server set up and took a streaming backup (using xbcloud with the &#8211;md5 switch passed) directly into the S3 bucket configured in the operator.  The final step was to define a custom restore resource and kick off the restore:</span></p><pre class=\"crayon-plain-tag\"># cat restore-external.yaml\napiVersion: pxc.percona.com/v1\nkind: PerconaXtraDBClusterRestore\nmetadata:\nname: restore-external-v1\nspec:\npxcCluster: migrate-from-external\nbackupSource:\ndestination: s3://&#60;S3-BUCKET-FOR-BACKUPS&#62;/external-80-full_backup\ns3:\ncredentialsSecret: &#60;MY-K8S-AWS-SECRET&#62;\nregion: us-east-1</pre><p><span>After some time, I verified that the restoration succeeded and also verified that my DBaaS cluster was operational again:</span></p><pre class=\"crayon-plain-tag\">$ kubectl logs job/restore-job-restore-external-v1-migrate-from-external</pre><p>&#160;</p>\n<p><span>If everything is fine, you can clean up the job:</span></p><pre class=\"crayon-plain-tag\">$ kubectl delete pxc-restore/restore-external-v1\n\nCompleted: 2021-06-04T16:42:58Z\nState: Succeeded\nEvents: &#60;none&#62;</pre><p><span>Success!  I was able to restore my external 8.0 instance into a new DBaaS-generated cluster.  The final step in a migration process is to set up replication into the new cluster.</span></p>\n<h2>Setting up Replication</h2>\n<p><span>With a replication user-defined, it was trivial to get replication running into the new cluster.  In fact, there was no difference between this test and setting up replication normally.  Once I allowed access to the source server (via VPC Security Groups), I simply started replication and verified that I was picking up new transactions:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; show replica status\\G\n*************************** 1. row ***************************\nReplica_IO_State: Waiting for master to send event\nSource_Host: 10.1.1.226\nSource_User: repl\nSource_Port: 3306\nConnect_Retry: 60\nSource_Log_File: binlog.000005\nRead_Source_Log_Pos: 679\nRelay_Log_File: migrate-from-external-pxc-0-relay-bin.000002\n...\nSeconds_Behind_Source: 0\n...\nRetrieved_Gtid_Set: c6a4c262-c4a7-11eb-bed8-0e0d8750f515:84-85\nExecuted_Gtid_Set: c6a4c262-c4a7-11eb-bed8-0e0d8750f515:1-85\nAuto_Position: 1\n...\n1 row in set (0.00 sec)</pre><p><span>Just to ensure things were working as expected, I ran a few queries and sent some write traffic to my primary test server.  Everything worked as expected when setting up replication from a stand-alone instance into the new cluster!</span></p>\n<h2>Primary Challenge &#8211; User Credentials</h2>\n<p><span>Working through this exercise, I did identify the main limitation in this process.  When I first attempted this exercise, the restore process hung and eventually failed.  The reason: conflicting user credentials in the freshly restored cluster.</span></p>\n<p><span>The operator manages the cluster nodes via credentials defined in a Kubernetes secret.  When new clusters are created, random and unique credentials are generated and used to set up the cluster.  While this is great for a new cluster and keeps it secure upon launch, it isn’t ideal for the migration process.</span></p>\n<p><span>While playing around with various migration test variations, I used one of the following two workaround methods:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Modifying the source database with the newly generated cluster credentials</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Modifying the k8s secret file with credentials from the existing database</span></li>\n</ol>\n<h3>Modifying the Source Database</h3>\n<p><span>For this method, the workaround I used was capturing all of the operator generated credentials on the empty cluster via </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-toolkit/LATEST/pt-show-grants.html\"><span>pt-show-grants</span></a><span>:</span></p><pre class=\"crayon-plain-tag\">pt-show-grants --only=clustercheck,monitor,operator,proxyadmin,root,xtrabackup</pre><p><span>I then applied these grants to the source server (</span><b>in practice, I would never do this</b><span>, but this was just an exercise with dummy data).  Once the credentials were updated and confirmed, I then took the S3 streaming backup and the restore went off without a hitch.</span></p>\n<h3>Modifying the Secrets File</h3>\n<p><span>For the second workaround, there are some assumptions:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You know all the users created by the operator by default</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Those users exist (or can be created) on the source database</span></li>\n</ol>\n<p><span>In this workaround, I grabbed the password(s) from the existing source cluster as the first step.  Once I had them base64 encoded, it was just a matter of editing the secrets created with the new cluster.  I only needed to modify the dbaas-* generated secrets as that was kept in sync with all the other secret files.</span></p>\n<p><span>The main thing in the process &#8211; ensure the secrets file is updated BEFORE kicking off the restore job.  Secrets are only reloaded when pods are terminated and restarted, so doing that cleanly is important.  The restore job does a few things:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Pull the backup from S3 into a new container</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Prepare and validate the backup</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Stop the old cluster</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Restart the cluster with the freshly prepared backup </span></li>\n</ol>\n<p><span>Assuming you have the secrets file in place before starting the job, the new credentials will be picked up nicely when the cluster restarts and all will go well.  Otherwise, you’ll be looking at lots of manual battles and debugging.</span></p>\n<h2>Other Limitations</h2>\n<p><span>The other primary limitation with the current release is that the source needs to also be running 8.0.  As the restore procedure uses xtrabackup-80 for the process, providing a 5.7 backup will result in the following error:</span></p><pre class=\"crayon-plain-tag\">This version of Percona XtraBackup can only perform backups and restores against MySQL 8.0 and Percona Server 8.0, please use Percona Xtrabackup 2.4 for this database.</pre><p><span>To handle a 5.7 -&#62; 8.0 migration, you would need to do a logical dump/reload of the databases in question.  Like the binary restore, the user credentials will be problematic so it would be preferable to omit the user tables.  This process comes with the standard 5.7 -&#62; 8.0 challenges, but it is possible.  </span></p>\n<h3>Summary</h3>\n<p><span>As this process is not supported (or even recommended) in the current release, I’ve omitted some details and configuration from this post.  Despite the challenges and the process being a little rough around the edges, it was great to validate xtrabackup restoration and replication into k8s from an external source.</span></p>\n<p><span>I’m excited to see the progress in the coming months as our DBaaS offering approaches GA.  With features like UX management of the process and MySQL user migration on the roadmap, it should be much easier in the future to migrate existing databases into Kubernetes. </span></p>\n<p><span>With the investments we are seeing around large k8s deployments, it would be a shame to limit it to new applications.  As the  <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\" target=\"_blank\" rel=\"noopener\">Percona Distribution for MySQL Operator</a> continues to evolve along with the DBaaS interface, the options should be unlimited.  As always, if you need help evaluating an existing architecture or migrating into Kubernetes, don’t hesitate to reach out to our Professional Services team! </span></p>\n","descriptionType":"html","publishedDate":"Mon, 14 Jun 2021 13:43:41 +0000","feedId":11,"bgimg":"","linkMd5":"1c4df3783474eeb76d845e9e789bff49","bgimgJsdelivr":"","metaImg":"","author":"Mike Benshoof","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn64@2020_2/2021/07/13/17-22-05-400_9e96df84615279a6.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-1024x351.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn91@2020_5/2021/07/13/17-21-57-146_3c74b870739e84e3.webp"},"publishedOrCreatedDate":1626196914585},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MongoDB Integrated Alerting in Percona Monitoring and Management","link":"https://www.percona.com/blog/?p=76563","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MongoDB Integrated Alerting\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76718\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-300x168.png\" alt=\"MongoDB Integrated Alerting\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" /><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM) recently introduced the Integrated Alerting feature as a technical preview. This was a very eagerly awaited feature, as PMM doesn&#8217;t need to integrate with an external alerting system anymore. Recently we blogged about <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/12/18/percona-monitoring-and-management-introduces-integrated-alerting-in-v2-13-via-a-technical-preview/\">the release</a> of this feature.</p>\n<p>PMM includes some built-in templates, and in this post, I am going to show you how to add your own alerts.</p>\n<h2>Enable Integrated Alerting</h2>\n<p>The first thing to do is navigate to the PMM Settings by clicking the wheel on the left menu, and choose Settings:</p>\n<p><img loading=\"lazy\" class=\"alignnone wp-image-76571 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-1024x549.png\" alt=\"\" width=\"900\" height=\"483\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-1024x549.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-300x161.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-200x107.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-367x197.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM.png 1255w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>Next, go to Advanced Settings, and click on the slider to enable Integrated Alerting down in the “Technical Preview” section.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76578 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-1024x706.png\" alt=\"\" width=\"900\" height=\"621\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-1024x706.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-300x207.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-200x138.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-367x253.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM.png 1349w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>While you&#8217;re here, if you want to enable SMTP or Slack notifications you can set them up right now by clicking the new Communications tab (which shows up after you hit &#8220;Apply Changes&#8221; turning on the feature).</p>\n<p>The example below shows how to configure email notifications through Gmail:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76676 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-1024x707.png\" alt=\"\" width=\"900\" height=\"621\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-1024x707.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-300x207.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-200x138.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-367x253.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM.png 1095w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>You should now see the Integrated Alerting option in the left menu under Alerting, so let&#8217;s go there next:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76577 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-1024x370.png\" alt=\"\" width=\"900\" height=\"325\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-1024x370.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-300x108.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-200x72.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-367x133.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM.png 1312w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h2></h2>\n<h2>Configuring Alert Destinations</h2>\n<p>After clicking on the Integrated Alerting option, go to the Notification Channels to configure the destination for your alerts. At the time of this writing, email via your SMTP server, Slack and PagerDuty are supported.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76576 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-1024x565.png\" alt=\"\" width=\"900\" height=\"497\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-1024x565.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-300x165.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-200x110.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-367x202.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM.png 1449w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h2>Creating a Custom Alert Template</h2>\n<p>Alerts are defined using <a target=\"_blank\" href=\"https://docs.victoriametrics.com/MetricsQL.html\">MetricsQL</a> which is backward compatible with Prometheus QL. As an example, let&#8217;s configure an alert to let us know if MongoDB is down.</p>\n<p>First, let&#8217;s go to the Explore option from the left menu. This is the place to play with the different metrics available and create the expressions for our alerts:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76574 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM.png\" alt=\"\" width=\"649\" height=\"450\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM.png 649w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM-300x208.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM-200x139.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM-367x254.png 367w\" sizes=\"(max-width: 649px) 100vw, 649px\" /></p>\n<p>To identify MongoDB being down, one option is using the up metric. The following expression would give us the alert we need:</p><pre class=\"crayon-plain-tag\">up{service_type=\"mongodb\"}</pre><p>To validate this, I shut down a member of a 3-node replica set and verified that the expression returns 0 when the node is down:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76579 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-1024x320.png\" alt=\"\" width=\"900\" height=\"281\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-1024x320.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-300x94.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-200x63.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-1536x481.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-367x115.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM.png 1895w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>The next step is creating a template for this alert. I won&#8217;t go into a lot of detail here, but you can check <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/04/16/integrated-alerting-design-in-percona-monitoring-and-management/\">Integrated Alerting Design in Percona Monitoring and Management</a> for more information about how templates are defined.</p>\n<p>Navigate to the Integrated Alerting page again, and click on the Add button, then add the following template:</p><pre class=\"crayon-plain-tag\">---\ntemplates:\n  - name: MongoDBDown\n    version: 1\n    summary: MongoDB is down\n    expr: |-\n      up{service_type=\"mongodb\"} == 0\n    severity: critical\n    annotations:\n      summary: MongoDB is down ({{ $labels.service_name }})\n      description: |-\n        MongoDB {{ $labels.service_name }} on {{ $labels.node_name }} is down</pre><p>This is how it looks like:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76573 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-1024x542.png\" alt=\"\" width=\"900\" height=\"476\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-1024x542.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-300x159.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-200x106.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-367x194.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM.png 1446w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>Next, go to the Alert Rules and create a new rule. We can use the Filters section to add comma-separated &#8220;key=value&#8221; pairs to filter alerts per node, per service, per agent, etc.</p>\n<p>For example: node_id=/node_id/123456, service_name=mongo1, agent_id=/agent_id/123456</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76572 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-1024x713.png\" alt=\"\" width=\"900\" height=\"627\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-1024x713.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-300x209.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-200x139.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-367x256.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM.png 1449w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>After you are done, hit the Save button and go to the Alerts dashboard to see if the alert is firing:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76584 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-1024x401.png\" alt=\"\" width=\"900\" height=\"352\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-1024x401.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-300x117.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-200x78.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-1536x601.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-1140x445.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-367x144.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM.png 1902w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>From this page, you can also silence any firing alerts.</p>\n<p>If you configured email as a destination, you should have also received a message like this one:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76675 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM.png\" alt=\"\" width=\"606\" height=\"721\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM.png 606w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM-252x300.png 252w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM-126x150.png 126w, https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM-367x437.png 367w\" sizes=\"(max-width: 606px) 100vw, 606px\" /></p>\n<p>For now, a single notification is sent. In the future, it will be possible to customize the behavior.</p>\n<h2>Creating MongoDB Alerts</h2>\n<p>In addition to the obvious &#8220;MongoDB is down&#8221; alert, there are a couple more things we should monitor. For starters, I&#8217;d suggest creating alerts for the following conditions:</p>\n<ul>\n<li>Replica set member in an unusual state</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">mongodb_replset_member_state != 1 and mongodb_replset_member_state != 2</pre><p></p>\n<ul>\n<li>Connections higher than expected</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">avg by (service_name) (mongodb_connections{state=\"current\"}) &#62; 5000</pre><p></p>\n<ul>\n<li>Cache evictions higher than expected</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">avg by(service_name, type) (rate(mongodb_mongod_wiredtiger_cache_evicted_total[5m])) &#62; 5000</pre><p></p>\n<ul>\n<li>Low WiredTiger tickets</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">avg by(service_name, type) (max_over_time(mongodb_mongod_wiredtiger_concurrent_transactions_available_tickets[1m])) &#60; 50</pre><p>The values listed above are just for illustrative purposes, you need to decide the proper thresholds for your specific environment(s).</p>\n<p>As another example, let&#8217;s add the alert template for the low WiredTiger tickets:</p><pre class=\"crayon-plain-tag\">---\ntemplates:\n  - name: MongoDB Wiredtiger Tickets\n    version: 1\n    summary: MongoDB Wiredtiger Tickets low\n    expr: avg by(service_name, type) (max_over_time(mongodb_mongod_wiredtiger_concurrent_transactions_available_tickets[1m])) &#60; 50\n    severity: warning\n    annotations:\n      description: \"WiredTiger available tickets on (instance {{ $labels.node_name }}) are less than 50\"</pre><p></p>\n<h2>Conclusion</h2>\n<p>Integrated alerting is a really nice to have feature. While it is still in tech preview state, we already have a few built-in alerts you can test, and also you can define your own. Make sure to check the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/using/alerting.html\">Integrated Alerting official documentation</a> for more information about this topic.</p>\n<p>Do you have any specific MongoDB alerts you&#8217;d like to see? Given the feature is still in technical preview, any contributions and/or feedback about the functionality are welcome as we’re looking to release this as GA very soon!</p>\n","descriptionType":"html","publishedDate":"Mon, 14 Jun 2021 15:42:49 +0000","feedId":11,"bgimg":"","linkMd5":"a03697da25f9fe29acca8989e5f2f380","bgimgJsdelivr":"","metaImg":"","author":"Ivan Groenewold","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn92@2020_2/2021/07/13/17-22-09-973_e3a0caab26d845c0.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn23@2020_6/2021/07/13/17-22-09-971_ea17e532ce803373.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-1024x549.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn96@2020_5/2021/07/13/17-22-08-800_a5d8f3f2eb639b37.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-1024x706.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn67@2020_3/2021/07/13/17-22-10-605_f8e0f84be8411e59.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-1024x707.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn44@2020_3/2021/07/13/17-22-05-545_80e006c40e834852.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-1024x370.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn27@2020_6/2021/07/13/17-22-10-126_f1a5d456a8406700.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-1024x565.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn68@2020_5/2021/07/13/17-22-09-932_77e5466ee82bc55e.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn84@2020_3/2021/07/13/17-22-08-941_895f7bf89d0810ba.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-1024x320.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn3@2020_4/2021/07/13/17-22-10-184_9361a6546784bff3.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-1024x542.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn71@2020_3/2021/07/13/17-21-55-178_2494aab9af9dd727.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-1024x713.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn47@2020_4/2021/07/13/17-22-10-479_cd3ce6f6a145318d.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-1024x401.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn12@2020_1/2021/07/13/17-22-08-069_b6df9cf062d11343.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn51@2020_1/2021/07/13/17-22-09-603_8d2b327eb77ede16.webp"},"publishedOrCreatedDate":1626196914578},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Migrating Ownership of Your Stored Routines, Views, and Triggers in MySQL","link":"https://www.percona.com/blog/?p=77159","description":"<img width=\"200\" height=\"107\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-200x107.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Migrating Ownership MySQL\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-200x107.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-300x160.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-1024x546.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-367x196.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><i><img loading=\"lazy\" class=\"alignright size-medium wp-image-77264\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-300x160.png\" alt=\"Migrating Ownership MySQL\" width=\"300\" height=\"160\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-300x160.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-1024x546.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-200x107.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-367x196.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />“It would be nice to have an option, that would allow to suppress the DEFINER statement in the CREATE VIEW statements generated by mysqldump. This would help when transferring data structures between databases with different security models.” </i></p>\n<h3>TLDR;</h3>\n<p>Use <a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/mysqlpump.html\">mysqlpump</a> with option<pre class=\"crayon-plain-tag\">--skip-definer</pre> instead of <pre class=\"crayon-plain-tag\">mysqldump</pre>.</p>\n<h3>The Story</h3>\n<p>This was requested as <a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=24680\">MySQL Bug #24680</a> on Nov 29, 2006. This feature request got large Community support. Even if we cannot see the number of people who voted for this request, the number of comments is impressive.</p>\n<p>The request is very reasonable: <pre class=\"crayon-plain-tag\">mysqldump</pre> is widely used during application development and it is a very common practice to migrate database structure between developers&#8217; machines and to the production servers.</p>\n<p>Imagine a situation where developer Sveta creates a database and adds few objects with <pre class=\"crayon-plain-tag\">DEFINER</pre>  clauses there. We will use only one for this post but in reality, she can have dozens.</p><pre class=\"crayon-plain-tag\">mysql&#62; CREATE VIEW large_tables AS SELECT * FROM information_schema.tables WHERE DATA_LENGTH &#62; 100000000;\nQuery OK, 0 rows affected (0,01 sec)</pre><p>Once you create a view default <pre class=\"crayon-plain-tag\">DEFINER</pre>  is the user who created this view:</p><pre class=\"crayon-plain-tag\">mysql&#62; SELECT DEFINER, TABLE_SCHEMA, TABLE_NAME FROM information_schema.views WHERE TABLE_NAME='large_tables';\n+---------+--------------+--------------+\n| DEFINER | TABLE_SCHEMA | TABLE_NAME   |\n+---------+--------------+--------------+\n| sveta@% | definers     | large_tables |\n+---------+--------------+--------------+\n1 row in set (0,01 sec)</pre><p>And this causes issues when another user tries to import such a view into a different server:</p><pre class=\"crayon-plain-tag\">mysql&#62; CREATE USER production;\nQuery OK, 0 rows affected (0,01 sec)\n\nmysql&#62; GRANT ALL ON definers.* TO production@'%';\nQuery OK, 0 rows affected (0,01 sec)\n\nmysql&#62; GRANT SESSION_VARIABLES_ADMIN ON *.* TO production@'%';\nQuery OK, 0 rows affected (0,01 sec)\n\n$ mysqldump -usveta definers | mysql -uproduction production\nERROR 1227 (42000) at line 61: Access denied; you need (at least one of) the SUPER or SET_USER_ID privilege(s) for this operation</pre><p>Here is the content of line 61:</p><pre class=\"crayon-plain-tag\">$ mysqldump -usveta definers | head -n 62 | tail\n/*!50001 DROP VIEW IF EXISTS `large_tables`*/;\n/*!50001 SET @saved_cs_client          = @@character_set_client */;\n/*!50001 SET @saved_cs_results         = @@character_set_results */;\n/*!50001 SET @saved_col_connection     = @@collation_connection */;\n/*!50001 SET character_set_client      = utf8mb4 */;\n/*!50001 SET character_set_results     = utf8mb4 */;\n/*!50001 SET collation_connection      = utf8mb4_0900_ai_ci */;\n/*!50001 CREATE ALGORITHM=UNDEFINED */\n/*!50013 DEFINER=`sveta`@`%` SQL SECURITY DEFINER */</pre><p>So this is a <pre class=\"crayon-plain-tag\">CREATE VIEW</pre>  operation that failed during import.</p>\n<p>Unfortunately, <pre class=\"crayon-plain-tag\">mysqldump</pre> still does not have an option that allows migrating definers.</p>\n<p>But since August 2015 and MySQL 5.7.8 we have a solution that, unfortunately, was overlooked in favor of the famous tool <pre class=\"crayon-plain-tag\">mysqldump</pre>.</p>\n<p>Version 5.7.8 and all which created after it, come with a new dump tool: <pre class=\"crayon-plain-tag\">mysqlpump</pre>  that has the option <pre class=\"crayon-plain-tag\">--skip-definer</pre>  and allows to migrate database objects without any issue:</p><pre class=\"crayon-plain-tag\">$ mysqlpump -h127.0.0.1 -P3306 -usveta --skip-definer definers | mysql -h127.0.0.1 -P13000 -uproduction definers\nDump completed in 17\n\n$ mysql -h127.0.0.1 -P13000 -uproduction definers -e \"SHOW FULL TABLES\"\n+--------------------+------------+\n| Tables_in_definers | Table_type |\n+--------------------+------------+\n| large_tables       | VIEW       |\n+--------------------+------------+\n\n$ mysql -h127.0.0.1 -P13000 -uproduction definers -e \"SELECT DEFINER, TABLE_SCHEMA, TABLE_NAME FROM information_schema.views WHERE TABLE_NAME='large_tables';\"\n+--------------+--------------+--------------+\n| DEFINER      | TABLE_SCHEMA | TABLE_NAME   |\n+--------------+--------------+--------------+\n| production@% | definers     | large_tables |\n+--------------+--------------+--------------+</pre><p>Note that <pre class=\"crayon-plain-tag\">mysqlpump</pre>automatically adds <pre class=\"crayon-plain-tag\">CREATE DATABASE</pre>  into the dump and full path to the database objects. E.g. <pre class=\"crayon-plain-tag\">CREATE ALGORITHM=UNDEFINED VIEW `definers`.`large_tables` AS select …</pre>  Therefore this method cannot be used to migrate view, routine, or trigger definitions between different databases on the same server.</p>\n<p>For more information about <pre class=\"crayon-plain-tag\">mysqlpump</pre> and why you should switch to this tool from <pre class=\"crayon-plain-tag\">mysqldump</pre> read this blog post, <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/04/17/the-mysqlpump-utility/\">The mysqlpump Utility</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 07 Jul 2021 13:23:18 +0000","feedId":11,"bgimg":"","linkMd5":"62029c87db3e05447872e34e8cc8241c","bgimgJsdelivr":"","metaImg":"","author":"Sveta Smirnova","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-200x107.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn56@2020_2/2021/07/13/17-22-06-557_1c362d0eca692e9b.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-300x160.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn36@2020_2/2021/07/13/17-22-08-272_8b34b3cdfc5311bc.webp"},"publishedOrCreatedDate":1626196914556},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Autoscaling Databases in Kubernetes for MongoDB, MySQL, and PostgreSQL","link":"https://www.percona.com/blog/?p=76820","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"autoscaling databases kubernetes mongodb mysql\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76959\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-300x168.png\" alt=\"autoscaling databases kubernetes mongodb mysql\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />At some point, your needs for improving database performance may run into a threshold where optimization and tuning are no longer enough. If you cannot change the database engine and can no longer tune the parameters for your workload, you need to use scaling.</p>\n<p>As it is widely known, scaling may be either vertical or horizontal. Vertical scaling means adding more resources to a single node. Usually is not related to database architecture in any special way &#8211; you just use faster storage (drives with better i/o capacity) or use different storages for different partitions, etc. On the contrary, horizontal scaling (adding and removing nodes) is all about distributed databases.</p>\n<p>So we can say that vertical scaling is mainly node-specific, and horizontal scaling is specific to database architecture. <b>That’s why we are going to deal with horizontal scaling in this post.</b></p>\n<p>Horizontal scaling is especially problematic in the case of mainstream database management systems initially designed for single-node usage: storage and computational load are not segregated within them, and clusters are maintained by having several full redundant copies of the same data.</p>\n<p>Automating this adds even more complexity because your database should be scaled out before the actual load increases and scaled in when the load decreases.</p>\n<p>To what extent is it possible to automate horizontal scaling of MongoDB, MySQL, and PostgreSQL databases in Kubernetes,  and how do you do it? Let’s try to find the answers.</p>\n<p>Before getting into the practical solution, we should recall some theory:</p>\n<ul>\n<li aria-level=\"1\">How to scale read and write requests in the reviewed databases, and why should they be scaled separately?</li>\n<li aria-level=\"1\">What are the possibilities to automate these scales?</li>\n</ul>\n<div class=\"highlight-default\">\n<h2>Scaling Writes</h2>\n<p>The nature of databases divides scaling into two very different parts: writes scaling and reads scaling.</p>\n<p>Typically, when changing database engine and tuning are out of scope, write requests are not significantly scalable in a relational database &#8211; you still need to write data to each node in the cluster. The only way to scale writes horizontally is to use <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Shard_(database_architecture)\">database shards</a> when data is spread across multiple database instances and there is some additional component that redirects queries to needed instances.</p>\n<p>If you have to scale writes, but database engine change, tuning, and sharding are not considered, you are limited to vertical scaling of your node resources. Sharding can be implemented in several ways: It can be supported by a specific database management system natively; if there is no native support, there may be a third-party extension for such functionality; finally, you can implement shards manually on the application level, separating portions of data and using different endpoints/connections. Generally, it worth choosing the easiest one among the available ways, if there are no additional considerations.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-76821 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis.jpg\" alt=\"Autoscaling Databases in Kubernetes\" width=\"873\" height=\"444\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis.jpg 873w, https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis-300x153.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis-200x102.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis-367x187.jpg 367w\" sizes=\"(max-width: 873px) 100vw, 873px\" /></p>\n</div>\n<div>\n<p>Let us quickly list all the possibilities.</p>\n<p><b>Sharding in MongoDB</b> is the easiest because it is a native feature of this database. For Kubernetes, MongoDB sharding is supported by the Percona Kubernetes Operators in your Percona Distribution for MongoDB environment. You can find information about enabling this feature <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/sharding.html\">here</a>.</p>\n<p><b>Sharding in MySQL</b> currently has several implementations:</p>\n<ul>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://vitess.io/docs/reference/features/sharding/\">Automated implementation</a> from Vitess</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://www.mysql.com/products/cluster/\">MySQL NDB Cluster from Oracle</a></li>\n<li aria-level=\"1\">Manual implementation based on ProxySQL query rules (<a target=\"_blank\" href=\"https://www.percona.com/blog/2017/04/12/proxysql-applying-and-chaining-the-rules/\">this blog post</a> explains how to create a sort of a primitive sharding with several tables and guess on the user’s level which of them to use for writes).</li>\n</ul>\n<p><b>Sharding in PostgreSQL</b> also can be implemented automatically or manually.</p>\n<ul>\n<li aria-level=\"1\">You can implement sharding by the <a target=\"_blank\" href=\"https://www.citusdata.com/\">Citus PostgreSQL extension</a>  (Citus Data, the company behind it, was acquired by Microsoft in 2019). Here is a <a target=\"_blank\" href=\"https://blog.dbi-services.com/sharding-with-postgresql/\">blog post</a> about implementing sharded database with it.</li>\n<li aria-level=\"1\">Also, you can create a sharded database manually <a target=\"_blank\" href=\"https://www.percona.com/blog/2019/05/24/an-overview-of-sharding-in-postgresql-and-how-it-relates-to-mongodbs/\">following this approach</a>, which combines declarative partitioning and PostgreSQL’s Foreign Data Wrapper.</li>\n</ul>\n<h2>Scaling Reads</h2>\n<p>Of course, sharding helps a lot with scaling reads also, but in many cases sharding is not mandatory if you just have to scale reads without scaling writes. Scaling reads can be reached with different caching techniques as well. But it can be done even simpler: you can scale reads by increasing the number of replicas and using <i>reads and writes splitting</i>.</p>\n<p><b>Reads and writes splitting in MongoDB</b> can be done in the following ways:</p>\n<ul>\n<li aria-level=\"1\">By a database driver if sharding is off,</li>\n<li aria-level=\"1\">By mongos if sharding is on.</li>\n</ul>\n<p>If you use the standard MongoDB driver, you already have splitting (just chose secondary, secondaryPreferred, or nearest <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/core/read-preference/\">read preference</a> instead of the default primary one); you can even control the <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/write-concern/\">write concern</a>.</p>\n<p><b>Reads and writes splitting in MySQL</b> can be done as follows:</p>\n<ul>\n<li aria-level=\"1\">With <a target=\"_blank\" href=\"https://proxysql.com/\">ProxySQL</a>,</li>\n<li aria-level=\"1\">On the application level (just use two endpoints, one for writes and one for reads with HAProxy in front of the database).</li>\n</ul>\n<p><b>Reads and writes splitting in PostgreSQL</b>:</p>\n<ul>\n<li aria-level=\"1\">By a database driver &#8211; but not all PostgreSQL drivers support reads and writes split: e.g. <a target=\"_blank\" href=\"https://www.postgresql.org/docs/13/libpq-connect.html#LIBPQ-MULTIPLE-HOSTS\">libpq</a> (native PostgreSQL driver) supports it, but <a target=\"_blank\" href=\"https://github.com/brianc/node-postgres\">node-postgres</a> (NodeJS applications driver) does not.</li>\n<li aria-level=\"1\">If your PostgreSQL driver doesn’t support splitting, you can split reads and writes with <a target=\"_blank\" href=\"https://www.pgpool.net\">Pgpool</a> proxy.</li>\n<li aria-level=\"1\">You can also make different connections for reads and writes in your application.</li>\n</ul>\n<h2>Autoscaling Reads</h2>\n<p>How can we do horizontal scaling for read requests?</p>\n<p>When you increase the number of members in your cluster, one member should do a backup, send this backup to a new member, and restore this backup (at least, that’s how databases do it currently in Kubernetes).</p>\n<p>For example, you have configured reads-writes splitting, and you have a cluster of two members. At the very moment when you scale it for 3 members, the read performance undergoes <i>a substantial decrease </i>(up to two times when done by Kubernetes Operators, because connections from the donor will be routed out) until you finish the backup saving process. After the backup restore is done, you will get the actual read performance increase.</p>\n<p><b><i>Note: </i></b><i>of course you can tweak connections to gain a less significant performance decrease &#8211; but in this case, it will take longer until your database reaches the target performance, which you supposedly need as soon as possible.</i></p>\n<p>That’s why we can’t scale automatically based on exceeding the current productivity of our two members. We should scale the cluster in advance. But you can predict your load in advance only if you know that there will be a peak load in some specific hours, so you can scale-out <i>before</i> this moment.</p>\n<p><img loading=\"lazy\" class=\"size-full wp-image-76822 aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33.png\" alt=\"\" width=\"500\" height=\"331\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33.png 500w, https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33-300x199.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33-200x132.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33-367x243.png 367w\" sizes=\"(max-width: 500px) 100vw, 500px\" /></p>\n<p>So, only scheduled scale-out makes sense.</p>\n<h2>Horizontal Autoscaling &#8211; The Kubernetes Way</h2>\n<p>If you use a dedicated Operator with your database clusters such as <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\">Percona Kubernetes Operator for Percona XtraDB Cluster</a>, scaling can be simplified even more. Let us see an example of doing this for the MySQL cluster managed by the Percona XtraDB Cluster Operator.</p>\n<p>You can scale the cluster out and in with the following command:</p><pre class=\"crayon-plain-tag\">kubectl scale --replicas=5 pxc/cluster1</pre><p><b><i>Note: </i></b><i>make sure that </i><i>kubectl scale</i><i> command is supported by the Operator you are using, if any. For example, Percona XtraDB Cluster Operator supports it only in per-namespace/non-clusterwide mode, starting from version 1.8.0, and some other Operators may lack this feature at all. Also, it is a good idea to refer to your Operators documentation for any scaling-related specifics which may affect autoscaling. For example, both Percona XtraDB Cluster Operator and Percona Operator for Percona Server for MongoDB have </i><i>allowUnsafeConfigurations</i><i> option, which should be turned on to prevent the Operator from changing the number of instances to safe defaults (the Operators carefully prevent all potentially unsafe combinations such as odd or even number of instances, etc., and this may conflict with autoscaling).</i></p>\n<p>Finally, if the temporary performance decrease is not a problem in your case, you can try using  <a target=\"_blank\" href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\">Horizontal Pod Autoscaler</a> which will scale your database cluster dynamically, based on some metrics (such as CPU utilization) instead of making scheduled scales. Percona XtraDB Cluster Operator allows you to do it with a config similar to the next one:</p><pre class=\"crayon-plain-tag\">apiVersion: autoscaling/v2beta1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: cluster1\nspec:\n  minReplicas: 3\n  maxReplicas: 5\n  metrics:\n  - resource:\n      name: cpu\n      targetAverageUtilization: 2\n    type: Resource\n  scaleTargetRef:\n    apiVersion: pxc.percona.com/v1\n    kind: PerconaXtraDBCluster\n    name: cluster1</pre><p></p>\n<h3>Conclusion</h3>\n<p>As we&#8217;ve shown, horizontal scaling of traditional databases falls into two very different tasks: scaling reads and scaling writes. The only way to scale writes horizontally is to use database sharding. Horizontal scaling of reads involves read/write splitting<i>. </i>Both sharding and read/write splitting can be done in different ways for the considered databases, and generally, the less native way implementation you chose, the more efforts it may take to bring it up.</p>\n<p>As far as horizontal autoscaling is concerned, it is a possible option, but scaling out is associated with a temporary large drop in performance. Therefore, it usually makes sense as a scale-on-schedule related to the planned load change.</p>\n<p>Finally, Kubernetes can automate scaling even more, but any database-related Operators in use should be checked for their compatibility with native Kubernetes scaling capabilities.</p>\n</div>\n","descriptionType":"html","publishedDate":"Wed, 23 Jun 2021 14:07:18 +0000","feedId":11,"bgimg":"","linkMd5":"103c5f9566a00742f8f7cb310ce26b0a","bgimgJsdelivr":"","metaImg":"","author":"Dmitriy Kostiuk","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn40@2020_1/2021/07/13/17-22-17-707_328aee9a84dec889.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn80@2020_1/2021/07/13/17-22-10-904_4fe3b1fa59759bd2.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn56@2020_2/2021/07/13/17-22-17-883_5aa93cfddd476fc5.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn95@2020_6/2021/07/13/17-22-07-847_44fc39a38666dc16.webp"},"publishedOrCreatedDate":1626196914572},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Webinar July 6: Converting MongoDB to Percona Server for MongoDB","link":"https://www.percona.com/blog/?p=76666","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-200x105.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Converting MongoDB to Percona Server\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-200x105.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-300x157.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-1024x536.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-1140x595.jpg 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-367x192.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social.jpg 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p data-pm-slice=\"1 1 []\"><img loading=\"lazy\" class=\"alignright size-medium wp-image-76932\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-300x157.jpg\" alt=\"Converting MongoDB to Percona Server\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-300x157.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-1024x536.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-200x105.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-1140x595.jpg 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-367x192.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social.jpg 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Join Percona experts Michal Nosek and Dimitri Vanoverbeke as they walk through the task of migrating a MongoDB database to Percona Server for MongoDB (PSMDB).</p>\n<p><em>BY THE END OF THIS HANDS-ON WORKSHOP YOU WILL BE ABLE TO</em>:</p>\n<p>&#8211; Uninstall MongoDB and install Percona Server for MongoDB</p>\n<p>&#8211; Convert a stand-alone MongoDB server to Percona Server for MongoDB</p>\n<p>&#8211; Add Percona Server for MongoDB to an existing MongoDB replica set</p>\n<p>&#8211; Convert a MongoDB replica set to a Percona Server for MongoDB replica set</p>\n<p>Please join <strong>Michal Nosek</strong> and <strong>Dimitri Vanoverbeke</strong> on <strong>July 6, 2021,</strong> at <strong>1:00 PM BST</strong> for their webinar <strong>Converting MongoDB to Percona Server for MongoDB</strong>.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://www.brighttalk.com/webcast/18708/493406?utm_source=Percona&#38;utm_medium=brighttalk&#38;utm_campaign=493406\" rel=\"noopener\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://www.brighttalk.com/webcast/18708/493406?utm_source=Percona&#38;utm_medium=brighttalk&#38;utm_campaign=493406\">sign up anyway</a>, and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Tue, 15 Jun 2021 17:28:20 +0000","feedId":11,"bgimg":"","linkMd5":"819f8ee7a79f56fb58e8f8af81dad30b","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-200x105.jpg":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn20@2020_2/2021/07/13/17-22-17-819_3ff5eedfaaefab73.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-300x157.jpg":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn64@2020_3/2021/07/13/17-21-55-184_068ff24938819aef.webp"},"publishedOrCreatedDate":1626196914572},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Understanding pg_repack: What Can Go Wrong – and How to Avoid It","link":"https://www.percona.com/blog/?p=76724","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Understanding pg_repack\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><a target=\"_blank\" href=\"https://reorg.github.io/pg_repack/\">pg_repack</a> is one of the oldest, widely used, extension projects for PostgreSQL. It is so much popular that even DBaaS service providers couldn&#8217;t avoid it. It is a &#8220;power tool&#8221; in the hands of a DBA to deal with bloated/fragmented tables. I can&#8217;t imagine a serious production deployment without it these days. It magically replaces the bloated, fragmented tables with a fresh fully packed table without holding an exclusive lock on the table during its processing**. This extension made PostgreSQL&#8217;s built-in commands like VACUUM FULL and CLUSTER almost useless.</p>\n<p><em>**Momentarily AccessExclusive locks are required. Please see the discussion below.</em></p>\n<p>But unfortunately, regular and repeated usage of pg_repack increased the comfort levels of everyone (myself included). As a consequence, it is randomly recommended as a solution for everything, as a panacea. But I recently started coming across cases like a scheduled job doing pg_repack of every table. This time it rang an alarm bell and it started to feel like <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Antibiotic_misuse\">overuse of antibiotics</a>. So I thought about writing about how pg_repack works and how it can affect your system while it is running for a regular user who doesn&#8217;t want to do a detailed study. because a better understanding might help for an informed decision on where it should be used.</p>\n<p>pg_repack has a lot of functionalities (options). In this blog post, my intention is to discuss only how it does the basic &#8220;repack&#8221;ing of a fragmented/bloated table.</p>\n<h2>Pre-Checks and Ensuring Sanity</h2>\n<p>This is to ensure that pg_repack is installed and extension is available in the database, we are running the pg_repack as a superuser, etc. It creates a provision for cleaning up temporary objects created by pg_repack. It collects metadata about tables and associated objects like Indexes, Toast, Triggers, etc. because tracking of tables and associated objects is very important. Objects like invalid indexes, conflicting triggers, etc. are checked. We are not going to discuss this in detail.</p>\n<p>The actual processing starts with obtaining an advisory lock on the table&#8217;s OID, to make sure no other pg_repack is working on the table. This is not so much a concern with full-table repacks, but mainly so that index-only repacks don&#8217;t interfere with each other or a full-table repack. If there are other pg_repaks in progress, repack attempts may get a message as follows and exit.</p><pre class=\"crayon-plain-tag\">ERROR: Another pg_repack command may be running on the table. Please try again later.</pre><p></p>\n<h3>Create temporary objects while holding AccessExclusive lock on the table</h3>\n<p>Yes. Correct, pg_repack needs the heavyweight <strong>AccessExclusive</strong> lock. But temporarily.  pg_repack attempts to gain a table ACCESS EXCLUSIVE lock by executing a statement as follows:</p>\n<div>\n<pre class=\"crayon-plain-tag\">LOCK TABLE &#60;tablename&#62; IN ACCESS EXCLUSIVE MODE</pre></p>\n<div>\n<div>An Access Exclusive lock requires that no other sessions are accessing the table, Not even a SELECT query. pg_repack wait for a &#8220;wait-time&#8221; (60 seconds by default). This wait-time can be changed using the optional parameter <code>--wait-timeout</code>. Once this wait-time is over pg_repack will start trying to cancel the conflicting statements.  Users may see messages as follows for each of the attempts.</div>\n<div>\n<pre class=\"crayon-plain-tag\">WARNING: canceling conflicted backends\nWARNING: canceling conflicted backends\n...</pre>\n</div>\n<p>So the point to be noted is:</p>\n<p><strong>So please avoid running pg_repack when there is a lot of concurrent activities on the table. because the new sessions are allowed to get conflicting locks like ACCESS SHARE concurrently and a session waiting for ACCESS EXCLUSIVE lock may need to wait indefinitely. We should be selecting a proper time window of low activity for pg_repack work<br />\n</strong></p>\n<p>These cancel attempts will continue for another round of &#8220;<span class=\"option\"><span class=\"lang:sh decode:true crayon-inline\">wait-timeout</span></span>&#8221; seconds. But even after attempting for this second round of wait-timeout, if the AcessExclusive lock is not obtained, it escalates to termination of every conflicting session. So pg_repack will terminate sessions if the total wait time exceeds double the &#8220;wait-time&#8221;. This could be problematic for application connections that get abruptly get terminated. This can lead to outages if the application layer does not handle it gracefully.</p>\n<p>The pg_repack may emit a message as follows:</p><pre class=\"crayon-plain-tag\">WARNING: terminating conflicted backends</pre><p></p>\n<div>And there will be PostgreSQL log entries as follows for each of the sessions which is killed</div>\n<p></p><pre class=\"crayon-plain-tag\">2021-06-17 06:28:46.317 UTC [2761] FATAL: terminating connection due to administrator command\n2021-06-17 06:28:46.317 UTC [2758] FATAL: terminating connection due to administrator command</pre><p></p>\n<div>\n<div>\n<div>\n<p>So the point to be noted is: <strong>pg_repack can terminate sessions if they stand against obtaining AcessExclusive lock which can lead to unexpected outage or misbehavior of the application.</strong></p>\n<p>If the double the wait time is crossed, pg_repack may just proceed with terminate the sessions. But, again this behavior also can be controlled using a parameter <code>--no-kill-backend</code>.  if this parameter is specified, pg_repack will respect all concurrent sessions and cancel itself instead of attempting to canceling or terminating other sessions<br />\npg_repack may emit a message as follows</p><pre class=\"crayon-plain-tag\">WARNING: timed out, do not cancel conflicting backends\nINFO: Skipping repack public.t1 due to timeout</pre><p>I believe this is more desirable in production systems. So the point to be noted is:</p>\n<div><strong>Always remember to specify <code>--no-kill-backend</code> whenever you deal with critical systems</strong></div>\n<div></div>\n<div>\n<p>When AccessExclusive is locked, pg_repack creates all temporary objects including the substituted table with the same structure.</p>\n</div>\n<div>It creates a primary key TYPE as per the original table. For example, if we are repacking a table with a primary key of a single field &#8220;id&#8221;, the primary key type definition would look like:</div>\n<p></p><pre class=\"crayon-plain-tag\">CREATE TYPE repack.pk_16423 AS (id integer)</pre><p></p>\n<div>This TYPE of definition is useful because there can be composite keys. The following is an example of it dealing with tables of a composite key.</div>\n<div>\n<div>\n<pre class=\"crayon-plain-tag\">CREATE TYPE repack.pk_16824 AS (id integer, id1 integer, id2 timestamp without time zone);</pre></p>\n<div>Then It proceeds to create a &#8220;log&#8221; table to capture all the data changes (CDC-Change data capture) during the pg_repack operation. This table will have a primary key of BIGINT data type, Primary key type of the original table created in the above step, and &#8220;row&#8221; datatype of the table which we are repacking. This row can hold the entire tuple information of the table which we repack.</div>\n<div></div>\n<div>This log table definition is easy because of the TYPE definition and the &#8220;row&#8221; type. here is an example</div>\n<p></p><pre class=\"crayon-plain-tag\">CREATE TABLE repack.log_16423 (id bigserial PRIMARY KEY, pk repack.pk_16423, row public.t1)</pre><p>Now pg_repack creates a trigger on the table to be repacked so that whenever there is DML on the table, corresponding information needs to be captured to the log table created above. This is done using an AFTER INSERT OR DELETE OR UPDATE trigger. For example:</p><pre class=\"crayon-plain-tag\">CREATE TRIGGER repack_trigger AFTER INSERT OR DELETE OR UPDATE ON public.t1 FOR EACH ROW EXECUTE PROCEDURE repack.repack_trigger('INSERT INTO repack.log_16423(pk, row) VALUES( CASE WHEN $1 IS NULL THEN NULL ELSE (ROW($1.id)::repack.pk_16423) END, $2)')</pre><p>Since the pg_repack is holding the AccessExclusive lock at this stage, there won&#8217;t be any concurrent DMLs at this stage, which is going to change in the following stages.</p>\n<p>pg_repack plays an important trick at this stage before releasing AcessExclusive lock as the <a target=\"_blank\" href=\"https://github.com/reorg/pg_repack/blob/ebc8a425fcabc06d62a1c9b51fbc3a5f460b2baa/bin/pg_repack.c#L1270\">comment in the source code</a> says:</p><pre class=\"crayon-plain-tag\">/* While we are still holding an AccessExclusive lock on the table, submit\n* the request for an AccessShare lock asynchronously from conn2.\n* We want to submit this query in conn2 while connection's\n* transaction still holds its lock, so that no DDL may sneak in\n* between the time that connection commits and conn2 gets its lock.\n*/</pre><p>Yes, pg_repack uses another connection to the database and sends an AccessShare lock request through that. This prevents any DDL in between the switch to AccessShare lock. The moment the main connection commits, An AccessShare lock will be granted to the second connection. So <strong>pg_repack uses two database connections</strong> to carry out the work.</p>\n<p>But still, there is a chance that some DDL can interfere. So <strong>pg_repack <a target=\"_blank\" href=\"https://github.com/reorg/pg_repack/blob/ebc8a425fcabc06d62a1c9b51fbc3a5f460b2baa/bin/pg_repack.c#L1565\">kills any concurrent DDL</a> against the table</strong> by default.</p>\n<p>Once this stage is complete pg_repack can proceed with releasing AccessExclusive lock on the first connection by <code>COMMIT</code>ing the transaction. So that the AccessShare lock request by the second connection will be granted. This COMMIT is very special that all the log table and triggers on the table will be committed so that it is available to the entire system from this point onwards.</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3>Copying rows/tuples to a temporary table</h3>\n<p>Copying of tuples from the table to a new table is performed with SERIALIZABLE isolation. because there shouldn&#8217;t be any inconsistency between the data getting into the log table and the temporary, substitute table which pg_repack is going to create.</p><pre class=\"crayon-plain-tag\">BEGIN ISOLATION LEVEL SERIALIZABLE</pre><p>Since the AccessExclusive lock is removed, concurrent sessions can proceed with their DMLs and Select queries. Only DDLs will be blocked. So we can say that the table is available for transactions and queries.</p>\n<p>Prior to the data copy, the log table is truncated. because pg_repack needs only those log data that is captured from the starting of data copy.</p><pre class=\"crayon-plain-tag\">DELETE FROM repack.log_16423</pre><p>Again pg_repack will attempt to kill any session which might be waiting for doing a DDL and get an AcessShare lock on the table. Since the other connection is already holding an AccessShare lock, This can be gained without much problem.</p>\n<p>At this stage, pg_repack creates a substitute table that is going to replace the original table with the exact same structure as the original table but without any data. It will be a CTAS statement, something like:</p><pre class=\"crayon-plain-tag\">CREATE TABLE repack.table_16423... AS SELECT col1,col2,col3... FROM ONLY public.t1 WITH NO DATA</pre><p>followed by the data copy:</p><pre class=\"crayon-plain-tag\">INSERT INTO repack.table_16423 SELECT col1,col2,co3... FROM ONLY public.t1</pre><p>Once the data copy is over, the transaction will be COMMIT ed. This completes one heaviest stage in repacking in terms of load and WAL generation</p>\n<p>Indexes, Keys will be created at this stage on this temporary, substitute table at this stage.</p>\n<h3>Apply the CDC log to a temporary table</h3>\n<p>Please remember that pg_repack&#8217;s main connection is not holding any lock on the table at this stage (other than the second connection&#8217;s AccessShare lock).  So There is nothing blocking the transactions (DMLs) at this stage. Depending on the time it took for the data copy in the previous stage, and concurrent transactions during the data copy, There could be a lot of CDC(Change Data Capture) entries in the log file. This needs to be copied to the new temporary/substitute table.</p>\n<p>This logic is implemented as C function in pg_repack. you may refer to the source code of <a target=\"_blank\" href=\"https://github.com/reorg/pg_repack/blob/ebc8a425fcabc06d62a1c9b51fbc3a5f460b2baa/lib/repack.c#L226\">repack_apply</a>. It reads all the data from the log table and processes INSERTS, UPDATES, and DELETES. In order to speed up the repeated operations, Prepared Statements are used. Finally, all those data from the log table which is processed will be deleted from the log table.</p>\n<h3>Swapping the original table with a temporary table</h3>\n<p>This is performed by the second connection because it already holds an AccessShare lock, But it will escalate the lock to AccessExclusive lock.</p><pre class=\"crayon-plain-tag\">LOCK TABLE public.t1 IN ACCESS EXCLUSIVE MODE</pre><p>The CDC apply will be performed once again (The same &#8220;repack_apply&#8221;) while holding the AccessExclusive lock on the table. So if there is any new entry that appears in the log table, that also will be processed.</p>\n<p>The original table and the temporary table quickly by executing repack_swap function like:</p><pre class=\"crayon-plain-tag\">SELECT repack.repack_swap('16423');</pre><p>This is the most beautiful and powerful part of pg_repack. which is implemented in a C function <a target=\"_blank\" href=\"https://github.com/reorg/pg_repack/blob/ebc8a425fcabc06d62a1c9b51fbc3a5f460b2baa/lib/repack.c#L823\"><span class=\"pl-en\">repack_swap</span></a>. Not just tables are swapped, ownership, associated toasts (table and index), indexes, and dependencies are also swapped. Oids are swapped so that the oid of the table remains the same even after pg_repack. The Swapping work complies with a COMMIT</p>\n<h3>Final cleanup</h3>\n<p>pg_repack uses its built-in C Function <a target=\"_blank\" href=\"https://github.com/reorg/pg_repack/blob/ebc8a425fcabc06d62a1c9b51fbc3a5f460b2baa/lib/repack.c#L995\"><span class=\"pl-en\">repack_drop</span></a> for doing the cleanup of all temporary objects. To prevent any concurrent sessions from acquiring a lock on the table which could prevent the cleanup, An AccessExclusive lock is obtained before the cleanup. This is the third time an AccessExcluive lock is placed on the table.</p>\n<h2>Summary</h2>\n<p>pg_repack is one of the most powerful, popular, and useful extensions. We encourage the usage wherever applicable with proper supervision. But please avoid over-usage. As I tried to explain,  we should expect a good amount of data movement between the original table to the temporary table, trigger writing to the log table, data copy from the log table to the temporary table, etc. So we should be expecting a higher WAL generation also. Considering all the implications, pg_repack needs to be performed on a low activity time window to avoid undesirable consequences.</p>\n<p>Some of the important points to reiterate for end-users are:</p>\n<ol>\n<li>pg_repack needs to acquire heavyweight AccessExclusive lock multiple times. But Temporarily.</li>\n<li>In a high concurrency situation, it will be almost impossible to get an AccessExclusive lock</li>\n<li>pg_repack, by default, will attempt canceling the conflicting statements if it is not able to gain AcessExclusive lock-in wait-time</li>\n<li>It may proceed to terminate sessions if the total wait exceeds double the amount of wait time. This could lead to undesirable outcomes and outages.</li>\n<li>Defaults of pg_repack may not be good for critical systems. use <strong><code>--no-kill-backend</code></strong> option to make it more gentle.</li>\n<li>No DDLs are allowed against the table which is undergoing pg_repack and any session that attempts to do so might get killed.</li>\n</ol>\n</div>\n</div>\n","descriptionType":"html","publishedDate":"Thu, 24 Jun 2021 13:04:08 +0000","feedId":11,"bgimg":"","linkMd5":"6dadeb3ac69f7954b4a1be520eac22c9","bgimgJsdelivr":"","metaImg":"","author":"Jobin Augustine","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn79@2020_4/2021/07/13/17-22-07-846_60411da68bbc41e6.webp"},"publishedOrCreatedDate":1626196914576},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Updated Percona Distribution for PostgreSQL Versions, Percona Distribution for MySQL 8.0.23: Release Roundup June 21, 2021","link":"https://www.percona.com/blog/?p=76526","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Release Roundup June 21 2021\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright size-medium wp-image-76782\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-300x169.png\" alt=\"Percona Release Roundup June 21 2021\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />It&#8217;s release roundup time again here at Percona!</h2>\n<p>Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download. This roundup includes a lot of releases, so be sure to check them all out!</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since June 7, 2021, including Percona Distribution for MySQL 8.0.23 (Percona XtraDB Cluster variant) and new versions of Percona Distribution for PostgreSQL with fixes for Red Hat Enterprise Linux 8/CentOS 8.</p>\n<p>&#160;</p>\n<h2>Percona Distribution for MySQL (PXC-based variant) 8.0.23</h2>\n<p>On June 9, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-distribution-mysql/8.0/index.html\">Percona Distribution for MySQL (PXC-based variant) 8.0.23</a> was released. Percona Distribution for MySQL is a single solution with the best and most critical enterprise components from the MySQL open source community, designed and tested to work together.  The Percona XtraDB Cluster-based deployment provides a high grade of high availability (4-5 nines) and almost instant failover.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/percona-distribution-mysql-pxc/LATEST/\">Download Percona Distribution for MySQL (PXC-based variant) 8.0.23</a></p>\n<p>&#160;</p>\n<h2>Percona Distribution for PostgreSQL</h2>\n<p>On June 10, 2021, we released the following new versions of <a target=\"_blank\" href=\"https://www.percona.com/software/postgresql-distribution\">Percona Distribution for PostgreSQL</a>, all of which include fixes for Red Hat Enterprise Linux 8/CentOS 8.</p>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"><strong>Percona Distribution for PostgreSQL 13</strong></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/13/release-notes-v13.3.upd.html\">Percona Distribution for PostgreSQL 13.3 Release Notes</a></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/13/release-notes-v13.2.upd4.html\">Percona Distribution for PostgreSQL 13.2 Release Notes</a></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"><strong>Percona Distribution for PostgreSQL 12</strong></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/12/release-notes-v12.7.upd.html\">Percona Distribution for PostgreSQL 12.7 Release Notes</a></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/12/release-notes-v12.6.upd4.html\">Percona Distribution for PostgreSQL 12.6 Release Notes</a></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"><strong>Percona Distribution for PostgreSQL 11</strong></div>\n<div dir=\"ltr\"></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/11/release-notes-v11.12.upd.html\">Percona Distribution for PostgreSQL 11.12 Release Notes</a></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/11/release-notes-v11.11.upd3.html\">Percona Distribution for PostgreSQL 11.11 Release Notes</a></div>\n<div dir=\"ltr\"><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/11/release-notes-v11.10.upd.html\">Percona Distribution for PostgreSQL 11.10 Release Notes</a></div>\n<p>&#160;</p>\n<h2>Percona Server for MongoDB 4.0.25-20</h2>\n<p>On June 17, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/4.0/release_notes/4.0.25-20.html\">Percona Server for MongoDB 4.0.25-20</a> was released. It is an enhanced, open source, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 4.0.25 Community Edition, supporting MongoDB 4.0.25 protocols and drivers. In this release, bug <a target=\"_blank\" class=\"reference external\" href=\"https://jira.percona.com/browse/PSMDB-210\">PSMDB-210</a> was fixed, where hot backup should respect killOp() requests.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/percona-server-mongodb-4.0/LATEST/\">Download Percona Server for MongoDB 4.0.25-20</a></p>\n<p>&#160;</p>\n<h2>Percona XtraDB Cluster 8.0.23-14.1</h2>\n<p>June 9, 2021, saw the release of <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/LATEST/release-notes/Percona-XtraDB-Cluster-8.0.23-14.1.html\">Percona XtraDB Cluster 8.0.23-14.1</a>. It&#8217;s a free, open source, enterprise-grade solution that includes the high availability and security features your business needs to meet customer expectations and business goals. An improvement in this release is to log a warning at startup if a keyring is specified, but the cluster traffic encryption is turned off. In addition, there are several bug fixes, which can be reviewed in the release notes.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraDB-Cluster-LATEST/\">Download Percona XtraDB Cluster 8.0.23-14.1</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"noopener\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n","descriptionType":"html","publishedDate":"Mon, 21 Jun 2021 07:48:47 +0000","feedId":11,"bgimg":"","linkMd5":"0a78b8d6ce35d6eafe698c607c1cf30d","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn33@2020_2/2021/07/13/17-22-08-089_33e393aa37add02a.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn76@2020_5/2021/07/13/17-22-11-831_1206f85aa340d0ff.webp"},"publishedOrCreatedDate":1626196914582},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"PostgreSQL HA with Patroni: Your Turn to Test Failure Scenarios","link":"https://www.percona.com/blog/?p=76405","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"PostgreSQL HA with Patroni\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span>A couple of weeks ago, Jobin and I did a short presentation during </span><b>Percona Live Online</b><span> bearing a similar title as the one for this post: “</span><a target=\"_blank\" href=\"https://www.percona.com/resources/videos/postgresql-ha-patroni-looking-failure-scenarios-and-how-cluster-recovers-them\"><i><span>PostgreSQL HA With Patroni: Looking at Failure Scenarios and How the Cluster Recovers From Them</span></i></a><span>”. We deployed a 3-node PostgreSQL environment with some recycled hardware we had lying around and set ourselves at “breaking” it in different ways: by unplugging network and power cables, killing main processes, attempting to saturate processors. All of this while continuously writing and reading data from PostgreSQL. The idea was to see how Patroni would handle the failures and manage the cluster to continue delivering service. It was a fun demo!</span></p>\n<p><span>We promised a follow-up post explaining how we set up the environment, so you could give it a try yourselves, and this is it. We hope you also have fun attempting to reproduce our small experiment, but mostly that you use it as an opportunity to learn how a PostgreSQL HA environment managed by Patroni works in practice: there is nothing like a hands-on lab for this!</span></p>\n<h2>Initial Setup</h2>\n<p><span>We recycled three 10-year old Intel Atom mini-computers for our experiment but you could use some virtual machines instead: even though you will miss the excitement of unplugging real cables, this can still be simulated with a VM. We installed the server version of Ubuntu 20.04 and configured them to know “each other” by hostname; here’s how the </span><i><span>hosts</span></i><span> file of the first node looked like:</span></p><pre class=\"crayon-plain-tag\">$ cat /etc/hosts\n127.0.0.1 localhost node1\n192.168.1.11 node1\n192.168.1.12 node2\n192.168.1.13 node3</pre><p></p>\n<h2>etcd</h2>\n<p><span>Patroni supports a myriad of systems for </span><a target=\"_blank\" href=\"https://github.com/zalando/patroni#patroni-a-template-for-postgresql-ha-with-zookeeper-etcd-or-consul\"><span>Distribution Configuration Store</span></a><span> but </span><i><span>etcd</span></i><span> remains a popular choice. We installed the version available from the Ubuntu repository on all three nodes:</span></p><pre class=\"crayon-plain-tag\">sudo apt-get install etcd</pre><p><span>It is necessary to initialize the etcd cluster from one of the nodes and we did that from node1 using the following configuration file:</span></p><pre class=\"crayon-plain-tag\">$ cat /etc/default/etcd\nETCD_NAME=node1\nETCD_INITIAL_CLUSTER=\"node1=http://192.168.1.11:2380\"\nETCD_INITIAL_CLUSTER_TOKEN=\"devops_token\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.1.11:2380\"\nETCD_DATA_DIR=\"/var/lib/etcd/postgresql\"\nETCD_LISTEN_PEER_URLS=\"http://192.168.1.11:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://192.168.1.11:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.1.11:2379\"</pre><p><span>Note how </span><span>ETCD_INITIAL_CLUSTER_STATE</span><span> is defined with “new”.</span></p>\n<p><span>We then restarted the service:</span></p><pre class=\"crayon-plain-tag\">sudo systemctl restart etcd</pre><p><span>We can then move on to install etcd on node2. The configuration file follows the same structure as that of node1, except that we are adding node2 to an existing cluster so we should indicate the other node(s):</span></p><pre class=\"crayon-plain-tag\">ETCD_NAME=node2\nETCD_INITIAL_CLUSTER=\"node1=http://192.168.1.11:2380,node2=http://192.168.1.12:2380\"\nETCD_INITIAL_CLUSTER_TOKEN=\"devops_token\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.1.12:2380\"\nETCD_DATA_DIR=\"/var/lib/etcd/postgresql\"\nETCD_LISTEN_PEER_URLS=\"http://192.168.1.12:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://192.168.1.12:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.1.12:2379\"</pre><p><span>Before we restart the service, we need to formally add node2 to the etcd cluster by running the following command on node1:</span></p><pre class=\"crayon-plain-tag\">sudo etcdctl member add node2 http://192.168.1.12:2380</pre><p><span>We can then restart the etcd service on node2:</span></p><pre class=\"crayon-plain-tag\">sudo systemctl restart etcd</pre><p><span>The configuration file for node3 looks like this:</span></p><pre class=\"crayon-plain-tag\">ETCD_NAME=node3\nETCD_INITIAL_CLUSTER=\"node1=http://192.168.1.11:2380,node2=http://192.168.1.12:2380,node3=http://192.168.1.13:2380\"\nETCD_INITIAL_CLUSTER_TOKEN=\"devops_token\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.1.13:2380\"\nETCD_DATA_DIR=\"/var/lib/etcd/postgresql\"\nETCD_LISTEN_PEER_URLS=\"http://192.168.1.13:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://192.168.1.13:2379,http://localhost:2379\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.1.13:2379\"</pre><p><span>Remember we need to add node3 to the cluster by running the following command on node1:</span></p><pre class=\"crayon-plain-tag\">sudo etcdctl member add node3 http://192.168.1.13:2380</pre><p><span>before we can restart the service on node3:</span></p><pre class=\"crayon-plain-tag\">sudo systemctl restart etcd</pre><p><span>We can verify the cluster state to confirm it has been deployed successfully by running the following command from any of the nodes:</span></p><pre class=\"crayon-plain-tag\">$ sudo etcdctl member list\n2ed43136d81039b4: name=node3 peerURLs=http://192.168.1.13:2380 clientURLs=http://192.168.1.13:2379 isLeader=false\nd571a1ada5a5afcf: name=node1 peerURLs=http://192.168.1.11:2380 clientURLs=http://192.168.1.11:2379 isLeader=true\necec6c549ebb23bc: name=node2 peerURLs=http://192.168.1.12:2380 clientURLs=http://192.168.1.12:2379 isLeader=false</pre><p><span>As we can see above, node1 is the leader at this point, which is expected since the etcd cluster has been bootstrapped from it. If you get a different result, check for etcd entries logged to </span><em><span>/var/log/syslog</span></em><span> on each node.</span></p>\n<h2>Watchdog</h2>\n<p><span>Quoting </span><a target=\"_blank\" href=\"https://patroni.readthedocs.io/en/latest/watchdog.html?highlight=watchdog#watchdog-support\"><span>Patroni’s manual</span></a><span>:</span></p>\n<blockquote><p><i><span>Watchdog devices are software or hardware mechanisms that will reset the whole system when they do not get a keepalive heartbeat within a specified timeframe. This adds an additional layer of fail safe in case usual Patroni split-brain protection mechanisms fail.</span></i></p></blockquote>\n<p><span>While the use of a watchdog mechanism with Patroni is optional, you shouldn’t really consider deploying a PostgreSQL HA environment in production without it.</span></p>\n<p><span>For our tests, we used the standard software implementation for watchdog that is shipped with Ubuntu 20.04, a module called </span><i><span>softdog</span></i><span>. Here’s the procedure we used in all three nodes to configure the module to load:</span></p><pre class=\"crayon-plain-tag\">sudo sh -c 'echo \"softdog\" &#62;&#62; /etc/modules'</pre><p><span>Patroni will be the component interacting with the watchdog device. Since Patroni is run by the </span><i><span>postgres</span></i><span> user, we need to either set the permissions of the watchdog device open enough so the </span><i><span>postgres </span></i><span>user can write to it or make the device owned by </span><i><span>postgres</span></i><span> itself, which we consider a safer approach (as it is more restrictive):</span></p><pre class=\"crayon-plain-tag\">sudo sh -c 'echo \"KERNEL==\\\"watchdog\\\", OWNER=\\\"postgres\\\", GROUP=\\\"postgres\\\"\" &#62;&#62; /etc/udev/rules.d/61-watchdog.rules'</pre><p><span>These two steps looked like all that would be required for watchdog to work but to our surprise, the </span><i><span>softdog</span></i><span> module wasn’t loaded after restarting the servers. After spending quite some time digging around we figured the module was blacklisted by default and there was a strain file with such a directive still lingering around:</span></p><pre class=\"crayon-plain-tag\">$ grep blacklist /lib/modprobe.d/* /etc/modprobe.d/* |grep softdog\n/lib/modprobe.d/blacklist_linux_5.4.0-72-generic.conf:blacklist softdog</pre><p><span>Editing that file in each of the nodes to remove the line above and restarting the servers did the trick:</span></p><pre class=\"crayon-plain-tag\">$ lsmod | grep softdog\nsoftdog                16384  0</pre><p></p><pre class=\"crayon-plain-tag\">$ ls -l /dev/watchdog*\ncrw-rw---- 1 postgres postgres  10, 130 May 21 21:30 /dev/watchdog\ncrw------- 1 root     root     245,   0 May 21 21:30 /dev/watchdog0</pre><p></p>\n<h2>PostgreSQL</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/postgresql-distribution\"><i><span>Percona Distribution for PostgreSQL</span></i></a><span> can be easily installed from the Percona Repository in a few easy steps:</span></p><pre class=\"crayon-plain-tag\">sudo apt-get update -y; sudo apt-get install -y wget gnupg2 lsb-release curl\nwget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\nsudo dpkg -i percona-release_latest.generic_all.deb\nsudo apt-get update\nsudo percona-release setup ppg-12\nsudo apt-get install percona-postgresql-12</pre><p><span>An important concept to understand in a PostgreSQL HA environment like this one is that PostgreSQL should not be started automatically by systemd during the server initialization: we should leave it to Patroni to fully manage it, including the process of starting and stopping the server. Thus, we should disable the service:</span></p><pre class=\"crayon-plain-tag\">sudo systemctl disable postgresql</pre><p><span>For our tests, we want to start with a fresh new PostgreSQL setup and let Patroni bootstrap the cluster, so we stop the server and remove the data directory that has been created as part of the PostgreSQL installation:</span></p><pre class=\"crayon-plain-tag\">sudo systemctl stop postgresql\nsudo rm -fr /var/lib/postgresql/12/main</pre><p><span>These steps should be repeated in nodes 2 and 3 as well.</span></p>\n<h2>Patroni</h2>\n<p><span>The Percona Repository also includes a package for Patroni so with it already configured in the nodes we can install Patroni with a simple:</span></p><pre class=\"crayon-plain-tag\">sudo apt-get install percona-patroni</pre><p><span>Here’s the configuration file we have used for node1:</span></p><pre class=\"crayon-plain-tag\">$ cat /etc/patroni/config.yml\nscope: stampede\nname: node1\n\nrestapi:\n  listen: 0.0.0.0:8008\n  connect_address: node1:8008\n\netcd:\n  host: node1:2379\n\nbootstrap:\n  # this section will be written into Etcd:/&#60;namespace&#62;/&#60;scope&#62;/config after initializing new cluster\n  dcs:\n    ttl: 30\n    loop_wait: 10\n    retry_timeout: 10\n    maximum_lag_on_failover: 1048576\n#    master_start_timeout: 300\n#    synchronous_mode: false\n    postgresql:\n      use_pg_rewind: true\n      use_slots: true\n      parameters:\n        wal_level: replica\n        hot_standby: \"on\"\n        logging_collector: 'on'\n        max_wal_senders: 5\n        max_replication_slots: 5\n        wal_log_hints: \"on\"\n        #archive_mode: \"on\"\n        #archive_timeout: 600\n        #archive_command: \"cp -f %p /home/postgres/archived/%f\"\n        #recovery_conf:\n        #restore_command: cp /home/postgres/archived/%f %p\n\n  # some desired options for 'initdb'\n  initdb:  # Note: It needs to be a list (some options need values, others are switches)\n  - encoding: UTF8\n  - data-checksums\n\n  pg_hba:  # Add following lines to pg_hba.conf after running 'initdb'\n  - host replication replicator 192.168.1.1/24 md5\n  - host replication replicator 127.0.0.1/32 trust\n  - host all all 192.168.1.1/24 md5\n  - host all all 0.0.0.0/0 md5\n#  - hostssl all all 0.0.0.0/0 md5\n\n  # Additional script to be launched after initial cluster creation (will be passed the connection URL as parameter)\n# post_init: /usr/local/bin/setup_cluster.sh\n  # Some additional users users which needs to be created after initializing new cluster\n  users:\n    admin:\n      password: admin\n      options:\n        - createrole\n        - createdb\n\npostgresql:\n  listen: 0.0.0.0:5432\n  connect_address: node1:5432\n  data_dir: \"/var/lib/postgresql/12/main\"\n  bin_dir: \"/usr/lib/postgresql/12/bin\"\n#  config_dir:\n  pgpass: /tmp/pgpass0\n  authentication:\n    replication:\n      username: replicator\n      password: vagrant\n    superuser:\n      username: postgres\n      password: vagrant\n  parameters:\n    unix_socket_directories: '/var/run/postgresql'\n\nwatchdog:\n  mode: required # Allowed values: off, automatic, required\n  device: /dev/watchdog\n  safety_margin: 5\n\ntags:\n    nofailover: false\n    noloadbalance: false\n    clonefrom: false\n    nosync: false</pre><p><span>With the configuration file in place, and now that we already have the </span><i><span>etcd</span></i><span> cluster up, all that is required is to restart the Patroni service:</span></p><pre class=\"crayon-plain-tag\">sudo systemctl restart patroni</pre><p><b>When Patroni starts, it will take care of initializing PostgreSQL</b><span> (because the service is not currently running and the data directory is empty) following the directives in the </span><i><span>bootstrap </span></i><span>section of Patroni’s configuration file. If everything went according to the plan, you should be able to connect to PostgreSQL using the credentials in the configuration file (password is </span><i><span>vagrant</span></i><span>):</span></p><pre class=\"crayon-plain-tag\">$ psql -U postgres\npsql (12.6 (Ubuntu 2:12.6-2.focal))\nType \"help\" for help.\n\npostgres=#</pre><p><span>Repeat the operation for installing Patroni on nodes 2 and 3: the only difference is that you will need to replace the references to node1 in the configuration file (there are four of them, shown in </span><b>bold</b><span>) with the respective node name.</span></p>\n<p><span>You can also check the state of the Patroni cluster we just created with:</span></p><pre class=\"crayon-plain-tag\">$ sudo patronictl -c /etc/patroni/config.yml list\n+----------+--------+-------+--------+---------+----+-----------+\n| Cluster  | Member |  Host |  Role  |  State  | TL | Lag in MB |\n+----------+--------+-------+--------+---------+----+-----------+\n| stampede | node1  | node1 | Leader | running |  2 |           |\n| stampede | node2  | node2 |        | running |  2 |         0 |\n| stampede | node3  | node3 |        | running |  2 |         0 |\n+----------+--------+-------+--------+---------+----+-----------+</pre><p><span>node1 started the Patroni cluster so it was automatically made the leader &#8211; and thus the primary/master PostgreSQL server. Nodes 2 and 3 are configured as read replicas (as the </span><i><span>hot_standby</span></i><span> option was enabled in Patroni’s configuration file).</span></p>\n<h2>HAProxy</h2>\n<p><span>A common implementation of high availability in a PostgreSQL environment makes use of a proxy: instead of connecting directly to the database server, the application will be connecting to the proxy instead, which will forward the request to PostgreSQL. When </span><a target=\"_blank\" href=\"http://www.haproxy.org/\"><span>HAproxy</span></a><span> is used for this, it is also possible to route read requests to one or more replicas, for load balancing. However, this is not a transparent process: the application needs to be aware of this and split read-only from read-write traffic itself. With HAproxy, this is done by providing two different ports for the application to connect. We opted for the following setup:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Writes   →  5000</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Reads   →  5001</span></li>\n</ul>\n<p><span>HAproxy can be installed as an independent server (and you can have as many as you want) but it can also be installed on the application server or the database server itself &#8211; it is a light enough service. For our tests, we planned on using our own Linux workstations (which also run Ubuntu 20.04) to simulate application traffic so we installed HAproxy on them:</span></p><pre class=\"crayon-plain-tag\">sudo apt-get install haproxy</pre><p><span>With the software installed, we modified the main configuration file as follows:</span></p><pre class=\"crayon-plain-tag\">$ cat /etc/haproxy/haproxy.cfg\nglobal\n    maxconn 100\n\ndefaults\n    log    global\n    mode    tcp\n    retries 2\n    timeout client 30m\n    timeout connect 4s\n    timeout server 30m\n    timeout check 5s\n\nlisten stats\n    mode http\n    bind *:7000\n    stats enable\n    stats uri /\n\nlisten primary\n    bind *:5000\n    option httpchk OPTIONS /master\n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n\nlisten standbys\n    balance roundrobin\n    bind *:5001\n    option httpchk OPTIONS /replica\n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008</pre><p><span>Note there are two sections: </span><i><span>primary</span></i><span>, using port 5000, and </span><i><span>standbys</span></i><span>, using port 5001. All three nodes are included in both sections: that’s because they are all potential candidates to be either primary or secondary. For HAproxy to know which role each node currently has, it will send an HTTP request to port 8008 of the node: Patroni will answer. Patroni provides a built-in REST API support for </span><a target=\"_blank\" href=\"https://patroni.readthedocs.io/en/latest/rest_api.html#health-check-endpoints\"><span>health check monitoring</span></a><span> that integrates perfectly with HAproxy for this:</span></p><pre class=\"crayon-plain-tag\">$ curl -s http://node1:8008\n{\"state\": \"running\", \"postmaster_start_time\": \"2021-05-24 14:50:11.707 UTC\", \"role\": \"master\", \"server_version\": 120006, \"cluster_unlocked\": false, \"xlog\": {\"location\": 25615248}, \"timeline\": 1, \"database_system_identifier\": \"6965869170583425899\", \"patroni\": {\"version\": \"1.6.4\", \"scope\": \"stampede\"}}</pre><p><span>We configured the </span><i><span>standbys</span></i><span> group to balance read-requests in a round-robin fashion, so each connection request (or reconnection) will alternate between the available replicas. We can test this in practice, let’s save the </span><i><span>postgres</span></i><span> user password in a file to facilitate the process:</span></p><pre class=\"crayon-plain-tag\">echo \"localhost:5000:postgres:postgres:vagrant\" &#62; ~/.pgpass\necho \"localhost:5001:postgres:postgres:vagrant\" &#62;&#62; ~/.pgpass\nchmod 0600 ~/.pgpass</pre><p><span>We can then execute two read-requests to verify the round-robin mechanism is working as intended:</span></p><pre class=\"crayon-plain-tag\">$ psql -Upostgres -hlocalhost -p<strong>5001</strong> -t -c \"select inet_server_addr()\"\n 192.168.1.13</pre><p></p><pre class=\"crayon-plain-tag\">$ psql -Upostgres -hlocalhost -p<strong>5001</strong> -t -c \"select inet_server_addr()\"\n 192.168.1.12</pre><p><span>as well as test the writer access:</span></p><pre class=\"crayon-plain-tag\">$ psql -Upostgres -hlocalhost -p<strong>5000</strong> -t -c \"select inet_server_addr()\"\n 192.168.1.11</pre><p><span>You can also check the state of HAproxy by visiting </span><a target=\"_blank\" href=\"http://localhost:7000/\"><span>http://localhost:7000/</span></a><span> on your browser.</span></p>\n<h2>Workload</h2>\n<p><span>To best simulate a production environment to test our failure scenarios, we wanted to have continuous reads and writes to the database. We could have used a benchmark tool such as Sysbench or Pgbench but we were more interested in observing the switch of source server upon a server failure than load itself. Jobin wrote a simple Python script that is perfect for this, </span><a target=\"_blank\" href=\"https://github.com/jobinau/pgscripts/blob/main/patroni/HAtester.py\"><i><span>HAtester</span></i></a><span>. As was the case with HAproxy, we run the script from our Linux workstation. Since it is a Python script, you need to have a PostgreSQL driver for Python installed to execute it:</span></p><pre class=\"crayon-plain-tag\">sudo apt-get install python3-psycopg2\ncurl -LO https://raw.githubusercontent.com/jobinau/pgscripts/main/patroni/HAtester.py\nchmod +x HAtester.py</pre><p><span>Edit the script with the credentials to access the PostgreSQL servers (through HAproxy) if you are using different settings from ours. The only requirement for it to work is to have the target table created beforehand, so first connect to the </span><i><span>postgres </span></i><span>database (unless you are using a different target) in the Primary and run:</span></p><pre class=\"crayon-plain-tag\">CREATE TABLE HATEST (TM TIMESTAMP);</pre><p><span>You can then start two different sessions:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>One for writes:</span><span><br />\n</span><br />\n<pre class=\"crayon-plain-tag\">./HAtester.py 5000</pre>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>One for reads:</span><br />\n<pre class=\"crayon-plain-tag\">./HAtester.py 5001</pre>\n</li>\n</ol>\n<p><span>The idea is to observe what happens with database traffic when the environment experiences a failure; that is, how HAproxy will route reads and writes as Patroni adjusts the PostgreSQL cluster. You can continuously monitor Patroni from the point of view of the nodes by opening a session in each of them and running the following command:</span></p><pre class=\"crayon-plain-tag\">sudo -u postgres watch patronictl -c /etc/patroni/config.yml list</pre><p><span>To facilitate observability and better follow the changes in real-time, we used the terminal multiplexer </span><a target=\"_blank\" href=\"https://github.com/tmux/tmux/wiki\"><span>Tmux</span></a><span> to visualize all 5 sessions on the same screen:</span></p>\n<p><img loading=\"lazy\" class=\"alignnone wp-image-76410 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1.png\" alt=\"\" width=\"1270\" height=\"901\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1.png 1270w, https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1-300x213.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1-1024x726.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1-200x142.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1-367x260.png 367w\" sizes=\"(max-width: 1270px) 100vw, 1270px\" /></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>On the left side, we have one session open for each of the 3 nodes, continuously running:</span><span><br />\n</span><br />\n<pre class=\"crayon-plain-tag\">sudo -u postgres watch patronictl -c /etc/patroni/config.yml list</pre><br />\n<span>It’s better to have the Patroni view for each node independently because when you start the failure tests you will lose connection to a part of the cluster.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>On the right side, we are executing the </span><i><span>HAtester.py</span></i><span> script from our workstation:</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>Sending writes through port 5000:</span><span><br />\n</span><br />\n<pre class=\"crayon-plain-tag\">./HAtester.py 5000</pre>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>and reads through port 5001:</span><span><br />\n</span><br />\n<pre class=\"crayon-plain-tag\">./HAtester.py 5001</pre>\n</li>\n</ul>\n</li>\n</ul>\n<p><span>A couple of notes on the execution of the HAtester.py script:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Pressing </span><span>Ctrl+C</span><span> will break the connection but the script will reconnect, this time to a different replica (in the case of </span><i><span>reads</span></i><span>) due to having the </span><i><span>Standbys</span></i><span> group on HAproxy configured with round-robin balancing.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>When a switchover or failover takes place and the nodes are re-arranged in the cluster, you may temporarily see writes sent to a node that used to be a replica and was just promoted as primary and reads send to a node that used to be the primary and was demoted as secondary: that’s a limitation of the </span><i><span>HAtester.py</span></i><span> script but “by design”; we favored faster reconnections and minimal checks on the node’s role for demonstration purposes. On a production application, this part ought to be implemented differently.</span></li>\n</ul>\n<h2>Testing Failure Scenarios</h2>\n<p><span>The fun part starts now! We leave it to you to test and play around to see what happens with the PostgreSQL cluster in practice following a failure. We leave as suggestions the tests we did in our presentation. For each failure scenario, observe how the cluster re-adjusts itself and the impact on read and write traffic.</span></p>\n<h3>1) Loss of Network Communication</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Unplug the network cable from one of the nodes (or simulate this condition in your VM):</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>First from a replica</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>Then from the primary</span></li>\n</ul>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Unplug the network cable from one replica and the primary at the same time:</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>Does Patroni experience a split-brain situation?</span></li>\n</ul>\n</li>\n</ul>\n<h3>2) Power Outage</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Unplug the power cable from the primary</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Wait until the cluster is re-adjusted then plug the power cable back and start the node</span></li>\n</ul>\n<h3>3) SEGFAULT</h3>\n<p><span>Simulate an OOM/crash by killing the </span><i><span>postmaster </span></i><span>process in one of the nodes with </span><span>kill -9</span><span>.</span></p>\n<h3>4) Killing Patroni</h3>\n<p><span>Remember that Patroni is managing PostgreSQL. What happens if the Patroni process (and not PostgreSQL) is killed?</span></p>\n<h3>5) CPU Saturation</h3>\n<p><span>Simulate CPU saturation with a benchmark tool such as </span><a target=\"_blank\" href=\"https://github.com/akopytov/sysbench\"><i><span>Sysbench</span></i></a><span>, for example:</span></p><pre class=\"crayon-plain-tag\">sysbench cpu --threads=10 --time=0 run</pre><p><span>This one is a bit tricky as the reads and writes are each single-threaded operation. You may need to decrease the priority of the </span><i><span>HAtester.py</span></i><span> processes with </span><a target=\"_blank\" href=\"https://man7.org/linux/man-pages/man1/renice.1.html\"><span>renice</span></a><span>, and possibly increase that of </span><i><span>Sysbench</span></i><span>’s.</span></p>\n<h3>6) Manual Switchover</h3>\n<p><span>Patroni facilitates changes in the PostgreSQL hierarchy. Switchover operations can be scheduled, the command below is interactive and will prompt you with options:</span></p><pre class=\"crayon-plain-tag\">sudo -u postgres patronictl -c /etc/patroni/config.yml switchover</pre><p><span>Alternatively, you can be specific and tell Patroni exactly what to do:</span></p><pre class=\"crayon-plain-tag\">sudo -u postgres patronictl -c /etc/patroni/config.yml switchover --master node1 --candidate node2 --force</pre><p></p>\n<hr />\n<p><span>We hope you had fun with this hands-on lab! If you have questions or comments, leave us a note in the comments section below!</span></p>\n","descriptionType":"html","publishedDate":"Fri, 11 Jun 2021 12:02:25 +0000","feedId":11,"bgimg":"","linkMd5":"87a0c051ddb862948f6d2aa8a21d2836","bgimgJsdelivr":"","metaImg":"","author":"Fernando Laudares Camargos","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn15@2020_5/2021/07/13/17-22-08-947_0c8ab1ae9c0afb7e.webp","https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn80@2020_1/2021/07/13/17-22-08-651_edcdb868e58314c5.webp"},"publishedOrCreatedDate":1626196914588},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"MyDumper 0.10.7 is Now Available","link":"https://www.percona.com/blog/?p=76767","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MyDumper 0.10.7 is Now Available\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><div class=\"application-main \" data-commit-hovercards-enabled=\"\" data-discussion-hovercards-enabled=\"\" data-issue-and-pr-hovercards-enabled=\"\">\n<div class=\"\">\n<p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-77178\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-300x157.png\" alt=\"MyDumper 0.10.7 is Now Available\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />The new</span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/releases/tag/v0.10.7\"> <span>MyDumper 0.10.7</span></a><span> version, which includes many new features and bug fixes, is now available.  You can download the code from</span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/archive/refs/tags/v0.10.7.tar.gz\"><span> here</span></a><span>.</span></p>\n<p><span>For this release, we have added several features like WHERE support that is required for partial backups. We also added CHECKSUM for tables which help to speed up the restore of large tables to take advantage of fast index creation, and more.</span></p>\n<p><b>New Features</b><span>:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Adding metadata file per table that contains the number of rows </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/353\"><span>#353</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Adding &#8211;where support </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/347\"><span>#347</span></a> <a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/223\"><span>#223</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Option to automatically disable/enable REDO_LOG </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/305\"><span>#305</span></a> <a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/334\"><span>#334</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Adding wsrep_sync_wait support </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/327\"><span>#327</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Adding fast index creation functionality </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/286\"><span>#286</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Adding ORDER BY Primary Key functionality </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/227\"><span>#227</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Added support for dumping checksums </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/141\"><span>#141</span></a> <a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/194\"><span>#194</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Dump strings using single quote instead of double quotes </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/191\"><span>#191</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Specify the number of snapshots </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/118\"><span>#118</span></a></li>\n</ul>\n<p><b>Bug Fixes:</b></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Fixed the create database section when creating with &#8211;source-db enabled </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/213\"><span>#213</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Escaping quotes on detect_generated_fields as it caused segfault </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/349\"><span>#349</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>[usingfastindex] Indexes on AUTO_INCREMENT column should not be selected for fast index creation </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/322\"><span>#322</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Fixed checksum compression </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/355\"><span>#355</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Fixed as constraint was ignored </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/351\"><span>#351</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Fixed int declaration to comply with C99 </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/346\"><span>#346</span></a></li>\n</ul>\n<p><b>Documentation:</b></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Added s to install </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/360\"><span>#360</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Added libatomic1 dependency reference on ubuntu </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/358\"><span>#358</span></a> <a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/359\"><span>#359</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Release signatures </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/28\"><span>#28</span></a></li>\n</ul>\n<p><b>Refactoring:</b></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Moving detected_generated_fields as parameter in table_job </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/331\"><span>#331</span></a> <a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/333\"><span>#333</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Abstract function for io </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/332\"><span>#332</span></a></li>\n</ul>\n<p><b>Won&#8217;t-fix:</b></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Cannot dump Clustrix tables </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/issues/87\"><span>#87</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Extending support of WITH_BINLOG to MySQL 8.0 </span><a target=\"_blank\" href=\"https://github.com/maxbube/mydumper/pull/341\"><span>#341</span></a></li>\n</ul>\n</div>\n</div>\n","descriptionType":"html","publishedDate":"Tue, 06 Jul 2021 11:51:33 +0000","feedId":11,"bgimg":"","linkMd5":"7f6a7898f2c92d2bfa70ab2a587f28e0","bgimgJsdelivr":"","metaImg":"","author":"David Ducos","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn40@2020_2/2021/07/13/17-22-07-083_b1c2d2ed6e373697.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn36@2020_3/2021/07/13/17-21-54-982_7ea3ef23cce988a0.webp"},"publishedOrCreatedDate":1626196914565},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Boosting Percona Distribution for MySQL Operator Efficiency","link":"https://www.percona.com/blog/?p=76888","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Distribution for MySQL Operator Efficiency\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-76965\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-300x157.png\" alt=\"Percona Distribution for MySQL Operator Efficiency\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Percona is well known for its offer of several outstanding fully open source, <a target=\"_blank\" href=\"https://www.percona.com/software\">free-to-download</a> software packages. And while Percona started as a MySQL-focused company, nowadays it covers different technologies such as MySQL, PostgreSQL, and MongoDB.</span></p>\n<p><span>In its constant effort to make life easier for our users, Percona had moved from providing single software packages to Percona Distributions for MySQL, MongoDB, and PostgreSQL. Percona Distributions are a set of software packages that Percona has tested and certifies working together. These are easier to deploy architectural solutions requiring the use of multiple components, such as proxy, topology manager, backup software, and more. </span></p>\n<p><span>But we are going even further, and with the release of Percona Distribution for MySQL/MongoDB <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\">Operator</a>, </span><span>we are providing a high level of automation to roll out and manage solutions based on Percona Distributions. </span></p>\n<p><span>One of my tasks, as MySQL technical leader, is to identify optimal architectures to serve several common cases. Such as Percona Distribution for MySQL: <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/04/14/percona-distribution-for-mysql-high-availability-with-group-replication-solution/\">High Availability with Group Replication Solutio</a>n</span><span>. Or in the case of the Percona Distribution for MySQL Operator, identify the different dimensions (low/mid/high utilization) and suggest a Vanilla setup with the scope to get the most out of the solution deployed.  </span></p>\n<p><span>This is a long exercise, which started with a lot of internal discussions to identify what can make sense as traffic, then testing, identifying the saturation points, testing again, and so on. </span></p>\n<p><span>It is during this process that I found a small problem (<a target=\"_blank\" href=\"https://jira.percona.com/browse/K8SPXC-749\">Feature Request</a></span><span>). This small issue is preventing us from easily and dynamically modifying some parameters in the checks the Operator uses. Given that, we had to put the testing on hold until the above FR is implemented. As you can see it is a small thing, but it will give us better control over the Operator&#8217;s behavior and will help you to have a well-tuned platform. </span></p>\n<p><span>This article is to show the level of improvement you can have with small but targeted tuning. To do so, I used the smallest solution we have identified. The solution is dimensioned to serve a small website or a simple application with a low level of traffic. </span></p>\n<h2>The Environment</h2>\n<p><span>To help identify a balanced setup we were using sysbench and sysbench-tpcc. The whole stack on GCP was composed of Application nodes with sysbench, two ProxySQL nodes for R/W split only, three VMS 8 CPU 32GB RAM, with the Percona operator managing the MySQL service.</span></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram.png\"><img loading=\"lazy\" class=\"aligncenter wp-image-76889 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram.png\" alt=\"\" width=\"463\" height=\"496\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram.png 463w, https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram-280x300.png 280w, https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram-140x150.png 140w, https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram-367x393.png 367w\" sizes=\"(max-width: 463px) 100vw, 463px\" /></a></p>\n<h2>Tests</h2>\n<p><span>For this specific test we were running 68 &#8211; 96 -128 &#8211; 256 threads:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Sysbench read-only</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Sysbench read/write</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Sysbench Tpc-c like </span></li>\n</ul>\n<p><span>The tests were run multiple times and the data considered is the consolidation of the multiple runs. </span></p>\n<p><span>We always run first on basic environments for baseline. Meaning no tuning for the MySQL or Operator, just dimension correctly disk space and BufferPool (and related).</span></p>\n<p><span>Then we apply some tuning and run the tests multiple times eventually refining when/where needed. </span></p>\n<p>The code can be found <a target=\"_blank\" href=\"https://github.com/Tusamarco/sysbench\">here</a> and <a target=\"_blank\" href=\"https://github.com/Tusamarco/sysbench-tpcc\">here</a></p>\n<h2><em>And now the results…</em></h2>\n<h2>Sysbench r/w tests</h2>\n<p><span>I am not going to describe in detail the images that I think are clear enough. Just keep in mind on the left we have the results from our baseline, and on the right, the same tests on the same platform with the optimization applied.</span></p>\n<h3>Operations</h3>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6.png\"><img loading=\"lazy\" class=\"aligncenter wp-image-76891 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-1024x502.png\" alt=\"Sysbench r/w tests\" width=\"900\" height=\"441\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-1024x502.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-300x147.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-200x98.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-1536x753.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-2048x1004.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-367x180.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></p>\n<p><span>It&#8217;s worth mentioning that without tuning, the platform was not able to consistently scale up to 256 threads. While with a bit of adjustment not only it was able to serve 256 threads but we could have gone a bit further.</span></p>\n<h3>Reads</h3>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-76892\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-1024x502.png\" alt=\"\" width=\"900\" height=\"441\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-1024x502.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-300x147.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-200x98.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-1536x753.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-2048x1004.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-367x180.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></p>\n<h3>Writes</h3>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-76893\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-1024x502.png\" alt=\"\" width=\"900\" height=\"441\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-1024x502.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-300x147.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-200x98.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-1536x753.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-2048x1004.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-367x180.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></p>\n<h3>Comments</h3>\n<p><span>As you can see, the sysbench tests clearly indicate that the platform with minor adjustment was acting better and that it was able to serve more and with constant scaling. Let me add that almost all the tests run on the “basic” platform had incidents, meaning as soon as the traffic was increasing, Sysbench was reporting connection interruptions or errors.</span></p>\n<h2>TPC-C</h2>\n<h3>Operations</h3>\n<h3><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-76895\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-1024x506.png\" alt=\"\" width=\"900\" height=\"445\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-1024x506.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-300x148.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-200x99.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-1536x759.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-2048x1012.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-367x181.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></h3>\n<h3>Reads</h3>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-76896\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-1024x506.png\" alt=\"\" width=\"900\" height=\"445\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-1024x506.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-300x148.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-200x99.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-1536x759.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-2048x1012.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-367x181.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></p>\n<h3>Writes</h3>\n<h3><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-76897\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-1024x506.png\" alt=\"\" width=\"900\" height=\"445\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-1024x506.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-300x148.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-200x99.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-1536x759.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-2048x1012.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-367x181.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></h3>\n<h3>Comments</h3>\n<p><span>Also for Tpc-c like tests, we have exactly the same trend. Our “optimized” solution was able to serve up to 1516 qps while the “basic” one was able to reach only 322. In this case, the “optimized” solution was not able to scale up to 256 threads, but that makes sense, given the more intense write workload present in this test and the small dimension of the platform.</span></p>\n<h2>Woah, What Have You Changed?</h2>\n<p><span>You may think we have done crazy things to get this difference, but we did not.</span></p>\n<p><span>Let us jump back. As indicated at the beginning, I had opened an FR (</span><a target=\"_blank\" href=\"https://jira.percona.com/browse/K8SPXC-749\"><span>https://jira.percona.com/browse/K8SPXC-749</span></a><span>) to be able to tune some/most of the timeouts existing in the operator.</span></p>\n<p><span>Why? Think about this, when you install a cluster on iron, you do not set it to be able to work only when the load is low, and all the components of the server are able to answer in nanoseconds. What you do instead is tune the whole system to accommodate the increasing load, and you will give some elements more space for “flexibility”, eventually expecting to have delays in answer. When doing so you also need to correctly align all the parameters that will be affected by the cascade. For instance, if you know your data nodes will be very busy serving queries, they may also slow down in answering internal health checks, but if you relax the cluster health checks and not the checks used for testing the cluster from the operator point of view, the platform will be unbalanced and will not work correctly.</span></p>\n<p><span>At the same time, if you do not tune the solution at all, you may end up with a platform that is theoretically able to serve the load, but that is crashing for artificial limitations. </span></p>\n<p><span>The last one is exactly what was happening with our “basic” solution. As it is, the operator comes with parameters that allow it to work well, but that is not designed to scale. Is like having a server where your CPUs are always at 20% and if the applications ask more, a controller will chop them in fear of having too much load. But the fact is that you want to have the CPUs at 80% or the server will be underutilized. </span></p>\n<p><span>Anyhow, what we have changed was some InnoDB parameters, to allow internal operations to work better. Then we force consistent reads in PXC, which actually SLOW down the operations, and finally, we tune the PXC cluster to be more flexible in its internal checks, avoiding having it expel nodes unless really needed to. </span></p>\n<p><span>All the above were done using the Operator configuration, but then we had to work on </span><b>manually changing</b><span> all the timeouts parameters used by the operator checks to be aligned with what we had defined in the cluster. </span></p>\n<p><span>In particular, what we have changed was:</span></p><pre class=\"crayon-plain-tag\">script                      line    value\n/usr/bin/clustercheckcron   33      TIMEOUT=10\nliveness-check.sh           23      TIMEOUT=5\nreadiness-check.sh          21      TIMEOUT=10\n/usr/local/bin/check_pxc.sh 15      TIMEOUT=${CUSTOM_TIMEOUT:-10}</pre><p></p>\n<h2>Wait&#8230; Why ProxySQL?</h2>\n<p><span>Ok, this is another long discussion and I will cover it better in another article. For now, just consider that HAProxy does not allow r/w splitting or other nice functionalities like firewalling, etc. So the idea is simple, let us use the operator with what fits it better, and then decouple the special needs, eventually adding proxysql in a separate deployment. </span></p>\n<p><span>If you are scared of the cost of adding an additional block to the architecture:</span></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a.png\"><img loading=\"lazy\" class=\"wp-image-76883 aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-1024x514.png\" alt=\"\" width=\"745\" height=\"374\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-1024x514.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-300x151.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-200x100.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-1536x771.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-2048x1028.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-367x184.png 367w\" sizes=\"(max-width: 745px) 100vw, 745px\" /></a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b.png\"><img loading=\"lazy\" class=\"alignnone wp-image-76884\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-1024x338.png\" alt=\"\" width=\"742\" height=\"245\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-1024x338.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-300x99.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-200x66.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-1536x507.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-2048x676.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-367x121.png 367w\" sizes=\"(max-width: 742px) 100vw, 742px\" /></a></p>\n<p><span>Where:<br />\n</span><span>ProxySQL means: Application → ProxySQL → HAProxy.<br />\n</span><span>HAProxy means: Application → HAProxy.<br />\n</span></p>\n<p><span>Hope this puts your worries at rest, of course, this is using the “optimized” solution.</span></p>\n<h3>Conclusions</h3>\n<p><span>The Percona Distribution for MySQL Operator is a constantly growing/improving solution. It also has a lot of interesting features, like being able to manage your backup/restore, point-in-time recovery, and more. But its adoption is still limited and it is normal to have some drawbacks like this one. It is on us who play with real production environments, or as in this case, playing to define certified solutions and giving feedback to improve how the operator works, in order to make it a stronger product able to serve you better day by day.</span></p>\n<p><span>Now we are going to wait for the FR to be implemented, and then we will recover our dimensioning work. </span></p>\n","descriptionType":"html","publishedDate":"Wed, 23 Jun 2021 15:25:54 +0000","feedId":11,"bgimg":"","linkMd5":"2f1bb10abb3c178a374f7f43fd35392e","bgimgJsdelivr":"","metaImg":"","author":"Marco Tusa","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn28@2020_3/2021/07/13/17-22-09-336_daaa0d3289cd7395.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn28@2020_5/2021/07/13/17-22-08-210_6ebc3c883ccf52ae.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn88@2020_3/2021/07/13/17-22-09-191_18f59609c769b9c3.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-1024x502.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn32@2020_2/2021/07/13/17-22-10-470_651f7fc6925c28db.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-1024x502.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn72@2020_5/2021/07/13/17-22-09-882_98d070fa06c1b76e.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-1024x502.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn32@2020_3/2021/07/13/17-22-11-240_19c6b8eeeee3c5f8.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-1024x506.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn44@2020_3/2021/07/13/17-22-07-943_ca772e57dc2e3c6b.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-1024x506.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn95@2020_3/2021/07/13/17-22-11-260_48017dce2b6bae0a.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-1024x506.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn39@2020_3/2021/07/13/17-22-10-184_b3118e60d4b06525.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-1024x514.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn44@2020_5/2021/07/13/17-22-10-792_3d2d69c244693db9.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-1024x338.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn24@2020_5/2021/07/13/17-22-09-093_ff108c8b173848ca.webp"},"publishedOrCreatedDate":1626196914590},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Chaos Testing Leads to More Stable Percona XtraDB Cluster","link":"https://www.percona.com/blog/?p=76745","description":"<img width=\"200\" height=\"113\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-200x113.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Chaos Testing Leads to More Stable Percona XtraDB Cluster\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster.png 1280w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76769\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-300x169.png\" alt=\"Chaos Testing Leads to More Stable Percona XtraDB Cluster\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster.png 1280w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In my talk at Percona Live 2021, “<a target=\"_blank\" href=\"https://www.percona.com/resources/videos/creating-chaos-databases-percona-live-2021\">Creating Chaos in Databases</a>”, I discussed how creating a controlled interruption in available resources (I used primary pod and network interruptions) allows us to test the stability of a database, and in our case, <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtradb-cluster\">Percona XtraDB Cluster</a>.</p>\n<p>I also mentioned in the talk that my testing led to diagnosing a few unpleasant bugs, namely:</p>\n<ul>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3437\">PXC-3437</a>: Node fails to join in the endless loop</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3580\">PXC-3580</a>: Aggressive network outages on one node makes the whole cluster unusable</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3596\">PXC-3596</a>: Node stuck in aborting SST</li>\n</ul>\n<p>Currently, I am happy to report these bugs are fixed in Percona XtraDB Cluster 8.0.23 and this version will provide you with a much better and stable experience, especially when used in a combination with our <a target=\"_blank\" href=\"https://www.percona.com/software/percona-kubernetes-operators\">Percona Distribution for MySQL Operator.</a></p>\n<p>I am not able to break Percona XtraDB Cluster 8.0.23 as I was able to in previous releases. It seems I need to be more creative to find more network-related bugs, so we will see how it goes.</p>\n<p>As a side note, I would like to mention that our fixes are available to everybody who would like to improve the stability of their products based on the Galera library. We do not hide our source code behind “Enterprise” paywalls or hide them in combined .tar.gz source code dumps.</p>\n<p>For example, a bug fix for bug <a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3580\">https://jira.percona.com/browse/PXC-3580</a> is available in the pull request <a target=\"_blank\" href=\"https://github.com/percona/galera/pull/214/files\">https://github.com/percona/galera/pull/214/files</a>. Percona is committed to providing you with a real Open Source experience.</p>\n<p>Happy Clustering!</p>\n","descriptionType":"html","publishedDate":"Thu, 17 Jun 2021 12:56:47 +0000","feedId":11,"bgimg":"","linkMd5":"0b8d2140da2ccca81d50f02f222f4d4d","bgimgJsdelivr":"","metaImg":"","author":"Vadim Tkachenko","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-200x113.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn35@2020_1/2021/07/13/17-22-05-092_c9a56436693b39ac.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn35@2020_3/2021/07/13/17-22-09-189_10d5ba8db3842a76.webp"},"publishedOrCreatedDate":1626196914571},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Authenticate Percona Server for MongoDB Users via Native LDAP","link":"https://www.percona.com/blog/?p=76902","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Authenticate Percona Server for MongoDB Users via Native LDAP\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\"><img loading=\"lazy\" class=\"alignright size-medium wp-image-77294\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-300x157.png\" alt=\"Authenticate Percona Server for MongoDB Users via Native LDAP\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Percona Server for MongoDB</a> supports two different ways of <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/LATEST/authentication.html\">authenticating</a> against an LDAP service:</p>\n<ul>\n<li>operating system libraries (aka Native LDAP)</li>\n<li><em>saslauthd</em> (aka LDAP proxy)</li>\n</ul>\n<p>We&#8217;ve talked about the LDAP proxy option <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/11/06/mongodb-security-using-ldap-authentication/\">many</a> <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/12/21/percona-server-for-mongodb-authentication-using-active-directory/\">times</a> <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/03/16/percona-server-for-mongodb-dashing-new-ldap-authentication-plugin/\">already</a>. In this post, I am going to discuss the Native LDAP approach.</p>\n<p>Note: for the purposes of the examples, I am considering a RHEL-based distribution.</p>\n<h2>Prerequisites</h2>\n<p>First of all, the following packages are needed at the operating system level:</p><pre class=\"crayon-plain-tag\">yum install cyrus-sasl-devel cyrus-sasl-md5 cyrus-sasl-plain cyrus-sasl-gssapi cyrus-sasl-lib</pre><p>If any of these are missing, you most likely will encounter some cryptic errors. For example, something like the following could appear in your <em>mongod.log</em>:</p><pre class=\"crayon-plain-tag\">2021-07-22T14:29:14.905-0500 E QUERY [js] Error: SASL(-4): no mechanism available: No worthy mechs found :</pre><p>By default, MongoDB creates a TLS connection when binding to the LDAP server. The next step is to make the certificate for the company&#8217;s internal Certificate Authority (CA) available to our MongoDB server. We can do this by placing the certificate file in /etc/openldap/certs/ directory:</p><pre class=\"crayon-plain-tag\">cp my_CA.crt /etc/openldap/certs/</pre><p>Next, we need to point our server to the CA certificate we copied, by adding the following line to <em>/etc/openldap/ldap.conf</em>:</p><pre class=\"crayon-plain-tag\">tee -a /etc/openldap/ldap.conf &#60;&#60;EOF\nTLS_CACERT /etc/openldap/certs/my_CA.crt\nEOF</pre><p></p>\n<h2>MongoDB Configuration</h2>\n<p>Once the prerequisites are fulfilled, we need to adjust our <em>mongod.conf</em> to authenticate against LDAP. We need:</p>\n<ul>\n<li>a read-only user that allows MongoDB to query LDAP</li>\n<li>an LDAP <em>queryTemplate</em> to authorize users based on LDAP group membership</li>\n</ul>\n<p>If you don&#8217;t know what this query string will be, you should work together with the LDAP server administrators to figure it out. The following example is for an Active Directory deployment:</p><pre class=\"crayon-plain-tag\">ldap: \n  servers: \"ldap.example.com\" \n  authz: \n    queryTemplate: \"DC=example,DC=com??sub?(&#38;(objectClass=group)(member:1.2.840.113556.1.4.1941:={USER}))\" \n  userToDNMapping: \n  '[ \n    { \n      match : \"(.+)\", \n      ldapQuery: \"DC=example,DC=com??sub?(userPrincipalName={0})\" \n    } \n  ]' \n  bind: \n    queryUser: \"ldapreadonly@example\" \n    queryPassword: \"mypwd\" \n  setParameter: \n    authenticationMechanisms: \"PLAIN,SCRAM-SHA-1,SCRAM-SHA-256\"</pre><p>We can also use <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/04/24/percona-server-for-mongodb-ldap-enhancements-user-to-dn-mapping/\">transformation expressions</a> in order to avoid specifying the complete DN of the authenticating users. In the example above, the {0} is replaced with the first token of the user as specified. If you are logging in as myuser@example.com that would be the string &#8220;myuser&#8221;, so the query becomes:</p><pre class=\"crayon-plain-tag\">ldapQuery: \"DC=example,DC=com??sub?(userPrincipalName=myuser)\"</pre><p>This returns the following LDAP result:</p><pre class=\"crayon-plain-tag\">\"cn=myuser,dc=example,dc=com\"</pre><p>The <em>queryTemplate</em> specified in the config file is the standard AD-specific way to query a user&#8217;s groups recursively. The {USER} above is replaced with the transformed username and becomes:</p><pre class=\"crayon-plain-tag\">queryTemplate: \"DC=example,DC=com??sub?(&#38;(objectClass=group)(member:1.2.840.113556.1.4.1941:=\"cn=myuser,dc=example,dc=com\"))\"</pre><p>The <em>authenticationMechanisms</em> as specified allows MongoDB to authenticate both LDAP and built-in users. The PLAIN word might raise some eyebrows but remember the connection is still encrypted unless you specify the <em>transportSecurity: none</em>.</p>\n<h2>Creating Roles for LDAP Groups</h2>\n<p>We need to create roles in the MongoDB admin database for each of the LDAP groups we are going to be using.</p>\n<p>For example, we can create groups for users that require read-only or read-write privileges respectively:</p><pre class=\"crayon-plain-tag\">db.getSiblingDB(\"admin\").createRole(\n   {\n     role: \"CN=myapp_rw,CN=Users,DC=example,DC=com\",\n     privileges: [],\n     roles: [\n       { role: \"readWrite\", db: \"myapp\" }\n     ]\n   }\n)\n\ndb.getSiblingDB(\"admin\").createRole(\n   {\n     role: \"CN=myapp_ro,CN=Users,DC=example,DC=com\",\n     privileges: [],\n     roles: [\n       { role: \"read\", db: \"myapp\" }\n     ]\n   }\n)</pre><p>In this case, any authenticating users that are members of the <em>myapp_ro</em> group in LDAP will automatically get read-only permissions against the <em>myapp</em> database.</p>\n<h2>Testing Access</h2>\n<p>To authenticate using LDAP, the following form can be used:</p><pre class=\"crayon-plain-tag\">mongo --username myuser@example.com --password mypwd --authenticationMechanism=PLAIN --authenticationDatabase='$external' --host 127.0.0.1</pre><p>Since we left the SCRAM-SHA options in the config file, we are still able to authenticate using MongoDB built-in users as well:</p><pre class=\"crayon-plain-tag\">mongo --username root --password mypwd --authenticationDatabase admin --authenticationMechanism=SCRAM-SHA1 --host 127.0.0.1</pre><p></p>\n<h2>Final Words</h2>\n<p>We&#8217;ve seen how to use the native method to configure LDAP integration. The main benefit of this method is that it requires fewer moving parts than the proxy-based approach.</p>\n<p>Keep in mind that <a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Percona Server for MongoDB</a> offers LDAP authentication (and authorization) free of charge in all versions. These features are not available in the MongoDB Community Edition.</p>\n<p>You might also want to check the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/LATEST/authentication.html#ldap-authorization\">official documentation</a> on this topic, as there are some additional options to deal with things like LDAP-referrals, connection pool sizes, etc.</p>\n","descriptionType":"html","publishedDate":"Thu, 08 Jul 2021 13:35:08 +0000","feedId":11,"bgimg":"","linkMd5":"30b453db8ff23a943b1282fdc3be0ab6","bgimgJsdelivr":"","metaImg":"","author":"Ivan Groenewold","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn7@2020_1/2021/07/13/17-22-09-272_a7120fd8ee1943f1.webp","https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn67@2020_2/2021/07/13/17-22-07-424_16314f275f690f42.webp"},"publishedOrCreatedDate":1626196914553},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Percona Distribution for MongoDB Operator 1.9,  Updated Percona Distribution for PostgreSQL: Release Roundup July 5, 2021","link":"https://www.percona.com/blog/?p=76946","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Software Release July 5 2021\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright size-medium wp-image-77010\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-300x169.png\" alt=\"Percona Software Release July 5 2021\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />It&#8217;s release roundup time again here at Percona!</h2>\n<p>Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download. This roundup includes a lot of releases, so be sure to check them all out!</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since June 21, 2021, including several version updates to Percona Distribution for PostgreSQL, as well as Percona Monitoring and Management 2.19.0.</p>\n<p>&#160;</p>\n<h2>Percona Distribution for MongoDB Operator 1.9.0</h2>\n<p>On June 29, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/RN/Kubernetes-Operator-for-PSMONGODB-RN1.9.0.htm\">Percona Distribution for MongoDB Operator 1.9.0</a> was released. It automates the creation, modification, or deletion of items in your Percona Server for MongoDB environment. The Operator contains the necessary Kubernetes settings to maintain a consistent Percona Server for MongoDB instance. modification, or deletion of items in your Percona Server for MongoDB environment.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb\">Download Percona Distribution for MongoDB Operator 1.9.0</a></p>\n<p>&#160;</p>\n<h2>Percona Distribution for PostgreSQL</h2>\n<p>On July 1, 2021, we released updated versions of Percona Distribution for PostgreSQL. With this update of Percona Distribution for PostgreSQL, <code>etcd</code> package is added as a <code>DEB</code> package to Percona Distribution for PostgreSQL for Debian 9 (“stretch”). This package is used to set up High Availability clusters with Patroni.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/13/release-notes-v13.3.upd2.html\">Percona Distribution for PostgreSQL 13.3</a><br />\n<a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/12/release-notes-v12.7.upd2.html\">Percona Distribution for PostgreSQL 12.7</a><br />\n<a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/11/release-notes-v11.12.upd2.html\">Percona Distribution for PostgreSQL 11.12</a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/postgresql-distribution\">Download Percona Distribution for PostgreSQL</a></p>\n<p>&#160;</p>\n<h2 id=\"percona-monitoring-and-management-2190\">Percona Monitoring and Management 2.19.0</h2>\n<p id=\"percona-monitoring-and-management-2190\">June 30, 2021, saw the release of <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/release-notes/2.19.0.html\">Percona Monitoring and Management 2.19.0</a>. With it, you can easily view and monitor the performance of your MySQL, MongoDB, PostgreSQL, and MariaDB databases. Release highlights include:</p>\n<ul>\n<li>Backup Management can now be enabled from the UI.  We also added support for MongoDB services on-demand backup and restore. For now, it only supports ReplicaSet on S3-compatible storage.</li>\n<li>Dashboards improvements\n<ul>\n<li>There are several community-driven improvements to ProxySQL data collection, with new dashboards to expose such metrics like: <em>Queries Latency histograms</em> and <code>SHUNNED_REPLICATION_LAG</code> state.</li>\n<li>Fixes for Amazon Aurora service detection on <a target=\"_blank\" href=\"https://pmmdemo.percona.com/graph/d/mysql-amazonaurora/mysql-amazon-aurora-details?var-service_name=rds-aurora57-instance-1\">the dashboard</a>, MongoDB ReplicaSet Summary, and other MongoDB memory-related panels.</li>\n</ul>\n</li>\n<li>Improvements to DBaaS secrets by generating strong passwords for operators. This is an improvement to the Automated Operator Installation released in PMM 2.18, which will greatly enhance security.</li>\n</ul>\n<p>In addition, there are several bug fixes and many improvements, which can be reviewed in the release notes.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Download Percona Monitoring and Management 2.19.0</a></p>\n<p>&#160;</p>\n<h2>Percona XtraBackup 2.4.23</h2>\n<p>On June 22, 2021, we released <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtrabackup/2.4/release-notes/2.4/2.4.23.html\">Percona XtraBackup 2.4.23</a>. It enables MySQL backups without blocking user queries, making it ideal for companies with large data sets and mission-critical applications that cannot tolerate long periods of downtime. In this release, there are several bug fixes, including a format correction for the <cite>xtrabackup –databases</cite> options and an update to the XtraBackup Help description for the parameter <cite>–stream</cite>.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/\">Download Percona XtraBackup 2.4.23</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"noopener\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n","descriptionType":"html","publishedDate":"Mon, 05 Jul 2021 12:00:42 +0000","feedId":11,"bgimg":"","linkMd5":"ea6966a41fd35ac8cca88fedca0f1777","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn92@2020_3/2021/07/13/17-22-10-837_d07303843605570b.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn75@2020_5/2021/07/13/17-22-10-918_96bc08260351d41a.webp"},"publishedOrCreatedDate":1626196914568},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Discover Why MongoDB Runs Better With Percona","link":"https://www.percona.com/blog/?p=76802","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-200x105.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MongoDB Percona\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-200x105.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-300x157.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-1024x536.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-1140x595.jpg 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-367x192.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628.jpg 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-76806\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-300x157.jpg\" alt=\"MongoDB Percona\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-300x157.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-1024x536.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-200x105.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-1140x595.jpg 1140w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-367x192.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628.jpg 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In just under a month, MongoDB will host its annual event, MongoDB.live. And just over a month ago, Percona held its annual event </span><a target=\"_blank\" href=\"https://www.percona.com/conferences/percona-live-online-2021\"><span>Percona Live</span></a><span>. </span></p>\n<p>Despite the naming convention similarity, these events couldn’t be more different!</p>\n<p><span>Percona Live was an open source database software community event with </span><b>196 speakers and over 200 presentations</b><span>. We platformed a huge range of people and companies that use and champion a variety of open source databases and tools. </span></p>\n<p><b>Although many people still think of MongoDB as open source, this is incorrect</b><span>. </span><a target=\"_blank\" href=\"https://opensource.org/\"><span>The Open Source Initiative</span></a><span> referred to MongoDB’s introduction of the Server Side Public License (SSPL) as </span><i><span>“fauxpen” </span></i><span>source license.</span></p>\n<p><span>In 2019, MongoDB CEO Dev Ittycheria </span><a target=\"_blank\" href=\"https://www.techrepublic.com/article/mongodb-ceo-tells-hard-truths-about-commercial-open-source/\"><span>stated in an interview</span></a><span>, “</span><i><span>MongoDB was built by MongoDB. There was no prior art. So one: it speaks to the technical acumen of the team here. And two: we didn’t open source it to get help from the community, to make the product better… </span></i><i><span>We open sourced as a freemium strategy; to drive adoption.” </span></i></p>\n<p><span>For many people, this is totally contrary to open source values and the practice of open source overall. </span></p>\n<p><span>The move away from open source and the community means that MongoDB has become increasingly closed off. Without market alternatives, MongoDB can become a monopoly. They can raise fees without competition and lock-in users. Some people believe that this is their intent with their planned new </span><a target=\"_blank\" href=\"https://www.mongodb.com/blog/post/new-quarterly-releases-starting-with-mongodb-5-0\"><span>Quarterly Release Cycle</span></a><span>, which will provide quarterly releases only to Atlas customers.</span></p>\n<p><b>This is where Percona can help. </b></p>\n<p><span>We offer a viable and secure </span><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb\"><span>drop-in replacement </span></a><span>for MongoDB Community with added enterprise-level features. Plus, market-leading </span><a target=\"_blank\" href=\"https://www.percona.com/services\"><span>support services</span></a><span> and </span><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\"><span>open source tools</span></a><span>. </span></p>\n<p><span>Percona customers are not locked in and enjoy a lower total cost of ownership, with the freedom to move their data at any time, without fees or barriers.</span></p>\n<p><b>For the next six weeks, we will be focusing on Percona’s MongoDB offering and all the benefits a move to Percona can bring to your business.</b></p>\n<p><span>Highlights include:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Expert webinars on a variety of hot MongoDB topics</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>New market insight and thought leadership</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>In-depth technical blogs addressing key MongoDB pain-points</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><b>Percona and Friends React to MongoDB.live</b><span> &#8211; a live stream on the July 15th where industry experts discuss the news and announcements coming from MongoDB.live</span></li>\n</ul>\n<p><span>Our first webinar kicks off on </span><b>June 29th</b><span> as Percona experts </span><b>Kimberly Wilkins, Mike Grayson, and Vinicius Grippa</b><span> present </span><b>‘Unlocking the Mystery of MongoDB Shard Key Selection</b><span>’ and offer advice on the measures to take if things go wrong. </span><a target=\"_blank\" href=\"https://learn.percona.com/mongodb-shard-key-selection\"><span>Please register now to attend for free.</span></a></p>\n<p><strong>Keep an eye on our blog and social channels for much more exciting content, insight, and events over the next few weeks. </strong></p>\n","descriptionType":"html","publishedDate":"Mon, 21 Jun 2021 12:00:44 +0000","feedId":11,"bgimg":"","linkMd5":"386eea3706c2575adfd931e8a631c1aa","bgimgJsdelivr":"","metaImg":"","author":"Rachel Pescador","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-200x105.jpg":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn20@2020_5/2021/07/13/17-22-08-256_994319764374d421.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-300x157.jpg":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn76@2020_5/2021/07/13/17-22-08-580_4f470f9e9b272f19.webp"},"publishedOrCreatedDate":1626196914576},{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","title":"Deploy a Dedicated Percona Server for MySQL 8.0 in Azure","link":"https://www.percona.com/blog/?p=76828","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL in Azure\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-76983\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-300x168.png\" alt=\"MySQL in Azure\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />This quickstart shows you how to use the Azure portal to deploy a dedicated <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL</a> 8.0 drop-in replacement for MySQL that provides superior performance, scalability, and instrumentation. It also shows you how to connect to the server.</p>\n<h2>Prerequisites</h2>\n<p>Existing Azure subscription. If you don&#8217;t have a subscription, create a <a target=\"_blank\" href=\"https://azure.microsoft.com/free/\">free Azure account</a> before starting.</p>\n<h2>Create Percona Server for MySQL 8.0 Azure Instance</h2>\n<ol>\n<li>Go to the <a target=\"_blank\" href=\"https://portal.azure.com/\" data-linktype=\"external\">Azure portal</a> to create a MySQL database using Percona Server for MySQL 8.0 image. Search for and select <strong>Percona Server for MySQL 8.0</strong>:<img loading=\"lazy\" class=\"alignnone wp-image-76829 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/1-1024x625.png\" alt=\"Azure MySQL\" width=\"900\" height=\"549\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/1-1024x625.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/1-300x183.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/1-200x122.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/1-1536x938.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/1-2048x1250.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/1-367x224.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>On the <strong>Percona Server for MySQL 8.0</strong> page, press <strong>Create</strong>:<img loading=\"lazy\" class=\"alignnone wp-image-76831 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/2-1024x877.png\" alt=\"\" width=\"900\" height=\"771\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/2-1024x877.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/2-300x257.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/2-175x150.png 175w, https://www.percona.com/blog/wp-content/uploads/2021/06/2-1536x1316.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/2-367x314.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/2.png 2025w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Create a virtual machine:<br />\n&#8211; Create a new <strong>Resource group</strong>:<img loading=\"lazy\" class=\"alignnone wp-image-76834 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/3-999x1024.png\" alt=\"create a virtual machine\" width=\"900\" height=\"923\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/3-999x1024.png 999w, https://www.percona.com/blog/wp-content/uploads/2021/06/3-293x300.png 293w, https://www.percona.com/blog/wp-content/uploads/2021/06/3-146x150.png 146w, https://www.percona.com/blog/wp-content/uploads/2021/06/3-1499x1536.png 1499w, https://www.percona.com/blog/wp-content/uploads/2021/06/3-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2021/06/3-367x376.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/3-50x50.png 50w, https://www.percona.com/blog/wp-content/uploads/2021/06/3.png 1568w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\n&#8211; Adjust <strong><strong><strong>Instance details options:</strong></strong></strong><img loading=\"lazy\" class=\"alignnone wp-image-76835 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/4-1024x812.png\" alt=\"Azure MySQL\" width=\"900\" height=\"714\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/4-1024x812.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/4-300x238.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/4-189x150.png 189w, https://www.percona.com/blog/wp-content/uploads/2021/06/4-1536x1218.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/4-367x291.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/4.png 1620w\" sizes=\"(max-width: 900px) 100vw, 900px\" />&#8211; Select a VM size to support the workload that you want to run(<strong>Size</strong>):<img loading=\"lazy\" class=\"alignnone wp-image-76836 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/5-1024x497.png\" alt=\"\" width=\"900\" height=\"437\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/5-1024x497.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/5-300x145.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/5-200x97.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/5-1536x745.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/5-2048x993.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/5-367x178.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" />&#8211; Setup <strong>Administrator account</strong> access:<img loading=\"lazy\" class=\"alignnone wp-image-76840 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/6-1024x542.png\" alt=\"\" width=\"900\" height=\"476\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/6-1024x542.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/6-300x159.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/6-200x106.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/6-1536x814.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/6-367x194.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/6.png 1546w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<table>\n<tbody>\n<tr>\n<td><b>Setting</b></td>\n<td><b>Description</b></td>\n</tr>\n<tr>\n<td><span>Subscription</span></td>\n<td><span>All resources in an Azure subscription are billed together.</span></td>\n</tr>\n<tr>\n<td><span>Resource group</span></td>\n<td><span>A resource group is a collection of resources that share the same lifecycle, permissions, and policies.</span></td>\n</tr>\n<tr>\n<td><span>Virtual machine name</span></td>\n<td><span>Virtual machines in Azure have two distinct names: virtual machine name used as the Azure resource identifier, and guest hostname. When you create a VM in the portal, the same name is used for both the virtual machine name and the hostname. The virtual machine name cannot be changed after the VM is created. You can change the hostname when you log into the virtual machine.</span></td>\n</tr>\n<tr>\n<td><span>Region</span></td>\n<td><span>Choose the Azure region that&#8217;s right for you and your customers. Not all VM sizes are available in all regions</span></td>\n</tr>\n<tr>\n<td><span>Availability options</span></td>\n<td><span>Azure offers a range of options for managing availability and resiliency for your applications. Architect your solution to use replicated VMs in Availability Zones or Availability Sets to protect your apps and data from datacenter outages and maintenance events. </span><a target=\"_blank\" href=\"https://go.microsoft.com/fwlink/?linkid=2102423\"><span>Learn more</span></a></td>\n</tr>\n<tr>\n<td><span>Availability zone</span></td>\n<td><span>You can optionally specify an availability zone in which to deploy your VM. If you choose to do so, your managed disk and public IP (if you have one) will be created in the same availability zone as your virtual machine.</span></td>\n</tr>\n<tr>\n<td><span>Image</span></td>\n<td><span>Choose Percona Server <strong>ps_8.0.22-13 &#8211; Gen1</strong> image as the base operating system for the VM</span></td>\n</tr>\n<tr>\n<td><span>Size</span></td>\n<td><span>Select a VM size to support the workload that you want to run. The size that you choose then determines factors such as processing power, memory, and storage capacity. Azure offers a wide variety of sizes to support many types of uses. Azure charges an hourly price based on the VM&#8217;s size and operating system. </span><a target=\"_blank\" href=\"http://go.microsoft.com/fwlink/?LinkId=2079861\"><span>Learn more about Virtual Machine sizes</span></a></td>\n</tr>\n<tr>\n<td><span>Authentication type</span></td>\n<td><span>Choose whether the administrator account will use username/password or SSH keys for authentication.</span></td>\n</tr>\n<tr>\n<td><span>Username</span></td>\n<td><span>The administrator username for the VM</span></td>\n</tr>\n</tbody>\n</table>\n<p>&#8211; Open <strong>Management</strong> tab and select <strong>Enable with custom storage account</strong> boot diagnostics option to abe to use Serial Console:<br />\n<strong>*Note:</strong> <em>Serial Console is currently incompatible with a managed boot diagnostics storage account. To use Serial Console, ensure that you are using a custom storage account.<br />\n</em><br />\n<img loading=\"lazy\" class=\"alignnone wp-image-76874 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/15-1024x903.png\" alt=\"\" width=\"900\" height=\"794\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/15-1024x903.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/15-300x264.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/15-170x150.png 170w, https://www.percona.com/blog/wp-content/uploads/2021/06/15-1536x1354.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/15-367x324.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/15.png 1976w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>&#8211; Press <strong>Review + create</strong> to provision Percona Server for MySQL 8.0, review settings and save <strong>private ssh key</strong>:</p>\n<p><img loading=\"lazy\" class=\"alignnone wp-image-76842 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/7-1024x839.png\" alt=\"\" width=\"900\" height=\"737\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/7-1024x839.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/7-300x246.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/7-183x150.png 183w, https://www.percona.com/blog/wp-content/uploads/2021/06/7-1536x1258.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/7-2048x1677.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/7-367x301.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Once the instance is created, you can look around and check all its settings:<img loading=\"lazy\" class=\"alignnone wp-image-76848 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-1024x575.png\" alt=\"\" width=\"900\" height=\"505\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-1024x575.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-1536x863.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-2048x1150.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-367x206.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Select <strong>Go to resource</strong> and open <strong>Serial Console</strong> to check VM boot log. VM is up and running and no issues were reported:<br />\n<strong>*Note:</strong> <em>Please pay attention to the message from Percona Server for MySQL 8.0. It provides the end-user with a temporary MySQL password and informs them about the need to change it.<br />\n</em><br />\n<img loading=\"lazy\" class=\"alignnone wp-image-76876 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/16-1024x640.png\" alt=\"\" width=\"900\" height=\"563\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/16-1024x640.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/16-300x188.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/16-200x125.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/16-1536x961.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/16-2048x1281.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/16-367x230.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Select <strong>Deployment details</strong> -&#62; <strong>INSTANCE_NAME-ip</strong> and copy instance public IP for connecting to the Percona MySQL server:<img loading=\"lazy\" class=\"alignnone wp-image-76849 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/9-1024x354.png\" alt=\"\" width=\"900\" height=\"311\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/9-1024x354.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/9-300x104.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/9-200x69.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/9-1536x531.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/9-2048x707.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/9-367x127.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n</ol>\n<h2>Test Local and Remote Connection to the Percona MySQL Server in Azure</h2>\n<h4>Local connection:</h4>\n<ol>\n<li>Connect to the server using the previously defined username and IP:<img loading=\"lazy\" class=\"alignnone wp-image-76854 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/10-1024x306.png\" alt=\"\" width=\"900\" height=\"269\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/10-1024x306.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/10-300x90.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/10-200x60.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/10-367x110.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/10.png 1386w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Open <strong>mysqld.log</strong> and find a temporary password that was set during MySQL Percona Server instance creation:</p><pre class=\"crayon-plain-tag\">[azureuser@ps-80 ~]$ sudo less /var/log/mysqld.log</pre><p><img loading=\"lazy\" class=\"alignnone wp-image-76857 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/11-1024x181.png\" alt=\"\" width=\"900\" height=\"159\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/11-1024x181.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/11-300x53.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/11-200x35.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/11-1536x272.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/06/11-2048x362.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/06/11-367x65.png 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Connect to the MySQL database and change the root&#8217;s password:</p><pre class=\"crayon-plain-tag\">ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyVeRySeCuReP@ZzW0Rd';</pre><p><img loading=\"lazy\" class=\"alignnone wp-image-76859 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/12-1024x531.png\" alt=\"\" width=\"900\" height=\"467\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/12-1024x531.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/12-300x156.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/12-200x104.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/12-367x190.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/12.png 1480w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n<li>Create a test database with a table in it and add one record:</p><pre class=\"crayon-plain-tag\">CREATE DATABASE ps80;\nCREATE TABLE ps80.example (id INT PRIMARY KEY, message VARCHAR(30));\nINSERT INTO ps80.example VALUES (1, 'Hello Percona-Server 8.0');\nSELECT * FROM ps80.example;</pre><p><img loading=\"lazy\" class=\"alignnone wp-image-76860 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/13-1024x589.png\" alt=\"\" width=\"900\" height=\"518\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/13-1024x589.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/13-300x172.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/13-200x115.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/13-367x211.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/13.png 1392w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n</ol>\n<h4>Remote connection:</h4>\n<ol>\n<li>Create a new test MySQL user for remote connections:</p><pre class=\"crayon-plain-tag\">CREATE USER 'ps80'@'%' IDENTIFIED BY 'MyVeRySeCuReP@ZzW0Rd_2';\nGRANT ALL PRIVILEGES ON ps80.* TO 'ps80'@'%';\nflush privileges;</pre><p>\n</li>\n<li>Connect from the remote host to the <strong>Percona Server for MySQL</strong> in Azure and check our test database and record in the created table:</p><pre class=\"crayon-plain-tag\">mysql -u ps80 -h 52.249.221.105 -p\n...\nSELECT * FROM ps80.example;</pre><p><img loading=\"lazy\" class=\"alignnone wp-image-76862 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/06/14-1024x653.png\" alt=\"\" width=\"900\" height=\"574\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/06/14-1024x653.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/06/14-300x191.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/06/14-200x128.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/06/14-367x234.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/06/14.png 1446w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></li>\n</ol>\n<div class=\"msportalfx-text-regular\">\n<p data-bind=\"sanitizedHtml: galleryItemDescription\"><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\"><strong>Percona Server for MySQL</strong></a> is trusted by thousands of enterprises to provide better performance and concurrency for their most demanding workloads than other MySQL servers and delivers greater value to MySQL server users with optimized performance, greater scalability and availability, enhanced backups and increased visibility.<br />\nNow <strong>Percona Server for MySQL</strong> is available in<strong> Azure.</strong></p>\n</div>\n<div class=\"fxc-base fxc-section fxc-section-wrapper\" data-bind=\"pcControl: moreFromPublisher, visible: showMoreFromPublisher\" data-formelement=\"pcControl: moreFromPublisher, visible: showMoreFromPublisher\">\n<div id=\"_weave_e_511\" class=\"fxc-weave-pccontrol fxc-section-control fxc-base msportalfx-customHtml msportalfx-form-formelement\" data-bind=\"pcControl: __control_vm__\" data-formelement=\"pcControl: __control_vm__\">\n<div class=\"azc-formElementSubLabelContainer\">\n<div class=\"azc-formElementContainer\" data-bind=\"untrustedHtml: { html: htmlTemplate, data: innerViewModel, isolated: isolated }\">\n<div data-bind=\"visible: sectionHasItems\">\n<div class=\"ext-gallery-ribbon-label ext-display-flex-row\"></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n","descriptionType":"html","publishedDate":"Thu, 24 Jun 2021 14:19:26 +0000","feedId":11,"bgimg":"","linkMd5":"e4840bb53d74ba0ffba2d186dd1d3221","bgimgJsdelivr":"","metaImg":"","author":"Oleksandr Miroshnychenko","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn64@2020_5/2021/07/13/17-22-08-748_586a7a48f5c81800.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn47@2020_4/2021/07/13/17-22-02-262_7db5ce9ef5dce912.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/1-1024x625.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn100@2020_3/2021/07/13/17-22-09-801_8e40469404ebf386.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/2-1024x877.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn39@2020_6/2021/07/13/17-22-08-794_a9302e26fc1c90b2.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/3-999x1024.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn56@2020_4/2021/07/13/17-22-08-621_6fb9aada7e10be7e.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/4-1024x812.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn40@2020_6/2021/07/13/17-22-09-262_c588e175a8ab2c3d.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/5-1024x497.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn40@2020_6/2021/07/13/17-22-08-931_aa1dd8a58c0657ab.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/6-1024x542.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn35@2020_3/2021/07/13/17-22-11-379_944762f935e874b3.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/15-1024x903.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn59@2020_3/2021/07/13/17-22-09-495_44234b771e584a9d.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/7-1024x839.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn52@2020_6/2021/07/13/17-22-10-475_8e248993bd6d9c3c.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-1024x575.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn91@2020_3/2021/07/13/17-22-07-707_0401f4e57e63cee5.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/16-1024x640.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn84@2020_6/2021/07/13/17-22-18-772_33c771477e15aaec.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/9-1024x354.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn88@2020_6/2021/07/13/17-21-55-767_07abec3a57b4e9d4.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/10-1024x306.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn83@2020_1/2021/07/13/17-22-03-066_5fb3135e2ad577fa.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/11-1024x181.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn16@2020_1/2021/07/13/17-22-08-114_37ce05a139a7682e.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/12-1024x531.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn11@2020_2/2021/07/13/17-22-02-503_5d45e74fb26f531c.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/13-1024x589.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn32@2020_6/2021/07/13/17-22-10-912_83cc6a8fc802f732.webp","https://www.percona.com/blog/wp-content/uploads/2021/06/14-1024x653.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn88@2020_4/2021/07/13/17-22-09-753_e35c2d5316ccc2db.webp"},"publishedOrCreatedDate":1626196914591}],"record":{"createdTime":"2021-07-14 01:21:54","updatedTime":"2021-07-14 01:21:54","feedId":11,"fetchDate":"Tue, 13 Jul 2021 17:21:54 +0000","fetchMs":407,"handleMs":186,"totalMs":25348,"newArticles":0,"totalArticles":40,"status":1,"type":0,"ip":"4cf9ab886509ef3fd2ece0a16b714d9c","hostName":"europe-58*","requestId":"a600812562bc4fd3bbaba80a3464aff3_11","contentType":"application/rss+xml; charset=UTF-8","totalBytes":3075070,"bgimgsTotal":0,"bgimgsGithubTotal":0,"articlesImgsTotal":162,"articlesImgsGithubTotal":162,"successGithubMap":{"myreaderx8":6,"myreaderx14":6,"myreaderx15":6,"myreaderx7":5,"myreaderx16":5,"myreaderx6":6,"myreaderx10":6,"myreaderx4":6,"myreaderx32":5,"myreaderx33":5,"myreaderx11":6,"myreaderx3":6,"myreaderx12":6,"myreaderx2":4,"myreaderx1":6,"myreaderx13":6,"myreaderx30":6,"myreaderx31":5,"myreaderx18":5,"myreaderx19":6,"myreaderx":6,"myreaderx25":5,"myreaderx27":5,"myreaderx21":6,"myreaderx22":5,"myreaderx23":5,"myreaderx24":6,"myreaderx5oss":6,"myreaderx29":6},"failGithubMap":{}},"feed":{"createdTime":"2020-05-30 17:21:38","updatedTime":"2020-09-01 09:23:03","id":11,"name":"Percona Database Performance Blog","url":"https://www.percona.com/blog/feed/","subscriber":null,"website":null,"icon":"https://www.percona.com/blog/wp-content/uploads/2018/09/percona-32x32.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn89@2020_6/2020/09/01/01-23-01-358_b72bb3b39c378fe6.png","description":"","weekly":null,"link":null},"noPictureArticleList":[],"tmpCommonImgCdnBytes":0,"tmpBodyImgCdnBytes":3075070,"tmpBgImgCdnBytes":0,"extra4":{"start":1626196913818,"total":0,"statList":[{"spend":587,"msg":"获取xml内容"},{"spend":186,"msg":"解释文章"},{"spend":1,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":24535,"msg":"正文链接上传到cdn"}]},"extra5":162,"extra6":162,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-032.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-039.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe63.herokuapp.com/":{"failCount":0,"successCount":9,"resultList":[200,200,200,200,200,200,200,200,200]},"http://europe61.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-028.herokuapp.com/":{"failCount":0,"successCount":9,"resultList":[200,200,200,200,200,200,200,200,200]},"http://europe66.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-015.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-60.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-024.herokuapp.com/":{"failCount":0,"successCount":9,"resultList":[200,200,200,200,200,200,200,200,200]},"http://us-038.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-020.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://europe-25.herokuapp.com/":{"failCount":0,"successCount":9,"resultList":[200,200,200,200,200,200,200,200,200]},"http://us-54.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://europe21.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-004.herokuapp.com/":{"failCount":0,"successCount":8,"resultList":[200,200,200,200,200,200,200,200]},"http://europe-57.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":11,"resultList":[200,200,200,200,200,200,200,200,200,200,200]},"http://europe67.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-008.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-016.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":10,"resultList":[200,200,200,200,200,200,200,200,200,200]},"http://us-012.herokuapp.com/":{"failCount":0,"successCount":9,"resultList":[200,200,200,200,200,200,200,200,200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png","sourceStatusCode":200,"destWidth":72,"destHeight":72,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn60@2020_5/2021/07/13/17-21-54-848_2d9b14cc3bc762a6.webp","sourceBytes":620,"destBytes":1362,"targetWebpQuality":75,"feedId":11,"totalSpendMs":398,"convertSpendMs":17,"createdTime":"2021-07-14 01:21:54","host":"us-008*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"85a323760676897ee72aca146fd55b44,fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"620 B","destSize":"1.3 KB","compressRate":"219.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn36@2020_3/2021/07/13/17-21-54-982_7ea3ef23cce988a0.webp","sourceBytes":21063,"destBytes":8620,"targetWebpQuality":75,"feedId":11,"totalSpendMs":483,"convertSpendMs":6,"createdTime":"2021-07-14 01:21:54","host":"us-036*","referer":"https://www.percona.com/blog/?p=76767","linkMd5ListStr":"7f6a7898f2c92d2bfa70ab2a587f28e0","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.6 KB","destSize":"8.4 KB","compressRate":"40.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/binlog2s3.png","sourceStatusCode":200,"destWidth":521,"destHeight":465,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn23@2020_5/2021/07/13/17-21-55-064_685b7d8fb4a1c380.webp","sourceBytes":33641,"destBytes":11492,"targetWebpQuality":75,"feedId":11,"totalSpendMs":636,"convertSpendMs":22,"createdTime":"2021-07-14 01:21:54","host":"us-008*","referer":"https://www.percona.com/blog/?p=77226","linkMd5ListStr":"2519f01c262c6c14e723ec0fc147c6c1","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.9 KB","destSize":"11.2 KB","compressRate":"34.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn27@2020_2/2021/07/13/17-21-55-195_72505bd1828b52b1.webp","sourceBytes":28998,"destBytes":9928,"targetWebpQuality":75,"feedId":11,"totalSpendMs":912,"convertSpendMs":5,"createdTime":"2021-07-14 01:21:54","host":"europe21*","referer":"https://www.percona.com/blog/?p=77061","linkMd5ListStr":"c802e2177f7f34c39ce8e41b2d24b46d","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"28.3 KB","destSize":"9.7 KB","compressRate":"34.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-300x157.jpg","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn64@2020_3/2021/07/13/17-21-55-184_068ff24938819aef.webp","sourceBytes":15495,"destBytes":12066,"targetWebpQuality":75,"feedId":11,"totalSpendMs":917,"convertSpendMs":5,"createdTime":"2021-07-14 01:21:54","host":"europe21*","referer":"https://www.percona.com/blog/?p=76666","linkMd5ListStr":"819f8ee7a79f56fb58e8f8af81dad30b","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.1 KB","destSize":"11.8 KB","compressRate":"77.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.13.10-AM-1024x542.png","sourceStatusCode":200,"destWidth":1024,"destHeight":542,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn71@2020_3/2021/07/13/17-21-55-178_2494aab9af9dd727.webp","sourceBytes":293248,"destBytes":15422,"targetWebpQuality":75,"feedId":11,"totalSpendMs":777,"convertSpendMs":34,"createdTime":"2021-07-14 01:21:54","host":"us-036*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"286.4 KB","destSize":"15.1 KB","compressRate":"5.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn9@2020_3/2021/07/13/17-21-55-121_203d68e483ab8dba.webp","sourceBytes":15923,"destBytes":4890,"targetWebpQuality":75,"feedId":11,"totalSpendMs":784,"convertSpendMs":7,"createdTime":"2021-07-14 01:21:54","host":"us-039*","referer":"https://www.percona.com/blog/?p=75470","linkMd5ListStr":"f477311e2b6a8ed038663178f8ea1c46","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.5 KB","destSize":"4.8 KB","compressRate":"30.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/9-1024x354.png","sourceStatusCode":200,"destWidth":1024,"destHeight":354,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn88@2020_6/2021/07/13/17-21-55-767_07abec3a57b4e9d4.webp","sourceBytes":167897,"destBytes":22982,"targetWebpQuality":75,"feedId":11,"totalSpendMs":945,"convertSpendMs":27,"createdTime":"2021-07-14 01:21:55","host":"us-008*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"164 KB","destSize":"22.4 KB","compressRate":"13.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-200x105.jpg","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn19@2020_4/2021/07/13/17-21-56-943_c6d4a900673af131.webp","sourceBytes":10083,"destBytes":8404,"targetWebpQuality":75,"feedId":11,"totalSpendMs":520,"convertSpendMs":4,"createdTime":"2021-07-14 01:21:56","host":"us-020*","referer":"https://www.percona.com/blog/?p=77254","linkMd5ListStr":"bb5d1e7fbccb0048b24243fb98524994","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"9.8 KB","destSize":"8.2 KB","compressRate":"83.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn83@2020_4/2021/07/13/17-21-56-926_094ce172264714ae.webp","sourceBytes":78627,"destBytes":15176,"targetWebpQuality":75,"feedId":11,"totalSpendMs":587,"convertSpendMs":8,"createdTime":"2021-07-14 01:21:56","host":"us-020*","referer":"https://www.percona.com/blog/?p=77277","linkMd5ListStr":"2dc117d7342c9f205c16c18da003bc11","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76.8 KB","destSize":"14.8 KB","compressRate":"19.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn55@2020_6/2021/07/13/17-21-56-924_e7a791854fbac14c.webp","sourceBytes":28585,"destBytes":10506,"targetWebpQuality":75,"feedId":11,"totalSpendMs":556,"convertSpendMs":6,"createdTime":"2021-07-14 01:21:56","host":"us-020*","referer":"https://www.percona.com/blog/?p=76991","linkMd5ListStr":"7baf993af9e188b6b137ed5a280af57b","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.9 KB","destSize":"10.3 KB","compressRate":"36.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-04-at-12.55.32-PM-1024x351.png","sourceStatusCode":200,"destWidth":1024,"destHeight":351,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn91@2020_5/2021/07/13/17-21-57-146_3c74b870739e84e3.webp","sourceBytes":139119,"destBytes":13204,"targetWebpQuality":75,"feedId":11,"totalSpendMs":929,"convertSpendMs":15,"createdTime":"2021-07-14 01:21:56","host":"europe21*","referer":"https://www.percona.com/blog/?p=76660","linkMd5ListStr":"1c4df3783474eeb76d845e9e789bff49","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"135.9 KB","destSize":"12.9 KB","compressRate":"9.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image1.png","sourceStatusCode":200,"destWidth":417,"destHeight":344,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn100@2020_4/2021/07/13/17-21-57-603_94f2481f94b27fff.webp","sourceBytes":36644,"destBytes":13300,"targetWebpQuality":75,"feedId":11,"totalSpendMs":408,"convertSpendMs":7,"createdTime":"2021-07-14 01:21:57","host":"us-036*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"35.8 KB","destSize":"13 KB","compressRate":"36.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn47@2020_4/2021/07/13/17-22-02-262_7db5ce9ef5dce912.webp","sourceBytes":23980,"destBytes":6950,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1097,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:01","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23.4 KB","destSize":"6.8 KB","compressRate":"29%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/12-1024x531.png","sourceStatusCode":200,"destWidth":1024,"destHeight":531,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn11@2020_2/2021/07/13/17-22-02-503_5d45e74fb26f531c.webp","sourceBytes":139796,"destBytes":32916,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1148,"convertSpendMs":25,"createdTime":"2021-07-14 01:22:01","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"136.5 KB","destSize":"32.1 KB","compressRate":"23.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/10-1024x306.png","sourceStatusCode":200,"destWidth":1024,"destHeight":306,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn83@2020_1/2021/07/13/17-22-03-066_5fb3135e2ad577fa.webp","sourceBytes":35980,"destBytes":6902,"targetWebpQuality":75,"feedId":11,"totalSpendMs":786,"convertSpendMs":12,"createdTime":"2021-07-14 01:22:02","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"35.1 KB","destSize":"6.7 KB","compressRate":"19.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image5.png","sourceStatusCode":200,"destWidth":790,"destHeight":303,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn72@2020_3/2021/07/13/17-22-04-090_0511d79263a41116.webp","sourceBytes":22637,"destBytes":10904,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1197,"convertSpendMs":9,"createdTime":"2021-07-14 01:22:03","host":"europe67*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.1 KB","destSize":"10.6 KB","compressRate":"48.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":74,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn27@2020_5/2021/07/13/17-22-05-092_147c67c11b518b52.webp","sourceBytes":5639,"destBytes":1326,"targetWebpQuality":75,"feedId":11,"totalSpendMs":563,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:04","host":"us-016*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.5 KB","destSize":"1.3 KB","compressRate":"23.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-200x113.png","sourceStatusCode":200,"destWidth":200,"destHeight":113,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn35@2020_1/2021/07/13/17-22-05-092_c9a56436693b39ac.webp","sourceBytes":32992,"destBytes":5312,"targetWebpQuality":75,"feedId":11,"totalSpendMs":688,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:04","host":"us-016*","referer":"https://www.percona.com/blog/?p=76745","linkMd5ListStr":"0b8d2140da2ccca81d50f02f222f4d4d","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.2 KB","destSize":"5.2 KB","compressRate":"16.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Cluster-Statuses-in-Percona-Kubernetes-Operators-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn6@2020_3/2021/07/13/17-22-05-063_a3954661b658bb9d.webp","sourceBytes":40479,"destBytes":7324,"targetWebpQuality":75,"feedId":11,"totalSpendMs":947,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:04","host":"europe67*","referer":"https://www.percona.com/blog/?p=77277","linkMd5ListStr":"2dc117d7342c9f205c16c18da003bc11","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"39.5 KB","destSize":"7.2 KB","compressRate":"18.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image10.png","sourceStatusCode":200,"destWidth":320,"destHeight":390,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn44@2020_2/2021/07/13/17-22-05-070_7ba795f2e7eb45ae.webp","sourceBytes":32651,"destBytes":18620,"targetWebpQuality":75,"feedId":11,"totalSpendMs":965,"convertSpendMs":10,"createdTime":"2021-07-14 01:22:04","host":"europe67*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.9 KB","destSize":"18.2 KB","compressRate":"57%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Migrating-Into-k8s-Running-the-Percona-Distribution-for-MySQL-Operator-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn64@2020_2/2021/07/13/17-22-05-400_9e96df84615279a6.webp","sourceBytes":12093,"destBytes":3510,"targetWebpQuality":75,"feedId":11,"totalSpendMs":524,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:05","host":"us-016*","referer":"https://www.percona.com/blog/?p=76660","linkMd5ListStr":"1c4df3783474eeb76d845e9e789bff49","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.8 KB","destSize":"3.4 KB","compressRate":"29%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn79@2020_6/2021/07/13/17-22-05-445_75c6012e9faf2084.webp","sourceBytes":21063,"destBytes":7884,"targetWebpQuality":75,"feedId":11,"totalSpendMs":978,"convertSpendMs":59,"createdTime":"2021-07-14 01:22:04","host":"us-012*","referer":"https://www.percona.com/blog/?p=77025","linkMd5ListStr":"8eb8e92d03bfcaf9d9e4eb5dff2f513d","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.6 KB","destSize":"7.7 KB","compressRate":"37.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.15.51-AM-1024x707.png","sourceStatusCode":200,"destWidth":1024,"destHeight":707,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn44@2020_3/2021/07/13/17-22-05-545_80e006c40e834852.webp","sourceBytes":471714,"destBytes":15674,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1216,"convertSpendMs":105,"createdTime":"2021-07-14 01:22:04","host":"us-012*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"460.7 KB","destSize":"15.3 KB","compressRate":"3.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":75,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn31@2020_6/2021/07/13/17-22-05-913_8d1760662c65eda5.webp","sourceBytes":5432,"destBytes":1446,"targetWebpQuality":75,"feedId":11,"totalSpendMs":683,"convertSpendMs":3,"createdTime":"2021-07-14 01:22:05","host":"europe67*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.3 KB","destSize":"1.4 KB","compressRate":"26.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":76,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn48@2020_2/2021/07/13/17-22-06-079_8f6b725a02096785.webp","sourceBytes":5436,"destBytes":1454,"targetWebpQuality":75,"feedId":11,"totalSpendMs":383,"convertSpendMs":3,"createdTime":"2021-07-14 01:22:05","host":"us-020*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.3 KB","destSize":"1.4 KB","compressRate":"26.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Blank-diagram-Page-2-31-1024x517.png","sourceStatusCode":200,"destWidth":1024,"destHeight":517,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn8@2020_4/2021/07/13/17-22-05-821_1f8b36d6894c0213.webp","sourceBytes":204824,"destBytes":29400,"targetWebpQuality":75,"feedId":11,"totalSpendMs":836,"convertSpendMs":25,"createdTime":"2021-07-14 01:22:05","host":"us-012*","referer":"https://www.percona.com/blog/?p=76815","linkMd5ListStr":"41274bddba64661f4cc18887e083ce09","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"200 KB","destSize":"28.7 KB","compressRate":"14.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image3-1-1024x147.png","sourceStatusCode":200,"destWidth":1024,"destHeight":147,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn52@2020_4/2021/07/13/17-22-06-234_0981ea59f51e821c.webp","sourceBytes":77972,"destBytes":7374,"targetWebpQuality":75,"feedId":11,"totalSpendMs":447,"convertSpendMs":9,"createdTime":"2021-07-14 01:22:06","host":"us-008*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76.1 KB","destSize":"7.2 KB","compressRate":"9.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image7.png","sourceStatusCode":200,"destWidth":529,"destHeight":150,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn64@2020_1/2021/07/13/17-22-06-639_e041fb9784bee107.webp","sourceBytes":14193,"destBytes":5890,"targetWebpQuality":75,"feedId":11,"totalSpendMs":435,"convertSpendMs":13,"createdTime":"2021-07-14 01:22:06","host":"us-036*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.9 KB","destSize":"5.8 KB","compressRate":"41.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image20.png","sourceStatusCode":200,"destWidth":558,"destHeight":288,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn96@2020_3/2021/07/13/17-22-06-861_041c1fc88e6c3d0d.webp","sourceBytes":44322,"destBytes":19072,"targetWebpQuality":75,"feedId":11,"totalSpendMs":386,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:06","host":"us-016*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"43.3 KB","destSize":"18.6 KB","compressRate":"43%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn72@2020_6/2021/07/13/17-22-06-738_dbd7b67d94a3fce8.webp","sourceBytes":21351,"destBytes":4982,"targetWebpQuality":75,"feedId":11,"totalSpendMs":571,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:06","host":"us-012*","referer":"https://www.percona.com/blog/?p=76592","linkMd5ListStr":"4ac6a00baf384d4228bb0850832721e0","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.9 KB","destSize":"4.9 KB","compressRate":"23.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-200x107.png","sourceStatusCode":200,"destWidth":200,"destHeight":107,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn56@2020_2/2021/07/13/17-22-06-557_1c362d0eca692e9b.webp","sourceBytes":30082,"destBytes":4868,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1084,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:06","host":"europe21*","referer":"https://www.percona.com/blog/?p=77159","linkMd5ListStr":"62029c87db3e05447872e34e8cc8241c","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.4 KB","destSize":"4.8 KB","compressRate":"16.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MyDumper-0.10.7-is-Now-Available-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn40@2020_2/2021/07/13/17-22-07-083_b1c2d2ed6e373697.webp","sourceBytes":13725,"destBytes":5050,"targetWebpQuality":75,"feedId":11,"totalSpendMs":544,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:06","host":"us-004*","referer":"https://www.percona.com/blog/?p=76767","linkMd5ListStr":"7f6a7898f2c92d2bfa70ab2a587f28e0","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.4 KB","destSize":"4.9 KB","compressRate":"36.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn95@2020_4/2021/07/13/17-22-07-018_8aee64af66262ce0.webp","sourceBytes":17830,"destBytes":5010,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1134,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:06","host":"europe-59*","referer":"https://www.percona.com/blog/?p=76691","linkMd5ListStr":"d0b3cc26c8b6425f9fa81b97d17f434d","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"17.4 KB","destSize":"4.9 KB","compressRate":"28.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png","sourceStatusCode":200,"destWidth":75,"destHeight":75,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn5@2020_5/2021/07/13/17-22-07-089_2826482aac8c233a.webp","sourceBytes":5479,"destBytes":1472,"targetWebpQuality":75,"feedId":11,"totalSpendMs":829,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:06","host":"europe-59*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.4 KB","destSize":"1.4 KB","compressRate":"26.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image5.png","sourceStatusCode":200,"destWidth":902,"destHeight":396,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn32@2020_3/2021/07/13/17-22-07-195_aaa191b45a584e45.webp","sourceBytes":37102,"destBytes":19582,"targetWebpQuality":75,"feedId":11,"totalSpendMs":984,"convertSpendMs":13,"createdTime":"2021-07-14 01:22:06","host":"europe-59*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"36.2 KB","destSize":"19.1 KB","compressRate":"52.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Blog_complex_archiver.png","sourceStatusCode":200,"destWidth":946,"destHeight":521,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn76@2020_3/2021/07/13/17-22-07-377_a4192c56825a4b8b.webp","sourceBytes":33453,"destBytes":19700,"targetWebpQuality":75,"feedId":11,"totalSpendMs":820,"convertSpendMs":17,"createdTime":"2021-07-14 01:22:07","host":"europe-25*","referer":"https://www.percona.com/blog/?p=77071","linkMd5ListStr":"e34a79158454ed17846ac7be9c87726b","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.7 KB","destSize":"19.2 KB","compressRate":"58.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image11.png","sourceStatusCode":200,"destWidth":1267,"destHeight":634,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn52@2020_4/2021/07/13/17-22-07-283_f8f2a2bec44bb7eb.webp","sourceBytes":138344,"destBytes":60002,"targetWebpQuality":75,"feedId":11,"totalSpendMs":749,"convertSpendMs":51,"createdTime":"2021-07-14 01:22:06","host":"us-032*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"135.1 KB","destSize":"58.6 KB","compressRate":"43.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image21.png","sourceStatusCode":200,"destWidth":583,"destHeight":322,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn67@2020_1/2021/07/13/17-22-07-558_f93551bf17324f48.webp","sourceBytes":32546,"destBytes":16408,"targetWebpQuality":75,"feedId":11,"totalSpendMs":412,"convertSpendMs":10,"createdTime":"2021-07-14 01:22:07","host":"us-004*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.8 KB","destSize":"16 KB","compressRate":"50.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn67@2020_2/2021/07/13/17-22-07-424_16314f275f690f42.webp","sourceBytes":43537,"destBytes":10820,"targetWebpQuality":75,"feedId":11,"totalSpendMs":993,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:06","host":"europe-59*","referer":"https://www.percona.com/blog/?p=76902","linkMd5ListStr":"30b453db8ff23a943b1282fdc3be0ab6","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"42.5 KB","destSize":"10.6 KB","compressRate":"24.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn4@2020_1/2021/07/13/17-22-07-647_fdc7ce35b993fd0e.webp","sourceBytes":27356,"destBytes":9844,"targetWebpQuality":75,"feedId":11,"totalSpendMs":430,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:07","host":"us-024*","referer":"https://www.percona.com/blog/?p=76698","linkMd5ListStr":"85a323760676897ee72aca146fd55b44","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.7 KB","destSize":"9.6 KB","compressRate":"36%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn12@2020_2/2021/07/13/17-22-07-422_cdb95707f2ca7ddb.webp","sourceBytes":19319,"destBytes":7270,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1103,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:06","host":"europe-60*","referer":"https://www.percona.com/blog/?p=77226","linkMd5ListStr":"2519f01c262c6c14e723ec0fc147c6c1","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.9 KB","destSize":"7.1 KB","compressRate":"37.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/8-1-1024x575.png","sourceStatusCode":200,"destWidth":1024,"destHeight":575,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn91@2020_3/2021/07/13/17-22-07-707_0401f4e57e63cee5.webp","sourceBytes":244316,"destBytes":38016,"targetWebpQuality":75,"feedId":11,"totalSpendMs":458,"convertSpendMs":30,"createdTime":"2021-07-14 01:22:07","host":"us-016*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"238.6 KB","destSize":"37.1 KB","compressRate":"15.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Move-Percona-Monitoring-and-Management-Server-Data-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn4@2020_4/2021/07/13/17-22-07-462_c20ee83c787966f1.webp","sourceBytes":18472,"destBytes":5194,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1096,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:06","host":"europe66*","referer":"https://www.percona.com/blog/?p=76991","linkMd5ListStr":"7baf993af9e188b6b137ed5a280af57b","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18 KB","destSize":"5.1 KB","compressRate":"28.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Understanding-pg_repack-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn79@2020_4/2021/07/13/17-22-07-846_60411da68bbc41e6.webp","sourceBytes":14426,"destBytes":3928,"targetWebpQuality":75,"feedId":11,"totalSpendMs":391,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:07","host":"us-032*","referer":"https://www.percona.com/blog/?p=76724","linkMd5ListStr":"6dadeb3ac69f7954b4a1be520eac22c9","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"14.1 KB","destSize":"3.8 KB","compressRate":"27.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image2.png","sourceStatusCode":200,"destWidth":629,"destHeight":260,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn16@2020_3/2021/07/13/17-22-07-460_593060b76fd9c572.webp","sourceBytes":35098,"destBytes":19196,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1180,"convertSpendMs":11,"createdTime":"2021-07-14 01:22:06","host":"europe63*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"34.3 KB","destSize":"18.7 KB","compressRate":"54.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image4.png","sourceStatusCode":200,"destWidth":1178,"destHeight":344,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn52@2020_3/2021/07/13/17-22-07-553_eb93dd75d340cac9.webp","sourceBytes":78742,"destBytes":28610,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1251,"convertSpendMs":17,"createdTime":"2021-07-14 01:22:06","host":"europe63*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76.9 KB","destSize":"27.9 KB","compressRate":"36.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/chart-scaling33.png","sourceStatusCode":200,"destWidth":500,"destHeight":331,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn95@2020_6/2021/07/13/17-22-07-847_44fc39a38666dc16.webp","sourceBytes":41300,"destBytes":11826,"targetWebpQuality":75,"feedId":11,"totalSpendMs":446,"convertSpendMs":12,"createdTime":"2021-07-14 01:22:07","host":"us-004*","referer":"https://www.percona.com/blog/?p=76820","linkMd5ListStr":"103c5f9566a00742f8f7cb310ce26b0a","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"40.3 KB","destSize":"11.5 KB","compressRate":"28.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_174900-1024x399.png","sourceStatusCode":200,"destWidth":1024,"destHeight":399,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn68@2020_3/2021/07/13/17-22-07-829_de5f7c698e0b3104.webp","sourceBytes":425701,"destBytes":40064,"targetWebpQuality":75,"feedId":11,"totalSpendMs":584,"convertSpendMs":28,"createdTime":"2021-07-14 01:22:07","host":"us-024*","referer":"https://www.percona.com/blog/?p=76991","linkMd5ListStr":"7baf993af9e188b6b137ed5a280af57b","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"415.7 KB","destSize":"39.1 KB","compressRate":"9.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn59@2020_1/2021/07/13/17-22-07-774_3eb00843401a95f2.webp","sourceBytes":48907,"destBytes":8376,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1018,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:07","host":"europe-59*","referer":"https://www.percona.com/blog/?p=76750","linkMd5ListStr":"cdfcb5a1c0777a46246dc7777fb49e82","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"47.8 KB","destSize":"8.2 KB","compressRate":"17.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190545-1024x370.png","sourceStatusCode":200,"destWidth":1024,"destHeight":370,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn88@2020_1/2021/07/13/17-22-07-702_8ecaeb5255f19ac4.webp","sourceBytes":294225,"destBytes":37986,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1410,"convertSpendMs":22,"createdTime":"2021-07-14 01:22:06","host":"europe63*","referer":"https://www.percona.com/blog/?p=76991","linkMd5ListStr":"7baf993af9e188b6b137ed5a280af57b","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"287.3 KB","destSize":"37.1 KB","compressRate":"12.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-11.33.37-AM-1024x401.png","sourceStatusCode":200,"destWidth":1024,"destHeight":401,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn12@2020_1/2021/07/13/17-22-08-069_b6df9cf062d11343.webp","sourceBytes":241637,"destBytes":19734,"targetWebpQuality":75,"feedId":11,"totalSpendMs":393,"convertSpendMs":21,"createdTime":"2021-07-14 01:22:07","host":"us-020*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"236 KB","destSize":"19.3 KB","compressRate":"8.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDBAuthorizationGrant-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn8@2020_3/2021/07/13/17-22-08-063_057f62f2acea9afe.webp","sourceBytes":25119,"destBytes":9012,"targetWebpQuality":75,"feedId":11,"totalSpendMs":450,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:07","host":"us-032*","referer":"https://www.percona.com/blog/?p=75470","linkMd5ListStr":"f477311e2b6a8ed038663178f8ea1c46","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.5 KB","destSize":"8.8 KB","compressRate":"35.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn33@2020_2/2021/07/13/17-22-08-089_33e393aa37add02a.webp","sourceBytes":42223,"destBytes":5028,"targetWebpQuality":75,"feedId":11,"totalSpendMs":841,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:07","host":"europe66*","referer":"https://www.percona.com/blog/?p=76526","linkMd5ListStr":"0a78b8d6ce35d6eafe698c607c1cf30d","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.2 KB","destSize":"4.9 KB","compressRate":"11.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/11-1024x181.png","sourceStatusCode":200,"destWidth":1024,"destHeight":181,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn16@2020_1/2021/07/13/17-22-08-114_37ce05a139a7682e.webp","sourceBytes":122470,"destBytes":33302,"targetWebpQuality":75,"feedId":11,"totalSpendMs":471,"convertSpendMs":13,"createdTime":"2021-07-14 01:22:07","host":"us-008*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"119.6 KB","destSize":"32.5 KB","compressRate":"27.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-getLastErrorDefaults-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn100@2020_6/2021/07/13/17-22-08-053_1f4f00a42e4f14e5.webp","sourceBytes":19068,"destBytes":4838,"targetWebpQuality":75,"feedId":11,"totalSpendMs":789,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:07","host":"europe67*","referer":"https://www.percona.com/blog/?p=77061","linkMd5ListStr":"c802e2177f7f34c39ce8e41b2d24b46d","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.6 KB","destSize":"4.7 KB","compressRate":"25.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture10-1024x506.png","sourceStatusCode":200,"destWidth":1024,"destHeight":506,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn44@2020_3/2021/07/13/17-22-07-943_ca772e57dc2e3c6b.webp","sourceBytes":80946,"destBytes":75626,"targetWebpQuality":75,"feedId":11,"totalSpendMs":723,"convertSpendMs":38,"createdTime":"2021-07-14 01:22:07","host":"us-032*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"79 KB","destSize":"73.9 KB","compressRate":"93.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image3-1024x453.png","sourceStatusCode":200,"destWidth":1024,"destHeight":453,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn79@2020_4/2021/07/13/17-22-07-833_ff2dea52c68e4060.webp","sourceBytes":404386,"destBytes":40922,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1310,"convertSpendMs":30,"createdTime":"2021-07-14 01:22:07","host":"europe63*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"394.9 KB","destSize":"40 KB","compressRate":"10.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn28@2020_5/2021/07/13/17-22-08-210_6ebc3c883ccf52ae.webp","sourceBytes":78465,"destBytes":15968,"targetWebpQuality":75,"feedId":11,"totalSpendMs":357,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:08","host":"us-036*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76.6 KB","destSize":"15.6 KB","compressRate":"20.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn32@2020_1/2021/07/13/17-22-08-247_e46d8e34698f3686.webp","sourceBytes":23575,"destBytes":9362,"targetWebpQuality":75,"feedId":11,"totalSpendMs":425,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:08","host":"us-024*","referer":"https://www.percona.com/blog/?p=77071","linkMd5ListStr":"e34a79158454ed17846ac7be9c87726b","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23 KB","destSize":"9.1 KB","compressRate":"39.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Migrating-Ownership-MySQL-300x160.png","sourceStatusCode":200,"destWidth":300,"destHeight":160,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn36@2020_2/2021/07/13/17-22-08-272_8b34b3cdfc5311bc.webp","sourceBytes":59775,"destBytes":8230,"targetWebpQuality":75,"feedId":11,"totalSpendMs":375,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:08","host":"us-012*","referer":"https://www.percona.com/blog/?p=77159","linkMd5ListStr":"62029c87db3e05447872e34e8cc8241c","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"58.4 KB","destSize":"8 KB","compressRate":"13.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-200x105.jpg","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn20@2020_5/2021/07/13/17-22-08-256_994319764374d421.webp","sourceBytes":11184,"destBytes":9488,"targetWebpQuality":75,"feedId":11,"totalSpendMs":680,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:07","host":"europe21*","referer":"https://www.percona.com/blog/?p=76802","linkMd5ListStr":"386eea3706c2575adfd931e8a631c1aa","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.9 KB","destSize":"9.3 KB","compressRate":"84.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":74,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn23@2020_6/2021/07/13/17-22-08-280_abb43840edeeeb7b.webp","sourceBytes":5510,"destBytes":1352,"targetWebpQuality":75,"feedId":11,"totalSpendMs":717,"convertSpendMs":3,"createdTime":"2021-07-14 01:22:07","host":"europe-59*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c,8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.4 KB","destSize":"1.3 KB","compressRate":"24.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":76,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn60@2020_6/2021/07/13/17-22-08-452_b03caa950c617134.webp","sourceBytes":3092,"destBytes":1182,"targetWebpQuality":75,"feedId":11,"totalSpendMs":355,"convertSpendMs":2,"createdTime":"2021-07-14 01:22:08","host":"us-004*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3 KB","destSize":"1.2 KB","compressRate":"38.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image16.png","sourceStatusCode":200,"destWidth":585,"destHeight":273,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn71@2020_3/2021/07/13/17-22-08-574_83e9bf0ee0289d4a.webp","sourceBytes":34220,"destBytes":18682,"targetWebpQuality":75,"feedId":11,"totalSpendMs":404,"convertSpendMs":9,"createdTime":"2021-07-14 01:22:08","host":"us-032*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.4 KB","destSize":"18.2 KB","compressRate":"54.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB_Blog_1200x628-300x157.jpg","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn76@2020_5/2021/07/13/17-22-08-580_4f470f9e9b272f19.webp","sourceBytes":21778,"destBytes":17354,"targetWebpQuality":75,"feedId":11,"totalSpendMs":366,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:08","host":"us-020*","referer":"https://www.percona.com/blog/?p=76802","linkMd5ListStr":"386eea3706c2575adfd931e8a631c1aa","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.3 KB","destSize":"16.9 KB","compressRate":"79.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/3-999x1024.png","sourceStatusCode":200,"destWidth":999,"destHeight":1024,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn56@2020_4/2021/07/13/17-22-08-621_6fb9aada7e10be7e.webp","sourceBytes":572164,"destBytes":60688,"targetWebpQuality":75,"feedId":11,"totalSpendMs":532,"convertSpendMs":45,"createdTime":"2021-07-14 01:22:08","host":"us-016*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"558.8 KB","destSize":"59.3 KB","compressRate":"10.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/05/screenshot498-1.png","sourceStatusCode":200,"destWidth":1270,"destHeight":901,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn80@2020_1/2021/07/13/17-22-08-651_edcdb868e58314c5.webp","sourceBytes":204827,"destBytes":147972,"targetWebpQuality":75,"feedId":11,"totalSpendMs":420,"convertSpendMs":54,"createdTime":"2021-07-14 01:22:08","host":"us-008*","referer":"https://www.percona.com/blog/?p=76405","linkMd5ListStr":"87a0c051ddb862948f6d2aa8a21d2836","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"200 KB","destSize":"144.5 KB","compressRate":"72.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image17.png","sourceStatusCode":200,"destWidth":583,"destHeight":293,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn43@2020_6/2021/07/13/17-22-08-537_6ac77f06ff08656f.webp","sourceBytes":33731,"destBytes":20692,"targetWebpQuality":75,"feedId":11,"totalSpendMs":877,"convertSpendMs":9,"createdTime":"2021-07-14 01:22:08","host":"europe63*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.9 KB","destSize":"20.2 KB","compressRate":"61.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/blog-gitops-add-key.png","sourceStatusCode":200,"destWidth":967,"destHeight":562,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn91@2020_6/2021/07/13/17-22-08-715_575957c8aa084c95.webp","sourceBytes":29601,"destBytes":23424,"targetWebpQuality":75,"feedId":11,"totalSpendMs":401,"convertSpendMs":17,"createdTime":"2021-07-14 01:22:08","host":"us-036*","referer":"https://www.percona.com/blog/?p=76815","linkMd5ListStr":"41274bddba64661f4cc18887e083ce09","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"28.9 KB","destSize":"22.9 KB","compressRate":"79.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Enabling-SSLTLS-Sessions-In-PgBouncer-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn100@2020_6/2021/07/13/17-22-08-745_82f8714a760d4806.webp","sourceBytes":34240,"destBytes":8696,"targetWebpQuality":75,"feedId":11,"totalSpendMs":386,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:08","host":"us-012*","referer":"https://www.percona.com/blog/?p=76592","linkMd5ListStr":"4ac6a00baf384d4228bb0850832721e0","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.4 KB","destSize":"8.5 KB","compressRate":"25.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.48.28-AM-1024x549.png","sourceStatusCode":200,"destWidth":1024,"destHeight":549,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn96@2020_5/2021/07/13/17-22-08-800_a5d8f3f2eb639b37.webp","sourceBytes":447961,"destBytes":28514,"targetWebpQuality":75,"feedId":11,"totalSpendMs":473,"convertSpendMs":36,"createdTime":"2021-07-14 01:22:08","host":"us-024*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"437.5 KB","destSize":"27.8 KB","compressRate":"6.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-in-Azure-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn64@2020_5/2021/07/13/17-22-08-748_586a7a48f5c81800.webp","sourceBytes":12376,"destBytes":3946,"targetWebpQuality":75,"feedId":11,"totalSpendMs":773,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:08","host":"europe67*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.1 KB","destSize":"3.9 KB","compressRate":"31.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/2-1024x877.png","sourceStatusCode":200,"destWidth":1024,"destHeight":877,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn39@2020_6/2021/07/13/17-22-08-794_a9302e26fc1c90b2.webp","sourceBytes":339749,"destBytes":53668,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1105,"convertSpendMs":39,"createdTime":"2021-07-14 01:22:08","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"331.8 KB","destSize":"52.4 KB","compressRate":"15.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/5-1024x497.png","sourceStatusCode":200,"destWidth":1024,"destHeight":497,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn40@2020_6/2021/07/13/17-22-08-931_aa1dd8a58c0657ab.webp","sourceBytes":221596,"destBytes":36592,"targetWebpQuality":75,"feedId":11,"totalSpendMs":483,"convertSpendMs":26,"createdTime":"2021-07-14 01:22:08","host":"us-024*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"216.4 KB","destSize":"35.7 KB","compressRate":"16.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image6.png","sourceStatusCode":200,"destWidth":597,"destHeight":270,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn76@2020_1/2021/07/13/17-22-08-916_bca0e92b24b750c2.webp","sourceBytes":40701,"destBytes":19300,"targetWebpQuality":75,"feedId":11,"totalSpendMs":486,"convertSpendMs":15,"createdTime":"2021-07-14 01:22:08","host":"us-024*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"39.7 KB","destSize":"18.8 KB","compressRate":"47.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/05/PostgreSQL-HA-with-Patroni-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn15@2020_5/2021/07/13/17-22-08-947_0c8ab1ae9c0afb7e.webp","sourceBytes":20180,"destBytes":4956,"targetWebpQuality":75,"feedId":11,"totalSpendMs":412,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:08","host":"us-032*","referer":"https://www.percona.com/blog/?p=76405","linkMd5ListStr":"87a0c051ddb862948f6d2aa8a21d2836","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"19.7 KB","destSize":"4.8 KB","compressRate":"24.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.07.42-AM.png","sourceStatusCode":200,"destWidth":649,"destHeight":450,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn84@2020_3/2021/07/13/17-22-08-941_895f7bf89d0810ba.webp","sourceBytes":62967,"destBytes":22354,"targetWebpQuality":75,"feedId":11,"totalSpendMs":826,"convertSpendMs":14,"createdTime":"2021-07-14 01:22:08","host":"europe21*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"61.5 KB","destSize":"21.8 KB","compressRate":"35.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn20@2020_5/2021/07/13/17-22-09-107_7cf47b307f072e1e.webp","sourceBytes":43711,"destBytes":11632,"targetWebpQuality":75,"feedId":11,"totalSpendMs":367,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:09","host":"us-016*","referer":"https://www.percona.com/blog/?p=77006","linkMd5ListStr":"9146dc7aa938ba3a63c1166880042b5c","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"42.7 KB","destSize":"11.4 KB","compressRate":"26.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-b-1024x338.png","sourceStatusCode":200,"destWidth":1024,"destHeight":338,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn24@2020_5/2021/07/13/17-22-09-093_ff108c8b173848ca.webp","sourceBytes":150759,"destBytes":56068,"targetWebpQuality":75,"feedId":11,"totalSpendMs":428,"convertSpendMs":35,"createdTime":"2021-07-14 01:22:08","host":"us-004*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"147.2 KB","destSize":"54.8 KB","compressRate":"37.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-on-Kubernetes-with-GitOps-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn44@2020_5/2021/07/13/17-22-09-193_b29b187aee2664ed.webp","sourceBytes":11179,"destBytes":3884,"targetWebpQuality":75,"feedId":11,"totalSpendMs":356,"convertSpendMs":3,"createdTime":"2021-07-14 01:22:09","host":"us-008*","referer":"https://www.percona.com/blog/?p=76815","linkMd5ListStr":"41274bddba64661f4cc18887e083ce09","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.9 KB","destSize":"3.8 KB","compressRate":"34.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Chaos-Testing-Leads-to-More-Stable-Percona-XtraDB-Cluster-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn35@2020_3/2021/07/13/17-22-09-189_10d5ba8db3842a76.webp","sourceBytes":68300,"destBytes":9840,"targetWebpQuality":75,"feedId":11,"totalSpendMs":403,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:09","host":"us-032*","referer":"https://www.percona.com/blog/?p=76745","linkMd5ListStr":"0b8d2140da2ccca81d50f02f222f4d4d","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"66.7 KB","destSize":"9.6 KB","compressRate":"14.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn3@2020_3/2021/07/13/17-22-08-980_d698798f84e9f24c.webp","sourceBytes":19298,"destBytes":8326,"targetWebpQuality":75,"feedId":11,"totalSpendMs":926,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:08","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76919","linkMd5ListStr":"f6f45ae8f099380d94dafe7f3ce05c64","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.8 KB","destSize":"8.1 KB","compressRate":"43.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/4-1024x812.png","sourceStatusCode":200,"destWidth":1024,"destHeight":812,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn40@2020_6/2021/07/13/17-22-09-262_c588e175a8ab2c3d.webp","sourceBytes":259677,"destBytes":40294,"targetWebpQuality":75,"feedId":11,"totalSpendMs":439,"convertSpendMs":40,"createdTime":"2021-07-14 01:22:09","host":"us-020*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"253.6 KB","destSize":"39.3 KB","compressRate":"15.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-200x107.png","sourceStatusCode":200,"destWidth":200,"destHeight":107,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn8@2020_2/2021/07/13/17-22-09-027_aadd37e328f4c549.webp","sourceBytes":31251,"destBytes":3614,"targetWebpQuality":75,"feedId":11,"totalSpendMs":924,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:08","host":"europe63*","referer":"https://www.percona.com/blog/?p=72932","linkMd5ListStr":"6e38e7442976ba487e13a16608f61402","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"30.5 KB","destSize":"3.5 KB","compressRate":"11.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Authenticate-Percona-Server-for-MongoDB-Users-via-Native-LDAP-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn7@2020_1/2021/07/13/17-22-09-272_a7120fd8ee1943f1.webp","sourceBytes":26012,"destBytes":5734,"targetWebpQuality":75,"feedId":11,"totalSpendMs":792,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:08","host":"europe61*","referer":"https://www.percona.com/blog/?p=76902","linkMd5ListStr":"30b453db8ff23a943b1282fdc3be0ab6","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.4 KB","destSize":"5.6 KB","compressRate":"22%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Untitled-Diagram.png","sourceStatusCode":200,"destWidth":463,"destHeight":496,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn88@2020_3/2021/07/13/17-22-09-191_18f59609c769b9c3.webp","sourceBytes":508848,"destBytes":38008,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1199,"convertSpendMs":15,"createdTime":"2021-07-14 01:22:08","host":"europe-59*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"496.9 KB","destSize":"37.1 KB","compressRate":"7.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image14.png","sourceStatusCode":200,"destWidth":607,"destHeight":239,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn55@2020_4/2021/07/13/17-22-09-387_c7e9249848ee350c.webp","sourceBytes":27517,"destBytes":13482,"targetWebpQuality":75,"feedId":11,"totalSpendMs":408,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:09","host":"us-036*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.9 KB","destSize":"13.2 KB","compressRate":"49%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image4-1.png","sourceStatusCode":200,"destWidth":172,"destHeight":77,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn63@2020_4/2021/07/13/17-22-09-439_fb4b644f056af65f.webp","sourceBytes":4446,"destBytes":3104,"targetWebpQuality":75,"feedId":11,"totalSpendMs":381,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:09","host":"us-012*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4.3 KB","destSize":"3 KB","compressRate":"69.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/binlog.png","sourceStatusCode":200,"destWidth":171,"destHeight":201,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn48@2020_1/2021/07/13/17-22-09-439_e62585814c6ffa21.webp","sourceBytes":9427,"destBytes":5116,"targetWebpQuality":75,"feedId":11,"totalSpendMs":673,"convertSpendMs":19,"createdTime":"2021-07-14 01:22:09","host":"europe21*","referer":"https://www.percona.com/blog/?p=77226","linkMd5ListStr":"2519f01c262c6c14e723ec0fc147c6c1","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"9.2 KB","destSize":"5 KB","compressRate":"54.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/15-1024x903.png","sourceStatusCode":200,"destWidth":1024,"destHeight":903,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn59@2020_3/2021/07/13/17-22-09-495_44234b771e584a9d.webp","sourceBytes":234235,"destBytes":41224,"targetWebpQuality":75,"feedId":11,"totalSpendMs":468,"convertSpendMs":41,"createdTime":"2021-07-14 01:22:09","host":"us-024*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"228.7 KB","destSize":"40.3 KB","compressRate":"17.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Distribution-for-MySQL-Operator-Efficiency-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn28@2020_3/2021/07/13/17-22-09-336_daaa0d3289cd7395.webp","sourceBytes":39375,"destBytes":7834,"targetWebpQuality":75,"feedId":11,"totalSpendMs":903,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:08","host":"europe67*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"38.5 KB","destSize":"7.7 KB","compressRate":"19.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Complex-Archival-with-Percona-Toolkit-pt-archiver-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn83@2020_6/2021/07/13/17-22-09-630_b409e890035a0615.webp","sourceBytes":18769,"destBytes":5306,"targetWebpQuality":75,"feedId":11,"totalSpendMs":336,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:09","host":"us-016*","referer":"https://www.percona.com/blog/?p=77071","linkMd5ListStr":"e34a79158454ed17846ac7be9c87726b","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.3 KB","destSize":"5.2 KB","compressRate":"28.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/14-1024x653.png","sourceStatusCode":200,"destWidth":1024,"destHeight":653,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn88@2020_4/2021/07/13/17-22-09-753_e35c2d5316ccc2db.webp","sourceBytes":165329,"destBytes":36898,"targetWebpQuality":75,"feedId":11,"totalSpendMs":506,"convertSpendMs":53,"createdTime":"2021-07-14 01:22:09","host":"us-004*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"161.5 KB","destSize":"36 KB","compressRate":"22.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image8.png","sourceStatusCode":200,"destWidth":591,"destHeight":316,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn4@2020_4/2021/07/13/17-22-09-871_0d1e4b3127d93cd2.webp","sourceBytes":25081,"destBytes":13488,"targetWebpQuality":75,"feedId":11,"totalSpendMs":432,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:09","host":"us-020*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.5 KB","destSize":"13.2 KB","compressRate":"53.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/1-1024x625.png","sourceStatusCode":200,"destWidth":1024,"destHeight":625,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn100@2020_3/2021/07/13/17-22-09-801_8e40469404ebf386.webp","sourceBytes":323523,"destBytes":49194,"targetWebpQuality":75,"feedId":11,"totalSpendMs":526,"convertSpendMs":36,"createdTime":"2021-07-14 01:22:09","host":"us-032*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"315.9 KB","destSize":"48 KB","compressRate":"15.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-Shell-101-System-Log-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn8@2020_3/2021/07/13/17-22-09-891_86da49f5abdf766d.webp","sourceBytes":12939,"destBytes":3756,"targetWebpQuality":75,"feedId":11,"totalSpendMs":415,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:09","host":"us-008*","referer":"https://www.percona.com/blog/?p=77025","linkMd5ListStr":"8eb8e92d03bfcaf9d9e4eb5dff2f513d","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.6 KB","destSize":"3.7 KB","compressRate":"29%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn20@2020_6/2021/07/13/17-22-09-955_dbc136ad5c1b1d67.webp","sourceBytes":25950,"destBytes":4100,"targetWebpQuality":75,"feedId":11,"totalSpendMs":344,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:09","host":"us-036*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.3 KB","destSize":"4 KB","compressRate":"15.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-11-at-9.13.24-AM.png","sourceStatusCode":200,"destWidth":606,"destHeight":721,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn51@2020_1/2021/07/13/17-22-09-603_8d2b327eb77ede16.webp","sourceBytes":95235,"destBytes":50816,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1156,"convertSpendMs":19,"createdTime":"2021-07-14 01:22:09","host":"europe-59*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"93 KB","destSize":"49.6 KB","compressRate":"53.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn23@2020_6/2021/07/13/17-22-09-971_ea17e532ce803373.webp","sourceBytes":28925,"destBytes":9332,"targetWebpQuality":75,"feedId":11,"totalSpendMs":388,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:09","host":"us-024*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"28.2 KB","destSize":"9.1 KB","compressRate":"32.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.52.46-AM-1024x565.png","sourceStatusCode":200,"destWidth":1024,"destHeight":565,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn68@2020_5/2021/07/13/17-22-09-932_77e5466ee82bc55e.webp","sourceBytes":370587,"destBytes":7890,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1021,"convertSpendMs":26,"createdTime":"2021-07-14 01:22:09","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"361.9 KB","destSize":"7.7 KB","compressRate":"2.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture7-1024x502.png","sourceStatusCode":200,"destWidth":1024,"destHeight":502,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn72@2020_5/2021/07/13/17-22-09-882_98d070fa06c1b76e.webp","sourceBytes":198513,"destBytes":76426,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1017,"convertSpendMs":39,"createdTime":"2021-07-14 01:22:09","host":"europe63*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"193.9 KB","destSize":"74.6 KB","compressRate":"38.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MongoDB-Integrated-Alerting-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn92@2020_2/2021/07/13/17-22-09-973_e3a0caab26d845c0.webp","sourceBytes":17176,"destBytes":5028,"targetWebpQuality":75,"feedId":11,"totalSpendMs":822,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:09","host":"europe67*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16.8 KB","destSize":"4.9 KB","compressRate":"29.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.50.14-AM-1024x370.png","sourceStatusCode":200,"destWidth":1024,"destHeight":370,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn27@2020_6/2021/07/13/17-22-10-126_f1a5d456a8406700.webp","sourceBytes":108731,"destBytes":17738,"targetWebpQuality":75,"feedId":11,"totalSpendMs":518,"convertSpendMs":17,"createdTime":"2021-07-14 01:22:09","host":"us-012*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"106.2 KB","destSize":"17.3 KB","compressRate":"16.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn15@2020_2/2021/07/13/17-22-10-158_ba8ee8f7102be27f.webp","sourceBytes":36942,"destBytes":10064,"targetWebpQuality":75,"feedId":11,"totalSpendMs":753,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:09","host":"europe-59*","referer":"https://www.percona.com/blog/?p=77242","linkMd5ListStr":"8bb05fd9b53b2b68f0a0e5757c0c898a","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"36.1 KB","destSize":"9.8 KB","compressRate":"27.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn11@2020_4/2021/07/13/17-22-10-195_036acfc60d0360ed.webp","sourceBytes":28327,"destBytes":6130,"targetWebpQuality":75,"feedId":11,"totalSpendMs":839,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:09","host":"europe21*","referer":"https://www.percona.com/blog/?p=77108","linkMd5ListStr":"9ba979ce53fbf99b863b800a7e3fa275","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.7 KB","destSize":"6 KB","compressRate":"21.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.31.20-AM-1024x320.png","sourceStatusCode":200,"destWidth":1024,"destHeight":320,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn3@2020_4/2021/07/13/17-22-10-184_9361a6546784bff3.webp","sourceBytes":180377,"destBytes":22038,"targetWebpQuality":75,"feedId":11,"totalSpendMs":666,"convertSpendMs":25,"createdTime":"2021-07-14 01:22:09","host":"us-54*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"176.1 KB","destSize":"21.5 KB","compressRate":"12.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture12-1024x506.png","sourceStatusCode":200,"destWidth":1024,"destHeight":506,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn39@2020_3/2021/07/13/17-22-10-184_b3118e60d4b06525.webp","sourceBytes":80659,"destBytes":75032,"targetWebpQuality":75,"feedId":11,"totalSpendMs":862,"convertSpendMs":46,"createdTime":"2021-07-14 01:22:09","host":"us-54*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"78.8 KB","destSize":"73.3 KB","compressRate":"93%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-10.16.45-AM-1024x713.png","sourceStatusCode":200,"destWidth":1024,"destHeight":713,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn47@2020_4/2021/07/13/17-22-10-479_cd3ce6f6a145318d.webp","sourceBytes":432847,"destBytes":11822,"targetWebpQuality":75,"feedId":11,"totalSpendMs":517,"convertSpendMs":31,"createdTime":"2021-07-14 01:22:10","host":"us-016*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"422.7 KB","destSize":"11.5 KB","compressRate":"2.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/7-1024x839.png","sourceStatusCode":200,"destWidth":1024,"destHeight":839,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn52@2020_6/2021/07/13/17-22-10-475_8e248993bd6d9c3c.webp","sourceBytes":380966,"destBytes":38248,"targetWebpQuality":75,"feedId":11,"totalSpendMs":499,"convertSpendMs":45,"createdTime":"2021-07-14 01:22:10","host":"us-004*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"372 KB","destSize":"37.4 KB","compressRate":"10%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-200x113.jpg","sourceStatusCode":200,"destWidth":200,"destHeight":113,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn71@2020_3/2021/07/13/17-22-10-556_7d3a2e717cf8f303.webp","sourceBytes":10250,"destBytes":8236,"targetWebpQuality":75,"feedId":11,"totalSpendMs":595,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:10","host":"us-008*","referer":"https://www.percona.com/blog/?p=77170","linkMd5ListStr":"546cf3627d4d586dfdef81692a954802","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10 KB","destSize":"8 KB","compressRate":"80.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image7.png","sourceStatusCode":200,"destWidth":402,"destHeight":51,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn60@2020_2/2021/07/13/17-22-10-519_12c8b5c584fe1482.webp","sourceBytes":4244,"destBytes":1994,"targetWebpQuality":75,"feedId":11,"totalSpendMs":663,"convertSpendMs":13,"createdTime":"2021-07-14 01:22:10","host":"us-54*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4.1 KB","destSize":"1.9 KB","compressRate":"47%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MongoDB-5.0-Percona-300x169.jpg","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn63@2020_1/2021/07/13/17-22-10-612_3e12e9163d017270.webp","sourceBytes":19291,"destBytes":15672,"targetWebpQuality":75,"feedId":11,"totalSpendMs":644,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:10","host":"us-032*","referer":"https://www.percona.com/blog/?p=77170","linkMd5ListStr":"546cf3627d4d586dfdef81692a954802","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.8 KB","destSize":"15.3 KB","compressRate":"81.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn68@2020_2/2021/07/13/17-22-10-571_d497f421be5428c6.webp","sourceBytes":11002,"destBytes":3180,"targetWebpQuality":75,"feedId":11,"totalSpendMs":624,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:10","host":"us-54*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.7 KB","destSize":"3.1 KB","compressRate":"28.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screen-Shot-2021-06-10-at-9.49.51-AM-1024x706.png","sourceStatusCode":200,"destWidth":1024,"destHeight":706,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn67@2020_3/2021/07/13/17-22-10-605_f8e0f84be8411e59.webp","sourceBytes":451809,"destBytes":18634,"targetWebpQuality":75,"feedId":11,"totalSpendMs":639,"convertSpendMs":31,"createdTime":"2021-07-14 01:22:10","host":"us-020*","referer":"https://www.percona.com/blog/?p=76563","linkMd5ListStr":"a03697da25f9fe29acca8989e5f2f380","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"441.2 KB","destSize":"18.2 KB","compressRate":"4.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn96@2020_3/2021/07/13/17-22-10-792_8bac5969ca8dba9d.webp","sourceBytes":59417,"destBytes":10766,"targetWebpQuality":75,"feedId":11,"totalSpendMs":424,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:10","host":"us-54*","referer":"https://www.percona.com/blog/?p=77143","linkMd5ListStr":"edeb191ea230adfca668add5f1768361","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"58 KB","destSize":"10.5 KB","compressRate":"18.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/ProxySQL-Admin-2.x-Encryption-of-Credential-Information-300x160.png","sourceStatusCode":200,"destWidth":300,"destHeight":160,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn36@2020_5/2021/07/13/17-22-10-560_7004f02505a926c3.webp","sourceBytes":62873,"destBytes":8826,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1021,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:10","host":"europe63*","referer":"https://www.percona.com/blog/?p=72932","linkMd5ListStr":"6e38e7442976ba487e13a16608f61402","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"61.4 KB","destSize":"8.6 KB","compressRate":"14%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-June-2021-Bug-Report-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn84@2020_3/2021/07/13/17-22-10-823_2e6296d971c567e9.webp","sourceBytes":47737,"destBytes":7550,"targetWebpQuality":75,"feedId":11,"totalSpendMs":405,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:10","host":"us-036*","referer":"https://www.percona.com/blog/?p=77064","linkMd5ListStr":"8b7578f4fbd3d552208d32b52e79fc5c","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"46.6 KB","destSize":"7.4 KB","compressRate":"15.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture6-1024x502.png","sourceStatusCode":200,"destWidth":1024,"destHeight":502,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn32@2020_2/2021/07/13/17-22-10-470_651f7fc6925c28db.webp","sourceBytes":195301,"destBytes":76648,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1235,"convertSpendMs":35,"createdTime":"2021-07-14 01:22:09","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"190.7 KB","destSize":"74.9 KB","compressRate":"39.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn92@2020_3/2021/07/13/17-22-10-837_d07303843605570b.webp","sourceBytes":42157,"destBytes":5034,"targetWebpQuality":75,"feedId":11,"totalSpendMs":413,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:10","host":"us-012*","referer":"https://www.percona.com/blog/?p=76946","linkMd5ListStr":"ea6966a41fd35ac8cca88fedca0f1777","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.2 KB","destSize":"4.9 KB","compressRate":"11.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Compound-Shard-Keys-on-MongoDB-4.4-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn88@2020_5/2021/07/13/17-22-10-893_acb157c6804c35bc.webp","sourceBytes":30336,"destBytes":5152,"targetWebpQuality":75,"feedId":11,"totalSpendMs":375,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:10","host":"us-024*","referer":"https://www.percona.com/blog/?p=77143","linkMd5ListStr":"edeb191ea230adfca668add5f1768361","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.6 KB","destSize":"5 KB","compressRate":"17%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/tpcc_ext4_zfs.png","sourceStatusCode":200,"destWidth":756,"destHeight":425,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn24@2020_2/2021/07/13/17-22-10-738_c9764d721ac171b4.webp","sourceBytes":58233,"destBytes":33364,"targetWebpQuality":75,"feedId":11,"totalSpendMs":544,"convertSpendMs":31,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=77189","linkMd5ListStr":"402545669a4da5bf8fdcb39f91435884","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"56.9 KB","destSize":"32.6 KB","compressRate":"57.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture1-a-1024x514.png","sourceStatusCode":200,"destWidth":1024,"destHeight":514,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn44@2020_5/2021/07/13/17-22-10-792_3d2d69c244693db9.webp","sourceBytes":231347,"destBytes":79548,"targetWebpQuality":75,"feedId":11,"totalSpendMs":716,"convertSpendMs":53,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"225.9 KB","destSize":"77.7 KB","compressRate":"34.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image6.png","sourceStatusCode":200,"destWidth":786,"destHeight":305,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn88@2020_3/2021/07/13/17-22-10-715_3365f471cde1c493.webp","sourceBytes":24548,"destBytes":11530,"targetWebpQuality":75,"feedId":11,"totalSpendMs":714,"convertSpendMs":13,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24 KB","destSize":"11.3 KB","compressRate":"47%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn51@2020_2/2021/07/13/17-22-10-715_bdc7f822668d31fb.webp","sourceBytes":11983,"destBytes":3438,"targetWebpQuality":75,"feedId":11,"totalSpendMs":719,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=77189","linkMd5ListStr":"402545669a4da5bf8fdcb39f91435884","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.7 KB","destSize":"3.4 KB","compressRate":"28.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190749-1024x381.png","sourceStatusCode":200,"destWidth":1024,"destHeight":381,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn48@2020_5/2021/07/13/17-22-10-971_ca04cee4a6f6430d.webp","sourceBytes":184910,"destBytes":13788,"targetWebpQuality":75,"feedId":11,"totalSpendMs":405,"convertSpendMs":37,"createdTime":"2021-07-14 01:22:10","host":"us-54*","referer":"https://www.percona.com/blog/?p=76991","linkMd5ListStr":"7baf993af9e188b6b137ed5a280af57b","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"180.6 KB","destSize":"13.5 KB","compressRate":"7.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image13.png","sourceStatusCode":200,"destWidth":754,"destHeight":795,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn60@2020_4/2021/07/13/17-22-10-949_b30f12a5078705de.webp","sourceBytes":107701,"destBytes":60888,"targetWebpQuality":75,"feedId":11,"totalSpendMs":471,"convertSpendMs":37,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"105.2 KB","destSize":"59.5 KB","compressRate":"56.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/13-1024x589.png","sourceStatusCode":200,"destWidth":1024,"destHeight":589,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn32@2020_6/2021/07/13/17-22-10-912_83cc6a8fc802f732.webp","sourceBytes":111313,"destBytes":25390,"targetWebpQuality":75,"feedId":11,"totalSpendMs":484,"convertSpendMs":27,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"108.7 KB","destSize":"24.8 KB","compressRate":"22.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Software-Release-July-5-2021-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn75@2020_5/2021/07/13/17-22-10-918_96bc08260351d41a.webp","sourceBytes":86073,"destBytes":10550,"targetWebpQuality":75,"feedId":11,"totalSpendMs":840,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:10","host":"europe21*","referer":"https://www.percona.com/blog/?p=76946","linkMd5ListStr":"ea6966a41fd35ac8cca88fedca0f1777","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.1 KB","destSize":"10.3 KB","compressRate":"12.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn80@2020_1/2021/07/13/17-22-10-904_4fe3b1fa59759bd2.webp","sourceBytes":25989,"destBytes":8056,"targetWebpQuality":75,"feedId":11,"totalSpendMs":787,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:10","host":"europe-59*","referer":"https://www.percona.com/blog/?p=76820","linkMd5ListStr":"103c5f9566a00742f8f7cb310ce26b0a","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.4 KB","destSize":"7.9 KB","compressRate":"31%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image12.png","sourceStatusCode":200,"destWidth":589,"destHeight":300,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn98@2020_5/2021/07/13/17-22-10-991_dc07a64d6552c7e0.webp","sourceBytes":36833,"destBytes":18754,"targetWebpQuality":75,"feedId":11,"totalSpendMs":517,"convertSpendMs":25,"createdTime":"2021-07-14 01:22:10","host":"us-015*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"36 KB","destSize":"18.3 KB","compressRate":"50.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image1-2.png","sourceStatusCode":200,"destWidth":787,"destHeight":296,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn12@2020_4/2021/07/13/17-22-11-008_96776a83f5240b1e.webp","sourceBytes":22296,"destBytes":10554,"targetWebpQuality":75,"feedId":11,"totalSpendMs":496,"convertSpendMs":31,"createdTime":"2021-07-14 01:22:10","host":"us-54*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.8 KB","destSize":"10.3 KB","compressRate":"47.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Refining-Shard-Keys-in-MongoDB-4.4-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn56@2020_1/2021/07/13/17-22-10-681_a4a11e9cd4041bfd.webp","sourceBytes":21042,"destBytes":5124,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1130,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:10","host":"europe67*","referer":"https://www.percona.com/blog/?p=77242","linkMd5ListStr":"8bb05fd9b53b2b68f0a0e5757c0c898a","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.5 KB","destSize":"5 KB","compressRate":"24.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image15.png","sourceStatusCode":200,"destWidth":594,"destHeight":553,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn15@2020_5/2021/07/13/17-22-11-052_dcabfbab179fd855.webp","sourceBytes":72788,"destBytes":24264,"targetWebpQuality":75,"feedId":11,"totalSpendMs":560,"convertSpendMs":19,"createdTime":"2021-07-14 01:22:10","host":"us-028*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"71.1 KB","destSize":"23.7 KB","compressRate":"33.3%"},{"code":1,"isDone":false,"source":"https://s.w.org/images/core/emoji/13.0.1/72x72/26a0.png","sourceStatusCode":200,"destWidth":72,"destHeight":72,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn23@2020_2/2021/07/13/17-22-11-250_36dd853bf8881a1b.webp","sourceBytes":595,"destBytes":1080,"targetWebpQuality":75,"feedId":11,"totalSpendMs":338,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:11","host":"us-54*","referer":"https://www.percona.com/blog/?p=76750","linkMd5ListStr":"cdfcb5a1c0777a46246dc7777fb49e82","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"595 B","destSize":"1.1 KB","compressRate":"181.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture8-1024x502.png","sourceStatusCode":200,"destWidth":1024,"destHeight":502,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn32@2020_3/2021/07/13/17-22-11-240_19c6b8eeeee3c5f8.webp","sourceBytes":217644,"destBytes":75956,"targetWebpQuality":75,"feedId":11,"totalSpendMs":454,"convertSpendMs":60,"createdTime":"2021-07-14 01:22:11","host":"us-54*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"212.5 KB","destSize":"74.2 KB","compressRate":"34.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Using-MySQL-8-Dual-Passwords-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn27@2020_2/2021/07/13/17-22-11-275_6d23508aeb2341c3.webp","sourceBytes":22729,"destBytes":5690,"targetWebpQuality":75,"feedId":11,"totalSpendMs":373,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:11","host":"us-032*","referer":"https://www.percona.com/blog/?p=77006","linkMd5ListStr":"9146dc7aa938ba3a63c1166880042b5c","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.2 KB","destSize":"5.6 KB","compressRate":"25%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Screenshot_20210625_190241.png","sourceStatusCode":200,"destWidth":539,"destHeight":201,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn16@2020_6/2021/07/13/17-22-11-262_b98502938f7e3459.webp","sourceBytes":22125,"destBytes":15532,"targetWebpQuality":75,"feedId":11,"totalSpendMs":408,"convertSpendMs":7,"createdTime":"2021-07-14 01:22:11","host":"us-004*","referer":"https://www.percona.com/blog/?p=76991","linkMd5ListStr":"7baf993af9e188b6b137ed5a280af57b","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.6 KB","destSize":"15.2 KB","compressRate":"70.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Dynamic-and-Static-Privileges-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn32@2020_4/2021/07/13/17-22-11-281_b4795f79cab3dc8a.webp","sourceBytes":17870,"destBytes":5036,"targetWebpQuality":75,"feedId":11,"totalSpendMs":399,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:11","host":"us-020*","referer":"https://www.percona.com/blog/?p=76698","linkMd5ListStr":"85a323760676897ee72aca146fd55b44","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"17.5 KB","destSize":"4.9 KB","compressRate":"28.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn11@2020_3/2021/07/13/17-22-11-276_771ca0496fb9e8fe.webp","sourceBytes":25889,"destBytes":8282,"targetWebpQuality":75,"feedId":11,"totalSpendMs":434,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:11","host":"us-016*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.3 KB","destSize":"8.1 KB","compressRate":"32%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Percona-Monitoring-and-Management-MySQL-Semi-Sync-Summary-Dashboard-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn8@2020_3/2021/07/13/17-22-11-325_cb3a671bda874208.webp","sourceBytes":19935,"destBytes":6382,"targetWebpQuality":75,"feedId":11,"totalSpendMs":370,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:11","host":"us-028*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"19.5 KB","destSize":"6.2 KB","compressRate":"32%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/6-1024x542.png","sourceStatusCode":200,"destWidth":1024,"destHeight":542,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn35@2020_3/2021/07/13/17-22-11-379_944762f935e874b3.webp","sourceBytes":215634,"destBytes":23230,"targetWebpQuality":75,"feedId":11,"totalSpendMs":383,"convertSpendMs":23,"createdTime":"2021-07-14 01:22:11","host":"us-008*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"210.6 KB","destSize":"22.7 KB","compressRate":"10.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image19.png","sourceStatusCode":200,"destWidth":351,"destHeight":224,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn100@2020_4/2021/07/13/17-22-11-189_0d89a3bb4ab93c65.webp","sourceBytes":15593,"destBytes":7242,"targetWebpQuality":75,"feedId":11,"totalSpendMs":909,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:10","host":"europe63*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.2 KB","destSize":"7.1 KB","compressRate":"46.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Picture11-1024x506.png","sourceStatusCode":200,"destWidth":1024,"destHeight":506,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn95@2020_3/2021/07/13/17-22-11-260_48017dce2b6bae0a.webp","sourceBytes":78481,"destBytes":75596,"targetWebpQuality":75,"feedId":11,"totalSpendMs":936,"convertSpendMs":36,"createdTime":"2021-07-14 01:22:10","host":"europe-25*","referer":"https://www.percona.com/blog/?p=76888","linkMd5ListStr":"2f1bb10abb3c178a374f7f43fd35392e","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76.6 KB","destSize":"73.8 KB","compressRate":"96.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn48@2020_3/2021/07/13/17-22-11-465_b34ad7e6f637e65d.webp","sourceBytes":34384,"destBytes":10470,"targetWebpQuality":75,"feedId":11,"totalSpendMs":416,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:11","host":"us-036*","referer":"https://www.percona.com/blog/?p=77286","linkMd5ListStr":"68431c88494742c3568392793d179467","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.6 KB","destSize":"10.2 KB","compressRate":"30.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQL-on-Rocky-Linux-8-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn80@2020_1/2021/07/13/17-22-11-601_f87d824be697d745.webp","sourceBytes":54864,"destBytes":12580,"targetWebpQuality":75,"feedId":11,"totalSpendMs":323,"convertSpendMs":6,"createdTime":"2021-07-14 01:22:11","host":"us-028*","referer":"https://www.percona.com/blog/?p=77108","linkMd5ListStr":"9ba979ce53fbf99b863b800a7e3fa275","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"53.6 KB","destSize":"12.3 KB","compressRate":"22.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/MySQLZFS-Performance-Update-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn44@2020_2/2021/07/13/17-22-11-585_da03720aaa7ba4fd.webp","sourceBytes":21849,"destBytes":6788,"targetWebpQuality":75,"feedId":11,"totalSpendMs":781,"convertSpendMs":5,"createdTime":"2021-07-14 01:22:11","host":"europe-59*","referer":"https://www.percona.com/blog/?p=77189","linkMd5ListStr":"402545669a4da5bf8fdcb39f91435884","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.3 KB","destSize":"6.6 KB","compressRate":"31.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image9.png","sourceStatusCode":200,"destWidth":937,"destHeight":797,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn39@2020_1/2021/07/13/17-22-11-662_e5429016721a38c6.webp","sourceBytes":87545,"destBytes":41556,"targetWebpQuality":75,"feedId":11,"totalSpendMs":869,"convertSpendMs":28,"createdTime":"2021-07-14 01:22:11","host":"europe21*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"85.5 KB","destSize":"40.6 KB","compressRate":"47.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/image18.png","sourceStatusCode":200,"destWidth":596,"destHeight":329,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn20@2020_4/2021/07/13/17-22-11-503_1dd16ac5fe329ea8.webp","sourceBytes":19719,"destBytes":11494,"targetWebpQuality":75,"feedId":11,"totalSpendMs":940,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:11","host":"europe67*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"19.3 KB","destSize":"11.2 KB","compressRate":"58.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-Release-Roundup-June-21-2021-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn76@2020_5/2021/07/13/17-22-11-831_1206f85aa340d0ff.webp","sourceBytes":86131,"destBytes":10580,"targetWebpQuality":75,"feedId":11,"totalSpendMs":430,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:11","host":"us-54*","referer":"https://www.percona.com/blog/?p=76526","linkMd5ListStr":"0a78b8d6ce35d6eafe698c607c1cf30d","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.1 KB","destSize":"10.3 KB","compressRate":"12.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Streaming-MySQL-Binlogs-to-S3-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn24@2020_5/2021/07/13/17-22-13-004_4eda573d4f45b300.webp","sourceBytes":12849,"destBytes":4056,"targetWebpQuality":75,"feedId":11,"totalSpendMs":419,"convertSpendMs":4,"createdTime":"2021-07-14 01:22:12","host":"us-038*","referer":"https://www.percona.com/blog/?p=77226","linkMd5ListStr":"2519f01c262c6c14e723ec0fc147c6c1","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.5 KB","destSize":"4 KB","compressRate":"31.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Sneak-Peek-Into-Mongo-5.0-With-Percona-300x157.jpg","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn14@2020_1/2021/07/13/17-22-13-495_1e8c0801e300a4fe.webp","sourceBytes":19591,"destBytes":15714,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1171,"convertSpendMs":8,"createdTime":"2021-07-14 01:22:13","host":"europe-57*","referer":"https://www.percona.com/blog/?p=77254","linkMd5ListStr":"bb5d1e7fbccb0048b24243fb98524994","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"19.1 KB","destSize":"15.3 KB","compressRate":"80.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/pyramid-scaling2bis.jpg","sourceStatusCode":200,"destWidth":873,"destHeight":444,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn56@2020_2/2021/07/13/17-22-17-883_5aa93cfddd476fc5.webp","sourceBytes":106411,"destBytes":28796,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1532,"convertSpendMs":77,"createdTime":"2021-07-14 01:22:16","host":"us-040*","referer":"https://www.percona.com/blog/?p=76820","linkMd5ListStr":"103c5f9566a00742f8f7cb310ce26b0a","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"103.9 KB","destSize":"28.1 KB","compressRate":"27.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Converting-to-MongoDB-social-200x105.jpg","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn20@2020_2/2021/07/13/17-22-17-819_3ff5eedfaaefab73.webp","sourceBytes":8570,"destBytes":7046,"targetWebpQuality":75,"feedId":11,"totalSpendMs":976,"convertSpendMs":37,"createdTime":"2021-07-14 01:22:17","host":"us-040*","referer":"https://www.percona.com/blog/?p=76666","linkMd5ListStr":"819f8ee7a79f56fb58e8f8af81dad30b","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"8.4 KB","destSize":"6.9 KB","compressRate":"82.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/image2-2.png","sourceStatusCode":200,"destWidth":787,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn92@2020_2/2021/07/13/17-22-17-689_00f5d0cb262b3f57.webp","sourceBytes":24360,"destBytes":12126,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1392,"convertSpendMs":100,"createdTime":"2021-07-14 01:22:16","host":"us-040*","referer":"https://www.percona.com/blog/?p=77091","linkMd5ListStr":"2c3200cea35dd4d441cb3b1a51abc531","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23.8 KB","destSize":"11.8 KB","compressRate":"49.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Recover-Percona-XtraDB-Cluster-5.7-Node-Without-SST-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn3@2020_6/2021/07/13/17-22-17-751_18f0788d48f39970.webp","sourceBytes":21048,"destBytes":5868,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1456,"convertSpendMs":67,"createdTime":"2021-07-14 01:22:16","host":"us-040*","referer":"https://www.percona.com/blog/?p=77286","linkMd5ListStr":"68431c88494742c3568392793d179467","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.6 KB","destSize":"5.7 KB","compressRate":"27.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/WiredTiger-MongoDB-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn47@2020_4/2021/07/13/17-22-17-870_df0ed1f5dc48e0ef.webp","sourceBytes":23871,"destBytes":4086,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1054,"convertSpendMs":47,"createdTime":"2021-07-14 01:22:17","host":"us-040*","referer":"https://www.percona.com/blog/?p=76750","linkMd5ListStr":"cdfcb5a1c0777a46246dc7777fb49e82","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23.3 KB","destSize":"4 KB","compressRate":"17.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/Percona-XtraBackup-for-Windows-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn11@2020_6/2021/07/13/17-22-18-436_d14e7b15feed9c3e.webp","sourceBytes":13061,"destBytes":4328,"targetWebpQuality":75,"feedId":11,"totalSpendMs":837,"convertSpendMs":24,"createdTime":"2021-07-14 01:22:17","host":"us-040*","referer":"https://www.percona.com/blog/?p=76919","linkMd5ListStr":"f6f45ae8f099380d94dafe7f3ce05c64","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.8 KB","destSize":"4.2 KB","compressRate":"33.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/autoscaling-databases-kubernetes-mongodb-mysql-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn40@2020_1/2021/07/13/17-22-17-707_328aee9a84dec889.webp","sourceBytes":14229,"destBytes":4194,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1581,"convertSpendMs":106,"createdTime":"2021-07-14 01:22:16","host":"us-040*","referer":"https://www.percona.com/blog/?p=76820","linkMd5ListStr":"103c5f9566a00742f8f7cb310ce26b0a","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.9 KB","destSize":"4.1 KB","compressRate":"29.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/07/Inspecting-MySQL-Servers-PMM-200x113.png","sourceStatusCode":200,"destWidth":200,"destHeight":113,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn4@2020_4/2021/07/13/17-22-17-940_67d272f6b5762395.webp","sourceBytes":15625,"destBytes":5008,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1400,"convertSpendMs":171,"createdTime":"2021-07-14 01:22:17","host":"us-040*","referer":"https://www.percona.com/blog/?p=77196","linkMd5ListStr":"fce4f389c5abef783c23818e0dd4dc08","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.3 KB","destSize":"4.9 KB","compressRate":"32.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/MySQL-Static-and-Dynamic-Privileges-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn76@2020_1/2021/07/13/17-22-17-679_43d87dca1f3ec8dd.webp","sourceBytes":27139,"destBytes":9804,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2411,"convertSpendMs":72,"createdTime":"2021-07-14 01:22:16","host":"us-040*","referer":"https://www.percona.com/blog/?p=76691","linkMd5ListStr":"d0b3cc26c8b6425f9fa81b97d17f434d","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.5 KB","destSize":"9.6 KB","compressRate":"36.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/06/16-1024x640.png","sourceStatusCode":200,"destWidth":1024,"destHeight":640,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn84@2020_6/2021/07/13/17-22-18-772_33c771477e15aaec.webp","sourceBytes":382447,"destBytes":109748,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1712,"convertSpendMs":114,"createdTime":"2021-07-14 01:22:17","host":"us-040*","referer":"https://www.percona.com/blog/?p=76828","linkMd5ListStr":"e4840bb53d74ba0ffba2d186dd1d3221","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"373.5 KB","destSize":"107.2 KB","compressRate":"28.7%"}],"successGithubMap":{"myreaderx8":6,"myreaderx14":6,"myreaderx15":6,"myreaderx7":5,"myreaderx16":5,"myreaderx6":6,"myreaderx10":6,"myreaderx4":6,"myreaderx32":5,"myreaderx33":5,"myreaderx11":6,"myreaderx3":6,"myreaderx12":6,"myreaderx2":4,"myreaderx1":6,"myreaderx13":6,"myreaderx30":6,"myreaderx31":5,"myreaderx18":5,"myreaderx19":6,"myreaderx":6,"myreaderx25":5,"myreaderx27":5,"myreaderx21":6,"myreaderx22":5,"myreaderx23":5,"myreaderx24":6,"myreaderx5oss":6,"myreaderx29":6},"failGithubMap":{}}