{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","title":"How TalkingData uses AWS open source Deep Java Library with Apache Spark for machine learning inference at scale","link":"https://aws.amazon.com/blogs/opensource/how-talkingdata-uses-aws-open-source-deep-java-library-with-apache-spark-for-machine-learning-inference-at-scale/","description":"<p><em>This post is contributed by Xiaoyan Zhang, a Data Scientist from TalkingData.</em></p> \n<p><a href=\"http://www.talkingdata.com/\" target=\"_blank\" rel=\"noopener noreferrer\">TalkingData</a> is a data intelligence service provider that offers data products and services to provide businesses insights on consumer behavior, preferences, and trends. One of TalkingData’s core services is leveraging machine learning and deep learning models to predict consumer behaviors (e.g., likelihood of a particular group to buy a house or a car) and use these insights for targeted advertising. For example, a car dealer will only want to show their ads to customers who the model predicts are most likely to buy a car in the next three months.</p> \n<p>Initially, TalkingData was building an XGBoost model for these types of predictions, but their data science team wanted to explore whether deep learning models could have a significant performance improvement for their use case. After experimentation, their data scientists built a model on PyTorch, an open source deep learning framework, that achieved a 13% improvement on recall rate. (Recall rate is the percentage of times a model is able to give a prediction within a predefined confidence level.) In other words, their deep learning model managed to generate more predictions while maintaining a consistent level of accuracy.</p> \n<p>Deploying a deep learning model in production was challenging at the scale at which TalkingData operates, and required the model to provide hundreds of millions of predictions per day. Previously, TalkingData had been using Apache Spark, an open source distributed processing engine, to address their large-scale data processing needs. Apache Spark distributes data processing and computing jobs over multiple instances, which results in faster processing; however, Apache Spark is a Java/Scala-based application that often results in memory leak issues (such as crashes) when running Python programs. This is because the Java garbage collector in Spark does not have visibility into the memory usage of the Python application, and thus does not complete memory cleaning in time.</p> \n<p>The XGBoost model supported Java, and TalkingData was able to use the XGBoost Java API to deploy the model in Java and it worked well on Spark. However, PyTorch, the framework used by TalkingData’s deep learning model, did not have an out-of-box Java API. As a result, TalkingData could not directly run the PyTorch model on Apache Spark due to the memory leak issue. To circumvent the memory leak problem, TalkingData had to move data from Apache Spark (after data processing) to a separate GPU instance for running the PyTorch model inference job, which increased the end-to-end processing time and introduced additional maintenance overhead.</p> \n<p>The article <a href=\"https://towardsdatascience.com/implement-object-detection-with-pytorch-in-java-in-5-minutes-c3ba5769e7aa\" target=\"_blank\" rel=\"noopener noreferrer\">Implement Object Detection with PyTorch in Java in 5 minutes with DJL, an Engine-agnostic Deep Learning Library</a> taught the TalkingData production team about DJL (Deep Java Library), an open source deep learning framework written in Java and developed by AWS.</p> \n<p>In this post, we will walk through the model that TalkingData used and showcase their solution of using DJL to run inference for PyTorch models on Apache Spark. This approach provides an end-to-end solution to run everything on Apache Spark without involving additional services, and it reduced running time by 66% and reduced maintenance costs.</p> \n<h2>About the model</h2> \n<p>Trained on aggregated multi-field data collected by SDK embedded applications, TalkingData’s model is a binary classification model used to infer whether the active user is likely to buy a car. Different fields of data are aggregated and processed as arrays of categorical features, which are inevitably sparse. When TalkingData used traditional machine learning models, such as logistic regression and XGBoost, training becomes challenging for these simple models to learn from sparse features without overfitting. However, millions of training data points made it feasible to build more complicated and powerful models, so TalkingData upgraded their model to DNN (Deep Neural Network) models.</p> \n<p><img class=\"alignnone size-full wp-image-7451\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f1_new.png\" alt=\"The model that TalkingData used and showcase their solution of using DJL to run inference for PyTorch models on Apache Spark. This approach provides an end-to-end solution to run everything on Apache Spark without involving additional services and reduced running time by 66% and generated savings in maintenance costs.\" width=\"541\" height=\"491\" /></p> \n<p>In compliance with <a href=\"http://www.talkingdata.com/safety.jsp?languagetype=en_us\" target=\"_blank\" rel=\"noopener noreferrer\">laws and regulations</a>, the TalkingData model takes user information, user application information, and advertising information as inputs. User information includes device name and device model, user application information covers SDK embedded app package names, and advertising information is user-engaged campaign information. These different fields of input are aggregated over time and preprocessed—including tokenization and normalization—as categorical features.</p> \n<p>Inspired by Wide and Deep learning (refer to the <a href=\"https://arxiv.org/pdf/1606.07792.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Wide &amp; Deep Learning for Recommender Systems</a> [PDF]) and <a href=\"https://research.google.com/pubs/archive/45530.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">YouTube Deep Neural Networks</a> (PDF), categorical features are first mapped to their indices according to a pre-generated mapping table and truncated as fixed length before being fed into the PyTorch DNN model. The model is trained with corresponding word embeddings for each field.</p> \n<p>Embedding is a method to represent categorical variables with numeric vectors. It is a technique for reducing dimensionality of sparse categorical variables. For example, millions of different categories can be represented using hundreds of numbers in a vector, thus achieving dimensionality reduction for modeling. Different fields’ embeddings are simply averaged before concatenation into a fixed-length vector, which is fed into a feedforward neural network. During training, the max training epoch is set as 40, whereas the early stopping round is set as 15. Compared to the XGBoost-Spark model, the DNN model improves Area under the ROC Curve (AUC) by 6.5%, and recall at desired precision by up to 26%. The DNN model’s result is impressive considering TalkingData’s data volume is huge.</p> \n<h2>Scenario</h2> \n<p><img class=\"alignnone size-full wp-image-7454\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f2.png\" alt=\"TalkingData upgraded their model to DNN (Deep Neural Network) Models\" width=\"673\" height=\"430\" /></p> \n<p>Deployment became an obstacle to the DNN model because most of the processing logic was written in Scala. Deploying a PyTorch model directly on Scala often created memory leak issues—the JVM garbage collector did not have visibility into memory usage inside the C++ application (lower-level API that PyTorch calls). To avoid this issue, TalkingData’s machine learning engineering team had to use a separate GPU instance to do the offline inference.</p> \n<p><img class=\"alignnone size-full wp-image-7453\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f3.png\" alt=\"Deploying PyTorch model directly on Scala often created memory leak issues— the JVM garbage collector did not have visibility into memory usage inside the C++ application (lower level API that PyTorch calls). To avoid this issue, TalkingData’s machine learning engineering team had to use a separate GPU instance to do the offline inference.\" width=\"960\" height=\"246\" /></p> \n<p>This solution also created its own set problems:</p> \n<ul> \n <li>Performance issues: Pulling the data off and re-uploading took around 30 minutes.</li> \n <li>Single point failure: Users were unable to utilize the multi-instances Spark provides for computing. Computing (i.e, inferencing) ran on one single GPU instance separately, and there was no fallback mechanism if that GPU instance failed.</li> \n <li>Maintenance overhead: TalkingData needed to maintain code bases for both Scala and Python.</li> \n <li>Hard to scale: Because the dataset is large, a single instance solution was not sufficient.</li> \n</ul> \n<p>The volume of data size was hundreds of gigabytes. It took more than six hours to finish an end-to-end inference job, which was twice the amount of time the TalkingData team was hoping it would take to complete the process. This design became the bottleneck for the whole pipeline.</p> \n<h2>Implementing DJL</h2> \n<p>To solve this issue, TalkingData rebuilt their inference pipeline using DJL, which offered a PyTorch Java package that can be directly deployed on Spark. As shown below, all work can be done inside the Spark instance:</p> \n<p><img class=\"alignnone size-full wp-image-7452\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f4.png\" alt=\"Al work can be done inside the Spark instance\" width=\"960\" height=\"246\" /></p> \n<p>This design delivered the following advantages:</p> \n<ul> \n <li>Reduced failure rate: Spark helped manage instances to avoid single points of failure.</li> \n <li>Reduced cost: In TalkingData’s original workaround, inference was running on a separate GPU instance instead of utilizing the multi-instance compute power from Apache Spark. Now, TalkingData could leverage Apache Spark’s computational power to save money. In this case, they were able to avoid 20% cost from GPU instance costs each time they ran batch inference.</li> \n <li>Reduced maintenance: Scaling on Spark and maintaining a single language was relatively easy.</li> \n <li>Improved performance: DJL’s multi-thread inference boosted the performance on Spark.</li> \n</ul> \n<p>After implementing DJL, TalkingData managed to run the complete inference job in less than two hours, which was three times faster than the previous solution. It also saved them time from maintaining both the separate GPU instance and Apache Spark instances.</p> \n<h3>DJL’s multithreading strategy</h3> \n<p>DJL’s configuration options allowed users make the most out of Apache Spark’s distributed processing capability. Along the lines of PyTorch’s advanced feature on inter-op parallelism and intra-op parallelism (for optimizing inference performance), DJL offered similar functionality via the configuration settings <code>num_interop_threads</code> and <code>num_threads</code>. The number could be adjusted along with the Apache Spark core executors configuration, such as <code>--num-executors</code>, as both of them were using the same underlying CPU pool. Thus, DJL still allowed users to fine-tune the computing resource allocation for different performance goals in the same manner as PyTorch.</p> \n<h3>Correctness reliability check</h3> \n<p>To ensure DJL’s PyTorch solution would also achieve the same result as PyTorch using Python, TalkingData conducted an experiment. They ran 440k test samples, which resulted in the following element-wise difference between Python and DJL’s Scala inference results:</p> \n<div data-section-style=\"13\"> \n <table id=\"BIA9CAgyVM8\" style=\"width: 27.2em\" title=\"Sheet1\"> \n  <tbody> \n   <tr id=\"BIA9CAww76M\"> \n    <td id=\"s:BIA9CAww76M;BIA9CApdWsn\"><strong>Item</strong></td> \n    <td id=\"s:BIA9CAww76M;BIA9CADb8Qf\"><strong>Result</strong></td> \n    <td id=\"s:BIA9CAww76M;BIA9CAvYVbv\"><strong>Explanation</strong></td> \n   </tr> \n   <tr id=\"BIA9CAfOzJT\"> \n    <td id=\"s:BIA9CAfOzJT;BIA9CApdWsn\">Count</td> \n    <td id=\"s:BIA9CAfOzJT;BIA9CADb8Qf\">4387830</td> \n    <td id=\"s:BIA9CAfOzJT;BIA9CAvYVbv\">Total number of data</td> \n   </tr> \n   <tr id=\"BIA9CANYhep\"> \n    <td id=\"s:BIA9CANYhep;BIA9CApdWsn\">mean</td> \n    <td id=\"s:BIA9CANYhep;BIA9CADb8Qf\">5.27E-08</td> \n    <td id=\"s:BIA9CANYhep;BIA9CAvYVbv\">mean diff</td> \n   </tr> \n   <tr id=\"BIA9CAHDOso\"> \n    <td id=\"s:BIA9CAHDOso;BIA9CApdWsn\">std</td> \n    <td id=\"s:BIA9CAHDOso;BIA9CADb8Qf\">1.09E-05</td> \n    <td id=\"s:BIA9CAHDOso;BIA9CAvYVbv\">standard deviation</td> \n   </tr> \n   <tr id=\"BIA9CAUp8O3\"> \n    <td id=\"s:BIA9CAUp8O3;BIA9CApdWsn\">p25</td> \n    <td id=\"s:BIA9CAUp8O3;BIA9CADb8Qf\">0.00E+00</td> \n    <td id=\"s:BIA9CAUp8O3;BIA9CAvYVbv\">Ascending order top 25% of data</td> \n   </tr> \n   <tr id=\"BIA9CAUnVXl\"> \n    <td id=\"s:BIA9CAUnVXl;BIA9CApdWsn\">p50</td> \n    <td id=\"s:BIA9CAUnVXl;BIA9CADb8Qf\">2.98E-08</td> \n    <td id=\"s:BIA9CAUnVXl;BIA9CAvYVbv\">Ascending order top 50% of data</td> \n   </tr> \n   <tr id=\"BIA9CAm9fOb\"> \n    <td id=\"s:BIA9CAm9fOb;BIA9CApdWsn\">p75</td> \n    <td id=\"s:BIA9CAm9fOb;BIA9CADb8Qf\">5.96E-08</td> \n    <td id=\"s:BIA9CAm9fOb;BIA9CAvYVbv\">Ascending order top 75% of data</td> \n   </tr> \n   <tr id=\"BIA9CAf3ZLB\"> \n    <td id=\"s:BIA9CAf3ZLB;BIA9CApdWsn\">p99</td> \n    <td id=\"s:BIA9CAf3ZLB;BIA9CADb8Qf\">1.79E-07</td> \n    <td id=\"s:BIA9CAf3ZLB;BIA9CAvYVbv\">Ascending order top 99% of data</td> \n   </tr> \n   <tr id=\"BIA9CApv8qf\"> \n    <td id=\"s:BIA9CApv8qf;BIA9CApdWsn\">max</td> \n    <td id=\"s:BIA9CApv8qf;BIA9CADb8Qf\">7.22E-03</td> \n    <td id=\"s:BIA9CApv8qf;BIA9CAvYVbv\">Maximum difference on result</td> \n   </tr> \n  </tbody> \n </table> \n</div> \n<p>This experiment proved DJL was highly reliable on the inference result by ensuring more than 99% of the data would fall into 10^-7 compared to the training results on PyTorch using Python, or a floating point difference of less than 0.0000001.</p> \n<p>For more information about Spark inference, view the <a href=\"https://github.com/aws-samples/djl-demo/tree/master/spark/image-classification\" target=\"_blank\" rel=\"noopener noreferrer\">DJL Spark example</a> on GitHub and review the <a href=\"https://towardsdatascience.com/deep-learning-with-spark-in-deep-java-library-in-10-minutes-923a73704094\" target=\"_blank\" rel=\"noopener noreferrer\">blog post</a>.</p> \n<h2>Conclusion</h2> \n<p>TalkingData is now deploying deep learning models on Apache Spark using DJL. They switched to using DJL for deployment for the following reasons:</p> \n<ul> \n <li>DJL eliminates the need to maintain additional infrastructure other than Apache Spark.</li> \n <li>DJL let TalkingData fully utilize the computing power from Apache Spark for inference.</li> \n <li>DJL is framework-agnostic, which gives TalkingData the ability to deploy any deep learning model (i.e, Tensorflow, PyTorch, MXNet, etc.) without any deployment code change, reducing time to market for TalkingData’s new products/services.</li> \n</ul> \n<h3>About DJL</h3> \n<p><a href=\"https://djl.ai\" target=\"_blank\" rel=\"noopener noreferrer\">Deep Java Library (DJL)</a> is a Deep Learning Framework written in Java, supporting both training and inference. DJL is built on top of modern Deep Learning engines (TenserFlow, PyTorch, MXNet, etc.). Using DJL can help you train your model or deploy your favorite models from a variety of engines without any additional conversion. It contains a powerful ModelZoo design that allows you to manage trained models and load them in a single line. The built-in ModelZoo currently supports more than 70 pre-trained and ready to use models from GluonCV, Hugging Face, PyTorch Hub, and Keras.</p> \n<p>Follow our <a href=\"https://github.com/awslabs/djl/tree/master/docs\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>, <a href=\"https://github.com/aws-samples/djl-demo\" target=\"_blank\" rel=\"noopener noreferrer\">demo repository</a>, <a href=\"https://join.slack.com/t/deepjavalibrary/shared_invite/zt-ar91gjkz-qbXhr1l~LFGEIEeGBibT7w\" target=\"_blank\" rel=\"noopener noreferrer\">Slack channel</a>, and <a href=\"https://twitter.com/deepjavalibrary\" target=\"_blank\" rel=\"noopener noreferrer\">Twitter account</a> for more documentation and examples of DJL.</p> \n<div class=\"blog-author-box\" style=\"border: 1px solid #d5dbdb;padding: 15px\"> \n <h3 class=\"lb-h4\">Xiaoyan Zhang</h3> \n <p style=\"color: #879196;font-size: 1.2rem\">Xiaoyan is a Data Scientist from TalkingData. She is experienced in ads recommendation, customer data analysis, and fraud detection. Currently she is focused on scalable data platform design and effective ads recommendation research.</p> \n</div> \n<p><em>The content and opinions in this post are those of the third-party author and AWS is not responsible for the content or accuracy of this post.</em></p>","descriptionType":"html","publishedDate":"Thu, 27 Aug 2020 13:45:43 +0000","feedId":13680,"bgimg":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f1_new.png","linkMd5":"6d0bc346ee72a3a4f47ec440afadb4e3","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn56@2020_2/2020/09/05/08-55-51-247_3758088b31edf5d9.webp","destWidth":541,"destHeight":491,"sourceBytes":19558,"destBytes":13408,"author":"Qing Lan","articleImgCdnMap":{"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f1_new.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn56@2020_2/2020/09/05/08-55-51-247_3758088b31edf5d9.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f2.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn30@2020_5/2020/09/05/08-55-52-982_c62c3cf4a9de4e02.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f3.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn37@2020_2/2020/09/05/08-55-53-376_6df1496d164ba557.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f4.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn26@2020_2/2020/09/05/08-55-52-938_e2322ea12c9ccd2e.webp"},"publishedOrCreatedDate":1599296151078},{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","title":"Using open source FHIR APIs with FHIR Works on AWS","link":"https://aws.amazon.com/blogs/opensource/using-open-source-fhir-apis-with-fhir-works-on-aws/","description":"<p>In September 2019, we published a blog post, <a href=\"https://aws.amazon.com/blogs/architecture/building-a-serverless-fhir-interface-on-aws/\" target=\"_blank\" rel=\"noopener noreferrer\">Building a Serverless FHIR Interface on AWS</a>, which explained why customers might want to use FHIR (Fast Healthcare interoperability Resources) as a healthcare interface, and why serverless technology is a cost-efficient and flexible approach to these interfaces. The post explained the basic concepts underpinning FHIR, and how to go about creating a few of the basic FHIR Resource types (Patients, Observations, and Bundles). FHIR is gaining popularity around the world —especially in the US— where it is required by the <a href=\"https://www.cms.gov/Regulations-and-Guidance/Guidance/Interoperability/index\" target=\"_blank\" rel=\"noopener noreferrer\">2021 CMS mandate</a>. This is a problem for partners and customers who provide services for others, but who are struggling to build their own cost-effective FHIR stack.</p> \n<p>In this post we explain how a new open source project in AWS, <b>FHIR Works on AWS</b>, is available to these customers to accelerate their use of FHIR in their own products. We provide an overview of the software package and explain how to get started with it.</p> \n<h2>Introduction</h2> \n<p>With healthcare data increasingly and almost entirely digitized, healthcare organizations have an opportunity to use this data to improve patient outcomes and operational efficiency. However, healthcare is littered with disparate medical systems with interfaces that are either proprietary or that conform to older standards, such as HL7 v2, IHE, CDA, among others. Implementations of earlier interface standards are frequently inconsistent, and hence fail to achieve usable healthcare interoperability. This leads to a situation in which data are digitally available but not generally accessible.</p> \n<p>Recently efforts have been made to address this by issuing regulations requiring the accessibility of data and the standards used to achieve this. In the US, for example, a 2020 mandate from the Center of Medicare and Medicaid Services (CMS) aims to enforce by 2021 standardized healthcare data interoperability, first by providing patient access to data free of charge, and subsequently by mandating interfaces and data elements to be shared between healthcare systems.</p> \n<h2>Overview of the solution</h2> \n<p>Building on the aforementioned blog post, AWS has created an open source project, <a href=\"https://github.com/awslabs/fhir-works-on-aws-deployment\" target=\"_blank\" rel=\"noopener noreferrer\">FHIR Works on AWS</a>, an open source software toolkit that can be used to add capabilities of a FHIR interface to existing healthcare software. It implements a serverless FHIR API that supports the majority of FHIR Resource types and the most important operations. It also provides a set of architecture patterns to guide customers and partners through the process of designing and building integrations to their existing systems.</p> \n<p>FHIR Works aims to help software engineers at independent software vendors, system integrators or healthcare customers to enhance their own products to provide access to data in those systems to mobile devices and web portals through integrating the FHIR standard APIs. It also allows these customers and partners to build connectors between their legacy and proprietary interfaces to the current FHIR standard. Finally, it includes guidance on how to customize the default FHIR Works on AWS API to their individual needs with specific FHIR Implementation Guides.</p> \n<p>Many integration use cases require the ability to connect to a FHIR interface on one side and to legacy environments on the other. To help customers and partners achieve external legacy connectivity, FHIR Works on AWS includes an Integration Framework. This enables users to create their own Transforms that connect FHIR Works on AWS to any external interface, or to consume others published as open source or to the AWS Marketplace, opening up additional revenue opportunities for the partners creating them.</p> \n<p>Different data access scenarios sometimes require a data store optimized for those use cases, and so the software also includes a storage abstraction layer that enables customer developers to substitute the default storage of the underlying architecture—<a href=\"https://aws.amazon.com/s3/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Simple Storage Service</a> (Amazon S3) and <a href=\"https://aws.amazon.com/dynamodb/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon DynamoDB</a>—with alternative storage services, such as <a href=\"https://aws.amazon.com/rds/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Relational Database Service</a> (Amazon RDS), <a href=\"https://aws.amazon.com/redshift/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Redshift</a>, <a href=\"https://aws.amazon.com/neptune/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Neptune</a>, <a href=\"https://aws.amazon.com/qldb/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Quantum Ledger Database</a> (Amazon QLDB), etc.</p> \n<p>FHIR Works on AWS is installed using the Serverless Framework, making it straightforward to customize using the widely known TypeScript programming language. The framework sets up the API endpoints and logic in the customer’s account, implemented using <a href=\"https://aws.amazon.com/api-gateway/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon API Gateway</a>, <a href=\"https://aws.amazon.com/lambda/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Lambda</a>, <a href=\"https://aws.amazon.com/dynamodb/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon DynamoDB</a>, <a href=\"https://aws.amazon.com/cognito/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Cognito</a>, Amazon S3, and <a href=\"https://aws.amazon.com/kms/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Key Management Service</a> (AWS KMS), along with <a href=\"https://aws.amazon.com/elasticsearch-service/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Elasticsearch Service</a> (Amazon ES).</p> \n<p>This diagram explains the interaction between the individual components:</p> \n<p><img class=\"alignnone size-full wp-image-7042\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/07/27/dierks-FHIR-f1.png\" alt=\"diagram of interaction between the individual FHIR Works components\" width=\"936\" height=\"406\" /></p> \n<h2>Walkthrough</h2> \n<p>With this software package, AWS aims to serve customers and partners who have engineering resources available and need to augment their own software solutions with FHIR API endpoints, or who need to build new software solutions that interface between FHIR APIs and existing systems with other interfaces, such as HL7 v2, HL7 v3, IHE, etc. The software package is especially interesting for those customers and partners whose products don’t have their own FHIR APIs, and who are not set up to build their own implementation, or who wish to use an open source stack to accelerate their software solutions.</p> \n<h3>Authentication</h3> \n<p>To connect to the FHIR Works on AWS APIs successfully, the user first must obtain an Amazon Cognito access token. Out of the box, Amazon Cognito is used for authentication, which, due to Amazon Cognito’s ability to federate with other identity providers, also allows for authentication against other systems, such as <a href=\"https://aws.amazon.com/directoryservice/active-directory/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Directory Service for Microsoft Active Directory</a>. Systems or users accessing the APIs also must have an API key, which will have been generated during installation. This way a two-tier authentication is facilitated for additional security.</p> \n<p>Authentication addresses both the client system and the user of that system:</p> \n<ol> \n <li>An API Gateway Key is provided to each external client system to authenticate it to the API. During installation only one key is generated. Admins will need to add keys for additional client systems based on their knowledge of the deployment context.</li> \n <li>An Amazon Cognito access token is used to authenticate the user making the request—either using the external system or directly against the APIs.</li> \n</ol> \n<p>Each user will have their own Amazon Cognito Identity. This enables system administrators and auditors audit access on all resources—by both system and by who made the request— giving them visibility of where all requests were made from and who made them.</p> \n<p>With this key and access token, a secure HTTPS connection is made to the REST endpoint of the FHIR API. This request is forwarded by API Gateway to the AWS Lambda function implementing the FHIR logic to process the request.</p> \n<p>Depending on the FHIR Operation in the request, the AWS Lambda function either accesses the FHIR persistence store (Amazon DynamoDB by default), the search subsystem (Amazon ES), or Amazon S3 to generate signed URLs for larger objects. Writes to Amazon DynamoDB are replicated asynchronously to Amazon ES to enable a more flexible search experience.</p> \n<p>Amazon DynamoDB can be substituted with other data stores by the customer to satisfy different use cases when incorporating FHIR Works on AWS into their solution.</p> \n<h3>Authorization</h3> \n<p>In this first release of FHIR Works on AWS, authorization is done using a Role-Based Access Control (RBAC). This restricts access to FHIR Operations and Resources based on a few simple role definitions that can be associated with users: auditor, practitioner, and non-practitioner. FHIR Works on AWS will be providing more sophisticated authorization in future releases, including SMART on FHIR.</p> \n<h3>Audit logging</h3> \n<p>To enable administrators and auditors to trace what patient information has been accessed by which user and when it was accessed, the API tracks all data access requests and responses. Requests and responses are intercepted by API Gateway and logged to <a href=\"https://aws.amazon.com/cloudwatch/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon CloudWatch</a>. Customers and partners can then run analytics on these logs as with other AWS products.</p> \n<p>Although CloudWatch is a convenient way to store such data, it comes at a higher price than S3. Thus, FHIR Works on AWS includes optional scripts to archive the audit logs to an encrypted S3 bucket for cost reduction. Customers can achieve further cost savings by extending these scripts to move the audit data into <a href=\"https://aws.amazon.com/glacier/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Simple Storage Service Glacier</a>.</p> \n<h3>Binary resources</h3> \n<p>Binary resources are challenging in the world of REST APIs, because transfers can exceed endpoint timeouts due to their size. Binary resources can be anything from small MRI images to large images or a series of images, as well as genomic data or EKG wavelengths. The slower transfers associated with these larger objects can quickly exceed limits on timeouts and payload sizes (6 and 10MB respectively for API Gateway and Lambda). Additionally, BASE64-encoded transmission of large files is inefficient through a REST API. This is an acknowledged issue with the FHIR specification that, at the time of this writing, is still awaiting an authoritative solution with current tendencies toward the path implemented by FHIR Works on AWS.</p> \n<p>FHIR Works on AWS uses a creative approach to address this, combining Amazon S3 with RESTful APIs. If a client wants to write a binary resource, upon making the POST request, it receives a response containing a time-limited, pre-signed S3 URL. The client can then use this temporary URL to upload the object.</p> \n<p>When retrieving the file, the response to the client’s GET request again includes a temporary S3 pre-signed URL that is used for the download.</p> \n<p>To ensure this approach is secure, the pre-signed URLs’ lifetime is extremely short, so a response’s chance of being intercepted is extremely low; it would require the transmission’s HTTPS TLS key to be hacked and the response object to be interpreted within a few seconds. This approach makes it practically impossible to gain unauthorized access to binary resources by this means, and to receive security approval by AWS Application Security. A further applicable preventative control would be to limit access by source IP address to the S3 bucket in question, which would enable only permitted clients to issue requests using that pre-signed URL.</p> \n<h2>Access to the source code</h2> \n<p>Why not try out FHIR Works on AWS right away? To simplify the inclusion of FHIR Works on AWS into your own code, it is structured as separate packages with their own repositories based on functional boundaries. This way it is easy to replace, for example, the storage layer with a custom storage without jeopardizing compatibility or upgrade safety for the other functional components. The central installation source code repository is publicly <a href=\"https://github.com/awslabs/fhir-works-on-aws-deployment\" target=\"_blank\" rel=\"noopener noreferrer\">available on GitHub</a>. Here you can find references to the other packages and instructions on how to use and consume them.</p> \n<p>Clone the repositories to access the entirety of its source code and scripts.</p> \n<h3>Installation</h3> \n<p>Installing the software is straightforward. Although the software’s main purpose is to provide customers and partners with source code to accelerate adding a FHIR API to their own solutions, testing the functionality first may be helpful.</p> \n<p>For this purpose, the software provides simple install scripts for Linux (Amazon, Ubuntu), macOS, Windows, and a Docker container for operating systems beyond this list. Using one of these methods will create the API Gateway FHIR API, associated Lambda functions, and also provision Amazon Cognito, DynamoDB, Amazon ES, and S3. This provides a deployment that can function as a standalone server for users to immediately test its endpoints prior to dissecting the packages for incorporation into their own software projects.</p> \n<p>The GitHub repositories contain a README.md file in Markdown format. (Use a Markdown viewer of your choice, such as MacDown for macOS or VS Code on Windows to view it appropriately formatted.) These files will be regularly updated with changes to the repository, and to educate users on the prerequisites and the installation process.</p> \n<h3>API endpoints</h3> \n<p>To connect to the API endpoints, an access token must be retrieved from Amazon Cognito, which also requires an API key to facilitate multi-factor security. This can be achieved using the Cognito APIs, or through a script provided with the software repository.</p> \n<p>FHIR Works on AWS’ FHIR capabilities are being enhanced with additional functionality, which is regularly released to the open source repository. Based on instructions from the README file, after you receive an access token, a call to the deployment’s <code>/metadata/</code> endpoint will reveal its FHIR Capability Statement.</p> \n<p>For example, on a macOS in the repository’s ./scripts/ directory, execute the following command, substituting all variables based on the output of the following command:</p> \n<pre>AWS_ACCESS_KEY_ID=&lt;ACCESS_KEY&gt; AWS_SECRET_ACCESS_KEY=&lt;SECRET-KEY&gt; python3 init-auth.py &lt;USER_POOL_APP_CLIENT_ID&gt; &lt;REGION&gt;</pre> \n<p>This will return an authentication token that can used with the <code>curl</code> utility to access the <code>/metadata</code> endpoint. For example:</p> \n<pre>curl -H &quot;Accept: application/fhir+json&quot; -H &quot;Authorization: Bearer ${TOKEN}&quot; -H &quot;x-api-key: ${&lt;API-KEY&gt;}&quot; https://&lt;hostname&gt;/&lt;stage&gt;/metadata\n</pre> \n<p>All STU3 and R4.0.1 FHIR resources are implemented, although some—such as Audit and Subscription—are restricted to stubs at this time. Bundles are implemented, however, to ensure complex linked Resources can be added and retrieved, it is limited to 25 entries per bundle.</p> \n<h3>Postman samples</h3> \n<p>The package also contains sample files that enable customers to test connections to their deployment using the <a href=\"https://www.postman.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Postman</a> tool. Inside the <code>postman/</code> folder, a collection of sample requests on a limited number of resources enables that tool to connect to the deployment’s FHIR API endpoints and create Patient Resources, search them, retrieve them, and delete them (implemented as a soft-delete); and to store, retrieve, and delete Binary resources, as well as retrieve its Capability Statement.</p> \n<p>Along with simple instructions on how to use these samples, this enables a user to test the endpoints, gain familiarity with FHIR, or test their own solutions once incorporated with FHIR Works on AWS.</p> \n<p>Import the <code>environments</code> file and the sample scripts into Postman, modify the authentication information in the environments within Postman (based on the output of the <code>init-auth.py</code> script above), and start testing to your heart’s content.</p> \n<h3>Cleaning up</h3> \n<p>The FHIR Works on AWS software package installs AWS resources using the Serverless Framework. To maintain a clean environment, Serverless is also used to remove FHIR Works and any trace of it from your environment. See the README.md file for details.</p> \n<h2>Conclusion</h2> \n<p>With the ever-growing need for native FHIR API support in healthcare software, smaller customers and partners struggle to keep up with the demand. FHIR Works on AWS gives these customers an option to use open source code in their applications rather than having to invest in creating and maintaining their own implementation. FHIR Works on AWS is simple to install and the code is easy to modify and incorporate into any software solution.</p>","descriptionType":"html","publishedDate":"Fri, 28 Aug 2020 19:02:05 +0000","feedId":13680,"bgimg":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/07/27/dierks-FHIR-f1.png","linkMd5":"b10a68dcae37c51c171ccc82989095ca","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn61@2020_4/2020/09/05/08-55-51-254_befb0f6e3fe3da73.webp","destWidth":936,"destHeight":406,"sourceBytes":202527,"destBytes":24082,"author":"Henner Dierks","articleImgCdnMap":{"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/07/27/dierks-FHIR-f1.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn61@2020_4/2020/09/05/08-55-51-254_befb0f6e3fe3da73.webp"},"publishedOrCreatedDate":1599296151077},{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","title":"OpenShift 4 on AWS Quick Starts","link":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","description":"<p>Customers selecting AWS as their preferred cloud have been able to deploy <a href=\"https://www.openshift.com/\" target=\"_blank\" rel=\"noopener noreferrer\">OpenShift</a> through a variety of means. In this post we will explore what has changed in the latest version of OpenShift, and what these changes mean for AWS customers. We also will explore the latest OpenShift on <a href=\"https://aws.amazon.com/quickstart/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Quick Starts</a> open source project, which is helping customers and partners deploy OpenShift on AWS, and we’ll review integration solutions that run as application workloads within OpenShift on AWS.</p> \n<h2>Overview</h2> \n<p>In 2017 AWS provided the first OpenShift Quick Start for OpenShift 3.x, which used <a href=\"https://aws.amazon.com/cloudformation/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS CloudFormation</a> to deploy the AWS resources and <a href=\"https://www.ansible.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Ansible</a> scripts to deploy OpenShift onto the provided <a href=\"https://aws.amazon.com/ec2/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Elastic Compute Cloud</a> (Amazon EC2) instances. The OpenShift control plane is deployed into the customer AWS account and this saw three master nodes behind <a href=\"https://aws.amazon.com/elasticloadbalancing/\" target=\"_blank\" rel=\"noopener noreferrer\">Elastic Load Balancing</a> (ELB) spread across three availability zones.</p> \n<p><img class=\"alignnone size-full wp-image-7140\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f1.png\" alt=\"\" width=\"900\" height=\"566\" /></p> \n<p>OpenShift 4 includes many changes. The adoption of <a href=\"https://www.openshift.com/learn/topics/operators\" target=\"_blank\" rel=\"noopener noreferrer\">Operators</a> has been significant—not only does OpenShift 4 allow partners to implement integrations via Operators, but all of the underlying features and components of OpenShift are Operator controlled. There is now a Storage Operator that provides simple storage configuration when running on AWS. The OpenShift Storage Operator has support for <a href=\"https://aws.amazon.com/ebs/?ebs-whats-new.sort-by=item.additionalFields.postDateTime&amp;ebs-whats-new.sort-order=desc\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Elastic Block Store</a> (Amazon EBS) as well as <a href=\"https://aws.amazon.com/efs/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Elastic File System</a> (Amazon EFS). Operations teams can configure the Storage Operator to provision and manage AWS storage directly from within the OpenShift management console and CLI. Machine sets allow customers to control scaling and healing of worker nodes directly from within OpenShift in the same way customers enjoyed with autoscaling groups.</p> \n<p>Here is a glimpse of some of the operators under the hood of a basic OpenShift install:</p> \n<p><img class=\"alignnone size-full wp-image-7141\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f2.png\" alt=\"\" width=\"900\" height=\"529\" /></p> \n<p>The OpenShift installation process has seen the most dramatic change. The OpenShift installer allows customers to select the environment on which they want to deploy clusters. When deploying OpenShift on AWS, parameters for the AWS region, number of availability zones, EC2 instance sizing, and the number of master and worker nodes would be defined. The installer then generates an ignition file that it uses to deploy the cluster.</p> \n<p>The OpenShift installer works for a user-provided infrastructure in which the underlying compute, storage, and networking is deployed first, and then OpenShift is installed onto these resources. This is similar to how OpenShift 3 would have been deployed. The OpenShift 4 install also works for installer-provisioned infrastructure in which the installer builds out the underlying AWS resources as part of the OpenShift install.</p> \n<p>AWS and Red Hat are constantly collecting customer feedback and using it to evolve recommended patterns for running OpenShift on AWS. As these evolutions are made, the Red Hat installer team updates the installer to work for these patterns. As such, the OpenShift installer has now become a living reference architecture for deploying OpenShift on AWS.</p> \n<p><img class=\"alignnone size-full wp-image-7142\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f3.png\" alt=\"\" width=\"900\" height=\"448\" /></p> \n<p>&nbsp;</p> \n<h2>OpenShift 4 on AWS Quick Starts</h2> \n<p>How do you take advantage of all the new OpenShift features, provide an even simpler prescriptive means customers may already be familiar with, and enable other solutions provided through the AWS Quick Starts program to deploy on OpenShift on AWS?</p> \n<p>The first change was to allow the <a href=\"https://aws.amazon.com/quickstart/architecture/openshift/\" target=\"_blank\" rel=\"noopener noreferrer\">Red Hat OpenShift on AWS Quick Start</a> to take advantage of the installer-provisioned infrastructure process provided by the OpenShift installer. As AWS and Red Hat improve the installer process upstream, the Quick Start can consume this directly. To this effect, the Quick Start will deploy into either a new VPC or an existing one.</p> \n<p>AWS CloudFormation is used to provide parameters for the installer process. This allows customers familiar with AWS Quick Starts solutions to run them in the way they are used to. Customers and AWS partners building Quick Start solutions that run on OpenShift can use the Red Hat OpenShift on AWS Quick Start as a submodule and a ready-to-consume building block.</p> \n<p>The Red Hat OpenShift on AWS Quick Start will provision a collection of <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (S3)</a> buckets to store the ignition files generated by <a href=\"https://aws.amazon.com/lambda/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Lambda</a> functions for use by the installer. These functions are created when deploying the Quick Start.</p> \n<p>Lambda functions download the OpenShift installer files and invoked the installer. This deploys OpenShift into the AWS customer account using the installer-provisioned infrastructure mode. Customers must provide a PullSecret needed by the install process to link this deployment of OpenShift to a subscription. Customers must first log into <a href=\"http://cloud.redhat.com\">cloud.redhat.com</a> to download their PullSecret.</p> \n<p><img class=\"alignnone size-full\" src=\"https://openshift4-on-aws.awsworkshop.io/images/GetPullSecret.gif\" width=\"1152\" height=\"720\" /></p> \n<p><img class=\"alignnone size-full wp-image-7143\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f5.png\" alt=\"\" width=\"900\" height=\"349\" /></p> \n<p>Three OpenShift master nodes will be deployed across three AWS Availability Zones (AZ). Should an AZ be impacted, the other two AZs provide resilience. Should a singe Amazon EC2 instance be impacted, the failover means within OpenShift itself will allow the cluster to continue functioning. Auto healing and replacement of the master nodes is not currently available.</p> \n<p><img class=\"alignnone size-full wp-image-7144\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f6.png\" alt=\"\" width=\"900\" height=\"747\" /></p> \n<p><img class=\"alignnone size-full wp-image-7147\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f7.png\" alt=\"OpenShift Hosts Configuration with 3 number of masters, 3 nodes, master instance type m5.xlarge, nodes instance type m5.xlarge\" width=\"900\" height=\"365\" /></p> \n<p>&nbsp;</p> \n<p>In the event a master node fails, follow the OpenShift documentation for <a href=\"https://docs.openshift.com/container-platform/4.3/backup_and_restore/replacing-failed-master.html\" target=\"_blank\" rel=\"noopener noreferrer\">replacing a failed master host</a> to replace it.</p> \n<p>Red Hat is working toward providing automatic scaling and healing of master nodes. When this becomes available it will be added to the installer and consumed by the Quick Start.</p> \n<p>Three machine sets are provisioned in separate AWS Availability Zones, allowing for scaling, resilience, and healing of the worker nodes. The machine sets will use <a href=\"https://aws.amazon.com/cloudwatch/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon CloudWatch</a> metrics to monitor the underlying EC2 instances. The machine sets will add and remove EC2 instances to the OpenShift cluster as demand changes. Replacement of nodes is also possible; although this was available in the OpenShift 3 Quick Start, machine sets provide a tighter integration between OpenShift and AWS. Additional machine sets can be added by operations teams post-deployment if desired. The OpenShift documentation provides additional details:</p> \n<ul> \n <li><a href=\"https://docs.openshift.com/container-platform/4.3/machine_management/creating_machinesets/creating-machineset-aws.html\" target=\"_blank\" rel=\"noopener noreferrer\">Creating a MachineSet in AWS</a></li> \n <li><a href=\"https://docs.openshift.com/container-platform/4.3/machine_management/creating-infrastructure-machinesets.html\" target=\"_blank\" rel=\"noopener noreferrer\">Creating infrastructure MachineSets</a></li> \n</ul> \n<p>Customers have a few options for managing certificates for SSL offloading. Though many customers opt to make use of the self-assigned certificates provided by OpenShift, AWS customers have voiced the desire to use <a href=\"https://aws.amazon.com/certificate-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Certificate Manager (ACM)</a> with OpenShift. The Red Hat OpenShift on AWS Quick Start in intended to work for a variety of options and use cases.</p> \n<p>The following image shows the certificate-related parameter inputs for the Quick Start:</p> \n<p><img class=\"alignnone size-full wp-image-7148\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f8.png\" alt=\"\" width=\"900\" height=\"539\" /></p> \n<p>Customers are able provide the ARN of certificates provided by ACM, import a certificate from a third-party certificate authority, or use the self-assigned certificate.</p> \n<h2>Conclusion</h2> \n<p>With the Red Hat OpenShift on AWS Quick Start, customers can deploy OpenShift on AWS with ease by providing a few parameters to an AWS CloudFormation template, or use this as part of a nested stack to deploy other solutions that would run on OpenShift on AWS.</p> \n<p>The AWS Quick Starts are all open source projects. Components and features of Red Hat OpenShift are open source, and we encourage you to take part in contributing.</p> \n<ul> \n <li><a href=\"https://github.com/aws-quickstart/quickstart-redhat-openshift\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Quick Starts on GitHub</a></li> \n <li><a href=\"https://github.com/openshift\" target=\"_blank\" rel=\"noopener noreferrer\">OpenShift on GitHub</a></li> \n <li><a href=\"https://github.com/openshift/enhancements/tree/master/enhancements\" target=\"_blank\" rel=\"noopener noreferrer\">Enhancement tracking repository for OKD</a></li> \n</ul> \n<p>&nbsp;</p>","descriptionType":"html","publishedDate":"Thu, 03 Sep 2020 12:50:19 +0000","feedId":13680,"bgimg":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f1.png","linkMd5":"efae17dc6b25459bd6df3ba0faba91e8","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn54@2020_3/2020/09/05/08-55-51-322_e836dd1feed6571a.webp","destWidth":900,"destHeight":566,"sourceBytes":444965,"destBytes":54420,"author":"Ryan Niksch","articleImgCdnMap":{"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f1.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn54@2020_3/2020/09/05/08-55-51-322_e836dd1feed6571a.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f2.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn86@2020_3/2020/09/05/08-55-52-998_784572edd0d2868d.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f3.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn77@2020_4/2020/09/05/08-55-53-076_245e30116ecc096e.webp","https://openshift4-on-aws.awsworkshop.io/images/GetPullSecret.gif":null,"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f5.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn93@2020_3/2020/09/05/08-55-53-116_ae2dde5112ad3adf.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f6.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn49@2020_3/2020/09/05/08-55-53-013_e47e0992010daff2.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f7.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn45@2020_5/2020/09/05/08-55-52-971_fd6caa8cf444a57f.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f8.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn61@2020_2/2020/09/05/08-55-53-031_4a73637d8802874f.webp"},"publishedOrCreatedDate":1599296151075},{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","title":"Dgraph on AWS: Setting up a horizontally scalable graph database","link":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","description":"<p><i>This article is a guest post from Jaoquin Menchaca, an SRE at Dgraph.</i></p> \n<p><a href=\"https://dgraph.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Dgraph</a> is an open source, distributed graph database, built for production environments, and written entirely in Go. Dgraph is fast, transactional, sharded, and distributed (joins, filters, sorts), consistently replicated with <a href=\"https://raft.github.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Raft</a>, and provides fault tolerance with synchronous replication and horizontal scalability.</p> \n<p>The language used to interact with Dgraph is GraphQL and our variant called GraphQL+-. This gives apps access to the benefits of GraphQL directly from the database.</p> \n<p>Dgraph has client integrations with official clients in Go, Java, Python, JavaScript, and C#; and community-supported clients with Dart, Rust, and Elixir. Dgraph users also can use any of the tools and libraries that work with GraphQL.</p> \n<p>To get started right away, <a href=\"https://dgraph.io/downloads\" target=\"_blank\" rel=\"noopener noreferrer\">download Dgraph</a> and follow the <a href=\"https://dgraph.io/docs/get-started/\" target=\"_blank\" rel=\"noopener noreferrer\">quick-start guide</a>.</p> \n<p>Getting started with Dgraph locally on your own computer, where you can quickly model your data in Dgraph and build your app, is easy. When you’re ready to deploy this to a production environment, you’ll want to deploy Dgraph to the cloud. You can horizontally scale Dgraph across multiple machines for high availability and data sharding.</p> \n<p>In this article, we’ll show how to set up a resilient highly available Dgraph cluster on AWS.</p> \n<h2>Dgraph architecture</h2> \n<p>Dgraph is deployed as a single binary with no external dependencies. You can use the same binary to run all of Dgraph. The official <a href=\"https://dgraph.io/docs/deploy/#docker\" target=\"_blank\" rel=\"noopener noreferrer\">Dgraph Docker image</a> simplifies deploying to Kubernetes, where you can set up a multi-node highly available Dgraph cluster.</p> \n<p>Two kinds of processes are in a Dgraph cluster: Zeros (cluster managers) and Alphas (data servers). Zeros control the Dgraph cluster, store the group membership of Alphas, and manage transactions cluster-wide. Alphas store data and indexes and serve all client requests.</p> \n<p>We will need at least one Zero and one Alpha to run Dgraph. There can be multiple Zeros and Alphas running in groups as a cluster. There is always a single group of Zeros and one or more groups of Alphas. Each group is a Raft consensus group for high availability and consistent replication.</p> \n<p><img class=\"alignnone size-full wp-image-7380\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f1.png\" alt=\"Raft consensus groups in Dgraph showing Zero Group and Alpha Group\" width=\"911\" height=\"320\" /></p> \n<p>Dgraph is resilient to any one of these instances failing. The cluster remains available for users to read and write their data. Distributed systems can fail for a myriad of reasons, and these failures shouldn’t make our backend go awry. As long as the majority of a group remains up, then requests can proceed. More specifically, if the number of replicas is <b>2N + 1</b>, up to <b>N</b> servers can be down without any impact on reads or writes. Groups are odd-numbered for a quorum.</p> \n<h2>Kubernetes: An ideal Dgraph companion</h2> \n<p>Although Dgraph can run on a cluster of nodes for high availability, an orchestration tool is necessary for health checking, self-healing, storage volume management, and setting up the network. The Kubernetes platform provides all of this, making it the ideal platform to host Dgraph.</p> \n<p>Kubernetes maintains Dgraph’s resiliency as it constantly monitors Dgraph instances for readiness and liveness, and it can automatically move instances off of unhealthy worker nodes and run them on healthy ones. Kubernetes manages stateful apps like Dgraph with <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\" target=\"_blank\" rel=\"noopener noreferrer\">StatefulSets</a>. Every Dgraph process is deployed as a <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod/\" target=\"_blank\" rel=\"noopener noreferrer\">Pod</a>. In StatefulSets, Kubernetes gives each pod the same hostname identity and persistent volumes even when it moves to different worker nodes. If a worker node goes bad or if a Dgraph process gets restarted, then the pod will restart on a healthy worker node and re-sync the latest changes from replicated peers. Even when a pod restarts, Dgraph is available to process all requests on the rest of the healthy nodes.</p> \n<p>The illustration below shows what the Dgraph Stateful Set (<b>sts</b>) as it relates to other components. This includes three pods and corresponding allocation of storage, called <b>pvc</b> (persistent volume claim) that comes from a persistent volume (<b>pv</b>). Alongside this, we deploy a service (<b>svc</b>) resource that will route traffic to one of three highly available pods.</p> \n<p><img class=\"alignnone size-full wp-image-7381\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f2.png\" alt=\"Kubernetes components deployed\" width=\"980\" height=\"737\" /></p> \n<h2>Creating a Kubernetes cluster on AWS</h2> \n<p>On AWS, <a href=\"https://aws.amazon.com/eks/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Elastic Kubernetes Service</a> (Amazon EKS) is the recommended way to run Kubernetes. Amazon EKS manages the master control plane and worker nodes and offers integration with AWS resources in security, networking, storage, monitoring, scaling, and more.</p> \n<p>Although Kubernetes provides high availability through scaling and recovery of workloads called pods, Amazon EKS node groups also provide scaling and recovery to the worker nodes themselves. The illustration below is an example Amazon EKS cluster that has six worker nodes available to host Dgraph Alphas and Zeros, as well multiple masters managed by Amazon EKS.</p> \n<p><img class=\"alignnone size-full wp-image-7382\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f3.png\" alt=\"Kubernetes with Amazon EKS\" width=\"950\" height=\"564\" /></p> \n<p>The simplest way to get started immediately with building an Amazon EKS cluster is to use <a href=\"https://eksctl.io/\" target=\"_blank\" rel=\"noopener noreferrer\">eksctl</a>, a command-line tool to deploy Amazon EKS using <a href=\"https://aws.amazon.com/cloudformation/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS CloudFormation</a> stacks. This tool automates a lot of complexity involved with provisioning Amazon EKS. In addition to <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html\" target=\"_blank\" rel=\"noopener noreferrer\">installing eksctl</a>, we also need to <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html\" target=\"_blank\" rel=\"noopener noreferrer\">install kubectl</a> to interact with Kubernetes once it’s up.</p> \n<h3>Provision EKS cluster</h3> \n<p>We have an example eksctl configuration that can be used for this exercise; download the example <a href=\"https://github.com/dgraph-io/dgraph/blob/master/contrib/config/kubernetes/dgraph-ha/cluster.yaml\" target=\"_blank\" rel=\"noopener noreferrer\">from GitHub</a>.</p> \n<p>We can create the cluster with the command:</p> \n<pre><code class=\"lang-bash\">CONFIG=&quot;https://raw.githubusercontent.com/dgraph-io/dgraph/master/contrib/config/kubernetes/dgraph-ha/cluster.yaml&quot;\n\ncurl --silent $CONFIG | eksctl create cluster --config-file -</code></pre> \n<p>This configuration creates a three-node Amazon EKS cluster in the <b>us-east-2</b> region. The process takes about 20 minutes to fully provision the Kubernetes infrastructure. Once the process completes, we can test our cluster with the following command:</p> \n<pre><code class=\"lang-bash\">kubectl get all --all-namespaces</code></pre> \n<p>With Kubernetes up and running, we can now deploy Dgraph.</p> \n<h2>Creating a high availability Dgraph cluster on Kubernetes</h2> \n<p>Now that we have a Kubenetes cluster with Amazon EKS, we can deploy a highly available Dgraph cluster on Kubernetes.</p> \n<p>We have an example manifest, <b>dgraph-ha.yaml</b>, to get us up and running with a high availability Dgraph cluster. We can run it in Kubernetes by running the following command:</p> \n<pre><code class=\"lang-bash\">MANIFEST=&quot;https://raw.githubusercontent.com/dgraph-io/dgraph/master/contrib/config/kubernetes/dgraph-ha/dgraph-ha.yaml&quot;\n\nkubectl apply --filename $MANIFEST</code></pre> \n<p>This Kubernetes manifest will create a Dgraph cluster with three Alpha pods and three Zero pods, as well as a pod for the web client Ratel. The Alpha and Zero pods are run via <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\" target=\"_blank\" rel=\"noopener noreferrer\">StatefulSets</a> with a persistent <a>Amazon Elastic Block Store (Amazon EBS)</a> volume to store the data, so they can keep the same data around even if they’re restarted or rescheduled to different machines. The web client Ratel is stateless, so it is a <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\" target=\"_blank\" rel=\"noopener noreferrer\">Deployment</a> with no extra persistent disks needed.</p> \n<p>The manifest does not expose any of these services to the public internet for security reasons. If we would like to add endpoints, we can modify the manifest to add these changes, such as changing the service type to <a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/\" target=\"_blank\" rel=\"noopener noreferrer\">LoadBalancer</a>, or adding an <a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\" target=\"_blank\" rel=\"noopener noreferrer\">Ingress</a> resource.</p> \n<p>The following Kubernetes diagram is similar to diagrams used in the <a href=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes basic tutorial</a> and other Kubernetes documentation. This is an overview of the components involved when deploying Dgraph on Kubernetes. The Zero and Alpha pods deployed by a StatefulSet controller, as mentioned previously, will be distributed across the cluster and have an attached disk, indicated by the purple disk icon. The Ratel pod deployed by a Deployment controller will only have a single pod in one of the tree worker nodes and does not have an attached persistent disk.</p> \n<p><img class=\"alignnone size-full wp-image-7383\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f4.png\" alt=\"Kubernetes Cluster\" width=\"891\" height=\"869\" /></p> \n<h2>Accessing the cluster (revised)</h2> \n<p>We can view services that are running with the following command:</p> \n<pre><code class=\"lang-bash\">kubectl get services</code></pre> \n<p>This will show something similar to the following:</p> \n<p><img class=\"alignnone size-full wp-image-7384\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f5.png\" alt=\"results showing services running\" width=\"950\" height=\"327\" /></p> \n<p>We will need to access <code>dgraph-alpha-public</code> and <code>dgraph-ratel-public</code>. With <code>dgraph-alpha-public</code>, we have HTTP access on port <code>8080</code> and gRPC access port <code>9080</code>, and with the <code>dgraph-ratel-public</code> web UI, we have HTTP access on port <code>8000</code>.</p> \n<p>We can make these accessible locally via <code>localhost</code> using the <code>kubectl port-forward</code> command. For this section, we will open up multiple terminal windows or tabs.</p> \n<h3>Port forward locally</h3> \n<p>In a new terminal, run the following command to access an Alpha pod through HTTP:</p> \n<pre><code class=\"lang-bash\">kubectl port-forward service/dgraph-alpha-public 8080:8080</code></pre> \n<p>In a new terminal, run the following command to access a Ratel pod through HTTP:</p> \n<pre><code class=\"lang-bash\">kubectl port-forward service/dgraph-ratel-public 8000:8000</code></pre> \n<h3>Interacting with Ratel</h3> \n<p>We can access Ratel by typing <a href=\"http://localhost:8000/\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost:8000/</a> in a browser. We will be presented with three options; select <b>Latest</b>.</p> \n<p>For the <b>Dgraph Server Connection</b>, select <a href=\"http://localhost:8080\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost:8080</a>, <b>Connect</b>, <b>Continue</b>. Now we should have a window that shows something like:</p> \n<p><img class=\"alignnone size-full wp-image-7385\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f6.png\" alt=\"For the Dgraph Server Connection, pick http://localhost:8080, hit the Connect button and then Continue button. You should by now have a window that looks something like this:\" width=\"950\" height=\"675\" /></p> \n<h4>Mutation using Ratel</h4> \n<p>If we already have mutations and queries in mind, we can run these now. This example is similar to our <a href=\"https://dgraph.io/docs/get-started/#step-2-run-mutation\" target=\"_blank\" rel=\"noopener noreferrer\">Getting Started Step 2: Run Mutation</a> documentation.</p> \n<p>Select the <b>Console</b> and <b>Mutate</b> radio button, copy and paste the text below, and then select the <b>Run</b> button.</p> \n<pre><code class=\"lang-bash\">{\n  &quot;set&quot;: [\n    {&quot;uid&quot;: &quot;_:luke&quot;,&quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;dgraph.type&quot;: &quot;Person&quot;},\n    {&quot;uid&quot;: &quot;_:leia&quot;,&quot;name&quot;: &quot;Princess Leia&quot;, &quot;dgraph.type&quot;: &quot;Person&quot;},\n    {&quot;uid&quot;: &quot;_:han&quot;,&quot;name&quot;: &quot;Han Solo&quot;, &quot;dgraph.type&quot;: &quot;Person&quot;},\n    {&quot;uid&quot;: &quot;_:lucas&quot;,&quot;name&quot;: &quot;George Lucas&quot;, &quot;dgraph.type&quot;: &quot;Person&quot;},\n    {&quot;uid&quot;: &quot;_:irvin&quot;,&quot;name&quot;: &quot;Irvin Kernshner&quot;, &quot;dgraph.type&quot;: &quot;Person&quot;},\n    {&quot;uid&quot;: &quot;_:richard&quot;,&quot;name&quot;: &quot;Richard Marquand&quot;, &quot;dgraph.type&quot;: &quot;Person&quot;},\n    {\n      &quot;uid&quot;: &quot;_:sw1&quot;,\n      &quot;name&quot;: &quot;Star Wars: Episode IV - A New Hope&quot;,\n      &quot;release_date&quot;: &quot;1977-05-25&quot;,\n      &quot;revenue&quot;: 775000000,\n      &quot;running_time&quot;: 121,\n      &quot;starring&quot;: [{&quot;uid&quot;: &quot;_:luke&quot;},{&quot;uid&quot;: &quot;_:leia&quot;},{&quot;uid&quot;: &quot;_:han&quot;}],\n      &quot;director&quot;: [{&quot;uid&quot;: &quot;_:lucas&quot;}],\n      &quot;dgraph.type&quot;: &quot;Film&quot;\n    },\n    {\n      &quot;uid&quot;: &quot;_:sw2&quot;,\n      &quot;name&quot;: &quot;Star Wars: Episode V - The Empire Strikes Back&quot;,\n      &quot;release_date&quot;: &quot;1980-05-21&quot;,\n      &quot;revenue&quot;: 534000000,\n      &quot;running_time&quot;: 124,\n      &quot;starring&quot;: [{&quot;uid&quot;: &quot;_:luke&quot;},{&quot;uid&quot;: &quot;_:leia&quot;},{&quot;uid&quot;: &quot;_:han&quot;}],\n      &quot;director&quot;: [{&quot;uid&quot;: &quot;_:irvin&quot;}],\n      &quot;dgraph.type&quot;: &quot;Film&quot;\n    },\n    {\n      &quot;uid&quot;: &quot;_:sw3&quot;,\n      &quot;name&quot;: &quot;Star Wars: Episode VI - Return of the Jedi&quot;,\n      &quot;release_date&quot;: &quot;1983-05-25&quot;,\n      &quot;revenue&quot;: 572000000,\n      &quot;running_time&quot;: 131,\n      &quot;starring&quot;: [{&quot;uid&quot;: &quot;_:luke&quot;},{&quot;uid&quot;: &quot;_:leia&quot;},{&quot;uid&quot;: &quot;_:han&quot;}],\n      &quot;director&quot;: [{&quot;uid&quot;: &quot;_:richard&quot;}],\n      &quot;dgraph.type&quot;: &quot;Film&quot;\n    },\n    {\n      &quot;uid&quot;: &quot;_:st1&quot;,\n      &quot;name&quot;: &quot;Star Trek: The Motion Picture&quot;,\n      &quot;release_date&quot;: &quot;1979-12-07&quot;,\n      &quot;revenue&quot;: 139000000,\n      &quot;running_time&quot;: 132,\n      &quot;dgraph.type&quot;: &quot;Film&quot;\n    }\n  ]\n}</code></pre> \n<h4>Schema using Ratel</h4> \n<p>Then we can alter the schema by selecting the <b>Schema</b> button on the left, and then the <b>Bulk Edit</b> button. In this edit box, copy and paste the text below, and then select <b>Apply Schema</b>.</p> \n<pre><code class=\"lang-bash\">name: string @index(term) .\n release_date: datetime @index(year) .\n revenue: float .\n running_time: int .\n \n type Person {\n   name\n }\n \n type Film {\n   name\n   release_date\n   revenue\n   running_time\n   starring\n   director\n }</code></pre> \n<p>The interface should look something like:</p> \n<p><img class=\"alignnone size-full wp-image-7386\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f7.png\" alt=\"Interface showing Edit Schema File with option to apply schema\" width=\"950\" height=\"625\" /></p> \n<h4>Query using Ratel</h4> \n<p>Now we can do a query. Select <b>Console</b>, <b>Query</b>, then copy and paste the following:</p> \n<pre><code class=\"lang-bash\">{\n me(func:allofterms(name, &quot;Star Wars&quot;)) @filter(ge(release_date, &quot;1980&quot;)) {\n   name\n   release_date\n   revenue\n   running_time\n   director {\n    name\n   }\n   starring {\n    name\n   }\n }\n}</code></pre> \n<p>After the results return, we are shown the JSON and the graphical representation of the graph. This should look something like the following:</p> \n<p><img class=\"alignnone size-full wp-image-7387\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f8.png\" alt=\"Once the results return, we can see the JSON as well as look at the graphical representation of the graph.\" width=\"950\" height=\"625\" /></p> \n<p>We also can view the equivalent result in JSON:</p> \n<p><img class=\"alignnone size-full wp-image-7388\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f9.png\" alt=\"Once the results return, we are shown the JSON and the graphical representation of the graph.\" width=\"950\" height=\"811\" /></p> \n<p>And that’s it. We have run our first mutation and ran a query to find the relationships between the movies actors played in and the directors of those movies.</p> \n<h2>Cleaning up</h2> \n<p>Once finished with the Dgraph cluster, we can remove it from Kubernetes with the following command:</p> \n<pre><code class=\"lang-bash\">MANIFEST=&quot;https://raw.githubusercontent.com/dgraph-io/dgraph/master/contrib/config/kubernetes/dgraph-ha/dgraph-ha.yaml&quot;\n \n# delete workloads (statefulsets, deployments, pods) and services\nkubectl delete --filename $MANIFEST\n# delete storage (persistent volume claims and associated volumes)\nkubectl delete pvc --selector app=dgraph-alpha\nkubectl delete pvc --selector app=dgraph-zero</code></pre> \n<p>If we are finished with the Amazon EKS cluster that we deployed with eksctl, we can remove this with:</p> \n<pre><code class=\"lang-bash\">eksctl delete cluster --name dgraph-ha-cluster --region us-east-2</code></pre> \n<h2>Conclusion</h2> \n<p>Refer to <a href=\"https://dgraph.io/docs/\" target=\"_blank\" rel=\"noopener noreferrer\">our documentation</a> for additional information on this deployment topic, and other Dgraph topics and links to tutorials. You can join the <a href=\"https://discuss.dgraph.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Dgraph community</a>, where you can post questions and share your experiences with Dgraph.</p> \n<div class=\"blog-author-box\" style=\"border: 1px solid #d5dbdb;padding: 15px\"> \n <p class=\"blog-author-image\"><img class=\"alignleft wp-image-1288 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/joaquin_menchaca.jpeg\" alt=\"Jaoquin Menchaca\" width=\"150\" height=\"150\" /></p> \n <h3 class=\"lb-h4\">Jaoquin Menchaca</h3> \n <p style=\"color: #879196;font-size: 1.2rem\">Joaquin is an SRE at Dgraph Labs. He started early in QA and transitioned to Ops. He is passionate about DevOps philosophy and advancements in cloud native infrastructure, and he brings years of experience in change configuration and container orchestration. In his spare time, Joaquin enjoys conversing in different languages, having studied 12, including French, Spanish, Japanese, and Korean.</p> \n</div> \n<p><em>The content and opinions in this post are those of the third-party author and AWS is not responsible for the content or accuracy of this post.</em></p>","descriptionType":"html","publishedDate":"Tue, 01 Sep 2020 13:48:48 +0000","feedId":13680,"bgimg":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f1.png","linkMd5":"11b14affaae75c5aa558447ba8650a32","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn70@2020_2/2020/09/05/08-55-51-473_67d6aafbdfe12797.webp","destWidth":911,"destHeight":320,"sourceBytes":32116,"destBytes":16010,"author":"Robert Zhu","articleImgCdnMap":{"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f1.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn70@2020_2/2020/09/05/08-55-51-473_67d6aafbdfe12797.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f2.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn2@2020_2/2020/09/05/08-55-53-051_cc0f5d601439c327.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f3.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn98@2020_2/2020/09/05/08-55-53-079_11214f442d552654.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f4.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_1/2020/09/05/08-55-53-176_bcfe9f6ae3c71bb8.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f5.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn81@2020_4/2020/09/05/08-55-52-967_343eaf38935a4cca.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f6.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn73@2020_5/2020/09/05/08-55-53-227_9012fe2fae9cb728.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f7.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn66@2020_5/2020/09/05/08-55-53-065_a7b4a7d1cd12d4b5.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f8.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn57@2020_3/2020/09/05/08-55-53-176_d9e5bd114f5fb23c.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f9.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn54@2020_2/2020/09/05/08-55-53-507_5ebd0ea75502c66c.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/joaquin_menchaca.jpeg":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn18@2020_6/2020/09/05/08-55-53-079_5eef3adf0bd94111.webp"},"publishedOrCreatedDate":1599296151076},{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","title":"Announcing the General Availability of Bottlerocket, an open source Linux distribution built to run containers","link":"https://aws.amazon.com/blogs/opensource/announcing-the-general-availability-of-bottlerocket-an-open-source-linux-distribution-purpose-built-to-run-containers/","description":"<p>As our customers increasingly adopt containers to run their workloads, we saw a need for a Linux distribution designed from the ground up to run containers with a focus on security, operations, and manageability at scale. Customers needed an operating system that would give them the ability to manage thousands of hosts running containers with automation.</p> \n<p>Meet Bottlerocket, a new open source Linux distribution that is built to run containers. Bottlerocket is designed to improve security and operations of your containerized infrastructure. Its built-in security hardening helps simplify security compliance, and its transactional update mechanism enables the use of container orchestrators to automate operating system (OS) updates and decrease operational costs.</p> \n<p>Bottlerocket is developed as an open source project on <a href=\"https://github.com/bottlerocket-os\">GitHub</a> with a public <a href=\"https://github.com/orgs/bottlerocket-os/projects/1\">roadmap</a>. We’re looking forward to building a community around Bottlerocket on GitHub and welcome your feature requests, bug reports, or contributions.</p> \n<h2>Bottlerocket technology</h2> \n<p>We began designing and building Bottlerocket based on the things we’ve learned from how customers use Amazon Linux to run containers and from running services such as AWS Fargate. At every step of the design process, we optimized Bottlerocket for security, speed, and ease of maintenance.</p> \n<p>Bottlerocket improves security by including only the software needed to run containers, which reduced the security attack surface. It uses Security-Enhanced Linux (SELinux) in enforcing mode to increase the isolation between containers and the host operating system, in addition to standard Linux kernel technologies to implement isolation between containerized workloads—such as control groups (cgroups), namespaces, and seccomp.</p> \n<p>Also, Bottlerocket uses <a href=\"https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/verity.html\">Device-mapper’s verity target</a> (dm-verity), a Linux kernel feature that provides integrity checking to help prevent attackers from persisting threats on the OS, such as overwriting core system software. The modern Linux kernel in Bottlerocket includes <a href=\"https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_BPF_performance_analysis_at_Netflix_OPN303-R1.pdf\">eBPF</a>, which reduces the need for kernel modules for many low-level system operations. Large parts of Bottlerocket are written in Rust, a modern programming language that helps ensure thread safety and prevent memory-related errors, such as buffer overflows that can lead to security vulnerabilities.</p> \n<p>Bottlerocket also enforces an operating model that further improves security by discouraging administrative connections to production servers. It is suited for large distributed environments in which control over any individual host is limited. For debugging, you can run an “<a href=\"https://github.com/bottlerocket-os/bottlerocket-admin-container\">admin container</a>” using <a href=\"https://github.com/bottlerocket-os/bottlerocket#api\">Bottlerocket’s API</a> (invoked via user data or AWS Systems Manager) and then log in with SSH for advanced debugging and troubleshooting. The admin container is an Amazon Linux 2 container image and contains utilities for troubleshooting and debugging Bottlerocket and runs with elevated privileges. It allows you to install and use standard debugging tools, such as traceroute, strace, tcpdump. The act of logging into an individual Bottlerocket instance is intended to be an infrequent operation for advanced debugging and troubleshooting.</p> \n<p>Bottlerocket improves operations and manageability at scale by making it easier to manage nodes and automate updates to nodes in your cluster. Unlike general-purpose Linux distributions designed to support applications packaged in a variety of formats, Bottlerocket is purpose-built to run containers. Updates to other general-purpose Linux distributions are applied on a package-by-package basis and the complex dependencies among their packages can result in errors, making the process challenging to automate.</p> \n<p>Furthermore, general-purpose operating systems come with the flexibility to configure each instance as necessary for its workload uniquely, which makes management that is performed with traditional Linux tools more complex. By contrast, updates to Bottlerocket can be applied and rolled back in an atomic manner, which makes them easy to automate, reducing management overhead and reducing operational costs.</p> \n<p>Bottlerocket integrates with container orchestrators to enable the automated patching of hosts to improve operational costs, manageability, and uptime. It is designed to work with any orchestrator, and AWS-provided builds work with <a href=\"https://aws.amazon.com/eks/\">Amazon EKS</a> (in General Availability), and <a href=\"https://aws.amazon.com/ecs/\">Amazon ECS</a> (in preview).</p> \n<h2>Bottlerocket open source project</h2> \n<p>We have launched Bottlerocket as an open source project to enable our customers to make customizations to the operating system (e.g., integration with custom orchestrators/kernels/container runtimes) used to run their infrastructure, submit them for upstream inclusion, and produce custom builds. All design documents, code, build tools, tests, and documentation will be hosted on GitHub. We will use the GitHub’s bug and feature tracking systems for project management. You can view and contribute to Bottlerocket source code using standard GitHub workflows. The availability of build, release, and test infrastructure makes it easy to produce custom builds that includes their changes. <a href=\"https://aws.amazon.com/bottlerocket/\">ISV partners</a> can quickly validate their software before their customers update to the latest versions of Bottlerocket.</p> \n<p>We want to grow a vibrant community of users and contributors who adopt and support Bottlerocket as an open source project. We believe that an open source approach enables us to drive innovation based on our experience with working with other open source projects in the container space such as containerd, Linux kernel, Kubernetes, and Firecracker.</p> \n<p>Bottlerocket includes standard open source components, such as the Linux kernel, containerd container runtime, etc. Bottlerocket-specific additions focus on reliable updates and an API-based mechanism to make configuration changes and trigger updates/roll-backs. Bottlerocket code is <a href=\"https://github.com/bottlerocket-os/bottlerocket/blob/develop/COPYRIGHT\">licensed</a> under either the Apache 2.0 license or the MIT license at your option. Underlying third-party code, like the Linux kernel, remains subject to its original license. If you modify Bottlerocket, you may use “Bottlerocket Remix” to refer to your builds in accordance with the <a href=\"https://github.com/bottlerocket-os/bottlerocket/blob/develop/TRADEMARKS.md\">policy guidelines</a>.</p> \n<h2>Getting started with Bottlerocket</h2> \n<p>Although you can run Bottlerocket as a standalone OS without an orchestrator for development and test use cases (using utilities in the admin container to administer and update Bottlerocket), we recommend using it with a container orchestrator to take advantage of all its benefits.</p> \n<p>An easy way to get started is by using AWS-provided Bottlerocket AMIs with either <a href=\"https://aws.amazon.com/eks/\">Amazon EKS</a> or <a href=\"https://aws.amazon.com/ecs/\">Amazon ECS</a> (in preview). You can find the IDs for these AMIs by querying SSM with the <a href=\"https://aws.amazon.com/cli/\">AWS CLI</a> as follows.</p> \n<p>To find the latest AMI ID for the Bottlerocket aws-k8s-1.17 variant, run:</p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">aws ssm get-parameter --region us-west-2 \\\n--name &quot;/aws/service/bottlerocket/aws-k8s-1.17/x86_64/latest/image_id&quot; \\\n--query Parameter.Value --output text</code></pre> \n <p>To find the latest AMI ID for the Bottlerocket aws-ecs-1 variant, run:</p> \n <div class=\"hide-language\"> \n  <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">aws ssm get-parameter --region us-west-2 \\\n--name &quot;/aws/service/bottlerocket/aws-ecs-1/x86_64/latest/image_id&quot; \\\n--query Parameter.Value --output text</code></pre> \n </div> \n</div> \n<p>In both of the above example commands, you can change the region if you operate in another region, or change the architecture from x86_64 to arm64 if you use <a href=\"https://aws.amazon.com/ec2/graviton/\">Graviton-</a>powered instances.</p> \n<p>Once you have this AMI ID, you can launch an EC2 instance and connect it to your existing EKS or ECS cluster. To connect to an EKS cluster with the Kubernetes variant of Bottlerocket, you’ll need to provide user data, such as the following, when you launch the EC2 instance:</p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">[settings.kubernetes]\napi-server = &quot;Your EKS API server endpoint here&quot;\ncluster-certificate = &quot;Your base64-encoded cluster certificate here&quot;\ncluster-name = &quot;Your cluster name here&quot;</code></pre> \n</div> \n<p>To connect to an ECS cluster with the ECS variant of Bottlerocket, you can provide user data like this:</p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">[settings.ecs]\ncluster = &quot;Your cluster name here&quot;</code></pre> \n</div> \n<p>For further instructions on getting started, see <a style=\"font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif\" href=\"https://github.com/bottlerocket-os/bottlerocket/blob/develop/QUICKSTART-EKS.md\">the guide for EKS</a><span style=\"font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif\"> and </span><a style=\"font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif\" href=\"https://github.com/bottlerocket-os/bottlerocket/blob/develop/QUICKSTART-ECS.md\">the guide for ECS</a><span style=\"font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif\">.</span></p> \n<h2>Contributing to Bottlerocket</h2> \n<p>In addition to using AWS-provided Bottlerocket AMIs, you can produce custom builds of Bottlerocket with your own changes. To do so, you can fork the GitHub repository, make your changes, and follow our <a href=\"https://github.com/bottlerocket-os/bottlerocket/blob/develop/BUILDING.md\">building</a> guide. As a prerequisite step, you must first set up your build environment. The build system is based on the Rust language. We recommend you install the latest stable Rust using <code>rustup</code>. To organize build tasks, we use <code>cargo-make</code> and <code>cargo-deny</code> during the build process. To get these, run:</p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">cargo install cargo-make\ncargo install cargo-deny --version 0.6.2</code></pre> \n</div> \n<p>Bottlerocket uses Docker to orchestrate package and image builds. We recommend Docker 19.03 or later. You’ll need to have Docker installed and running with your user account able to access the Docker API. This is commonly enabled by adding your user account to the docker group.</p> \n<p>To build an image, run after your source code changes are made:</p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">cargo make</code></pre> \n</div> \n<p>All packages will be built in turn, and then compiled into an <code>img</code> file in the <code>build</code>/ directory.</p> \n<p>Next, to register the Bottlerocket AMI, for use on Amazon EC2, you need to set up the <a href=\"https://aws.amazon.com/cli/\">aws-cli</a> and run:</p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">cargo make ami</code></pre> \n</div> \n<p>We invite you to join us in further enhancing Bottlerocket. See the Bottlerocket <a href=\"https://github.com/bottlerocket-os/bottlerocket/issues\">issues list</a> and the Bottlerocket <a href=\"https://github.com/orgs/bottlerocket-os/projects/1\">roadmap</a>. We welcome contributions. Going over existing issues is a great way to get started contributing. See our <a href=\"https://github.com/bottlerocket-os/bottlerocket/blob/develop/CONTRIBUTING.md\">contributor’s guide</a> for details.</p> \n<p>We hope you use Bottlerocket to run your containers and we look forward to your feedback!</p>","descriptionType":"html","publishedDate":"Mon, 31 Aug 2020 17:45:36 +0000","feedId":13680,"bgimg":"","linkMd5":"72a7c528e17b8a47ff39094c930f86b7","bgimgJsdelivr":"","metaImg":"","author":"Samartha Chandrashekar","publishedOrCreatedDate":1599296151077},{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","title":"AWS adds observability metrics to the OpenTelemetry C++ library","link":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","description":"<p><i>In this post, three AWS interns—Brandon Kimberly, Ankit Bhargava, and Hudson Humphries—describe their first engineering contributions to the popular open source observability project <a href=\"https://opentelemetry.io/\" target=\"_blank\" rel=\"noopener noreferrer\">OpenTelemetry</a>. </i></p> \n<p>Recently we made contributions to OpenTelemetry that included the metrics collection and processing functionality for the C++ library. These metrics are collected from instrumented applications and infrastructure. They allow users to monitor the health of their services, improve performance, and detect anomalies. In this post we explain how the new metrics pipeline works, how it might be used in code, and the lessons we learned along the way.</p> \n<h2>OpenTelemetry</h2> \n<p>OpenTelemetry is a complete solution that solves the problem of collecting telemetry metrics. Its mission is to develop an open, industry-wide standard for telemetry data, and to provide reference implementations with universal tools that support metrics, tracing, and logs. OpenTelemetry currently supports Python, Golang, JavaScript, Erlang, Java, .NET, PHP, Rust, C++, Ruby, and Swift.</p> \n<p>We found that the C++ API and SDK was a possible area of contribution, in particular, implementing the Metrics API and SDK functionality as it was at the time nonexistent. We saw this as a substantial contribution opportunity that aligned with our team’s development skill set and interests.</p> \n<p>Given that we were implementing this portion of the library from scratch, we reviewed the universal OpenTelemetry specification to understand the metrics pipeline requirements. This added another layer of complexity to our task because the specification itself remains under development. This meant we were constantly aiming at a moving target. We translated these requirements into a set of design documents that we iteratively reviewed with the OpenTelemetry community.</p> \n<p>Open source projects are unique in that, rather than a single central figure making decisions, there is generally a community process for decision-making. For example, all of our reviews, from initial project designs to the final code, received critiques from OpenTelemetry contributors across many organizations. Though design documents are perpetually evolving, we began implementing once we felt our proposal was sufficiently detailed and comprehensive.</p> \n<p><img class=\"size-full wp-image-7478 aligncenter\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f1_new.png\" alt=\"OpenTelemetry API &amp; SDK Structure\" width=\"687\" height=\"424\" /></p> \n<p>The OpenTelemetry specification demands an API and a SDK for its metrics architecture. The API defines how to capture metric data, while the SDK processes, queries, and exports it. A user can inject our API elements into their application with no compilation issues; however, the API on its own will not be able to generate any useful metric data. After a user installs the SDK, the library aggregates, filters, and distributes API-captured data to any number of visualization backend services. We like to think of the API as feeding data into the SDK pipeline.</p> \n<p>The API consists of three major components: <strong>metric</strong> <strong>instruments</strong>, <strong>meter</strong>, and <strong>meter provider classes</strong>. Metric instruments are what a user injects into their code at strategic locations to capture data of interest. The meter is responsible for creating these instruments and managing them in an internal registry. The meter also provides a single endpoint for collecting data from all operational metric instruments. Finally, the meter provider creates a global meter instance and allows users to specify certain aspects of the pipeline.</p> \n<p><img class=\"size-full wp-image-7479 aligncenter\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f2_new.png\" alt=\"Metrics SDK Data Path\" width=\"852\" height=\"620\" /></p> \n<h3>Metrics SDK</h3> \n<p>The Metrics SDK has five components that turn captured raw data into insightful metrics:</p> \n<ul> \n <li><b>Controller</b>: The Controller oversees and manages all SDK elements.</li> \n <li><b>Accumulator</b>: Users start the pipeline from the Controller, which then queries the Accumulator for data at a user-specified interval.</li> \n <li><b>Aggregators</b>: When queried, the Accumulator (the SDK version of the meter) will loop over all the aggregators in its registry and collect their current state. Note that each metric instrument has its own aggregator to combine captured data.</li> \n <li><b>Processor</b>: The accumulator then batches these states and sends data to the Processor for filtering. We implemented a default processor that acts as a pass through; users can easily define their own and plug them into the pipeline.</li> \n <li><b>Exporter</b>: The Processor will send data back to the Controller, which hands it off to the Exporter at the conclusion of the pipeline. We can see how the metric instruments capture data as it weaves its way through numerous components before finally reaching the user.</li> \n</ul> \n<h3>OStreamExporter</h3> \n<p>We also implemented an OStreamExporter for the metrics and tracing pipelines. These Exporters are comparable to <code>stdout</code> in other OpenTelemetry projects. Exporters are initialized with an <code>ostream</code> to which the user wants to send all metric or tracing data. We originally only planned to implement <code>stdout</code> functionality, but we decided to handle all streams with <code>stdout</code> being the default. This was a simple change for a lot of additional functionality.</p> \n<p>The OStreamMetricsExporter implements only one function, <code>Export()</code>, which takes in a vector of records that contain the name, description, labels, and aggregator from an instrument. The function then sends the name, description, and labels to <code>ostream</code>. Aggregators are templatized and held within a <code>variant</code>, making the process of sending them to the <code>ostream</code> more complicated. First, we must find out what type the aggregator is holding, which we can find by using <code>holds_alternative</code>. We then send this to a template function to unpack the aggregator from the <code>variant</code>. Once we have the aggregator, we can check what type of aggregator is, then send the relevant information to the <code>ostream</code> based on its kind.</p> \n<h3>OStreamSpanExporter</h3> \n<p>The OStreamSpanExporter is the equivalent of the OStreamMetricsExporter for the tracing pipeline. Implemented in the C++ project, the tracing pipeline functions like the metrics pipeline.</p> \n<p>The SpanProcessor automatically send spans to the Exporter when their memory is deleted. The SpanExporter receives a span of spans and sends their basic information to the initial <code>ostream</code>. This includes the name, trace id, span id, parent span id, start time, duration, description, and status. The span also has attributes, which are held in a <code>map of string to variant</code> and, because it holds a <code>variant</code>, we must unpack the value. After we unpack the <code>variant</code>, we can also send the data it holds to the <code>ostream</code> and conclude exporting.</p> \n<p>With this information, users can monitor the health of their system, detect anomalies, and improve performance. These metrics are an improvement over logs because they are intelligently aggregated and automatically processed. Users can spend more time analyzing the insights instead of tediously extracting them from thousands of lines of logs.</p> \n<p>We can examine how a user might actually instrument their code and capture labeled data in the following diagram:</p> \n<p><img class=\"alignnone size-full wp-image-7278\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/12/opentelemtry_f3.png\" alt=\"Instrument Use Code Snippet\" width=\"844\" height=\"314\" /></p> \n<p>Throughout this project, we learned a great deal about developing scalable code and working with a large community of open source contributors. As interns, we are used to writing code the minute we see a specification, but this approach fails miserably as the project grows in complexity. We found that it is crucial to plan nearly every aspect of a library’s architecture before writing a single line of code.</p> \n<p>Additionally, we embraced the tenets of open source design, which center on transparency and debate: Document and discuss everything, no exceptions. Overall, working on OpenTelemetry was a terrific experience, and we are interested in continuing to work in the open source community.</p> \n<h3>References</h3> \n<ul> \n <li><a href=\"https://github.com/open-telemetry/opentelemetry-cpp\" target=\"_blank\" rel=\"noopener noreferrer\">opentelemetry-cpp</a>: Learn more about OpenTelemetry observability with metrics functionality.</li> \n <li><a href=\"https://github.com/open-o11y/docs\" target=\"_blank\" rel=\"noopener noreferrer\">open-o11y/docs repository</a>: Our Metrics SDK, API, and Exporter design documents.</li> \n <li><a href=\"https://opentelemetry.io/\" target=\"_blank\" rel=\"noopener noreferrer\">OpenTelemetry project</a></li> \n</ul> \n<h3>About the authors</h3> \n<div class=\"blog-author-box\" style=\"border: 1px solid #d5dbdb;padding: 15px\"> \n <p class=\"blog-author-image\"><img class=\"alignleft wp-image-1288 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/kimberly.png\" alt=\"randon Kimberly\" width=\"150\" height=\"150\" /></p> \n <h3 class=\"lb-h4\">Brandon Kimberly</h3> \n <p style=\"color: #879196;font-size: 1.2rem\">Brandon Kimberly is a senior at Ohio University, currently interning as a software developer at AWS. He is interested in machine learning, observability, and all things Rust.</p> \n</div> \n<div class=\"blog-author-box\" style=\"border: 1px solid #d5dbdb;padding: 15px\"> \n <p class=\"blog-author-image\"><img class=\"alignleft wp-image-1288 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Ankit-Bhargava.png\" alt=\"Ankit Bhargava\" width=\"150\" height=\"150\" /></p> \n <h3 class=\"lb-h4\">Ankit Bhargava</h3> \n <p style=\"color: #879196;font-size: 1.2rem\">Ankit Bhargava is a senior at the University of Michigan, majoring in computer science and business, and interning as a software engineer at AWS. When he’s not working on OpenTelemetry, Ankit likes to read about cybersecurity and machine learning.</p> \n</div> \n<div class=\"blog-author-box\" style=\"border: 1px solid #d5dbdb;padding: 15px\"> \n <p class=\"blog-author-image\"><img class=\"alignleft wp-image-1288 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Hudson-Humphries.png\" alt=\"Hudson Humphries\" width=\"150\" height=\"150\" /></p> \n <h3 class=\"lb-h4\">Hudson Humphries</h3> \n <p style=\"color: #879196;font-size: 1.2rem\">Hudson Humphries is a senior at Texas A&amp;M University, majoring in computer science with a minor in Statistics, and interning as a software engineer at AWS. He’s interested in Data Analytics.</p> \n</div> \n<p><em>The content and opinions in this post are those of the third-party author and AWS is not responsible for the content or accuracy of this post.</em></p>","descriptionType":"html","publishedDate":"Tue, 01 Sep 2020 13:39:32 +0000","feedId":13680,"bgimg":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f1_new.png","linkMd5":"54a83b8934921a1efecf31e1e0f28063","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn66@2020_3/2020/09/05/08-55-51-269_8a79fcb71da7bedf.webp","destWidth":687,"destHeight":424,"sourceBytes":64426,"destBytes":20422,"author":"Alolita Sharma","articleImgCdnMap":{"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f1_new.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn66@2020_3/2020/09/05/08-55-51-269_8a79fcb71da7bedf.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f2_new.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn10@2020_4/2020/09/05/08-55-52-979_41da933918d9f6c2.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/12/opentelemtry_f3.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn14@2020_6/2020/09/05/08-55-53-155_ea193f5dbdfcca84.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/kimberly.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn42@2020_4/2020/09/05/08-55-53-357_e9f475f2dafefed7.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Ankit-Bhargava.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn33@2020_6/2020/09/05/08-55-52-988_c7607f4c7371d9a1.webp","https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Hudson-Humphries.png":null},"publishedOrCreatedDate":1599296151077}],"record":{"createdTime":"2020-09-05 16:55:51","updatedTime":"2020-09-05 16:55:51","feedId":13680,"fetchDate":"Sat, 05 Sep 2020 08:55:51 +0000","fetchMs":142,"handleMs":919,"totalMs":124433,"newArticles":0,"totalArticles":20,"status":1,"type":0,"ip":"ec73b7a24802041eef890ee8e1971ea9","hostName":"us-027*","requestId":"c736f8daaa2048dbaf484416d2c622cd_13680","contentType":"application/rss+xml;charset=UTF-8","totalBytes":879464,"bgimgsTotal":5,"bgimgsGithubTotal":5,"articlesImgsTotal":29,"articlesImgsGithubTotal":27,"successGithubMap":{"myreaderx8":2,"myreaderx7":1,"myreaderx15":1,"myreaderx6":1,"myreaderx16":1,"myreaderx4":1,"myreaderx10":1,"myreaderx32":1,"myreaderx3":1,"myreaderx33":1,"myreaderx11":1,"myreaderx12":1,"myreaderx2":1,"myreaderx1":1,"myreaderx13":1,"myreaderx30":1,"myreaderx31":1,"myreaderx18":1,"myreaderx":1,"myreaderx25":1,"myreaderx27":1,"myreaderx21":1,"myreaderx22":1,"myreaderx24":1,"myreaderx5oss":1,"myreaderx29":1},"failGithubMap":{"myreaderx14":1}},"feed":{"createdTime":"2020-08-25 04:38:48","updatedTime":"2020-09-01 09:22:18","id":13680,"name":"AWS Open Source Blog","url":"https://aws.amazon.com/blogs/opensource/feed","subscriber":null,"website":null,"icon":"https://aws.amazon.com/favicon.ico","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx64/cdn75@2020_1/2020/09/05/08-55-50-301_27a4e5d487919ba8.ico","description":"","weekly":null,"link":"https://aws.amazon.com"},"noPictureArticleList":[{"createdTime":"2020-09-05 16:57:54","updatedTime":"2020-09-05 16:57:54","id":null,"feedId":13680,"linkMd5":"efae17dc6b25459bd6df3ba0faba91e8"},{"createdTime":"2020-09-05 16:57:54","updatedTime":"2020-09-05 16:57:54","id":null,"feedId":13680,"linkMd5":"54a83b8934921a1efecf31e1e0f28063"}],"tmpCommonImgCdnBytes":128342,"tmpBodyImgCdnBytes":751122,"tmpBgImgCdnBytes":0,"extra4":{"start":1599296149990,"total":0,"statList":[{"spend":169,"msg":"获取xml内容"},{"spend":919,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":121581,"msg":"正文链接上传到cdn"}]},"extra5":29,"extra6":28,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Hudson-Humphries.png","sourceStatusCode":200,"destWidth":104,"destHeight":92,"sourceBytes":18203,"destBytes":1718,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":250,"convertSpendMs":3,"createdTime":"2020-09-05 16:55:52","host":"us-030*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn21/contents/2020/09/05/08-55-52-965_8bb852a68b83403f.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Sat, 05 Sep 2020 08:55:53 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["84DE:56EB:12AD1CD:1F24A10:5F535298"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1599299161"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn21/contents/2020/09/05/08-55-52-965_8bb852a68b83403f.webp","historyStatusCode":[],"spendMs":138},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"17.8 KB","destSize":"1.7 KB","compressRate":"9.4%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Hudson-Humphries.png","sourceStatusCode":200,"destWidth":104,"destHeight":92,"sourceBytes":18203,"destBytes":1718,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":57,"convertSpendMs":4,"createdTime":"2020-09-05 16:55:53","host":"us-030*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn21/contents/2020/09/05/08-55-53-128_8bb852a68b83403f.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Sat, 05 Sep 2020 08:55:53 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["84DE:56EB:12AD1E4:1F24B13:5F535299"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1599299161"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn21/contents/2020/09/05/08-55-53-128_8bb852a68b83403f.webp","historyStatusCode":[],"spendMs":39},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"17.8 KB","destSize":"1.7 KB","compressRate":"9.4%"},null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://europe-56.herokuapp.com/":{"failCount":1,"successCount":2,"resultList":[200,200,null]},"http://us-013.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe68.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-021.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-005.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-030.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-009.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe-60.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-52.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-038.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-025.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-001.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-017.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe64.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-22.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[206,200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f1_new.png","sourceStatusCode":200,"destWidth":541,"destHeight":491,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn56@2020_2/2020/09/05/08-55-51-247_3758088b31edf5d9.webp","sourceBytes":19558,"destBytes":13408,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":936,"convertSpendMs":12,"createdTime":"2020-09-05 16:55:51","host":"us-030*","referer":"https://aws.amazon.com/blogs/opensource/how-talkingdata-uses-aws-open-source-deep-java-library-with-apache-spark-for-machine-learning-inference-at-scale/","linkMd5ListStr":"6d0bc346ee72a3a4f47ec440afadb4e3,6d0bc346ee72a3a4f47ec440afadb4e3","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"19.1 KB","destSize":"13.1 KB","compressRate":"68.6%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f1_new.png","sourceStatusCode":200,"destWidth":687,"destHeight":424,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn66@2020_3/2020/09/05/08-55-51-269_8a79fcb71da7bedf.webp","sourceBytes":64426,"destBytes":20422,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":970,"convertSpendMs":25,"createdTime":"2020-09-05 16:55:51","host":"us-005*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063,54a83b8934921a1efecf31e1e0f28063","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"62.9 KB","destSize":"19.9 KB","compressRate":"31.7%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f1.png","sourceStatusCode":200,"destWidth":900,"destHeight":566,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn54@2020_3/2020/09/05/08-55-51-322_e836dd1feed6571a.webp","sourceBytes":444965,"destBytes":54420,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1145,"convertSpendMs":36,"createdTime":"2020-09-05 16:55:51","host":"us-029*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8,efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"434.5 KB","destSize":"53.1 KB","compressRate":"12.2%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/07/27/dierks-FHIR-f1.png","sourceStatusCode":200,"destWidth":936,"destHeight":406,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn61@2020_4/2020/09/05/08-55-51-254_befb0f6e3fe3da73.webp","sourceBytes":202527,"destBytes":24082,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1417,"convertSpendMs":38,"createdTime":"2020-09-05 16:55:51","host":"us-017*","referer":"https://aws.amazon.com/blogs/opensource/using-open-source-fhir-apis-with-fhir-works-on-aws/","linkMd5ListStr":"b10a68dcae37c51c171ccc82989095ca,b10a68dcae37c51c171ccc82989095ca","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"197.8 KB","destSize":"23.5 KB","compressRate":"11.9%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f1.png","sourceStatusCode":200,"destWidth":911,"destHeight":320,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn70@2020_2/2020/09/05/08-55-51-473_67d6aafbdfe12797.webp","sourceBytes":32116,"destBytes":16010,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1597,"convertSpendMs":11,"createdTime":"2020-09-05 16:55:51","host":"europe68*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32,11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.4 KB","destSize":"15.6 KB","compressRate":"49.9%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f7.png","sourceStatusCode":200,"destWidth":900,"destHeight":365,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn45@2020_5/2020/09/05/08-55-52-971_fd6caa8cf444a57f.webp","sourceBytes":48380,"destBytes":12718,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":910,"convertSpendMs":21,"createdTime":"2020-09-05 16:55:52","host":"us-021*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"47.2 KB","destSize":"12.4 KB","compressRate":"26.3%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f5.png","sourceStatusCode":200,"destWidth":950,"destHeight":327,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn81@2020_4/2020/09/05/08-55-52-967_343eaf38935a4cca.webp","sourceBytes":89925,"destBytes":34178,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":938,"convertSpendMs":20,"createdTime":"2020-09-05 16:55:52","host":"us-021*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"87.8 KB","destSize":"33.4 KB","compressRate":"38%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f2.png","sourceStatusCode":200,"destWidth":673,"destHeight":430,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn30@2020_5/2020/09/05/08-55-52-982_c62c3cf4a9de4e02.webp","sourceBytes":92485,"destBytes":15404,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":989,"convertSpendMs":30,"createdTime":"2020-09-05 16:55:52","host":"us-005*","referer":"https://aws.amazon.com/blogs/opensource/how-talkingdata-uses-aws-open-source-deep-java-library-with-apache-spark-for-machine-learning-inference-at-scale/","linkMd5ListStr":"6d0bc346ee72a3a4f47ec440afadb4e3","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"90.3 KB","destSize":"15 KB","compressRate":"16.7%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/sharma_opentelemetry_f2_new.png","sourceStatusCode":200,"destWidth":852,"destHeight":620,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn10@2020_4/2020/09/05/08-55-52-979_41da933918d9f6c2.webp","sourceBytes":106360,"destBytes":17930,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":950,"convertSpendMs":27,"createdTime":"2020-09-05 16:55:52","host":"us-001*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"103.9 KB","destSize":"17.5 KB","compressRate":"16.9%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f4.png","sourceStatusCode":200,"destWidth":960,"destHeight":246,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn26@2020_2/2020/09/05/08-55-52-938_e2322ea12c9ccd2e.webp","sourceBytes":52163,"destBytes":15236,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":990,"convertSpendMs":38,"createdTime":"2020-09-05 16:55:52","host":"us-017*","referer":"https://aws.amazon.com/blogs/opensource/how-talkingdata-uses-aws-open-source-deep-java-library-with-apache-spark-for-machine-learning-inference-at-scale/","linkMd5ListStr":"6d0bc346ee72a3a4f47ec440afadb4e3","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"50.9 KB","destSize":"14.9 KB","compressRate":"29.2%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/joaquin_menchaca.jpeg","sourceStatusCode":200,"destWidth":200,"destHeight":200,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn18@2020_6/2020/09/05/08-55-53-079_5eef3adf0bd94111.webp","sourceBytes":10922,"destBytes":6882,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":971,"convertSpendMs":4,"createdTime":"2020-09-05 16:55:52","host":"us-52*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.7 KB","destSize":"6.7 KB","compressRate":"63%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f8.png","sourceStatusCode":200,"destWidth":900,"destHeight":539,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn61@2020_2/2020/09/05/08-55-53-031_4a73637d8802874f.webp","sourceBytes":136599,"destBytes":33504,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1019,"convertSpendMs":42,"createdTime":"2020-09-05 16:55:52","host":"us-038*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"133.4 KB","destSize":"32.7 KB","compressRate":"24.5%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/Ankit-Bhargava.png","sourceStatusCode":200,"destWidth":116,"destHeight":98,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn33@2020_6/2020/09/05/08-55-52-988_c7607f4c7371d9a1.webp","sourceBytes":22017,"destBytes":1956,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":988,"convertSpendMs":4,"createdTime":"2020-09-05 16:55:52","host":"europe68*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.5 KB","destSize":"1.9 KB","compressRate":"8.9%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f2.png","sourceStatusCode":200,"destWidth":900,"destHeight":529,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn86@2020_3/2020/09/05/08-55-52-998_784572edd0d2868d.webp","sourceBytes":247124,"destBytes":61464,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1054,"convertSpendMs":31,"createdTime":"2020-09-05 16:55:52","host":"us-009*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"241.3 KB","destSize":"60 KB","compressRate":"24.9%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f2.png","sourceStatusCode":200,"destWidth":980,"destHeight":737,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn2@2020_2/2020/09/05/08-55-53-051_cc0f5d601439c327.webp","sourceBytes":138049,"destBytes":44378,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1061,"convertSpendMs":54,"createdTime":"2020-09-05 16:55:52","host":"us-025*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"134.8 KB","destSize":"43.3 KB","compressRate":"32.1%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f3.png","sourceStatusCode":200,"destWidth":950,"destHeight":564,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn98@2020_2/2020/09/05/08-55-53-079_11214f442d552654.webp","sourceBytes":240065,"destBytes":47510,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1115,"convertSpendMs":32,"createdTime":"2020-09-05 16:55:52","host":"us-038*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"234.4 KB","destSize":"46.4 KB","compressRate":"19.8%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f3.png","sourceStatusCode":200,"destWidth":900,"destHeight":448,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn77@2020_4/2020/09/05/08-55-53-076_245e30116ecc096e.webp","sourceBytes":77896,"destBytes":22510,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1099,"convertSpendMs":28,"createdTime":"2020-09-05 16:55:52","host":"us-034*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76.1 KB","destSize":"22 KB","compressRate":"28.9%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f7.png","sourceStatusCode":200,"destWidth":950,"destHeight":625,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn66@2020_5/2020/09/05/08-55-53-065_a7b4a7d1cd12d4b5.webp","sourceBytes":127474,"destBytes":65882,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1104,"convertSpendMs":65,"createdTime":"2020-09-05 16:55:52","host":"us-025*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"124.5 KB","destSize":"64.3 KB","compressRate":"51.7%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f6.png","sourceStatusCode":200,"destWidth":900,"destHeight":747,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn49@2020_3/2020/09/05/08-55-53-013_e47e0992010daff2.webp","sourceBytes":157888,"destBytes":42174,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1230,"convertSpendMs":31,"createdTime":"2020-09-05 16:55:52","host":"us-009*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"154.2 KB","destSize":"41.2 KB","compressRate":"26.7%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/04/niksch-quick-start_f5.png","sourceStatusCode":200,"destWidth":900,"destHeight":349,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn93@2020_3/2020/09/05/08-55-53-116_ae2dde5112ad3adf.webp","sourceBytes":49725,"destBytes":15442,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1154,"convertSpendMs":14,"createdTime":"2020-09-05 16:55:52","host":"europe-60*","referer":"https://aws.amazon.com/blogs/opensource/openshift-4-on-aws-quick-start/","linkMd5ListStr":"efae17dc6b25459bd6df3ba0faba91e8","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"48.6 KB","destSize":"15.1 KB","compressRate":"31.1%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/26/kimberly.png","sourceStatusCode":200,"destWidth":118,"destHeight":114,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn42@2020_4/2020/09/05/08-55-53-357_e9f475f2dafefed7.webp","sourceBytes":28542,"destBytes":2590,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":924,"convertSpendMs":5,"createdTime":"2020-09-05 16:55:53","host":"us-034*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.9 KB","destSize":"2.5 KB","compressRate":"9.1%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/12/opentelemtry_f3.png","sourceStatusCode":200,"destWidth":844,"destHeight":314,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn14@2020_6/2020/09/05/08-55-53-155_ea193f5dbdfcca84.webp","sourceBytes":190933,"destBytes":31632,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1342,"convertSpendMs":18,"createdTime":"2020-09-05 16:55:52","host":"europe64*","referer":"https://aws.amazon.com/blogs/opensource/aws-adds-observability-metrics-to-the-opentelemetry-c-library/","linkMd5ListStr":"54a83b8934921a1efecf31e1e0f28063","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"186.5 KB","destSize":"30.9 KB","compressRate":"16.6%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f4.png","sourceStatusCode":206,"destWidth":891,"destHeight":869,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_1/2020/09/05/08-55-53-176_bcfe9f6ae3c71bb8.webp","sourceBytes":484984,"destBytes":46964,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1352,"convertSpendMs":38,"createdTime":"2020-09-05 16:55:52","host":"europe-22*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[206],"sourceSize":"473.6 KB","destSize":"45.9 KB","compressRate":"9.7%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/25/qingla_f3.png","sourceStatusCode":200,"destWidth":960,"destHeight":246,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn37@2020_2/2020/09/05/08-55-53-376_6df1496d164ba557.webp","sourceBytes":46736,"destBytes":13596,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1418,"convertSpendMs":11,"createdTime":"2020-09-05 16:55:52","host":"europe-56*","referer":"https://aws.amazon.com/blogs/opensource/how-talkingdata-uses-aws-open-source-deep-java-library-with-apache-spark-for-machine-learning-inference-at-scale/","linkMd5ListStr":"6d0bc346ee72a3a4f47ec440afadb4e3","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"45.6 KB","destSize":"13.3 KB","compressRate":"29.1%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f6.png","sourceStatusCode":200,"destWidth":950,"destHeight":675,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn73@2020_5/2020/09/05/08-55-53-227_9012fe2fae9cb728.webp","sourceBytes":63130,"destBytes":53872,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1434,"convertSpendMs":37,"createdTime":"2020-09-05 16:55:52","host":"europe-56*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"61.7 KB","destSize":"52.6 KB","compressRate":"85.3%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f8.png","sourceStatusCode":200,"destWidth":950,"destHeight":625,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn57@2020_3/2020/09/05/08-55-53-176_d9e5bd114f5fb23c.webp","sourceBytes":152391,"destBytes":71320,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":1710,"convertSpendMs":35,"createdTime":"2020-09-05 16:55:52","host":"europe-60*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"148.8 KB","destSize":"69.6 KB","compressRate":"46.8%"},{"code":1,"isDone":false,"source":"https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2020/08/19/zhu-dgraph_f9.png","sourceStatusCode":200,"destWidth":950,"destHeight":811,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn54@2020_2/2020/09/05/08-55-53-507_5ebd0ea75502c66c.webp","sourceBytes":194336,"destBytes":93980,"targetWebpQuality":75,"feedId":13680,"totalSpendMs":2092,"convertSpendMs":47,"createdTime":"2020-09-05 16:55:52","host":"europe-22*","referer":"https://aws.amazon.com/blogs/opensource/dgraph-on-aws-setting-up-a-horizontally-scalable-graph-database/","linkMd5ListStr":"11b14affaae75c5aa558447ba8650a32","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"189.8 KB","destSize":"91.8 KB","compressRate":"48.4%"}],"successGithubMap":{"myreaderx8":2,"myreaderx7":1,"myreaderx15":1,"myreaderx6":1,"myreaderx16":1,"myreaderx4":1,"myreaderx10":1,"myreaderx32":1,"myreaderx3":1,"myreaderx33":1,"myreaderx11":1,"myreaderx12":1,"myreaderx2":1,"myreaderx1":1,"myreaderx13":1,"myreaderx30":1,"myreaderx31":1,"myreaderx18":1,"myreaderx":1,"myreaderx25":1,"myreaderx27":1,"myreaderx21":1,"myreaderx22":1,"myreaderx24":1,"myreaderx5oss":1,"myreaderx29":1},"failGithubMap":{"myreaderx14":1}}