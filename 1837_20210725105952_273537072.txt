{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2021-07-25 18:57:37","updatedTime":"2021-07-25 18:57:37","title":"7 Papers & Radios | ICML、RSS顶会杰出、最佳论文；AlphaFold解锁98.5%人类蛋白质结构","link":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","description":"<div><div><div id=\"media\" class=\"rich_media_thumb_wrp\">\n\n            <img class=\"rich_media_thumb\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbqMBAia86CFj2cC3nHSEGgs1Uxd7ict7RhguzwEKSagJ0hibFddqnASMKw/0?wx_fmt=jpeg?imageView2/1/w/600\">\n        </div>\n    \n\n    \n\n    <div class=\"rich_media_content\" id=\"js_content\">\n                    \n\n                    \n                    \n                    \n                    <section data-mpa-powered-by=\"yiban.io\" data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" data-style=\"white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: \" helvetica neue sans gb yahei arial sans-serif box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__0\" style=\"max-width: 100%;white-space: normal;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-size-adjust: auto;font-family: \" visible><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" data-style=\"margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;\" class=\"js_darkmode__1\" style=\"margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><p style=\"margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(163, 163, 163) !important;\"><span style=\"max-width: 100%;text-decoration: inherit;visibility: visible;color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);box-sizing: border-box !important;overflow-wrap: break-word !important;\">机器之心 &amp; ArXiv Weekly Radiostation</span></p><section style=\"margin-top: 10px;margin-bottom: 5px;max-width: 100%;min-height: 1em;text-align: center;visibility: visible;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"max-width: 100%;letter-spacing: 0.544px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">参与：杜伟</strong><strong style=\"max-width: 100%;letter-spacing: 0.544px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">、<strong style=\"max-width: 100%;letter-spacing: 0.544px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">楚航、罗若天</strong></strong></span></strong></section></section></section></section></section></section></section></section></section></section></section></section><blockquote data-type=\"2\" data-url=\"\" data-author-name=\"\" data-content-utf8-length=\"122\" data-source-title=\"\" style=\"color: rgba(0, 0, 0, 0.5);max-width: 100%;white-space: normal;font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><section style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section style=\"max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;color: rgba(0, 0, 0, 0.498);font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif border-box break-word>本周的重要论文包括 ICML 2021 杰出论文、RSS 2021最佳论文等。</span></section></section></blockquote><section style=\"max-width: 100%;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></strong></section><section style=\"max-width: 100%;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br></span></strong></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">目录：</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ol class=\"list-paddingleft-2\" style=\"list-style-type: decimal;\"><li><p><span style=\"font-size: 15px;\">ViTGAN: Training GANs with Vision Transformers</span></p></li><li><p><span style=\"font-size: 15px;\">TARE: A Hierarchical Framework for Efficiently Exploring Complex 3D Environments</span></p></li><li><p><span style=\"font-size: 15px;\">Event Prediction in the Big Data Era: A Systematic Survey</span></p></li><li><p><span style=\"font-size: 15px;\">Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies </span></p></li><li><p><span style=\"font-size: 15px;\">YOLOX: Exceeding YOLO Series in 2021</span></p></li><li><p><span style=\"font-size: 15px;\">How Do Adam and Training Strategies Help BNNs Optimization?</span></p></li><li><p><span style=\"font-size: 15px;\">Highly Accurate Protein Structure Prediction for the Human Proteome</span></p></li><li><p><span style=\"font-size: 15px;\">ArXiv Weekly Radiostation：NLP、CV、ML 更多精选论文（附音频）</span></p></li></ol><p style=\"max-width: 100%;min-height: 1em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br></span></p><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 1：ViTGAN: Training GANs with Vision Transformers</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Kwonjoon Lee、Huiwen Chang、Lu Jiang 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://arxiv.org/pdf/2107.04589.pdf</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">近日，加州大学圣迭戈分校与 Google Research 的一项研究提出了使用视觉 Transformer 来训练 GAN。这篇论文的研究议题是：不使用卷积或池化，能否使用视觉 Transformer 来完成图像生成任务？更具体而言：能否使用 ViT 来训练生成对抗网络（GAN）并使之达到与已被广泛研究过的基于 CNN 的 GAN 相媲美的质量？他们遵照最本原的  ViT 设计，使用纯粹基本的 ViT 训练了 GAN。为了实现训练动态的稳定以及促进基于 ViT 的 GAN 的收敛，这篇论文提出了多项必需的修改。研究者在三个标准的图像合成基准上进行了实验。结果表明，新模型 ViTGAN 极大优于之前的基于 Transformer 的 GAN 模型，并且在没有使用卷积和池化时也取得了与 StyleGAN2 等领先的基于 CNN 的 GAN 相媲美的表现。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.47113594040968343\" data-s=\"300,640\" data-type=\"png\" data-w=\"1074\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbfibYbAcjKkTw4KibRXkHlMd0ClwIMXbYvSGPYia5KVs6WzDuhjLWUhZQQ/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"font-size: 12px;\">ViTGAN 模型架构。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5125506072874494\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1235\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb07dTjgLp2XyLZbbMtlvibQRANLRTL9FeDRzQBJ0P8WsuC1wJbwAm11A/640?wx_fmt=jpeg\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"font-size: 12px;\">生成器架构。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">Transformer 也能生成图像，新型 ViTGAN 性能比肩基于 CNN 的 GAN。</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 2：TARE: A Hierarchical Framework for Efficiently Exploring Complex 3D Environments</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Chao Cao、Hongbiao Zhu、Howie Choset、Ji Zhang</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://roboticsconference.org/program/papers/018/</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">让机器人在复杂的 3D 空间中自主探索是一个颇具挑战性的问题，因为它需要同时完成两项任务：1）在线更新环境表示，以跟踪已探索的区域；2）搜索连续可遍历路径的表示，以引导机器人探索未知区域。在这篇论文中，研究者提出了一种在复杂 3D 环境中自主探索的方法，其探索速度比当前的 SOTA 方法还要快。具体来说，该方法使用了一种分层框架：第一层在局部规划范围内保持环境的高分辨率表示并计算详细路径；第二层在全局范围内保持环境的低分辨率表示并计算粗略路径。该架构表明，在机器人附近进行详细的数据处理是最高效的，牺牲远离机器人区域的细节计算可以提高计算速度。该方法根据路径的长度优化整个探索路径。此外，局部区域的路径在运动动力学上是可行的，机器人可以遵循该路径快速前进。<br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">在实验中，该系统通过地面和空中机器人，自主探索了高维、复杂的室内外环境。与 SOTA 方法相比，该方法的探索效率（每秒平均探索量）提高了 80%，但消耗的算力还不到 SOTA 方法的 50%。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5895316804407713\" data-s=\"300,640\" data-type=\"png\" data-w=\"1089\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb6wEZVfdn6DiaDNvdicABgFZLh7LQJVH3LaHozKqVUZDYvKqwWboAeENQ/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">探索框架示意图。</span></em></span></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\"><br></span></em></span></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5117753623188406\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1104\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbRibC27Gyb5cRexyCDFm0YxHbNY5iaKvicicQWRvxKf7AjW9fCPric1NoUEQ/640?wx_fmt=jpeg\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">其他方法的比较。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">本文摘得机器人顶会 RSS 的最佳论文奖。</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 3：Event Prediction in the Big Data Era: A Systematic Survey</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Liang Zhao</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://dl.acm.org/doi/10.1145/3450287</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">事件是基于特定地点、时间和语义发生的对我们的社会或自然环境产生重大影响的事情，例如地震、内乱、系统故障、流行病和犯罪。能够提前预测此类事件的发生以减少潜在的损害是非常重要的。虽然事件预测传统上极具挑战性，但它现在正成为大数据时代的一种可行选择并正在经历快速增长。当然，这也归功于高性能计算机和 AI 技术的进步。最近来自艾默里大学的教授赵亮博士首次对该领域进行了全面的综述和数据代码资源整理。该工作全面总结了事件预测的问题定义、方法、应用、测评、数据以及未来发展方向。该工作刚刚发表在计算机综述顶刊 ACM Computing Surveys 上。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.21422523285351397\" data-s=\"300,640\" data-type=\"png\" data-w=\"1181\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb5Im8unaXA5n7ukzjBFluTRcxD3QzJZPHYWMKdVXMRKd2Sa0OCZicxKg/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">事件预测中不同的时间类型。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.56640625\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1280\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbVyF2y7g1DB6tYS2CsTdIEMzBx2KvvXic7ibWE5Z6GbDBTAd0YO0ngkZg/640?wx_fmt=jpeg\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">事件预测问题与技术分类。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">37 页 pdf，埃默里大学最新「大数据时代事件预测」综述，ACM 顶级期刊上发表。</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 4：Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Paul Vicol、Luke Metz、Jascha Sohl-Dickstein</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：http://proceedings.mlr.press/v139/vicol21a/vicol21a.pdf</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">目前，展开（unrolled）计算图应用在很多场景中，包括训练 RNN、通过展开优化微调超参数和训练可学习优化器等。但是，在这类计算图中优化参数的方法存在着高方差梯度、偏差、更新缓慢以及大量内存使用等诸多问题。</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究者提出了一种名为 Persistent Evolution Strategies （PES）的方法，它可以将计算图分成一系列截断的展开，并在每次展开后执行基于进化策略的更新步骤。PES 通过在整个展开序列上累积校正项消除这些截断的偏差，可以实现快速参数更新，具有低内存使用、无偏差以及合理的方差特征。实验表明，PES 在合成任务上展现出了与其他梯度估计方法的优势，并在训练可学习优化器和微调超参数方面具有适用性。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.19921875\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1280\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbBP74pSUbU6YkIhlm8hO6OZ2AgMR49ia34NJVAdPjrIJ5TmDHednk3IA/640?wx_fmt=jpeg\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">图右为一个展开计算图，展示了如何使用图左的公式 1 和公式 2 来描述 RNN 和展开优化。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.4292682926829268\" data-s=\"300,640\" data-type=\"png\" data-w=\"1025\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbRj8YUwDGliaweWkG7Agict4h6ANeCN8T5zAXmEuyrliajhiaVVT1TO7hiag/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">PES 方法与其他在展开计算图中学习参数的方法的比较。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">本文摘得 ICML 2021 杰出论文奖。</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 5：YOLOX: Exceeding YOLO Series in 2021</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Zheng Ge、Songtao Liu、Feng Wang 等 </span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://arxiv.org/abs/2107.08430</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">随着目标检测技术的发展，YOLO 系列始终追寻可以实时应用的最佳速度和准确率权衡。学界人士不断提取当时最先进的检测技术（如 YOLOv2 的 anchor、YOLOv3 的残差网络），并对这些检测技术进行优化以实现最佳性能。目前而言，YOLOv5 在速度和准确率上有最好的权衡，在 COCO 数据集上以 13.7ms 的速度获得 48.2% AP。然而，过去两年时间里，目标检测领域的主要进展集中在无锚点检测器、先进的标签分配策略以及端到端的检测器。<br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">但是，这些技术还没有集成到 YOLO 系列模型中，YOLOv4 、 YOLOv5 仍然还是基于 anchor 的检测器，使用手工分配策略进行训练。近日，旷视的研究者将解耦头、数据增强、无锚点以及标签分类等目标检测领域的优秀进展与 YOLO 进行了巧妙地集成组合，提出了 YOLOX，不仅实现了超越 YOLOv3、YOLOv4 和 YOLOv5 的 AP，而且取得了极具竞争力的推理速度。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.565625\" data-s=\"300,640\" data-type=\"png\" data-w=\"1280\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb2Oyxewt9dZRBeeVnAxYDvdR5TWhgEUIia8H3NokiaCDhlDx2E92M2pAA/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">YOLOv3 头与本文提出的解耦头之间的架构差异。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.3420168067226891\" data-s=\"300,640\" data-type=\"png\" data-w=\"1190\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbmK0Q21nBZynibXYur7mXdo4AOwWCe1Ce0SbueicvdCotmq7B4c4e3Iyg/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">研究者提出的基于 YOLOX 模型的 2D 实时目标检测系统在 Argoverse-HD 数据集上实现了 41.1% 的 AP。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">超越全系列 YOLO、Anchor-free + 技巧组合，旷视开源性能更强的 YOLOX。</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 6：How Do Adam and Training Strategies Help BNNs Optimization?</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Zechun Liu、Zhiqiang Shen、Shichao Li 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://arxiv.org/abs/2106.11309</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">二值化网络（BNN）是一种网络压缩方法，把原本需要 32 bit 表示的神经网络参数值和激活值都二值化到只需要用 1 bit 表示，即  -1/+1 表示。这种极度的压缩方法在带来优越的压缩性能的同时，会造成网络精度的下降。在今年的 ICML 会议中，一篇来自 CMU 和 HKUST 科研团队的论文仅通过调整训练算法，在 ImageNet 数据集上取得了比之前的 SOTA BNN 网络 ReActNet 高 1.1% 的分类精度，最终的 top-1 accuracy 达到 70.5%，超过了所有同等量级的二值化网络。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.6486042692939245\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1218\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbn6uFQXpSibRUVVjIp4DajEbhuibLLeNYwic9HfU8GialqiaugJBLehqEwXQ/640?wx_fmt=jpeg\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">真实网络（real network）和二值网络的示意图。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9740394600207685\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"963\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb1vWmGNmicEdj8mpTnnrDBaEuNa3A4ON8Kx6jSzJIJDR4uXDJdSRcD3w/640?wx_fmt=jpeg\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">该论文综合所有分析得出的训练策略，在用相同的网络结构的情况下，取得了比 state-of-the-art ReActNet 超出 1.1% 的结果。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">二值化网络如何训练？这篇 ICML 2021 论文给你答案。</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 7：Highly Accurate Protein Structure Prediction for the Human Proteome</span></strong></section><section style=\"line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-2\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Kathryn Tunyasuvunakool、Jonas Adler、Zachary Wu</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://www.nature.com/articles/s41586-021-03828-1</span></p></li></ul><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong></span><span style=\"font-size: 15px;\">蛋白质由很多氨基酸长链组成，通过折叠成精确 3D 结构来完成无数的任务。这些结构控制着它们与其它分子互动的方式，决定了其功能以及它在疾病中的功能紊乱程度。阐明蛋白质的结构是分子生物学的核心议题，更是治疗患者、拯救生命、改变生活的医学发展的核心。</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">在这一领域，DeepMind 的 AlphaFold 被寄予厚望。在上周发表在《自然》杂志上的一篇论文中，DeepMind 表示，AlphaFold 预测的蛋白质结构已经能达到原子水平的准确度。</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">如今，这一成果的最大回报已经到来：其中一个研究小组刚刚宣布，他们已经使用新开发的 AlphaFold 预测出了 35 万种蛋白质的结构，包括人类基因组所表达的约 2 万种蛋白质和其他 20 种生物学研究中常用的模式生物（如大肠杆菌、酵母和果蝇）的蛋白质，是以前用实验方法解决的蛋白质数量的两倍多。该组织表示，未来，他们还将继续扩大预测的范围，将预测数量扩展至已编目的所有蛋白质，这大约要覆盖 1 亿个分子。</span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.2712962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb7TT20FuAd4BQqJYexAqA4znb7VjSmsjwWn1cFlPKaMeicNvSYghOtYw/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">CASP14 的预测。</span></em></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.0211267605633803\" data-s=\"300,640\" data-type=\"png\" data-w=\"568\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbtfGIgbwRIAZSzPHu5CW6fbriapm9lCF3W7HwWErcicgW0Xqnbss76pfQ/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">在 CASP14 中 AlphaFold 相对于其他方法的精度。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9879227053140096\" data-s=\"300,640\" data-type=\"png\" data-w=\"828\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbdBIicjnialbBoXibnKgl5pM77WTPJVuwz9PuYx3scWU6y1QszBkibGKmDQ/640?wx_fmt=png\"></p><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">AlphaFold DB 对自各种生物体的预测示例。</span></em></span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"color: rgb(61, 170, 214);\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong></span><span style=\"font-size: 15px;\">高效预测 98.5% 的人类蛋白质结构，AlphaFold 再登 Nature，数据库全部免费开放。</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"white-space: normal;max-width: 100%;letter-spacing: 0.544px;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center border-box break-word><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif border-box break-word>ArXiv Weekly Radiostation</strong></span></section><section style=\"white-space: normal;max-width: 100%;letter-spacing: 0.544px;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center border-box break-word><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></section><section style=\"white-space: normal;max-width: 100%;letter-spacing: 0.544px;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word>机器之心联合由楚航、罗若天发起的ArXiv Weekly Radiostation，在 7 Papers 的基础上，精选本周更多重要论文，包括NLP、CV、ML领域各10篇精选，并提供音频形式的论文摘要简介，详情如下：</span></section><section style=\"white-space: normal;max-width: 100%;letter-spacing: 0.544px;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word><br></span></section><section><mpvoice class=\"js_editor_audio audio_iframe js_uneditable custom_select_card\" src=\"/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;name=10%20NLP%20Papers.mp3&amp;play_length=18:26\" isaac2=\"1\" low_size=\"2075.53\" source_size=\"2048\" high_size=\"4322.58\" name=\"10 NLP Papers.mp3\" play_length=\"1106000\" voice_encode_fileid=\"MzA3MzI4MjgzM18yNjUwODIyMDYz\" data-topic_id=\"\" data-topic_name=\"\" data-pluginname=\"insertaudio\"></mpvoice></section><section style=\"white-space: normal;max-width: 100%;letter-spacing: 0.544px;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><br><span style=\"max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb>本周 10 篇 NLP 精选论文是：</span><br></section><section style=\"line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. Neural Abstructions: Abstractions that Support Construction for Grounded Language Learning.  (from Christopher D. Manning, Li Fei-Fei)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset.  (from Oriol Vinyals)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. Beyond Goldfish Memory: Long-Term Open-Domain Conversation.  (from Jason Weston)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. Cross-Lingual BERT Contextual Embedding Space Mapping with Isotropic and Isometric Conditions.  (from Philipp Koehn)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. Self-Supervised Contrastive Learning with Adversarial Perturbations for Robust Pretrained Language Models.  (from Roger Wattenhofer)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. A pattern recognition approach for distinguishing between prose and poetry.  (from Luciano da F. Costa)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">7. Proactive Retrieval-based Chatbots based on Relevant Knowledge and Goals.  (from Kun Zhou)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">8. As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical Translation.  (from Jun Wang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">9. More Parameters? No Thanks!.  (from C V Jawahar)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">10. Target-Oriented Fine-tuning for Zero-Resource Named Entity Recognition.  (from Ying Zhang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section><mpvoice class=\"js_editor_audio audio_iframe js_uneditable custom_select_card\" src=\"/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;name=10%20CV%20Papers.mp3&amp;play_length=22:59\" isaac2=\"1\" low_size=\"2606.65\" source_size=\"2560\" high_size=\"5387.48\" name=\"10 CV Papers.mp3\" play_length=\"1379000\" voice_encode_fileid=\"MzA3MzI4MjgzM18yNjUwODIyMDY0\" data-topic_id=\"\" data-topic_name=\"\" data-pluginname=\"insertaudio\"></mpvoice></section><section style=\"line-height: 1.75em;\"><br><span style=\"font-size: 15px;\"></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb>本周 10 篇 CV 精选论文是：</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. Active 3D Shape Reconstruction from Vision and Touch.  (from Jitendra Malik)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. YOLOX: Exceeding YOLO Series in 2021.  (from Jian Sun)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. CCVS: Context-aware Controllable Video Synthesis.  (from Jean Ponce, Cordelia Schmid)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. Unsupervised Discovery of Object Radiance Fields.  (from Leonidas J. Guibas)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. Conditional Directed Graph Convolution for 3D Human Pose Estimation.  (from Lei Zhang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. Query2Label: A Simple Transformer Way to Multi-Label Classification.  (from Lei Zhang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">7. DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation.  (from Dacheng Tao)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">8. Compound Figure Separation of Biomedical Images with Side Loss.  (from Agnes B. Fogo)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">9. ReSSL: Relational Self-Supervised Learning with Weak Augmentation.  (from Fei Wang, Changshui Zhang, Xiaogang Wang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">10. Adaptive Dilated Convolution For Human Pose Estimation.  (from Liang Wang, Tieniu Tan)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section><mpvoice class=\"js_editor_audio audio_iframe js_uneditable custom_select_card\" src=\"/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;name=10%20ML%20Papers.mp3&amp;play_length=21:06\" isaac2=\"1\" low_size=\"2380.02\" source_size=\"2355.2\" high_size=\"4949.01\" name=\"10 ML Papers.mp3\" play_length=\"1266000\" voice_encode_fileid=\"MzA3MzI4MjgzM18yNjUwODIyMDY1\" data-topic_id=\"\" data-topic_name=\"\" data-pluginname=\"insertaudio\"></mpvoice></section><section style=\"line-height: 1.75em;\"><br><span style=\"font-size: 15px;\"></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb>本周 10 篇 ML 精选论文是：</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. Visual Representation Learning Does Not Generalize Strongly Within the Same Domain.  (from Bernhard Schölkopf)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. Distribution of Classification Margins: Are All Data Equal?.  (from Tomaso Poggio)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. Species Distribution Modeling for Machine Learning Practitioners: A Review.  (from Pietro Perona)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. The Benchmark Lottery.  (from Oriol Vinyals)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. Using system context information to complement weakly labeled data.  (from Lothar Thiele)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. Bridging the Gap between Spatial and Spectral Domains: A Theoretical Framework for Graph Neural Networks.  (from Lei Zhang, Charu Aggarwal, Chang-Tien Lu)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">7. A Theory of PAC Learnability of Partial Concept Classes.  (from Noga Alon)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">8. Preventing dataset shift from breaking machine-learning biomarkers.  (from Gaël Varoquaux)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">9. GoTube: Scalable Stochastic Verification of Continuous-Depth Models.  (from Daniela Rus)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">10. Benchmarking AutoML Frameworks for Disease Prediction Using Medical Claims.  (from Jason H. Moore)</span></section><section style=\"line-height: 1.75em;\"><br></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><p style=\"margin-top: 5px;white-space: normal;text-align: center;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">© THE END </span></p><p style=\"margin-top: 5px;white-space: normal;text-align: center;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">转载请联系本公众号获得授权</span></p><p style=\"margin-top: 5px;white-space: normal;text-align: center;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">投稿或寻求报道：content@jiqizhixin.com</span></p>\n                </div>\n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650822066&amp;idx=5&amp;sn=0959b0e1bc5e2d18f7abaae86e21abd6&amp;chksm=84e591ccb39218da1cff37cff49094547b819e228bf1867fb6bcf573c742753a30de168f59e4&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/6155/eBNdZJiBCu\"></div></div>","descriptionType":"html","publishedDate":"Sun, 25 Jul 2021 04:38:00 +0000","feedId":1837,"bgimg":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbqMBAia86CFj2cC3nHSEGgs1Uxd7ict7RhguzwEKSagJ0hibFddqnASMKw/0?wx_fmt=jpeg?imageView2/1/w/600","linkMd5":"94a361a989e9bd535101318dd4219dd1","destWidth":236,"destHeight":235,"sourceBytes":11974,"destBytes":12716,"author":"","articleImgCdnMap":{"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbqMBAia86CFj2cC3nHSEGgs1Uxd7ict7RhguzwEKSagJ0hibFddqnASMKw/0?wx_fmt=jpeg?imageView2/1/w/600":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbfibYbAcjKkTw4KibRXkHlMd0ClwIMXbYvSGPYia5KVs6WzDuhjLWUhZQQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb07dTjgLp2XyLZbbMtlvibQRANLRTL9FeDRzQBJ0P8WsuC1wJbwAm11A/640?wx_fmt=jpeg":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn88@2020_1/2021/07/25/10-58-57-888_75a781842fdc1e09.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb6wEZVfdn6DiaDNvdicABgFZLh7LQJVH3LaHozKqVUZDYvKqwWboAeENQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbRibC27Gyb5cRexyCDFm0YxHbNY5iaKvicicQWRvxKf7AjW9fCPric1NoUEQ/640?wx_fmt=jpeg":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn65@2020_2/2021/07/25/10-58-13-133_f68892baf23766f4.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb5Im8unaXA5n7ukzjBFluTRcxD3QzJZPHYWMKdVXMRKd2Sa0OCZicxKg/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbVyF2y7g1DB6tYS2CsTdIEMzBx2KvvXic7ibWE5Z6GbDBTAd0YO0ngkZg/640?wx_fmt=jpeg":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn74@2020_3/2021/07/25/10-57-59-309_a94880d2794df3a7.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbBP74pSUbU6YkIhlm8hO6OZ2AgMR49ia34NJVAdPjrIJ5TmDHednk3IA/640?wx_fmt=jpeg":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn97@2020_3/2021/07/25/10-57-52-864_b912c38d770ba083.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbRj8YUwDGliaweWkG7Agict4h6ANeCN8T5zAXmEuyrliajhiaVVT1TO7hiag/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_1/2021/07/25/10-58-06-106_562a419280fb85cb.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb2Oyxewt9dZRBeeVnAxYDvdR5TWhgEUIia8H3NokiaCDhlDx2E92M2pAA/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbmK0Q21nBZynibXYur7mXdo4AOwWCe1Ce0SbueicvdCotmq7B4c4e3Iyg/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbn6uFQXpSibRUVVjIp4DajEbhuibLLeNYwic9HfU8GialqiaugJBLehqEwXQ/640?wx_fmt=jpeg":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb1vWmGNmicEdj8mpTnnrDBaEuNa3A4ON8Kx6jSzJIJDR4uXDJdSRcD3w/640?wx_fmt=jpeg":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn54@2020_1/2021/07/25/10-59-02-544_666c4915c46e2877.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb7TT20FuAd4BQqJYexAqA4znb7VjSmsjwWn1cFlPKaMeicNvSYghOtYw/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbtfGIgbwRIAZSzPHu5CW6fbriapm9lCF3W7HwWErcicgW0Xqnbss76pfQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn4@2020_6/2021/07/25/10-58-01-496_aacd5e2536f21dea.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbdBIicjnialbBoXibnKgl5pM77WTPJVuwz9PuYx3scWU6y1QszBkibGKmDQ/640?wx_fmt=png":null,"http://www.jintiankansha.me/rss_static/6155/eBNdZJiBCu":null},"publishedOrCreatedDate":1627210657532}],"record":{"createdTime":"2021-07-25 18:57:37","updatedTime":"2021-07-25 18:57:37","feedId":1837,"fetchDate":"Sun, 25 Jul 2021 10:57:37 +0000","fetchMs":716,"handleMs":19,"totalMs":135432,"newArticles":0,"totalArticles":5,"status":1,"type":0,"ip":"4cf9ab886509ef3fd2ece0a16b714d9c","hostName":"europe-24*","requestId":"fc4338d26c9a4cf987010b7958747967_1837","contentType":"application/rss+xml","totalBytes":472366,"bgimgsTotal":1,"bgimgsGithubTotal":0,"articlesImgsTotal":17,"articlesImgsGithubTotal":7,"successGithubMap":{"myreaderx15":1,"myreaderx6":1,"myreaderx4":1,"myreaderx33":1,"myreaderx13":1,"myreaderx30":1,"myreaderx29":1},"failGithubMap":{"myreaderx23":1,"myreaderx31":1}},"feed":{"createdTime":"2020-08-24 21:31:33","updatedTime":"2020-09-01 09:54:29","id":1837,"name":"机器之心","url":"http://feedmaker.kindle4rss.com/feeds/almosthuman2014.weixin.xml","subscriber":null,"website":null,"icon":"http://www.sogou.com/images/logo/new/favicon.ico?v=4","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx65/cdn87@2020_3/2020/09/01/01-54-30-263_d24121c9beed1de6.ico","description":"专业的人工智能媒体和产业服务平台","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2021-07-25 18:59:52","updatedTime":"2021-07-25 18:59:52","id":null,"feedId":1837,"linkMd5":"94a361a989e9bd535101318dd4219dd1"}],"tmpCommonImgCdnBytes":0,"tmpBodyImgCdnBytes":472366,"tmpBgImgCdnBytes":0,"extra4":{"start":1627210656573,"total":0,"statList":[{"spend":940,"msg":"获取xml内容"},{"spend":19,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":123295,"msg":"正文链接上传到cdn"}]},"extra5":17,"extra6":10,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbqMBAia86CFj2cC3nHSEGgs1Uxd7ict7RhguzwEKSagJ0hibFddqnASMKw/0?wx_fmt=jpeg?imageView2/1/w/600","sourceStatusCode":200,"destWidth":236,"destHeight":235,"sourceBytes":11974,"destBytes":12716,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":5579,"convertSpendMs":5,"createdTime":"2021-07-25 18:57:37","host":"europe62*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1,94a361a989e9bd535101318dd4219dd1","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx31/cdn38/contents/2021/07/25/10-57-42-980_ced01b0fb562a104.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69855631.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Sun, 25 Jul 2021 10:57:43 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["A480:13A78:15D5443:16A8849:60FD43A6"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1627214035"],"x-ratelimit-resource":["core"],"x-ratelimit-used":["60"],"x-xss-protection":["0"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx31/cdn38/contents/2021/07/25/10-57-42-980_ced01b0fb562a104.webp","historyStatusCode":[],"spendMs":156},"base64UserPassword":null,"token":"da243******************************d9e47"},"githubUser":"myreaderx31","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.7 KB","destSize":"12.4 KB","compressRate":"106.2%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbqMBAia86CFj2cC3nHSEGgs1Uxd7ict7RhguzwEKSagJ0hibFddqnASMKw/0?wx_fmt=jpeg?imageView2/1/w/600","sourceStatusCode":200,"destWidth":236,"destHeight":235,"sourceBytes":11974,"destBytes":12716,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":5565,"convertSpendMs":5,"createdTime":"2021-07-25 18:57:43","host":"europe62*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1,94a361a989e9bd535101318dd4219dd1","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx31/cdn38/contents/2021/07/25/10-57-48-553_ced01b0fb562a104.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69855631.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Sun, 25 Jul 2021 10:57:48 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["A480:13A78:15D5712:16A8B39:60FD43AC"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1627214035"],"x-ratelimit-resource":["core"],"x-ratelimit-used":["60"],"x-xss-protection":["0"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx31/cdn38/contents/2021/07/25/10-57-48-553_ced01b0fb562a104.webp","historyStatusCode":[],"spendMs":156},"base64UserPassword":null,"token":"da243******************************d9e47"},"githubUser":"myreaderx31","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.7 KB","destSize":"12.4 KB","compressRate":"106.2%"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/6155/eBNdZJiBCu","sourceStatusCode":0,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":410,"convertSpendMs":0,"createdTime":"2021-07-25 18:57:48","host":"europe63*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[0],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/6155/eBNdZJiBCu","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":718,"convertSpendMs":0,"createdTime":"2021-07-25 18:57:49","host":"us-009*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb5Im8unaXA5n7ukzjBFluTRcxD3QzJZPHYWMKdVXMRKd2Sa0OCZicxKg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":231,"sourceBytes":53321,"destBytes":15314,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":9348,"convertSpendMs":12,"createdTime":"2021-07-25 18:57:48","host":"us-030*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn13/contents/2021/07/25/10-57-58-151_61a0bc5f90517838.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Sun, 25 Jul 2021 10:57:58 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["C0D6:3901:2766BEE:4E6CCF9:60FD43B6"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1627214040"],"x-ratelimit-resource":["core"],"x-ratelimit-used":["62"],"x-xss-protection":["0"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn13/contents/2021/07/25/10-57-58-151_61a0bc5f90517838.webp","historyStatusCode":[],"spendMs":37},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"52.1 KB","destSize":"15 KB","compressRate":"28.7%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb5Im8unaXA5n7ukzjBFluTRcxD3QzJZPHYWMKdVXMRKd2Sa0OCZicxKg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":231,"sourceBytes":53321,"destBytes":15314,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":1227,"convertSpendMs":17,"createdTime":"2021-07-25 18:57:58","host":"us-001*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn13/contents/2021/07/25/10-57-59-516_61a0bc5f90517838.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Sun, 25 Jul 2021 10:57:59 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["9AD4:3901:2766C4D:4E6CDBE:60FD43B7"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1627214040"],"x-ratelimit-resource":["core"],"x-ratelimit-used":["62"],"x-xss-protection":["0"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn13/contents/2021/07/25/10-57-59-516_61a0bc5f90517838.webp","historyStatusCode":[],"spendMs":39},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"52.1 KB","destSize":"15 KB","compressRate":"28.7%"},null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://europe-56.herokuapp.com/":{"failCount":2,"successCount":1,"resultList":[200,null,null]},"http://us-018.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-037.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe68.herokuapp.com/":{"failCount":2,"successCount":1,"resultList":[200,null,null]},"http://europe63.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[0]},"http://us-034.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-009.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[405,200]},"http://us-030.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-52.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-026.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-038.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-006.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-001.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://europe64.herokuapp.com/":{"failCount":2,"successCount":1,"resultList":[200,null,null]},"http://us-010.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe-22.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbBP74pSUbU6YkIhlm8hO6OZ2AgMR49ia34NJVAdPjrIJ5TmDHednk3IA/640?wx_fmt=jpeg","sourceStatusCode":200,"destWidth":1080,"destHeight":215,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn97@2020_3/2021/07/25/10-57-52-864_b912c38d770ba083.webp","sourceBytes":30507,"destBytes":23224,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":4277,"convertSpendMs":12,"createdTime":"2021-07-25 18:57:48","host":"us-001*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.8 KB","destSize":"22.7 KB","compressRate":"76.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbVyF2y7g1DB6tYS2CsTdIEMzBx2KvvXic7ibWE5Z6GbDBTAd0YO0ngkZg/640?wx_fmt=jpeg","sourceStatusCode":200,"destWidth":1080,"destHeight":612,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn74@2020_3/2021/07/25/10-57-59-309_a94880d2794df3a7.webp","sourceBytes":93368,"destBytes":63474,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":10763,"convertSpendMs":21,"createdTime":"2021-07-25 18:57:48","host":"us-009*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"91.2 KB","destSize":"62 KB","compressRate":"68%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbtfGIgbwRIAZSzPHu5CW6fbriapm9lCF3W7HwWErcicgW0Xqnbss76pfQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":568,"destHeight":580,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn4@2020_6/2021/07/25/10-58-01-496_aacd5e2536f21dea.webp","sourceBytes":50432,"destBytes":20184,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":13215,"convertSpendMs":16,"createdTime":"2021-07-25 18:57:48","host":"europe64*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"49.2 KB","destSize":"19.7 KB","compressRate":"40%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbRj8YUwDGliaweWkG7Agict4h6ANeCN8T5zAXmEuyrliajhiaVVT1TO7hiag/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1025,"destHeight":440,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_1/2021/07/25/10-58-06-106_562a419280fb85cb.webp","sourceBytes":168741,"destBytes":81200,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":17909,"convertSpendMs":27,"createdTime":"2021-07-25 18:57:48","host":"europe68*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"164.8 KB","destSize":"79.3 KB","compressRate":"48.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpbRibC27Gyb5cRexyCDFm0YxHbNY5iaKvicicQWRvxKf7AjW9fCPric1NoUEQ/640?wx_fmt=jpeg","sourceStatusCode":200,"destWidth":1080,"destHeight":553,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn65@2020_2/2021/07/25/10-58-13-133_f68892baf23766f4.webp","sourceBytes":109818,"destBytes":80844,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":25164,"convertSpendMs":30,"createdTime":"2021-07-25 18:57:48","host":"europe-56*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"107.2 KB","destSize":"78.9 KB","compressRate":"73.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb07dTjgLp2XyLZbbMtlvibQRANLRTL9FeDRzQBJ0P8WsuC1wJbwAm11A/640?wx_fmt=jpeg","sourceStatusCode":200,"destWidth":1080,"destHeight":554,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn88@2020_1/2021/07/25/10-58-57-888_75a781842fdc1e09.webp","sourceBytes":107886,"destBytes":83730,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":7472,"convertSpendMs":31,"createdTime":"2021-07-25 18:58:50","host":"us-001*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"105.4 KB","destSize":"81.8 KB","compressRate":"77.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibDtXH52MrJH5eZsyZiaPBpb1vWmGNmicEdj8mpTnnrDBaEuNa3A4ON8Kx6jSzJIJDR4uXDJdSRcD3w/640?wx_fmt=jpeg","sourceStatusCode":200,"destWidth":963,"destHeight":938,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn54@2020_1/2021/07/25/10-59-02-544_666c4915c46e2877.webp","sourceBytes":162311,"destBytes":119710,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":12159,"convertSpendMs":31,"createdTime":"2021-07-25 18:58:50","host":"us-001*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20ICML%E3%80%81RSS%E9%A1%B6%E4%BC%9A%E6%9D%B0%E5%87%BA%E3%80%81%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%EF%BC%9BAlphaFold%E8%A7%A3%E9%94%8198.5%25%E4%BA%BA%E7%B1%BB%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84","linkMd5ListStr":"94a361a989e9bd535101318dd4219dd1","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"158.5 KB","destSize":"116.9 KB","compressRate":"73.8%"}],"successGithubMap":{"myreaderx15":1,"myreaderx6":1,"myreaderx4":1,"myreaderx33":1,"myreaderx13":1,"myreaderx30":1,"myreaderx29":1},"failGithubMap":{"myreaderx23":1,"myreaderx31":1}}