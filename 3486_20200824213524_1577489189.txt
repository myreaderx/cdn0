{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"记一次Redis连接池问题引发的RST","link":"https://blog.huoding.com/?p=816","description":"<p>某个项目，因为监控尚不完善，所以我时常会人肉查查状态，终于有一天发现了异常：</p>\n<div id=\"attachment_817\" style=\"width: 1210px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/05/netstat.png\"><img aria-describedby=\"caption-attachment-817\" loading=\"lazy\" class=\"size-full wp-image-817\" src=\"https://blog.huoding.com/wp-content/uploads/2020/05/netstat.png\" alt=\"watch -d -n1 'netstat -s | grep reset'\" width=\"1200\" height=\"400\" /></a><p id=\"caption-attachment-817\" class=\"wp-caption-text\">watch -d -n1 &#8216;netstat -s | grep reset&#8217;</p></div>\n<p>如图所示，服务器发送了大量的 reset，在我 watch 的时候还在发，多半有问题。</p>\n<p><span id=\"more-816\"></span></p>\n<p>通过 tcpdump 我们可以简单抓取一下 RST 包：</p>\n<pre>shell&#62; tcpdump -nn 'tcp[tcpflags] &#38; (tcp-rst) != 0'</pre>\n<p>不过更好的方法是通过 tcpdump 多抓一些流量然后用 wireshark 来分析：</p>\n<div id=\"attachment_818\" style=\"width: 1910px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/05/rst.png\"><img aria-describedby=\"caption-attachment-818\" loading=\"lazy\" class=\"size-full wp-image-818\" src=\"https://blog.huoding.com/wp-content/uploads/2020/05/rst.png\" alt=\"RST\" width=\"1900\" height=\"820\" /></a><p id=\"caption-attachment-818\" class=\"wp-caption-text\">RST</p></div>\n<p>如图所示，描述了一个 web 服务器和一个 redis 服务器的交互过程，有两个问题：</p>\n<ul>\n<li>在我的场景里，使用了 <a href=\"https://github.com/openresty/lua-resty-redis\" target=\"_blank\" rel=\"noopener noreferrer\">lua-resty-redis</a> 连接池，为什么还会发送 FIN 来关闭连接？</li>\n<li>即便关闭连接，为什么 web 服务器收到 FIN 后还会发送 RST 补刀？</li>\n</ul>\n<p>因为项目代码比较多，我一时确定不了 lua-resty-redis 连接池的问题在哪，所以我打算先搞定为什么 web 服务器收到 FIN 后还会发送 RST 补刀的问题。</p>\n<p>我们可以通过 systemtap 来查查内核（3.10.0-693）是通过什么函数来发送 RST 的：</p>\n<pre>shell&#62; stap -l 'kernel.function(\"*\")' | grep tcp | grep reset\nkernel.function(\"bictcp_hystart_reset@net/ipv4/tcp_cubic.c:129\")\nkernel.function(\"bictcp_reset@net/ipv4/tcp_cubic.c:105\")\nkernel.function(\"tcp_cgroup_reset@net/ipv4/tcp_memcontrol.c:200\")\nkernel.function(\"tcp_fastopen_reset_cipher@net/ipv4/tcp_fastopen.c:39\")\nkernel.function(\"tcp_highest_sack_reset@include/net/tcp.h:1538\")\nkernel.function(\"tcp_need_reset@net/ipv4/tcp.c:2183\")\nkernel.function(\"tcp_reset@net/ipv4/tcp_input.c:3916\")\nkernel.function(\"tcp_reset_reno_sack@net/ipv4/tcp_input.c:1918\")\nkernel.function(\"tcp_sack_reset@include/net/tcp.h:1091\")\nkernel.function(\"tcp_send_active_reset@net/ipv4/tcp_output.c:2792\")\nkernel.function(\"tcp_v4_send_reset@net/ipv4/tcp_ipv4.c:579\")\nkernel.function(\"tcp_v6_send_reset@net/ipv6/tcp_ipv6.c:888\")</pre>\n<p>虽然我并不熟悉内核，但并不妨碍解决问题。通过查看<a href=\"https://elixir.bootlin.com/linux/v3.10/source\" target=\"_blank\" rel=\"noopener noreferrer\">源代码</a>，可以大致判断出 RST 是 tcp_send_active_reset 或者 tcp_v4_send_reset 发送的（看名字 tcp_reset 很像是我们要找的，不过实际上它的作用是收到 RST 的时候需要做什么）。</p>\n<p>为了确认到底是谁发送的，我启动了两个命令行窗口：</p>\n<p>一个运行 tcpdump：</p>\n<pre>shell&#62; tcpdump -nn 'tcp[tcpflags] &#38; (tcp-rst) != 0'</pre>\n<p>另一个运行 systemtap：</p>\n<pre>#! /usr/bin/env stap\n\nprobe kernel.function(\"tcp_send_active_reset\") {\n    printf(\"%s tcp_send_active_reset\\n\", ctime())\n}\n\nprobe kernel.function(\"tcp_v4_send_reset\") {\n    printf(\"%s tcp_v4_send_reset\\n\", ctime())\n}\n</pre>\n<p>通过对照两个窗口显示内容的时间点，最终确认 RST 是 tcp_v4_send_reset 发送的。</p>\n<p>接下来确认一下 tcp_v4_send_reset 是谁调用的：</p>\n<pre>#! /usr/bin/env stap\n\nprobe kernel.function(\"tcp_v4_send_reset\") {\n    print_backtrace()\n    printf(\"\\n\")\n}\n\n// output\n\n0xffffffff815eebf0 : tcp_v4_send_reset+0x0/0x460 [kernel]\n0xffffffff815f06b3 : tcp_v4_rcv+0x5a3/0x9a0 [kernel]\n0xffffffff815ca054 : ip_local_deliver_finish+0xb4/0x1f0 [kernel]\n0xffffffff815ca339 : ip_local_deliver+0x59/0xd0 [kernel]\n0xffffffff815c9cda : ip_rcv_finish+0x8a/0x350 [kernel]\n0xffffffff815ca666 : ip_rcv+0x2b6/0x410 [kernel]\n0xffffffff81586f22 : __netif_receive_skb_core+0x572/0x7c0 [kernel]\n0xffffffff81587188 : __netif_receive_skb+0x18/0x60 [kernel]\n0xffffffff81587210 : netif_receive_skb_internal+0x40/0xc0 [kernel]\n0xffffffff81588318 : napi_gro_receive+0xd8/0x130 [kernel]\n0xffffffffc0119505 [virtio_net]\n</pre>\n<p>如上所示，tcp_v4_rcv 调用 tcp_v4_send_reset 发送了 RST，看看 tcp_v4_rcv 的<a href=\"https://elixir.bootlin.com/linux/v3.10/source/net/ipv4/tcp_ipv4.c#L1961\" target=\"_blank\" rel=\"noopener noreferrer\">源代码</a>：</p>\n<pre>int tcp_v4_rcv(struct sk_buff *skb)\n{\n    ...\n\n    sk = __inet_lookup_skb(&#38;tcp_hashinfo, skb, th-&#62;source, th-&#62;dest);\n    if (!sk)\n        <strong>goto no_tcp_socket;</strong>\n\nprocess:\n    if (sk-&#62;sk_state == TCP_TIME_WAIT)\n        goto do_time_wait;\n\n    ...\n\nno_tcp_socket:\n    if (!xfrm4_policy_check(NULL, XFRM_POLICY_IN, skb))\n        goto discard_it;\n\n    if (skb-&#62;len &#60; (th-&#62;doff &#60;&#60; 2) || tcp_checksum_complete(skb)) {\ncsum_error:\n        TCP_INC_STATS_BH(net, TCP_MIB_CSUMERRORS);\nbad_packet:\n        TCP_INC_STATS_BH(net, TCP_MIB_INERRS);\n    } else {\n        tcp_v4_send_reset(NULL, skb);\n    }\n\n    ...\n\ndo_time_wait:\n\n    ...\n\n    switch (tcp_timewait_state_process(inet_twsk(sk), skb, th)) {\n\n        ...\n\n        case TCP_TW_RST:\n            <strong>goto no_tcp_socket;</strong>\n\n        ...\n\n    }\n\n    ...\n}\n</pre>\n<p>有两处可能会触发 tcp_v4_send_reset（no_tcp_socket）。先看后面的 tcp_v4_send_reset 代码，也就是 do_time_wait 相关的部分，只有进入 TIME_WAIT 状态才会执行相关逻辑，而本例中发送了 RST，并没有正常进入 TIME_WAIT 状态，不符合要求，所以问题的症结应该是前面的 tcp_v4_send_reset 代码，也就是 __inet_lookup_skb 相关的部分：当 sk 不存在的时候，reset。</p>\n<p>不过 sk 为什么会不存在呢？当 web 服务器发送 FIN 的时候，进入 FIN_WAIT_1 状态，当 redis 服务器回复 ACK 的时候，进入 FIN_WAIT_2 状态，如果 sk 不存在，那么就说明 FIN_WAIT_1 或者 FIN_WAIT_2 中的某个状态丢失了，通过 ss 观察一下：</p>\n<pre>shell&#62; watch -d -n1 'ss -ant | grep FIN'</pre>\n<p>通常，FIN_WAIT_1 或者 FIN_WAIT_2 存在的时间都很短暂，不容易观察，不过在本例中，流量比较大，所以没问题。如果你的环境没有大流量，也可自己通过 ab/wrk 之类的压力工具人为给一些压力。结果发现，可以观察到 FIN_WAIT_1，但是却很难观察到 FIN_WAIT_2，看上去 FIN_WAIT_2 似乎丢失了。</p>\n<p>原本以为可能和 linger，tcp_fin_timeout 之类的设置有关，经确认排除嫌疑。彷徨了许久，记起 TIME_WAIT 有一个控制项：tcp_max_tw_buckets，可以用来控制 TIME_WAIT 的数量，会不会与此有关：</p>\n<pre>shell&#62; sysctl -a | grep tcp_max_tw_buckets\nnet.ipv4.tcp_max_tw_buckets = 131072\n\nshell&#62; cat /proc/net/sockstat\nsockets: used 1501\nTCP: inuse 117 orphan 0 tw 127866 alloc 127 mem 56\nUDP: inuse 9 mem 8\nUDPLITE: inuse 0\nRAW: inuse 0\nFRAG: inuse 0 memory 0</pre>\n<p>对比系统现有的 tw，可以发现已经临近 tcp_max_tw_buckets 规定的上限，试着提高阈值，会发现又能观察到 FIN_WAIT_2 了，甚至 RST 的问题也随之消失。</p>\n<p>如此一来， RST 问题算是有眉目了：TIME_WAIT 数量达到 tcp_max_tw_buckets 规定的上限，进而影响了 FIN_WAIT_2 的存在（问题细节尚未搞清楚），于是在 tcp_v4_rcv 调用 __inet_lookup_skb 查找 sk 的时候查不到，最终只好发送 RST。</p>\n<p>结论：tcp_max_tw_buckets 不能太小！</p>\n<p>&#8230;</p>\n<p>问题到这里还不算完，别忘了我们还有一个  lua-resty-redis 连接池的问题尚未解决。</p>\n<p>如何验证连接池是否生效呢？</p>\n<p>最简单的方法是核对连接 redis 的 TIME_WAIT 状态是否过多，肯定的话那么就说明连接池可能没生效，为什么是可能？因为在高并发情况下，当连接过多的时候，会按照 LRU 机制关闭旧连接，此时出现大量 TIME_WAIT 是正常的。</p>\n<blockquote><p>When the connection pool would exceed its size limit, the least recently used (kept-alive) connection already in the pool will be closed to make room for the current connection.</p></blockquote>\n<p>最准确的方法是使用 redis 的 <a href=\"https://redis.io/commands/client-list\" target=\"_blank\" rel=\"noopener noreferrer\">client list</a> 命令，它会打印每个连接的 age 连接时长。通过此方法，我验证发现 web 服务器和 redis 服务器之间的连接，总是在 age 很小的时候就被断开，说明有问题。</p>\n<p>在解决问题前了解一下 lua-resty-redis 的连接池是如何使用的：</p>\n<pre>local redis = require \"resty.redis\"\nlocal red = redis:new()\n\nred:connect(ip, port)\n\n...\n\nred:set_keepalive(0, 100)</pre>\n<p>只要用完后记得调用 <a href=\"https://github.com/openresty/lua-resty-redis#set_keepalive\" target=\"_blank\" rel=\"noopener noreferrer\">set_keepalive</a> 把连接放回连接池即可。一般出问题的地方有两个：</p>\n<ul>\n<li>openresty 禁用了 lua_code_cache，此时连接池无效</li>\n<li>redis 的 timeout 太小，此时长链接可能会频繁被关闭</li>\n</ul>\n<p>在我的场景里，如上问题均不存在。每当我一筹莫展的时候我就重看一遍文档，当看到 <a href=\"https://github.com/openresty/lua-resty-redis#connect\" target=\"_blank\" rel=\"noopener noreferrer\">connect</a> 的部分时，下面一句话提醒了我：</p>\n<blockquote><p>Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.</p></blockquote>\n<p>也就是说，即便是短链接，在 connect 的时候也会尝试从连接池里获取连接，这样的话，如果是长短连接混用的情况，那么连接池里长链接建立的连接就可能会被短链接关闭掉。顺着这个思路，我搜索了一下源代码，果然发现某个角落有一个短链接调用。</p>\n<p>结论：不要混用长短连接！</p>\n","descriptionType":"html","publishedDate":"Sun, 03 May 2020 17:01:19 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/05/netstat.png","linkMd5":"c4e28733e1901cf7ef9b8996747d0bbc","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn85@2020_3/2020/08/24/21-35-03-859_6696b1bfc6c94a92.webp","destWidth":1200,"destHeight":400,"sourceBytes":60006,"destBytes":27368,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/05/netstat.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn85@2020_3/2020/08/24/21-35-03-859_6696b1bfc6c94a92.webp","https://blog.huoding.com/wp-content/uploads/2020/05/rst.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn43@2020_5/2020/08/24/21-35-22-763_67a2c7b1fd7135df.webp"},"publishedOrCreatedDate":1598304897608},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"手把手教你用OpenResty里的FFI","link":"https://blog.huoding.com/?p=805","description":"<p>了解 OpenResty 的人应该知道，OpenResty 原本的 API 都是基于 C 实现的，不过在新版里都已经改成了基于 FFI 实现的，为什么这么做？因为 FFI 在效率上更有优势，除此以外，FFI 还有一个优点是可以很便利的和 C 交互，我们不妨设想一下，C 语言有那么多成熟的库，通过 FFI，我们可以轻而易举的引入到自己的应用中，何乐而不为呢？</p>\n<p><span id=\"more-805\"></span></p>\n<p>本文通过 <a href=\"https://hashids.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Hashids</a> 手把手教你用 OpenResty 里的 FFI。说起 Hashids，它的功能是把一个正整数转换成一个相对更短的唯一 ID，比如把 123456789 转换成 NRv345。基本上主流语言都实现了 Hashids，当然也有 <a href=\"https://github.com/leihog/hashids.lua\" target=\"_blank\" rel=\"noopener noreferrer\">Lua</a> 版本，不过本文即然是讲解 FFI 的，自然不会采用此版本，实际上我们使用的是 <a href=\"https://hashids.org/c/\" target=\"_blank\" rel=\"noopener noreferrer\">C</a> 版本。</p>\n<p>下载了 C 版本的 Hashids 源代码之后，第一件事是编译出动态链接库：</p>\n<pre>➜ gcc -shared -fPIC -o libhashids.so /path/to/hashids.c\n➜ gcc -dynamiclib -fPIC -o libhashids.dylib /path/to/hashids.c</pre>\n<p>不同操作系统使用不同的命令：Linux 用前一个，Mac 用后一个。此外还需要把库文件放到系统路径里，同样有操作系统差异，Linux 用 ldconfig，Mac 用 install_name_tool，细节不赘述，让我们直接看看如何通过 FFI 来使用 C 语言的动态链接库，简单说和把大象放冰箱一样，分三步：首先通过 ffi.cdef 添加头文件；然后通过 ffi.load 加载动态链接库，最后把 C 语言的操作步骤翻译成 Lua 代码。看代码吧：</p>\n<pre>local ffi = require \"ffi\"\n\nffi.cdef[[\nstruct hashids_s {\n    char *alphabet;\n    char *alphabet_copy_1;\n    char *alphabet_copy_2;\n    size_t alphabet_length;\n\n    char *salt;\n    size_t salt_length;\n\n    char *separators;\n    size_t separators_count;\n\n    char *guards;\n    size_t guards_count;\n\n    size_t min_hash_length;\n};\ntypedef struct hashids_s hashids_t;\n\nvoid\nhashids_free(hashids_t *hashids);\n\nhashids_t *\nhashids_init(const char *salt);\n\nsize_t\nhashids_encode(hashids_t *hashids, char *buffer, size_t numbers_count,\n    unsigned long long *numbers);\n\nsize_t\nhashids_decode(hashids_t *hashids, const char *str,\n    unsigned long long *numbers, size_t numbers_max);\n\nsize_t\nhashids_estimate_encoded_size(hashids_t *hashids, size_t numbers_count,\n    unsigned long long *numbers);\n]]\n\nlocal id = 123456789\n\nlocal C = ffi.load(\"hashids\")\nlocal hashids = C.hashids_init(\"this is my salt\")\nlocal numbers = ffi.new(\"unsigned long long[1]\", id)\nlocal size = C.hashids_estimate_encoded_size(hashids, 1, numbers)\nlocal buffer = ffi.new(\"char[?]\", size)\nlocal length = C.hashids_encode(hashids, buffer, 1, numbers)\nlocal hashid = ffi.string(buffer, length)\nlocal str = ffi.new(\"char[?]\", #hashid, hashid)\nnumbers = ffi.new(\"unsigned long long[1]\")\nC.hashids_decode(hashids, str, numbers, -1)\nC.hashids_free(hashids)\n\nngx.say(\"id: \", id)                       -- id: 123456789\nngx.say(\"hashid: \", hashid)               -- hashid: NRv345\nngx.say(\"decode: \", numbers[0])           -- decode: 123456789ULL\nngx.say(\"decode: \", tonumber(numbers[0])) -- decode: 123456789\n</pre>\n<p>在使用 Lua 操作动态链接库的时候，和 C 语言总体保持一致，常见的整数，字符串等数据类型都可以直接使用，唯一需要注意的是 C 语言的指针类型无法直接映射到 Lua 的数据类型，此时的变通做法是通过 ffi.new 声明一个「只有一个元素的数组」。</p>\n<p>LuaJIT FFI 不仅可以调用 C 语言，还可以调用其他语言，比如 Go，详情可以参考：</p>\n<ul>\n<li><a href=\"https://dev.to/vladimirvivien/calling-go-functions-from-other-languages\" target=\"_blank\" rel=\"noopener noreferrer\">Calling Go Functions from Other Languages</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000008633849\" target=\"_blank\" rel=\"noopener noreferrer\">在 LuaJIT 中调用 Go 函数</a></li>\n</ul>\n<p>关于 LuaJIT FFI 更多信息，建议浏览<a href=\"https://luajit.org/ext_ffi.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a>。下面文档也值得一看：</p>\n<ul>\n<li><a href=\"https://segmentfault.com/a/1190000015802547\" target=\"_blank\" rel=\"noopener noreferrer\">LuaJIT FFI 介绍，及其在 OpenResty 中的应用（上）</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000016149595\" target=\"_blank\" rel=\"noopener noreferrer\">LuaJIT FFI 介绍，及其在 OpenResty 中的应用（下）</a></li>\n</ul>\n<p>此外，<a href=\"https://github.com/luapower\" target=\"_blank\" rel=\"noopener noreferrer\">luapower</a> 上能找到不少使用 <a href=\"https://github.com/luapower?q=ffi\" target=\"_blank\" rel=\"noopener noreferrer\">FFI</a> 的代码，建议多看看。</p>\n","descriptionType":"html","publishedDate":"Sun, 08 Mar 2020 13:13:37 +0000","feedId":3486,"bgimg":"","linkMd5":"b1e6678f55fbcdfd07d35aac0a684b0f","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897610},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"手把手教你用ETCD","link":"https://blog.huoding.com/?p=839","description":"<p>一句话概括的话：<a href=\"https://etcd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">ETCD</a> 是一个基于 <a href=\"https://raft.github.io/\" target=\"_blank\" rel=\"noopener noreferrer\">RAFT</a> 的分布式 KV 存储系统。一个 ETCD 集群通常是由 3、5、7 之类奇数个节点组成的，为什么不选择偶数个节点？在集群系统中为了选出 LEADER 节点，至少要有半数以上的节点达成共识，举例说明：</p>\n<ul>\n<li>当集群有 3 个节点的时候，至少要有 2 个节点达成共识，最多容灾 1 个节点。</li>\n<li>当集群有 4 个节点的时候，至少要有 3 个节点达成共识，最多容灾 1 个节点。</li>\n<li>当集群有 5 个节点的时候，至少要有 3 个节点达成共识，最多容灾 2 个节点。</li>\n</ul>\n<p>如上可见当节点数是偶数个的时候，系统的容灾能力并没有得到提升，所以节点数一般选择 3、5、7 之类的奇数，至于具体选择多少的话，一般推荐 3 或者 5 比较合适，太少的话系统没有容灾能力，太多的话 LEADER 节点的通信任务会变得繁重，影响性能。</p>\n<p><span id=\"more-839\"></span></p>\n<p>如何搭建一个 ETCD 集群呢？比如在本地部署一个 3 个节点的集群，参考<a href=\"https://etcd.io/docs/v3.4.0/op-guide/clustering/\" target=\"_blank\" rel=\"noopener noreferrer\">文档</a>操作：</p>\n<pre>CLUSTER=\"etcd-0=http://127.0.0.1:2380,etcd-1=http://127.0.0.1:3380,etcd-2=http://127.0.0.1:4380\"\n\n/usr/local/bin/etcd \\\n    --name etcd-0 \\\n    --data-dir etcd-0.etcd\n    --listen-client-urls http://127.0.0.1:2379 \\\n    --listen-peer-urls http://127.0.0.1:2380 \\\n    --advertise-client-urls http://127.0.0.1:2379 \\\n    --initial-advertise-peer-urls http://127.0.0.1:2380 \\\n    --initial-cluster ${CLUSTER} &#38;\n\n/usr/local/bin/etcd \\\n    --name etcd-1 \\\n    --data-dir etcd-1.etcd\n    --listen-client-urls http://127.0.0.1:3379 \\\n    --listen-peer-urls http://127.0.0.1:3380 \\\n    --advertise-client-urls http://127.0.0.1:3379 \\\n    --initial-advertise-peer-urls http://127.0.0.1:3380 \\\n    --initial-cluster ${CLUSTER} &#38;\n\n/usr/local/bin/etcd \\\n    --name etcd-2 \\\n    --data-dir etcd-2.etcd\n    --listen-client-urls http://127.0.0.1:4379 \\\n    --listen-peer-urls http://127.0.0.1:4380 \\\n    --advertise-client-urls http://127.0.0.1:4379 \\\n    --initial-advertise-peer-urls http://127.0.0.1:4380 \\\n    --initial-cluster ${CLUSTER} &#38;</pre>\n<p>集群运行起来后，可以通过如下命令来确认状态是否正常：</p>\n<pre>shell&#62; etcdctl member list -w table\n+------------------+---------+--------+-----------------------+-----------------------+------------+\n|        ID        | STATUS  |  NAME  |      PEER ADDRS       |     CLIENT ADDRS      | IS LEARNER |\n+------------------+---------+--------+-----------------------+-----------------------+------------+\n| b71f75320dc06a6c | started | etcd-0 | http://127.0.0.1:2380 | http://127.0.0.1:2379 |      false |\n| d07d5325fff892c1 | started | etcd-1 | http://127.0.0.1:3380 | http://127.0.0.1:3379 |      false |\n| b7bacd4212cc9323 | started | etcd-2 | http://127.0.0.1:4380 | http://127.0.0.1:4379 |      false |\n+------------------+---------+--------+-----------------------+-----------------------+------------+\n\nshell&#62; etcdctl endpoint status --cluster -w table\n+-----------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|       ENDPOINT        |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://127.0.0.1:2379 | b71f75320dc06a6c |  3.4.10 |   25 kB |     false |      false |         2 |          8 |                  8 |        |\n| http://127.0.0.1:3379 | d07d5325fff892c1 |  3.4.10 |   25 kB |      true |      false |         2 |          8 |                  8 |        |\n| http://127.0.0.1:4379 | b7bacd4212cc9323 |  3.4.10 |   25 kB |     false |      false |         2 |          8 |                  8 |        |\n+-----------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n</pre>\n<p>虽然在本地部署 ETCD 集群很简单，但是在 K8S 上部署 ETCD 集群的话，往往会复杂很多，网上能找到一些别人共享的<a href=\"https://github.com/wilhelmguo/etcd-statefulset\" target=\"_blank\" rel=\"noopener noreferrer\">部署脚本</a>，估计大家看了会疯掉。难点主要在于当我们在 K8S 上部署 ETCD 集群的时候，出于可伸缩性的考虑，一般不会采用固定 IP 的做法，也就是说节点的 IP 是无法事先确定的，而启动 ETCD 集群的时候又需要确定各个接入的节点（initial-cluster），于是产生了矛盾。好在作为一个有状态服务（<a href=\"https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/\" target=\"_blank\" rel=\"noopener noreferrer\">StatefulSet</a>），可以使用 <a href=\"https://kubernetes.io/zh/docs/concepts/services-networking/service/#headless-services\" target=\"_blank\" rel=\"noopener noreferrer\">Headless service</a> 为每一个 POD 提供一个稳定的并且唯一的网络标识，也就是内网域名：「$(statefulset)-$(ordinal).$(service).$(namespace).svc.cluster.local」，当交互双方在同一个 namespace 下的话，甚至可以简写成「$(statefulset)-$(ordinal).$(service)」：</p>\n<ul>\n<li>$(statefulset) 是 StatefulSet 的名字。</li>\n<li>$(ordinal) 是 Pod 的序号，从 0 到 N-1。</li>\n<li>$(service) 是 Service 的名字。</li>\n<li>$(namespace) 是服务所在的 namespace。</li>\n</ul>\n<p>虽然每次部署的时候，节点 IP 都可能会变，但是节点的内网域名是不会变的，并且它会自动解析到对应的 IP 上，了解了这些，我们就可以编写自己的 K8S 脚本了：</p>\n<pre>apiVersion: v1\nkind: Service\nmetadata:\n  name: etcd\n  namespace: default\nspec:\n  clusterIP: None\n  publishNotReadyAddresses: true\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: etcd\n  namespace: default\nspec:\n  serviceName: etcd\n  replicas: 3\n  template:\n    spec:\n      dnsPolicy: ClusterFirst\n      containers:\n      - name: etcd\n        command:\n        - sh\n        - -c\n        - |\n          CLUSTER=\"\"\n\n          for i in $(seq 0 3); do\n            CLUSTER=${CLUSTER}${CLUSTER:+,}etcd-${i}=http://etcd-${i}.etcd:2380\n          done\n\n          exec /usr/local/bin/etcd \\\n            --name ${HOSTNAME} \\\n            --data-dir /var/run/etcd/default.etcd \\\n            --listen-client-urls http://0.0.0.0:2379 \\\n            --listen-peer-urls http://0.0.0.0:2380 \\\n            --advertise-client-urls http://${HOSTNAME}.etcd:2379 \\\n            --initial-advertise-peer-urls http://${HOSTNAME}.etcd:2380 \\\n            --initial-cluster ${CLUSTER}\n</pre>\n<p>友情提示：如上脚本非完整代码，此外，其中有几个需要留意的配置，分别是：</p>\n<ul>\n<li><a href=\"https://kubernetes.io/zh/docs/concepts/services-networking/service/#headless-services\" target=\"_blank\" rel=\"noopener noreferrer\">clusterIP: None</a>：表示是一个 Headless service。</li>\n<li><a href=\"https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/\" target=\"_blank\" rel=\"noopener noreferrer\">publishNotReadyAddresses: true</a>：不管 POD 是否准备就绪，都发布内网域名。</li>\n<li><a href=\"https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/\" target=\"_blank\" rel=\"noopener noreferrer\">dnsPolicy: ClusterFirst</a>：请求会优先在集群所在域查询，如此内网域名才会生效。</li>\n</ul>\n<p>掌握了前面说的内容之后，独立部署一个 ETCD 集群应该问题不大了，不过如果是在外网部署的话，安全起见，最好学习 TLS 相关知识，<a href=\"https://etcd.io/docs/v3.4.0/op-guide/security/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a>不容错过，其中有一个关于使用 <a href=\"https://github.com/cloudflare/cfssl\" target=\"_blank\" rel=\"noopener noreferrer\">cfssl</a> 生成<a href=\"https://github.com/coreos/docs/blob/master/os/generate-self-signed-certificates.md\" target=\"_blank\" rel=\"noopener noreferrer\">自签名证书</a>的<a href=\"https://github.com/etcd-io/etcd/tree/master/hack/tls-setup\" target=\"_blank\" rel=\"noopener noreferrer\">例子</a>，此外，强烈建议多看看「<a href=\"https://github.com/k8sp/tls\" target=\"_blank\" rel=\"noopener noreferrer\">TLS完全指南</a>」，里面有关于<a href=\"https://github.com/k8sp/tls/blob/master/etcd.md\" target=\"_blank\" rel=\"noopener noreferrer\">安全etcd机群</a>的精彩描述。</p>\n<p>最后，再安利一下 etcd web ui 方面比较出色的工具：<a href=\"https://github.com/evildecay/etcdkeeper\" target=\"_blank\" rel=\"noopener noreferrer\">etcdkeeper</a>，收工。</p>\n","descriptionType":"html","publishedDate":"Wed, 19 Aug 2020 09:34:59 +0000","feedId":3486,"bgimg":"","linkMd5":"f1d784d64c2bb78ab5898bc15d7a4703","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897592},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"白话布隆过滤器","link":"https://blog.huoding.com/?p=825","description":"<p>日常开发中，一个常见需求是判断一个元素是否在一个集合中。比如当你在浏览器中输入一个网址的时候，浏览器会判断网址是否在黑名单里。通常的解决方案是直接查询数据库，看看是否存在相关的记录，不过这往往会比较慢，于是我们又会引入缓存来提升速度，可是当数据比较多的时候，缓存会消耗大量的内存。有没有既速度快又节省内存的解决方案呢？本文介绍一种算法：布隆过滤器（<a href=\"https://en.wikipedia.org/wiki/Bloom_filter\" target=\"_blank\" rel=\"noopener noreferrer\">Bloom filter</a>）。</p>\n<p><span id=\"more-825\"></span></p>\n<p>所谓布隆过滤器，是由一个名叫布隆的人提出的：当一个元素被加入集合时，通过多个哈希函数将元素映射到一个比特数组中的若干个位置，并把它们置为 1 ，查询时，只要看看这些位置是不是都是 1 就知道元素是否（可能）在集合中了：如果这些位置中有任意一个是 0，那么此元素一定不在集合中；如果都是 1，那么此元素可能在集合中，注意是「可能」在，也就是说「可能」不在，这被称作「<a href=\"https://brilliant.org/wiki/bloom-filter/#false-positives-analysis\" target=\"_blank\" rel=\"noopener noreferrer\">False positive</a>」。实际使用中，布隆过滤器可以用在对 False positive 不那么敏感的领域，比如开头说的检测网址是否在黑名单里的问题，因为用户浏览的大部分网址都是正常的网址，所以可以先用布隆过滤器进行一次初筛，一旦发现可疑目标后再查询数据库确诊。</p>\n<div id=\"attachment_823\" style=\"width: 490px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/06/bloom.gif\"><img aria-describedby=\"caption-attachment-823\" loading=\"lazy\" class=\"size-full wp-image-823\" src=\"https://blog.huoding.com/wp-content/uploads/2020/06/bloom.gif\" alt=\"Bloom filter\" width=\"480\" height=\"240\" /></a><p id=\"caption-attachment-823\" class=\"wp-caption-text\">Bloom filter</p></div>\n<p>如上图所示，字符串「Hello」被哈希函数映射到比特数组中索引 1 和 3 的位置，布隆过滤器就会把这些位置置为 1；字符串「Bloom」被哈希函数映射到比特数组中索引 1 和 2 的位置，布隆过滤器也会把这些位置置为 1。细心的读者可能已经发现，两个字符串在哈希的时候发生了碰撞，都映射了索引 1，是否有问题？好消息是问题不大，布隆过滤器使用的是多个哈希函数，查询时，必须所有的哈希函数映射的索引位置都确认才行；坏消息是如果比特数组长度不够大，那么随着新元素的不断加入，比特数组中的大部分索引位置都会被置为 1，后续的误报率会越来越大。</p>\n<p>由此可见，在使用布隆过滤器的时候，如果想获得一个可接受的误报率，那么首先要选择合适的哈希函数，其次要协调好哈希函数数量和比特数组大小之间的关系。</p>\n<p>哈希函数应该尽可能保证数据分布均匀，此外，为了保证运行效率，应该选择尽可能快的哈希函数，比如：<a href=\"https://sites.google.com/site/murmurhash/\" target=\"_blank\" rel=\"noopener noreferrer\">murmurhash</a>、<a href=\"http://isthe.com/chongo/tech/comp/fnv/\" target=\"_blank\" rel=\"noopener noreferrer\">FNV</a>，至于 md5、sha1 等等，并不是好选择。</p>\n<p>如果使用很多很多的哈希函数，加上很大很大的比特数组，那么无疑可以把误报率降低到趋近于零，不过出于效率和成本的考虑，我们不会那样干，实际使用中，会通过调整哈希函数数量和比特数组大小之间的关系，来获得一个可接受的误报率，在 <a href=\"https://en.wikipedia.org/wiki/Bloom_filter\" target=\"_blank\" rel=\"noopener noreferrer\">wiki</a> 中给出了计算方法，本文省略证明过程，直接给出结论：「k = (m/n) ln2」，其中：k 是哈希函数的个数；m 是比特数组的大小；n 是过滤器中元素的数量；ln2 约等于 0.693：</p>\n<ul>\n<li>如果比特数组大小是过滤器中元素数量的 4 倍（也就是 m/n = 4），那么哈希函数数量为 3（实际为 2.77 四舍五入）的时候，误报率（14.7%）相对较低。</li>\n<li>如果比特数组大小是过滤器中元素数量的 6 倍（也就是 m/n = 6），那么哈希函数数量为 4（实际为 4.16 四舍五入）的时候，误报率（5.61%）相对较低。</li>\n<li>如果比特数组大小是过滤器中元素数量的 8 倍（也就是 m/n = 8），那么哈希函数数量为 6（实际为 5.55 四舍五入）的时候，误报率（2.16%）相对较低。</li>\n</ul>\n<p>在 <a href=\"http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html\" target=\"_blank\" rel=\"noopener noreferrer\">Bloom Filters &#8211; the math</a> 一文中，对 k 和 m/n 的关系进行了详细的统计分析，供参考：</p>\n<div id=\"attachment_824\" style=\"width: 919px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/06/false_positive.jpg\"><img aria-describedby=\"caption-attachment-824\" loading=\"lazy\" class=\"size-full wp-image-824\" src=\"https://blog.huoding.com/wp-content/uploads/2020/06/false_positive.jpg\" alt=\"False positive\" width=\"909\" height=\"726\" /></a><p id=\"caption-attachment-824\" class=\"wp-caption-text\">False positive</p></div>\n<p>实际使用中，我们可以先确认系统能忍受的最大误报率是多少，然后再确认 k 和 m/n。假设我们觉得 2% 左右的误报率是可以接受的，那么我们就可以选择 k=6，m/n=8，此时虽然看上去保存 n 个元素就需要创建 8n 个大小的比特数组，从数值上看似乎有点浪费空间，但是别忘了，我们用的是比特数组，8bit=1byte，换句话说，此场景下，保存一个元素仅需要一个字节的成本，所以说相比较直接保存元素本身而言还是很节省内存的。</p>\n<p>虽然布隆过滤器简单好用，但是它也有自己的缺点：不支持删除元素。原因是如果删除元素，那么需要把元素对应的若干个索引位置的值从 1 置为 0，可是这些索引位置可能关系到别的元素，一旦置为 0，所有的相关元素都会被删除。如果你使用布隆过滤器，并且需要删除元素的话，那么你只能删除元素后重建整个数据结构。当然，你也可以选择其它的算法，比如布谷鸟过滤器（<a href=\"https://en.wikipedia.org/wiki/Cuckoo_filter\" target=\"_blank\" rel=\"noopener noreferrer\">Cukoo filter</a>），它支持删除元素，更酷，但是也更复杂，篇幅所限，本文就不多说了，有兴趣的读者可以参照<a href=\"https://brilliant.org/wiki/cuckoo-filter/\" target=\"_blank\" rel=\"noopener noreferrer\">相关资料</a>自行学习。</p>\n<p>本文关于布隆过滤器就介绍到这里，如果大家跃跃欲试的话，很多现成的选择，比如：</p>\n<ul>\n<li>Mozilla 开发的适用于 openresty 的 lua 版本布隆过滤器：<a href=\"https://github.com/mozilla-services/lua_sandbox_extensions/blob/master/bloom_filter/index.md\" target=\"_blank\" rel=\"noopener noreferrer\">Lua Bloom Filter Module</a></li>\n<li>Willf 开发的 Golang 版本布隆过滤器：<a href=\"https://github.com/willf/bloom\" target=\"_blank\" rel=\"noopener noreferrer\">bloom</a></li>\n</ul>\n<p>当然，明白了原理，自己实现一个也不难，如果使用 Redis 的话，直接包装一下 Bitmap 就可以，如果还想更简单点，可以直接使用 RedisLabs 提供的 <a href=\"https://redislabs.com/redis-enterprise/redis-bloom/\" target=\"_blank\" rel=\"noopener noreferrer\">RedisBloom</a> 模块。</p>\n","descriptionType":"html","publishedDate":"Mon, 22 Jun 2020 04:31:01 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/06/bloom.gif","linkMd5":"0834b92ebcd3a159c7593b6f36c3f536","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn78@2020_4/2020/08/24/21-35-01-655_792c9650724a3ec1.webp","destWidth":480,"destHeight":240,"sourceBytes":29974,"destBytes":13366,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/06/bloom.gif":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn78@2020_4/2020/08/24/21-35-01-655_792c9650724a3ec1.webp","https://blog.huoding.com/wp-content/uploads/2020/06/false_positive.jpg":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn32@2020_1/2020/08/24/21-35-21-106_87c9ecf051179ffa.webp"},"publishedOrCreatedDate":1598304897607},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"记一次有惊无险的丢包调试经历","link":"https://blog.huoding.com/?p=814","description":"<p>某个项目把服务器从 CentOS 操作系统从 5 升级到了 7（3.10.0-693），一切都很顺利，直到我在服务器上闲逛的时候，无意间发现了一个「大问题」：网卡 eth0 在 RX 上存在丢包（dropped）现象，丢得还很有规律，每一两秒丢一个包！</p>\n<div id=\"attachment_815\" style=\"width: 1510px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/04/ifconfig.png\"><img aria-describedby=\"caption-attachment-815\" loading=\"lazy\" class=\"wp-image-815 size-full\" src=\"https://blog.huoding.com/wp-content/uploads/2020/04/ifconfig.png\" alt=\"watch -d -n1 'ifconfig'\" width=\"1500\" height=\"778\" /></a><p id=\"caption-attachment-815\" class=\"wp-caption-text\">watch -d -n1 &#8216;ifconfig&#8217;</p></div>\n<p><span id=\"more-814\"></span></p>\n<p>一开始怀疑是不是网卡的 ring buffer 太小了，通过「ethtool」确认：</p>\n<pre>shell&#62; ethtool -g eth0\nRing parameters for eth0:\nPre-set maximums:\nRX:\t\t256\nRX Mini:\t0\nRX Jumbo:\t0\nTX:\t\t256\nCurrent hardware settings:\nRX:\t\t256\nRX Mini:\t0\nRX Jumbo:\t0\nTX:\t\t256</pre>\n<p>看上去确实不大，可惜 Current hardware settings 已经达到 Pre-set maximums 最大值，没法加大了。为了确认网卡是否真的存在丢包，继续通过「ethtool」确认：</p>\n<pre>shell&#62; ethtool -S eth0\nno stats available\n\nshell&#62; ethtool -i eth0\ndriver: virtio_net\nversion: 1.0.0\nfirmware-version:\nexpansion-rom-version:\nbus-info: 0000:00:04.0\nsupports-statistics: no\nsupports-test: no\nsupports-eeprom-access: no\nsupports-register-dump: no\nsupports-priv-flags: no</pre>\n<p>看上去是 kvm 的 virtio_net 不支持 statistics，好在还有别的方法：</p>\n<pre>shell&#62; find /sys -name eth0\n/sys/devices/pci0000:00/0000:00:04.0/virtio1/net/eth0\n/sys/class/net/eth0\n\nshell&#62; cd /sys/devices/pci0000:00/0000:00:04.0/virtio1/net/eth0\nshell&#62; cd statistics\nshell&#62; grep . * | grep rx\nrx_bytes:633037730314\nrx_compressed:0\nrx_crc_errors:0\nrx_dropped:206975\nrx_errors:0\nrx_fifo_errors:0\nrx_frame_errors:0\nrx_length_errors:0\nrx_missed_errors:0\nrx_nohandler:0\nrx_over_errors:0\nrx_packets:4717658080</pre>\n<p>虽然 rx_dropped 不为零，但是 rx_errors 等却都为零，这说明 ring buffer 并没有出现溢出的情况，否则 rx_fifo_errors 之类的错误不可能为零，由此可以推断：网卡已经把数据完整交给了操作系统，其本身并没有丢包，真正丢包的是操作系统。</p>\n<p>如何判断操作系统在哪里丢包的呢？是时候表演真正的技术了，dropwatch 出场：</p>\n<pre>shell&#62; dropwatch -l kas\nInitalizing kallsyms db\n\ndropwatch&#62; start\nEnabling monitoring...\nKernel monitoring activated.\nIssue Ctrl-C to stop monitoring\n6 drops at ip_rcv+cf (0xffffffff815ca47f)\n11 drops at ipv6_rcv+3ad (0xffffffff81643d7d)\n75 drops at tcp_v4_rcv+87 (0xffffffff815f0197)\n426 drops at sk_stream_kill_queues+50 (0xffffffff8157a740)\n235 drops at tcp_rcv_state_process+1b0 (0xffffffff815e4fb0)\n137 drops at tcp_v4_rcv+87 (0xffffffff815f0197)\n11 drops at ipv6_rcv+3ad (0xffffffff81643d7d)\n1 drops at __netif_receive_skb_core+3d2 (0xffffffff81586d82)\n\nshell&#62; grep -w -A 10 __netif_receive_skb_core /proc/kallsyms\nffffffff815869b0 t __netif_receive_skb_core\nffffffff81587170 t __netif_receive_skb\nffffffff815871d0 t netif_receive_skb_internal\nffffffff81587290 T netif_receive_skb\nffffffff81587300 t napi_gro_complete\nffffffff81587400 T napi_gro_flush\nffffffff81587490 T napi_complete_done\nffffffff81587550 T napi_complete\nffffffff81587570 T sk_busy_loop\nffffffff81587830 t net_rx_action\nffffffff81587bb0 t dev_gro_receive</pre>\n<p>关于 dropwatch 的原理，它是通过监控 kfree_skb 的调用来监控操作系统可能的丢包行为，有的丢包可能是正常行为，有的丢包可能是异常行为。如此说来，我们遇到的丢包会是上面哪个函数引起的呢？是正常的还是异常的呢？运气不好的话，可能得一个一个挨个分析，好在我们运气不错，记得文章开头我们提到过，在我们的问题中，每一两秒丢一个包，于是自然而然的将目光锁定在 __netif_receive_skb_core 之上（丢包地址 0xffffffff81586d82 介于 ffffffff815869b0 和 ffffffff81587170 之间）。</p>\n<p>查询一下 <a href=\"https://elixir.bootlin.com/linux/v3.10/source\" target=\"_blank\" rel=\"noopener noreferrer\">Linux 源代码</a>中 __netif_receive_skb_core 函数的定义来确认一下丢包原因：</p>\n<pre>static int __netif_receive_skb_core(struct sk_buff *skb, bool pfmemalloc)\n{\n    ...\n\n    if (pfmemalloc &#38;&#38; !skb_pfmemalloc_protocol(skb))\n        goto drop;\n\n    ...\n\ndrop:\n    atomic_long_inc(&#38;skb-&#62;dev-&#62;rx_dropped);\n    kfree_skb(skb);\n    /* Jamal, now you will not able to escape explaining\n     * me how you were going to use this. :-)\n     */\n    ret = NET_RX_DROP;\n\n    ...\n}\n\nstatic bool skb_pfmemalloc_protocol(struct sk_buff *skb)\n{\n    switch (skb-&#62;protocol) {\n    case __constant_htons(ETH_P_ARP):\n    case __constant_htons(ETH_P_IP):\n    case __constant_htons(ETH_P_IPV6):\n    case __constant_htons(ETH_P_8021Q):\n    case __constant_htons(ETH_P_8021AD):\n        return true;\n    default:\n        return false;\n    }\n}</pre>\n<p>当 pfmemalloc 为真，且 skb_pfmemalloc_protocol 中判断不支持包协议的时候，就会丢包。此外，代码里能看到调用了 kfree_skb，侧面验证了 dropwatch 的工作原理。</p>\n<p>如何判断我们问题中丢的包协议是什么呢，是时候表演真正的技术了， systemtap 出场：</p>\n<pre>#! /usr/bin/env stap\n\nprobe kernel.function(\"__netif_receive_skb_core\").label(\"drop\") {\n    printf(\"0x%04X\\n\", ntohs($skb-&#62;protocol))\n}\n\n// output\n\n0x0004</pre>\n<p>顺便说一句，有了 systemtap，几乎可以为所欲为，比如<a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/systemtap_beginners_guide/useful-systemtap-scripts#dropwatchsect\" target=\"_blank\" rel=\"noopener noreferrer\">替换</a>前面提到的 dropwatch。</p>\n<p>从前面我们对 Linux 源代码的分析，skb_pfmemalloc_protocol 中支持的包 <a href=\"https://github.com/openbsd/src/blob/master/sys/net/ethertypes.h\" target=\"_blank\" rel=\"noopener noreferrer\">protocol</a> 如下：</p>\n<pre>#define ETH_P_ARP\t0x0806\t/* Address Resolution packet\t*/\n#define ETH_P_IP\t0x0800\t/* Internet Protocol packet\t*/\n#define ETH_P_IPV6\t0x86DD\t/* IPv6 over bluebook\t\t*/\n#define ETH_P_8021Q\t0x8100  /* 802.1Q VLAN Extended Header  */\n#define ETH_P_8021AD\t0x88A8  /* 802.1ad Service VLAN\t\t*/</pre>\n<p>而 systemtap 脚本检测到的包 protocol 为 0x0004，也就是路由器发出的 802.3 包：</p>\n<pre>#define\tETHERTYPE_8023\t0x0004\t/* IEEE 802.3 packet */</pre>\n<p>因为是系统不支持的包，所以被丢掉了。</p>\n<p>其实只要了解了问题的缘由，使用 tcpdump 也能抓出被系统丢掉的包，只要：打印出包的 ether type，然后过滤掉操作系统支持其协议的包，剩下的就是丢掉的包：</p>\n<pre>shell&#62; tcpdump -i eth0 -e | grep -v -E 'ARP|IP|802.1Q|802.1AD'\n802.3,\nlength 105: LLC,\ndsap STP (0x42) Individual,\nssap STP (0x42) Command,\nctrl 0x03: STP 802.1s,\nRapid STP,\nCIST Flags [Learn, Forward, Agreement],\nlength 102</pre>\n<p>需要说明得是，CentOS 新旧版本在处理此类问题的行为有所不同：面对不支持协议的包，虽然 CentOS 新旧版本都会丢掉它，但是旧版不会更新丢包计数器（rx_dropped），新版却会更新丢包计数器（rx_dropped），细节就不展开了，有兴趣的自行查阅。</p>\n","descriptionType":"html","publishedDate":"Mon, 27 Apr 2020 07:38:23 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/04/ifconfig.png","linkMd5":"24100b4bef3ab587303b04d734dac9f0","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn87@2020_1/2020/08/24/21-35-14-909_ffc042a3f8ab449a.webp","destWidth":1500,"destHeight":778,"sourceBytes":604156,"destBytes":88538,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/04/ifconfig.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn87@2020_1/2020/08/24/21-35-14-909_ffc042a3f8ab449a.webp"},"publishedOrCreatedDate":1598304897608},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"一个尾调用相关的诡异报错信息","link":"https://blog.huoding.com/?p=804","description":"<p>一个 OpenResty 的接口报错了，我查了一下日志，发现如下报错信息：</p>\n<blockquote><p>bad argument #1 to &#8216;test&#8217; (string expected, got userdata)</p></blockquote>\n<p>看上去这就是一道送分题啊：无非就是 test 函数的第一个参数类型应该是 string，实际传递的却是 userdata。就当我觉得可以轻而易举解决问题的时候，突然发现 test 函数定义就没有参数，调用的时候也没传参数，真是太诡异了。</p>\n<p><span id=\"more-804\"></span></p>\n<p>群里问了一些网友，结合自己瞎蒙，大概搞清楚了问题的来龙去脉，看看复现过程：</p>\n<pre>➜ cat t.lua\nlocal cjson = require \"cjson\"\nlocal function test()\n    return cjson.decode(ngx.null)\nend\ntest()\n➜ resty t.lua\nERROR: t.lua:5: bad argument #1 to 'test' (string expected, got userdata)\nstack traceback:\n\tt.lua:5: in function 'file_gen'\n\tinit_worker_by_lua:45: in function \n\t[C]: in function 'xpcall'\n\tinit_worker_by_lua:52: in function</pre>\n<p>看到这里，估计有人已经猜到原因了：问题似乎和尾调用（<a href=\"https://en.wikipedia.org/wiki/Tail_call\" target=\"_blank\" rel=\"noopener noreferrer\">Tall call</a>）相关，验证一下：</p>\n<pre>➜ cat t.lua\nlocal cjson = require \"cjson\"\nlocal function test()\n    local result = cjson.decode(ngx.null)\n    return result\nend\ntest()\n➜ resty t.lua\nERROR: t.lua:3: bad argument #1 to 'decode' (string expected, got userdata)\nstack traceback:\n\tt.lua:3: in function 'test'\n\tt.lua:6: in function 'file_gen'\n\tinit_worker_by_lua:45: in function \n\t[C]: in function 'xpcall'\n\tinit_worker_by_lua:52: in function</pre>\n<p>当我们去掉尾调用后，错误信息恢复了正常，验证了我们的猜测，诡异错误信息确实和尾调用相关。当然，真正的问题是因为我们在使用 cjson.decode 的时候传递了错误的参数，尾调用本身并没有问题，但是不得不说的是，它拐带的错误信息实在是坑人。</p>\n","descriptionType":"html","publishedDate":"Tue, 03 Mar 2020 11:32:53 +0000","feedId":3486,"bgimg":"","linkMd5":"09be32883a1a4bace1ed94650602dcda","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897610},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"如何在OpenResty里实现代码热更新","link":"https://blog.huoding.com/?p=807","description":"<p>所谓「代码热更新」，是指代码发生变化后，不用 reload 或者 graceful restart 进程就能生效。比如有一个聊天服务，连接着一百万个用户的长连接，所谓代码热更新就是在长连接不断的前提下完成代码更新。实际上因为所有的 require 操作都是通过 package.loaded 来加载模块的，只要代码是以 module 的形式组织的，那么就可以通过 package.loaded 实现代码热更新，并且基本不影响性能。</p>\n<p><span id=\"more-807\"></span></p>\n<p>下面让我们做个实验来说明一下如何实现代码热更新的，首先设置如下配置：</p>\n<pre>lua_code_cache on;\nworker_processes 1;\n\nlocation /run {\n    content_by_lua_block {\n        ngx.say(require(\"test\").run())\n    }\n}\n\nlocation /unload {\n    allow 127.0.0.1;\n    deny all;\n\n    content_by_lua_block {\n        package.loaded[ngx.var.arg_m] = nil\n    }\n}</pre>\n<p>需要说明的是，之所以把 worker_processes 设置为 1，是因为每个 worker 进程都有一个独立的 lua vm，设置成 1 更方便测试，稍后我会说明大于 1 的时候怎么办。此外，有两个 location，其中 run 是用来运行模块的，unload 的是用来卸载模块的。</p>\n<p>接着在 package.path 所包含的某个路径上创建 test 模块：</p>\n<pre>local _M = {}\n\nfunction _M.run()\n    return 1\nend\n\nreturn _M</pre>\n<p>逻辑很简单，就是返回一个数字。一切准备就绪后，reload 一下 ngx，让我们开始实验：</p>\n<ol>\n<li>请求 http://localhost/run，显示 1</li>\n<li>修改模块 test.lua，把 1 改成 100</li>\n<li>请求 http://localhost/unload?m=test，卸载 package.loaded 中的 test</li>\n<li>请求 http://localhost/run，显示 100</li>\n</ol>\n<p>由此可见，在模块内容被修改后，我们没有 reload 进程，只是通过卸载 package.loaded 中对应的模块，就实现了代码热更新。</p>\n<p>看起来实现代码热更新非常简单。打住！有例外，让我们修改一下 test 模块：</p>\n<pre>local ffi = require(\"ffi\")\n\nffi.cdef[[\nstruct test { int v; };\n]]\n\nlocal _M = {}\n\nfunction _M.run()\n    local test = ffi.new(\"struct test\", {1})\n\n    return test.v\nend\n\nreturn _M</pre>\n<p>还是打印一个数字，只是用 ffi 实现的，让我们再来重复一下实验步骤，结果报错了：</p>\n<blockquote><p>attempt to redefine &#8230;</p></blockquote>\n<p>究其原因，是因为当我们通过 package.loaded 卸载模块的时候，如果用到了 ffi.cdef 之类的 ffi 操作，那么其中的 C 语言类型声明是无法卸载的。</p>\n<p>好在我们可以通过条件判断来决定是否要执行 ffi.cdef 语句：</p>\n<pre>if not pcall(ffi.typeof, \"struct test\") then\n    ffi.cdef[[\n    struct test { int v; };\n    ]]\nend</pre>\n<p>说明：如果我们要修改原始定义的话，那么就只能 reload 了。好在这种情况不多。</p>\n<p>最后，让我来说一说多进程的问题，在测试过程中，我只使用了一个进程，并且通过一个特定的 location 来实现卸载 package.loaded 中指定模块的功能，但是在实际情况中， worker_processes 多半是大于 1 的，也就说有多个 worker 进程，此时，如果再使用特定 location 来操作的话，你是无法确定到底是操作在哪个 worker 上的。</p>\n<p>比较直观的解决方案是：</p>\n<div>\n<ol>\n<li>把需要动态加载的代码放在一个模块文件中，并标记版本号。</li>\n<li>暴露一个 location，允许从外部写最新的版本号到共享内存字典。</li>\n<li>通过 <a href=\"https://www.lua.org/manual/5.1/manual.html#pdf-package.loaders\" target=\"_blank\" rel=\"noopener noreferrer\">package.loaders</a> 实现自定义的 loader，把它插在 package.loaders 第二个位置上（因为缺省情况下第一个位置是为 <a href=\"https://www.lua.org/manual/5.1/manual.html#pdf-package.preload\" target=\"_blank\" rel=\"noopener noreferrer\">package.preload</a> 准备的，第二个位置是为 <a href=\"https://www.lua.org/manual/5.1/manual.html#pdf-package.path\" target=\"_blank\" rel=\"noopener noreferrer\">package.path</a> 准备的），这样在 require 的时候就可以按照自定义的逻辑加载模块：检查模块的版本号与共享内存字典中的最新版本号是否一致，如果不一致的话，则通过 loadstring 重新加载模块，并且缓存到 package.loaded 中去。</li>\n</ol>\n<p>如此可以解决问题，但是不爽的是每个请求都要检查版本号。看看另一个方案：</p>\n<ol>\n<li>在 init_worker 设置每个 worker 都通过 timer 定时扫描自己的共享内存队列。</li>\n<li>暴露一个 location，允许从外部写模块名字到每一个 worker 的共享内存队列。</li>\n<li>如果 timer 发现新数据，就说明有模块变化了，通过 package.loaded 卸载，再通过 require 重新加载模块，当然也可以自定义 loader，通过 loadstring 重新加载模块。</li>\n</ol>\n<p>补充：如果自定义 loader 的话，那么在通过 loadstring 加载模块的时候，不一定非要从本地磁盘加载模块，思维发散一下，可以通过读取远程数据来加载。比如说有一百台服务器需要更新代码，那么可以把新代码发送到某个 redis 上，然后所有服务器通过请求 redis 拿到新代码，并把 loadstring 缓存到 package.loaded 中去，如此避免了部署的麻烦。</p>\n</div>\n","descriptionType":"html","publishedDate":"Wed, 25 Mar 2020 07:26:31 +0000","feedId":3486,"bgimg":"","linkMd5":"f7a1896941eb2116d4cfb167a41d3efc","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897609},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"Golang代码修改后自动重启","link":"https://blog.huoding.com/?p=830","description":"<p>写 Golang 项目有两件很烦的事情：一件是错误处理时连绵不绝的「if err != nil」，另一件是作为编译型语言，代码修改后不能实时看到效果，</p>\n<p><span id=\"more-830\"></span></p>\n<p>借助一些工具可以实现文件修改后自动编译重启，比如：</p>\n<ul>\n<li>Linux 环境：<a href=\"https://github.com/inotify-tools/inotify-tools\" target=\"_blank\" rel=\"noopener noreferrer\">inotify-tools</a>（<a href=\"https://www.alexedwards.net/blog/golang-automatic-reloads\" target=\"_blank\" rel=\"noopener noreferrer\">Golang Automatic Reloads</a>）</li>\n<li>Mac 环境：<a href=\"https://github.com/emcrisostomo/fswatch\" target=\"_blank\" rel=\"noopener noreferrer\">fswatch</a></li>\n</ul>\n<p>不过常见的工具要么不跨平台，要么操作复杂，好在我发现了一个 facebook 出品的神器：<a href=\"https://facebook.github.io/watchman/\" target=\"_blank\" rel=\"noopener noreferrer\">watchman</a>，不仅跨平台，而且操作简单，你只要写个脚本对接上就行了，当项目代码改变时，它会自动调用你的脚本。</p>\n<ol>\n<li>watchman <a href=\"https://facebook.github.io/watchman/docs/cmd/watch.html\" target=\"_blank\" rel=\"noopener noreferrer\">watch</a> /path/to/your/project</li>\n<li>watchman &#8212; <a href=\"https://facebook.github.io/watchman/docs/cmd/trigger.html\" target=\"_blank\" rel=\"noopener noreferrer\">trigger</a> /path/to/your/project -p &#8216;\\.go$&#8217; &#8212; /path/to/your/script</li>\n</ol>\n<p>注意：如果遇到问题可以查日志「/usr/local/var/run/watchman/*-state/log」</p>\n<p>注意：如果你的编辑器有自动保存之类的功能，务必记得关闭它，比如 vscode：</p>\n<div id=\"attachment_831\" style=\"width: 1320px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/07/autosave.png\"><img aria-describedby=\"caption-attachment-831\" loading=\"lazy\" class=\"size-full wp-image-831\" src=\"https://blog.huoding.com/wp-content/uploads/2020/07/autosave.png\" alt=\"自动保存\" width=\"1310\" height=\"870\" /></a><p id=\"caption-attachment-831\" class=\"wp-caption-text\">自动保存</p></div>\n<p>除了 watch 之外，还有一些别的选择，比如 <a href=\"https://github.com/cosmtrek/air\" target=\"_blank\" rel=\"noopener noreferrer\">air</a> 也不错，留给大家自己研究吧。</p>\n","descriptionType":"html","publishedDate":"Fri, 31 Jul 2020 11:22:49 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/07/autosave.png","linkMd5":"28badefa58decb1d41814415a95e2a2f","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn68@2020_1/2020/08/24/21-35-05-999_8c1008a2839c441f.webp","destWidth":1310,"destHeight":870,"sourceBytes":164981,"destBytes":65726,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/07/autosave.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn68@2020_1/2020/08/24/21-35-05-999_8c1008a2839c441f.webp"},"publishedOrCreatedDate":1598304897593},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"如何查询同时包含多个指定标签的文章","link":"https://blog.huoding.com/?p=775","description":"<p>文章和标签是典型的多对多的关系，也就是说每一篇文章都可以包含多个标签，如图：</p>\n<div id=\"attachment_776\" style=\"width: 930px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2019/09/articles_tags.png\"><img aria-describedby=\"caption-attachment-776\" loading=\"lazy\" class=\"size-full wp-image-776\" src=\"https://blog.huoding.com/wp-content/uploads/2019/09/articles_tags.png\" alt=\"每一篇文章都可以包含多个标签\" width=\"920\" height=\"398\" /></a><p id=\"caption-attachment-776\" class=\"wp-caption-text\">每一篇文章都可以包含多个标签</p></div>\n<p>下面问题来了：如何查询 tag_id 同时包含 1、2、3 的 article_id？此问题看似简单，实际上也非常简单，本来是一道送分题，但是很多人却做不出来！</p>\n<p><span id=\"more-775\"></span></p>\n<h2>方法一：</h2>\n<pre>SELECT article_id FROM (\n    SELECT article_id, GROUP_CONCAT(tag_id ORDER BY tag_id) tag_ids\n    FROM articles_tags\n    WHERE article_id in (1, 2, 3)\n    GROUP BY article_id\n) t WHERE tag_ids LIKE '%1,2,3%';</pre>\n<p>说明：此方法利用 GROUP_CONCAT 来解决问题，不过鉴于 GROUP_CONAT 是 MySQL 专有函数，出于通用性的考虑，我们并不推荐使用此方法。</p>\n<h2>方法二：</h2>\n<pre>SELECT at1.article_id\nFROM articles_tags at1\nJOIN articles_tags at2 ON at1.article_id = at2.article_id AND at2.tag_id = 2\nJOIN articles_tags at3 ON at1.article_id = at3.article_id AND at3.tag_id = 3\nWHERE at1.tag_id = 1</pre>\n<h2>方法三：</h2>\n<pre>SELECT article_id\nFROM articles_tags\nWHERE tag_id in (1, 2, 3)\nGROUP BY article_id\nHAVING COUNT(*) = 3</pre>\n<p>关于一对多关系的查询问题，实际情况可能会更复杂一些，让我们扩展一下本题：</p>\n<ul>\n<li>如何查询 tag_id 包含 1、2 但不包含 3 的 article_id？</li>\n<li>如何查询 tag_id 包含 1、2、3 中至少两个的 article_id？</li>\n</ul>\n<p>如果你理解了前面介绍的几种方法，那么解决这些扩展问题并不困难，不要固守某一种方法，要根据情况选择合适的方法，篇幅所限，恕不赘述，留给大家自己解决吧。</p>\n","descriptionType":"html","publishedDate":"Sun, 22 Sep 2019 02:29:03 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2019/09/articles_tags.png","linkMd5":"d509612184349c809b7b972328232f43","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn79@2020_3/2020/08/24/21-35-03-684_0a4672c187edc7ab.webp","destWidth":920,"destHeight":398,"sourceBytes":80675,"destBytes":12222,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2019/09/articles_tags.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn79@2020_3/2020/08/24/21-35-03-684_0a4672c187edc7ab.webp"},"publishedOrCreatedDate":1598304897612},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"关于Cosocket的SocketBusy报错","link":"https://blog.huoding.com/?p=795","description":"<p>关于 OpenResty 的 <a href=\"https://github.com/openresty/lua-nginx-module#ngxsockettcp\" target=\"_blank\" rel=\"noopener noreferrer\">cosocket</a>，文档里有如下一段描述：</p>\n<blockquote><p>the cosocket object here is full-duplex, that is, a reader &#8220;light thread&#8221; and a writer &#8220;light thread&#8221; can operate on a single cosocket object simultaneously (both &#8220;light threads&#8221; must belong to the same Lua handler though, see reasons above). But you cannot have two &#8220;light threads&#8221; both reading (or writing or connecting) the same cosocket, otherwise you might get an error like &#8220;socket busy reading&#8221; when calling the methods of the cosocket object.</p></blockquote>\n<p>简单点儿说，cosocket 是全双工的，如果同一个 lua handler 有一个读线程和一个写线程的话，那么它们可以同时操作一个 cosocket 对象，但是如果两个线程一起读或者写一个 cosocket 对象的话，那么会触发「socket busy」错误。</p>\n<p><span id=\"more-795\"></span></p>\n<p>测试需要，我用「nc -l 1111」命令启动了一个 TCP 服务，监听 1111 端口，如果手头没有 linux 环境，不能使用 nc 命令的话，那么你随便用某个网址的 80 端口也是一样的。</p>\n<p>首先让我们编程复现一下「socket busy」错误，代码逻辑很简单，就是让两个线程对同一个 cosocket 一起发出写操作。通过 <a href=\"https://github.com/openresty/resty-cli\" target=\"_blank\" rel=\"noopener noreferrer\">resty</a> 运行如下代码：</p>\n<pre>local sock = ngx.socket.tcp()\nsock:connect(\"127.0.0.1\", 1111) -- shell: nc -l 1111\n\nlocal data = {}\n\nfor i = 1, 1024 do\n    data[i] = \"data\"\nend\n\ndata = table.concat(data) .. \"\\n\"\n\nlocal function test(worker)\n    for i = 1, 9999 do\n        ngx.log(ngx.ERR, worker, \": \", i)\n\n        local _, err = sock:send(data)\n        -- ngx.sleep(0)\n\n        if err then\n            ngx.log(ngx.ERR, worker, \": \", i, \" err: \", err)\n            break\n        end\n    end\nend\n\nlocal a = ngx.thread.spawn(test, \"a\")\nlocal b = ngx.thread.spawn(test, \"b\")\n\nngx.thread.wait(a, b)\n\nngx.thread.kill(a)\nngx.thread.kill(b)\n</pre>\n<p>结果如下，确实出现了错误「socket busy」：</p>\n<div id=\"attachment_797\" style=\"width: 1008px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/01/socket1.png\"><img aria-describedby=\"caption-attachment-797\" loading=\"lazy\" class=\"size-full wp-image-797\" src=\"https://blog.huoding.com/wp-content/uploads/2020/01/socket1.png\" alt=\"并发出错\" width=\"998\" height=\"518\" /></a><p id=\"caption-attachment-797\" class=\"wp-caption-text\">并发出错</p></div>\n<p>我在做实验的时候遇到了两个问题需要说明一下：</p>\n<ul>\n<li>问题一：测试数据（本例中 data 为 4k）最好大一点，否则可能无法复现错误。</li>\n<li>问题二：从结果看，线程 a 运行了几百次后，线程 b 才开始运行，也就是说线程 a 得到了 CPU 就不愿意撒手，此时可以通过 ngx.sleep(0) 主动交出 CPU 控制权。</li>\n</ul>\n<p>接下来看看如何解决「socket busy」错误，既然出现「socket busy」错误的原因是多线程一起读或者写同一个 cosocket 对象，那我们只要加一把锁让操作串行就行了，不过需要注意的是，这里不要通过 <a href=\"https://github.com/openresty/lua-resty-lock\" target=\"_blank\" rel=\"noopener noreferrer\">lua-resty-lock</a> 来加锁，而应该通过 <a href=\"https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/semaphore.md\" target=\"_blank\" rel=\"noopener noreferrer\">semaphore</a> 来加锁，这是因为 lua-resty-lock 的控制粒度比较粗，适合请求在多个 worker 时的情况，而 semaphore 的控制粒度比较细，适合请求在单个 worker 时的情况。通过 <a href=\"https://github.com/openresty/resty-cli\" target=\"_blank\" rel=\"noopener noreferrer\">resty</a> 运行如下代码：</p>\n<pre>local semaphore = require \"ngx.semaphore\"\nlocal sema = semaphore.new()\n\nlocal sock = ngx.socket.tcp()\nsock:connect(\"127.0.0.1\", 1111) -- shell: nc -l 1111\n\nlocal data = {}\n\nfor i = 1, 1024 do\n    data[i] = \"data\"\nend\n\ndata = table.concat(data) .. \"\\n\"\n\nlocal function test(worker)\n    for i = 1, 9999 do\n        ngx.log(ngx.ERR, worker, \": \", i)\n\n        local ok, _ = sema:wait(1)\n\n        if not ok then\n            break\n        end\n\n        local _, err = sock:send(data)\n        sema:post()\n\n        if err then\n            ngx.log(ngx.ERR, worker, \": \", i, \" err: \", err)\n            break\n        end\n    end\nend\n\nlocal a = ngx.thread.spawn(test, \"a\")\nlocal b = ngx.thread.spawn(test, \"b\")\n\nsema:post()\n\nngx.thread.wait(a, b)\n\nngx.thread.kill(a)\nngx.thread.kill(b)\n</pre>\n<p>结果如下，你会发现请求完全执行完了，整个过程中没有出错：</p>\n<div id=\"attachment_798\" style=\"width: 1010px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/01/socket2.png\"><img aria-describedby=\"caption-attachment-798\" loading=\"lazy\" class=\"size-full wp-image-798\" src=\"https://blog.huoding.com/wp-content/uploads/2020/01/socket2.png\" alt=\"并发未出错\" width=\"1000\" height=\"518\" /></a><p id=\"caption-attachment-798\" class=\"wp-caption-text\">并发未出错</p></div>\n<p>和前一个图相比较，你会发现本图中，线程 a 和线程 b 交错执行，不再需要通过 ngx.sleep(0) 来主动交出 CPU 控制权，这是因为 semo:wait 完成了类似的操作。</p>\n<p>以后使用 OpenResty 的时候，如果多个线程要同时读或者写同一个 cosocket 对象，那么切记要用 semaphore 控制一下，避免出现「socket busy」错误。当然了，最理想的情况是不用引入 semaphore，每个 cosocket 对象都有一个专门的读线程，一个专门的写线程，此时如果读线程需要写操作，可以考虑通过队列把写操作转给写线程去完成，如此一来既避免使用 semaphore，又充分发挥了全双工的效率，爽歪歪。</p>\n","descriptionType":"html","publishedDate":"Wed, 15 Jan 2020 06:06:40 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/01/socket1.png","linkMd5":"c7c3866d35ab3953e9b89f16537d6ebb","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn90@2020_2/2020/08/24/21-35-03-154_74aecf53a728c223.webp","destWidth":998,"destHeight":518,"sourceBytes":89491,"destBytes":33896,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/01/socket1.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn90@2020_2/2020/08/24/21-35-03-154_74aecf53a728c223.webp","https://blog.huoding.com/wp-content/uploads/2020/01/socket2.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn41@2020_1/2020/08/24/21-35-20-333_0de2f6c81094f1ac.webp"},"publishedOrCreatedDate":1598304897610},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"使用Fiddler把请求从HTTPS改成HTTP","link":"https://blog.huoding.com/?p=784","description":"<p>为什么我要把请求从 HTTPS 改成 HTTP？这是因为生产环境是 HTTPS 的，而测试环境却是 HTTP 的，我要在测试环境测试应用，所以需要把请求从 HTTPS 改成 HTTP。为什么我不在测试环境部署一套 HTTPS 证书？这是因为 HTTPS 证书属于敏感信息。</p>\n<p><span id=\"more-784\"></span></p>\n<p>最开始，我的想法是应用打包的时候打两个包，分别是正式包和测试包，正式包使用 HTTPS 来请求服务器，测试包使用 HTTP 来请求服务器。这个方法当然可以工作，不过实在是太蠢了！好在公司的测试兄弟告诉我可以用 Fiddler 来搞定这个问题：</p>\n<div id=\"attachment_785\" style=\"width: 1151px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2019/11/fiddler.jpg\"><img aria-describedby=\"caption-attachment-785\" loading=\"lazy\" class=\"size-full wp-image-785\" src=\"https://blog.huoding.com/wp-content/uploads/2019/11/fiddler.jpg\" alt=\"Fiddler\" width=\"1141\" height=\"352\" /></a><p id=\"caption-attachment-785\" class=\"wp-caption-text\">Fiddler</p></div>\n<p>也就是说，Fiddler 在这里就是一个「中间人」的角色，当客户端发送 HTTPS 请求 给服务器的时候，Fiddler 拦截到请求，将其解密后以 HTTP 的形式转发给服务器，然后再把服务器的响应加密成 HTTPS 返回给客户端。</p>\n<p>了解了原理之后，我们只要一小段 FiddlerScript 代码就能完成此功能：</p>\n<pre>if (oSession.isHTTPS &#38;&#38; oSession.HostnameIs(\"test.com\")) {\n    oSession.oRequest.headers.UriScheme = \"http\";\n}</pre>\n<p>添加的位置：在 FiddlerScript 标签里搜索 OnBeforeRequest 方法，加到最上面即可：</p>\n<div id=\"attachment_786\" style=\"width: 685px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2019/11/script.png\"><img aria-describedby=\"caption-attachment-786\" loading=\"lazy\" class=\"size-full wp-image-786\" src=\"https://blog.huoding.com/wp-content/uploads/2019/11/script.png\" alt=\"Script\" width=\"675\" height=\"550\" /></a><p id=\"caption-attachment-786\" class=\"wp-caption-text\">Script</p></div>\n<p>BTW：记得在 Options -&#62; HTTPS 里选中 Decrypt HTTPS traffic。</p>\n<p>本文好像太水了，<a href=\"https://libgen.is/\" target=\"_blank\" rel=\"noopener noreferrer\">LibGen</a> 上有一本名为「<a href=\"https://libgen.is/book/index.php?md5=C9396C3D8CE62D59969A75620B1EE2C2\" target=\"_blank\" rel=\"noopener noreferrer\">Debugging with Fiddler</a>」的电子书，完整介绍了 Fiddler 各种高大上的用法，有兴趣的不妨下载看看。</p>\n","descriptionType":"html","publishedDate":"Sat, 30 Nov 2019 08:03:32 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2019/11/fiddler.jpg","linkMd5":"a322a67d9e504f02b59fa821a6ed9225","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn82@2020_5/2020/08/24/21-35-01-830_564f438aae367427.webp","destWidth":1141,"destHeight":352,"sourceBytes":69336,"destBytes":48708,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2019/11/fiddler.jpg":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn82@2020_5/2020/08/24/21-35-01-830_564f438aae367427.webp","https://blog.huoding.com/wp-content/uploads/2019/11/script.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn46@2020_4/2020/08/24/21-35-17-653_6ebb29d3de5b76e3.webp"},"publishedOrCreatedDate":1598304897611},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"关于OpenResty里的ngx.on_abort","link":"https://blog.huoding.com/?p=812","description":"<p>关于 OpenResty 里的 <a href=\"https://github.com/openresty/lua-nginx-module#ngxon_abort\" target=\"_blank\" rel=\"noopener noreferrer\">ngx.on_abort</a>，官方文档里是这样说明的：</p>\n<blockquote><p>Registers a user Lua function as the callback which gets called automatically when the client closes the (downstream) connection prematurely.</p></blockquote>\n<p><span id=\"more-812\"></span></p>\n<p>也就是说：当客户端提前关闭连接的时候，在 ngx.on_abort 里注册的函数会被触发，下面做个实验看看，把如下代码加入 nginx.conf，并 reload 进程使其生效：</p>\n<pre>lua_check_client_abort on;\n\nlocation /test_http {\n    content_by_lua_block {\n        ngx.on_abort(function(a)\n            ngx.log(ngx.ERR, \"abort\")\n        end)\n\n        ngx.sleep(100)\n    }\n}</pre>\n<p>开启两个命令行窗口：一个 tail -f error.log，另一个 curl http://127.0.0.1/test_http。因为我在代码里设置了 sleep，所以 curl 无疑会卡住，通过执行 Ctrl+c 强行终止，以此构造出一个客户端提前关闭连接的场景，此时我们在 tail 窗口就能看到输出了 log，由此可知当客户端提前关闭连接的时候，在 http 的情况下， ngx.on_abort 里注册的函数会被触发。</p>\n<p>不过如果你仔细查看和 ngx.on_abort 相关的 lua_check_client_abort 的文档，会发现：</p>\n<blockquote><p>According to the current implementation, however, if the client closes the connection before the Lua code finishes reading the request body data via ngx.req.socket, then ngx_lua will neither stop all the running &#8220;light threads&#8221; nor call the user callback (if ngx.on_abort has been called). Instead, the reading operation on ngx.req.socket will just return the error message &#8220;client aborted&#8221; as the second return value (the first return value is surely nil).</p></blockquote>\n<p>也就是说，当客户端提前关闭连接的时候，如果 ngx.req.socket 中的数据没有被读取，那么 ngx.on_abort 里注册的函数不会被触发。实际上指的就是非 http 情况，也就是自己处理 socket 的情况，比如 websocket：</p>\n<pre>lua_check_client_abort on;\n\nlocation /test_websocket {\n    content_by_lua_block {\n        ngx.on_abort(function()\n            ngx.log(ngx.ERR, \"abort\")\n        end)\n\n        local server = require \"resty.websocket.server\"\n        local wb = server:new()\n\n        while true do\n            local data, typ, err = wb:recv_frame()\n\n            if wb.fatal then\n                ngx.log(ngx.ERR, err)\n                return ngx.exit(444)\n            end\n        end\n    }\n}</pre>\n<p>然后通过一个网页来调用如上的 websocket 服务：</p>\n<pre>&#60;script&#62;\nvar ws = new WebSocket('ws://127.0.0.1/websocket');\nws.send(\"test\");\n&#60;/script&#62;</pre>\n<p>与之前不同的是，因为我们要执行网页中的 javascript 代码，所以必须通过浏览器来执行 test_websocket 请求，而不是 curl，当请求发出后，会连接 websocket 发送一个字符串，直接关闭浏览器，以此构造出一个客户端提前关闭连接的场景，需要说明的是这里不用 sleep，因为已经连上 websocket 了，此时我们在 tail 窗口就能看到输出了 log，但是却不是 ngx.on_abort 的 log，而是 wb.fatal 的 log：</p>\n<blockquote><p>failed to receive the first 2 bytes: client aborted</p></blockquote>\n<p>由此可知当客户端提前关闭连接的时候，在 websocket 的情况下， ngx.on_abort 里注册的函数不会被触发。</p>\n<p>结论：通过 ngx.on_abort 检测客户端是否提前断开连接的方法，仅仅对 http 场景有效，对其它需要要手动处理 socket 数据的场景（比如 websocket）无效，对于此类场景，可以读取 socket 数据，通过报错信息来判断客户端是否提前关闭了连接，需要留意的是文档描述是错误信息等于「client aborted」表示客户端提前关闭了连接，但是 lua-resty-websocket 把这个报错信息<a href=\"https://github.com/openresty/lua-resty-websocket/blob/master/lib/resty/websocket/protocol.lua#L51\" target=\"_blank\" rel=\"noopener noreferrer\">重新加工</a>了一下，所以不能按等于判断，必须按包含判断，可见通过判断错误信息等于什么来判断错误类型的方式有点不靠谱，其实在 websocket 场景，如果要求不是特别严格的话，那么只要 fatal 为真就可以认为客户端已经断开了。</p>\n","descriptionType":"html","publishedDate":"Mon, 13 Apr 2020 06:24:38 +0000","feedId":3486,"bgimg":"","linkMd5":"aafb642420e4dba8dfcce92556c7f55e","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897609},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"如何扩展一个OpenResty模块","link":"https://blog.huoding.com/?p=801","description":"<p>因为 Lua 本身并没有继承之类的语法，所以我们不能通过 OOP 的套路来扩展模块，不过实际上对于 Lua 来说，扩展一个模块有更简单的方法，下面我们以 <a href=\"https://github.com/openresty/lua-resty-string\" target=\"_blank\" rel=\"noopener noreferrer\">lua-resty-string</a> 模块中的 <a href=\"https://github.com/openresty/lua-resty-string/blob/master/lib/resty/aes.lua\" target=\"_blank\" rel=\"noopener noreferrer\">aes</a> 加解密功能为例子来说明一下。</p> \n<p><span id=\"more-801\"></span></p> \n<p>在 aes 加解密的过程中，有一个「填充」的过程，相关技术细节可以参考我以前写的「<a href=\"https://blog.huoding.com/2019/05/06/739\" target=\"_blank\" rel=\"noopener noreferrer\">聊聊AES</a>」，当然，不懂也没关系，你只要知道目前的 resty.aes 不支持配置填充的功能即可，因为 OpenSSL 缺省是激活了填充的，所以一旦我们需要自定义填充方法，那么就需要关闭缺省的填充行为，此时 resty.aes 无能为力。</p> \n<p>通过查看 resty.aes 源代码，我们知道它是通过 ffi 调用 <a href=\"https://www.openssl.org/docs/man1.0.2/man3/\" target=\"_blank\" rel=\"noopener noreferrer\">OpenSSL</a> 来实现相关功能的，所以我们只需要依葫芦画瓢扩展 resty.aes 即可，不过最好不要修改 resty.aes 源代码，否则日后的升级会变得麻烦，推荐新建一个模块，比如本例中的 resty.aes_with_padding：</p> \n<pre>local aes = require \"resty.aes\"\nlocal ffi = require \"ffi\"\n\nlocal C = ffi.C\n\nffi.cdef[[\nint EVP_CIPHER_CTX_set_padding(EVP_CIPHER_CTX *ctx, int padding);\n]]\n\nfunction aes.set_padding(self, padding)\n    local encrypt_ctx, decrypt_ctx = self._encrypt_ctx, self._decrypt_ctx\n\n    if encrypt_ctx == nil or decrypt_ctx == nil then\n        return nil, \"not initialized\"\n    end\n\n    C.EVP_CIPHER_CTX_set_padding(encrypt_ctx, padding)\n    C.EVP_CIPHER_CTX_set_padding(decrypt_ctx, padding)\n\n    return 1\nend\n\nreturn aes\n</pre> \n<p>实际使用的时候，把原本调用 resty.aes 的地方改成 resty.aes_with_padding，然后代码里通过调用新创建的 set_padding 方法来控制开启还是关闭填充。</p> \n<p>如上可见，扩展一个 OpenResty 模块和把大象放冰箱一样简单，只需三步：首先创建一个新模块；接着引入要扩展的旧模块；最后直接在新模块中给旧模块添加新方法。</p>","descriptionType":"html","publishedDate":"Wed, 19 Feb 2020 06:07:18 +0000","feedId":3486,"bgimg":"","linkMd5":"0cd8fa040656798b57c24a1e7f118f84","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897610},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"OpenResty与模块","link":"https://blog.huoding.com/?p=779","description":"<p>Lua 中没有常见面向对象语言中所谓类的概念，取而代之使用模块来组织管理代码。关于模块的基础知识大家可以参考「<a href=\"https://moonbingbing.gitbooks.io/openresty-best-practices/lua/module.html\" target=\"_blank\" rel=\"noopener noreferrer\">OpenResty 最佳实战</a>」，本文聊点别的。</p>\n<p><span id=\"more-779\"></span></p>\n<p>如何实现一个模块呢？假设我们要实现一个不太安全的房奴模块（houseslave.lua）：</p>\n<pre>local _M = {}\n\n\nlocal mt = { __index = _M }\n\n\nfunction _M.new(me, bank)\n    local t = {\n        me = me,\n        bank = bank,\n    }\n\n    return setmetatable(t, mt)\nend\n\n\nfunction _M.repay(self, money)\n    self.me.money = self.me.money - money\n    self.bank.money = self.bank.money + money\nend\n\n\nreturn _M</pre>\n<p>如果我们借用类的思维来解释这段代码，那么大概意思就是：类的属性保存在表（t）中，类的方法保存在元表（mt）中，二者通过 <a href=\"https://moonbingbing.gitbooks.io/openresty-best-practices/lua/metatable.html\" target=\"_blank\" rel=\"noopener noreferrer\">setmetatable</a> 关联起来。</p>\n<p>实际使用的时候，大致如下所示：</p>\n<pre>local houseslave = require \"houseslave\"\nlocal hs = houseslave.new(me, bank)\nhs:repay(10000)</pre>\n<p>学习模块最好的方法就是多看别人是如何搞的，但也不能完全照搬，以很多人都很熟悉的 <a href=\"https://github.com/openresty/lua-resty-redis\" target=\"_blank\" rel=\"noopener noreferrer\">lua-resty-redis</a> 模块为例，如果通过 <a href=\"https://github.com/mpeterv/luacheck\" target=\"_blank\" rel=\"noopener noreferrer\">luacheck</a> 来检查的话，会发现很多问题，我们就以 new 方法的问题为例来说明一下，<a href=\"https://github.com/openresty/lua-resty-redis#new\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a>的描述如下：</p>\n<blockquote><p>red, err = redis:new()</p></blockquote>\n<p>通过冒号语法糖，self 参数被隐式传递了，但这不是重点，要紧的是 self 在这里有没有意义？实际上，new 相当于是类里的构造函数，在调用构造函数之前，还没有实例化出对象，此时 self 是多余的，应该去掉 new 参数中 self 的定义，当然调用方式也要改一下：</p>\n<blockquote><p>red, err = redis.new()</p></blockquote>\n<p>如果你没搞清楚，可以多看看前面房奴的例子，体会一下「点」和「冒号」的差异。</p>\n<p>OpenResty 通过 package.path 来查找模块，初学者往往不知道应该把自己写的模块放到哪个目录，此时可以通过 <a href=\"https://github.com/openresty/resty-cli\" target=\"_blank\" rel=\"noopener noreferrer\">resty-cli</a> 工具来确认你的 package.path 设置：</p>\n<div id=\"attachment_781\" style=\"width: 1034px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2019/10/package.path_.jpg\"><img aria-describedby=\"caption-attachment-781\" loading=\"lazy\" class=\"size-full wp-image-781\" src=\"https://blog.huoding.com/wp-content/uploads/2019/10/package.path_.jpg\" alt=\"package.path\" width=\"1024\" height=\"453\" /></a><p id=\"caption-attachment-781\" class=\"wp-caption-text\">package.path</p></div>\n<p>已经装载的模块保存在 package.loaded.* 中，于是我们可以通过 package.loaded.* = nil 的方式卸载对应的模块，如此一来就实现了<a href=\"https://moonbingbing.gitbooks.io/openresty-best-practices/ngx_lua/hot_load.html\" target=\"_blank\" rel=\"noopener noreferrer\">热装载代码</a>，同把大象放冰箱一样分三步：</p>\n<ol>\n<li>把需要动态加载的代码放在一个 Lua 模块文件 foo.lua 中，并标记版本号。</li>\n<li>暴露一个 location 以便从外部写最新的版本号到一个 ngx_lua 共享内存字典中。</li>\n<li>在 Lua 代码中，首先检查当前 foo 模块的版本号与共享内存字典中的最新版本号是否一致；如果不一致的话，则卸载当前的 foo 模块（package.loaded.foo = nil ），然后再调用 local foo = require &#8220;foo&#8221;，从而完成热装载代码。</li>\n</ol>\n<p>需要说明的是，使用了 LuaJIT FFI 的模块是不能通过清空 package.loaded 中的对应字段卸载的，好在多数时候，需要频繁热装载代码的模块往往是业务相关的模块，我们可以在设计之初，有意识的把 LuaJIT FFI 相关的代码单独剥离出来。</p>\n<p>好了，赶在十月底最后一天完成了本月的文章，虽然没什么营养，但习惯不能丢。</p>\n","descriptionType":"html","publishedDate":"Thu, 31 Oct 2019 11:59:27 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2019/10/package.path_.jpg","linkMd5":"cc0174142122cf2cffc934c85fa1b5f9","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn84@2020_5/2020/08/24/21-35-03-899_ce31ccad4bed050c.webp","destWidth":1024,"destHeight":453,"sourceBytes":104479,"destBytes":60698,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2019/10/package.path_.jpg":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn84@2020_5/2020/08/24/21-35-03-899_ce31ccad4bed050c.webp"},"publishedOrCreatedDate":1598304897612},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"数据库ID生成器基准测试","link":"https://blog.huoding.com/?p=768","description":"<p>在说明如何基准测试之前，我想聊聊我为什么要做这个事儿，话说最近做某后台的时候需要一个 ID 生成器，我不太想用 snowflake 等复杂的解决方案，也不太想用 redis 来实现，因为我手头只有 mysql，所以我琢磨着就用 mysql 实现吧。</p>\n<p><span id=\"more-768\"></span></p>\n<p>实际上当初 <a href=\"https://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/\" target=\"_blank\" rel=\"noopener noreferrer\">flickr</a> 就是这么干的，利用 <a href=\"https://dev.mysql.com/doc/refman/8.0/en/information-functions.html#function_last-insert-id\" target=\"_blank\" rel=\"noopener noreferrer\">LAST_INSERT_ID</a> 返回最新插入的 id：</p>\n<pre>mysql&#62; CREATE TABLE `Tickets64` (\n  `id` bigint(20) unsigned NOT NULL auto_increment,\n  `stub` char(1) NOT NULL default '',\n  PRIMARY KEY  (`id`),\n  UNIQUE KEY `stub` (`stub`)\n) ENGINE=MyISAM;\n\nmysql&#62; REPLACE INTO Tickets64 (stub) VALUES ('a');\nmysql&#62; SELECT LAST_INSERT_ID();</pre>\n<p>不过我没有直接拷贝此方案，因为看上去它至少有两个可以优化的地方：</p>\n<ol>\n<li>因为一张表只能有一个自增字段，所以一个表只能做一个独立的 id 生成器。</li>\n<li>REPLACE 实际上相当于先 DELETE 再 INSERT，也就是两步操作。</li>\n</ol>\n<p>按照文档描述 LAST_INSERT_ID 支持表达式参数，如此说来我们可以通过它来自行维护 id，从而去掉对 auto_increment 的依赖，进而不再需要 REPLACE，直接 UPDATE 即可：</p>\n<pre>mysql&#62; CREATE TABLE `seq` (\n  `id` bigint(20) unsigned NOT NULL DEFAULT '0',\n  `name` varchar(255) NOT NULL DEFAULT '',\n  UNIQUE KEY `name` (`name`)\n) ENGINE=InnoDB;\n\nmysql&#62; INSERT INTO seq (id, name) VALUES (0, 'global');\nmysql&#62; INSERT INTO seq (id, name) VALUES (0, 'another');\n\nmysql&#62; UPDATE seq SET id = LAST_INSERT_ID(id+1) WHERE name = 'global';\nmysql&#62; SELECT LAST_INSERT_ID();</pre>\n<p>确定了解决方案，我琢磨着得 Benchmark 看看这条 SQL 语句的性能怎么样，其实 MySQL 本身有一个 <a href=\"https://dev.mysql.com/doc/refman/5.5/en/information-functions.html#function_benchmark\" target=\"_blank\" rel=\"noopener noreferrer\">Benchmark</a> 函数，但是它只能用来测试 SELECT 这样的读操作 SQL，不能用来测试 UPDATE，REPLACE 这样的写操作 SQL，于是我到处找 SQL 性能测试工具，结果发现虽然有 <a href=\"https://dev.mysql.com/doc/refman/8.0/en/mysqlslap.html\" target=\"_blank\" rel=\"noopener noreferrer\">mysqlslap</a>、<a href=\"https://github.com/Percona-Lab/tpcc-mysql\" target=\"_blank\" rel=\"noopener noreferrer\">tpcc-mysql</a> 之类的重量级测试工具，但是却不符合我的需求：我只想要一个能压力测试一条 SQL 的小工具！</p>\n<p>既然没有现成的，那么我们不妨自己实现一个：</p>\n<pre>package main\n\nimport (\n\t\"database/sql\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/viper\"\n\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\nvar db *sql.DB\nvar number, concurrency int\n\nvar cmd = &#38;cobra.Command{\n\tUse:   \"benchmark sql\",\n\tShort: \"a sql benchmark tool\",\n\tArgs: func(cmd *cobra.Command, args []string) error {\n\t\tif len(args) != 1 {\n\t\t\tcmd.Usage()\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\treturn nil\n\t},\n\tRun: func(cmd *cobra.Command, args []string) {\n\t\tb := benchmark{\n\t\t\tsql:         args[0],\n\t\t\tnumber:      number,\n\t\t\tconcurrency: concurrency,\n\t\t}\n\n\t\tb.run()\n\t},\n}\n\nfunc init() {\n\tcobra.OnInitialize(config)\n\n\tcmd.Flags().IntVarP(&#38;number, \"number\", \"n\", 100, \"number\")\n\tcmd.Flags().IntVarP(&#38;concurrency, \"concurrency\", \"c\", 1, \"concurrency\")\n\tcmd.Flags().SortFlags = false\n}\n\nfunc config() {\n\tviper.AddConfigPath(\".\")\n\tviper.SetConfigName(\"db\")\n\tviper.SetConfigType(\"toml\")\n\n\terr := viper.ReadInConfig()\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdriver := viper.GetString(\"driver\")\n\tdsn := viper.GetString(\"dsn\")\n\n\tdb, err = sql.Open(driver, dsn)\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc main() {\n\tif err := cmd.Execute(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\ntype benchmark struct {\n\tsql         string\n\tnumber      int\n\tconcurrency int\n\tduration    chan time.Duration\n\tstart       time.Time\n\tend         time.Time\n}\n\nfunc (b *benchmark) run() {\n\tb.duration = make(chan time.Duration, b.number)\n\tb.start = time.Now()\n\tb.runWorkers()\n\tb.end = time.Now()\n\n\tb.report()\n}\n\nfunc (b *benchmark) runWorkers() {\n\tvar wg sync.WaitGroup\n\n\twg.Add(b.concurrency)\n\n\tfor i := 0; i &#60; b.concurrency; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tb.runWorker(b.number / b.concurrency)\n\t\t}()\n\t}\n\n\twg.Wait()\n\tclose(b.duration)\n}\n\nfunc (b *benchmark) runWorker(num int) {\n\tfor i := 0; i &#60; num; i++ {\n\t\tstart := time.Now()\n\t\tb.request()\n\t\tend := time.Now()\n\n\t\tb.duration &#60;- end.Sub(start)\n\t}\n}\n\nfunc (b *benchmark) request() {\n\tif _, err := db.Exec(b.sql); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc (b *benchmark) report() {\n\tsum := 0.0\n\tnum := float64(len(b.duration))\n\n\tfor duration := range b.duration {\n\t\tsum += duration.Seconds()\n\t}\n\n\tqps := int(num / b.end.Sub(b.start).Seconds())\n\ttpq := sum / num * 1000\n\n\tfmt.Printf(\"qps: %d [#/sec]\\n\", qps)\n\tfmt.Printf(\"tpq: %.3f [ms]\\n\", tpq)\n}\n</pre>\n<p>代码是用 Golang 写的，运行前记得在命令同级目录编辑好数据库配置文件 db.toml：</p>\n<pre>driver = \"mysql\"\ndsn = \"&#60;username&#62;:&#60;passwrod&#62;@&#60;protocol&#62;(&#60;host&#62;:&#60;port&#62;)/&#60;database&#62;\"</pre>\n<p>下面让我们看看原始方案和我们改进的方案有什么不同：</p>\n<pre>shell&#62; /path/to/benchmark -n 100000 -c 10 \"\n    REPLACE INTO Tickets64 (stub) VALUES ('a')\n\"\nshell&#62; /path/to/benchmark -n 100000 -c 10 \"\n    UPDATE seq SET id = LAST_INSERT_ID(id+1) WHERE name = 'global'\n\"</pre>\n<p>结果令人大吃一惊，所谓的改进方案比原始方案慢得多！仔细对比两个方案的表结构，发现原始方案数据引擎使用的是 MyISAM，而改进方案使用的是 InnoDB，于是我把数据引擎统一改成 MyISAM，重新测试，性能终于上来了，不过两者性能差异并不大，甚至 REPLACE 的性能还要比 UPDATE 好一点，具体原因我没有深究，就留给读者去探索吧。</p>\n<p>虽然有一些小问题悬而未决，好在搞出一个压测 SQL 的小工具，也算是有所得吧。</p>\n","descriptionType":"html","publishedDate":"Wed, 21 Aug 2019 02:30:38 +0000","feedId":3486,"bgimg":"","linkMd5":"6b8f91c8de5990d2f3b1241eb1b0abf9","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897613},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"为什么「0.1+0.2!=0.3」，而「0.1+0.3==0.4」","link":"https://blog.huoding.com/?p=769","description":"<p>我们都知道潮汐现象，上学的时候老师多半简单解释一句「月球引力所致」就算了，而我们也都觉得自己明白了，但是凡事就怕琢磨：如果涨潮仅仅是月球对地球万有引力的作用结果的话，那么每天同一个地点，应该仅仅在距离月球最近引力最强的时候有一次涨潮才对，但是住在海边的人都知道，同一个地点，每天会有两次涨潮，<a href=\"https://book.douban.com/review/6653141/\" target=\"_blank\" rel=\"noopener noreferrer\">为什么</a>？</p>\n<p>我抛出这个问题并不是我转行搞物理学了，而是我发现很多司空见惯的问题，如果深究的话，你就会发现很多人根本就没搞懂。浮点数运算就是这样一个问题，每个人都知道浮点数运算有精度损失，但是为什么「0.1+0.2!=0.3」，而「0.1+0.3==0.4」：</p>\n<div id=\"attachment_770\" style=\"width: 1330px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2019/08/float.png\"><img aria-describedby=\"caption-attachment-770\" loading=\"lazy\" class=\"size-full wp-image-770\" src=\"https://blog.huoding.com/wp-content/uploads/2019/08/float.png\" alt=\"\" width=\"1320\" height=\"500\" /></a><p id=\"caption-attachment-770\" class=\"wp-caption-text\">float</p></div>\n<p>除了含含糊糊的精度损失，你能给出更有营养的解释么？让我们看看到底是为什么！</p>\n<p><span id=\"more-769\"></span></p>\n<p>首先，让我们举一个整数的例子，比如：</p>\n<ul>\n<li>十进制「13」：1*(10^1) + 3(10^0) = 10 + 3 = 13</li>\n<li>二进制「1101」：1*(2^3) + 1*(2^2) + 0*(2^1) + 1*(2^0) = 8 + 4 + 0 + 1 = 13</li>\n</ul>\n<p>接着，让我们再举一个小数的例子，比如：</p>\n<ul>\n<li>十进制「0.625」：6*(10^-1) + 2*(10^-2) + 5*(10^-3) = 0.625</li>\n<li>二进制「0.101」：1*(2^-1) + 0*(2^-2) + 1*(2^-3) = 5/8 = 0.625</li>\n</ul>\n<p>最重要的一点是你要明白计算机是如何表示小数的：比如二进制的「0.1111111」，无非就是十进制的「1/2 + 1/4 + 1/8 + 1/16 + 1/32 + 1/64 + 1/128」，不过细心的你可能已经发现问题了，计算机这种处理小数的方式存在精度损失的，比如一个十进制的「0.1」，换算成分数的话就是十进制的「1/10」，对比前面的结果，你会发现计算机没办法精确表示它，只能近似等于二进制的「0.00011」，也就是十进制的「1/16 + 1/32 = 3/32」，当然二进制小数点后可以多取几位，可惜结果是只能无限趋近，但永远不可能等于。</p>\n<p>下面看看为什么「0.1 + 0.2 != 0.3」，而「0.1 + 0.3 == 0.4」。既然存在精度损失，那么「0.1 + 0.2 != 0.3」也说得过去，我们推算一下为什么「0.1 + 0.3 == 0.4」：</p>\n<ul>\n<li>十进制的「0.1」近似等于二进制「0.00011」</li>\n<li>十进制的「0.3」近似等于二进制「0.01001」</li>\n<li>十进制的「0.4」近似等于二进制「0.01100」</li>\n</ul>\n<p>于是，十进制的「0.1 + 0.3」也就是二进制的「0.00011 + 0.01001」：</p>\n<pre>  0.00011\n+ 0.01001\n---------\n  0.01100</pre>\n<p>不多不少，答案正好是 0.4！也就是说，虽然有精度损失，但是刚刚好碰巧抵消了彼此的误差。希望大家阅读完本文之后，能够彻底搞清楚浮点数运算的相关问题，如果还有不清楚的地方，推荐阅读：<a href=\"https://zh.wikipedia.org/wiki/IEEE_754\" target=\"_blank\" rel=\"noopener noreferrer\">IEEE 754</a> 和 <a href=\"https://floating-point-gui.de/\" target=\"_blank\" rel=\"noopener noreferrer\">THE FLOATING-POINT GUIDE</a>。</p>\n","descriptionType":"html","publishedDate":"Fri, 23 Aug 2019 07:44:28 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2019/08/float.png","linkMd5":"449fd40cbd504f87be0ef1a694cdb8ea","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn72@2020_6/2020/08/24/21-35-01-018_f3109d064e7051a3.webp","destWidth":1320,"destHeight":500,"sourceBytes":47647,"destBytes":17318,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2019/08/float.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn72@2020_6/2020/08/24/21-35-01-018_f3109d064e7051a3.webp"},"publishedOrCreatedDate":1598304897613},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"我的Golang热重载工具Air不好使了","link":"https://blog.huoding.com/?p=843","description":"<p>我使用 VSCode Remote-Containters 作为 golang 开发环境，因为生产环境使用的镜像主要是 alpine，所以开发环境自然而然使用了 golang:alpine，对应 Dockerfile 的内容如下：</p>\n<pre>FROM golang:alpine\nRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.cloud.tencent.com/g' /etc/apk/repositories\nRUN apk add alpine-sdk\nRUN go env -w GOPROXY=https://goproxy.cn,direct\nRUN go get github.com/cosmtrek/air\n</pre>\n<p>如上所示，出于众所周知的原因，我设置了 GOPROXY，并且安装了一个名为 <a href=\"https://github.com/cosmtrek/air\" target=\"_blank\" rel=\"noopener noreferrer\">air</a> 的工具，熟悉 golang 的朋友都知道，它是用来实现热重载的，本来一切都正常，结果突然报错：「Setctty set but Ctty not valid in child」：</p>\n<div id=\"attachment_844\" style=\"width: 1670px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/08/air.png\"><img aria-describedby=\"caption-attachment-844\" loading=\"lazy\" class=\"size-full wp-image-844\" src=\"https://blog.huoding.com/wp-content/uploads/2020/08/air.png\" alt=\"air\" width=\"1660\" height=\"718\" data-wp-editing=\"1\" /></a><p id=\"caption-attachment-844\" class=\"wp-caption-text\">air</p></div>\n<p>在 air 的 <a href=\"https://github.com/cosmtrek/air/issues\" target=\"_blank\" rel=\"noopener noreferrer\">issue</a> 里没找到对应的报告，不过在 golang 的 <a href=\"https://github.com/golang/go/issues/29458\" target=\"_blank\" rel=\"noopener noreferrer\">issue</a> 里倒是发现了一些线索：</p>\n<blockquote><p>If tty is going to be open in the child process, then it must have a file descriptor in the child process. When using os/exec.Cmd as the creack/pty code does, tty must be in Stdin or Stdout or Stderr or ExtraFiles. If it isn&#8217;t in any of those, then it will be closed when the child process runs. If it is in one of those, that gives you the file descriptor number that you should use in Ctty.</p>\n<p><span style=\"font-family: 'Helvetica Neue', Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-style: normal;\">Right now the creack code is setting Ctty to the parent&#8217;s file descriptor number. That is working (assuming that it is working) by accident. The correct fix is to ensure that tty is passed to the child somewhere, and set Ctty to the appropriate descriptor number. If it is possible for all of Stdin, Stdout, Stderr to be set, the simplest approach would be to always add tty to ExtraFiles, and set Ctty to 3. That will work for old versions of Go and also for the upcoming 1.15 release.</span></p></blockquote>\n<p>我只想让 air 正常工作，并不想深究工作原理，好在里面提到了 <a href=\"https://github.com/creack/pty\" target=\"_blank\" rel=\"noopener noreferrer\">creack/pty</a>，而 air 正好<a href=\"https://github.com/cosmtrek/air/blob/master/go.mod\" target=\"_blank\" rel=\"noopener noreferrer\">依赖</a>它，于是顺藤摸瓜找到了对应的 <a href=\"https://github.com/creack/pty/issues/96\" target=\"_blank\" rel=\"noopener noreferrer\">issue</a>，发现此问题是新版 golang 1.15 才出现的，并且已经<a href=\"https://github.com/creack/pty/releases/tag/v1.1.10\" target=\"_blank\" rel=\"noopener noreferrer\">修复</a>了，可惜 air 没有升级 pty 版本，于是遇到新版 golang 后，问题就出来了。</p>\n<p>恰好前几天 Golang 放出来 1.15 的正式版，因为我在 Dockerfile 里使用 golang:alpine 作为标签，并没有明确版本，相当于是 latest，也就是最新版 1.15，所以触发了问题。知道了问题的缘由后，解决方法就简单了，两种方法：</p>\n<ul>\n<li>改用 golang:1.14-alpine3.12 这种有版本的标签绕开问题版本。</li>\n<li>使用 go get 命令的时候，应该尽可能加上 -u 选项，以便能自动升级版本。</li>\n</ul>\n<p>最好的方式莫过于继续使用新版 golang 1.15，同时给 go get 加上 -u 选项：</p>\n<pre>FROM golang:1.15-alpine3.12\nRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.cloud.tencent.com/g' /etc/apk/repositories\nRUN apk add alpine-sdk\nRUN go env -w GOPROXY=https://goproxy.cn,direct\nRUN go get -u github.com/cosmtrek/air\n</pre>\n<p>不过当我们这么干的时候，发现我安装的 air 依然有问题，为了验证问题，我在一个干净的容器里手动安装，结果搞出一个匪夷所思的 v1.21.2 的版本来：</p>\n<pre>shell&#62; go get -u github.com/cosmtrek/air\ngo: github.com/cosmtrek/air upgrade =&#62; v1.21.2</pre>\n<p>我在官网上根本查不到这个版本，直觉告诉我可能和 GOPROXY 有关，于是禁用后再执行，发现一切都正常了，好在 <a href=\"https://goproxy.cn/\" target=\"_blank\" rel=\"noopener noreferrer\">goproxy.cn</a> 支持查询各个版本的下载量，于是我就<a href=\"https://goproxy.cn/stats/github.com/cosmtrek/air@v1.21.2\" target=\"_blank\" rel=\"noopener noreferrer\">查询</a>了一下 v1.21.2 这个匪夷所思的版本，结果发现从 2020-08-07 开始一直有数据：</p>\n<div id=\"attachment_846\" style=\"width: 1110px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/08/goproxy.png\"><img aria-describedby=\"caption-attachment-846\" loading=\"lazy\" class=\"size-full wp-image-846\" src=\"https://blog.huoding.com/wp-content/uploads/2020/08/goproxy.png\" alt=\"goproxy\" width=\"1100\" height=\"698\" /></a><p id=\"caption-attachment-846\" class=\"wp-caption-text\">goproxy</p></div>\n<p>如此看来，问题的来龙去脉大概是这样的：2020-08-07 之前的某天，官方在升级打包的时候搞错了标签（v1.21.2），尽管很快删掉了，但是却被 goproxy.cn 给缓存了下来，之后发布的版本（v.1.12.X）虽然名义上是新版本，但是由于数字上都小于问题版本，结果导致是用 goproxy.cn 的用户在 go get 安装的时候加 -u 选项也得不到新版本。</p>\n<p>让各个代理都删除错误版本显然并不现实，毕竟除了 <a href=\"https://goproxy.io/zh/\" target=\"_blank\" rel=\"noopener noreferrer\">goproxy.cn</a> 还有 <a href=\"https://goproxy.io/\" target=\"_blank\" rel=\"noopener noreferrer\">goproxy.io</a> 等很多代理都可能有问题，其实只要重新发布一个保证大于 v1.21.2 的新版本（比如 v1.21.3）就可以了，在此之前，我们可以通过「go get -u github.com/cosmtrek/air@v1.12.4」这样的方式来固定主版本并升级依赖版本的权宜之计来缓解问题。</p>\n","descriptionType":"html","publishedDate":"Sun, 23 Aug 2020 08:28:40 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/08/air.png","linkMd5":"6cb8a91733709b2f79fce7ca95fc36b9","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn75@2020_5/2020/08/24/21-35-13-480_e0c7d5ca1a743522.webp","destWidth":1660,"destHeight":718,"sourceBytes":370065,"destBytes":47816,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/08/air.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn75@2020_5/2020/08/24/21-35-13-480_e0c7d5ca1a743522.webp","https://blog.huoding.com/wp-content/uploads/2020/08/goproxy.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn38@2020_2/2020/08/24/21-35-19-475_c2cc57ffc8f8711a.webp"},"publishedOrCreatedDate":1598304897592},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"记录Viper加载远程配置填坑过程","link":"https://blog.huoding.com/?p=832","description":"<p>关于 <a href=\"https://github.com/spf13/viper\" target=\"_blank\" rel=\"noopener noreferrer\">viper</a>，无须多言，它是 Golang 社区里最流行的配置文件工具，除了常见功能之外，它还支持很多高级功能，比如可以加载远程配置，正好我最近在研究 <a href=\"https://etcd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">etcd</a>，于是我打算把二者结合起来，没想到就此开启了填坑之旅。</p>\n<p><span id=\"more-832\"></span></p>\n<p>按照<a href=\"https://github.com/spf13/viper#watching-changes-in-etcd---unencrypted\" target=\"_blank\" rel=\"noopener noreferrer\">文档</a>上的介绍，只需启动一个 goroutine 执行 <a href=\"https://github.com/spf13/viper/search?q=WatchRemoteConfig&#38;type=Code\" target=\"_blank\" rel=\"noopener noreferrer\">WatchRemoteConfig</a> 即可：</p>\n<div id=\"attachment_833\" style=\"width: 1530px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/08/watch.png\"><img aria-describedby=\"caption-attachment-833\" loading=\"lazy\" class=\"size-full wp-image-833\" src=\"https://blog.huoding.com/wp-content/uploads/2020/08/watch.png\" alt=\"Watching Changes in etcd\" width=\"1520\" height=\"1300\" /></a><p id=\"caption-attachment-833\" class=\"wp-caption-text\">Watching Changes in etcd</p></div>\n<p>可惜当我套用如上代码时，却发现在我的环境里根本没法用。究其原因，是因为 viper 依赖 <a href=\"https://github.com/bketelsen/crypt\" target=\"_blank\" rel=\"noopener noreferrer\">crypt</a>，而 crypt 截至目前还<a href=\"https://github.com/bketelsen/crypt/issues/6\" target=\"_blank\" rel=\"noopener noreferrer\">不支持</a>新版 etcd 的 api。</p>\n<p>viper 使用 crypt 做什么呢？在文档中可以找到如下描述：</p>\n<blockquote><p>Viper uses crypt to retrieve configuration from the K/V store, which means that you can store your configuration values encrypted and have them automatically decrypted if you have the correct gpg keyring. Encryption is optional.</p></blockquote>\n<p>也就是说，KV 中可以存储加密的数据，viper 在获取的时候通过 crypt 自动解密。虽然此功能的出发点很好，但是在绝大多数场景下，etcd 中的数据通过 acl + tls 来保护就足够了，并不需要存储加密数据。此外，别的不说，如果真的都存储加密数据，那么至少我们想通过 <a href=\"https://github.com/evildecay/etcdkeeper\" target=\"_blank\" rel=\"noopener noreferrer\">etcdkeeper</a> 之类的工具修改 etcd 数据就不容易了。</p>\n<p>于是我琢磨着有没有变通的方法，当我在查阅<a href=\"https://github.com/spf13/viper/blob/master/remote/remote.go\" target=\"_blank\" rel=\"noopener noreferrer\">原始代码</a>的时候，发现一个奇怪的问题：</p>\n<div id=\"attachment_834\" style=\"width: 1308px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/08/remote.png\"><img aria-describedby=\"caption-attachment-834\" loading=\"lazy\" class=\"size-full wp-image-834\" src=\"https://blog.huoding.com/wp-content/uploads/2020/08/remote.png\" alt=\"\" width=\"1298\" height=\"998\" /></a><p id=\"caption-attachment-834\" class=\"wp-caption-text\">remote</p></div>\n<p>如上所示：Get 和 Watch 两个操作几乎一摸一样，内部都是调用后端的 Get 方法来获取数据。此时回头看看开头关于 WatchRemoteConfig 的例子的话，你会发现虽然语意上是想通过 Watch 监控，但是后端实际上执行的却是 Get，所谓的 Watch 监控其实是通过 Get 轮询实现的！官方代码为什么要这么干呢？当我 <a href=\"https://github.com/spf13/viper/commits/master/remote/remote.go\" target=\"_blank\" rel=\"noopener noreferrer\">blame</a> 后终于发现了<a href=\"https://github.com/spf13/viper/pull/313\" target=\"_blank\" rel=\"noopener noreferrer\">原因</a>：</p>\n<p>原本 Get 和 Watch 两个操作是各自独立的，当在 for 循环里调用 WatchRemoteConfig 的时候，实际上就相当于在 for 循环里调用后端 <a href=\"https://github.com/bketelsen/crypt/blob/master/backend/etcd/etcd.go\" target=\"_blank\" rel=\"noopener noreferrer\">Watch</a>，偏偏 crypt 的 Watch 实现在每次调用的时候都会生成一个新的 goroutine，并且无法退出，于是乎 goroutine 的数量就失控了，因为问题出在 crypt 身上，viper 无法根治，为了掩盖此问题，不得不把 Watch 改成了 Get，并引入一个 <a href=\"https://github.com/spf13/viper/search?q=WatchRemoteConfigOnChannel&#38;type=Code\" target=\"_blank\" rel=\"noopener noreferrer\">WatchRemoteConfigOnChannel</a> 方法来实现更完善的监控。</p>\n<p>了解了前因后果之后，我决定跳过 crypt，自己实现加载远程配置的功能，其实就是实现 viper 中的 remoteConfigFactory 接口：</p>\n<pre>type remoteConfigFactory interface {\n\tGet(rp RemoteProvider) (io.Reader, error)\n\tWatch(rp RemoteProvider) (io.Reader, error)\n\tWatchChannel(rp RemoteProvider) (&#60;-chan *RemoteResponse, chan bool)\n}</pre>\n<p>代码如下所示，参考了原始 <a href=\"https://github.com/spf13/viper/blob/master/remote/remote.go\" target=\"_blank\" rel=\"noopener noreferrer\">remote.go</a> 的实现方式：</p>\n<pre>package remote\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"io\"\n\t\"time\"\n\n\t\"github.com/spf13/viper\"\n\t\"go.etcd.io/etcd/clientv3\"\n)\n\ntype Config struct {\n\tviper.RemoteProvider\n\n\tUsername string\n\tPassword string\n}\n\nfunc (c *Config) Get(rp viper.RemoteProvider) (io.Reader, error) {\n\tc.RemoteProvider = rp\n\n\treturn c.get()\n}\n\nfunc (c *Config) Watch(rp viper.RemoteProvider) (io.Reader, error) {\n\tc.RemoteProvider = rp\n\n\treturn c.get()\n}\n\nfunc (c *Config) WatchChannel(rp viper.RemoteProvider) (&#60;-chan *viper.RemoteResponse, chan bool) {\n\tc.RemoteProvider = rp\n\n\trr := make(chan *viper.RemoteResponse)\n\tstop := make(chan bool)\n\n\tgo func() {\n\t\tfor {\n\t\t\tclient, err := c.newClient()\n\n\t\t\tif err != nil {\n\t\t\t\ttime.Sleep(time.Duration(time.Second))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdefer client.Close()\n\n\t\t\tch := client.Watch(context.Background(), c.RemoteProvider.Path())\n\n\t\t\tselect {\n\t\t\tcase &#60;-stop:\n\t\t\t\treturn\n\t\t\tcase res := &#60;-ch:\n\t\t\t\tfor _, event := range res.Events {\n\t\t\t\t\trr &#60;- &#38;viper.RemoteResponse{\n\t\t\t\t\t\tValue: event.Kv.Value,\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn rr, stop\n}\n\nfunc (c *Config) newClient() (*clientv3.Client, error) {\n\tclient, err := clientv3.New(clientv3.Config{\n\t\tEndpoints: []string{c.Endpoint()},\n\t\tUsername:  c.Username,\n\t\tPassword:  c.Password,\n\t})\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn client, nil\n}\n\nfunc (c *Config) get() (io.Reader, error) {\n\tclient, err := c.newClient()\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdefer client.Close()\n\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tresp, err := client.Get(ctx, c.Path())\n\tcancel()\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn bytes.NewReader(resp.Kvs[0].Value), nil\n}\n</pre>\n<p>实际调用代码和以前类似，只需额外触发一下 WatchRemoteConfigOnChannel 即可：</p>\n<pre>func main() {\n\tendpoint := \"http://127.0.0.1:2379\"\n\tpath := \"/config/test\"\n\n\tviper.RemoteConfig = &#38;remote.Config{}\n\n\tv := viper.New()\n\tv.AddRemoteProvider(\"etcd\", endpoint, path)\n\tv.SetConfigType(\"toml\")\n\tv.ReadRemoteConfig()\n\tv.WatchRemoteConfigOnChannel()\n\n\thttp.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprint(w, v.GetString(\"service.password\"))\n\t})\n\n\thttp.ListenAndServe(\":8080\", nil)\n}</pre>\n<p>最后再次强烈推荐通过 etcdkeeper 作为 etcd 的 web 前端工具，真好看真方便：</p>\n<div id=\"attachment_836\" style=\"width: 1348px\" class=\"wp-caption alignnone\"><a href=\"https://blog.huoding.com/wp-content/uploads/2020/08/etcdkeeper.png\"><img aria-describedby=\"caption-attachment-836\" loading=\"lazy\" class=\"size-full wp-image-836\" src=\"https://blog.huoding.com/wp-content/uploads/2020/08/etcdkeeper.png\" alt=\"etcdkeeper\" width=\"1338\" height=\"1000\" /></a><p id=\"caption-attachment-836\" class=\"wp-caption-text\">etcdkeeper</p></div>\n<p>一切就绪后，你可以试着修改 etcd 里的数据，甚至重启 etcd 服务后再修改 etcd 里的数据，你会惊喜的发现应用代码无需轮询就能实时感知到数据变化，完美！</p>\n","descriptionType":"html","publishedDate":"Mon, 10 Aug 2020 09:13:44 +0000","feedId":3486,"bgimg":"https://blog.huoding.com/wp-content/uploads/2020/08/watch.png","linkMd5":"0dcc6bf3facc84cb69ab018b02c163d9","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn73@2020_6/2020/08/24/21-35-10-636_1f674c50bb8d78bd.webp","destWidth":1520,"destHeight":1300,"sourceBytes":262953,"destBytes":104546,"author":"老王","articleImgCdnMap":{"https://blog.huoding.com/wp-content/uploads/2020/08/watch.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn73@2020_6/2020/08/24/21-35-10-636_1f674c50bb8d78bd.webp","https://blog.huoding.com/wp-content/uploads/2020/08/remote.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn33@2020_6/2020/08/24/21-35-22-571_c99ba236cca387f4.webp","https://blog.huoding.com/wp-content/uploads/2020/08/etcdkeeper.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn40@2020_6/2020/08/24/21-35-19-838_db254d32e92bd837.webp"},"publishedOrCreatedDate":1598304897593},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"被忽视的time命令","link":"https://blog.huoding.com/?p=788","description":"<p>如果要选 Linux 下最容易被忽视的命令，time 应该算一个。简单来说，它是一个用来计算命令运行时间的工具，之所以说它容易被忽视，一方面很多人根本不知道 time 的存在，而是习惯在命令启动前后记录两个时间戳，然后手动计算命令运行时间；另一方面很多人虽然知道 time 的存在，但是却并没有真正理解它的含义。</p>\n<p><span id=\"more-788\"></span></p>\n<p>下面让我们通过若干例子来理解 time 的真正含义：</p>\n<pre>shell&#62; time ls\n\nreal\t0m0.003s\nuser\t0m0.001s\nsys\t0m0.002s</pre>\n<p>大概意思是 ls 命令运行花了 0.003 秒，其中用户态花了 0.001 秒，内核态花了 0.002 秒，看上去似乎「real = user + sys」？此等式是否成立，在回答这个问题之前我们不妨看看 real、user、sys 的确切含义，如下定义源自 <a href=\"https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1\" target=\"_blank\" rel=\"noopener noreferrer\">Stackoverflow</a>：</p>\n<ul>\n<li>\n<div>\n<div>Real is wall clock time &#8211; time from start to finish of the call. This is all elapsed time including time slices used by other processes and time the process spends blocked (for example if it is waiting for I/O to complete).</div>\n</div>\n</li>\n<li>User is the amount of CPU time spent in user-mode code (outside the kernel) within the process. This is only actual CPU time used in executing the process. Other processes and time the process spends blocked do not count towards this figure.</li>\n<li>Sys is the amount of CPU time spent in the kernel within the process. This means executing CPU time spent in system calls within the kernel, as opposed to library code, which is still running in user-space. Like &#8216;user&#8217;, this is only CPU time used by the process.</li>\n</ul>\n<p>总的来说，real 是我们直观感受到的消耗的时间，如果命令运行时被堵塞了，那么堵塞时间也是被统计在内的， user 统计在用户态态模式下消耗的 CPU 时间，如果命令运行时被堵塞了，那么堵塞时间并不被统计在内，sys 统计在内核态模式下消耗的 CPU 时间，如果命令运行时被堵塞了，那么堵塞时间并不被统计在内。</p>\n<p>看上去是否统计堵塞时间是区分 real 和 user、sys 的关键，看看下面这个 sleep 例子：</p>\n<pre>shell&#62; time sleep 1\n\nreal\t0m1.002s\nuser\t0m0.001s\nsys\t0m0.001s</pre>\n<p>那么除了堵塞时间，还有别的关键点么，让我们再看看下面两个例子：</p>\n<pre>shell&#62; time find /etc -type f | xargs -n1 -I{} cat {} &#62; /dev/null\n\nreal\t0m2.050s\nuser\t0m0.626s\nsys\t0m1.533s\n\nshell&#62; time find /etc -type f | xargs -n1 -I{} -P2 cat {} &#62; /dev/null\n\nreal\t0m1.079s\nuser\t0m0.681s\nsys\t0m1.486s\n</pre>\n<p>前后两个例子的区别在于后者在使用 xargs 的时候通过「-P」选项激活了多进程，换句话说，后者可以同时用到多个 CPU。</p>\n<p>了解了相关知识之后，我们通过 real、user、sys 的大小就可以判断程序的行为：</p>\n<ul>\n<li>如果 real 远远大于 user + sys，那么说明程序可能有严重的堵塞问题。</li>\n<li>如果 real 基本等于 user + sys，那么说明程序可能没有用到多 CPU 能力，</li>\n<li>如果 real 远远小于 user + sys，那么说明程序可能用到了多 CPU 能力。</li>\n</ul>\n<p>怎么样？看似简单的 time 命令，是不是远比你想的要复杂得多！</p>\n","descriptionType":"html","publishedDate":"Sun, 08 Dec 2019 03:57:36 +0000","feedId":3486,"bgimg":"","linkMd5":"e693af0dc0132367ba18323db954d1a5","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897611},{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","title":"如何使用PHP解析XML大文件","link":"https://blog.huoding.com/?p=790","description":"<p>如果使用 PHP 解析 XML 的话，那么常见的选择有如下几种：<a href=\"https://www.php.net/manual/en/book.dom.php\" target=\"_blank\" rel=\"noopener noreferrer\">DOM</a>、<a href=\"https://www.php.net/manual/en/book.simplexml.php\" target=\"_blank\" rel=\"noopener noreferrer\">SimpleXML</a>、<a href=\"https://www.php.net/manual/en/book.xmlreader.php\" target=\"_blank\" rel=\"noopener noreferrer\">XMLReader</a>。如果要解析 XML 大文件的话，那么首先要排除的是 DOM，因为使用 DOM 的话，需要把整个文件全部加载才能解析，效率堪忧，相比较而言，SimpleXML 和 XMLReader 更好些，SimpleXML 相对简单，而 XMLReader 相对复杂，但是它可以自定义解析整个过程，特别是流式解析的特点让其效率更高。</p>\n<p><span id=\"more-790\"></span></p>\n<p>下面我以一个 XML 大文件例子来对比一下 SimpleXML 和 XMLReader 的用法：</p>\n<pre>&#60;certificates&#62;\n  ...\n  &#60;certificate&#62;\n    &#60;domain&#62;...&#60;/domain&#62;\n    &#60;id_status&#62;...&#60;/id_status&#62;\n    &#60;official_site_status&#62;...&#60;/official_site_status&#62;\n    &#60;business_status&#62;...&#60;/business_status&#62;\n    &#60;host&#62;...&#60;/host&#62;\n    &#60;auth_level&#62;...&#60;/auth_level&#62;\n    &#60;sitename&#62;...&#60;/sitename&#62;\n    &#60;sitetype&#62;...&#60;/sitetype&#62;\n    &#60;phone&#62;...&#60;/phone&#62;\n    &#60;auth_num&#62;...&#60;/auth_num&#62;\n    &#60;nickname0&#62;...&#60;/nickname0&#62;\n    &#60;icp&#62;...&#60;/icp&#62;\n    &#60;is_certed&#62;...&#60;/is_certed&#62;\n    &#60;is_official&#62;...&#60;/is_official&#62;\n    &#60;existed_years&#62;...&#60;/existed_years&#62;\n    &#60;addr&#62;...&#60;/addr&#62;\n    &#60;type&#62;...&#60;/type&#62;\n  &#60;/certificate&#62;\n  ...\n&#60;certificates&#62;\n</pre>\n<p>先看看用 SimpleXML 的话怎么搞：</p>\n<pre>&#60;?php\n\n$values = simplexml_load_file('file.xml');\n\nforeach ($values as $value) {\n    var_dump($value);\n}\n\n?&#62;</pre>\n<p>在看看用 XMLReader 的话怎么搞：</p>\n<pre>&#60;?php\n\n$xml = new XMLReader();\n$xml-&#62;open('file.xml');\n\nfor ($name = null, $value = []; $xml-&#62;read(); null) {\n    if ($xml-&#62;nodeType == XMLReader::ELEMENT) {\n        $name = $xml-&#62;name;\n\n        if ($name == 'certificate') {\n            if ($value) {\n                var_dump($value);\n            }\n\n            $value = [];\n            continue;\n        }\n    }\n\n    if ($xml-&#62;nodeType == XMLReader::TEXT) {\n        if ($name) {\n            $value[$name] = $xml-&#62;value;\n        }\n    }\n}\n\n?&#62;</pre>\n<p>在本例中，XML 文件有几百万行，XMLReader 的效率是 SimpleXML 的两倍左右。</p>\n<p>了解了相关知识，让我们看看如何选择合适的 XML 解析方法：如果规则比较复杂的话， 比如要查询当前节点的上下文，那么 DOM 是合理的选择；如果 XML 体积比较大的话，那么 XMLReader 是效率更高。不过如果没有特殊需求的话，那么尽量选择 SimpleXML，毕竟它用起来更简单。</p>\n","descriptionType":"html","publishedDate":"Sun, 05 Jan 2020 04:23:25 +0000","feedId":3486,"bgimg":"","linkMd5":"57afdf36ba7db080115f7a1fd7580bf1","bgimgJsdelivr":"","metaImg":"","author":"老王","publishedOrCreatedDate":1598304897611}],"record":{"createdTime":"2020-08-25 05:34:57","updatedTime":"2020-08-25 05:34:57","feedId":3486,"fetchDate":"Mon, 24 Aug 2020 21:34:57 +0000","fetchMs":2585,"handleMs":3168,"totalMs":32419,"newArticles":0,"totalArticles":20,"status":1,"type":0,"ip":"34.233.8.4","hostName":"us-017.herokuapp.com","requestId":"3777cfe9daa14ed4941dd265972ad48c_3486","contentType":"application/rss+xml; charset=UTF-8","totalBytes":950048,"bgimgsTotal":11,"bgimgsGithubTotal":11,"articlesImgsTotal":18,"articlesImgsGithubTotal":18,"successGithubMap":{"myreaderx14":1,"myreaderx8":2,"myreaderx15":2,"myreaderx6":2,"myreaderx32":1,"myreaderx21":2,"myreaderx33":1,"myreaderx24":2,"myreaderx1":2,"myreaderx30":1,"myreaderx5oss":2},"failGithubMap":{}},"feed":{"createdTime":"2020-08-25 04:29:26","updatedTime":"2020-08-25 04:29:26","id":3486,"name":"火丁笔记","url":"http://huoding.com/feed","subscriber":null,"website":null,"icon":"https://blog.huoding.com/favicon.ico","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx62/cdn14@2020_6/2020/08/24/21-34-56-794_06b87c40543d862c.ico","description":"多研究些问题，少谈些主义。","weekly":null,"link":"https://blog.huoding.com"},"noPictureArticleList":[],"tmpCommonImgCdnBytes":520202,"tmpBodyImgCdnBytes":429846,"tmpBgImgCdnBytes":0,"extra4":{"start":1598304891419,"total":0,"statList":[{"spend":3026,"msg":"获取xml内容"},{"spend":3168,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":1,"msg":"修正封面图上传失败重新上传"},{"spend":7780,"msg":"正文链接上传到cdn"}]},"extra5":18,"extra6":18,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{"https://blog.huoding.com/?p=801_/2019/05/06/739":"https://blog.huoding.com/2019/05/06/739"},"extra111_proxyServerAndStatMap":{"http://us-032.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-037.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-033.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-035.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2019/08/float.png","sourceStatusCode":200,"destWidth":1320,"destHeight":500,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn72@2020_6/2020/08/24/21-35-01-018_f3109d064e7051a3.webp","sourceBytes":47647,"destBytes":17318,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":4357,"convertSpendMs":31,"createdTime":"2020-08-25 05:34:57","host":"us-011*","referer":"https://blog.huoding.com/?p=769","linkMd5ListStr":"449fd40cbd504f87be0ef1a694cdb8ea,449fd40cbd504f87be0ef1a694cdb8ea","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"46.5 KB","destSize":"16.9 KB","compressRate":"36.3%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/06/bloom.gif","sourceStatusCode":200,"destWidth":480,"destHeight":240,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn78@2020_4/2020/08/24/21-35-01-655_792c9650724a3ec1.webp","sourceBytes":29974,"destBytes":13366,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":4847,"convertSpendMs":157,"createdTime":"2020-08-25 05:34:57","host":"us-014*","referer":"https://blog.huoding.com/?p=825","linkMd5ListStr":"0834b92ebcd3a159c7593b6f36c3f536,0834b92ebcd3a159c7593b6f36c3f536","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.3 KB","destSize":"13.1 KB","compressRate":"44.6%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2019/11/fiddler.jpg","sourceStatusCode":200,"destWidth":1141,"destHeight":352,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn82@2020_5/2020/08/24/21-35-01-830_564f438aae367427.webp","sourceBytes":69336,"destBytes":48708,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":5043,"convertSpendMs":20,"createdTime":"2020-08-25 05:34:57","host":"us-016*","referer":"https://blog.huoding.com/?p=784","linkMd5ListStr":"a322a67d9e504f02b59fa821a6ed9225,a322a67d9e504f02b59fa821a6ed9225","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"67.7 KB","destSize":"47.6 KB","compressRate":"70.2%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/01/socket1.png","sourceStatusCode":200,"destWidth":998,"destHeight":518,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn90@2020_2/2020/08/24/21-35-03-154_74aecf53a728c223.webp","sourceBytes":89491,"destBytes":33896,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":6294,"convertSpendMs":67,"createdTime":"2020-08-25 05:34:57","host":"us-021*","referer":"https://blog.huoding.com/?p=795","linkMd5ListStr":"c7c3866d35ab3953e9b89f16537d6ebb,c7c3866d35ab3953e9b89f16537d6ebb","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"87.4 KB","destSize":"33.1 KB","compressRate":"37.9%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2019/09/articles_tags.png","sourceStatusCode":200,"destWidth":920,"destHeight":398,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn79@2020_3/2020/08/24/21-35-03-684_0a4672c187edc7ab.webp","sourceBytes":80675,"destBytes":12222,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":6782,"convertSpendMs":16,"createdTime":"2020-08-25 05:34:57","host":"us-015*","referer":"https://blog.huoding.com/?p=775","linkMd5ListStr":"d509612184349c809b7b972328232f43,d509612184349c809b7b972328232f43","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"78.8 KB","destSize":"11.9 KB","compressRate":"15.1%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/05/netstat.png","sourceStatusCode":200,"destWidth":1200,"destHeight":400,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn85@2020_3/2020/08/24/21-35-03-859_6696b1bfc6c94a92.webp","sourceBytes":60006,"destBytes":27368,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":6987,"convertSpendMs":42,"createdTime":"2020-08-25 05:34:57","host":"us-019*","referer":"https://blog.huoding.com/?p=816","linkMd5ListStr":"c4e28733e1901cf7ef9b8996747d0bbc,c4e28733e1901cf7ef9b8996747d0bbc","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"58.6 KB","destSize":"26.7 KB","compressRate":"45.6%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2019/10/package.path_.jpg","sourceStatusCode":200,"destWidth":1024,"destHeight":453,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn84@2020_5/2020/08/24/21-35-03-899_ce31ccad4bed050c.webp","sourceBytes":104479,"destBytes":60698,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":7250,"convertSpendMs":35,"createdTime":"2020-08-25 05:34:57","host":"us-018*","referer":"https://blog.huoding.com/?p=779","linkMd5ListStr":"cc0174142122cf2cffc934c85fa1b5f9,cc0174142122cf2cffc934c85fa1b5f9","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"102 KB","destSize":"59.3 KB","compressRate":"58.1%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/07/autosave.png","sourceStatusCode":200,"destWidth":1310,"destHeight":870,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn68@2020_1/2020/08/24/21-35-05-999_8c1008a2839c441f.webp","sourceBytes":164981,"destBytes":65726,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":9336,"convertSpendMs":62,"createdTime":"2020-08-25 05:34:57","host":"us-012*","referer":"https://blog.huoding.com/?p=830","linkMd5ListStr":"28badefa58decb1d41814415a95e2a2f,28badefa58decb1d41814415a95e2a2f","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"161.1 KB","destSize":"64.2 KB","compressRate":"39.8%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/08/watch.png","sourceStatusCode":200,"destWidth":1520,"destHeight":1300,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn73@2020_6/2020/08/24/21-35-10-636_1f674c50bb8d78bd.webp","sourceBytes":262953,"destBytes":104546,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":13919,"convertSpendMs":87,"createdTime":"2020-08-25 05:34:57","host":"us-012*","referer":"https://blog.huoding.com/?p=832","linkMd5ListStr":"0dcc6bf3facc84cb69ab018b02c163d9,0dcc6bf3facc84cb69ab018b02c163d9","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"256.8 KB","destSize":"102.1 KB","compressRate":"39.8%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/08/air.png","sourceStatusCode":200,"destWidth":1660,"destHeight":718,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn75@2020_5/2020/08/24/21-35-13-480_e0c7d5ca1a743522.webp","sourceBytes":370065,"destBytes":47816,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":16783,"convertSpendMs":50,"createdTime":"2020-08-25 05:34:57","host":"us-013*","referer":"https://blog.huoding.com/?p=843","linkMd5ListStr":"6cb8a91733709b2f79fce7ca95fc36b9,6cb8a91733709b2f79fce7ca95fc36b9","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"361.4 KB","destSize":"46.7 KB","compressRate":"12.9%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/04/ifconfig.png","sourceStatusCode":200,"destWidth":1500,"destHeight":778,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn87@2020_1/2020/08/24/21-35-14-909_ffc042a3f8ab449a.webp","sourceBytes":604156,"destBytes":88538,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":18383,"convertSpendMs":220,"createdTime":"2020-08-25 05:34:57","host":"us-020*","referer":"https://blog.huoding.com/?p=814","linkMd5ListStr":"24100b4bef3ab587303b04d734dac9f0,24100b4bef3ab587303b04d734dac9f0","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"590 KB","destSize":"86.5 KB","compressRate":"14.7%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2019/11/script.png","sourceStatusCode":200,"destWidth":675,"destHeight":550,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn46@2020_4/2020/08/24/21-35-17-653_6ebb29d3de5b76e3.webp","sourceBytes":42816,"destBytes":63260,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":2525,"convertSpendMs":21,"createdTime":"2020-08-25 05:35:16","host":"us-037*","referer":"https://blog.huoding.com/?p=784","linkMd5ListStr":"a322a67d9e504f02b59fa821a6ed9225","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.8 KB","destSize":"61.8 KB","compressRate":"147.7%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/08/goproxy.png","sourceStatusCode":200,"destWidth":1100,"destHeight":698,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn38@2020_2/2020/08/24/21-35-19-475_c2cc57ffc8f8711a.webp","sourceBytes":100347,"destBytes":38974,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":4203,"convertSpendMs":30,"createdTime":"2020-08-25 05:35:16","host":"us-033*","referer":"https://blog.huoding.com/?p=843","linkMd5ListStr":"6cb8a91733709b2f79fce7ca95fc36b9","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"98 KB","destSize":"38.1 KB","compressRate":"38.8%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/08/etcdkeeper.png","sourceStatusCode":200,"destWidth":1338,"destHeight":1000,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn40@2020_6/2020/08/24/21-35-19-838_db254d32e92bd837.webp","sourceBytes":95594,"destBytes":28360,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":4593,"convertSpendMs":45,"createdTime":"2020-08-25 05:35:16","host":"us-034*","referer":"https://blog.huoding.com/?p=832","linkMd5ListStr":"0dcc6bf3facc84cb69ab018b02c163d9","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"93.4 KB","destSize":"27.7 KB","compressRate":"29.7%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/01/socket2.png","sourceStatusCode":200,"destWidth":1000,"destHeight":518,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn41@2020_1/2020/08/24/21-35-20-333_0de2f6c81094f1ac.webp","sourceBytes":88035,"destBytes":37848,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":5100,"convertSpendMs":52,"createdTime":"2020-08-25 05:35:16","host":"us-035*","referer":"https://blog.huoding.com/?p=795","linkMd5ListStr":"c7c3866d35ab3953e9b89f16537d6ebb","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"86 KB","destSize":"37 KB","compressRate":"43%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/06/false_positive.jpg","sourceStatusCode":200,"destWidth":909,"destHeight":726,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn32@2020_1/2020/08/24/21-35-21-106_87c9ecf051179ffa.webp","sourceBytes":96699,"destBytes":62646,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":5890,"convertSpendMs":24,"createdTime":"2020-08-25 05:35:16","host":"us-032*","referer":"https://blog.huoding.com/?p=825","linkMd5ListStr":"0834b92ebcd3a159c7593b6f36c3f536","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"94.4 KB","destSize":"61.2 KB","compressRate":"64.8%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/08/remote.png","sourceStatusCode":200,"destWidth":1298,"destHeight":998,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn33@2020_6/2020/08/24/21-35-22-571_c99ba236cca387f4.webp","sourceBytes":131677,"destBytes":50054,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":7400,"convertSpendMs":88,"createdTime":"2020-08-25 05:35:16","host":"us-032*","referer":"https://blog.huoding.com/?p=832","linkMd5ListStr":"0dcc6bf3facc84cb69ab018b02c163d9","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"128.6 KB","destSize":"48.9 KB","compressRate":"38%"},{"code":1,"isDone":false,"source":"https://blog.huoding.com/wp-content/uploads/2020/05/rst.png","sourceStatusCode":200,"destWidth":1900,"destHeight":820,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn43@2020_5/2020/08/24/21-35-22-763_67a2c7b1fd7135df.webp","sourceBytes":229011,"destBytes":148704,"targetWebpQuality":75,"feedId":3486,"totalSpendMs":7737,"convertSpendMs":107,"createdTime":"2020-08-25 05:35:16","host":"us-036*","referer":"https://blog.huoding.com/?p=816","linkMd5ListStr":"c4e28733e1901cf7ef9b8996747d0bbc","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"223.6 KB","destSize":"145.2 KB","compressRate":"64.9%"}],"successGithubMap":{"myreaderx14":1,"myreaderx8":2,"myreaderx15":2,"myreaderx6":2,"myreaderx32":1,"myreaderx21":2,"myreaderx33":1,"myreaderx24":2,"myreaderx1":2,"myreaderx30":1,"myreaderx5oss":2},"failGithubMap":{}}