{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-11-16 17:03:23","updatedTime":"2020-11-16 17:03:23","title":"More Cool FFmpeg Tricks","link":"https://www.opensourceforu.com/?p=46368","description":"<div> \n <a href=\"https://www.opensourceforu.com/2020/11/more-cool-ffmpeg-tricks/\"><img title=\"FFmpeg-featured-image_Sept-2020\" src=\"https://i2.wp.com/www.opensourceforu.com/wp-content/uploads/2020/10/FFmpeg-featured-image_Sept-2020.jpg?fit=1024%2C576&amp;ssl=1\" alt=\"FFMG video editing\" width=\"1024\" height=\"576\" /></a> \n</div> \n<p><em>These new FFmpeg tricks fill up some gaps in an article carried on this subject in OSFY in 2016.</em></p> \n<p>This is a follow-up to the article ‘Cool FFmpeg Tricks’ (<em> 2016/05/cool-ffmpeg-tricks/</em>) I wrote for the readers of OSFY in 2016. Early this year, I found that the number of FFmpeg-related options in my Nautilus context menu had increased so much that there was enough material to write another FFmpeg article.</p> \n<figure id=\"attachment_46371\" aria-describedby=\"caption-attachment-46371\" style=\"width: 415px\" class=\"wp-caption aligncenter\">\n <figcaption id=\"caption-attachment-46371\" class=\"wp-caption-text\">\n  Figure 1: Use shell scripts to automate FFmpeg tasks\n </figcaption>\n</figure> \n<p>Then, I thought, why not combine the two and write a book on FFmpeg? I then started on a self-publishing spree that lasted until I had six books to my name. (My book publishing process is entirely powered by FOSS — Eclipse, MarkDown/ CommonMark, KHTMLToPDF, GIMP, Inkscape, Itext, ImageMagick and Calibre. I did not spend a paisa on anything other than Internet and electricity.) You can find my books at <em><a href=\"https://www.amazon.com/author/vsubhash\"> <p><strong>FFmpeg installation</strong><br /> FFmpeg now includes three programs — ffmpeg, ffprobe and ffplay. In 2018, ffserver was removed.</p> \n   <ul> \n    <li><em><strong>Build from source:</strong></em> It is best if you compile the source code and build the FFmpeg programs on your OS. FFmpeg.org provides guides for several operating systems (<a href=\"https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu\"><em> <li><strong>Download binaries:</strong> Compiled binaries (executable files of the three programs) are available from<em> <li><em><strong>Statically built binaries:</strong></em> I am still on Ubuntu 10.10, and I am unable to compile the FFmpeg source code on it. However, I was able to write the book using the latest build thanks to statically built binaries from the site<a href=\"https://johnvansickle.com/ffmpeg/\"><em> grubs in my Ubuntu 10.10 and Ubuntu 20 are unable to boot each other. Anyone who knows the fix can email <a href=\"mailto:info@vsubhash.com\"><em>info@vsubhash.com</em></a>.]</em></a></li> </em></li></em></a></li>\n   </ul> <p><strong>Concatenate videos</strong><br /> When I wrote my original article, I was an FFmpeg newbie. Cutting and pasting together videos is not as troublefree as the article may have suggested. All input videos have to have the same codec, dimensions and frame rate. Although FFmpeg may try its best, the conversion can fail or the final video may not be playable.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">echo “file ‘tank-cut-recoded.mp4’” &gt; file-list.txt\necho “file ‘tank.mp4’” &gt;&gt; file-list.txt\nffmpeg -f concat -i file-list.txt -c copy tank-mix.mp4</pre> <p>When you try to individually convert the input videos down to a common codec, dimensions and frame rate, and then convert them all into a single file, the lossy algorithm does damage twice. To limit the loss, it is best if you use the raw uncompressed video of each input video. This is rarely the case.</p> \n   <figure id=\"attachment_46372\" aria-describedby=\"caption-attachment-46372\" style=\"width: 278px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46372\" class=\"wp-caption-text\">\n     Figure 2: Presets available for the x264 codec\n    </figcaption>\n   </figure> <p><strong>Convert to MP4</strong><br /> While I have no problems with using Ogg video on my Linux systems, my electronic devices do not support it. (This is ironic because they run on Linux.) As I am unable to stream videos because of poor Internet connectivity, I have to convert all non-MP4 videos. The conversion I had suggested in the original article was based on constant bit rate. A better goal is constant quality. FFmpeg’s native x264 codec has several presets, ranging from ‘veryslow’ to ‘ultrafast’. You also need to use the constant rate factor option ‘crf’, whose value ranges from 0 (lossless) to 63 (worst).</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i elastigirl.mp4 \\\n       -c:v libx264 -crf 31 -preset slow \\\n       -c:a copy \\\n       incredible.mp4</pre> <p>Although FFmpeg continues to support several other x264 codecs, the native encoder (libx264) is now the preferred option. An advantage with constant quality is that multiple passes are not required (used to achieve the correct bit rate).</p> \n   <figure id=\"attachment_46374\" aria-describedby=\"caption-attachment-46374\" style=\"width: 590px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46374\" class=\"wp-caption-text\">\n     Figure 3: Rotate filter options\n    </figcaption>\n   </figure> \n   <figure id=\"attachment_46375\" aria-describedby=\"caption-attachment-46375\" style=\"width: 590px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46375\" class=\"wp-caption-text\">\n     Figure 4: This video has been tilted to the left by 20°\n    </figcaption>\n   </figure> <p><strong>Cut a video</strong><br /> When a raw uncompressed video is converted using a video codec, the compression algorithm creates keyframes to eliminate redundant data. When you cut a video at a particular timestamp, the frames near that location may not have all the information because they are not keyframes. (In other words, clean cuts are not possible with highly compressed videos.) Some frames will have to be eliminated and ‘video jumps’ become noticeable. The audio and video may also go out of sync.</p> <p>To limit these problems, whenever you cut a video, fix the timestamps of the frames before further processing.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -y -i barbara.mp4 \\\n-filter_complex \\\n“[0:v:0]trim=start=0:end=16, setpts=PTS-STARTPTS[lv];\n[0:v:0]trim=start=36:end=44, setpts=PTS-STARTPTS[rv];\n[0:a:0]atrim=start=0:end=16, asetpts=N/SAMPLE_RATE/TB[la];\n[0:a:0]atrim=start=36:end=44, asetpts=N/SAMPLE_RATE/TB[ra];\n[lv][rv]concat=n=2:v=1:a=0[v];\n[la][ra]concat=n=2:v=0:a=1[a]” \\\n-map ‘[v]’ -map ‘[a]’ barb-cut.mp4</pre> <p>In this example, the audio and video from seconds 16 to 44 are removed, and the timestamps of the remaining segments are counted again before being provided to the concat filters.</p> <p><strong>Rotate a video</strong><br /> In the original article, you learned that a video can be rotated in spans of 90°. Values 0 and 3 flip the video in addition to the rotation.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i barb.mp4 \\\n-filter:video “transpose=1” \\\nbarb-rotated.mp4</pre> <p>Figure 3 shows the transpose filter; filter values 1 and 2 rotate the video right and left. The values 0 and 3 cause rotation but also flip the video.</p> <p>More discrete levels of rotation are possible with the rotate filter.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -y -i barbara.mp4 \\\n-vf rotate=angle=-20*PI/180:fillcolor=brown\nbarb20.mp4</pre> <p>If you want to simply flip the video, use <em>vflip</em> and<em> hflip</em> filters.</p> \n   <figure id=\"attachment_46376\" aria-describedby=\"caption-attachment-46376\" style=\"width: 590px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46376\" class=\"wp-caption-text\">\n     Figure 5: The flip filters are used to horizontally and vertically flip a video\n    </figcaption>\n   </figure> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i lucas.mp4 \\\n-filter:v “vflip” \\\nlucas-upside-down.mp4\nffmpeg -i lucas.mp4 \\\n-filter:v “hflip” \\\nlucas-half-crazy.mp4\nffmpeg -i lucas.mp4 \\\n-filter:v “hflip,vflip” \\\nlucas-totally-flipped.mp4</pre> <p><strong>Normalise audio</strong><br /> You can increase or decrease the volume level in an audio or video file using the volume filter. You set the filter value to a multiple of the input volume or specify the maximum loudness level in decibels.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i low.mp3 -af ‘volume=3’ high.mp3</pre> <p>Adjusting the volume in this manner may not work all the time. Sometimes, the audio is so low that even doubling it does not make a difference. The correct solution involves two steps. First, use the volumedetect filter to determine the loudness of audio samples in the file. Then, apply the volume filter based on what you learnt in the first step.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i low.mp3 -af “volumedetect” -f null -</pre> <p>In Figure 6, the volumedetect filter shows that maximum loudness of all samples is at 17dB. The histogram shows the number of samples that would get clipped if the volume was taken any higher than 17. For example, increasing the volume to 18dB would clip the waveform in six samples.</p> <p>After studying this, it is clear that the loudness needs to be raised to a maximum of 17dB.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i low.mp3 \\\n-af ‘volume=17dB’ -f ogg \\\nnormalized.ogg</pre> <p>Normalisation preserves the original waveform while increasing only the loudness.</p> <p><strong>Slipstream audio to a video</strong><br /> Sometimes, I encounter a video where the audio has some problems. I usually extract the audio stream to an MP3 file so that I can examine it in Audacity. After I fix the problem, I export the corrected audio to another MP3 file. Then, I remove the original audio from the video and add this corrected MP3 stream as its audio. I use maps to accomplish this.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">#Extract the audio\nffmpeg -i original-video.mp4 \\\n-map 0:1 \\\nproblem-audio.mp3\n\n# Fix the problem in problem-audio.mp3 using Audacity and create\n# corrected-audio.mp3\n\n#Replace existing audio with fixed audio from mp3\nffmpeg -i original-video.mp4 -i corrected-audio.mp3 \\\n-map 0:0 -map 1:0 \\\n-codec copy \\\nvideo-with-corrected-audio.mp4</pre> <p>In the first command, <em>-map 0:1</em> refers to the first input file’s or the video’s second stream, which happens to be the audio stream. (The -map option may be redundant but it helps in debugging more complex commands.) In the second <em>ffmpeg</em> command, <em>-map 0:0</em> refers to the first input file’s or the video file’s first stream, which is the video stream. The map in <em>-map 1:0</em> refers to the second input file’s or the audio file’s first stream, which is the corrected audio stream.</p> <p><strong>Slipstream subtitles to video</strong><br /> Subtitles were very useful to me when I had to create a book-read video for my first book. The audio had issues and I decided to create subtitles and burn them into the video. (I used the GNOME subtitles program to transcribe the video and save to a subtitle file. It has simple keyboard shortcuts for controlling the playback [play/pause/rewind/fast forward] of the video while typing the subtitles. No need to use the mouse.)</p> \n   <figure id=\"attachment_46377\" aria-describedby=\"caption-attachment-46377\" style=\"width: 420px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46377\" class=\"wp-caption-text\">\n     Figure 6: Use volumedetect filter before using volume filter\n    </figcaption>\n   </figure> <p>I did not like the tiny font used by YouTube so I burned my subtitles into the video. Such subtitles become part of the video and cannot be turned off.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -y -i book-read.mp4 \\\n-filter_complex “subtitles=transcript.ass” \\\n-c:a copy \\\nread-subtitled.mp4</pre> <p>While burning subtitles into the video is a failsafe alternative, your first option should be to add a subtitle stream (analogous to a video stream or an audio stream) in the multimedia file container. (MP4, MOV, MKV and other formats are just file containers. The actual codecs can be anything in the wild.) For Matroska videos, you can even add a custom subtitle display font file as a stream.</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">ffmpeg -i sarah.mp4 -i subtitle.ass \\\n-map 0:v -map 0:a -map 1:s \\\n-c:v copy -c:a copy -c:s ass \\\n-metadata:s:s:0 language=eng \\\n-attach Florentia.ttf \\\n-metadata:s:3 mimetype=application/x-truetype-font \\\nsarah-subtitled.mkv</pre> <p>In this command, the <em>-map 1:s</em> ensures that the subtitles will be from the second file (the SubStation Alpha file). Even if the MP4 file had a subtitle stream, it will not be included in the MKV file.</p> \n   <figure id=\"attachment_46378\" aria-describedby=\"caption-attachment-46378\" style=\"width: 480px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46378\" class=\"wp-caption-text\">\n     Figure 7: A video with burned-in subtitles\n    </figcaption>\n   </figure> <p>SRT is the most popular subtitle format. SubStation Alpha (SSA) is the most feature-rich subtitle format because it supports a custom font, text colour, outline colour, shadow colour, background box and even rotation. All of this SSA awesomeness is supported only by the Matroska format.</p> <p>The specification of the endearing but difficult SSA format is available on the <a href=\"https://www.matroska.org\"><em></em></a> website (Technical Info » Subtitles » SSA). However, I will risk a description here for the style statement.</p> \n   <figure id=\"attachment_46379\" aria-describedby=\"caption-attachment-46379\" style=\"width: 590px\" class=\"wp-caption aligncenter\">\n    <figcaption id=\"caption-attachment-46379\" class=\"wp-caption-text\">\n     Figure 8: The SubStation Alpha (SSA) subtitle format offers the most features\n    </figcaption>\n   </figure> <p>Style: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding</p> <p><em>Name</em> refers to a subtitle display style. You can define and use many different styles, not just the default. The colours are in hexadecimal AABBGGRR format! <em>PrimaryColour</em> is the colour of the subtitle text. OutlineColour is for the outline of the text. BackColour is the colour of the shadow behind the text. SecondaryColour and OutlineColour are automatically used when timestamps collide.<em> Bold, Italic,</em> et al, are -1 for true and 0 for false. (Yeah, I know.) <em>ScaleX</em> and <em>ScaleY</em> specify magnification (1-100).<em> Spacing</em> is additional pixel space between letters.</p> \n   <figure id=\"attachment_46380\" aria-describedby=\"caption-attachment-46380\" style=\"width: 904px\" class=\"wp-caption alignnone\">\n    <figcaption id=\"caption-attachment-46380\" class=\"wp-caption-text\">\n     Figure 9: Default SSA styles used by FFmpeg, GNOME Subtitles and the author\n    </figcaption>\n   </figure> <p><em>Angle</em> is about rotation (0-360) and controlled by Alignment.<em> BorderStyle</em> uses 1 (outline and drop-shadow) and 3 (outline box). If BorderStyle is 1, then Outline represents pixel space width (0-4) of its outline. In the same case, Shadow represents pixel space (0-4) below the text and shadow. Alignment takes 1 (left), 2 (centre) and 3 (right). If you add 4 to them, the subtitle appears at the top of the screen. If you add 8, it goes to the middle. Then, we have Margin from the left, right and bottom edges of the screen. <em>Encoding</em> is 0 for ANSI Latin and 1 for Unicode (I think).</p> <p>I have a Caja Actions Configuration script that changes the style statement in a SSA file to:</p> <pre class=\"brush: bash; gutter: false; first-line: 0\">Style: Default,Florentia,30,&amp;H2200CCCC,&amp;H000000FF,&amp;H2200 00EE,&amp;HAA00CCCC,-1,-1,0,0,100,100,0, 30.00,3,2,3,1,20,20,40,1.</pre><p>The post <a rel=\"nofollow\" href=\"https://www.opensourceforu.com/2020/11/more-cool-ffmpeg-tricks/\">More Cool FFmpeg Tricks</a> appeared first on <a rel=\"nofollow\" href=\"https://www.opensourceforu.com\">Open Source For You</a>.</p> </a></em></p>","descriptionType":"html","publishedDate":"Mon, 09 Nov 2020 11:55:33 +0000","feedId":3140,"bgimg":"https://i2.wp.com/www.opensourceforu.com/wp-content/uploads/2020/10/FFmpeg-featured-image_Sept-2020.jpg?fit=1024%2C576&ssl=1","linkMd5":"f9fb74da01c40fd05e13e4fb707839fb","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn63@2020_3/2020/11/16/09-03-23-704_1e72043ec8a1ed73.webp","destWidth":1024,"destHeight":576,"sourceBytes":103770,"destBytes":103770,"author":"V Subhash","articleImgCdnMap":{"https://i2.wp.com/www.opensourceforu.com/wp-content/uploads/2020/10/FFmpeg-featured-image_Sept-2020.jpg?fit=1024%2C576&ssl=1":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn63@2020_3/2020/11/16/09-03-23-704_1e72043ec8a1ed73.webp"},"publishedOrCreatedDate":1605517403551}],"record":{"createdTime":"2020-11-16 17:03:23","updatedTime":"2020-11-16 17:03:23","feedId":3140,"fetchDate":"Mon, 16 Nov 2020 09:03:23 +0000","fetchMs":32564,"handleMs":7,"totalMs":34535,"newArticles":0,"totalArticles":10,"status":1,"type":0,"ip":"1661e3634e6f9e9d5e805b84c6365b30","hostName":"us-034*","requestId":"44a633ae29874ae3941b4a42be6bf481_3140","contentType":"application/atom+xml; charset=UTF-8","totalBytes":103770,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":1,"articlesImgsGithubTotal":1,"successGithubMap":{"myreaderx22":1},"failGithubMap":{}},"feed":{"createdTime":"2020-08-25 04:29:19","updatedTime":"2020-09-01 10:22:38","id":3140,"name":"Open Source For You","url":"http://www.opensourceforu.com/feed/atom/","subscriber":null,"website":null,"icon":"https://www.opensourceforu.com/favicon.ico","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn13@2020_5/2020/09/01/02-22-32-326_e18dede8194c051b.jpg","description":"The Complete Magazine on Open Source","weekly":null,"link":null},"noPictureArticleList":[],"tmpCommonImgCdnBytes":103770,"tmpBodyImgCdnBytes":0,"tmpBgImgCdnBytes":0,"extra4":{"start":1605517370816,"total":0,"statList":[{"spend":32728,"msg":"获取xml内容"},{"spend":7,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":0,"msg":"正文链接上传到cdn"}]},"extra5":1,"extra6":1,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{"https://www.opensourceforu.com/?p=46368_mailto:info@vsubhash.com":"mailto:info@vsubhash.com"},"extra111_proxyServerAndStatMap":{},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://i2.wp.com/www.opensourceforu.com/wp-content/uploads/2020/10/FFmpeg-featured-image_Sept-2020.jpg?fit=1024%2C576&ssl=1","sourceStatusCode":200,"destWidth":1024,"destHeight":576,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn63@2020_3/2020/11/16/09-03-23-704_1e72043ec8a1ed73.webp","sourceBytes":103770,"destBytes":103770,"feedId":3140,"totalSpendMs":1782,"convertSpendMs":0,"createdTime":"2020-11-16 17:03:23","host":"us-032*","referer":"https://www.opensourceforu.com/?p=46368","linkMd5ListStr":"f9fb74da01c40fd05e13e4fb707839fb,f9fb74da01c40fd05e13e4fb707839fb","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"101.3 KB","destSize":"101.3 KB","compressRate":"100%"}],"successGithubMap":{"myreaderx22":1},"failGithubMap":{}}