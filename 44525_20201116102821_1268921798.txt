{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-11-16 18:25:45","updatedTime":"2020-11-16 18:25:45","title":"实时关注豆瓣租房信息，几行代码帮你轻松搞定","link":"https://webview.tech/?p=1712","description":"\n<p>现代年轻人的日常生活已经离不开互联网，无论是订机票，点外卖还是网购，本质上，我们都已经习惯从互联网获取信息，并从中筛选、鉴别，作出决策。</p>\n\n\n\n<p>但有时，如何从浩瀚的信息之海找到我们所需要的东西，则是一个大问题。这时，技术就派上了用场。</p>\n\n\n\n<p>设想这样一种场景，你租住的房子很快就要到期，可你却诸事缠身，没办法花费诸多精力寻找合适的房源。你第一时间想到了房屋中介，但又投鼠忌器，害怕自己的个人信息被人不经意间「分享」，你还希望直接和一房东对话，找一套直租房源。</p>\n\n\n\n<p>你想到了论坛，你看到了密密麻麻的帖子，并从中仔细挑选符合你期望的房源。结果你发现，看了半天，<strong>满意的似乎并不多，只能再刷刷看有没有新发布的帖子。</strong></p>\n\n\n\n<p>生活中诸如此类的情景还有很多，其实，在精力有限的情况下，可以让你的电脑替你去论坛搜索所期望的信息，收集打包并呈现在你眼前。</p>\n\n\n\n<p>下面以租房和寻找二手物品为例，介绍我们是如何用简单的方法筛选出相关信息并进行定时更新的。</p>\n\n\n\n<h2>豆瓣小组获取租房信息</h2>\n\n\n\n<p>豆瓣上有很多专门的租房小组，尽管这些年也逐渐「沦陷」为房屋中介的战场，但由于历史悠久，我们还是能从中筛选出合适房源。</p>\n\n\n\n<p>接下来的尝试，我们以「上海租房」小组为例，从该主页可以看到，相同类型的小组不少，当然也适用于这个方法。</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044018.png\" alt=\"图片\"/><figcaption>豆瓣「上海租房」小组首页</figcaption></figure>\n\n\n\n<p>知己知彼，百战不殆。在抓取该页面信息之前，我们先来看看页面结构是怎样的。</p>\n\n\n\n<p>点击豆瓣页面中的「更多小组讨论」后，会发现帖子标题涵盖了我们关心的<strong>地铁线路</strong>、<strong>站名</strong>以及<strong>周边位置</strong>等信息。因此，我们的目标就可以概括为<strong>定时获取包含某些关键字的帖子标题以及链接</strong>，<strong>并去重。</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044022.png\" alt=\"图片\"/><figcaption>小组讨论帖标题的关键词</figcaption></figure>\n\n\n\n<p>「人生苦短，我用 Python」，我们的这个小工具就是基于 Python 3 实现的。而且方便的是，小组讨论不必登录就可以浏览，这就省去了模拟浏览器登录的麻烦。</p>\n\n\n\n<h3>安装 python</h3>\n\n\n\n<p>首先，我们需要 <a href=\"https://www.python.org/downloads/\">安装 Python</a> ，详细方法可见这篇<a href=\"https://www.runoob.com/python/python-install.html\">教程</a>。建议使用 3.x 版本，毕竟今年 1 号起， <a href=\"https://pythonclock.org/\">2.X版本官方都停止维护了。</a></p>\n\n\n\n<p>Windows 下载安装包后，运行安装即可。</p>\n\n\n\n<p>终端处输入 Python 显示版本信息则表示安装成功。</p>\n\n\n\n<p>图为在 Windows cmd 中的效果。</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044024.png\" alt=\"图片\"/><figcaption>cmd 中输入 python 查看版本</figcaption></figure>\n\n\n\n<p>虽然 Python 以短小精悍闻名，但我们还是想再精简下工作量，我们使用 <a href=\"https://scrapy.org\">Scrapy 框架</a>来抓取网页上的信息，Scrapy 是 Python 的一个知名第三方爬虫库，Windows 平台可以直接通过安装Python后自带的 pip 安装，一行命令解决。</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"bash\" class=\"language-bash\">pip install Scrapy</code></pre>\n\n\n\n<p>但 Mac OS 系统自带的 Python 2.7 会和  Scrapy 产生冲突，Mac OS 用户建议使用 <a href=\"https://virtualenv.pypa.io/en/latest/\">virtualenv</a> 在虚拟环境中进行安装。\n都安装完毕后，就可以创建项目了。</p>\n\n\n\n<h3>创建项目</h3>\n\n\n\n<p>我们创建一个用以提取信息发送邮件的项目，将其命名为 ForumSpider。<a href=\"http://doc.scrapy.org/en/latest/intro/tutorial.html\">新建项目</a>，首先 cd 到相应的目录，执行如下的命令：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"bash\" class=\"language-bash\">scrapy startproject ForumSpider</code></pre>\n\n\n\n<p>一个初始的 Scrapy 项目就生成了，下图是这个项目的目录结构，由于我们实现的功能比较简单，可以暂时不用关心其他文件，我们只需在 settings.py 中进行简单设置，然后在 spiders 目录下定义一个我们自己的爬取工具就够用了。\n</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044025.png\" alt=\"图片\"/><figcaption>scrapy 项目结构</figcaption></figure>\n\n\n\n<p>首先，我们需要在 settings.py 中设置 USER_AGENT，即用户代理，</p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p>User Agent中文名为用户代理，简称 UA，是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器渲染引擎、浏览器语言、浏览器插件等</p></blockquote>\n\n\n\n<p>简而言之，这就是客户机器的身份标识。我们需要设置此项<strong>以便能够隐藏机器的身份，不容易被网站拒绝。</strong>settings.py 中已经自带了一些配置。在浏览器中按下 F12，选择 Network 标签页，随意点击一个链接，就可以从 Header 中获取 USER_AGENT：</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044026.png\" alt=\"图片\"/><figcaption>查看 User Agent</figcaption></figure>\n\n\n\n<p>将其替换 settings.py 中的 USER_AGENT：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044027.png\" alt=\"图片\"/><figcaption>修改配置</figcaption></figure>\n\n\n\n<p>另外，我们选择遵循 <a href=\"https://developers.google.com/search/reference/robots_txt?hl=zh-CN\">Robots 规则</a>，</p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p>robots.txt是一种存放于网站根目录下的ASCII编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。</p></blockquote>\n\n\n\n<p>Robots.txt中定义了我们可以爬取的范围，符合对应该网站的爬取规范，以避免不必要的爬虫风险。之后，我们就可以新建一个工具定义我们的爬取规则。在此之前，我们需要从网站中找寻一定的规律来编写我们的脚本，我们打开刚才的「更多小组讨论」的帖子列表页面，观察 url 的规律，下图分别是第一页的 url 和第二页的 url，可以看出，分页参数 start 代表开始的元素编号，每页 25 个帖子：</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044029.png\" alt=\"图片\"/><figcaption>第 0 -25 个帖子的 url</figcaption></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044030.png\" alt=\"图片\"/><figcaption>第 25 -50 个帖子的 url</figcaption></figure>\n\n\n\n<p>了解了每次爬取的 url 的变化规律，接下来我们需要了解爬取内容的 DOM 树结构，进入控制台，选择 Elements 标签页，使用旁边的选择器定位标题所在的结构：</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044031.gif\" alt=\"图片\"/><figcaption>定位标题所在元素的操作</figcaption></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044032.png\" alt=\"图片\"/><figcaption>标题所在的 a 标签</figcaption></figure>\n\n\n\n<p>我们发现，整个列表是在一个名为 olt 的 class 中呈现的，标题所在的 class 名为 title，并且其中的超链接标签中包含了我们需要的所有信息，标题和链接。由于页面中可能包含有多个名为 title 的 class，因此我们将其父级元素 olt 同时作为条件选择以便更方便地定位。</p>\n\n\n\n<p>回到刚才的项目，我们此时需要新建一个名为 douban 的爬取工具：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"bash\" class=\"language-bash\">scrapy genspider douban \"douban.com\"</code></pre>\n\n\n\n<p>douban.com 是我们设定的爬取域，生成的文件如图所示：\n</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044033.png\" alt=\"图片\"/><figcaption>工具主函数</figcaption></figure>\n\n\n\n<p>start_urls 代表了爬取的 url，但实际上我们如果需要爬取多个页面的话， url 则是动态的。因此我们可以将 allowed_domains 和 start_urls 变量删去，用 start_requests 方法来动态生成爬取的 url：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">def start_requests(self):\n    for i in range(0, 5 * 25, 25):\n        url = 'https://www.douban.com/group/549538/discussion?start={page}'.format(page=i)\n        yield scrapy.Request(url=url, callback=self.parse)</code></pre>\n\n\n\n<p>这个方法的功能就是循环爬取 start=0 到 start=100 的页面内容，每次共爬取 5 页，爬取时调用 parse 中指定的规则。\n在刚才我们探索页面结构的基础上，parse 方法定义为：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">def parse(self, response):\n    for title in response.css('.olt .title'):\n        yield {'title': title.css('a::text').getall(), 'link': title.css('a::attr(href)').getall()}</code></pre>\n\n\n\n<p>这个方法的含义是获取 olt 的子元素 title 下的 a 标签的文本和 href 属性，即内容和链接。getall 代表获取符合上述条件的所有元素的内容和链接。\n到这里，爬取的功能已经全部编写完毕了，一共是 7 行代码。但我们所需要的功能是在获取到新发布的帖子的信息时，收到推送或提醒。Scrapy 中内置了 mail 模块，可以很轻松地实现定时发送邮件的功能。那我们可以考虑先把爬取到的信息存储到文件中进行分析，再将由关键词筛选得到的信息与上一次筛选过后的信息进行比较，如果存在更新，就更新存储筛选信息的文件，并发送邮件。我们可以用以下的命令来将爬取到的信息输入到 JSON 文件中：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"bash\" class=\"language-bash\">scrapy crawl douban -o douban.json\n</code></pre>\n\n\n\n<p>既然需要定时执行，那我们就需要在根目录中创建一个 douban_main.py，用 time 库编写一个简单的定时器，用以爬取之前清空存储爬取信息的文件，并每 21600 秒（6 个小时）执行一次爬取分析：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">import time, os\nwhile True:\n    if os.path.exists(\"douban.json\"):\n        with open(\"douban.json\",'r+') as f:\n            f.truncate()\n    os.system(\"scrapy crawl douban -o douban.json\")\n    time.sleep(21600)\n</code></pre>\n\n\n\n<p>最后一步，就是筛选信息并发送邮件了，发送邮件需要引用 MailSender 类：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">from scrapy.mail import MailSender\n</code></pre>\n\n\n\n<p>首先，我们要确保发送邮件的邮箱 SMTP 服务开启，并获取授权码，以 QQ 邮箱为例：\n</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044034.png\" alt=\"图片\"/><figcaption>开启 POP3 / SMTP 服务及 IMAP / SMTP 服务</figcaption></figure>\n\n\n\n<p>获取授权码之后，配置 MailSender 实例：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">mailer = MailSender(\n    smtphost=\"smtp.qq.com\",\n    mailfrom=\"xxxxxxxxx@qq.com\",\n    smtpuser=\"xxxxxxxxx@qq.com\",\n    smtppass=\"16 位授权码\",\n    smtpssl=True,\n    smtpport=465\n)\n</code></pre>\n\n\n\n<p>最后，我们需要指定一些关键词，为了便于理解，匹配的写法比较简易，注重性能的朋友们可以使用正则匹配。注意每次分析完毕之后，我们将迄今为止出现的符合关键词的信息写入到 douban_store.json 中，并在新信息出现时保持更新。这个过程写在爬虫程序结束之后调用的 close 方法中。附上 douban.py 的所有内容：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\"># -*- coding: utf-8 -*-\nimport scrapy, json, os\nfrom scrapy.mail import MailSender\nclass DoubanSpider(scrapy.Spider):\n    name = 'douban'\n    def start_requests(self):\n        for i in range(0, 5 * 25, 25):\n            url = 'https://www.douban.com/group/549538/discussion?start={page}'.format(page=i)\n            yield scrapy.Request(url=url, callback=self.parse)\n    def parse(self, response):\n        for title in response.css('.olt .title'):\n            yield {'title': title.css('a::text').getall(), 'link': title.css('a::attr(href)').getall()}\n    def close(self):\n        mailer = MailSender(\n            smtphost=\"smtp.qq.com\",\n            mailfrom=\"463584015@qq.com\",\n            smtpuser=\"463584015@qq.com\",\n            smtppass=\"afnzygrvbezsbgja\",\n            smtpssl=True,\n            smtpport=465\n        ) # 配置邮箱\n        obj_store, new_info = [], []\n        key_words = ['枫桥路', '曹杨路', '11 号线']\n        if os.path.exists(\"D:\\\\ForumSpider\\\\douban_store.json\"):\n            with open(\"D:\\\\ForumSpider\\\\douban_store.json\", 'r') as f:\n                obj_store = json.load(f)  # 读取之前爬取的符合关键词的信息\n        with open(\"D:\\\\ForumSpider\\\\douban.json\", 'r') as load_f:\n            load_dict = json.load(load_f)\n            for info in load_dict:\n                content = info[\"title\"][0].replace('\\n', '').replace('\\r', '').strip() #按标题进行筛选\n                for k in key_words:\n                    if k in content:\n                        tmp = {\"title\": content, \"link\": info[\"link\"][0]}\n                        if tmp not in obj_store: # 如果之前的爬取没有遇到过，则加入到新信息列表\n                            new_info.append(tmp)\n                            obj_store.append(tmp)\n        if len(new_info) > 0:\n            with open(\"D:\\\\ForumSpider\\\\douban_store.json\", 'w') as writer:\n                json.dump(obj_store, writer) # 更新到旧信息列表\n            return mailer.send(  # 发送邮件\n                to=['lolilukia@foxmail.com'],\n                subject='【豆瓣脚本】上海租房',\n                body='\\n'.join([str(x['title'] + ':' + x['link']) for x in new_info])\n            )                        \n</code></pre>\n\n\n\n<p>运行 douban_main.py 即可定时运行这个信息爬取脚本：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"bash\" class=\"language-bash\">python douban_main.py\n</code></pre>\n\n\n\n<p>包含主函数，这个脚本一共 51 行，现在已经能满足使用需要，当然还可以进一步精简优化。执行脚本之后，很快我就收到了第一封邮件：\n</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044035.png\" alt=\"图片\"/><figcaption>租房信息爬取结果邮件</figcaption></figure>\n\n\n\n<p>上述脚本适用于所有豆瓣小组，稍改改动优化过后也可以应用于获取留学信息、追星八卦等等方面。</p>\n\n\n\n<h2>场景 2：获取二手物品信息</h2>\n\n\n\n<p>上述的场景适用于不需要登录就能查看信息的一些网站，然而大多数情况下，更多的信息需要登录之后才能查看。很多网站登录的时候使用了验证码，扫码等策略避免自动登录，cookie 的模拟登录方式又极容易过期，使用简单的策略爬取网站信息似乎有些困难，下面以 v2ex 论坛为例，介绍另一种爬取网页信息的半自动方法。</p>\n\n\n\n<p>为何称为半自动方法呢，进入 v2ex 的登录页，我们发现登录框的下方需要输入验证码，如果我们需要模拟登录的话，可能还需要写一个模式识别的程序，甚至比我们浏览论坛的时间成本还高。如果能够人工输入一次验证码，然后让程序自动定时爬取，好像也可以接受。这样的话，我们可以采用模拟人工操作浏览器行为的框架 selenium。</p>\n\n\n\n<p>selenium 依旧可以使用 pip 来进行安装：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"bash\" class=\"language-bash\">pip install selenium\n</code></pre>\n\n\n\n<p>selenium 3 之后需要单独安装浏览器驱动，因此我们需要下载 <a href=\"https://github.com/mozilla/geckodriver/releases\">geckodriver</a> 和 <a href=\"https://chromedriver.chromium.org/downloads\">chromedriver</a>。</p>\n\n\n\n<p>，其他浏览器需要安装对应的驱动），并将它们都加入到环境变量 PATH 中。</p>\n\n\n\n<p>首先，我们先使用 selenium 调用浏览器，打开 v2ex 的登录页面：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">\nfrom selenium import webdriver\nsigin_url = 'https://www.v2ex.com/signin'\ndriver = webdriver.Chrome('D:\\\\chrome_driver\\\\chromedriver.exe')\ndriver.get(sigin_url)\n</code></pre>\n\n\n\n<p>以下是运行效果： </p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044035.gif\" alt=\"图片\"/><figcaption>selenium 运行效果</figcaption></figure>\n\n\n\n<p>接下来，我们需要自动填充用户名和密码，然后等待我们人工输入验证码进入论坛。我们还是使用 CSS Selector 的方式定位元素，找到用户名和密码所在的输入框：</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044036.png\" alt=\"图片\"/><figcaption>查看输入框的 DOM 树结构</figcaption></figure>\n\n\n\n<p>我们发现这两个输入框没有标识 id，也没有特别的 class 名称，因此我们可以使用 find_elements_by_css_selector 返回这一类元素的列表，幸运的是登录页一共只有 3 个输入框，因此我们可以通过索引迅速锁定它们，并填充我们的用户名密码。当然这里也可以用 tag 来定位：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">user_name = driver.find_elements_by_css_selector('.cell .sl')[0]\nuser_name.send_keys('v2ex 用户名')\nuser_pwd = driver.find_elements_by_css_selector('.cell .sl')[1]\nuser_pwd.send_keys('v2ex 密码')\n</code></pre>\n\n\n\n<p>运行效果如下： </p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044037.gif\" alt=\"图片\"/><figcaption>打开页面自动输入用户名和密码</figcaption></figure>\n\n\n\n<p>验证码需要我们自行输入，为了让程序等待我们输入完毕验证码并点击登录按钮之后再进行爬取，我们设定一个 while 循环，当页面跳转到论坛列表页，出现特定元素时跳出：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">while True: # 等待人工输入验证码\n    table = driver.find_elements_by_id('Tabs')\n    if len(table) != 0:\n        break\n</code></pre>\n\n\n\n<p>其余的逻辑与场景 1 大抵相仿，在此不多加赘述。模拟浏览器行为的写法比较简单，访问页面时调用形如 driver.get(url) 的方法即可，抓取的写法也很好理解，只是由于调用了浏览器，爬取速度会稍慢。不过这也无妨，我们要做的就是在点击登录按钮之后等待邮件即可。由于这个场景不再使用 Scrapy 进行抓取，发送邮件我们改用 Python 内置的 smtplib 和 email 模块，进行简单的配置（16 位授权码的获取方式参见场景 1）：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">import smtplib\nfrom email.mime.text import MIMEText\nfrom email.header import Header\nsender = 'xxxxxx@qq.com'\nsubject = '【v2ex 脚本】二手交易'\nsmtpserver = 'smtp.qq.com'\npasscode = '场景 1 出现过的 16 位授权码'\n</code></pre>\n\n\n\n<p>然后需要构造一个 MIMEText 实例，用以定义发送的内容、发件人、收件人和主题等等：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">msg = MIMEText(body, 'html', 'utf8')\nmsg['From'] = sender\nmsg['To'] = sender\nmsg['Subject'] = Header(subject, charset='utf8')\n</code></pre>\n\n\n\n<p>这里的 body 就是我们筛选出的新信息的字符串，发送邮件的过程也十分简单：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">smtp = smtplib.SMTP()\nsmtp.connect(smtpserver)\nsmtp.login(sender, passcode)\nsmtp.sendmail(sender, sender, msg.as_string())\n</code></pre>\n\n\n\n<p>如果需要多次运行，则可以使用 JSON 文件记录筛选过的信息，如果仅运行一次，将 obj_store 放置在 while 循环外即可。注意尽量避免较短时间内多次进行登录操作，否则可能会被封 IP。另外，如果新增回复，链接会发生变化，因此此处只判断 title 是否出现过。附上 v2ex_main.py 的所有内容：</p>\n\n\n\n<pre class=\"wp-block-code\"><code lang=\"python\" class=\"language-python\">from selenium import webdriver\nimport time, os, json\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.header import Header\n\n\nsender = 'xxxxxxxxx@qq.com'\nsubject = '【v2ex 脚本】二手交易'\nsmtpserver = 'smtp.qq.com'\npasscode = '16 位授权码'\n\n\nsigin_url = 'https://www.v2ex.com/signin'\ndriver = webdriver.Chrome('D:\\\\chrome_driver\\\\chromedriver.exe')\ndriver.get(sigin_url)\nuser_name = driver.find_elements_by_css_selector('.cell .sl')[0]\nuser_name.send_keys('v2ex 用户名')\nuser_pwd = driver.find_elements_by_css_selector('.cell .sl')[1]\nuser_pwd.send_keys('v2ex 密码')\nwhile True: # 等待人工输入验证码\n    table = driver.find_elements_by_id('Tabs')\n    if len(table) != 0:\n        break\nkey_words = ['mbp', 'AirPods', '触摸板']\nobj_store = []\nwhile True:\n    new_info = []\n    for i in range(0, 5):\n        driver.get('https://www.v2ex.com/go/all4all?p={page}'.format(page=i+1))\n        items = driver.find_elements_by_css_selector('.item_title a')\n        for item in items:\n            for k in key_words:\n                if k in item.text:\n                    tmp = {'title': item.text, 'link': item.get_attribute('href')}\n                    if tmp['title'] not in obj_store:\n                        new_info.append(tmp)\n                        obj_store.append(tmp['title'])\n    if len(new_info) > 0:\n        body = '\\n'.join([str(x['title'] + ':' + x['link']) for x in new_info])\n        msg = MIMEText(body, 'html', 'utf8')\n        msg['From'] = sender\n        msg['To'] = sender\n        msg['Subject'] = Header(subject, charset='utf8')\n        smtp = smtplib.SMTP()\n        smtp.connect(smtpserver)\n        smtp.login(sender, passcode)\n        smtp.sendmail(sender, sender, msg.as_string())\n        smtp.close()\n    time.sleep(1800)\n</code></pre>\n\n\n\n<p>爬取的过程如下图所示：</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044038.gif\" alt=\"图片\"/><figcaption>整体运行效果</figcaption></figure>\n\n\n\n<p>切记不要关闭浏览器，随后会收到一封来自脚本的邮件：</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://podcast.webview.tech/podblog/2020-02-23-044039.png\" alt=\"图片\"/><figcaption>二手信息爬取结果邮件</figcaption></figure>\n\n\n\n<h2>总结</h2>\n\n\n\n<p>以上仅是相应于场景提出的小规模样例，生活中其实有相当多的应用，比如最近一段时间抢购口罩等等。这样的小工具能够一定程度上提高我们生活的效率，避免花费不必要的时间。</p>\n\n\n\n<p>最后，虽然网页爬虫能够给我们的生活带来一定的便利，免去人工筛选信息的烦恼，但还是要注意道德与法律的边界，防止带来一系列负面影响。</p>\n\n\n\n\n","descriptionType":"html","publishedDate":"Sun, 23 Feb 2020 07:58:24 +0000","feedId":44525,"bgimg":"https://podcast.webview.tech/podblog/2020-02-23-044018.png","linkMd5":"87eba696d05b8c8619bcf2401fc67784","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn37@2020_1/2020/11/16/10-25-48-971_56db67228a6b8d44.webp","destWidth":1645,"destHeight":862,"sourceBytes":223782,"destBytes":83766,"author":"lolilukia","articleImgCdnMap":{"https://podcast.webview.tech/podblog/2020-02-23-044018.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn37@2020_1/2020/11/16/10-25-48-971_56db67228a6b8d44.webp","https://podcast.webview.tech/podblog/2020-02-23-044022.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn78@2020_5/2020/11/16/10-25-53-137_8babe0c374f65c94.webp","https://podcast.webview.tech/podblog/2020-02-23-044024.png":null,"https://podcast.webview.tech/podblog/2020-02-23-044025.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn89@2020_2/2020/11/16/10-25-53-857_07abdebc7b525837.webp","https://podcast.webview.tech/podblog/2020-02-23-044026.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn92@2020_5/2020/11/16/10-25-53-916_9202922d86394b8d.webp","https://podcast.webview.tech/podblog/2020-02-23-044027.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn58@2020_2/2020/11/16/10-25-52-879_5565ecaf864830ed.webp","https://podcast.webview.tech/podblog/2020-02-23-044029.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn41@2020_6/2020/11/16/10-25-53-619_ecc99aa75b6e9097.webp","https://podcast.webview.tech/podblog/2020-02-23-044030.png":null,"https://podcast.webview.tech/podblog/2020-02-23-044031.gif":null,"https://podcast.webview.tech/podblog/2020-02-23-044032.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn69@2020_4/2020/11/16/10-25-52-963_dafb983739bd6a7f.webp","https://podcast.webview.tech/podblog/2020-02-23-044033.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn65@2020_4/2020/11/16/10-25-52-806_b603b855bec445b7.webp","https://podcast.webview.tech/podblog/2020-02-23-044034.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn61@2020_5/2020/11/16/10-25-52-855_8eccda2ff462f42d.webp","https://podcast.webview.tech/podblog/2020-02-23-044035.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn54@2020_1/2020/11/16/10-25-54-512_37b007144c8e9e02.webp","https://podcast.webview.tech/podblog/2020-02-23-044035.gif":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn96@2020_5/2020/11/16/10-25-56-523_c112d7e78c186e6e.webp","https://podcast.webview.tech/podblog/2020-02-23-044036.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn49@2020_6/2020/11/16/10-25-52-674_7d4aa9168abae576.webp","https://podcast.webview.tech/podblog/2020-02-23-044037.gif":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_1/2020/11/16/10-25-54-649_646d8b2ee7777b15.webp","https://podcast.webview.tech/podblog/2020-02-23-044038.gif":"https://cdn.jsdelivr.net/gh/myreaderx/cdn79@2020_3/2020/11/16/10-25-58-879_94e47d6a7924026d.webp","https://podcast.webview.tech/podblog/2020-02-23-044039.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn99@2020_5/2020/11/16/10-25-53-439_95eaaedcaefccf6c.webp"},"publishedOrCreatedDate":1605522345911}],"record":{"createdTime":"2020-11-16 18:25:45","updatedTime":"2020-11-16 18:25:45","feedId":44525,"fetchDate":"Mon, 16 Nov 2020 10:25:45 +0000","fetchMs":1428,"handleMs":45,"totalMs":157781,"newArticles":0,"totalArticles":57,"status":1,"type":0,"ip":"f80c7bd81200785c5e1521e0fff25478","hostName":"us-038*","requestId":"427fb4d3492540daaf656a9ed0e3c4fe_44525","contentType":"application/rss+xml; charset=UTF-8","totalBytes":1941846,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":18,"articlesImgsGithubTotal":15,"successGithubMap":{"myreaderx8":1,"myreaderx27":1,"myreaderx6":1,"myreaderx16":1,"myreaderx10":1,"myreaderx21":1,"myreaderx22":1,"myreaderx3":1,"myreaderx2":1,"myreaderx1":1,"myreaderx30":1,"myreaderx18":1,"myreaderx29":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{"myreaderx14":1,"myreaderx23":1}},"feed":{"createdTime":"2020-09-07 03:35:00","updatedTime":"2020-09-07 05:53:01","id":44525,"name":"WEB VIEW","url":"https://webview.tech/feed/","subscriber":72,"website":null,"icon":"http://webview.tech/wp-content/uploads/2019/01/podcast_logo.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx65/cdn71@2020_1/2020/09/06/21-52-51-825_ac31a805bd625017.png","description":"不囿于 WEB，不止于 VIEW","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2020-11-16 18:28:21","updatedTime":"2020-11-16 18:28:21","id":null,"feedId":44525,"linkMd5":"87eba696d05b8c8619bcf2401fc67784"}],"tmpCommonImgCdnBytes":83766,"tmpBodyImgCdnBytes":1858080,"tmpBgImgCdnBytes":0,"extra4":{"start":1605522343758,"total":0,"statList":[{"spend":2108,"msg":"获取xml内容"},{"spend":45,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":151530,"msg":"正文链接上传到cdn"}]},"extra5":18,"extra6":17,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044030.png","sourceStatusCode":200,"destWidth":1352,"destHeight":412,"sourceBytes":41189,"destBytes":38830,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":2601,"convertSpendMs":19,"createdTime":"2020-11-16 18:25:50","host":"us-54*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn74/contents/2020/11/16/10-25-52-570_afbbad82b101f667.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 16 Nov 2020 10:25:52 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["EA7C:0EA7:270805E:3FD2A94:5FB253A5"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1605524975"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn74/contents/2020/11/16/10-25-52-570_afbbad82b101f667.webp","historyStatusCode":[],"spendMs":52},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"37.9 KB","compressRate":"94.3%","sourceSize":"40.2 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044024.png","sourceStatusCode":200,"destWidth":695,"destHeight":367,"sourceBytes":12748,"destBytes":29748,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":3604,"convertSpendMs":19,"createdTime":"2020-11-16 18:25:50","host":"us-010*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn3/contents/2020/11/16/10-25-53-547_139def91df58e419.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 16 Nov 2020 10:25:53 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["85E4:1AB7:13E41FC:2ED04E9:5FB25397"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1605525006"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn3/contents/2020/11/16/10-25-53-547_139def91df58e419.webp","historyStatusCode":[],"spendMs":47},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"29.1 KB","compressRate":"233.4%","sourceSize":"12.4 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044024.png","sourceStatusCode":200,"destWidth":695,"destHeight":367,"sourceBytes":12748,"destBytes":29748,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":1214,"convertSpendMs":17,"createdTime":"2020-11-16 18:25:53","host":"us-010*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn3/contents/2020/11/16/10-25-54-800_139def91df58e419.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 16 Nov 2020 10:25:54 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["85E4:1AB7:13E4270:2ED1622:5FB253B1"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1605525006"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn3/contents/2020/11/16/10-25-54-800_139def91df58e419.webp","historyStatusCode":[],"spendMs":56},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"29.1 KB","compressRate":"233.4%","sourceSize":"12.4 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044030.png","sourceStatusCode":200,"destWidth":1352,"destHeight":412,"sourceBytes":41189,"destBytes":38830,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":2481,"convertSpendMs":31,"createdTime":"2020-11-16 18:25:52","host":"us-54*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn74/contents/2020/11/16/10-25-55-020_afbbad82b101f667.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 16 Nov 2020 10:25:55 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["8CD8:3050:25D690E:3F1117E:5FB253B2"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1605524975"],"x-ratelimit-used":["60"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn74/contents/2020/11/16/10-25-55-020_afbbad82b101f667.webp","historyStatusCode":[],"spendMs":93},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"37.9 KB","compressRate":"94.3%","sourceSize":"40.2 KB"},null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-018.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-24.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-007.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe66.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-015.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-022.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-011.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-54.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe62.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-019.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-57.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-010.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-003.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-027.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044018.png","sourceStatusCode":200,"destWidth":1645,"destHeight":862,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn37@2020_1/2020/11/16/10-25-48-971_56db67228a6b8d44.webp","sourceBytes":223782,"destBytes":83766,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":4060,"convertSpendMs":66,"createdTime":"2020-11-16 18:25:45","host":"us-023*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784,87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"81.8 KB","compressRate":"37.4%","sourceSize":"218.5 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044033.png","sourceStatusCode":200,"destWidth":1146,"destHeight":476,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn65@2020_4/2020/11/16/10-25-52-806_b603b855bec445b7.webp","sourceBytes":44672,"destBytes":35494,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":3635,"convertSpendMs":19,"createdTime":"2020-11-16 18:25:50","host":"us-003*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"34.7 KB","compressRate":"79.5%","sourceSize":"43.6 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044034.png","sourceStatusCode":200,"destWidth":886,"destHeight":257,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn61@2020_5/2020/11/16/10-25-52-855_8eccda2ff462f42d.webp","sourceBytes":20846,"destBytes":30014,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":3661,"convertSpendMs":24,"createdTime":"2020-11-16 18:25:50","host":"us-015*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"29.3 KB","compressRate":"144%","sourceSize":"20.4 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044027.png","sourceStatusCode":200,"destWidth":1647,"destHeight":962,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn58@2020_2/2020/11/16/10-25-52-879_5565ecaf864830ed.webp","sourceBytes":114437,"destBytes":83786,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":3822,"convertSpendMs":80,"createdTime":"2020-11-16 18:25:50","host":"us-027*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"81.8 KB","compressRate":"73.2%","sourceSize":"111.8 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044036.png","sourceStatusCode":200,"destWidth":1115,"destHeight":817,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn49@2020_6/2020/11/16/10-25-52-674_7d4aa9168abae576.webp","sourceBytes":77435,"destBytes":47892,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":3722,"convertSpendMs":33,"createdTime":"2020-11-16 18:25:50","host":"europe62*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"46.8 KB","compressRate":"61.8%","sourceSize":"75.6 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044022.png","sourceStatusCode":200,"destWidth":1500,"destHeight":846,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn78@2020_5/2020/11/16/10-25-53-137_8babe0c374f65c94.webp","sourceBytes":280013,"destBytes":66708,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":4022,"convertSpendMs":67,"createdTime":"2020-11-16 18:25:50","host":"us-018*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"65.1 KB","compressRate":"23.8%","sourceSize":"273.5 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044032.png","sourceStatusCode":200,"destWidth":1305,"destHeight":716,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn69@2020_4/2020/11/16/10-25-52-963_dafb983739bd6a7f.webp","sourceBytes":68519,"destBytes":74358,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":4105,"convertSpendMs":32,"createdTime":"2020-11-16 18:25:50","host":"europe66*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"72.6 KB","compressRate":"108.5%","sourceSize":"66.9 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044039.png","sourceStatusCode":200,"destWidth":748,"destHeight":884,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn99@2020_5/2020/11/16/10-25-53-439_95eaaedcaefccf6c.webp","sourceBytes":402505,"destBytes":61796,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":4446,"convertSpendMs":35,"createdTime":"2020-11-16 18:25:50","host":"us-022*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"60.3 KB","compressRate":"15.4%","sourceSize":"393.1 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044029.png","sourceStatusCode":200,"destWidth":1357,"destHeight":408,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn41@2020_6/2020/11/16/10-25-53-619_ecc99aa75b6e9097.webp","sourceBytes":41555,"destBytes":36206,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":4564,"convertSpendMs":31,"createdTime":"2020-11-16 18:25:50","host":"us-011*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"35.4 KB","compressRate":"87.1%","sourceSize":"40.6 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044025.png","sourceStatusCode":200,"destWidth":686,"destHeight":391,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn89@2020_2/2020/11/16/10-25-53-857_07abdebc7b525837.webp","sourceBytes":15903,"destBytes":15228,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":4717,"convertSpendMs":16,"createdTime":"2020-11-16 18:25:50","host":"us-011*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"14.9 KB","compressRate":"95.8%","sourceSize":"15.5 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044026.png","sourceStatusCode":200,"destWidth":1152,"destHeight":907,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn92@2020_5/2020/11/16/10-25-53-916_9202922d86394b8d.webp","sourceBytes":139103,"destBytes":88732,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":5176,"convertSpendMs":45,"createdTime":"2020-11-16 18:25:50","host":"europe-57*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"86.7 KB","compressRate":"63.8%","sourceSize":"135.8 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044035.png","sourceStatusCode":200,"destWidth":750,"destHeight":1624,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn54@2020_1/2020/11/16/10-25-54-512_37b007144c8e9e02.webp","sourceBytes":519848,"destBytes":88324,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":5458,"convertSpendMs":56,"createdTime":"2020-11-16 18:25:50","host":"us-040*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"86.3 KB","compressRate":"17%","sourceSize":"507.7 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044037.gif","sourceStatusCode":200,"destWidth":665,"destHeight":958,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_1/2020/11/16/10-25-54-649_646d8b2ee7777b15.webp","sourceBytes":110201,"destBytes":85134,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":5574,"convertSpendMs":1870,"createdTime":"2020-11-16 18:25:50","host":"us-007*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"83.1 KB","compressRate":"77.3%","sourceSize":"107.6 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044035.gif","sourceStatusCode":200,"destWidth":813,"destHeight":958,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn96@2020_5/2020/11/16/10-25-56-523_c112d7e78c186e6e.webp","sourceBytes":125735,"destBytes":85924,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":7474,"convertSpendMs":2187,"createdTime":"2020-11-16 18:25:50","host":"us-034*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"83.9 KB","compressRate":"68.3%","sourceSize":"122.8 KB"},{"code":1,"isDone":false,"source":"https://podcast.webview.tech/podblog/2020-02-23-044038.gif","sourceStatusCode":200,"destWidth":665,"destHeight":958,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn79@2020_3/2020/11/16/10-25-58-879_94e47d6a7924026d.webp","sourceBytes":676934,"destBytes":1058484,"targetWebpQuality":75,"feedId":44525,"totalSpendMs":10168,"convertSpendMs":5050,"createdTime":"2020-11-16 18:25:50","host":"us-019*","referer":"https://webview.tech/?p=1712","linkMd5ListStr":"87eba696d05b8c8619bcf2401fc67784","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"destSize":"1 MB","compressRate":"156.4%","sourceSize":"661.1 KB"}],"successGithubMap":{"myreaderx8":1,"myreaderx27":1,"myreaderx6":1,"myreaderx16":1,"myreaderx10":1,"myreaderx21":1,"myreaderx22":1,"myreaderx3":1,"myreaderx2":1,"myreaderx1":1,"myreaderx30":1,"myreaderx18":1,"myreaderx29":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{"myreaderx14":1,"myreaderx23":1}}