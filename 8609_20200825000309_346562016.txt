{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"4 Tips to Make Your Shiny Dashboard Faster","link":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/","description":"<figure> \n <img src=\"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/shiny-comparisons.gif\" alt=\"Fast versus slow Shiny app\" /> \n <figcaption>\n  A slow-running Shiny application (left) and an optimized one (right)\n </figcaption> \n</figure> \n<p><em>This is a guest post from RStudio’s partner, <a href=\"https://appsilon.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Appsilon Data Science</a></em></p> \n<p>When developing Shiny applications, we at Appsilon strive to implement functionality, enhance appearance, and optimize the user’s experience. However, we often forget about one of the most important elements of UX: the speed of the application. Nobody wants to use a slow application that takes seconds (or minutes) to load or navigate. In this article, I will share four tips and best practices that will help your Shiny applications run much faster. Those tips are:</p> \n<ol> \n <li>Figure out why your Shiny app is running slowly</li> \n <li>Use faster functions</li> \n <li>Pay attention to scoping rules for Shiny apps</li> \n <li>Use caching operations</li> \n</ol> \n<p>The theme underlying these tips can be summed up by this quote:</p> \n<blockquote>\n <p> \"The reason for Shiny's slow action [is] usually not Shiny.\" - Winston Chang </p>\n</blockquote> \n<h3 id=\"1-measure-where-your-shiny-app-is-spending-its-time\">1. Measure Where Your Shiny App Is Spending Its Time</h3> \n<p>With R, we can find some very useful solutions for verifying which parts of our code are less effective. One of my favorite tools is the <em>profvis</em> package, whose output is shown below:</p> \n<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/profvis_huf2899d6f70360f0ff36bef024ea46923_131651_728x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/profvis.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/profvis.jpg\" width=\"728\" alt=\"Profvis screenshot\" /> \n </div> \n <br /> A timing measurement created by the \n <em>profvis</em> package \n</figure> \n<p>Profvis allows you to measure the execution time and R memory consumption of R code. The package itself can generate a readable report that helps us identify inefficient parts of the code, and it can be used to test Shiny applications. You can see profvis in action <a href=\"https://rstudio.com/resources/shiny-dev-con/profiling/\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p> \n<p>If we are only interested in measuring a code fragment rather than a complete application, we may want to consider simpler tools such as the <em>tictoc</em> package, which measures the time elapsed to run a particular code fragment.</p> \n<h3 id=\"2-use-faster-functions\">2. Use Faster Functions</h3> \n<p>Once you’ve profiled your application, take a hard look at the functions consuming the most time. You may achieve significant performance gains by replacing the functions you routinely use with faster alternatives.</p> \n<p>For example, a Shiny app might search a large vector of strings for ones starting with the characters “an”. Most R programmers would use a function such as <code>grepl</code> as shown below:</p> \n<pre><code>  grepl(\"^an\", cnames),\n</code></pre> \n<p>However, we don’t need the regular expression capabilities of grepl to find strings starting with a fixed pattern. We can tell grepl not to bother with regular expressions by adding the parameter <code>fixed = TRUE</code>. Even better, though, is to use the base R function <code>startsWith</code>. As you can see from the benchmarks below, both options are faster than the original grepl, but the simpler startsWith function performs the search more than 30 times faster.</p> \n<pre><code>microbenchmark::microbenchmark(\n  grepl(\"an\", cnames),\n  grepl(\"an\", cnames, fixed = TRUE)\n  startsWith(cnames, \"an\")\n)\n\nUnit: microseconds\n                              expr      min        lq       mean   median       uq      max neval\n grepl(\"an\", cnames)               2046.846 2057.7725 2082.44583 2067.474 2089.499 2449.035   100\n grepl(\"an\", cnames, fixed = TRUE) 1127.246 1130.7440 1146.35229 1132.597 1136.032 1474.634   100\n startsWith(cnames, \"an\")            62.982   63.2485   64.47847   63.548   64.155   79.528   100\n</code></pre> \n<p>Similarly, consider the following expressions:</p> \n<pre><code>sum_value &lt;- 0\nfor (i in 1:100) {\n  sum_value &lt;- sum_value + i ^ 2\n}\n</code></pre> \n<p>versus</p> \n<pre><code>sum_value &lt;- sum((1:100) ^ 2)\n</code></pre> \n<p>Even a novice R programmer would likely use the second version because it takes advantage of the vectorized function <code>sum</code>.</p> \n<p>When we create more complex functions for our Shiny apps, we should similarly look for vectorized operations to use instead of loops whenever possible. For example, the following code does a simple computation on two columns in a long data frame:</p> \n<pre><code>frame &lt;- data.frame (col1 = runif (10000, 0, 2),\n                     col2 = rnorm (10000, 0, 2))\n\n  for (i in 1:nrow(frame)) {\n    if (frame[i, 'col1'] + frame[i, 'col2'] &gt; 1) {\n      output[i] &lt;- \"big\"\n    } else {\n      output[i] &lt;- \"small\"\n    }\n  }\n\n</code></pre> \n<p>However, an equivalent output can be obtained much faster by using <code>ifelse</code> which is a vectorized function:</p> \n<pre><code>  output &lt;- ifelse(frame$col1 + frame$col2 &gt; 1, \"big\", \"small\")\n</code></pre> \n<p>This vectorized version is easier to read and computes the same result about 100 times faster.</p> \n<h3 id=\"3-pay-attention-to-object-scoping-rules-in-shiny-apps\">3. Pay Attention to Object Scoping Rules in Shiny Apps</h3> \n<ol> \n <li><strong>Global</strong>: Objects in global.R are loaded into R’s global environment. They persist even after an app stops. This matters in a normal R session, but not when the app is deployed to Shiny Server or Connect. To learn more about how to scale Shiny applications to thousands of users on RStudio Connect, <a href=\"https://support.rstudio.com/hc/en-us/articles/231874748-Scaling-and-Performance-Tuning-in-RStudio-Connect\" target=\"_blank\" rel=\"noopener noreferrer\">this recent article</a> has some excellent tips.</li> \n <li><strong>Application-level:</strong> Objects defined in app.R outside of the <code>server</code> function are similar to global objects, except that their lifetime is the same as the app; when the app stops, they go away. These objects can be shared across all Shiny sessions served by a single R process and may serve multiple users.</li> \n <li><strong>Session-level:</strong> Objects defined within the <code>server</code> function are accessible only to one user session.</li> \n</ol> \n<p>In general, the best practice is:</p> \n<ul> \n <li>Create objects that you wish to be shared among all users of the Shiny application in the global or app-level scopes (e.g., loading data that users will share).</li> \n <li>Create objects that you wish to be private to each user as session-level objects (e.g., generating a user avatar or displaying session settings).</li> \n</ul> \n<h3 id=\"4-use-caching-operations\">4. Use Caching Operations</h3> \n<p>If you’ve used all of the previous tips and your application still runs slowly, it’s worth considering implementing caching operations. In 2018, RStudio introduced the ability to <a href=\"https://blog.rstudio.com/2018/11/13/shiny-1-2-0/\" target=\"_blank\" rel=\"noopener noreferrer\">cache charts</a> in the Shiny package. However, if you want to speed up repeated operations other than generating graphs, it is worth using a custom caching solution.</p> \n<p>One of my favorite packages that I use for this case is <a href=\"https://cran.r-project.org/web/packages/memoise/\" target=\"_blank\" rel=\"noopener noreferrer\">memoise</a>. Memoise saves the results of new invocations of functions while reusing the answers from previous invocations of those functions.</p> \n<p>The <code>memoise</code> package currently offers 3 methods for storing cached objects:</p> \n<ol> \n <li><code>cache_mem</code> - storing cache in RAM (default)</li> \n <li><code>cache_filesystem(path)</code> - storing cache on the local disk</li> \n <li><code>cache_s3(s3_bucket)</code> - storage in the AWS S3 file database</li> \n</ol> \n<p>The selected caching type is defined by the <code>cache</code> parameter in the <code>memoise</code> function.</p> \n<p>If our Shiny application is served by a single R process and its RAM consumption is low, the simplest method is to use the first option, cache_mem, where the target function is defined and its answers cached in the global environment in RAM. All users will then use shared cache results, and the actions of one user will speed up the calculations of others. You can see a simple example below:</p> \n<pre><code>library(memoise)\n\n# Define an example expensive to calculate function\nexpensive_function &lt;- function(x) {\n    sum((1:x) ^ 2)\n    Sys.sleep(5)    # make it seem to take even longer\n  }\n\nsystem.time(expensive_function(1000)) # Takes at least 5 seconds\n    user  system elapsed \n  0.013   0.016   5.002 \nsystem.time(expensive_function(1000)) # Still takes at least 5 seconds\n   user  system elapsed \n  0.016   0.015   5.005 \n\n# Now, let's cache results using memoise and its default cache_memory\n\nmemoised_expensive_function &lt;- memoise(expensive_function)\nsystem.time(memoised_expensive_function(1000)) # Takes at least 5 seconds\n   user  system elapsed \n  0.016   0.015   5.001 \nsystem.time(memoised_expensive_function(1000)) # Returns much faster\n   user  system elapsed \n  0.015   0.000   0.015 \n</code></pre> \n<p>The danger associated with using in-memory caching, however, is that if you don’t manage the cached results, it will grow without bound and your Shiny application will eventually run out of memory. You can manage the cached results using the <code>timeout</code> and <code>forget</code> functions.</p> \n<p>If the application is served by many processes running on one server, the best option to ensure cache sharing among all users is to use <code>cache_filesystem</code> and store objects locally on the disk. Again, you will want to manage the cache, but you will be limited only by your available disk space.</p> \n<p>In the case of an extensive infrastructure using many servers, the easiest method will be to use <code>cache_s3</code> which will store its cached values on a shared external file system – in this case, AWS S3.</p> \n<hr /> \n<p><strong>About Appsilon Data Science:</strong></p> \n<p><a href=\"https://appsilon.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/appsilon-logo.png\" alt=\"Appsilon logo\" align=\"left\" /></a> One of the winners of the <a href=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/\" target=\"_blank\" rel=\"noopener noreferrer\">2020 Shiny Contest</a> and a <a href=\"https://rstudio.com/certified-partners/\" target=\"_blank\" rel=\"noopener noreferrer\">Full Service RStudio Partner</a>, <a href=\"https://appsilon.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Appsilon</a> delivers enterprise Shiny apps, data science and machine learning consulting, and support with R and Python for customers all around the world.</p>","descriptionType":"text/html","publishedDate":"Tue, 21 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/shiny-comparisons.gif","linkMd5":"3e8ea12a54ace5c7aa2029a4096a28c0","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn61@2020_2/2020/08/25/00-02-52-883_da2eaa486e9b4065.webp","destWidth":1600,"destHeight":402,"sourceBytes":3153719,"destBytes":1998116,"author":"Krystian Igras, Appsilon Data Science","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/shiny-comparisons.gif":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn61@2020_2/2020/08/25/00-02-52-883_da2eaa486e9b4065.webp","https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/profvis.jpg":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn57@2020_5/2020/08/25/00-02-55-124_1e01418265c26d41.webp","https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/appsilon-logo.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn53@2020_2/2020/08/25/00-02-55-995_18820f668146d434.webp"},"publishedOrCreatedDate":1598313739860},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"RStudio 1.3 Released","link":"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/","description":"<img srcset=\"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/rstudio-1-3-screenshot_huf92451e5dbf14521dba579c6c38a2a93_1008693_1167x0_resize_box_2.png, https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/rstudio-1-3-screenshot.png 2x\" src=\"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/rstudio-1-3-screenshot.png\" width=\"1167\" alt=\"Screenshot of RStudio 1.3 showing a few of the new features.\" /> \n<p>Today we’re excited to announce the general release of RStudio 1.3. This release features many major improvements to the IDE, including:</p> \n<ul> \n <li>Dramatically improved <strong>accessibility</strong> for sight-impaired users, which also upgrades keyboard navigation, contrast ratios, and visibility for everyone.</li> \n <li>A real-time <strong>spell-checking engine</strong>, with suggestions, customizable dictionaries, and a built-in whitelist for common data science terms.</li> \n <li>Extensible, in-IDE <strong>tutorials</strong> powered by the <a href=\"https://rstudio.github.io/learnr/\"><code>learnr</code> package</a>.</li> \n <li><strong>Settings and preferences</strong> are now stored in plain text files you can back up or manage with other tools; they can also be applied globally to all users on an RStudio Server.</li> \n <li>Improved compatibility with <strong>R 4.0</strong> and <strong>iPad OS 13.1</strong>.</li> \n <li>Many improvements to <strong>RStudio Server security</strong>, including idle timeouts and hardening against common types of attacks.</li> \n <li>Dozens of small productivity improvements, including <strong>autosave</strong>, <strong>global replace</strong>, <strong>customizable file templates</strong>, <strong>Shiny jobs</strong>, and more.</li> \n</ul> \n<p>If you’ve purchased the Professional version of RStudio, this release also has some new capabilities for you:</p> \n<ul> \n <li><strong>RStudio Desktop Pro</strong> can now function as a client for RStudio Server Pro; run your R session on your server with the convenience of native desktop windows and menus.</li> \n <li>A new <strong>user manager</strong> on the Admin Dashboard makes it easy to manage licensed users on RStudio Server Pro.</li> \n <li>Many small improvements to the <strong>Kubnernetes</strong> and <strong>Slurm</strong> Job Launcher plugins.</li> \n</ul> \n<p>See our <a href=\"https://blog.rstudio.com/categories/rstudio-ide\">blog series on RStudio 1.3</a> for articles describing a selection of the new capabilities in detail, and the <a href=\"https://rstudio.com/products/rstudio/release-notes/\">RStudio 1.3 Release Notes</a> for a comprehensive list of features and bugfixes in this release.</p> \n<p>A special thanks to <a href=\"https://www.massey.ac.nz/massey/expertise/profile.cfm?stref=416430\">Dr Jonathan Godfrey</a> and <a href=\"https://www.jooyoungseo.com/\">JooYoung Seo</a> for their insight into the new accessibility features, and to the hundreds of community members who helped us shape this release with their ideas, bugfixes, and contributions. We couldn’t do this without you! Please <a href=\"https://rstudio.com/products/rstudio/download/\">download the new release</a> and let us know what you think on our <a href=\"https://community.rstudio.com/c/rstudio-ide\">community forum</a>.</p>","descriptionType":"text/html","publishedDate":"Wed, 27 May 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"68af3705d621c6d14c73a2f713059404","bgimgJsdelivr":"","metaImg":"","author":"Jonathan McPherson","articleImgCdnMap":{"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/rstudio-1-3-screenshot.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn89@2020_6/2020/08/25/00-02-55-857_b14a64c7a26e73e0.webp"},"publishedOrCreatedDate":1598313739858},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"sparklyr 1.2: Foreach, Spark 3.0 and Databricks Connect","link":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/","description":"<p><img src=\"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-sparklyr.png\" style=\"display: none\" alt=\"sparklyr ascii art\" /></p> \n<p>A new version of <a href=\"https://sparklyr.ai\"><code>sparklyr</code></a> is now available on CRAN! In this <code>sparklyr 1.2</code> release, the following new improvements have emerged into spotlight:</p> \n<ul> \n <li>A <code>registerDoSpark()</code> method to create a <a href=\"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/#foreach\"><code>foreach</code></a> parallel backend powered by Spark that enables hundreds of existing R packages to run in Spark.</li> \n <li>Support for <a href=\"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/#databricks-connect\">Databricks Connect</a>, allowing <code>sparklyr</code> to connect to remote Databricks clusters.</li> \n <li>Improved support for Spark <a href=\"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/#structures\">structures</a> when collecting and querying their nested attributes with <code>dplyr</code>.</li> \n</ul> \n<p>A number of inter-op issues observed with <code>sparklyr</code> and the Spark 3.0 preview were also addressed recently, in hope that by the time Spark 3.0 officially graces us with its presence, <code>sparklyr</code> will be fully ready to work with it. Most notably, key features such as <code>spark_submit()</code>, <code>sdf_bind_rows()</code>, and standalone connections are now finally working with Spark 3.0 preview.</p> \n<p>To install <code>sparklyr</code> 1.2 from CRAN run,</p> \n<pre><code class=\"language-r\">install.packages(\"sparklyr\")\n</code></pre> \n<p>The full list of changes are available in the <code>sparklyr</code> <a href=\"https://github.com/sparklyr/sparklyr/blob/master/NEWS.md\">NEWS</a> file.</p> \n<h2 id=\"foreach\">Foreach</h2> \n<p>The <a href=\"https://CRAN.R-project.org/package=foreach\"><code>foreach</code></a> package provides the <code>%dopar%</code> operator to iterate over elements in a collection in parallel. Using <code>sparklyr</code> 1.2, you can now register Spark as a backend using <code>registerDoSpark()</code> and then easily iterate over R objects using Spark:</p> \n<pre><code class=\"language-r\">library(sparklyr)\nlibrary(foreach)\nsc &lt;- spark_connect(master = \"local\", version = \"2.4\")\nregisterDoSpark(sc)\nforeach(i = 1:3, .combine = 'c') %dopar% {\n  sqrt(i)\n}\n</code></pre> \n<pre><code>[1] 1.000000 1.414214 1.732051\n</code></pre> \n<p>Since many R packages are based on <code>foreach</code> to perform parallel computation, we can now make use of all those great packages in Spark as well!</p> \n<p>For instance, we can use <a href=\"https://tidymodels.github.io/parsnip/\"><code>parsnip</code></a> and the <a href=\"https://tidymodels.github.io/tune/\"><code>tune</code></a> package with data from <a href=\"https://CRAN.R-project.org/package=mlbench\"><code>mlbench</code></a> to perform hyperparameter tuning in Spark with ease:</p> \n<pre><code class=\"language-r\">library(tune)\nlibrary(parsnip)\nlibrary(mlbench)\ndata(Ionosphere)\nsvm_rbf(cost = tune(), rbf_sigma = tune()) %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"kernlab\") %&gt;%\n  tune_grid(Class ~ .,\n    resamples = rsample::bootstraps(dplyr::select(Ionosphere, -V2), times = 30),\n    control = control_grid(verbose = FALSE))\n</code></pre> \n<pre><code># Bootstrap sampling\n# A tibble: 30 x 4\n   splits            id          .metrics          .notes\n * &lt;list&gt;            &lt;chr&gt;       &lt;list&gt;            &lt;list&gt;\n 1 &lt;split [351/124]&gt; Bootstrap01 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 2 &lt;split [351/126]&gt; Bootstrap02 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 3 &lt;split [351/125]&gt; Bootstrap03 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 4 &lt;split [351/135]&gt; Bootstrap04 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 5 &lt;split [351/127]&gt; Bootstrap05 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 6 &lt;split [351/131]&gt; Bootstrap06 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 7 &lt;split [351/141]&gt; Bootstrap07 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 8 &lt;split [351/123]&gt; Bootstrap08 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n 9 &lt;split [351/118]&gt; Bootstrap09 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n10 &lt;split [351/136]&gt; Bootstrap10 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;\n# … with 20 more rows\n</code></pre> \n<p>The Spark connection was already registered, so the code ran in Spark without any additional changes. We can verify that this was the case by navigating to the Spark web interface:</p> \n<p><img src=\"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-spark-backend-foreach-package.png\" alt=\"Spark running foreach package using sparklyr\" /></p> \n<h2 id=\"databricks-connect\">Databricks Connect</h2> \n<p><a href=\"https://docs.databricks.com/dev-tools/databricks-connect.html\">Databricks Connect</a> allows you to connect your favorite IDE (like <a href=\"https://rstudio.com/products/rstudio/download/\">RStudio</a>!) to a Spark <a href=\"https://databricks.com/\">Databricks</a> cluster.</p> \n<p>You will first have to install the <code>databricks-connect</code> Python package as described in our <a href=\"https://github.com/sparklyr/sparklyr#connecting-through-databricks-connect\">README</a> and start a Databricks cluster, but once that’s ready, connecting to the remote cluster is as easy as running:</p> \n<pre><code class=\"language-r\">sc &lt;- spark_connect(\n  method = \"databricks\",\n  spark_home = system2(\"databricks-connect\", \"get-spark-home\", stdout = TRUE))\n</code></pre> \n<p><img src=\"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-spark-databricks-connect-rstudio.png\" alt=\"Databricks Connect with RStudio Desktop\" /></p> \n<p>That’s about it, you are now remotely connected to a Databricks cluster from your local R session.</p> \n<h2 id=\"structures\">Structures</h2> \n<p>If you previously used <code>collect()</code> to deserialize structurally complex Spark data frames into their equivalents in R, you likely have noticed that Spark SQL struct columns were only mapped into JSON strings in R, which was non-ideal. You might also have run into a much dreaded <code>java.lang.IllegalArgumentException: Invalid type list</code> error when using <code>dplyr</code> to query nested attributes from any struct column of a Spark data frame in <code>sparklyr</code>.</p> \n<p>Unfortunately, often times in real-world Spark use cases, data describing entities comprised of sub-entities (e.g., a product catalog of all hardware components of some computers) needs to be denormalized / shaped in an object-oriented manner in the form of Spark SQL structs to allow efficient read queries. When <code>sparklyr</code> had the limitations mentioned above, users often had to invent their own workarounds when querying Spark struct columns, which explained why there was a mass popular demand for <code>sparklyr</code> to have better support for such use cases.</p> \n<p>The good news is with <code>sparklyr</code> 1.2, those limitations no longer exist when working running with Spark 2.4 or above.</p> \n<p>As a concrete example, consider the following catalog of computers:</p> \n<pre><code class=\"language-r\">library(dplyr)\ncomputers &lt;- tibble::tibble(\n  id = seq(1, 2),\n  attributes = list(\n    list(\n      processor = list(freq = 2.4, num_cores = 256),\n      price = 100\n   ),\n   list(\n     processor = list(freq = 1.6, num_cores = 512),\n     price = 133\n   )\n  )\n)\ncomputers &lt;- copy_to(sc, computers, overwrite = TRUE)\n</code></pre> \n<p>A typical <code>dplyr</code> use case involving <code>computers</code> would be the following:</p> \n<pre><code class=\"language-r\">high_freq_computers &lt;- computers %&gt;%\n                       filter(attributes.processor.freq &gt;= 2) %&gt;%\n                       collect()\n</code></pre> \n<p>As previously mentioned, before <code>sparklyr</code> 1.2, such query would fail with <code>Error: java.lang.IllegalArgumentException: Invalid type list</code>.</p> \n<p>Whereas with <code>sparklyr</code> 1.2, the expected result is returned in the following form:</p> \n<pre><code># A tibble: 1 x 2\n     id attributes\n  &lt;int&gt; &lt;list&gt;\n1     1 &lt;named list [2]&gt;\n</code></pre> \n<p>where <code>high_freq_computers$attributes</code> is what we would expect:</p> \n<pre><code>[[1]]\n[[1]]$price\n[1] 100\n[[1]]$processor\n[[1]]$processor$freq\n[1] 2.4\n[[1]]$processor$num_cores\n[1] 256\n</code></pre> \n<h2 id=\"and-more\">And More!</h2> \n<p>Last but not least, we heard about a number of pain points <code>sparklyr</code> users have run into, and have addressed many of them in this release as well. For example:</p> \n<ul> \n <li>Date type in R is now correctly serialized into Spark SQL date type by <code>copy_to()</code></li> \n <li><code>&lt;spark dataframe&gt; %&gt;% print(n = 20)</code> now actually prints 20 rows as expected instead of 10</li> \n <li><code>spark_connect(master = \"local\")</code> will emit a more informative error message if it’s failing because the loopback interface is not up</li> \n</ul> \n<p>… to name just a few. We want to thank the open source community for their continuous feedback on <code>sparklyr</code>, and are looking forward to incorporating more of that feedback to make <code>sparklyr</code> even better in the future.</p> \n<p>Finally, in chronological order, we wish to thank the following individuals for contributing to <code>sparklyr</code> 1.2: <a href=\"https://github.com/zero323\">zero323</a>, <a href=\"https://github.com/Loquats\">Andy Zhang</a>, <a href=\"https://github.com/yl790\">Yitao Li</a>, <a href=\"https://github.com/javierluraschi\">Javier Luraschi</a>, <a href=\"https://github.com/falaki\">Hossein Falaki</a>, <a href=\"https://github.com/lu-wang-dl\">Lu Wang</a>, <a href=\"https://github.com/samuelmacedo83\">Samuel Macedo</a> and <a href=\"https://github.com/jozefhajnala\">Jozef Hajnala</a>. Great job everyone!</p> \n<p>If you need to catch up on <code>sparklyr</code>, please visit <a href=\"https://sparklyr.ai\">sparklyr.ai</a>, <a href=\"https://spark.rstudio.com\">spark.rstudio.com</a>, or some of the previous release posts: <a href=\"https://blog.rstudio.com/2020/01/29/sparklyr-1-1/\">sparklyr 1.1</a> and <a href=\"https://blog.rstudio.com/2019/03/15/sparklyr-1-0/\">sparklyr 1.0</a>.</p> \n<p>Thank you for reading this post.</p> \n<p>This post was originally published on <a href=\"https://blogs.rstudio.com/ai/\">blogs.rstudio.com/ai/</a></p>","descriptionType":"text/html","publishedDate":"Wed, 06 May 2020 00:00:00 +0000","feedId":8609,"bgimg":"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-sparklyr.png","linkMd5":"f18dd3380e238f6c89cf75f4ef0cb37f","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn56@2020_2/2020/08/25/00-02-24-853_a3289d5e6ee4ffa8.webp","destWidth":354,"destHeight":303,"sourceBytes":3509,"destBytes":3200,"author":"Yitao Li","articleImgCdnMap":{"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-sparklyr.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn56@2020_2/2020/08/25/00-02-24-853_a3289d5e6ee4ffa8.webp","https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-spark-backend-foreach-package.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn73@2020_4/2020/08/25/00-02-55-186_b453efcca0d4472f.webp","https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-spark-databricks-connect-rstudio.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn74@2020_5/2020/08/25/00-02-57-376_ff54fab90e75d489.webp"},"publishedOrCreatedDate":1598313739860},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"RStudio and COVID-19","link":"https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/","description":"<div align=\"center\" style=\"padding-top: 35px;\"> \n <img srcset=\"https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/covid-19-map_huf3e7474723f6c687c1c505214994b814_357640_1200x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/covid-19-map.jpg 2x\" src=\"https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/covid-19-map.jpg\" width=\"1200\" alt=\"A map of the United States with COVID-19 data\" /> \n</div> \n<p>As we’re all aware, the impact of the current global pandemic has been significant. We know that many in the R community are involved in the response, and we want to help out where we can.</p> \n<h2 id=\"shinyapps-io\">shinyapps.io</h2> \n<p>If you are using R and Shiny to analyse or visualise COVID-19 data and want an easy way to share your work with others, we’d like to offer you six months of free basic hosting on <a href=\"http://shinyapps.io/\">shinyapps.io</a>. This will enable you to share your app widely without having to worry about the number of compute hours (basic accounts are usually limited to 500 compute hours per month, but we won’t enforce that limit on these apps). Just use the discount code <code>COVID_DISCOUNT_2020_BASIC</code> when you sign up or upgrade (the coupon must be redeemed before June 1).</p> \n<p>Due to a limitation in our system, you will need a credit card on file to take advantage of the discount. We know this is a hassle, but we won’t charge your card for the first six months, and we’ll send out an email reminder before the coupon expires so you can downgrade back to the free plan. (You can learn more about upgrades and downgrades in the <a href=\"https://docs.rstudio.com/shinyapps.io/billing-and-account-management.html#invoices-payments\">shinyapps.io user’s guide</a>.)</p> \n<p>If you’d like access to the Standard plan for hosting (e.g., you need authentication so you can share data only within your hospital), please get in touch with <a href=\"https://support.rstudio.com/hc/en-us/requests/new\">Support</a> and we’ll do our best to help out.</p> \n<h2 id=\"professional-products\">Professional products</h2> \n<p>We don’t want access to our commercial products to gate your COVID-19 academic research. If your <a href=\"https://rstudio.com/pricing/academic-pricing/\">qualified academic research group</a> could substantially benefit from <a href=\"https://rstudio.com/products/connect/\">RStudio Connect</a>, <a href=\"https://rstudio.com/products/rstudio/#rstudio-server\">RStudio Server Pro</a>, or <a href=\"https://rstudio.com/products/package-manager/\">RStudio Package Manager</a>, we may be able to offer additional discounts on an annual plan or free access for 6 months. Please contact <a href=\"mailto:info@rstudio.com\">info@rstudio.com</a> for more details.</p> \n<h2 id=\"other-r-help\">Other R help</h2> \n<p>Are you a COVID-19-focussed research group that needs a little help with R programming (whether it be data analysis, app development, or package construction)? We obviously can’t help everyone, but our engineers would love to help out where possible. If you have pressing R development needs, <a href=\"https://community.rstudio.com/w/covid-help\">please fill out this form</a>. The posts created via this form will be posted publicly on RStudio Community and our engineers and sustainers will be monitoring the forum regularly.</p>","descriptionType":"text/html","publishedDate":"Fri, 17 Apr 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"094b8d65098dc7eb1d45365ae5abcd8a","bgimgJsdelivr":"","metaImg":"","author":"Hadley Wickham","articleImgCdnMap":{"https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/covid-19-map.jpg":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn79@2020_6/2020/08/25/00-02-55-395_6ee29567f62ba0e3.webp"},"publishedOrCreatedDate":1598313739859},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"The Role of the Data Scientist","link":"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/existential_hu4621bfeee787ef8630b6bfba2b75aea4_207595_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/existential.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/existential.jpg\" width=\"800\" alt=\"An illustration of a data scientist gazing into the distance\" /> \n</div> \n<h2 id=\"data-scientists-face-an-existential-crisis\">Data Scientists Face an Existential Crisis</h2> \n<p>The term data scientist has always been a bit controversial. William Cleveland coined the term in 2001 to advocate the practical use of statistics in other technical fields and believed that use warranted a new name. Nowadays, professionals sporting a data science title typically hold a Ph.D., possess some detailed domain knowledge, and are either computer science majors who learned statistics or statisticians who learned to program. And while most of us have seen <a href=\"http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram\" target=\"_blank\" rel=\"noopener noreferrer\">Drew Conway’s diagram showing that combination of skills</a>, I think Joel Grus’ addition of evil intent allows us to better recognize other interesting combinations (see Figure 1 below).</p> \n<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/venn-diagrams_hu33bcd405dbf51ce8ac52a47f3aeecdbd_389831_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/venn-diagrams.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/venn-diagrams.jpg\" width=\"800\" alt=\"Differing views on what makes a good data scientist\" /> \n</div> \n<p>However, new technologies and a difficult economic environment caused by COVID-19 restrictions have raised new questions about the data scientist role, including:</p> \n<ul> \n <li><strong>Will their jobs be replaced by automated tools?</strong> A slew of vendors, from DataRobot to Oracle, are offering no-code or low-code analytic tools that promise to replace expensive data scientists with point-and-click web pages. While most buyers understand it’s not that simple, those vendor promotions create fear and doubt in executive minds.</li> \n <li><strong>Will executives resort to intuition?</strong> Most seasoned leaders were comfortable running their organizations by gut feel before data scientists arrived. When confronted with a high-risk economic environment, some may feel that “trust me” is a safer and easier-to-defend strategy than trying to explain complex models.</li> \n <li><strong>Is their career simply a hot trend that will go away?</strong> Data scientist careers have been on a roll for the last ten years, with <a href=\"https://www.glassdoor.com/Salaries/data-scientist-salary-SRCH_KO0,14.htm\" target=\"_blank\" rel=\"noopener noreferrer\">Glassdoor reporting mean starting salaries exceeding US$100,000</a>. With the economy now on a downtrend, this hot trend may now cool.</li> \n</ul> \n<h2 id=\"the-reality-organizations-need-data-scientists-more-than-ever\">The Reality: Organizations Need Data Scientists More Than Ever</h2> \n<p>COVID-19 crisis has created much fear, uncertainty, and doubt—commonly abbreviated as FUD—in all of our lives. However, based on what we see from organizations using our packages and products, RStudio believes that this FUD is unwarranted because:</p> \n<ul> \n <li><strong>Identifying and solving hard problems can’t be automated.</strong> Automated tools work well for well-understood problems, such as extraction and visualization of well-structured data. However, to compete in today’s environment, organizations must attack the truly hard problems that we don’t understand yet. Such problems exist in nearly every realm of human activity, ranging from mundane topics such as natural language understanding for customer service up to the Grand Challenges in Global Health. These problems can’t be encapsulated into automated systems until a data scientist first solves them.</li> \n <li><strong>Data-driven decision-making has proven to create better results.</strong> While intuitive management may have led to success in the past, data suggests that such an approach may not be competitive in today’s markets. A <a href=\"https://www.mckinsey.com/business-functions/marketing-and-sales/our-insights/five-facts-how-customer-analytics-boosts-corporate-performance\" target=\"_blank\" rel=\"noopener noreferrer\">study done by management consulting firm McKinsey &amp; Company</a> reports that data-driven companies were 23 times more likely to outperform competitors in acquiring new users and 19 times more likely to achieve above-average profitability than their non-data-driven competitors. With such case studies being taught in schools today, most leaders recognize that they need data scientists to be competitive.</li> \n <li><strong>Demand for data science tools has never been higher.</strong> During these difficult times, many organizations are doubling down on open source tooling because they know it is the best path to reproducible, durable analytics. Downloads of open source software and demand for courses that teach using these tools have only increased in the last quarter.</li> \n</ul> \n<h2 id=\"serious-data-science-helps-data-scientists-demonstrate-their-value\">Serious Data Science Helps Data Scientists Demonstrate Their Value</h2> \n<p>From RStudio’s point of view, the most convincing arguments we see for a bright data science future come from the work being done by the R and Python data science communities. We hear such stories regularly, and we’ve been collecting examples of this work as part of <a href=\"https://rstudio.com/about/customer-stories/\" target=\"_blank\" rel=\"noopener noreferrer\">our Customer Stories program</a>. We’ll add more of those stories in the months to come as we continue to talk to the tens of thousands of data scientists in our community that use our tools every day. It’s their work that inspires us to build and distribute the software we create.</p> \n<p>These stories have helped us envision what we believe to be the new role of the successful data scientist, Specifically, we believe that the role of a data scientist is to deliver what we’ve called <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">Serious Data Science</a>. Just as was implied in Conway’s Venn diagram in Figure 1a, Serious Data Science draws on some of the best practices found in software development, statistics, and domain expertise to deliver results that are:</p> \n<ul> \n <li><strong>Credible.</strong> It’s no longer enough for data scientists to create models that only they understand. Today’s best data scientists create data products that are not only statistically correct, but that can be visualized, explained, and withstand scrutiny by a large community of peers. Credibility within a large organization demands communication and collaboration skills beyond computation.</li> \n <li><strong>Agile.</strong> Serious data science practitioners expect that they’ll have to perform many iterations on their analysis to eventually address real-world business problems. Agility demands that they not only develop apps quickly but that they also regularly share those results with stakeholders to create consensus. (see our prior post <a href=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/\" target=\"_blank\" rel=\"noopener noreferrer\">Getting to the Right Question</a> for more details of this challenge).</li> \n <li><strong>Durable.</strong> Today’s data scientists understand that cutting-edge analysis has no value if it can’t still deliver value after they have moved on. Durable results require that they use processes that can survive changes in computing environments and infrastructure into the future.</li> \n</ul> \n<p>Look for a deeper discussion of the ways data scientists can enhance their role using Serious Data Science during the month of June.</p> \n<h2 id=\"learn-more-about-the-data-scientist-s-role-and-serious-data-science\">Learn More about the Data Scientist’s Role and Serious Data Science</h2> \n<p>For a real-world view of how data scientists work to solve hard, complex, and valuable problems, watch Pim Bongaerts from the California Academy of Sciences speak about using data science to help save coral reefs.</p> \n<div style=\"padding: 35px 0 35px 0;\"> \n <script src=\"https://fast.wistia.com/embed/medias/zhpb795rre.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_zhpb795rre videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/zhpb795rre/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div> \n</div> \n<p>Eduardo Ariño de la Rubia, Data Science Manager at Facebook, <a href=\"https://rstudio.com/resources/rstudioconf-2020/value-in-data-science-beyond-models-in-production/\" target=\"_blank\" rel=\"noopener noreferrer\">spoke at rstudio::conf 2020 on the role of a data scientist</a>, with an emphasis on how they bring value beyond putting models in production.</p> \n<p>We also recommend our prior blog posts in this series:</p> \n<ul> \n <li><a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Driving Real, Lasting Value with Serious Data Science</strong></a> defines the components and need for serious data science.</li> \n <li><a href=\"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Equipping Your Data Science Team to Work from Home</strong></a> outlines server infrastructure that can make work-from-home data scientists more effective.</li> \n <li><a href=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Wrangling Unruly Data: The Bane of Every Data Science Team</strong></a> explains why data wrangling is an integral (and unavoidably lengthy) part of data science.</li> \n <li><a href=\"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Avoid Irrelevancy and Fire Drills in Data Science Teams</strong></a> explains how data science teams can avoid being pigeon-holed into roles of ivory tower researchers or always-on-call data firefighters.</li> \n <li><a href=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Getting to the Right Question</strong></a> discusses the communications gap between business people and data science and how to bridge that divide.</li> \n</ul>","descriptionType":"text/html","publishedDate":"Wed, 27 May 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"bc1651d11bf689931989cd41e5de328c","bgimgJsdelivr":"","metaImg":"","author":"Carl Howe, Sean Lopp","articleImgCdnMap":{"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/existential.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn42@2020_3/2020/08/25/00-02-56-542_d124b48268641e1c.webp","https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/venn-diagrams.jpg":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn31@2020_1/2020/08/25/00-02-55-351_b77b35090995aa12.webp","https://fast.wistia.com/embed/medias/zhpb795rre/swatch":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn45@2020_2/2020/08/25/00-02-54-935_3982763a37966fa7.webp"},"publishedOrCreatedDate":1598313739858},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Why You Need a World Class IDE to Do Serious Data Science","link":"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/tunnel-hero_hu8238d51c6a0ced31f06f172ae89f8ecc_1802467_2592x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/tunnel-hero.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/tunnel-hero.jpg\" width=\"2592\" alt=\"Yosemite park tunnel\" /> \n</div> \n<p style=\"text-align: right !important;margin-top: 0px;margin-bottom: 30px;\"><i>Photo by <a style=\"color: #000000;\" href=\"https://unsplash.com/@danieljerez\">Daniel Jerez</a> on <a style=\"color: #000000;\" href=\"https://unsplash.com/photos/CD4WHrWio6Q\">Unsplash</a></i></p> \n<p>Data science can feel like an endless tunnel, with tremendous investment at the beginning and little visibility into where or when your results will emerge. Data science teams wrestle with many challenges, such as rapid iteration of new ideas, business alignment, productivity, transparency, and delivering durable value.</p> \n<p>As we’ve discussed in <a href=\"https://blog.rstudio.com/2020/06/24/delivering-durable-value/\" target=\"_blank\" rel=\"noopener noreferrer\">recent blog posts</a>, there are many advantages to using code for your data science work. However, to make your data science teams as productive as possible, they need the best environment in which to efficiently write that code. In this post, I explain why serious data science requires a world-class IDE.</p> \n<p><br /></p> \n<h2 id=\"1-data-science-by-its-nature-is-iterative\">1. Data Science by Its Nature Is Iterative</h2> \n<p>There is no better way to shine a light on a solution than the back-and-forth testing of new ideas with code and a fail-fast attitude. You ultimately need to try an idea, search for new functions, review the syntax, visualize the results, make updates, and repeat.</p> \n<p>The RStudio IDE lets you run statistical commands just this way, with the option to visualize results early on as you are building. This engaging means of executing code continuously from the console and directly inline from saved scripts lends itself to increased experimentation and ultimately faster results. With one environment, you can view, debug, and track the history of results, making it substantially easier to build off existing work.</p> \n<p>Rich features, such as automated code validation, syntax highlighting, and smart indentation, make coding and iterating new work even faster. Don’t remember the format of a function? Just type a question mark before it, and the full syntax opens up in a separate pane. Check out our latest addition to these features with spell-check and guidance for conventional data science terms in the newest RStudio 1.3 release <a href=\"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p> \n<p><br /></p> \n<h2 id=\"2-your-business-has-unique-challenges\">2. Your Business Has Unique Challenges</h2> \n<p>Software on its own is useless for the specific questions and answers that your business will uniquely demand. With the high rate of failure in data science projects (learn more <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> in our recent post), success will ultimately rely on data scientists understanding the business and its data and using code to extract insights from that data. While most development environments design around programming tasks, the RStudio IDE is built for authoring particular questions and answers. <br><br> \n   <blockquote>\n    <p>While most development environments design around programming tasks, the RStudio IDE is built for authoring particular questions and answers.</p>\n   </blockquote> <br /></br></br></p> \n<p>Dedicated panes in the IDE connecting to a database, defining variables, and pre-viewing and managing data give you the control needed to reach a final solution.</p> \n<p><br /></p> \n<h2 id=\"3-multiple-tools-and-technologies-leads-to-inefficiency\">3. Multiple Tools and Technologies Leads to Inefficiency</h2> \n<p>For the data scientist, the sheer number of environments and technologies when trying to find solutions is continually a challenge. Every time you have to switch between tools, windows, or import from one to another means lost time and mental energy.</p> \n<p>While the RStudio IDE integrates the R console, source code, output plots, database connections, and code execution environment all in one place, interoperability with other tools and technologies make it even more potent for development. You might need to grab some data in a SQL database, query, open Python to analyze, visualize in D3, and model in a language like Stan. With the RStudio IDE, all of this is possible in one place, as we recently demonstrated in <a href=\"https://blog.rstudio.com/2020/07/07/interoperability-july/\" target=\"_blank\" rel=\"noopener noreferrer\">this blog post</a>. You can also very fluidly and naturally author Python inside R Markdown, allowing for a language-agnostic approach with your team. Learn more about this with <a href=\"https://rstudio.com/solutions/r-and-python/\" target=\"_blank\" rel=\"noopener noreferrer\">“R &amp; Python: A Love Story.”</a></p> \n<p><br /></p> \n<h2 id=\"4-teams-require-accountability-and-transparency\">4. Teams Require Accountability and Transparency</h2> \n<p>Git support inside the RStudio IDE makes sharing code and collaborating over a versioned environment possible and easy. When your team inspects how a problem was first solved, they need to see how the solution evolved. Using tools like R Markdown from within the IDE allows you to create a rich variety of content: PDFs, word documents, slides, and HTML files. Integration with <a href=\"https://rstudio.com/products/connect/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Connect</a> then allows visually appealing and digestible results from the RStudio IDE to be made available to shareholders across the organization with secure publishing of code and scheduled reports.</p> \n<p>All of these content types are reproducible because they are generated from code, allowing your team to peer-review your work and make your work auditable by third parties.</p> \n<p><br /></p> \n<h2 id=\"5-solutions-must-last\">5. Solutions Must Last</h2> \n<p>Vendors often lock developers into proprietary products that incur rising costs and discourage reuse. Building with an IDE based on community and open source has tremendous potential for avoiding these pitfalls and making your data science work more durable. The RStudio IDE can import over 16,000 open source packages from the R community that avoid this type of lock-in. When we ask R users in our annual survey what tools they use for their applications, 86% say they use the RStudio Desktop IDE (see the chart below). With this large community of IDE users and RStudio’s commitment to open source, data scientists can worry less about being locked into license fees and focus on solving problems.</p> \n<figure> \n <div style=\"padding: 35px 0 35px 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/survey-chart_hua0d4d4b24f4da3a102e4452ac738b95f_231872_1166x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/survey-chart.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/survey-chart.jpg\" width=\"1166\" alt=\"Chart from survey for tools used with R applications\" /> \n </div> \n <figcaption>\n  Figure 1: 86% of respondents interested in R use the RStudio IDE.\n </figcaption> \n</figure> \n<p>To learn more about the RStudio IDE, and explore how you can use it in your environment, <a href=\"https://rstudio.com/products/rstudio/\" target=\"_blank\" rel=\"noopener noreferrer\">download</a> a free copy from the RStudio web site today.</p>","descriptionType":"text/html","publishedDate":"Thu, 09 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"e9a77b8e3c91680d61827afaca8792d5","bgimgJsdelivr":"","metaImg":"","author":"Daniel Petzold","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/tunnel-hero.jpg":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn89@2020_3/2020/08/25/00-02-57-848_be5f368920445635.webp","https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/survey-chart.jpg":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn97@2020_6/2020/08/25/00-02-56-696_4c7fc95916f98ad2.webp"},"publishedOrCreatedDate":1598313739856},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Equipping Your Data Science Team to Work from Home","link":"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/work-from-home-desk_huf8eb8a6cb4e75b7dd9f0feb434968414_260117_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/work-from-home-desk.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/work-from-home-desk.jpg\" width=\"800\" alt=\"Photo of a work-from-home desk\" /> \n</div> \n<p><em>Photo by Djurdjica Boskovic on Unsplash</em></p> \n<p>If your data science team experienced an abrupt transition to working at home, it may be a good time to rethink their development tools. In this post, I’ll talk about why laptop-centric data science gets in the way of strong data science teams and why you should consider deploying development and publishing servers.</p> \n<h2 id=\"working-from-home-has-affected-both-people-and-data\">Working from Home Has Affected Both People and Data</h2> \n<p>Like tigers and koalas, we data scientists are fairly solitary creatures. We typically eschew meetings, embrace focus time, and block out distractions to focus on our work. And on those rare times when we need help, our typical reaction is to walk over to a colleague’s desk and brainstorm an answer.</p> \n<p>Enter COVID-19 and the new work-from-home environment. At first glance, it would appear nothing really has to change for the typical data science workflow; team members armed with laptops appear well-equipped to continue their data science work. However, many data science teams are now struggling with:</p> \n<ul> \n <li><strong>Collaborative deprivation.</strong> While we all feel some sense of isolation during this lockdown, working from home deprives data scientists of their most effective collaboration techniques. Without the ability to pop over to someone’s desk to ask a question or get help debugging a piece of code, many data scientists find themselves not making the progress they are used to.</li> \n <li><strong>Locked-in development licenses</strong>. Many teams have been rather chagrined to find that their commercial data analysis software licenses are only valid in their enterprise environment, forcing them into a painful dance with VPN software when working from home.</li> \n <li><strong>Firewalled data</strong>. Many organizations prohibit access to sensitive corporate data from outside the firewall to limit security risks and preserve user privacy. That’s no big deal when the data science team is working from an office, but it becomes a serious issue when working from home.</li> \n <li><strong>Inconsistent laptop environments</strong>. Data scientists often download their own versions of libraries and development tools. However, that means that code developed on one data scientist’s laptop won’t necessarily work for another data scientist who has different versions of packages loaded. Working from home without regular contact with other team members allows these inconsistencies to fester and grow, raising roadblocks to reproducible results. Worse, data scientists risk losing code and data living in those unique laptop environments should their hard drive fail or their laptop fall victim to a household accident.</li> \n</ul> \n<h2 id=\"serious-data-science-requires-collaborative-tools\">Serious Data Science Requires Collaborative Tools</h2> \n<p>To be able to do their work collaboratively and repeatably, data science teams need infrastructure that encourages it and is supported by the organization and IT. That typically means shared servers for:</p> \n<ul> \n <li><strong>Code Development</strong>. Having a shared development server allows everyone to share a consistent programming environment. Servers can also be configured to provide more computational and memory resources for the team to share, including back end CPU and GPU clusters. For teams working on machine learning models, for example, training a new model on a laptop might take days, while training that same model using a Kubernetes cluster might only take hours or minutes. And since the development server is typically hosted within the organization firewall, it can be configured to have full access to datasets that would not be allowed externally.</li> \n <li><strong>Application publishing</strong>. Data scientists who used to share their insights using a conference room and a projector now need ways to publish results that don’t require real-time attendance. While most companies have some types of internal web servers, those rarely support R and Python run-time environments. Data science teams need a publishing platform that is easy to use, letting them share work without opening an IT ticket for every change.</li> \n <li><strong>Package control</strong>. Solitary data scientists tend to do their own package management, frequently installing the latest and greatest packages that they find. However, using the latest and greatest software can often backfire when other team members try to reproduce or build onto their work. Storing approved packages on a centralized server and defining that as the standard data science environment makes your data science work more reproducible and long-lasting.</li> \n</ul> \n<h2 id=\"which-servers-should-you-choose\">Which Servers Should You Choose?</h2> \n<p>Which server-based tools you choose obviously depend on factors such as team size, workload, and company software policies. RStudio offers both open source and commercial alternatives, allowing organizations to choose whichever satisfies their needs best. Table 1 summarizes both approaches.</p> \n<p>In addition to providing enhanced security, auditing, and usage monitoring, Pro solutions add other benefits that are less quantifiable. Specifically:</p> \n<ul> \n <li><strong>RStudio Server Pro adds back end computational muscle.</strong> As we noted above, many data science workloads benefit significantly from being run on server platforms with beefy processors and capacious memory. RStudio Server Pro offers a feature called <a href=\"https://solutions.rstudio.com/documents/Scaling-RStudio-Server-Pro-with-Kubernetes.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Launcher that can offload R and Python job execution onto a back end Kubernetes or SLURM cluster</a>. For groups doing serious machine learning, this one feature can speed up the team’s productivity significantly.</li> \n <li><strong>RStudio Connect creates a production environment that your team controls</strong>. Shiny apps, Jupyter Notebooks, and R Markdown documents are great tools for communicating with people outside your data science team, but they need a place to live. RStudio Connect provides that place to live and gives your team a secure, centralized portal for data products, automated emails, and Plumber and Dash APIs that let non-data scientists make use of their insights.</li> \n <li><strong>RStudio Package Manager ensures your team’s work is repeatable</strong>. With 15,000 R packages on CRAN constantly being updated, an R application that runs with today’s versions of those packages won’t necessarily work with tomorrow’s. Package Manager makes it easier to have stable access to packages, so your whole team can be using the same playbook. It can also restrict packages versions to only those that have been certified by a central authority, thereby ensuring approved results.</li> \n</ul> \n<table> \n <tr> \n  <th> Open Source Solution</th> \n  <th> Value </th> \n  <th> Pro Solution </th> \n  <th> Added Value in Pro </th> \n </tr> \n <tr> \n  <td><a href=\"https://rstudio.com/products/rstudio/#rstudio-server\">RStudio Server</a></td> \n  <td> \n   <ul> \n    <li>Broadens access to development tools</li> \n    <li>Boosts compute and memory resources available</li> \n    <li>Ensures common development environment</li> \n   </ul> </td> \n  <td><a href=\"https://rstudio.com/products/rstudio/#rstudio-server\">RStudio Server Pro*</a></td> \n  <td> \n   <ul> \n    <li>Adds collaborative editing and projects</li> \n    <li>Supports multiple R versions and sessions</li> \n    <li>Provides Launcher support for back end execution clusters</li> \n    <li>Supports bilingual data science teams with Jupyter</li> \n   </ul> </td> \n </tr> \n <tr> \n  <td><a href=\"https://rstudio.com/products/shiny/shiny-server/\">Shiny Server</a>,<br />Homegrown Web Servers</td> \n  <td> \n   <ul> \n    <li>Eases publishing of Shiny applications</li> \n    <li>Allows broad access to data science results</li> \n   </ul> </td> \n  <td><a href=\"https://rstudio.com/products/connect/\">RStudio Connect</a></td> \n  <td> \n   <ul> \n    <li>Consolidates many types of content on one server</li> \n    <li>Allows scheduled production and emails</li> \n    <li>Hosts R- and Python-based APIs</li> \n   </ul> </td> \n </tr> \n <tr> \n  <td><a href=\"https://cran.r-project.org/web/packages/miniCRAN/index.html\">miniCRAN Mirror</a></td> \n  <td> \n   <ul> \n    <li>Maintains a local copy of packages from approved sources</li> \n   </ul> </td> \n  <td><a href=\"https://rstudio.com/products/package-manager/\">RStudio Package Manager</a></td> \n  <td> \n   <ul> \n    <li>Speeds installs using binaries</li> \n    <li>Allows use of multiple package versions and checkpoints for roll back</li> \n    <li>Provides package use insights for IT</li> \n   </ul> </td> \n </tr> \n</table> \n<h4 id=\"table-1-open-source-and-professional-server-options-to-support-data-scientists\">Table 1: Open Source and Professional Server Options To Support Data Scientists.</h4> \n<p>*RStudio Server Pro, RStudio Connect, and RStudio Package Manager are also available bundled as RStudio Team.</p> \n<h2 id=\"don-t-be-afraid-to-mix-and-match-servers-as-your-needs-dictate\">Don’t Be Afraid To Mix and Match Servers As Your Needs Dictate</h2> \n<p>The collaboration processes data science teams have used for years have already been disrupted by COVID-19 and work from home mandates. The question for data science leaders is what they can do to provide new ways of working that are as good or better than what went before. Centralizing your data science development and production processes is a way to do that.</p> \n<p>Emily Riederer, an Analytics Manager at Capital One, <a href=\"https://vimeo.com/theranchstudios/review/398622411/383d5791b1?sort=lastUserActionEventDate&amp;direction=desc\" target=\"_blank\" rel=\"noopener noreferrer\">summarized some of the benefits she’s seen from this centralized approach</a> at RStudio::conf 2020.</p> \n<div style=\"padding: 35px 0 35px 0;\"> \n <script src=\"https://fast.wistia.com/embed/medias/cac6g1r9gr.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_cac6g1r9gr videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/cac6g1r9gr/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div> \n</div> \n<p>With that said, using servers to make your work-from-home data science team more productive doesn’t have to be a Manhattan Project all-or-nothing proposition. If your data scientists are comfortable developing code on their laptops, you may want to begin by installing a publishing platform like RStudio Connect, and put off development and package management servers for another day. Similarly, some teams start by installing RStudio Server for centralized development and defer publishing and package management. But for teams doing serious data science, they have to start somewhere.</p> \n<p>We’ll be posting additional commentary and case studies on equipping data science teams to work from home in the coming weeks. In the meantime, we recommend <a href=\"https://appsilon.com/rstudio-connect-as-a-solution-for-remote-data-science-teams/\" target=\"_blank\" rel=\"noopener noreferrer\">a recent post about how Appsilon has used Connect</a> to create a remote work-friendly culture.</p> \n<h2 id=\"for-more-information\">For More Information</h2> \n<p>If you’d like to learn more about how to better equip your data science team to work from home, we recommend:</p> \n<ul> \n <li><strong><a href=\"https://rstudio.com/resources/rstudioconf-2019/rstudio-job-launcher-changing-where-we-run-r-stuff/\" target=\"_blank\" rel=\"noopener noreferrer\">Changing Where We Run Stuff</a></strong>. This 18-minute video of an RStudio::conf 2019 talk by Darby Hadley describes how Launcher improves workload scaling and isolation.</li> \n <li><strong><a href=\"https://solutions.rstudio.com/launcher/kubernetes/#want-to-learn-more-about-rstudio-server-pro-and-kubernetes\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Server Pro with Kubernetes Overview</a></strong>. This document provides architectural block diagrams and links to frequently asked questions about RStudio Pro and Launcher.</li> \n <li><strong><a href=\"https://rstudio.com/products/connect/\" target=\"_blank\" rel=\"noopener noreferrer\">The RStudio Connect Product Page</a></strong>. This overview of RStudio Connect provides links to several videos going into details of how it can help your data science team communicate better throughout the organization.</li> \n <li><strong><a href=\"https://rstudio.com/resources/rstudioconf-2020/building-a-new-data-science-pipeline-for-the-ft-with-rstudio-connect/\" target=\"_blank\" rel=\"noopener noreferrer\">Building a new data science pipeline for the FT with RStudio Connect</a>.</strong> George Kastrinakis from the Financial Times presented this 16-minute talk at RStudio::conf 2020 about how RStudio Connect significantly sped up its data science work and made it more agile.</li> \n <li><strong><a href=\"https://rstudio.com/resources/webinars/reproducibility-in-production/\" target=\"_blank\" rel=\"noopener noreferrer\">Reproducibility in Production</a>.</strong> This webinar by Garrett Grolemund describes how computational documents (such as RMarkdown and Jupyter Notebooks) help deliver reproducible results for your business stakeholders.</li> \n <li><strong><a href=\"https://rstudio.com/resources/webinars/introduction-to-the-rstudio-package-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">Introduction to RStudio Package Manager</a>.</strong> This recorded webinar provides a detailed description of what RStudio Package Manager is and how it aids reproducibility in R applications.</li> \n</ul>","descriptionType":"text/html","publishedDate":"Tue, 12 May 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"f1482487bf469c1b8522c883a0ea2cde","bgimgJsdelivr":"","metaImg":"","author":"Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/work-from-home-desk.jpg":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn26@2020_5/2020/08/25/00-02-55-070_43addc51b94226a1.webp","https://fast.wistia.com/embed/medias/cac6g1r9gr/swatch":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn13@2020_1/2020/08/25/00-02-56-393_d9c6a2d09bdde1b2.webp"},"publishedOrCreatedDate":1598313739860},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"sparklyr 1.3: Higher-order Functions, Avro and Custom Serializers","link":"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/","description":"<p><img src=\"https://blog.rstudio.com/images/2020-07-16-sparklyr-1-3-available.jpg\" style=\"display: none\" alt=\"sparklyr 1.3 is now available on CRAN\" /></p> \n<p><a href=\"https://sparklyr.ai\"><code>sparklyr</code></a> 1.3 is now available on <a href=\"https://cran.r-project.org/web/packages/sparklyr/index.html\">CRAN</a>, with the following major new features:</p> \n<ul> \n <li><a href=\"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#higher-order-functions\">Higher-order Functions</a> to easily manipulate arrays and structs</li> \n <li>Support for Apache <a href=\"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#avro\">Avro</a>, a row-oriented data serialization framework</li> \n <li><a href=\"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#custom-serialization\">Custom Serialization</a> using R functions to read and write any data format</li> \n <li><a href=\"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#other-improvements\">Other Improvements</a> such as compatibility with EMR 6.0 &amp; Spark 3.0, and initial support for Flint time series library</li> \n</ul> \n<p>To install <code>sparklyr</code> 1.3 from CRAN, run</p> \n<pre><code class=\"language-r\">install.packages(\"sparklyr\")\n</code></pre> \n<p>In this post, we shall highlight some major new features introduced in sparklyr 1.3, and showcase scenarios where such features come in handy. While a number of enhancements and bug fixes (especially those related to <code>spark_apply()</code>, <a href=\"https://arrow.apache.org/\">Apache Arrow</a>, and secondary Spark connections) were also an important part of this release, they will not be the topic of this post, and it will be an easy exercise for the reader to find out more about them from the sparklyr <a href=\"https://github.com/sparklyr/sparklyr/blob/master/NEWS.md\">NEWS</a> file.</p> \n<h2 id=\"higher-order-functions\">Higher-order Functions</h2> \n<p><a href=\"https://issues.apache.org/jira/browse/SPARK-19480\">Higher-order functions</a> are built-in Spark SQL constructs that allow user-defined lambda expressions to be applied efficiently to complex data types such as arrays and structs. As a quick demo to see why higher-order functions are useful, let’s say one day Scrooge McDuck dove into his huge vault of money and found large quantities of pennies, nickels, dimes, and quarters. Having an impeccable taste in data structures, he decided to store the quantities and face values of everything into two Spark SQL array columns:</p> \n<pre><code class=\"language-r\">library(sparklyr)\n\nsc &lt;- spark_connect(master = \"local\", version = \"2.4.5\")\ncoins_tbl &lt;- copy_to(\n  sc,\n  tibble::tibble(\n    quantities = list(c(4000, 3000, 2000, 1000)),\n    values = list(c(1, 5, 10, 25))\n  )\n)\n</code></pre> \n<p>Thus declaring his net worth of 4k pennies, 3k nickels, 2k dimes, and 1k quarters. To help Scrooge McDuck calculate the total value of each type of coin in sparklyr 1.3 or above, we can apply <code>hof_zip_with()</code>, the sparklyr equivalent of <a href=\"https://spark.apache.org/docs/latest/api/sql/index.html#zip_with\">ZIP_WITH</a>, to <code>quantities</code> column and <code>values</code> column, combining pairs of elements from arrays in both columns. As you might have guessed, we also need to specify how to combine those elements, and what better way to accomplish that than a concise one-sided formula   <code>~ .x * .y</code>   in R, which says we want (quantity * value) for each type of coin? So, we have the following:</p> \n<pre><code class=\"language-r\">result_tbl &lt;- coins_tbl %&gt;%\n  hof_zip_with(~ .x * .y, dest_col = total_values) %&gt;%\n  dplyr::select(total_values)\n\nresult_tbl %&gt;% dplyr::pull(total_values)\n</code></pre> \n<pre><code>[1]  4000 15000 20000 25000\n</code></pre> \n<p>With the result <code>4000 15000 20000 25000</code> telling us there are in total $40 dollars worth of pennies, $150 dollars worth of nickels, $200 dollars worth of dimes, and $250 dollars worth of quarters, as expected.</p> \n<p>Using another sparklyr function named <code>hof_aggregate()</code>, which performs an <a href=\"https://spark.apache.org/docs/latest/api/sql/index.html#aggregate\">AGGREGATE</a> operation in Spark, we can then compute the net worth of Scrooge McDuck based on <code>result_tbl</code>, storing the result in a new column named <code>total</code>. Notice for this aggregate operation to work, we need to ensure the starting value of aggregation has data type (namely, <code>BIGINT</code>) that is consistent with the data type of <code>total_values</code> (which is <code>ARRAY&lt;BIGINT&gt;</code>), as shown below:</p> \n<pre><code class=\"language-r\">result_tbl %&gt;%\n  dplyr::mutate(zero = dplyr::sql(\"CAST (0 AS BIGINT)\")) %&gt;%\n  hof_aggregate(start = zero, ~ .x + .y, expr = total_values, dest_col = total) %&gt;%\n  dplyr::select(total) %&gt;%\n  dplyr::pull(total)\n</code></pre> \n<pre><code>[1] 64000\n</code></pre> \n<p>So Scrooge McDuck’s net worth is $640 dollars.</p> \n<p>Other higher-order functions supported by Spark SQL so far include <code>transform</code>, <code>filter</code>, and <code>exists</code>, as documented in <a href=\"https://spark.apache.org/docs/latest/api/sql/index.html\">here</a>, and similar to the example above, their counterparts (namely, <code>hof_transform()</code>, <code>hof_filter()</code>, and <code>hof_exists()</code>) all exist in sparklyr 1.3, so that they can be integrated with other <code>dplyr</code> verbs in an idiomatic manner in R.</p> \n<h2 id=\"avro\">Avro</h2> \n<p>Another highlight of the sparklyr 1.3 release is its built-in support for Avro data sources. Apache Avro is a widely used data serialization protocol that combines the efficiency of a binary data format with the flexibility of JSON schema definitions. To make working with Avro data sources simpler, in sparklyr 1.3, as soon as a Spark connection is instantiated with <code>spark_connect(..., package = \"avro\")</code>, sparklyr will automatically figure out which version of <code>spark-avro</code> package to use with that connection, saving a lot of potential headaches for sparklyr users trying to determine the correct version of <code>spark-avro</code> by themselves. Similar to how <code>spark_read_csv()</code> and <code>spark_write_csv()</code> are in place to work with CSV data, <code>spark_read_avro()</code> and <code>spark_write_avro()</code> methods were implemented in sparklyr 1.3 to facilitate reading and writing Avro files through an Avro-capable Spark connection, as illustrated in the example below:</p> \n<pre><code class=\"language-r\">library(sparklyr)\n\n# The `package = \"avro\"` option is only supported in Spark 2.4 or higher\nsc &lt;- spark_connect(master = \"local\", version = \"2.4.5\", package = \"avro\")\n\nsdf &lt;- sdf_copy_to(\n  sc,\n  tibble::tibble(\n    a = c(1, NaN, 3, 4, NaN),\n    b = c(-2L, 0L, 1L, 3L, 2L),\n    c = c(\"a\", \"b\", \"c\", \"\", \"d\")\n  )\n)\n\n# This example Avro schema is a JSON string that essentially says all columns\n# (\"a\", \"b\", \"c\") of `sdf` are nullable.\navro_schema &lt;- jsonlite::toJSON(list(\n  type = \"record\",\n  name = \"topLevelRecord\",\n  fields = list(\n    list(name = \"a\", type = list(\"double\", \"null\")),\n    list(name = \"b\", type = list(\"int\", \"null\")),\n    list(name = \"c\", type = list(\"string\", \"null\"))\n  )\n), auto_unbox = TRUE)\n\n# persist the Spark data frame from above in Avro format\nspark_write_avro(sdf, \"/tmp/data.avro\", as.character(avro_schema))\n\n# and then read the same data frame back\nspark_read_avro(sc, \"/tmp/data.avro\")\n\n</code></pre> \n<pre><code># Source: spark&lt;data&gt; [?? x 3]\n      a     b c\n  &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;\n  1     1    -2 \"a\"\n  2   NaN     0 \"b\"\n  3     3     1 \"c\"\n  4     4     3 \"\"\n  5   NaN     2 \"d\"\n\n</code></pre> \n<h2 id=\"custom-serialization\">Custom Serialization</h2> \n<p>In addition to commonly used data serialization formats such as CSV, JSON, Parquet, and Avro, starting from sparklyr 1.3, customized data frame serialization and deserialization procedures implemented in R can also be run on Spark workers via the newly implemented <code>spark_read()</code> and <code>spark_write()</code> methods. We can see both of them in action through a quick example below, where <code>saveRDS()</code> is called from a user-defined writer function to save all rows within a Spark data frame into 2 RDS files on disk, and <code>readRDS()</code> is called from a user-defined reader function to read the data from the RDS files back to Spark:</p> \n<pre><code class=\"language-r\">library(sparklyr)\n\nsc &lt;- spark_connect(master = \"local\")\nsdf &lt;- sdf_len(sc, 7)\npaths &lt;- c(\"/tmp/file1.RDS\", \"/tmp/file2.RDS\")\n\nspark_write(sdf, writer = function(df, path) saveRDS(df, path), paths = paths)\nspark_read(sc, paths, reader = function(path) readRDS(path), columns = c(id = \"integer\"))\n</code></pre> \n<pre><code># Source: spark&lt;?&gt; [?? x 1]\n     id\n  &lt;int&gt;\n1     1\n2     2\n3     3\n4     4\n5     5\n6     6\n7     7\n</code></pre> \n<h2 id=\"other-improvements\">Other Improvements</h2> \n<h3 id=\"sparklyr-flint\">Sparklyr.flint</h3> \n<p><a href=\"https://github.com/r-spark/sparklyr.flint\">Sparklyr.flint</a> is a sparklyr extension that aims to make functionalities from the <a href=\"https://github.com/twosigma/flint\">Flint</a> time-series library easily accessible from R. It is currently under active development. One piece of good news is that, while the original <a href=\"https://github.com/twosigma/flint\">Flint</a> library was designed to work with Spark 2.x, a slightly modified <a href=\"https://github.com/yl790/flint\">fork</a> of it will work well with Spark 3.0, and within the existing sparklyr extension framework. <code>sparklyr.flint</code> can automatically determine which version of the Flint library to load based on the version of Spark it’s connected to. Another bit of good news is, as previously mentioned, <code>sparklyr.flint</code> doesn’t know too much about its own destiny yet. Maybe you can play an active part in shaping its future!</p> \n<h3 id=\"emr-6-0\">EMR 6.0</h3> \n<p>This release also features a small but important change that allows sparklyr to correctly connect to the version of Spark 2.4 that is included in Amazon EMR 6.0.</p> \n<p>Previously, sparklyr automatically assumed any Spark 2.x it was connecting to was built with Scala 2.11 and attempted to load any required Scala artifacts built with Scala 2.11 as well. This became problematic when connecting to Spark 2.4 from Amazon EMR 6.0, which is built with Scala 2.12. Starting from sparklyr 1.3, such problem can be fixed by simply specifying <code>scala_version = \"2.12\"</code> when calling <code>spark_connect()</code> (e.g., <code>spark_connect(master = \"yarn-client\", scala_version = \"2.12\")</code>).</p> \n<h3 id=\"spark-3-0\">Spark 3.0</h3> \n<p>Last but not least, it is worthwhile to mention sparklyr 1.3.0 is known to be fully compatible with the recently released Spark 3.0. We highly recommend upgrading your copy of sparklyr to 1.3.0 if you plan to have Spark 3.0 as part of your data workflow in future.</p> \n<h2 id=\"acknowledgement\">Acknowledgement</h2> \n<p>In chronological order, we want to thank the following individuals for submitting pull requests towards sparklyr 1.3:</p> \n<ul> \n <li><a href=\"https://github.com/jozefhajnala\">Jozef Hajnala</a></li> \n <li><a href=\"https://github.com/falaki\">Hossein Falaki</a></li> \n <li><a href=\"https://github.com/samuelmacedo83\">Samuel Macêdo</a></li> \n <li><a href=\"https://github.com/yl790\">Yitao Li</a></li> \n <li><a href=\"https://github.com/Loquats\">Andy Zhang</a></li> \n <li><a href=\"https://github.com/javierluraschi\">Javier Luraschi</a></li> \n <li><a href=\"https://github.com/nealrichardson\">Neal Richardson</a></li> \n</ul> \n<p>We are also grateful for valuable input on the sparklyr 1.3 roadmap, <a href=\"https://github.com/sparklyr/sparklyr/pull/2434\">#2434</a>, and <a href=\"https://github.com/sparklyr/sparklyr/pull/2551\">#2551</a> from <a href=\"https://github.com/javierluraschi\">@javierluraschi</a>, and insightful advice on <a href=\"https://github.com/sparklyr/sparklyr/issues/1773\">#1773</a> and <a href=\"https://github.com/sparklyr/sparklyr/issues/2514\">#2514</a> from <a href=\"https://github.com/mattpollock\">@mattpollock</a> and <a href=\"https://github.com/benmwhite\">@benmwhite</a>.</p> \n<p>Please note if you believe you are missing from the acknowledgement above, it may be because your contribution has been considered part of the next sparklyr release rather than part of the current release. We do make every effort to ensure all contributors are mentioned in this section. In case you believe there is a mistake, please feel free to contact the author of this blog post via e-mail (yitao at rstudio dot com) and request a correction.</p> \n<p>If you wish to learn more about <code>sparklyr</code>, we recommend visiting <a href=\"https://sparklyr.ai\">sparklyr.ai</a>, <a href=\"https://spark.rstudio.com\">spark.rstudio.com</a>, and some of the previous release posts such as <a href=\"https://blogs.rstudio.com/ai/posts/2020-04-21-sparklyr-1.2.0-released/\">sparklyr 1.2</a> and <a href=\"https://blog.rstudio.com/2020/01/29/sparklyr-1-1/\">sparklyr 1.1</a>.</p> \n<p>Thanks for reading!</p> \n<p>This post was originally posted on <a href=\"https://blogs.rstudio.com/ai/\">blogs.rstudio.com/ai/</a></p>","descriptionType":"text/html","publishedDate":"Thu, 16 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"https://blog.rstudio.com/images/2020-07-16-sparklyr-1-3-available.jpg","linkMd5":"299bc46a95e2ba8757c060c1428bf545","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn70@2020_4/2020/08/25/00-02-24-855_2cc555566a3f7e0a.webp","destWidth":492,"destHeight":700,"sourceBytes":93301,"destBytes":43132,"author":"Yitao Li","articleImgCdnMap":{"https://blog.rstudio.com/images/2020-07-16-sparklyr-1-3-available.jpg":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn70@2020_4/2020/08/25/00-02-24-855_2cc555566a3f7e0a.webp"},"publishedOrCreatedDate":1598313739857},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Interoperability in July","link":"https://blog.rstudio.com/2020/07/07/interoperability-july/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/07/07/interoperability-july/icecream-hero_hu33bcd405dbf51ce8ac52a47f3aeecdbd_631411_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/07/interoperability-july/icecream-hero.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/07/interoperability-july/icecream-hero.jpg\" width=\"800\" alt=\"July-ice-cream-cones\" /> \n</div> \n<p><span>Photo by <a href=\"https://unsplash.com/@mark_crz?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Mark Cruz</a> on <a href=\"https://unsplash.com/s/photos/ice-cream-cones?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span></p> \n<p>The TIOBE Company just published the July edition of its <a href=\"https://www.tiobe.com/tiobe-index/\" target=\"_blank\" rel=\"noopener noreferrer\">TIOBE Programming Community Index</a> of programming language popularity. R users will be pleased to see that R is now ranked as the 8th most popular programming language as shown in the screenshot below, having risen 12 positions since July of last year.</p> \n<figure> \n <img src=\"https://blog.rstudio.com/2020/07/07/interoperability-july/tiobe-july.jpg\" alt=\"Figure 1: TIOBE Language Rankings showing R as the 8th Most Popular Language\" /> \n <figcaption>\n  Figure 1: TIOBE Language Rankings showing R as the 8th Most Popular Language\n </figcaption> \n</figure> \n<p>While we at RStudio are pleased to see R climbing the TIOBE charts, what we’re going to focus on this month is all the other languages, both on this list and not, that data science teams also use to do their jobs. We’re going to focus on <strong>interoperability</strong> with R, and how it helps data science teams get more value of all their organization’s analytic investments.</p> \n<p>If you’re a regular reader of this blog, you may already know that the RStudio IDE supports Python (you can read more at <a href=\"https://rstudio.com/solutions/r-and-python/\" target=\"_blank\" rel=\"noopener noreferrer\">R &amp; Python: A Love Story</a>. What’s less well-known, however, is that when you write code in R Markdown within the IDE, you may also embed:</p> \n<ul> \n <li><strong>SQL code</strong> for accessing databases,</li> \n <li><strong>BASH code</strong> for shell scripts,</li> \n <li><strong>C and C++ code</strong> using the <code>Rcpp</code> package,</li> \n <li><strong>STAN code</strong> for doing statistical modeling,</li> \n <li><strong>Javascript</strong> for doing web programming,</li> \n <li><strong>and many more languages</strong>. You can find a complete list of the many platforms supported in the language engines chapter of the book, <a href=\"https://bookdown.org/yihui/rmarkdown/language-engines.html\" target=\"_blank\" rel=\"noopener noreferrer\">R Markdown: The Definitive Guide</a>.</li> \n</ul> \n<p>If you’re wondering how this could work, I’ve created a very simple example R Markdown document that demonstrates how languages can work together. It creates an in-memory database of <code>gapminder</code> data, queries it using SQL, prints the result of the query in R, plots the result using <code>matplotlib</code> in Python and saves the result as an image, and then prints the size of the image in BASH.</p> \n<pre class=\"markdown\">\n<code>\n---\ntitle: \"Multilingual R Markdown\"\nauthor: \"Carl Howe, RStudio\"\ndate: \"7/6/2020\"\noutput: html_document\n---\n```{r setup, include=FALSE, echo = TRUE}\nknitr::opts_chunk$set(echo = TRUE, collapse = TRUE)\nlibrary(tidyverse)\nlibrary(rlang)\nlibrary(reticulate)\nlibrary(RSQLite)\nlibrary(DBI)\nlibrary(gapminder)\nreticulate::use_python(\"/usr/local/bin/python3\", required = TRUE)\n```\n\n```{r gm_db_setup}\ngapminder_sqllite_db &lt;- dbConnect(RSQLite::SQLite(), \":memory:\")\ndbWriteTable(conn = gapminder_sqllite_db,\"gapminder\", gapminder)\ncountry &lt;- \"Switzerland\"\n```\n\n## use R variable `country` in SQL query\n```{sql connection = gapminder_sqllite_db, output.var=\"gmdata\"}\nSELECT * FROM gapminder WHERE country = ?country\n```\n\n## Access results of SQL query in R\n```{r}\nhead(gmdata, 5)\n##       country continent year lifeExp     pop gdpPercap\n## 1 Switzerland    Europe 1952   69.62 4815000  14734.23\n## 2 Switzerland    Europe 1957   70.56 5126000  17909.49\n## 3 Switzerland    Europe 1962   71.32 5666000  20431.09\n## 4 Switzerland    Europe 1967   72.77 6063000  22966.14\n## 5 Switzerland    Europe 1972   73.78 6401400  27195.11\n```\n\n## Plot in Python and save result as .png\n```{python}\nimport matplotlib.pyplot as plt\nplt.plot(r.gmdata.year, r.gmdata.lifeExp)\nplt.grid(True)\nplt.title(\"Switzerland Life Expectancy (years)\")\nplt.savefig(\"./SwitzerlandLifeExp.png\")\n```\n\n## Show size of Python plot using BASH\n```{bash}\nls -l SwitzerlandLifeExp.png\n## -rw-r--r--  1 chowe  staff  26185 Jul  7 17:26 SwitzerlandLifeExp.png\n```\n</code></pre> \n<figure> \n <img src=\"https://blog.rstudio.com/2020/07/07/interoperability-july/SwitzerlandLifeExp.png\" alt=\"Python Plot of Switzerland Life Expectancy\" /> \n <figcaption>\n  Figure 2: Resulting Python Plot of Switzerland Life Expectancy\n </figcaption> \n</figure> \n<p>Throughout the month of July, we’ll be devoting several articles to how RStudio supports interoperability and the benefits interoperability brings to data science teams. We encourage you to look for those subsequent posts this month. Meanwhile, to learn more about how interoperability improves the productivity of data science teams and some of the many platforms that RStudio supports, we recommend the following resources:</p> \n<ul> \n <li><a href=\"https://rstudio.com/resources/rstudioconf-2019/new-language-features-in-rstudio/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>New language features in RStudio</strong></a>: This rstudio::conf 2019 video by developer Jonathan McPherson talks about how the RStudio IDE dramatically improves support for many languages frequently used alongside R in data science projects, including SQL, D3, Stan, and Python.</li> \n <li><a href=\"https://rstudio.com/resources/webinars/r-python-a-data-science-love-story/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>R &amp; Python: A Data Science Love Story</strong></a>: This webinar with RStudio’s Lou Bajuk and Sean Lopp discusses how RStudio’s toolchain supports the use of both R and Python, including support for Jupyter notebooks.</li> \n <li><a href=\"https://rstudio.com/resources/rstudioconf-2019/ursa-labs-and-apache-arrow-in-2019/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Ursa Labs and Apache Arrow</strong></a>. In this rstudio::conf 2019 video, Wes McKinney talks about Ursa Labs’ work with Apache Arrow is dramatically speeding data sharing between R, Python, and other data science environments.</li> \n</ul>","descriptionType":"text/html","publishedDate":"Tue, 07 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"7975ce8fad1a1bda09ef932ac7fca674","bgimgJsdelivr":"","metaImg":"","author":"Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/07/interoperability-july/icecream-hero.jpg":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn69@2020_1/2020/08/25/00-02-56-608_a5cc6ee1dd550da8.webp","https://blog.rstudio.com/2020/07/07/interoperability-july/tiobe-july.jpg":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn85@2020_1/2020/08/25/00-02-56-459_51705e91675527bb.webp","https://blog.rstudio.com/2020/07/07/interoperability-july/SwitzerlandLifeExp.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn89@2020_2/2020/08/25/00-02-55-114_0e8b53c9fcccdf37.webp"},"publishedOrCreatedDate":1598313739856},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Interoperability: Getting the Most Out of Your Analytic Investments","link":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/sparklers-hero_hu33bcd405dbf51ce8ac52a47f3aeecdbd_506870_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/sparklers-hero.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/sparklers-hero.jpg\" width=\"800\" alt=\"Sparklers at night\" /> \n</div> \n<p>_Photo by <a href=\"https://unsplash.com/@federize?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" target=\"_blank\" rel=\"noopener noreferrer\">Federico Beccari</a> on <a href=\"https://unsplash.com/s/photos/connection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" target=\"_blank\" rel=\"noopener noreferrer\">Unsplash</a>_</p> \n<h3 id=\"the-challenges-of-complexity-and-underutilization\">The Challenges of Complexity and Underutilization</h3> \n<p>Organizations typically have multiple different environments and frameworks to support their analytic work, with each tool providing specialized capabilities or serving different audiences. These usually include:</p> \n<ul> \n <li><strong>Spreadsheets</strong> created in Excel or Google Sheets,</li> \n <li><strong>Data science tools</strong> including R, Python, SPSS, SAS, and many others,</li> \n <li><strong>BI tools</strong> such as Tableau or PowerBI,</li> \n <li><strong>Data storage and management frameworks</strong> including databases and Spark clusters,</li> \n <li><strong>Job management clusters</strong> such as Kubernetes and Slurm.</li> \n</ul> \n<p>For example, in our most recent R Community Survey, we asked what tools and languages respondents used besides R. The results shown in Figure 1 illustrate the wide variety of tools that may be present in an organization.</p> \n<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/tools-chart_hu8f1059083b10818c69ced0698b9d48b7_226736_1229x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/tools-chart.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/tools-chart.jpg\" width=\"1229\" alt=\"Tools Chart\" /> \n </div> \n <figcaption>\n  Figure 1: Respondents we surveyed use a wide variety of tools in addition to R.\n </figcaption> \n</figure> \n<p>These tools and frameworks provide flexibility and power but can also have two unpleasant, unintended consequences: <strong>productivity-undermining complexity</strong> for various stakeholders and <strong>underutilization of expensive analytic frameworks</strong>.</p> \n<p>The stakeholders in the organization experience these consequences because:</p> \n<ul> \n <li><strong>Data scientists require multiple environments to get their work done.</strong> If data scientists have to leave their native tools to access other things they need such as a Spark cluster or a database, they have to switch contexts and remember how to use systems they might only rarely touch. Often, this means they won’t fully exploit the data and other resources available, or they waste time learning and relearning various systems, APIs, languages, and interfaces.</li> \n <li><strong>Data science leaders worry about productivity.</strong> When their teams struggle in this way, these leaders worry that their teams aren’t delivering the full value that they could. This inefficiency can make it more difficult to defend budgets and hire additional team members when needed. These leaders may also face criticism from other departments demanding to know why the data science team isn’t fully utilizing expensive BI deployments or powerful computing resources.</li> \n <li><strong>IT spends time and money supporting underutilized resources.</strong> Analytic infrastructures such as Spark or Kubernetes require considerable resources to set up and maintain. If these resources are being underutilized, IT will question their lack of ROI and whether they should continue to maintain them. These questions can lead to uncomfortable internal friction between departments, particularly depending on who requested the investments in the first place and what expectations were used to justify them.</li> \n</ul> \n<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/interoperability_hu6ac60d5ee9bdf8071e064aee6a4cb1cc_92914_960x0_resize_box_2.png, https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/interoperability.png 2x\" src=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/interoperability.png\" width=\"960\" alt=\"Platforms diagram\" /> \n </div> \n <figcaption>\n   Figure 2: Interoperability is a key strength of the R ecosystem.\n </figcaption> \n</figure> \n<h3 id=\"teams-need-interoperable-tools\">Teams Need Interoperable Tools</h3> \n<p>Interoperable systems that give a data scientist direct access to different platforms from their native tools can help address these challenges. Everyone benefits from this approach because:</p> \n<ul> \n <li><strong>Data scientists keep working in their preferred environment.</strong> Rather than constantly switching between different tools and IDEs and interrupting their flow, data scientists can continue to work in the tools and languages they prefer. This makes the data scientist more productive and reduces the need to keep switching contexts.</li> \n <li><strong>Data science leaders get more productivity from their teams.</strong> When teams are more productive, they deliver more value to their organization. Delivered value helps them justify more training, tools, and team members. Easier collaboration and reuse of each other’s work further increases productivity. For example, if a data scientist who prefers R can easily call the Python script developed by a colleague from their preferred language, they avoid reimplementing the same work twice.</li> \n <li><strong>Teams make better use of IT resources.</strong> Since it is easier for data scientists to use the frameworks and other infrastructure IT has put in place, they use those resources more consistently. This higher utilization helps the organization achieve the expected ROI from these analytic investments.</li> \n</ul> \n<h2 id=\"encouraging-interoperability\">Encouraging Interoperability</h2> \n<p>Interoperability is a mindset more than technology. You can encourage interoperability throughout your data science team with four initiatives:</p> \n<ol> \n <li><strong>Embrace open source software.</strong> One of the advantages of open source software is the wide community providing specialized packages to connect to data sources, modeling frameworks, and other resources. If you need to connect to something, there is an excellent chance someone in the community has already built a solution. For example, as shown in Figure 2, the R ecosystem already provides interoperability with many different environments.</li> \n <li><strong>Make the data natively accessible.</strong> Good data science needs access to good up-to-date data. Direct access to data in the data scientist’s preferred tool, instead of requiring the data scientist to use specialized software, helps the data scientist be more productive and makes it easier to automate a data pipeline as part of a data product. Extensive resources exist to help, whether your data is in <a href=\"https://db.rstudio.com/\" target=\"_blank\" rel=\"noopener noreferrer\">databases</a>, <a href=\"https://spark.rstudio.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Spark clusters</a>, or elsewhere.<br /></li> \n <li><strong>Provide connections to other data science or ML tools.</strong> Every data scientist has a preferred language or tool, and every data science tool has its unique strengths. By providing easy connections to other tools, you expand the reach of your team and make it easier to collaborate and benefit from the work of others. For example, the <a href=\"https://rstudio.github.io/reticulate/\" target=\"_blank\" rel=\"noopener noreferrer\">reticulate</a> package allows an R user to call Python in a variety of ways, and the <a href=\"https://tensorflow.rstudio.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Tensorflow package</a> provides an interface to large-scale TensorFlow machine learning applications.</li> \n <li><strong>Make your compute environments natively accessible.</strong> Most data scientists aren’t familiar with job management clusters such as Kubernetes and Slurm and often struggle to use them. By making these environments available directly from their native tools, your data scientists are far more likely to use them. For example, <a href=\"https://rstudio.com/products/rstudio-server-pro/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Server Pro</a> allows a data scientist to run a script on a Kubernetes or Slurm cluster directly from within their familiar IDE.</li> \n</ol> \n<p>Eric Nantz, a Research Scientist at Eli Lilly and Company, spoke at rstudio::conf 2020 about the importance of interoperability in R:</p> \n<p><script src=\"https://fast.wistia.com/embed/medias/jyk6q0svdy.jsonp\" async=\"\"></script><script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_jyk6q0svdy videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/jyk6q0svdy/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div></p> \n<h2 id=\"learn-more-about-interoperability\">Learn more about Interoperability</h2> \n<p>In future posts, we will expand on this idea of Interoperability, with a particular focus on teams using R and Python, and how open source data science can complement BI tools.</p> \n<p>If you’d like to learn more about Interoperability, we recommend these resources:</p> \n<ul> \n <li><a href=\"https://blog.rstudio.com/2020/07/07/interoperability-july/\" target=\"_blank\" rel=\"noopener noreferrer\">In this recent blog post</a>, we introduced the idea of interoperability with an example of calling multiple different languages from the RStudio IDE.</li> \n <li><a href=\"https://rstudio.com/about/customer-stories/brown-forman/\" target=\"_blank\" rel=\"noopener noreferrer\">In this recent customer spotlight</a>, Paul Ditterline, Manager Data Science at Brown-Forman, describes how RStudio products helped their data science team “turn into application developers and data engineers without learning any new languages or computer science skills.”</li> \n <li><a href=\"https://solutions.rstudio.com/production/integrations/\" target=\"_blank\" rel=\"noopener noreferrer\">This article</a> describes how RStudio products integrate with many different frameworks, including databases, Spark, Kubernetes, Slurm, Git, etc.</li> \n <li><a href=\"https://rstudio.com/solutions/r-and-python/\" target=\"_blank\" rel=\"noopener noreferrer\">R and Python, a Love Story</a> shows how RStudio products helped bilingual data science teams collaborate more productively, and have a greater impact on their organization.</li> \n <li>At rstudio::conf 2020, George Kastrinakis from Financial Times <a href=\"https://rstudio.com/resources/rstudioconf-2020/building-a-new-data-science-pipeline-for-the-ft-with-rstudio-connect/\" target=\"_blank\" rel=\"noopener noreferrer\">presented a case study</a> on building a new data science pipeline, using R and RStudio Connect.</li> \n</ul>","descriptionType":"text/html","publishedDate":"Wed, 15 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"097471c73b959a4994817ed8b3269efe","bgimgJsdelivr":"","metaImg":"","author":"Lou Bajuk, Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/sparklers-hero.jpg":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn2@2020_1/2020/08/25/00-02-55-078_d5847c8b243a7687.webp","https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/tools-chart.jpg":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn10@2020_1/2020/08/25/00-02-55-209_c8d3fe868e514bd8.webp","https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/interoperability.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn38@2020_1/2020/08/25/00-02-55-019_6da3fc4b49a62df6.webp","https://fast.wistia.com/embed/medias/jyk6q0svdy/swatch":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn6@2020_1/2020/08/25/00-02-56-279_2d10e83e90e54d15.webp"},"publishedOrCreatedDate":1598313739856},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"3 Wild-Caught R and Python Applications","link":"https://blog.rstudio.com/2020/07/28/practical-interoperability/","description":"<p>A colleague recently asked me an intriguing question:</p> \n<p>“Do you know of any good examples of R and Python interoperability being used to solve real-world problems instead of just toy examples?”</p> \n<p>I had to admit that I hadn’t gone looking for such examples but that I’d see if I could find any. So I put the following query out on Twitter:</p> \n<blockquote> \n <p>Does anyone have a cool mixed R and Python app (probably in R Markdown but not required) that they’d like to share? Ideally it would be one that shows both languages to their best advantage.</p> \n</blockquote> \n<p>I received several responses to my plea, so I thought I’d share them here to illustrate some of the characteristics of R interoperability “in the wild.” At the end, I’ll use these examples to discuss three broad motivations for interoperability that readers may find useful.</p> \n<p><br /></p> \n<h3 id=\"example-1-wrapping-a-user-interface-around-a-simulation\">Example 1: Wrapping a User Interface Around A Simulation</h3> \n<figure> \n <a href=\"https://tomicapretto.shinyapps.io/simulation-app\" target=\"_blank\" rel=\"noopener noreferrer\"> \n  <div style=\"padding: 35px 0 0 0;\"> \n   <img srcset=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/simulation_huf2899d6f70360f0ff36bef024ea46923_148746_772x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/28/practical-interoperability/simulation.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/simulation.jpg\" width=\"772\" alt=\"Simulation screen shot\" /> \n  </div> </a> \n <figcaption>\n   Figure 1: A Shiny App that estimates densities using Python \n </figcaption> \n</figure> \n<p>The first example I’d like to share is a simulation built by Tomas Capretto (@CaprettoTomas), who described it as follows:</p> \n<blockquote>\n  I have an application built on Shiny that uses functions to estimate densities \n <br> written in Python. It works both in http://shinyapps.io and locally.<br> Online app: <a href=\"https://tomicapretto.shinyapps.io/simulation-app\" target=\"_blank\" rel=\"noopener noreferrer\"> https://tomicapretto.shinyapps.io/simulation-app/</a><br> More info: <a href=\"https://github.com/tomicapretto/density_estimation\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/tomicapretto/density_estimation</a><br> </br></br></br></br> \n</blockquote> \n<p>As I’ll discuss in the next section, this application shows a common division of labor in interoperable applications: it uses an interactive user interface based on Shiny that then calls a collection of Python routines that do the primary computation.</p> \n<p>By the way, another of my respondents, Nikolay Dudaev (@nikdudaev), built his application to work the other way around from this first one:</p> \n<blockquote> \n <p>There is something I cannot share but I do all the analysis, tidying, transformations etc in R and then display the results in the app written in Python and Dash.</p> \n</blockquote> \n<p><br /></p> \n<h3 id=\"example-2-processing-lake-catchment-data-using-a-gis\">Example 2: Processing Lake Catchment Data Using a GIS</h3> \n<figure> \n <a href=\"https://fishandwhistle.net/post/2020/calling-qgis-from-r/\" target=\"_blank\" rel=\"noopener noreferrer\"> \n  <div style=\"padding: 35px 0 0 0;\"> \n   <img srcset=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/catchment_hu156d6c127a112a3b8a29b51bfc859b17_46595_340x0_resize_box_2.png, https://blog.rstudio.com/2020/07/28/practical-interoperability/catchment.png 2x\" src=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/catchment.png\" width=\"340\" alt=\"Lake Catchment Analysis\" /> \n  </div> </a> \n <figcaption>\n   Figure 2: A lake watershed computed with the help of SAGA and GRASS GIS algorithms. \n </figcaption> \n</figure> \n<p>Another common interoperability use case is using another language to gain access to a unique code base. In this case, Dewey Dunnington (@paleolimbot ) needed a Geographic Information System (GIS) installer called QGIS, which gives him access to SAGA and GRASS GIS systems.</p> \n<blockquote>\n  Not sure if this totally fits the bill, but it's Python + R working together in the same blog post! \n <br> <a href=\"https://fishandwhistle.net/post/2020/calling-qgis-from-r/\" target=\"_blank\" rel=\"noopener noreferrer\">https://fishandwhistle.net/post/2020/calling-qgis-from-r/</a> </br> \n</blockquote> \n<p>While Dewey notes that he could have done this using R libraries that access the SAGA and GRASS systems, he ultimately decided that it was easier just to call the Python versions which already had QGIS installed.</p> \n<p><br /></p> \n<h3 id=\"example-3-multi-omics-factor-analysis\">Example 3: Multi-Omics Factor Analysis</h3> \n<figure> \n <a href=\"https://github.com/bioFAM/MOFA2\" target=\"_blank\" rel=\"noopener noreferrer\"> \n  <div style=\"padding: 35px 0 0 0;\"> \n   <img srcset=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/mofa_hu1a690b177a27673d203d8938cbb0d492_490864_1377x0_resize_box_2.png, https://blog.rstudio.com/2020/07/28/practical-interoperability/mofa.png 2x\" src=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/mofa.png\" width=\"1377\" alt=\"MOFA \" /> \n  </div> </a> \n <figcaption>\n   Figure 3: MOFA infers an interpretable low-dimensional representation in terms of a few latent factors. \n </figcaption> \n</figure> \n<p>OK, I admit it: I only have the vaguest idea of what this program does. Fortunately the repository pointed to by Ryan Thompson’s (@DarwinAwdWinner) tweet provides a pretty good description, provided you know about multi-omic data sets.</p> \n<blockquote>\n  MOFA is written partly in Python and partly in R: \n <br> <a href=\"https://github.com/bioFAM/MOFA2\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/bioFAM/MOFA2</a> </br> \n</blockquote> \n<p>See Ryan’s Github repo for more details. Interoperability takes place during the processing workflow as follows: 1. The user loads the source data and trains the model using either a Python notebook or R code (which calls Python code using the <code>reticulate</code> package). Both versions process the training data and output a model. 2. The model data is then processed downstream for viewing and interactive exploration using Shiny. At present, the downstream process only runs in R.</p> \n<p><br /></p> \n<h2 id=\"interoperability-helps-data-scientists-avoid-reinventing-the-wheel\">Interoperability Helps Data Scientists Avoid Reinventing the Wheel</h2> \n<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/interoperability-hexes_hu3130671f8ed27b89048e40eb3f36a2ad_86953_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/07/28/practical-interoperability/interoperability-hexes.jpg 2x\" src=\"https://blog.rstudio.com/2020/07/28/practical-interoperability/interoperability-hexes.jpg\" width=\"800\" alt=\"Three Interoperability motivations\" /> \n </div> \n <figcaption>\n   Figure 4: Three motivations for writing interoperable code. \n </figcaption> \n</figure> \n<blockquote> \n <p>“If I have seen further, it is by standing on the shoulders of giants.” – Isaac Newton, 1675</p> \n</blockquote> \n<p>When faced with a difficult challenge in their jobs, few data scientists say to themselves, “I think I’ll include new languages in my analysis just for fun.” Instead, data scientists typically write interoperable code to solve problems and to build on the work of others, just as Isaac Newton said 345 years ago.</p> \n<p>Our examples above illustrate three motivations that underlie many interoperable applications. These motivations frequently overlap and in some situations, all three might apply. Nonetheless, many interoperable applications come about because data scientists want to:</p> \n<ul> \n <li><strong>Accelerate results.</strong> Tomas Capretto, the author of our first example, wrapped some existing Python simulation code in a Shiny application to allow interactive exploration of the simulation results. While he could have achieved the same goal by rewriting his interactive simulation entirely in R, he instead used existing code to create a shorter path to the result he was trying to achieve. This approach meant his users could interact with his simulation right away instead of waiting for him to rewrite the simulator (our June blog post “<a href=\"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/\" target=\"_blank\" rel=\"noopener noreferrer\">Is Your Data Science Team Agile?</a>” provides more details of why this type of agility is important).</li> \n <li><strong>Access specialized knowledge.</strong> Dewey Dunnington needed access to SAGA and GRASS GIS systems because those geographical information systems contain algorithms that represent the gold standard for GIS work. While R and Python boast tens of thousands of libraries and modules, we shouldn’t expect them each to contain every key algorithm for every field of research, especially as fields of study have become increasingly more specialized. Interoperable code allows us to build on that prior work that’s been done, regardless of what language it was written in.</li> \n <li><strong>Participate in an ecosystem.</strong> Ryan Thompson’s application demonstrates another type of mixed R and Python workflow. His front-end R and Python notebooks allow data scientists to collect data using whichever tool they are more comfortable with, and the model created by those front-end notebooks then drives an R-only downstream processing step. His MOFA model is one of many used in the the open source <a href=\"https://bioconductor.org\" target=\"_blank\" rel=\"noopener noreferrer\"><em>bioconductor.org</em></a> community, which includes hundreds of developers writing primarily in R. Similar large communities have built up around Python-based machine learning packages such as <a href=\"https://tensorflow.rstudio.com\" target=\"_blank\" rel=\"noopener noreferrer\"><em>tensorflow</em></a> and <a href=\"https://keras.rstudio.com\" target=\"_blank\" rel=\"noopener noreferrer\"><em>keras</em></a>, and around cluster-based computing via the <a href=\"https://spark.rstudio.com\" target=\"_blank\" rel=\"noopener noreferrer\"><em>sparklyr</em></a> package for R. Writing interoperable code allows data scientists to both participate in and contribute to those communities, even if they aren’t fluent in the native programming language of each group. Better yet, these cross-language projects expand the population of the communities and encourage the sustainability of their code bases for the greater world.</li> \n</ul> \n<p>The examples I’ve given here are only a small subset of many interoperability efforts taking place in the R and Python communities. If you have other interoperability examples you’d like to showcase, please send me an email at <a href=\"mailto::carl@rstudio.com\" target=\"_blank\" rel=\"noopener noreferrer\">carl@rstudio.com</a> or tag me on Twitter at @cdhowe. I’m particularly interested in how you arrived at your interoperability approach and what benefits you gained from interoperability.</p>","descriptionType":"text/html","publishedDate":"Tue, 28 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"0666e48ece98e7a7a00af8a4b6e33c0a","bgimgJsdelivr":"","metaImg":"","author":"Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/28/practical-interoperability/simulation.jpg":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn9@2020_6/2020/08/25/00-02-56-534_22c21e11bd4d78aa.webp","https://blog.rstudio.com/2020/07/28/practical-interoperability/catchment.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn14@2020_3/2020/08/25/00-02-55-152_b0cf55bcddf74988.webp","https://blog.rstudio.com/2020/07/28/practical-interoperability/mofa.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn50@2020_3/2020/08/25/00-02-56-186_16d7770ecf581f0b.webp","https://blog.rstudio.com/2020/07/28/practical-interoperability/interoperability-hexes.jpg":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn62@2020_4/2020/08/25/00-02-55-028_7eab7d878cb06bf2.webp"},"publishedOrCreatedDate":1598313739855},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"How to Deliver Maximum Value Using R & Python ","link":"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img src=\"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/legos.jpeg\" style=\"display:block;margin-left:auto;margin-right:auto;\"> </img>\n</div> \n<p style=\"text-align: right !important;margin-top: 0px;margin-bottom: 30px;\"> <i>Photo by <a style=\"color: #000000;\" href=\"https://unsplash.com/@vladhilitanu\">Vlad Hilitanu</a> on <a style=\"color: #000000;\" href=\"https://unsplash.com/photos/1FI2QAYPa-Y\">Unsplash</a></i></p> \n<p><em>This is a guest post from RStudio’s partner, <a href=\"https://www.landeranalytics.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Lander Analytics</a></em></p> \n<p>R and Python are two of the more prominent data science languages. These languages didn’t become popular by accident, they grew by making their tools easier and more productive. Python’s Pandas allowed Python to create heterogeneous <a href=\"https://twitter.com/chendaniely/status/1279142678656155654\" target=\"_blank\" rel=\"noopener noreferrer\">panel data</a> inspired by R’s <code>data.frame</code> object. R’s <em>caret</em> and <em>tidymodels</em> libraries unified the machine learning API just like Python’s <em>scikit-learn</em>.</p> \n<p>Look under the hood of most applications and libraries and you’ll eventually find a different language from the one you’re using. This isn’t a new concept; each language has their own strengths. Generally, though, the more interoperable languages are, the easier an end-user can pick the tool best suited for their work.</p> \n<p>This is why language wars never made sense and many core developers never participate in the “mine is better” debate. Groups such as <a href=\"https://ursalabs.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Ursa Labs</a>, using projects such as <a href=\"https://arrow.apache.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Apache Arrow</a>, are even trying to expand interoperability across more languages.</p> \n<p>As the RStudio team discussed in a <a href=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/\" target=\"_blank\" rel=\"noopener noreferrer\">recent blog post</a>, the more interoperable these languages become, the better for us as data scientists to pick the tool we know for the task at hand. The next question for newcomers naturally becomes: which language should I learn?</p> \n<p>I’ve talked about this in the <a href=\"https://chendaniely.github.io/2019/08/28/r-or-python-which-one-to-learn-first/\" target=\"_blank\" rel=\"noopener noreferrer\">past</a>. Essentially, it does not matter. But the language that is being used in the place you want to work in, friends that know a language and you can potentially ask for help, or even the first tutorial that you read online that resonated the best with you, are all subjective ways to help you pick the “first” language. The data skills around manipulating data into tidy format are transferable across languages. Learning how to think sequentially and breaking down problems are all skills you learn by doing; You will rarely meet another data scientist or programmer who doesn’t know how to at least “read” another language.</p> \n<p>In general, I recommend that you should choose your language based on its support of:</p> \n<ul> \n <li>Tidy data principles</li> \n <li>Interactive interfaces</li> \n <li>Powerful Libraries</li> \n <li>Interoperability with everything else you use</li> \n</ul> \n<p>From a data science perspective, I recommend using <a href=\"https://r4ds.had.co.nz/tidy-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">tidy data principles</a> as the central point to learn a new language. Over time, you’ll certainly find something “on the other side,” that you will want to try out. For example, I love how I can <a href=\"https://speakerdeck.com/chendaniely/using-python-with-r\" target=\"_blank\" rel=\"noopener noreferrer\">program microcontrollers with Python using MicroPython and CircuitPython</a>, and how easy the R ecosystem has made communicating results and findings.</p> \n<p>This means I can work on a Python analysis (or Python-using team) and easily deploy Shiny applications around it using <em>reticulate</em>. Conversely, we could convert R output into a plumber REST API for our Python Django, Flask, or Pyramid application, or even directly run R using <em>rpy2</em>. These interfacing layers allow maintainers to only maintain a wrapper and not a full re-implementation of a library. As an R user, this also means R libraries can be created around Python libraries so the R community does not need to re-implement Python tools. The R Keras package is a great example of taking a fully maintained Python package and wrapping it for R users using <em>reticulate</em>. With tools like <em>reticulate</em>, you have a simple way to call Python natively within R.</p> \n<p>The most common Python data types are also seamlessly accessible as R objects, which means you can incorporate Python into all of the R publication and communication tools like Shiny and RMarkdown. The converse is also true from the Python perspective. R code can be run within Python using <em>rpy2</em>, which means popular Python web frameworks can also benefit from R pipelines. If the language itself does not matter, why not learn both and leverage the best of both worlds simultaneously?</p> \n<p>Data science teams should be multilingual and the need for dual Python and R training is evident in data science programs (e.g., <a href=\"https://ubc-mds.github.io/2020-02-03-teach-python-and-r/\" target=\"_blank\" rel=\"noopener noreferrer\">University of British Columbia</a>) that aim to teach both simultaneously. This isn’t without its challenges, but it is acknowledging and addressing the need for eventually knowing both Python and R. New data science tools inspired by another language benefits us all as data scientists. The ease of interoperability gives the user the flexibility to fill in any tool gaps for their own needs. Instead of “what language should I use”, you now think about the whole team and consider which programming interface best resonates with the users, or which infrastructure stack so the SysAdmins feel most comfortable in deploying and maintaining.</p> \n<hr /> \n<p><strong>About Lander Analytics:</strong></p> \n<p><a href=\"https://www.landeranalytics.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/lander-logo.jpg\" alt=\"Lander Analytics logo\" align=\"left\" /></a>An RStudio <a href=\"https://rstudio.com/certified-partners/\" target=\"_blank\" rel=\"noopener noreferrer\">Full Service Partner</a>, Lander Analytics is a New York-based data science firm, whose staff specializes in statistical consulting and infrastructure, running the full gamut of RStudio product assistance from procurement, implementation and installation to ongoing maintenance and support. They also provides open source training services for R, Python, Stan, Deep Learning, SQL and numerous other languages.</p>","descriptionType":"text/html","publishedDate":"Thu, 13 Aug 2020 00:00:00 +0000","feedId":8609,"bgimg":"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/legos.jpeg","linkMd5":"9eb540cf39b3f0e434d65ecde8b7e822","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn71@2020_6/2020/08/25/00-02-24-801_d9bd1f2e9fbbcac8.webp","destWidth":1050,"destHeight":700,"sourceBytes":131282,"destBytes":70044,"author":"Dan Chen, Lander Analytics","articleImgCdnMap":{"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/legos.jpeg":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn71@2020_6/2020/08/25/00-02-24-801_d9bd1f2e9fbbcac8.webp","https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/lander-logo.jpg":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn66@2020_6/2020/08/25/00-02-54-936_2468eaa091d6f43b.webp"},"publishedOrCreatedDate":1598313739854},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"rstudio::global() talk deadline extension","link":"https://blog.rstudio.com/2020/08/13/rstudio-global-talk-deadline-extension/","description":"<p>We’ve received requests from a number of you to <a href=\"https://blog.rstudio.com/2020/07/17/rstudio-global-call-for-talks/\">submit talks for rstudio::global()</a> after the deadline (tomorrow, August 14). We know things are particuarly tough at the moment, so we’re extending the deadline by two weeks for everyone;&nbsp;<strong>the new submission deadline is August 28</strong> at 11:59PM PDT. We’ll aim to get decisions back by late September.</p> \n<p><a href=\"https://forms.gle/5mzcMKd75xaDf2zi9\"><strong>APPLY NOW!</strong></a></p>","descriptionType":"text/html","publishedDate":"Thu, 13 Aug 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"f0fb38dd5a9d44024a357df066166951","bgimgJsdelivr":"","metaImg":"","author":"Hadley Wickham","publishedOrCreatedDate":1598313739854},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Do, Share, Teach, and Learn Data Science with RStudio Cloud","link":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/","description":"<div style=\"padding: 35px 0 15px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-1600_huccc8efdc8d312ddf524b7505433f11b7_33972_800x0_resize_box_2.png, https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-1600.png 2x\" src=\"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-1600.png\" width=\"800\" alt=\"Clouds\" /> \n</div> \n<p>RStudio is proud to announce the general availability of <a href=\"https://rstudio.cloud/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Cloud</a>, its cloud-based platform for doing, teaching, and learning data science using only a browser. This general release incorporates feedback from thousands of users, based on more than 3.5 million hours of compute time.</p> \n<h2 id=\"what-is-rstudio-cloud\">What is RStudio Cloud?</h2> \n<p>RStudio Cloud is a lightweight, cloud-based solution that allows anyone to do, share, teach, and learn data science online. RStudio Cloud makes it easy to:</p> \n<ul> \n <li><strong>Analyze your data</strong> using the RStudio IDE, directly from your browser.</li> \n <li><strong>Share projects</strong> with your team, class, workshop, or the world.</li> \n <li><strong>Teach data science</strong> with R to your students or colleagues.</li> \n <li><strong>Learn data science</strong> in an instructor-led environment or with interactive tutorials.</li> \n</ul> \n<p>With RStudio Cloud, there’s nothing to configure, and no dedicated hardware or installation is required. Individual users, instructors, and students only need a browser.</p> \n<p>We will always offer a free plan for casual use, and we now offer paid premium plans for professionals, instructors, researchers, and organizations as well. Learn more about what plans are <a href=\"https://rstudio.cloud/plans/free\" target=\"_blank\" rel=\"noopener noreferrer\">available here</a>.</p> \n<p>RStudio Cloud is a great platform for both casual and professional data scientists. The ability to share projects makes it easy for researchers from different groups or institutions to collaborate and is useful for any data science team that wants to build and share data science work without having to maintain their own IT infrastructure. With this release, our new premium offerings also give users the option of scaling their environments up to more cores and memory if needed.</p> \n<p>We have many exciting features planned over the coming months. This first release focuses on helping users teach and learn Data Science. These capabilities have been refined through extensive alpha/beta testing by over a thousand academic institutions and other organizations.</p> \n<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/tutorial-screen_huf2899d6f70360f0ff36bef024ea46923_237974_702x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/tutorial-screen.jpg 2x\" src=\"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/tutorial-screen.jpg\" width=\"702\" alt=\"Tutorial Screenshot\" /> \n </div> \n <figcaption>\n  <em>Figure 1: RStudio Cloud Primers help you learn the basics of data science via interactive tutorials. See <a href=\"https://rstudio.cloud/learn/primers\" target=\"_blank\" rel=\"noopener noreferrer\">https://rstudio.cloud/learn/primers</a> for more information.</em>\n </figcaption> \n</figure> \n<p>RStudio Cloud simplifies the process of teaching R, whether to students or colleagues, by letting the instructor focus on the content, not the infrastructure. Students learn directly from their web browsers, with nothing to install locally, and with no infrastructure for the instructor to maintain.</p> \n<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-components_hudbae7d7af69610e840855db46f8b345e_207278_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-components.jpg 2x\" src=\"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-components.jpg\" width=\"800\" alt=\"Cloud Components\" /> \n </div> \n <figcaption>\n  <em>Figure 2: Create projects within your personal workspace to teach and share with others.</em>\n </figcaption> \n</figure> \n<p>As shown in Figure 2, RStudio Cloud is designed from the ground up to make data science teaching easier for instructors and students, including new features such as:</p> \n<ul> \n <li><strong>Projects:</strong> The fundamental unit of work on RStudio Cloud, projects encapsulate R code, packages and data files and provide isolation from other analyses. Projects can be public or private.</li> \n <li><strong>Spaces:</strong> Every RStudio Cloud user gets a personal workspace in which to create projects. You can also create private, shared spaces that function as virtual classrooms for courses and workshops.</li> \n <li><strong>Members:</strong> Users who can access a space. Members can be assigned different roles, giving them capabilities appropriate for instructors, TAs and students.</li> \n <li><strong>Assignments:</strong> When teaching a class or workshop, projects can be made into assignments. Students can make copies of projects created by the instructor, with the necessary environment automatically replicated. Instructors can peek into student projects and check their progress.</li> \n</ul> \n<p>To learn more or sign up for free, visit <a href=\"https://rstudio.cloud/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Cloud</a> or check out our recent webinar on <a href=\"https://rstudio.com/resources/webinars/teaching-r-online-with-rstudio-cloud/\" target=\"_blank\" rel=\"noopener noreferrer\">Teaching R Online with RStudio Cloud</a>.</p>","descriptionType":"text/html","publishedDate":"Wed, 05 Aug 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"d1d11e70c6eb49eb96fd02351cc04c5e","bgimgJsdelivr":"","metaImg":"","author":"Lou Bajuk","articleImgCdnMap":{"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-1600.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn14@2020_5/2020/08/25/00-02-55-324_30e5b585f794977e.webp","https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/tutorial-screen.jpg":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn82@2020_2/2020/08/25/00-02-56-936_5ebb8261b9bb99c8.webp","https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-components.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn1@2020_4/2020/08/25/00-02-55-081_b450af8f420eb25d.webp"},"publishedOrCreatedDate":1598313739855},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Getting to the Right Question","link":"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/","description":"<h2 id=\"the-root-problem-we-don-t-all-speak-the-same-language\">The Root Problem: We Don’t All Speak the Same Language</h2> \n<p>Organizations across the modern business world recognize the critical importance of Data Science for competitive advantage. That recognition has driven Glassdoor to rate Data Scientist as <a href=\"https://www.glassdoor.com/List/Highest-Paying-Jobs-LST_KQ0,19.htm\">one of the 25 top paying jobs in America in 2020</a>.</p> \n<p>However, many organizations struggle to put these data scientists’ knowledge to work in their businesses where they can actually have an impact on success. We hear data scientists say, “The business can’t really tell us what they want, so they waste a lot of our time.” And in return, business people often say, “Our data scientists are really smart, but the applications they build too often fall short of what we’re looking for.”</p> \n<p>The problem here is that data scientists and business people speak very different languages. Specifically, they struggle to understand each other around:</p> \n<ul> \n <li><strong>data.</strong> When a business person thinks about data associated with the business, they often are thinking about data that they can see in Web pages or spreadsheets. Data scientists, on the other hand, are usually looking for data that they can access using an Application Programming Interface or API.</li> \n <li><strong>process.</strong> When business people think about the process for analysis, they tend to think in people-centric terms along the lines of “Becky takes the order, and then transmits that data to George.” Data scientists, on the other hand, usually think of process as a series of automated programs that works without people.</li> \n <li><strong>results.</strong> Data scientists think of a result as an analysis running and producing correct output. Business people see a result as something that has an effect on the organization’s (usually financial) metrics. These are rarely the same thing, at least in the first version of a data science project.<br /></li> \n</ul> \n<p>Both points of view are valid – they just aren’t the same, which creates a communications gap.</p> \n<h2 id=\"iterative-development-can-overcome-the-communications-gap\">Iterative Development Can Overcome the Communications Gap</h2> \n<p><em>“An approximate answer to the right question is worth a great deal more than a precise answer to the wrong question.”</em> –John Tukey</p> \n<h3 id=\"astellas-aymen-waqar-discusses-the-analytics-communications-gap\">Astellas’ Aymen Waqar discusses the analytics communications gap:</h3> \n<div style=\"padding: 15px 40px 35px 40px;text-align: center;\"> \n <script src=\"https://fast.wistia.com/embed/medias/iwmemji2xh.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <span class=\"wistia_embed wistia_async_iwmemji2xh popover=true popoverAnimateThumbnail=true videoFoam=true\" style=\"display:inline-block;height:100%;position:relative;width:100%\">&nbsp;</span>\n  </div>\n </div> \n</div> \n<p>These communications gaps are part of a larger challenge of defining (and refining) the problem. While your business stakeholder might believe they have a clear definition of the problem they are trying to solve, they may not understand whether the data is available, how complex the modeling might be or how long building a model on large data might take, or what adjacent problems might be potentially more valuable and/or far simpler to solve. So, before starting the development process, the data scientist and the business stakeholder must explore and discuss the problem in enough detail to create a realistic development plan. And while data scientists and business people may struggle to understand each other’s words, they usually can agree if they can just see a working model. The difficult part is getting to that working model.</p> \n<h2 id=\"a-commonly-used-data-exploration-process-can-help\">A Commonly Used Data Exploration Process Can Help</h2> \n<p>One way to get to agreement is to break down the project into simpler pieces and get agreement on each piece before moving on to the next. Garrett Grolemund and Hadley Wickham propose the following process below in their book <a href=\"https://r4ds.had.co.nz\"><em>R for Data Science</em></a>. This process isn’t specific to any technology such as R or Python. Rather it’s a way to get your data scientist and business sponsor to come to consensus on what question they are attacking.</p> \n<div align=\"center\" style=\"padding: 35px 0 35px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/process2_hu840e541eb9c20db57a0f157bce88fcd7_298855_1199x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/process2.jpg 2x\" src=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/process2.jpg\" width=\"1199\" alt=\"A visualization of the data science process\" /> \n</div> \n<p>The four steps are</p> \n<ol> \n <li><strong>Import</strong>. Identify the data you plan to use, and focus first on importing that data so you can work with it.</li> \n <li><strong>Tidy</strong>. Now that you have the data in hand, reshape and manipulate the data into a form that your analysis tools can easily work with.</li> \n <li><strong>Understand</strong>. This step is where your data scientists should be interacting most with sponsors by turning the data into visuals and models, and getting feedback about whether they satisfy the business needs.</li> \n <li><strong>Communicate</strong>. Once you have consensus on what you’re building, this is where you simplify and polish the result so that everyone will understand the result.</li> \n</ol> \n<h2 id=\"four-recommendations-for-applying-this-process\">Four Recommendations For Applying This Process</h2> \n<p>Many data scientists (or at least those who have read <em>R for Data Science</em>) use this type of process for doing analysis. However, fewer think of using it as a communications tool to ensure they are answering the proper business questions. You can help your data scientists apply this approach; encourage them to:</p> \n<ul> \n <li><strong>Schedule check-ins at each step.</strong> Before you begin, set up regular check-ins with your business sponsors. Ideally, these should roughly correspond with the development phases listed above to ensure that everyone is in sync before moving on to the next phase.</li> \n <li><strong>Use rapid prototyping tools and languages.</strong> R and Python are the tools of choice for most data scientists because they are well-suited to the type of iterative development process being described here. Both languages speed development and have excellent visualization tools which will help drive consensus.</li> \n <li><strong>Document progress using public documents.</strong> Use a single Google Docs file to record each meeting and to record decisions. Don’t start a new document with each meeting, but simply prepend the date and the most recent meeting notes at top. By the time the project is done, you’ll have a record of the entire process from beginning to end which will help plan future projects.</li> \n <li><strong>Defer performance concerns until you have an agreed result.</strong> Too many projects get bogged down designing for full-scale deployment before they actually know what they are building. Instead, develop a prototype that everyone agrees is the right idea, and then revise it to scale up when you decide to put it into production. This approach simplifies early decision-making and doesn’t waste precious project time on premature optimizations.</li> \n</ul> \n<p>Once the application satisfies both your data scientists and business stakeholders, you’ll want to share the finished application with the wider business community. One of the easiest ways to do this is through <em>RStudio Connect</em>, which can help you rapidly refine your content during the prototyping phase, and share it widely and consistently in the production phase. We will talk more about that in our next blog post. Meanwhile, to learn more about how Connect can add push-button publishing, scheduled execution of reports, and flexible security policies to your team’s data science work, please visit the <a href=\"https://rstudio.com/products/connect/\">RStudio Connect product page</a>.</p> \n<div style=\"padding: 25px 0 25px 0;\"></div>","descriptionType":"text/html","publishedDate":"Wed, 22 Apr 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"5c74c2ad7961b0ea8491162615e3eca1","bgimgJsdelivr":"","metaImg":"","author":"Carl Howe, RStudio","articleImgCdnMap":{"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/process2.jpg":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn78@2020_4/2020/08/25/00-02-56-672_fc449398b040cae0.webp"},"publishedOrCreatedDate":1598313739860},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Is Your Data Science Team Agile?","link":"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/","description":"<p><style type=\"text/css\"> table { border-top: 1px solid rgba(117,170,219,.6); border-bottom: 1px solid rgba(117,170,219,.6); margin: 45px 0 45px 0; padding: 40px 0 20px 0; } tr:nth-child(even) { background: #ffffff; } tr { vertical-align: top; } th { font-size: 24px; font-weight: 400; } td li { font-size: 15px; } </style> \n <div style=\"padding: 35px 0 35px 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/winding-path-hero_hu33bcd405dbf51ce8ac52a47f3aeecdbd_599743_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/winding-path-hero.jpg 2x\" src=\"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/winding-path-hero.jpg\" width=\"800\" alt=\"Winding path through woods\" /> \n </div></p> \n<p><em>Photo by <a href=\"https://unsplash.com/@vespir?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" target=\"_blank\" rel=\"noopener noreferrer\">James Forbes</a> on <a href=\"https://unsplash.com/s/photos/winding-path-through-woods?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" target=\"_blank\" rel=\"noopener noreferrer\">Unsplash</a></em></p> \n<p>As we recently wrote in our first post on <a href=\"https://deploy-preview-290--rstudio-blog.netlify.app/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">Serious Data Science</a>, there are numerous challenges to effectively implementing data science in an organization. Many industry surveys warn that <strong>most analytics and data science projects fail</strong>, and <strong>most companies don’t achieve the revenue and profit growth that they hoped</strong> their data science investments would deliver. In this post, we’ll examine some underlying causes of why this happens.</p> \n<p>In our previous post in this series, we discussed how to tackle <a href=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/\" target=\"_blank\" rel=\"noopener noreferrer\">building credibility for your data science team</a>. Here, we will focus on the challenges of quickly delivering real value with your data science team with a platform that supports an agile approach.</p> \n<h2 id=\"data-science-development-is-often-a-long-and-winding-path-to-value\">Data Science Development is Often a Long and Winding Path to Value</h2> \n<p>In talking with many different data science teams, we’ve heard that it takes far too long for a team to ramp up, perform analyses, and then share those analyses in an impactful way with their organization. This makes it challenging for data science leaders to deliver value to the rest of their organization, which in turn makes it difficult to justify buying new tools, hiring new team members, and investing in their training.</p> \n<p>Several common obstacles make it difficult for a data science team to quickly ramp up and be productive:</p> \n<ul> \n <li><strong>Training on new tools:</strong> When an organization invests in a new data science platform or brings in new team members unfamiliar with that tool, teams often require extensive training before they can start reliably delivering analyses.</li> \n <li><strong>Monolithic applications:</strong> Too many data science development projects try to solve all problems at once by building or buying a single grand solution. Frequently these new massive tools take months to implement, require major changes to processes and demand significant configuration and professional services before they can be used effectively. And, if the new platforms don’t integrate well with existing tools, data scientists are forced to use multiple different environments to get their work done, which impedes their productivity and often leads to those analytic investments being under-utilized.</li> \n <li><strong>Slow exploratory development:</strong> Good data science requires the ability to rapidly explore many approaches to solving a problem and to revise proposed solutions with colleagues and stakeholders. However, many firms adopt point-and-click model development tools in their quests for ease of use, not realizing that those interactive systems lock data scientists into hours of manual labor to create a new version when stakeholders request changes.</li> \n <li><strong>Difficult to share and access results:</strong> Finally, if your stakeholders cannot find your data products, they won’t use them. Too many insights get delivered using ad hoc emails or isolated web links because existing tools make it difficult to deploy data science insights without extensive help from IT. This leads to stakeholders frequently struggling to find results, using analyses based on old data, or waiting too long to get an updated version.</li> \n</ul> \n<h2 id=\"finding-the-shortest-path-to-value\">Finding the Shortest Path to Value</h2> \n<p>Delivering data science value in an organization requires that your team be agile. While “Agile” usually refers to a very specific development methodology, here we use “agile” to simply describe a process that has four principles:</p> \n<ol> \n <li><strong>Use what you have.</strong> To quickly ramp up and deliver value, take advantage of the existing knowledge of your team and your previous investments.</li> \n <li><strong>Collaborate regularly.</strong> The users of the product continuously meet with and influence developers.</li> \n <li><strong>Iterate on deliverables rapidly.</strong> Developers incorporate feedback into the product in short development cycles until it delivers what the users want.</li> \n <li><strong>Deliver results frequently.</strong> The process routinely delivers new products for users to critique and improve.</li> \n</ol> \n<p>Applying these principles to the data science development process allows your team to deliver value more quickly and efficiently. They help your team overcome the obstacles noted previously, and they demonstrate commitment to a Serious Data Science approach (see Figure 1).</p> \n<div style=\"overflow-x:auto;\"> \n <table> \n  <tr> \n   <th> Obstacles </th> \n   <th> Solutions </th> \n  </tr> \n  <tr> \n   <td>Training required on new tools </td> \n   <td>Use tools many data scientists already know </td> \n  </tr> \n  <tr> \n   <td>Monolithic applications take too long to set up and don’t use existing analytic investments </td> \n   <td>Focus on small prototypes to prove value, using tools that integrate with your existing frameworks </td> \n  </tr> \n  <tr> \n   <td>Slow exploratory development </td> \n   <td>Rapid, code-based development </td> \n  </tr> \n  <tr> \n   <td>Difficult to access and share results </td> \n   <td>Deliver live results directly to stakeholders </td> \n  </tr> \n </table> \n</div> \n<p>Figure 1: Use agile principles in a Serious Data Science approach to address common development obstacles.</p> \n<p>To make your team more agile in your data science development process, we recommend that you:</p> \n<ul> \n <li><strong>Apply your existing knowledge.</strong> Many data scientists already know how to use R and Python because of the huge open source communities around these languages. This means your team will not require extensive training on a new platform. Using R and Python as the foundation of your data science platform also helps you quickly recruit and retain the best Data Science talent by letting your data scientists work in the environments they already know and love.</li> \n <li><strong>Focus on small prototypes that prove value.</strong> Instead of trying to build or buy a single data science platform, focus your development on small easy-to-test modules that can then be combined with code or scripts. As an example, instead of trying to reinvent the entire customer buying experience, break up that concept into independent prototypes that improve recommendations, streamline purchases, and improve pricing for profitability. And choose a platform that integrates well with the other analytic frameworks you’ve already built, so that you can exploit those investments, rather building everything from scratch. (We will be talking about this principle of Interoperability in greater detail in the future).</li> \n <li><strong>Rapidly evolve your solution using code-based development.</strong> We recommended using a code-based data science foundation such as R or Python that allows easy auditing and peer review in our <a href=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/\" target=\"_blank\" rel=\"noopener noreferrer\">prior blog post about credibility</a>. Code also allows you to rapidly evolve your solution to explore new approaches and accommodate stakeholder feedback. One of the features of R and Python that users love most is how easy it is to explore different analytic approaches to solving any given problem. For example, this <a href=\"https://rstudio.com/about/customer-stories/liberty-mutual/\" target=\"_blank\" rel=\"noopener noreferrer\">recent customer spotlight with Liberty Mutual</a> highlights the power and flexibility of R in their data science environment.</li> \n <li><strong>Deliver live results directly to stakeholders.</strong> Stakeholder feedback is critical to agile development, but it won’t help if they don’t have your latest results. You can eliminate that concern if you publish data science results on a web-based platform such as <a href=\"https://rstudio.com/products/connect/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Connect</a>. You can even automate this publication process using continuous integration development techniques such as Github actions. You can also notify stakeholders with automated emails from packages like <em>blastula</em>, which we will be covering in more detail in an upcoming webinar. Speeding up this delivery and feedback mechanism ensures stakeholders get input and see the value your data science team is delivering in real-time.</li> \n</ul> \n<h3 id=\"astellas-aymen-waqar-discusses-the-analytics-communications-gap\">Astellas’ Aymen Waqar discusses the analytics communications gap:</h3> \n<div style=\"padding: 15px 40px 35px 40px;text-align: center;\"> \n <script src=\"https://fast.wistia.com/embed/medias/iwmemji2xh.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <span class=\"wistia_embed wistia_async_iwmemji2xh popover=true popoverAnimateThumbnail=true videoFoam=true\" style=\"display:inline-block;height:100%;position:relative;width:100%\">&nbsp;</span>\n  </div>\n </div> \n</div> \n<h2 id=\"learn-more-about-serious-data-science\">Learn more about Serious Data Science</h2> \n<p>For more information, see our previous posts <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">introducing the concepts of Serious Data Science</a>, and <a href=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/\" target=\"_blank\" rel=\"noopener noreferrer\">drilling into the importance of credibility</a>. In the coming weeks, we will round out this series with a post on how to make sure the value your data science team provides is durable.</p> \n<p>If you’d like to learn more, we also recommend:</p> \n<ul> \n <li><a href=\"https://rstudio.com/about/customer-stories/brown-forman/\" target=\"_blank\" rel=\"noopener noreferrer\">Paul Ditterline describes a Serious Data Science approach adopted by Brown-Forman</a>, in which building on familiar open-source languages allowed their data scientists to ramp up quickly, and “turn into application developers and data engineers without learning any new languages or computer science skills.”</li> \n <li><a href=\"https://rstudio.com/solutions/r-and-python/\" target=\"_blank\" rel=\"noopener noreferrer\">R and Python: A Love Story</a> shows how RStudio enables collaboration between the R and Python users on your data science team and helps all of them easily share their data science insights with your stakeholders.</li> \n <li>Visit the <a href=\"https://rstudio.com/products/team/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Team product page</a> to learn how the RStudio Team platform for data science allows you to capitalize on your existing analytic investments and rapidly deliver value to your organization.</li> \n <li>For more information on using RStudio Connect and the blastula package to send custom emails to your stakeholders with plots, tables, and results inline, see <a href=\"https://blog.rstudio.com/2020/01/22/rstudio-connect-1-8-0/\" target=\"_blank\" rel=\"noopener noreferrer\">this recent blog post</a> on the Connect 1.8 release.</li> \n <li>See <a href=\"https://rstudio.com/about/what-makes-rstudio-different/\" target=\"_blank\" rel=\"noopener noreferrer\">What Makes RStudio Different</a> to learn about how RStudio helps support open source data science.</li> \n</ul>","descriptionType":"text/html","publishedDate":"Tue, 09 Jun 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"a8bdb1435a05dc69a07c3ca00ca739a6","bgimgJsdelivr":"","metaImg":"","author":"Lou Bajuk, Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/winding-path-hero.jpg":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn98@2020_3/2020/08/25/00-02-55-417_38d0c594821393ac.webp"},"publishedOrCreatedDate":1598313739858},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Announcing Public Package Manager and v1.1.6","link":"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/","description":"<div style=\"padding: 35px 0 35px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/public-package-manager_hu090f9cdbc2876402e9201b4f44d261d6_109308_647x0_resize_box_2.png, https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/public-package-manager.png 2x\" src=\"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/public-package-manager.png\" width=\"647\" alt=\"The homepage of the public package manager site\" /> \n</div> \n<p>Today we are excited to release version 1.1.6 of RStudio Package Manager and announce <a href=\"https://packagemanager.rstudio.com\">https://packagemanager.rstudio.com</a>. This service builds on top of the work done by CRAN, to offer the R community:</p> \n<ul> \n <li>Access to <strong>pre-compiled packages on Linux</strong> via <code>install.packages</code> resulting in <a href=\"https://blog.rstudio.com/2019/11/07/package-manager-v1-1-no-interruptions/\">significantly faster</a> package install times on Linux systems including cloud servers, CI/CD systems, and Docker containers.<br /></li> \n <li><strong>Historical checkpoints for CRAN</strong> enabling reproducible work, and even <a href=\"https://blog.rstudio.com/2019/01/30/time-travel-with-rstudio-package-manager-1-0-4/\">time travel</a>, by freezing package dependencies with a one-line repository option.</li> \n <li>Expanded <strong>Windows support for older versions of R</strong>, allowing you to access the latest versions of packages on older versions of R without compiling from source.</li> \n</ul> \n<p>We invite everyone to try this service, but please note we do not currently support package binaries for Mac OS though we are considering adding support in the future. The easiest way to get started is by visiting the <a href=\"https://packagemanager.rstudio.com/client/#/repos/1/overview\">Package Manager Setup Page</a>. You can also view <a href=\"https://support.rstudio.com/hc/en-us/articles/360046703913\">frequently asked questions</a> or <a href=\"https://rstudio.com/products/package-manager\">learn more about RStudio Package Manager</a>.</p> \n<h3 id=\"relationship-to-cran\">Relationship to CRAN</h3> \n<p>This service builds off of the work done by CRAN and is a supplement to RStudio’s <a href=\"https://cran.rstudio.com\">popular CRAN mirror</a>. If CRAN were a brewery, Package Manager would be your local liquor store; Package Manager wouldn’t be possible without CRAN, but we hope it makes it a little easier to install packages without having to go to the (literal) source each time.</p> \n<p>For <strong>package authors</strong>, before a package is available on Package Manager it must be accepted, tested, and distributed on CRAN. Package Manager watches for those updates and then carefully builds updated or new packages on additional operating systems and R versions, finally adding them as a versioned checkpoint.</p> \n<p>For <strong>R users</strong>, Package Manager acts like a regular CRAN mirror, ensuring all the code you know how to write automatically works. Note that Package Manager can lag behind CRAN by a few days, so if you need the latest packages you can add both Package Manager and CRAN to your repo option.</p> \n<h3 id=\"community-integrations\">Community Integrations</h3> \n<p>In addition to using the Public Package Manager directly, R users can benefit from community integrations that access the service automatically:</p> \n<ul> \n <li><p>The <a href=\"https://github.com/rstudio/renv\">renv</a> package helps R users manage package environments over time, and is able to use the service to provide faster install times and increase cross-platform project portability.</p></li> \n <li><p>The <a href=\"https://github.com/r-lib/actions\">actions</a> package provides GitHub Actions for package authors taking advantage of CI/CD workflows such as automated testing. The package uses Public Package Manager to speed up actions and eliminate redundant package compilation.</p></li> \n <li><p>The popular <a href=\"https://www.rocker-project.org/\">rocker</a> project gives R users a convenient way to work with Docker. This ecosystem increasingly takes advantage of Public Package Manager to provide faster package installs within a container as well as versioned installs for reproducible research.</p></li> \n</ul> \n<p>If your community project would benefit from Public Package Manager please <a href=\"https://community.rstudio.com/c/r-admin/package-manager?tags=package-manager%2Cpublic-rspm\">create a topic </a> on the RStudio Community.</p> \n<h3 id=\"support-legal-terms-and-feedback\">Support, Legal Terms, and Feedback</h3> \n<p>Please consult the <a href=\"https://rstudio.com/about/rstudio-service-terms-of-use/\">RStudio Terms of Use</a> prior to use. If you use R in an organization, we recommend <a href=\"https://rstudio.com/products/package-manager\">evaluating RStudio Package Manager</a> which includes all the benefits of the public Package Manager plus additional controls and features for professional data science teams: the ability to serve packages in offline environments, access to curated subsets of CRAN, and the ability to share private R packages.</p> \n<p>RStudio does not provide direct support for this service you can get help through RStudio Community. The best way to ask a question is to <a href=\"https://community.rstudio.com/c/r-admin/package-manager?tags=package-manager%2Cpublic-rspm\">create a topic</a> on RStudio Community after reviewing the <a href=\"https://support.rstudio.com/hc/en-us/articles/360046703913\">FAQ</a>. This forum is also the best place to leave suggestions or feedback, we’re eager to learn how we can better support your needs!</p> \n<p>If you are interested in learning more about how Package Manager works, these open source repositories provide information on how we <a href=\"https://github.com/rstudio/r-builds\">build and distribute R</a>, handle <a href=\"https://github.com/rstudio/r-system-requirements\">system requirements</a>, and <a href=\"https://github.com/rstudio/r-docker\">manage our build environment</a>. Package Manager relies on the tireless work of a team of engineers, thousands of compute hours, and TBs of storage and network IO.</p> \n<p>The RStudio Package Manager <a href=\"https://docs.rstudio.com/rspm/admin\">admin guide</a> also provides details on how Package Manager <a href=\"https://docs.rstudio.com/rspm/admin/repositories/#repo-syncing\">interacts with CRAN</a>, how it <a href=\"https://docs.rstudio.com/rspm/admin/serving-binaries/\">serves binary packages</a>, and details the <a href=\"https://docs.rstudio.com/rspm/admin/getting-started/configuration/\">additional options</a> available for on-premise use.</p> \n<h3 id=\"new-updates-in-rstudio-package-manager-v1-1-6\">New Updates in RStudio Package Manager v1.1.6</h3> \n<p>In addition to <a href=\"https://packagemanager.rstudio.com\">https://packagemanager.rstudio.com</a>, the 1.1.6 release offers the community and customers incremental updates including:<br /> - Access to an <a href=\"https://packagemanager.rstudio.com/__api__/swagger/index.html\">API to easily integrate Package Manager</a> with other systems and services<br /> - Support for R 4.0 and Ubuntu 20<br /> - More robust access and debugging when distributing packages from Git (applicable to on-premise customers only)</p> \n<p>Please review the full <a href=\"https://docs.rstudio.com/rspm/news/\">release notes</a> and consider <a href=\"https://docs.rstudio.com/rpm/installation/\">upgrading to the latest version</a>.</p>","descriptionType":"text/html","publishedDate":"Wed, 01 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"656dbda9dcda41c02614146b77177646","bgimgJsdelivr":"","metaImg":"","author":"Sean Lopp","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/public-package-manager.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn22@2020_2/2020/08/25/00-02-56-663_2c0520f72a8ebd3c.webp"},"publishedOrCreatedDate":1598313739857},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Driving Real, Lasting Value with Serious Data Science","link":"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/","description":"<p><style type=\"text/css\"> table { border-top: 1px solid rgba(117,170,219,.6); border-bottom: 1px solid rgba(117,170,219,.6); margin: 45px 0 45px 0; padding: 40px 0 20px 0; } tr:nth-child(even) { background: #ffffff; } tr { vertical-align: top; } th { font-size: 24px; font-weight: 400; } td li { font-size: 15px; } </style> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/windmills_hu6ee16a36a339853c6315f94d2969330d_109221_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/windmills.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/windmills.jpg\" width=\"800\" alt=\"Giant Dutch windmills\" /> \n </div></p> \n<p>Data science is now a hot area of investment for many organizations. Countless blogs, articles, and analyst reports emphasize that effective data science is critical for competitive advantage, and many business leaders believe that data science is vital for an organization to survive, much less thrive, over the next several years.</p> \n<p>However, many data science leaders grapple with an existential crisis for their teams. On the one hand, many vendors and analyst reports emphasize the rise of Citizen Data Scientists, empowered by tools that promise to augment and automate the hard work of data science to automagically answer vital questions, no Data Scientist required. On the other hand, machine learning and deep learning methods in the hands of software engineers, fueled by lots of computational power, answer more and more questions (as long as the problem is well-defined, and there is sufficient data available). Squeezed in between these trends, what is the role of a data scientist?</p> \n<p>Even worse, nearly as many blogs and analyst reports emphasize the challenges of effectively implementing data science in an organization, and emphatically state that <strong>most analytics and data science projects fail</strong>, and <strong>most companies don’t achieve the revenue and profit growth that they hoped</strong> their data science investments would deliver.</p> \n<p>We will dive into the role of a data scientist in more detail in the coming weeks, but here we will focus on this question: Why is getting real, lasting value from data science investments so difficult?</p> \n<h2 id=\"many-data-science-projects-lack-credibility-and-impact-over-time\">Many data science projects lack credibility and impact over time</h2> \n<p>In talking to many different organizations implementing data science projects, we have seen many challenges that prevent data science investments from delivering the value they should. These typically fall into three categories:</p> \n<ul> \n <li><p><strong>Lack of credibility:</strong> Data science leaders grapple with whether their team has the necessary training and the right tools to discover relevant and valuable insights in their data. Once the team has found something interesting, how can others in the organization understand and trust those insights enough to actually change their behavior, and make decisions based on them? This problem is compounded if the approach is a difficult-to-explain, black box model.</p></li> \n <li><p><strong>Slow path to value:</strong> Seemingly simple questions like “Which customers will be our most profitable next quarter?” often turn into month-long research projects as data scientists scour the firm for data and struggle to wrangle it into shape (a topic we discussed in a recent blog post, <a href=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/\" target=\"_blank\" rel=\"noopener noreferrer\">Wrangling Unruly Data</a>). Then once the data scientists start to develop an analysis, they find iterating and refining their results with stakeholders slow and unwieldy (something we covered in another blog post, <a href=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/\" target=\"_blank\" rel=\"noopener noreferrer\"> Getting to the Right Question</a>). These slow response times frustrate business sponsors and often stymie putting data insights into action. Worse, they encourage decision makers to go with their gut intuition instead of data.</p></li> \n <li><p><strong>Ephemeral benefits:</strong> Once a valuable insight or tool has reached a decision maker, organizations struggle with maintaining and growing the value of these data science investments over time. They find it difficult to implement repeatable and reproducible processes as their systems and data science tools evolve, which often forces them to start from scratch when solving a new problem, or to reimplement old analyses when needed. Furthermore, data science practice at an organization often become dependent on a single software vendor, and that vendor may try to extract more of the value the customer receives as software license revenue.</p></li> \n</ul> \n<p>Andrew Mangano, Data Intelligence Lead at Salesforce, spoke at rstudio::conf 2020 about the importance of delivering useful insights to your stakeholders.</p> \n<div style=\"padding: 35px 0 35px 0;\"> \n <script src=\"https://fast.wistia.com/embed/medias/67q4k9196d.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_67q4k9196d videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/67q4k9196d/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div> \n</div> \n<h2 id=\"real-world-problems-need-serious-data-science\">Real-world problems need serious data science</h2> \n<p>So what’s the answer? And how do you cut through all the hype and confusion?</p> \n<p>The reality is that hard, vaguely defined but valuable to solve, problems exist in the world. Commodity approaches (whether via augmented analytics for citizen data scientists, or standard machine learning approaches for software engineers) yield commodity answers. <strong>Real-world business problems require smart, agile data science teams</strong> empowered with the flexibility and breadth of open source languages like R and Python. We know this because <strong>tens of thousands of you use our software every day to do amazing things.</strong></p> \n<p>To deliver real, lasting value, organizations need to set aside the hype and build on a strong foundation. We recommend adopting a strategy we call <em>Serious Data Science</em>. As shown in Figure 1, Serious Data Science is an approach to data science designed to deliver insights that are:</p> \n<ul> \n <li><strong>Credible:</strong> The first step is to ensure that your team has the training and tools to find insights that are relevant and valuable, and that your team can communicate these insights to other stakeholders in your organization in a way that builds trust and understanding.</li> \n <li><strong>Agile:</strong> Next, the platform you use must enable data scientists to quickly develop and iterate those valuable insights, and get them to your decision makers, where they can have an impact.</li> \n <li><strong>Durable:</strong> Finally, to deliver lasting value, the platform must also make it easy to reuse and reproduce your team’s data science work, to deliver up-to-date insights, and do so in a sustainable way for the long term.</li> \n</ul> \n<h4 id=\"serious-data-science-is\">Serious Data Science is….</h4> \n<div style=\"overflow-x:auto;\"> \n <table> \n  <tr> \n   <th> Credible</th> \n   <th> Agile </th> \n   <th> Durable </th> \n  </tr> \n  <tr> \n   <td> \n    <ul> \n     <li>Uses widely deployed and trusted tools</li> \n     <li>Includes comprehensive data science capabilities</li> \n     <li>Offers flexibility through the use of code</li> \n     <li>Provides transparency through visualizations and code</li> \n    </ul> </td> \n   <td> \n    <ul> \n     <li>Employs existing knowledge and analytic investments</li> \n     <li>Allows rapid development and iteration</li> \n     <li>Scales well for enterprise and production use</li> \n     <li>Empowers your business stakeholders</li> \n    </ul> </td> \n   <td> \n    <ul> \n     <li>Provides reusable, reproducible code and results</li> \n     <li>Delivers relevant, up-to-date insights</li> \n     <li>Supports and is supported by a vital open source community</li> \n     <li>Avoids vendor lock-in</li> \n    </ul> </td> \n  </tr> \n </table> \n</div> \n<h4 id=\"figure-1-crucial-elements-of-a-serious-data-science-platform\">Figure 1: Crucial elements of a Serious Data Science platform.</h4> \n<h2 id=\"why-you-should-adopt-serious-data-science\">Why you should adopt Serious Data Science</h2> \n<p>We’ll be writing in detail about these components of Serious Data Science in the weeks to come. But before we get to that, we must address a topic near and dear to every data science leader: the role of the data scientist within the organization. Our post next Tuesday will address how that role is changing in today’s organizations, and why they will need the Serious Data Science framework to continue demonstrating their value in the months and years to come.</p> \n<h2 id=\"learn-more-about-serious-data-science\">Learn more about Serious Data Science</h2> \n<p>If you’d like to learn more about Serious Data Science, we recommend:</p> \n<ul> \n <li><a href=\"https://rstudio.com/about/customer-stories/brown-forman/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Paul Ditterline describes a Serious Data Science approach adopted by Brown-Forman</strong></a>, reducing dependency on tools like Excel, to solve more, and more complex, data science problems more efficiently.</li> \n <li><a href=\"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Avoiding Irrelevancy and Fire Drills in Data Science Teams</strong></a> is another view of the challenges facing today’s data science teams, and how to tackle those challenges.</li> \n <li><a href=\"https://rstudio.com/about/what-makes-rstudio-different/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>What Makes RStudio Different</strong></a> highlights RStudio’s mission to create free and open-source software for data science, in order to allow anyone with access to a computer to participate freely in a data-centric global economy.</li> \n <li><a href=\"https://rstudio.com/solutions/r-and-python/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>R &amp; Python: A Love Story</strong></a> shows how RStudio helps make the full breadth and power of R and Python available to data science teams, and helps them make an impact on their organizations.</li> \n <li><a href=\"https://rstudio.com/resources/rstudioconf-2020/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Recorded talks from rstudio::conf 2020</strong></a> highlight the amazing, impactful, creative work that the open source data science community is doing.<br /></li> \n</ul>","descriptionType":"text/html","publishedDate":"Tue, 19 May 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"6cafd3b26e73d3fffc1095811d0ec17a","bgimgJsdelivr":"","metaImg":"","author":"Lou Bajuk","articleImgCdnMap":{"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/windmills.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn30@2020_5/2020/08/25/00-02-55-113_fb719f6cbd56af22.webp","https://fast.wistia.com/embed/medias/67q4k9196d/swatch":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn86@2020_3/2020/08/25/00-02-54-840_0e4e92c89fd9902d.webp"},"publishedOrCreatedDate":1598313739859},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"RStudio Connect 1.8.4","link":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/","description":"<h2 id=\"a-place-for-python-applications\">A place for Python applications</h2> \n<p>For data science teams looking to promote data-driven decision making within an organization, interactive applications built in R and Python are often the gold standard. These interactive tools, built by data science teams, are powerful when put in the hands of the right people, but they don’t do much good at all if they only run locally. R users who build Shiny applications hit this roadblock, and so do Python users working with tools like Dash, Bokeh, and Streamlit. IT departments want to help but often aren’t sure how. RStudio Connect solves this problem, for both R and Python applications.</p> \n<p>RStudio Connect 1.8.4 focuses on helping Python users by including support for a full suite of interactive application types. Support for publishing Dash applications is now generally available, and this release introduces new Beta offerings for <a href=\"https://bokeh.org/\" target=\"_blank\">Bokeh</a> and <a href=\"https://www.streamlit.io/\" target=\"_blank\">Streamlit</a> application deployment.</p> \n<h3 align=\"center\"><a href=\"https://rstudio.chilipiper.com/book/rsc-demo\">See RStudio Connect in Action</a></h3> \n<h2 id=\"interactive-python-applications\">Interactive Python Applications</h2> \n<h3 id=\"get-started-with-the-rstudio-connect-jump-start\">Get started with the RStudio Connect Jump Start</h3> \n<p>For a hands-on approach to learning about Python content in RStudio Connect, try exploring the Jump Start Examples. This resource contains lightweight data science project examples built with various R and Python frameworks. The Jump Start Examples appear in the RStudio Connect dashboard when you first log in. You can download each project, run it locally, and follow the provided instructions to publish it back to the RStudio Connect server; or you could simply browse the examples and deployment steps to get a sense for how you might publish your own project.</p> \n<p><img src=\"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/python-jump-start-184.png\" alt=\"Python Jump Start Screenshot\" /></p> \n<h3 id=\"develop-and-deploy-python-applications-from-your-favorite-python-ide\">Develop and deploy Python applications from your favorite Python IDE</h3> \n<p>New users often ask, <em>Do I have to develop Python applications in the RStudio IDE in order to publish them in RStudio Connect?</em> The answer is no! You do not need to touch the RStudio IDE for Python content development or publishing.</p> \n<p>Publishing Python applications to RStudio Connect requires the <a href=\"https://pypi.org/project/rsconnect-python/\" target=\"_blank\"><code>rsconnect-python</code></a> package. This package is available to install with pip from PyPI and enables a command-line interface that can be used to publish from any Python IDE including PyCharm, VS Code, JupyterLab, Spyder, and others.</p> \n<p>Once you have the <code>rsconnect-python</code> package, the only additional information you need to supply is the RStudio Connect server address and a <a href=\"https://docs.rstudio.com/connect/user/api-keys/\">publisher API key</a>.</p> \n<p>The application shown here is the Stock Pricing Dashboard built with Dash and available for download from the Jump Start Examples available in RStudio Connect. The example comes packaged with everything needed to run it locally in the Python IDE of your choice. When you’re ready to try publishing, the Jump Start will guide you through that process, including all the required commands from <code>rsconnect-python</code>.</p> \n<p><img src=\"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/dash-jumpstart-example.gif\" alt=\"GIF of the Dash Jump Start example in RStudio Connect\" /></p> \n<h3 id=\"streamlit-and-bokeh-applications\">Streamlit and Bokeh Applications</h3> \n<p>Data scientists who develop Streamlit or Bokeh applications can also use the <a href=\"https://pypi.org/project/rsconnect-python/\" target=\"_blank\"><code>rsconnect-python</code></a> package to publish to RStudio Connect. If you’ve previously used the <code>rsconnect-python</code> package for other types of Python content deployment, make sure you upgrade to the latest version before attempting to use the Beta features with RStudio Connect 1.8.4.</p> \n<p>This release ships with a example for Streamlit, located in the Jump Start Examples Python tab. For Bokeh, we recommend starting with examples from the <a href=\"https://docs.bokeh.org/en/latest/docs/gallery.html#server-app-examples\" target=\"_blank\">Bokeh App Gallery</a>. Source code for the Bokeh gallery applications is available from the <a href=\"https://github.com/bokeh/bokeh/tree/master/examples/app/\" target=\"_blank\">Bokeh GitHub repository</a>.</p> \n<p>Visit the User Guide to learn more about our beta support for Streamlit and Bokeh:</p> \n<ul> \n <li>Learn more about <a href=\"https://docs.rstudio.com/connect/user/streamlit/\">deploying Streamlit applications</a></li> \n <li>Learn more about <a href=\"https://docs.rstudio.com/connect/user/bokeh/\">deploying Bokeh applications</a></li> \n</ul> \n<p><strong>What does “Beta” Mean?</strong> <em>Bokeh and Streamlit app deployment are beta features. This means they are still undergoing final testing before official release. Should you encounter any bugs, glitches, lack of functionality or other problems, please let us know so we can improve before public release.</em></p> \n<h3 align=\"center\">Learn how data science teams use RStudio products<br /><a href=\"https://rstudio.com/solutions/r-and-python/\">Visit R &amp; Python - A Love Story</a></h3> \n<h2 id=\"new-notable\">New &amp; Notable</h2> \n<h3 id=\"scheduling-across-time-zones\">Scheduling Across Time Zones</h3> \n<p>A new time zone option for scheduled reports can be used to prevent schedules from breaking during daylight savings time changes. Publishers can now configure a report to run in a specific time zone by modifying the settings available in the <a href=\"https://docs.rstudio.com/connect/user/scheduling/\">Schedule panel</a>.</p> \n<h3 id=\"content-usage-tracking\">Content Usage Tracking</h3> \n<p>In previous versions of RStudio Connect, content usage was only available for static and rendered content, as well as Shiny applications. With this release, Python content and Plumber API usage data is available via the <a href=\"https://docs.rstudio.com/connect/api/#instrumentation\">Instrumentation API</a>. Learn more about tracking content usage on RStudio Connect in the <a href=\"https://docs.rstudio.com/connect/cookbook/user-activity/\">Server API Cookbook</a>.</p> \n<p><img src=\"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/content-usage-past30.png\" alt=\"Screenshot of the Content Usage Info Panel in RStudio Connect\" width=\"40%\" /></p> \n<h2 id=\"authentication-changes\">Authentication Changes</h2> \n<h3 id=\"openid-connect\">OpenID Connect</h3> \n<p>RStudio Connect 1.8.4 introduces OpenID Connect as an authentication provider for single sign-on (SSO). This new functionality is built on top of the existing support for OAuth2, which was previously limited to Google authentication. For backwards compatibility, Google is the default configuration, so no action is necessary for existing installations. See the <a href=\"https://docs.rstudio.com/connect/admin/authentication/oauth2/\">OAuth2</a> section of the Admin Guide for details.</p> \n<h3 id=\"automatic-user-role-mapping\">Automatic User Role Mapping</h3> \n<p>RStudio Connect now supports assigning user roles from authentication systems that support remote groups. Roles can be assigned in a custom attribute or automatically mapped from an attribute or group name. See <a href=\"https://docs.rstudio.com/connect/admin/user-management/#user-role-mapping\">Automatic User Role Mapping</a> for more details.</p> \n<h3 id=\"custom-login-logout-for-proxied-authentication\">Custom Login &amp; Logout for Proxied Authentication</h3> \n<p>Proxied authentication now supports more customizable login and logout flows with the settings ProxyAuth.LoginURL and ProxyAuth.LogoutURL. See the <a href=\"https://docs.rstudio.com/connect/admin/authentication/proxied/\">Proxied Authentication</a> section of the Admin Guide for details.</p> \n<h3 align=\"center\"><a href=\"https://rstudio.com/products/connect/evaluation/\">Try the free 45 day evaluation of RStudio Connect 1.8.4</a></h3> \n<h2 id=\"deprecations-breaking-changes\">Deprecations &amp; Breaking Changes</h2> \n<ul> \n <li><strong>Breaking Change</strong> SSLv3 is no longer supported, since it is considered cryptographically broken.</li> \n <li><strong>Deprecation</strong> The setting <code>Python.LibraryCheckIsFatal</code> has been deprecated. Python library version checks are now non-fatal and result in a warning in the RStudio Connect log at startup.</li> \n</ul> \n<p>Please review the <a href=\"http://docs.rstudio.com/connect/news\">full release notes</a>.</p> \n<blockquote> \n <h4 id=\"upgrade-planning\">Upgrade Planning</h4> \n <p>For RStudio Connect installations that make use of Python, note that the latest version of the virtualenv package (version 20) is now supported. This is a reversal of the previous RStudio Connect 1.8.2 requirement on virtualenv. This release also provides support for Ubuntu 20.04 LTS.</p> \n</blockquote> \n<p>To perform an upgrade, download and run the installation script. The script installs a new version of RStudio Connect on top of the earlier one, and existing configuration settings are respected.</p> \n<pre><code># Download the installation script\ncurl -Lo rsc-installer.sh https://cdn.rstudio.com/connect/installer/installer-v1.1.0.sh\n\n# Run the installation script\nsudo bash ./rsc-installer.sh 1.8.4-11\n</code></pre> \n<h3 align=\"center\"><a href=\"https://rstudio.com/products/connect/\">Click through to learn more about RStudio Connect</a></h3>","descriptionType":"text/html","publishedDate":"Tue, 14 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/python-jump-start-184.png","linkMd5":"f8e6210e6198c2f20cd474e74430d85b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn65@2020_4/2020/08/25/00-02-24-882_a14f8c86cebdd189.webp","destWidth":1194,"destHeight":643,"sourceBytes":243924,"destBytes":42830,"author":"Kelly O'Briant","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/python-jump-start-184.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn65@2020_4/2020/08/25/00-02-24-882_a14f8c86cebdd189.webp","https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/dash-jumpstart-example.gif":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn65@2020_5/2020/08/25/00-03-07-245_90510822eb4abf74.webp","https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/content-usage-past30.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn26@2020_6/2020/08/25/00-02-54-859_4f10853d392d7b5a.webp"},"publishedOrCreatedDate":1598313739856},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"rstudio::global(2021)","link":"https://blog.rstudio.com/2020/07/17/rstudio-global-2021/","description":"<p>We’ve made the difficult decision to cancel rstudio:conf(2021) for the health and safety of our attendees and the broader community 😢. Instead, we’re excited to announce rstudio::global(2021): our first ever virtual event focused on all things R and RStudio!</p> \n<p>We have never done a virtual event before and we’re feeling both nervous and excited. We will make rstudio::global() our most inclusive and global event, making the most of the freedom from geographical and economic constraints that comes with an online event. That means that the conference will be free, designed around participation from every time zone, and have <a href=\"https://blog.rstudio.com/2020/07/17/rstudio-global-call-for-talks\">speakers from around the world</a>.</p> \n<p>We’re still working through the details, but as of today we’re thinking that most talks will be pre-recorded (so you can watch at your leisure), accompanied by a 24 hour live event filled with keynotes, interviews, opportunities to share knowledge, and as much fun as we can possibly squeeze into a virtual event! We don’t know the precise dates yet, but it’s likely to be late January 2021.</p> \n<p>We’ll share more over the next few weeks: if you would like to receive notifications about the details, please subscribe below.</p> \n<script src=\"//pages.rstudio.net/js/forms2/js/forms2.min.js\"></script> \n<form id=\"mktoForm_3297\"></form> \n<script>MktoForms2.loadForm(\"//pages.rstudio.net\", \"709-NXN-706\", 3297);</script> \n<p>(If you already registered for rstudio::conf() as a superfan, we’ll be in touch shortly to find out if you’d prefer a refund or to transfer your registration to 2022. If you have any questions in the mean time, please feel free to reach out to <a href=\"mailto:conf@rstudio.com\">conf@rstudio.com</a>)</p>","descriptionType":"text/html","publishedDate":"Fri, 17 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"74b31af835ce07f7b153052cab5f926b","bgimgJsdelivr":"","metaImg":"","author":"Hadley Wickham","publishedOrCreatedDate":1598313739855},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Is Your Data Science Credible Enough?","link":"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/","description":"<p><style type=\"text/css\"> table { border-top: 1px solid rgba(117,170,219,.6); border-bottom: 1px solid rgba(117,170,219,.6); margin: 45px 0 45px 0; padding: 40px 0 20px 0; } tr:nth-child(even) { background: #ffffff; } tr { vertical-align: top; } th { font-size: 24px; font-weight: 400; } td li { font-size: 15px; } </style> \n <div style=\"padding: 35px 0 35px 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/black-box_hu33bcd405dbf51ce8ac52a47f3aeecdbd_435891_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/black-box.jpg 2x\" src=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/black-box.jpg\" width=\"800\" alt=\"Black Box\" /> \n </div></p> \n<h2 id=\"does-your-data-science-lack-credibility\">Does Your Data Science Lack Credibility?</h2> \n<p>In <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">a recent post</a>, we defined three key attributes of a concept we call Serious Data Science: Credibility, Agility and Durability. In this post, we’ll drill into the challenge of delivering credible insights to your stakeholders, and how to address that challenge.</p> \n<p>Ultimately, organizations use data science to discover valuable insights and then apply those insights intelligently. Such applications might include making a better decision, improving a process, or otherwise changing how things are usually done. However, to make this happen, the organization must do at least two things:</p> \n<ul> \n <li>Communicate these insights to the right decision-maker, stakeholder, or system (we’ll talk more about that in our next Serious Data Science post on being Agile).<br /></li> \n <li>Convince decision makers to trust the insight and accept its implications. If decision makers lack this trust, then they will likely ignore the recommendation, and fall back on “the way we’ve always done things.”</li> \n</ul> \n<p>Typically, a host of unasked questions underlie a decision-maker’s seeming resistance to data-driven insights. They might not act on the conclusions of a data science team because they:</p> \n<ul> \n <li><strong>Don’t know the skills of the data scientist:</strong> Does the person who created this insight know what they are doing? Do they understand business risks as well as they understand their models?</li> \n <li><strong>Don’t trust data science tools:</strong> Did the data scientist depend too much on software in creating this result? Did the data science team just use black box tools that auto-magically produced an answer without an understanding of the business?</li> \n <li><strong>Don’t have confidence in the development process:</strong> Did the data scientist consider all reasonable approaches to the problem? Was there any way for someone else to review what was done, and know how things changed over time?</li> \n <li><strong>Don’t understand what the results mean:</strong> What is this insight actually telling me? How does it apply to what I do? What factors does it reflect? Is it really better than what we have done before? Could I get fired for acting on this result?</li> \n</ul> \n<p>All these questions and doubts contribute to stakeholder hesitation, especially when they feel that they, not the data scientist, will ultimately be held responsible for the result. Fortunately, there are ways to overcome these obstacles.</p> \n<h2 id=\"how-can-you-deliver-credible-insights\">How Can You Deliver Credible Insights?</h2> \n<p>To deliver insights that your decision makers and other stakeholders trust and actually use, we recommend adopting a Serious Data Science approach. To do this, your team must have the training and tools to find insights that are relevant and valuable. And, your team must communicate these insights to other stakeholders in your organization in a way that builds trust and understanding.</p> \n<p>Here are the key elements which will help your team meet these challenges:</p> \n<ul> \n <li><strong>Widely-used open source software:</strong> The best way to make sure your team has the training to use a data science tool properly is to <strong>use the tools they already know</strong>. Millions of data scientists around the world learn data science using open source languages, such as R and Python. While some may argue which language is best (see <a href=\"https://blog.rstudio.com/2019/12/17/r-vs-python-what-s-the-best-for-language-for-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">this blog post</a> for our take on that question), both have tremendous strengths and are trusted platforms.</li> \n <li><strong>Comprehensive data science capabilities:</strong> To be confident your team will find the best approach to any particular question, they need a wide range of analytic approaches readily available to apply and compare. Powered and validated by huge, ever-expanding communities and package libraries, the R and Python ecosystems ensure your team will always have the broadest range of tools for their analyses</li> \n <li><strong>Process transparency via code:</strong> Code allows others to inspect how a problem was first solved, and how that solution matured over time. Unlike point-and-click solutions where the history of how the analysis evolved is hidden beneath a pretty (inter)face or a spreadsheet where the logic is strewn across countless different cells, code explicitly describes what steps lead to the results. Further, code can be peer-reviewed and audited by third parties for further assurance of correct behavior.</li> \n <li><strong>Understanding through visualizations:</strong> Just as a picture is worth a thousand words, a great visualization can explain a thousand lines of code. Visualizations help stakeholders understand complex data science insights and build confidence in the results. Interactive tools such as <a href=\"https://shiny.rstudio.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Shiny</a> allow data scientists to create visualizations that can improve the understanding of a data scientist’s work while spurring engagement from stakeholders.</li> \n</ul> \n<p>Heather Nolis, Machine Learning Engineer at T-Mobile, and Jacqueline Nolis, Principal Data Scientist at Nolis, LLC, recently spoke at rstudio::conf 2020 about how they used Shiny to share their machine learning models drove engagement and built trust with their business stakeholders.</p> \n<div align=\"center\" style=\"padding: 35px 0 35px 0;\"> \n <script src=\"https://fast.wistia.com/embed/medias/58qjn34mxy.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_58qjn34mxy videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/58qjn34mxy/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div> \n</div> \n<h2 id=\"serious-data-science-credible-agile-and-durable\">Serious Data Science: Credible, Agile, and Durable</h2> \n<p>These elements of Serious Data Science—trusted tools, comprehensive capabilities, flexibility, and transparency—will all help your team deliver insights that are more likely to be accepted by decision makers and actually have an impact. Next week, we will focus on Agility, and how your team can not only develop apps quickly but also regularly share those results with stakeholders to create a consensus, so you can make sure you are <a href=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/\" target=\"_blank\" rel=\"noopener noreferrer\">Getting to the Right Question</a>.</p> \n<p><strong>Serious Data Science is:</strong></p> \n<div style=\"overflow-x:auto;\"> \n <table> \n  <tr> \n   <th> Credible</th> \n   <th> Agile </th> \n   <th> Durable </th> \n  </tr> \n  <tr> \n   <td> \n    <ul> \n     <li>Uses widely deployed and trusted tools</li> \n     <li>Includes comprehensive data science capabilities</li> \n     <li>Offers flexibility through the use of code</li> \n     <li>Provides transparency through visualizations and code</li> \n    </ul> </td> \n   <td> \n    <ul> \n     <li>Employs existing knowledge and analytic investments</li> \n     <li>Allows rapid development and iteration</li> \n     <li>Scales well for enterprise and production use</li> \n     <li>Empowers your business stakeholders</li> \n    </ul> </td> \n   <td> \n    <ul> \n     <li>Provides reusable, reproducible code and results</li> \n     <li>Delivers relevant, up-to-date insights</li> \n     <li>Supports and is supported by a vital open source community</li> \n     <li>Avoids vendor lock-in</li> \n    </ul> </td> \n  </tr> \n </table> \n</div> \n<h4 id=\"figure-1-being-credible-is-one-of-the-crucial-elements-of-a-serious-data-science-platform\">Figure 1: Being credible is one of the crucial elements of a Serious Data Science platform.</h4> \n<h2 id=\"learn-more-about-serious-data-science\">Learn More about Serious Data Science</h2> \n<p>If you’d like to learn more about Serious Data Science, we recommend the following in addition to our previous posts in this series:</p> \n<ul> \n <li>In <a href=\"https://rstudio.com/about/customer-stories/redfin/\" target=\"_blank\" rel=\"noopener noreferrer\">a recent customer spotlight</a>, Jared Goulart, Director - Operations Analytics at Redfin, described how a serious data science approach helped his team engage with stakeholders, allowing them to quickly evaluate different scenarios and plan their budgets for the next year.</li> \n <li><a href=\"https://rstudio.com/solutions/r-and-python/\" target=\"_blank\" rel=\"noopener noreferrer\">R &amp; Python: A Love Story</a> shows how RStudio helps make the full breadth and power of R and Python available to data science teams and helps them make an impact on their organizations.</li> \n <li>The <a href=\"https://shiny.rstudio.com/gallery/\" target=\"_blank\" rel=\"noopener noreferrer\">Shiny Gallery</a> highlights some of the amazing interactive visualizations that Shiny developers have created with R to convey insights and help their stakeholders make better, more informed decisions.<br /></li> \n</ul>","descriptionType":"text/html","publishedDate":"Tue, 02 Jun 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"eb57041877eac365a90956f292f97507","bgimgJsdelivr":"","metaImg":"","author":"Lou Bajuk, Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/black-box.jpg":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn21@2020_1/2020/08/25/00-02-56-218_a8087ff98a9810bd.webp","https://fast.wistia.com/embed/medias/58qjn34mxy/swatch":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn1@2020_5/2020/08/25/00-02-56-298_dc60adf5b1a22645.webp"},"publishedOrCreatedDate":1598313739858},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"R & RStudio - The Interoperability Environment for Data Analytics","link":"https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/","description":"<div style=\"padding: 35px 0px 15px 0px;\"> \n <img srcset=\"https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/large_image_hu7bfae29c2ee88c3f2d1380e39f919058_421945_1222x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/large_image.jpg 2x\" src=\"https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/large_image.jpg\" width=\"1222\" alt=\"Laptop with hexes\" /> \n</div> \n<p>On the RStudio Developer Blog we’ve recently written a series on <a href=\"https://blog.rstudio.com/2020/07/07/interoperability-july/\" target=\"_blank\">interoperability and R</a>, including why <a href=\"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/\" target=\"_blank\">enterprises should embrace workflows that are open to diverse toolsets</a>.</p> \n<p>The designers of R, from its very beginnings, have dealt directly with how best to tap into other tools. Statisticians, analysts, and data scientists have long been challenged to bring together all the statistical methods and technologies required to perform the analysis the situation calls for—and this challenge has grown as more tools, libraries, and frameworks become available.</p> \n<p>John Chambers writing on the design philosophy behind the S programming language, the predecessor to R,</p> \n<blockquote>\n  “[W]e wanted to be able to begin in an interactive environment, where they did not consciously think of themselves as programming. Then as their needs become clearer and their sophistication increased, they should be able to slide gradually into programming, when the language and system aspects would become more important.” \n</blockquote> \n<p>Part of this design philosophy is to minimize the amount of effort and overhead required to get your analytics work done. It is not fair to assume that every data scientist is programming all day, or coming from a computer science background, but they still need to implement some of the most sophisticated tools programmers use.</p> \n<p>The ecosystem around R has striven to strike the right balance between a domain specific environment optimized for data science workflows and output, and a general programming environment. For example CRAN, Bioconductor, rOpenSci, and GitHub provide collections of packages written with data science in mind, which extend core R’s functionality, letting you tap into (and share) statistical methods and field-specific tools — when and only when you need them.</p> \n<p>Many of the most popular packages offer interfaces to tools in other languages. For example, most tidyverse packages include compiled (C/C++) code. Interestingly, core R itself connects you to tooling mostly written in other programming languages. As of R 4.0.2 over 75% of the lines in core R’s codebase are written C or Fortran (C 43%, Fortran 33%, &amp; R 23.9%).</p> \n<h2 id=\"rstudio-design-philosophy-and-development-priorities\">RStudio - design philosophy and development priorities</h2> \n<p>Our <a href=\"https://rstudio.com/about/\" target=\"_blank\">mission</a> at RStudio is to create free and open source software for data science, scientific research, and technical communication. R is a wonderful environment for data analysis, and we’ve focused on making it easier to use. We do this through our IDE and <a href=\"https://rstudio.com/about/pbc-report/\" target=\"_blank\">open sources packages</a>, such as the tidyverse. We also do this by making data science easier to learn through <a href=\"https://rstudio.com/products/cloud/\" target=\"_blank\">RStudio Cloud</a> and our support for <a href=\"https://education.rstudio.com/\" target=\"_blank\">data science education</a>. And we help make R easier to manage and scale out across an organization through our <a href=\"https://rstudio.com/products/team/\" target=\"_blank\">our professional products</a>, supporting best practices for data science in the enterprise through our <a href=\"https://solutions.rstudio.com/\" target=\"_blank\">solutions team</a>.</p> \n<p>As part of this effort, we have focused heavily on enabling and supporting interoperability between R and other tools. We recently outlined in a <a href=\"https://blog.rstudio.com/2020/07/07/interoperability-july/\" target=\"_blank\">recent blog post</a> how the RStudio IDE allows you to embed many different languages in RMarkdown documents, including:</p> \n<ul> \n <li><strong>Using R &amp; Python together</strong> through the <code>reticulate</code> package</li> \n <li><strong>SQL code</strong> for accessing databases,</li> \n <li><strong>BASH code</strong> for shell scripts,</li> \n <li><strong>C and C++ code</strong> using the <code>Rcpp</code> package,</li> \n <li><strong>STAN code</strong> with <code>rstan</code> for Bayesian modeling,</li> \n <li><strong>Javascript</strong> for doing web programming,</li> \n <li><strong>and many more languages</strong>. You can find a complete list of the many platforms supported in the language engines chapter of the book, <a href=\"https://bookdown.org/yihui/rmarkdown/language-engines.html\" target=\"_blank\">R Markdown: The Definitive Guide</a>.</li> \n</ul> \n<p>And we work with the community to support:</p> \n<ul> \n <li>Bilingual data science teams, by providing a single platform for data scientists to develop in R or Python (<a href=\"https://rstudio.com/products/rstudio-server-pro/\" target=\"_blank\">RStudio Server Pro</a>), and to deploy applications built with either (through <a href=\"https://rstudio.com/products/connect/\" target=\"_blank\">RStudio Connect</a>)</li> \n <li>Making it easy to create web applications with shiny or put models into production via plumber APIs</li> \n <li>Supporting easy access to data sources, such <code>odbc</code>, <code>DBI</code>, and <code>dbplyr</code> for <a href=\"https://db.rstudio.com/\" target=\"_blank\">database access and wrangling</a>.</li> \n <li>Incubating <a href=\"https://ursalabs.org/\" target=\"_blank\">Ursa Labs</a>, which is focused on building the next generation of cross language tools, leveraging the Apache Arrow project.</li> \n <li>Integration from R with other modeling frameworks, including <a href=\"https://tensorflow.rstudio.com/\" target=\"_blank\">TensorFlow</a> and <a href=\"https://spark.rstudio.com/mlib/\" target=\"_blank\">SparkMLlib</a></li> \n <li>Using <a href=\"https://spark.rstudio.com/\" target=\"_blank\">Sparklyr</a> and <a href=\"https://docs.rstudio.com/rsp/integration/launcher-kubernetes/\" target=\"_blank\">Launcher with kubernetes</a> to distribute your calculations or modeling operations over many machines, <em>which we will be discussing in more depth in an upcoming blog post</em>.<br /></li> \n</ul> \n<p>This list goes on and on and grows by the week.</p> \n<p>R with RStudio is a wonderful environment for anyone who seeks understanding through the analysis of data. It does this by finding a balance between a domain specific environment and a general programming language that doesn’t prioritize data scientists. That is, it strives to be an environment optimized for analytics workflows and output. At the fulcrum of this balance is extensive interoperability, the ability to pull in interfaces into other technologies as they are needed, and a vibrant community sustaining these. This has been the goal for R since initial design principles, through the extensive work shared by the R community, and significant continued investment by RStudio.</p>","descriptionType":"text/html","publishedDate":"Mon, 17 Aug 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"35f3492cce655552471f3c06678747a3","bgimgJsdelivr":"","metaImg":"","author":"Curtis Kephart and Lou Bajuk","articleImgCdnMap":{"https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/large_image.jpg":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn6@2020_1/2020/08/25/00-02-55-231_3197a9913edd6c5e.webp"},"publishedOrCreatedDate":1598313739854},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"RStudio Adds New R Features in Qubole's Open Data Lake","link":"https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/","description":"<figure> \n <div style=\"padding: 35px 0 0 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/qubole-launch_hu7be151f6be41d7776cd4d85ca8ff009a_230384_650x0_resize_box_2.png, https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/qubole-launch.png 2x\" src=\"https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/qubole-launch.png\" width=\"650\" alt=\"Qubole Launch\" /> \n </div> \n <br /> Launch RStudio Server Pro from inside the Qubole platform \n</figure> \n<p>We are excited to team up with Qubole to offer data science teams the ability to <a href=\"https://spark.rstudio.com/examples/qubole-cluster/\" target=\"_blank\" rel=\"noopener noreferrer\">use RStudio Server Pro from directly within the Qubole Open Data Lake Platform</a>. Qubole is an open, simple, and secure data lake platform for machine learning, streaming and ad-hoc analytics. RStudio and Qubole customers now have access to RStudio’s out-of-the-box features and Qubole’s unique managed services that supercharge data science and data exploration workflows for R users, while optimizing costs for R-based projects. Within the Qubole platform, data scientists are able to easily access and analyze large datasets using the RStudio IDE, securely within their enterprise running in their public cloud environment of choice (AWS, Azure, or Google).</p> \n<p>With massive amounts of data becoming more accessible, data scientists increasingly need more computational power. Cluster frameworks such as Apache Spark, and their integration with R using the SparkR and SparklyR libraries, help these users quickly make sense of their big data and derive actionable insights for their businesses. However, high CPU costs, long setup times, and complex management processes often prevent data scientists from taking advantage of these powerful frameworks.</p> \n<p>Now that Qubole has added RStudio Server Pro into its offering, it now offers its users:</p> \n<ul> \n <li><strong>Single click access to Spark clusters</strong>. With Qubole’s authentication mechanisms, no additional sign-in is required.</li> \n <li><strong>Automatic persistence</strong> of users’ files and data sets when clusters are restarted.</li> \n <li><strong>Pre-installed packages</strong> such as Sparklyr, tidyverse, and other popular R packages.</li> \n <li><strong>Cluster Package Manager</strong> allows users to define cluster-wide R &amp; Python dependencies for Spark applications</li> \n <li><strong>Performance optimizations</strong> such as Qubole’s optimized spark distribution allows the cluster to automatically scale up when the sparklyr application needs more resources and downscales as cluster resources are not in use.</li> \n <li><strong>Spark UI, Logs, and Resource Manager links</strong> available in the RStudio Connections pane for seamlessly managing applications.</li> \n</ul> \n<div style=\"text-align: center;\">\n <iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/vfmdaIwxbMw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe> \n</div> \n<p>Enterprise users benefit from this new integration because this new upgraded platform:</p> \n<ul> \n <li><strong>Limits CPU expenses to what users need.</strong> The Qubole cluster automatically scales up when the sparklyr application needs more resources, and downscales when cluster resources are not un use.</li> \n <li><strong>Allows on-demand cluster use.</strong> With single-click integration, users can seamlessly access large datasets that can persist automatically.</li> \n <li><strong>Simplifies cluster management.</strong> Qubole’s Cluster Package Manager, with pre-installed R packages, lets users define R and Python dependencies across their clusters.</li> \n</ul> \n<h3 id=\"how-do-i-enable-this-integration\">How do I enable this integration?</h3> \n<p>If you already are a Qubole customer, and would like to enable RStudio Server Pro in your environment, please <a href=\"https://www.qubole.com/company/contact-us/\" target=\"_blank\" rel=\"noopener noreferrer\">contact</a> your Qubole support team.</p> \n<h3 id=\"want-to-learn-more-about-rstudio-server-pro\">Want to learn more about RStudio Server Pro?</h3> \n<p><a href=\"https://rstudio.com/products/rstudio-server-pro/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Server Pro</a> is the preferred data analysis and integrated development experience for professional R users and data science teams who use R and Python. RStudio Server Pro enables the collaboration, centralized management, metrics, security, and commercial support that professional data science teams need to operate at scale.</p> \n<p><strong><a href=\"https://rstudio.com/products/rstudio-server-pro/evaluation/\" target=\"_blank\" rel=\"noopener noreferrer\">Try a Free 45 Day Evaluation</a></strong> or <strong><a href=\"https://rstudio.chilipiper.com/book/rsp-demo\" target=\"_blank\" rel=\"noopener noreferrer\">See in in Action</a></strong></p>","descriptionType":"text/html","publishedDate":"Mon, 03 Aug 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"a2422cfc63a580fd2de167683c5c0b45","bgimgJsdelivr":"","metaImg":"","author":"Samantha Toet","articleImgCdnMap":{"https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/qubole-launch.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn61@2020_6/2020/08/25/00-02-56-900_dbba7a472a3f08d4.webp"},"publishedOrCreatedDate":1598313739855},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"rstudio::global() call for talks","link":"https://blog.rstudio.com/2020/07/17/rstudio-global-call-for-talks/","description":"<p>We’re excited to announce that the call for talks for <a href=\"https://blog.rstudio.com/2020/07/17/rstudio-global-2021\">rstudio::global(2021)</a> is now open! Since we’re rethinking the conference to make the most of the new venue, the talks are going to be a little different to usual.</p> \n<p>This year we are particularly interested in talks from people who can’t usually make it in person, or are newer to conference speaking. We’re excited to partner with <a href=\"https://www.articulationinc.com/\">Articulation Inc</a> to offer free speaker coaching: as long as you have an interesting idea and are willing to put in some work, we’ll help you develop a great talk. (And if you’re an old hand at conference presentations, we’re confident that Articulation can help you get even better!)</p> \n<p>Talks will be 20 minutes long and recordings will be due in early December, and you’ll also be part of the live program in January; details TBD. We’ll provide support to make sure that everyone can produce a high quality video regardless of circumstances.</p> \n<p>To apply, as well as the usual title and abstract, you’ll need to create a 60 second video that introduces you and your proposed topic. In the video, you should tell us who you are, why your topic is important, and what attendees will take away from it. We’re particularly interested in hearing about:</p> \n<ul> \n <li><p>How you’ve used R (by itself or with other technologies) to solve a challenging problem.</p></li> \n <li><p>Your favourite R package (whether you wrote it or not) and how it significantly eases an entire class of problems or extends R into new domains.</p></li> \n <li><p>Your techniques for teaching R to help it reach new domains and new audiences.</p></li> \n <li><p>Broad reflections on the R community, R packages, or R code.</p></li> \n</ul> \n<p>Applications close August 28, and you’ll hear back from us in late September.</p> \n<p><a href=\"https://forms.gle/5mzcMKd75xaDf2zi9\"><strong>APPLY NOW!</strong></a></p>","descriptionType":"text/html","publishedDate":"Fri, 17 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"311bb0eda0efcec8c8981ee89e640364","bgimgJsdelivr":"","metaImg":"","author":"Hadley Wickham","publishedOrCreatedDate":1598313739855},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Wrangling Unruly Data: The Bane of Every Data Science Team","link":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/","description":"<div style=\"padding: 35px 0 10px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/data-wrangling3_hu0d4277b578b5f15589238d34e61ce1cd_247297_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/data-wrangling3.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/data-wrangling3.jpg\" width=\"800\" alt=\"A visualization of random squares becoming an organized pattern\" /> \n</div> \n<p>There’s an old saying (at least old in data scientist years) that goes, “90% of data science is data wrangling.” This rings particularly true for data science leaders, who watch their data scientists spend days painstakingly picking apart ossified corporate datasets or arcane Excel spreadsheets. Does data science really have to be this hard? And why can’t they just delegate the job to someone else?</p> \n<h2 id=\"data-is-more-than-just-numbers\">Data Is More Than Just Numbers</h2> \n<p>The reason that data wrangling is so difficult is that data is more than text and numbers. As shown in Figure 1, data scientists routinely have to deal with:</p> \n<ul> \n <li><strong>missing entries</strong>. The phrase “You can’t always get what you want” is more than just a rock anthem – it also applies to data. Not every column or row in a real-world data set will be populated, yet data scientists still have to work with the data.</li> \n <li><strong>ambiguous values</strong>. Without further information, a data scientist doesn’t know if a value of <em><sup>3</sup>⁄<sub>4</sub></em> is a fraction, a month and a day, or just a string.</li> \n <li><strong>mixed data types</strong>. People who enter data will sometimes insert comments along with the data which the data scientist then has to separate and exclude to work with the actual data values.</li> \n</ul> \n<div style=\"padding: 35px 0 35px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig1_huf2899d6f70360f0ff36bef024ea46923_85501_751x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig1.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig1.jpg\" width=\"751\" alt=\"Figure 1: Inconsistent ways of entering values impede data understanding\" /> \n</div> \n<h4 id=\"figure-1-inconsistent-ways-of-entering-values-impede-data-understanding\">Figure 1: Inconsistent ways of entering values impede data understanding.</h4> \n<h2 id=\"it-s-not-just-the-data-it-s-the-context\">It’s Not Just The Data; It’s the Context</h2> \n<p>The data challenges listed above are just the tip of the iceberg. Many datasets originate in Excel, and many Excel creators hide information in their column and row names as shown in Figure 2. In other data sets, no metadata is included within the data set at all. Instead data publishers provide a completely separate data dictionary that data scientists have to interpret to use the data.</p> \n<div style=\"padding: 35px 0 35px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig2_huf2899d6f70360f0ff36bef024ea46923_107665_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig2.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig2.jpg\" width=\"800\" alt=\"Figure 2: Data only starts to make sense when values have context\" /> \n</div> \n<h4 id=\"figure-2-data-only-starts-to-make-sense-when-values-have-context\">Figure 2: Data only starts to make sense when values have context.</h4> \n<h2 id=\"the-data-wrangling-challenge-has-no-easy-solutions\">The Data Wrangling Challenge Has No Easy Solutions</h2> \n<p>With these challenges facing them, your data scientists are far from wasting time when they are data wrangling. In fact, transforming data is an essential part of the understanding process</p> \n<p>However, data science leaders can speed up data wrangling within a team by encouraging some simple behaviors:</p> \n<ol> \n <li><strong>Write code to allow reproducibility</strong>. Too many data scientists perform data wrangling using drag-and-drop tools like Excel. That approach may seem faster the first time that data set is ingested, but that manual process will stand in the way of reproducing the analysis later. Instead write functions for ingesting data that can be re-run every time the data changes, and you’ll save time in the long run.</li> \n <li><p><strong>Embrace tidy data</strong>. The <a href=\"https://www.tidyverse.org\"><em>tidyverse</em> collection of packages in R</a> establishes a standardized way of storing and manipulating data called <em>tidy data</em>, as shown in Figure 3. The tidyverse ensures that all the context needed to understand a data set is made explicit by giving every variable its own column, every observation its own row, and storing only one value per cell.</p></li> \n <li><p><strong>Create a standard data ingestion library</strong>. If your entire team defaults to using tidy data and the tidyverse in all their analyses, then they’ll find it easier to read and reuse each other’s data wrangling code. You can encourage that behavior by establishing a team Github organization where they can share those code packages and speed up their data understanding in future projects.</p></li> \n</ol> \n<div style=\"text-align: center;padding: 35px 0 35px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig3_huf2899d6f70360f0ff36bef024ea46923_107996_594x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig3.jpg 2x\" src=\"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig3.jpg\" width=\"594\" alt=\"Figure 3: Tidy data makes all context explicit and gives each variable its own column\" /> \n</div> \n<h4 id=\"figure-3-tidy-data-makes-all-context-explicit-and-gives-each-variable-its-own-column\">Figure 3: Tidy data makes all context explicit and gives each variable its own column.</h4> \n<p>These behaviors can yield big rewards for data science teams. At rstudio::conf 2020, Dr. Travis Gerke of Moffitt Cancer Center in Tampa, Florida noted that reproducible pipelines have proved a game-changer in wrangling and unlocking complex patient data for the Center’s researchers.</p> \n<div align=\"center\" style=\"padding: 35px 0 35px 0;\"> \n <script src=\"https://fast.wistia.com/embed/medias/1jhwr01cpr.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_1jhwr01cpr videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/1jhwr01cpr/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div> \n</div> \n<h2 id=\"learn-more-about-reproducibility-and-sharing-standard-libraries\">Learn More About Reproducibility and Sharing Standard Libraries</h2> \n<p>If you’d like to learn more about how to reduce data wrangling hassles, we recommend:</p> \n<ul> \n <li><a href=\"https://resources.rstudio.com/rstudio-conf-2020/rmarkdown-driven-development-emily-riederer\">An rstudio::conf talk by Emily Riederer, an Analytics Manager at Capital One</a> describes how reproducible programming using RMarkdown can help R users develop better software programming practices.</li> \n <li><a href=\"https://resources.rstudio.com/webinars/reproducibility-in-production\">This recent RStudio webinar on Reproducibility in Production</a> shows you how to write executable R Markdown documents for a production environment.</li> \n <li><a href=\"https://rstudio.com/products/package-manager/\">RStudio Package Manager</a> helps you share standard and consistent libraries across your data science team. This professional product empowers R users to access packages and reproduce environments while giving IT control and visibility into package use.</li> \n</ul>","descriptionType":"text/html","publishedDate":"Tue, 05 May 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"9d7aa41ca9b5da46260765dbe8b6f72d","bgimgJsdelivr":"","metaImg":"","author":"Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/data-wrangling3.jpg":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn49@2020_1/2020/08/25/00-02-55-361_4e53e82e92e739e4.webp","https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig1.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn53@2020_4/2020/08/25/00-02-55-555_7cdd72c317980c75.webp","https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig2.jpg":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn29@2020_1/2020/08/25/00-02-55-130_f6ce2731c9768396.webp","https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig3.jpg":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn57@2020_3/2020/08/25/00-02-56-320_52ea7390edb8d843.webp","https://fast.wistia.com/embed/medias/1jhwr01cpr/swatch":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn77@2020_3/2020/08/25/00-02-54-967_cf1f5eefc914d382.webp"},"publishedOrCreatedDate":1598313739859},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Future-Proofing Your Data Science Team","link":"https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/tomorrowland-hero_hu33bcd405dbf51ce8ac52a47f3aeecdbd_337095_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/tomorrowland-hero.jpg 2x\" src=\"https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/tomorrowland-hero.jpg\" width=\"800\" alt=\"Tomorrowland\" /> \n</div> \n<p style=\"text-align: right !important;margin-top: 0px;margin-bottom: 30px;\"><i>Photo by <a style=\"color: #000000;\" href=\"https://unsplash.com/@sushioutlaw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Brian McGowan</a> on <a style=\"color: #000000;\" href=\"https://blog.rstudio.com/s/photos/brian-mcgowan-tomorrowland?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></i></p> \n<p><em>This is a guest post from RStudio’s partner, Mango Solutions</em></p> \n<p>As RStudio’s Carl Howe recently discussed in his blog post on <a href=\"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/\" target=\"_blank\" rel=\"noopener noreferrer\">equipping remote data science teams</a>, with the rapidly evolving COVID-19 crisis, companies have been increasingly forced to adopt working from home policies. Our technology and digital infrastructure has never been more important. Newly formed remote data science teams need to maintain productivity and continue to drive effective stakeholder communication and business value, and the only way to achieve this is through appropriate infrastructure and well-defined ways of working.</p> \n<p>Whether your workforce works remotely or otherwise, centralizing platforms and enabling a cloud based infrastructure for data science will lead to more opportunities for collaboration. It may even reduce IT spend in terms of equipment and maintenance overhead, thus future-proofing your data science infrastructure for the long run.</p> \n<p>So when it comes to implementing long-lived platform, here are some things to keep in mind:</p> \n<h2 id=\"collaboration-through-a-centralized-data-and-analytics-platform\">Collaboration Through a Centralized Data and Analytics Platform</h2> \n<p>A centralized platform, such as RStudio Server Pro, means all your data scientists will have access to an appropriate platform and be working within the same environment. Working in this way means that a package written by one developer can work with a minimum of effort in all your developers’ environments allowing simpler collaboration. There are other ways of achieving this with technologies such as <em>virtualenv</em> for Python, but this requires that each project set up its own environment, thereby increasing overhead. Centralizing this effort ensures that there is a well-understood way of creating projects, and each developer is working in the same way.</p> \n<p>When using a centralized platform, some significant best practices are:</p> \n<ul> \n <li><strong>Version control</strong>. If you are writing code of any kind, even just scripts, it should be versioned religiously and have clear commit messages. This ensures that users can see each change made in scripts if anything breaks and can reproduce your results on their own.</li> \n <li><strong>Packages</strong>. Whether you are working in Python or R, code should be packaged and treated like the valuable commodity it is. At Mango Solutions, a frequent challenge we address with our clients is to debug legacy code where a single ‘expert’ in a particular technology has written some piece of process which has become mission critical and then left the business. There is then no way to support, develop, or otherwise change this process without the whole business grinding to a halt. Packaging code and workflows helps to document and enforce dependencies, which can make legacy code easier to manage. These packages can then be maintained by RStudio Package Manager or Artifactory.</li> \n <li><strong>Reusability.</strong> By putting your code in packages and managing your environments with <em>renv</em>, you’re able to make your data science reusable. Creating this institutional knowledge means that you can avoid a Data Scientist becoming a single point of failure, and, when a data scientist does leave, you won’t be left with a model that nobody understands or can’t run. As Lou Bajuk explained in his blog post, <a href=\"https://blog.rstudio.com/2020/06/24/delivering-durable-value/\" target=\"_blank\" rel=\"noopener noreferrer\">Does your Data Science Team Deliver Durable Value?</a>, durable code is a significant criteria for future-proofing your data science organization.</li> \n</ul> \n<h2 id=\"enabling-a-cloud-based-environment\">Enabling a Cloud-based Environment</h2> \n<p>In addition to this institutional knowledge benefit, running this data science platform on a cloud instance allows us to scale up the platform easily. With the ability to deploy to Kubernetes, scaling your deployment as your data science team grows is a huge benefit while only requiring you to pay for what you need to, when you need it.</p> \n<p>This move to cloud comes with some tangential benefits which are often overlooked. Providing your data science team with a cloud-based environment has a number of benefits:</p> \n<ol> \n <li>The cost of hardware for your data science staff can be reduced to low cost laptops rather than costly high end on-premise hardware.</li> \n <li>By providing a centralized development platform, you allow remote and mobile work which is a key discriminator for hiring the best talent.</li> \n <li>By enhancing flexibility, you are better positioned to remain productive in unforeseen circumstances.</li> \n</ol> \n<p>This last point cannot be overstated. At the beginning of the Covid-19 lockdown, a nationwide company whose data team was tied to desktops found themselves struggling to provide enough equipment to continue working through the lockdown. As a result, their data science team could not function and were unable to provide insights that would have been invaluable through these changing times. By contrast, here at Mango, our data science platform strategy allowed us to switch seamlessly to remote working, add value to our partners, and deliver insights when they were needed most.</p> \n<p>Building agility into your basic ways of working means that you are well placed to adapt to unexpected events and adopt new platforms which are easier to update as technology moves on.</p> \n<p>Once you have a centralized analytics platform and cloud-based infrastructure in place, how are you going to convince the business to use it? This is where the worlds of Business Intelligence and software dev-ops come to the rescue.</p> \n<p>Analytics-backed dashboards using technologies like Shiny or Dash for Python with RStudio Connect means you can quickly and easily create front ends for business users to access results from your models. You can also easily expose APIs that allow your websites to be backed by scalable models, potentially creating new ways for customers to engage with your business.</p> \n<p>A word of caution here: Doing this without considering how you are going to maintain and update what have now become software products can be dangerous. Models may go out of date, functionality can become irrelevant, and the business can become disillusioned. Fortunately, these are solved problems in the web world, and solutions such as containers and Kubernetes alongside CI/CD tools make this a simpler challenge. As a consultancy we have a tried and tested solutions that expose APIs from R or Python that back high-throughput websites from across a number of sectors for our customers.</p> \n<h2 id=\"collaborative-forms-of-communications\">Collaborative Forms of Communications</h2> \n<p>The last piece of the puzzle for your data science team to be productive has nothing to do with data science but is instead about communication. Your data science team may create insights from your data, but they are like a rudderless ship without input from the business. Understanding business problems and what has value to the wider enterprise requires good communication. This means that your data scientists have to partner with people who understand the sales and marketing strategy. And if you are to embrace the ethos of flexibility as protection against the future, then good video-conferencing and other technological communications are essential.</p> \n<hr style=\"width:100%;border:1px solid rgba(0,0,0,.1);margin:50px 0\"> \n <h3 id=\"about-dean-wood-and-mango-solutions\">About Dean Wood and Mango Solutions</h3> \n <p>Dean Wood is a Data Science Leader at <a href=\"https://www.mango-solutions.com\" target=\"_blank\" rel=\"noopener noreferrer\">Mango Solutions</a>. Mango Solutions provides complex analysis solutions, consulting, training, and application development for some of the largest companies in the world. Founded and based in the UK in 2002, the company offers a number of bespoke services for data analysis including validation of open-source software for regulated industries.</p> \n</hr>","descriptionType":"text/html","publishedDate":"Tue, 30 Jun 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"0098c973d1500637b41dd2471b1edd18","bgimgJsdelivr":"","metaImg":"","author":"Dean Wood, Mango Solutions","articleImgCdnMap":{"https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/tomorrowland-hero.jpg":"https://cdn.jsdelivr.net/gh/myreaderx/cdn10@2020_4/2020/08/25/00-02-55-271_0e4c8e7392ea94ef.webp"},"publishedOrCreatedDate":1598313739857},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Does your Data Science Team Deliver Durable Value?","link":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/","description":"<p><style type=\"text/css\"> table { border-top: 1px solid rgba(117,170,219,.6); border-bottom: 1px solid rgba(117,170,219,.6); margin: 25px 0 15px 0; padding: 40px 35px 35px 35px; width: 100%; } tr:nth-child(even) { background: #ffffff; } tr { vertical-align: top; } td { text-align: left; padding: 2px 5px; } th { font-size: 24px; font-weight: 400; padding-bottom: 15px; text-align: left; } td li { font-size: 15px; } .quote-spacing { padding:0 80px; } .quote-size { font-size: 140%; line-height: 34px; } @media only screen and (max-width: 600px) { .quote-spacing { padding:0; } .quote-size { font-size: 120%; line-height: 28px; } table { padding: 40px 0px 35px 0px; } } </style> \n <div style=\"padding: 35px 0 35px 0;\"> \n  <img srcset=\"https://blog.rstudio.com/2020/06/24/delivering-durable-value/big-rock-hero_hu33bcd405dbf51ce8ac52a47f3aeecdbd_571200_800x0_resize_q75_box.jpg, https://blog.rstudio.com/2020/06/24/delivering-durable-value/big-rock-hero.jpg 2x\" src=\"https://blog.rstudio.com/2020/06/24/delivering-durable-value/big-rock-hero.jpg\" width=\"800\" alt=\"Large durable rock\" /> \n </div></p> \n<p><em>Photo by <a href=\"https://unsplash.com/@zoltantasi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" target=\"_blank\" rel=\"noopener noreferrer\">Zoltan Tasi</a> on <a href=\"https://unsplash.com/s/photos/boulder-rock?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" target=\"_blank\" rel=\"noopener noreferrer\">Unsplash</a></em></p> \n<p>In a recent series of blog posts, we introduced the idea of <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">Serious Data Science</a> to help tackle the challenges of effectively implementing data science in an organization. We then focused on the importance of <a href=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/\" target=\"_blank\" rel=\"noopener noreferrer\">delivering insights that are credible with your stakeholders</a> and <a href=\"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/\" target=\"_blank\" rel=\"noopener noreferrer\">approaching data science projects in an agile way</a>. However, once you’ve created valuable insights, the challenge is then how to continue to deliver those insights in a repeatable and sustainable way. Otherwise, your initial impact may be short-lived.</p> \n<h2 id=\"obstacles-to-providing-ongoing-value-with-data-science\">Obstacles to providing ongoing value with data science</h2> \n<p>Once a valuable insight or tool has reached a decision maker, organizations struggle with maintaining and growing the value of these data science investments over time. Far too often, they need to start from scratch when solving a new problem or are forced to painfully reimplement old analyses when they are unexpectedly needed. Some of the key areas data science teams struggle with include:</p> \n<ul> \n <li><strong>Lack of reuse:</strong> Especially when your data science insights are locked up in a spreadsheet or a point-and-click tool, it can be nearly impossible to reuse that analysis in new ways. This forces data scientists to start from scratch when a new problem comes along and makes it difficult to build an analytical toolbox of valuable intellectual property over time.</li> \n <li><strong>Lack of reproducibility:</strong> When you share your analysis with someone else, they may find it difficult to reproduce it if they don’t have identical versions of tools and libraries. As these tools evolve, you may find it impossible to recreate your analyses. Both of these situations are frustrating, leading to unnecessary work and anxiety as you attempt to figure out what element of the environment has changed.</li> \n <li><strong>Stale insights and repetitive work:</strong> While a stakeholder may value your analysis today, they’ll likely want to run it again with updated data in the future. If your analysis is static, it quickly becomes stale which forces the decision maker to either make a decision on old data or to ask you for an update. These out-of-date analyses lead to frustration on both sides, as the stakeholder waits for the update, and the data scientist is forced to repeat work instead of working on new analyses.</li> \n</ul> \n<div style=\"overflow-x:auto;\"> \n <table> \n  <tr> \n   <th>Obstacles </th> \n   <th>Solutions </th> \n  </tr> \n  <tr> \n   <td>Lack of reuse </td> \n   <td>Build your analyses with code, not clicks </td> \n  </tr> \n  <tr> \n   <td>Lack of reproducibility </td> \n   <td>Manage data science environments for repeatability </td> \n  </tr> \n  <tr> \n   <td>Stale insights and repetitive work </td> \n   <td>Deploy tools to keep insights up to date </td> \n  </tr> \n  <tr> \n   <td>Unsustainable data science platforms </td> \n   <td>Embrace platforms that support open source software </td> \n  </tr> \n </table> \n <div style=\"font-size:85%;padding-bottom: 20px;\"> \n  <i>Figure 1: Common obstacles to delivering durable value with your data science and approaches to mitigate them.</i> \n </div> \n <h2 id=\"a-durable-approach-to-data-science\">A Durable Approach to Data Science</h2> \n <p>To make the benefits of your data science insights durable over the long term, we recommend applying <em>Serious Data Science</em> principles as outlined in Figure 1. We suggest that your data science teams:</p> \n <ul> \n  <li><strong>Build your analyses with code, not clicks.</strong> Data science teams should use a code-oriented approach because code can be developed, applied, and adapted to solve similar problems in the future. This reusable and extensible code then becomes core intellectual property for your organization which will make it easier to solve new problems in the future and increase the aggregate value of your data science work.</li> \n  <li><strong>Manage data science environments for repeatability.</strong> Organizations need ways to reproduce reports and dashboards as projects, tools, and dependencies change. Otherwise, your team may spend far too much time attempting to recreate old results, or worse, it may give different answers to the same questions at different points in time, thereby undermining your team’s credibility. Use packages such as <a href=\"https://rstudio.github.io/renv/articles/renv.html\" target=\"_blank\" rel=\"noopener noreferrer\">renv</a> for individual projects and use products such as <a href=\"https://rstudio.com/products/package-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Package Manager</a> to improve reproducibility across a larger organization.</li> \n  <li><strong>Deploy tools to keep insights up to date.</strong> No one wants to make a decision based on old data. Publish your insights on web-based tools such as <a href=\"https://rstudio.com/products/connect/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Connect</a> to keep your business stakeholders up to date with on-demand access and scheduled updates. Deploying insights this way also frees the data scientist to spend their time solving new problems rather than solving the same problem again and again.<br /></li> \n </ul> \n <p>Sharla Gelfand recently spoke at rstudio::conf 2020 about the benefits of reproducible reports for the College of Nurses of Ontario:</p> \n <div style=\"padding: 20px 0 35px 0;\"> \n  <script src=\"https://fast.wistia.com/embed/medias/cj68m8on14.jsonp\" async=\"\"></script> \n  <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script> \n  <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\"> \n   <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\"> \n    <div class=\"wistia_embed wistia_async_cj68m8on14 videoFoam=true\" style=\"height:100%;position:relative;width:100%\"> \n     <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\"> \n      <img src=\"https://fast.wistia.com/embed/medias/cj68m8on14/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" /> \n     </div> \n    </div> \n   </div> \n  </div> \n </div> \n <h2 id=\"building-on-a-sustainable-foundation\">Building on a Sustainable Foundation</h2> \n <p>To this point, our serious data science approach has largely been independent of the underlying data science platform. However, your choice of data science platform can itself pose a risk to the durability of the work you do. Your data platform can become unsustainable over time due to:</p> \n <ul> \n  <li><strong>High license costs:</strong> Expensive software and variable budgets often force teams to restrict platform access to a select few data scientists. Worse, those teams may have to hold off on tackling new data science projects or deploying to more stakeholders until Finance approves money for more seats.</li> \n  <li><strong>Dwindling communities:</strong> If the platform or language decreases in its popularity with developers, it may become difficult to find new data scientists who are familiar with it.</li> \n  <li><strong>Vendor acquisitions or shifts in business models:</strong> If the platform maker is acquired by a larger company or shifts their business model, it may abandon or scale back investment in their previous product. Alternatively, sometimes vendors move from an innovation to a value extraction model, where locked-in customers are forced to pay higher license fees over time.</li> \n </ul> \n <p>Regardless of the underlying reason, an unsustainable platform can drive up costs and potentially even force an organization to start from scratch with a new platform. To reduce these threats, we recommend embracing platforms that support open source software. Doing so improves the sustainability of your data science because these platforms are:</p> \n <ul> \n  <li><strong>Cost effective:</strong> Open source software can deliver tremendous value at minimal cost, which mitigates the risk of losing your data science platform due to future budget cuts. It also makes it much easier to expand to more users as your data science team grows.</li> \n  <li><strong>Widely supported:</strong> The R and Python open source communities are large and growing, so you can be confident these tools, and the expertise to use them will be available for many years to come. These communities are further bolstered by <a href=\"https://rstudio.com/about/what-makes-rstudio-different/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio’s mission</a>, which is dedicated to sustainable investment in free and open-source software for data science.</li> \n  <li><strong>Vendor independent:</strong> RStudio’s founder JJ Allaire wrote the following in a <a href=\"https://blog.rstudio.com/2020/06/24/delivering-durable-value/ https://blog.rstudio.com/2020/01/29/rstudio-pbc/\" target=\"_blank\" rel=\"noopener noreferrer\">recent blog post</a>:</li> \n </ul> \n <div style=\"background-color: #f8f8f8;padding:50px 30px 30px 30px;margin:50px 0;\"> \n  <div style=\"text-align:center;padding-bottom:10px;\"> \n   <img src=\"https://blog.rstudio.com/2020/06/24/delivering-durable-value/logo-lockup.svg\" width=\"400px\"> </img> \n  </div> \n  <div class=\"quote-spacing\"> \n   <p class=\"quote-size\"><i>\"Users should be wary of the underlying motivations and goals of software companies, especially ones that provide the essential tools required to carry out their work.\"</i></p> \n   <p style=\"text-align: right;\">JJ Allaire, CEO, RStudio<br><a href=\"https://rstudio.com/pbc-keynote\" target=\"_blank\">rstudio.com/pbc-keynote</a></br></p> \n  </div> \n </div> \n <p>With this caution in mind, consider building your data science investments on a platform with an open source core. Should they change their business or licensing model, everything you need to do your core data science work will still be freely available, and you can freely choose whether you want to pay the vendor’s price.</p> \n <h2 id=\"learn-more-about-serious-data-science\">Learn more about Serious Data Science</h2> \n <p>For more information, check our previous posts <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">introducing the concepts of Serious Data Science</a>, <a href=\"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/\" target=\"_blank\" rel=\"noopener noreferrer\">drilling into the importance of credibility</a>, and exploring <a href=\"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/\" target=\"_blank\" rel=\"noopener noreferrer\">how to apply agile principles</a> to your data science work.</p> \n <p>If you’d like to learn more, we also recommend:</p> \n <ul> \n  <li>In this upcoming webinar, <a href=\"https://pages.rstudio.net/BeyondDashboardFatigueWebinar.html\" target=\"_blank\" rel=\"noopener noreferrer\">Beyond Dashboard Fatigue</a> , we’ll discuss how to repeatably deliver up-to-data analyses to your stakeholders using proactive email notifications through the blastula and gt packages, and how RStudio pro products can be used to scale out those solutions for enterprise applications</li> \n  <li>In this <a href=\"https://rstudio.com/about/customer-stories/astra_zeneca/\" target=\"_blank\" rel=\"noopener noreferrer\"> customer spotlight</a>, Paul Metcalf, Head, Machine Learning and AI, Oncology R&amp;D at AstraZeneca, describes how his team “created a robust toolchain for routine tasks and enabled reproducible research” with R, RStudio, and Shiny.</li> \n  <li>To learn more about how RStudio Connect makes it simple to deliver repeatable, up-to-date data products to your stakeholders, check out the <a href=\"https://rstudio.com/products/connect/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Connect product page</a>.</li> \n  <li>RStudio’s Sean Lopp explores the importance of Reproducible Environments in this <a href=\"https://rviews.rstudio.com/2019/04/22/reproducible-environments/\" target=\"_blank\" rel=\"noopener noreferrer\">RViews Blog post</a>.</li> \n  <li>Garrett Grolemund <a href=\"https://rstudio.com/resources/webinars/reproducibility-in-production/\" target=\"_blank\" rel=\"noopener noreferrer\">presented a webinar</a> on the role that computational documents like RMarkdown play in supporting reproducibility in production.</li> \n  <li><a href=\"https://rstudio.com/about/what-makes-rstudio-different/\" target=\"_blank\" rel=\"noopener noreferrer\">What Makes RStudio Different</a> explains that RStudio’s mission is to sustainably create free and open-source software for data science and allow anyone with access to a computer to participate freely in a data-centric global economy.</li> \n </ul> \n</div>","descriptionType":"text/html","publishedDate":"Wed, 24 Jun 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"f9ccab012024ff50b664df1abebdd28b","bgimgJsdelivr":"","metaImg":"","author":"Lou Bajuk, Carl Howe","articleImgCdnMap":{"https://blog.rstudio.com/2020/06/24/delivering-durable-value/big-rock-hero.jpg":"https://cdn.jsdelivr.net/gh/myreaderx/cdn22@2020_1/2020/08/25/00-02-56-214_5235689438b024bf.webp","https://fast.wistia.com/embed/medias/cj68m8on14/swatch":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn46@2020_3/2020/08/25/00-02-55-935_6c3b66372fbb2817.webp","https://blog.rstudio.com/2020/06/24/delivering-durable-value/logo-lockup.svg":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn41@2020_6/2020/08/25/00-02-54-990_5c3dd8e2427052e2.svg"},"publishedOrCreatedDate":1598313739858},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Winners of the 2nd Annual Shiny Contest","link":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","description":"<script src=\"https://blog.rstudio.com/rmarkdown-libs/header-attrs/header-attrs.js\"></script> \n<p><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/shiny-contest-cover.jpeg\" width=\"100%\" /></p> \n<p>At rstudio::conf(2020) we <a href=\"https://rstudio.com/resources/rstudioconf-2020/making-the-shiny-contest/\" target=\"_blank\" rel=\"noopener noreferrer\">announced</a> the Shiny Contest 2020. Since then, lots changed in the world, and we decided to hold off on announcing the results of the contest for a bit. Today we would like to take some time to acknowledge the winners, honourable mentions, and runners up for Shiny Contest 2020.</p> \n<p>But before that, let’s start with some stats!</p> \n<p>We had 220 submissions from 183 unique Shiny developers to the contest this year. The number of submissions this year was 62% higher than last year, which, frankly, contributed to the lengthy review period.</p> \n<p>This year we announced a prize specifically for novice Shiny developers, and we are thrilled that 32% of the submissions were from developers with less than 1 year experience with Shiny.</p> \n<p>We were also incredibly impressed by the wide variety of application areas of the submissions. The figures below shows the distributions of categories and keywords for the app submissions. Perhaps unsurprisingly, lots of submissions involving COVID-19 data! Note that especially the categories plot likely underestimates the diversity of application areas since it can be quite difficult to classify some apps into a single category.</p> \n<p><img src=\"https://blog.rstudio.com/post/2020-07-13-winners-of-the-2nd-shiny-contest/index_files/figure-html/categories-keywords-1.png\" width=\"100%\" /></p> \n<p>Apps were evaluated based on technical merit and artistic achievement. Some apps excelled in one of these categories and some in the other, and some in both. Evaluation also took into account the narrative on the contest submission post on RStudio Community.</p> \n<p>All winners of the Shiny Contest 2020 will get one year of shinyapps.io Basic Plan, a bunch of hex stickers of RStudio packages, and a spot on the <a href=\"https://shiny.rstudio.com/gallery/#user-showcase\" target=\"_blank\" rel=\"noopener noreferrer\">Shiny User Showcase</a>. Runners up will additionally get any number of RStudio t-shirts, books, and mugs (worth up to $200) where mailing is possible. And, finally, grand prize winners will additionally receive special and persistent recognition by RStudio in the form of a winners page and a badge that will be publicly visible on their <a href=\"http://rstudio.community/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Community</a> profile, as well as half-an-hour one-on-one with a representative from the RStudio Shiny team for Q&amp;A and feedback!</p> \n<p>Alright, without further ado, here are the winners! Note that winners are listed in no specific order within each category.</p> \n<div id=\"grand-prizes\" class=\"section level2\"> \n <h2>Grand prizes</h2> \n <div id=\"blog-explorer\" class=\"section level3\"> \n  <h3>🏆 <a href=\"https://nz-stefan.shinyapps.io/blog-explorer/\" target=\"_blank\" rel=\"noopener noreferrer\">Blog Explorer</a></h3> \n  <p><a href=\"https://nz-stefan.shinyapps.io/blog-explorer/\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/topic-model-results.png\" align=\"right\" width=\"100%\" /></a></p> \n  <p>A Shiny app to browse the results of a topic model trained on 30,000+ blog articles about the statistical programming language R.</p> \n  <p>We loved the beautiful UI of this app that is developed using HTML templates. Topic modeling results are presented using network graphs that leverage JavaScript. The app code is clear and makes fantastic use of modules. We also enjoyed the through narrative on the submission. <a href=\"https://community.rstudio.com/t/blog-explorer-2020-shiny-contest-submission/58803\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br /></p> \n </div> \n <div id=\"git-discoverer\" class=\"section level3\"> \n  <h3>🏆 <a href=\"https://rajkstats.shinyapps.io/git_discoverer_app/\" target=\"_blank\" rel=\"noopener noreferrer\">Git Discoverer</a></h3> \n  <p><a href=\"https://rajkstats.shinyapps.io/git_discoverer_app\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/git-discoverer.png\" align=\"right\" width=\"100%\" /></a></p> \n  <p>This project is re-work the app author’s submission for RStudio Shiny Contest 2019. The re-worked app features popular machine learning and deep learning projects on GitHub, dynamic rendering, functionality to sort by trend, stars, and forks as well as a disconnect screen for Shiny Server.</p> \n  <p>We loved that the app author re-built this app to try out skills they developed over the past year. The improvement in the UI is very striking! And the submission narrative is incredibly detailed as well! <a href=\"https://community.rstudio.com/t/re-work-of-gitdiscoverer-2020-shiny-contest-submission/58325\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br /></p> \n </div> \n <div id=\"shiny-decisions\" class=\"section level3\"> \n  <h3>🏆 <a href=\"https://sparktuga.shinyapps.io/ShinyDecisions/\" target=\"_blank\" rel=\"noopener noreferrer\">Shiny Decisions</a></h3> \n  <p><a href=\"https://sparktuga.shinyapps.io/ShinyDecisions/\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/shiny-decisions.png\" align=\"right\" width=\"100%\" /></a></p> \n  <p>A game about making the best of terrible choices. In Shiny Decisions your goal is to last as long as possible while making decisions that affect the wealth, population and environment quality in the world.</p> \n  <p>The app is quite complex, and hard to describe with words. We strongly recommend giving the game a try to get a sense of it! The code for the app is equally complex, but very well organised.</p> \n  <p><br /></p> \n </div> \n <div id=\"datify\" class=\"section level3\"> \n  <h3>🏆 <a href=\"https://kneijenhuijs.shinyapps.io/Datify\" target=\"_blank\" rel=\"noopener noreferrer\">Datify</a></h3> \n  <p><a href=\"https://kneijenhuijs.shinyapps.io/Datify\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/datify.png\" align=\"right\" width=\"100%\" /></a></p> \n  <p>Curious about the sentiment of your favourite artists? And how do they compare to other artists? Are specific artists changing their musical style over time? And do they vary more in their musical creativity than others? Answers to these type of questions can be found in this app that is inspired, in part, by one of last year’s winning submissions, the <a href=\"https://community.rstudio.com/t/shiny-contest-submission-sentify-spotify-musical-sentiment-visualization/25207\" target=\"_blank\" rel=\"noopener noreferrer\">Sentify</a> app.</p> \n  <p>We loved the clean UI of this app and the interactivity when selecting artists. The various data visualisations and the consistent use of color in them is quite striking as well! We should also note that this app won one of the Grand Prizes in the novice category with app developers having less than 1 year experience with Shiny!</p> \n  <p><br /></p> \n </div> \n <div id=\"hexmake\" class=\"section level3\"> \n  <h3>🏆 <a href=\"https://connect.thinkr.fr/hexmake/\" target=\"_blank\" rel=\"noopener noreferrer\">Hexmake</a></h3> \n  <p><a href=\"https://connect.thinkr.fr/hexmake/\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/hexmake.png\" align=\"right\" width=\"100%\" /></a></p> \n  <p>An application to build your own hex sticker. Allows to customise name, font, colours, to manipulate the image, to export the hex and to save it in an open hex database.</p> \n  <p>The application area is quite straightforward but the technical details of this app are what set it apart from other apps with a similar goal. The app comes with a series of tools built on top of the magick package that allows the user to modify the image they upload to the app. It also comes with its own file format for the resulting hex and it’s plugged into a Mongo database where users can save their own hexes and share it with others. It also has a nice walk through to help users get started. <a href=\"https://community.rstudio.com/t/hexmake-2020-shiny-contest-submission/59122\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br><br /></br></p> \n </div> \n</div> \n<div id=\"runners-up\" class=\"section level2\"> \n <h2>Runners up</h2> \n <p><a href=\"https://parmsam.shinyapps.io/one_source_indy/\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/one-source-indy.png\" align=\"right\" height=\"170\" /></a></p> \n <div id=\"one-source-indy\" class=\"section level3\"> \n  <h3>🏅 <a href=\"https://parmsam.shinyapps.io/one_source_indy/\" target=\"_blank\" rel=\"noopener noreferrer\">One Source Indy</a></h3> \n  <p>This app uses Indianapolis community resource data to create an open source app to better inform in-need homeless or unstably-housed individuals living in Indianapolis on resources available in their community. The prototype was created to show how publicly available resource data can be used with R shiny, to potentially collaborate with Indianapolis homeless outreach organizations, and to encourage others to develop similar applications for social good.</p> \n  <p>We loved the application area of this app and that the app authors also made the webscraping code available. We were also very impressed by the complexity of the app given that the app authors had less than one year experience with Shiny. <a href=\"https://community.rstudio.com/t/one-source-indy-2020-shiny-contest-submission/55391\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br /></p> \n  <p><a href=\"https://sebastianwolf.shinyapps.io/Corona-Shiny/\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/corona-shiny.png\" align=\"right\" height=\"170\" /></a></p> \n </div> \n <div id=\"material-design-covid-19-dashboard\" class=\"section level3\"> \n  <h3>🏅 <a href=\"https://sebastianwolf.shinyapps.io/Corona-Shiny/\" target=\"_blank\" rel=\"noopener noreferrer\">Material Design COVID-19 Dashboard</a></h3> \n  <p>Governments and COVID-19: Which one stops it faster, better, has fewer people dying? These questions get answered in this visually appealing and mobile friendly dashboard that uses plotly and shinymaterial. <a href=\"https://community.rstudio.com/t/material-design-corona-covid-19-dashboard-2020-shiny-contest-submission/59690\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br><br><br><br /></br></br></br></p> \n  <p><a href=\"https://dgranjon.shinyapps.io/deminR\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/deminR.png\" align=\"right\" height=\"170\" /></a></p> \n </div> \n <div id=\"deminr\" class=\"section level3\"> \n  <h3>🏅 <a href=\"https://dgranjon.shinyapps.io/deminR\" target=\"_blank\" rel=\"noopener noreferrer\">deminR</a></h3> \n  <p>This is the R version of the Minesweeper. The goal is simple : flag all the mines as quick as possible by clicking on the grid. While this app is optimized for mobile use, it also works on desktop. Note that since the right click on desktop platforms is replaced by a long press for mobiles which takes more time, scores are categorized by devices. As soon as you click on a mine, the game is immediately lost. You may reset the game at any time when the timer is on by clicking on the option button in the navigation bar. After a success, the score may be shared on twitter (as long as you have a twitter account). <a href=\"https://community.rstudio.com/t/deminr-a-minesweeper-for-r-2020-shiny-contest-submission/56356\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br /></p> \n  <p><a href=\"https://johncoene.shinyapps.io/fopi-contest/#home\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/freedom-of-press.png\" align=\"right\" height=\"170\" /></a></p> \n </div> \n <div id=\"freedom-of-press-index\" class=\"section level3\"> \n  <h3>🏅 <a href=\"https://johncoene.shinyapps.io/fopi-contest/#home\" target=\"_blank\" rel=\"noopener noreferrer\">Freedom of Press Index</a></h3> \n  <p>This app visualises the Freedom of Press Index. It is built using the fullPage package and presents essentially two “views”: (1) to explore the progress of the index through time and (2) another to compare indices across countries. The application is packaged with golem so it can be easily shared and also comes with a docker image. <a href=\"https://community.rstudio.com/t/freedom-of-press-index-2020-shiny-contest-submission/55775\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br><br><br><br /></br></br></br></p> \n  <p><a href=\"https://nicohahn.shinyapps.io/covid19/\"><img src=\"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/covid-storyboard.png\" align=\"right\" height=\"170\" /></a></p> \n </div> \n <div id=\"visualization-of-covid-19-cases\" class=\"section level3\"> \n  <h3>🏅 <a href=\"https://nicohahn.shinyapps.io/covid19/\" target=\"_blank\" rel=\"noopener noreferrer\">Visualization of Covid-19 Cases</a></h3> \n  <p>This app takes a slightly different approach to visualizing the outbreak of the coronavirus. While the confirmed and deceased cases can still be viewed on a world map, the main goal was to tell the story of the virus. Where it came from, how it spread and what consequences it had. It is designed as a story board that is supplemented by various plots to underline the significance of different events. <a href=\"https://community.rstudio.com/t/visualization-of-covid-19-cases-2020-shiny-contest-submission/57211\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n  <p><br><br /></br></p> \n </div> \n</div> \n<div id=\"honorable-mentions\" class=\"section level2\"> \n <h2>Honorable mentions</h2> \n <p>✨ <a href=\"https://scotland.shinyapps.io/sg-equality-evidence-finder/\" target=\"_blank\" rel=\"noopener noreferrer\">Equality evidence finder</a>: The Equality Evidence Finder provides a summary of the range of available equality research and statistics for Scotland. The app currently contains over 250 interactive charts and 500 equality evidence summaries, covering a wide range of policy areas. • Data can be read directly from the Scottish Government open data platform, allowing charts to be updated automatically as soon as new data is published. <a href=\"https://community.rstudio.com/t/scottish-government-equality-evidence-finder-2020-shiny-contest-submission/53699\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://dgkf.shinyapps.io/riddlr-challenge-catalog/\" target=\"_blank\" rel=\"noopener noreferrer\">riddlr: Test-case-driven R Programming Challenges</a>: A set of shiny tools for creating coding challenges. Questions are added via a simple Rmd template , making it easy for contributors to expand the variety of questions. Metadata about the question is captured in the yaml header and named code chunks are used to capture the pre-populated code block, solution and test inputs. <a href=\"https://community.rstudio.com/t/riddlr-r-programming-challenges-2020-shiny-contest-submission/54078\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://smirnovayu.shinyapps.io/hangman_en/\" target=\"_blank\" rel=\"noopener noreferrer\">Hangman</a>: Classic hangman in Shiny! Press a letter, if it is in the word - it is added to it, if not - a picture of a hangman gets extended by one line. There is a Russian version in the app repo as well! <a href=\"https://community.rstudio.com/t/hangman-2020-shiny-contest-submission/54937\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://shahreyar-abeer.shinyapps.io/life_of_pi/\" target=\"_blank\" rel=\"noopener noreferrer\">Life of pi: A Monte Carlo simulation</a>: A shiny app that demonstrates the use of Monte Carlo Simulation to estimate the value of <span class=\"math inline\">\\(\\pi\\)</span>. <a href=\"https://community.rstudio.com/t/life-of-pi-a-monte-carlo-simulation-2020-shiny-contest-submission/59748\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://hssgenomics.shinyapps.io/RNAseq_DRaMA/\" target=\"_blank\" rel=\"noopener noreferrer\">rnaseqDRaMA - RNAseq data visualization and mining </a>: RNAseq has been widely adopted as the method of choice for large-scale gene expression profiling. Data under-utilization, however remains a major challenge due to specific skill set required for data processing, interpretation, and analysis. To simplify end-user RNA-seq data interpretation, we created RNA-seq DRaMA (RNAseq Data Retrieval and Mining Analytical platform) - an R/Shiny interactive reporting system with user-friendly web interface for data exploration and visualization (<a href=\"https://hssgenomics.shinyapps.io/RNAseq_DRaMA/\" class=\"uri\">https://hssgenomics.shinyapps.io/RNAseq_DRaMA/</a> ). The app supports many methods for data exploration including: sample PCA and multidimensional scaling, gene- and sample- correlation analyses, Venn diagram and UpSet set visualizations, gene expression group barplots and heatmaps with hierarchical clustering, volcano plots, pathway analysis with QuSAGE, and Transcription Factor network analysis. All plots are highly customized in terms of sample, feature, threshold, and color selections and create publication-ready pdf and tabular outputs. All features are well-documented with an in-app manual. RNAseq DRaMA has been extensively tested at the HSS Genomics Center with more than 100 projects delivered and several projects currently deployed in the public domain. The app comes with a manual written in bookdown! <a href=\"https://community.rstudio.com/t/rnaseqdrama-rnaseq-data-visualization-and-mining-2020-shiny-contest-submission/57244\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://rafa-pereira-br.shinyapps.io/accessibilityatlas/\" target=\"_blank\" rel=\"noopener noreferrer\">Accessibility Atlas</a>: The Accessibility Atlas is a Shiny App that allows people to interactively explore the results of the Access to Opportunities Project . It contains maps and charts that allow users to visualize estimates of people’s access to employment, education and health services at a high spatial resolution and disaggregated by socio-economic groups according to income level and color/race. In English and Portugese. <a href=\"https://community.rstudio.com/t/accessibility-atlas-2020-shiny-contest-submission/57337\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://mklienz.shinyapps.io/dude-wmb/\" target=\"_blank\" rel=\"noopener noreferrer\">Dude Where’s my Bus</a>: This Shiny application provides the user with a series of tools to inform them about the location and due times of buses and trains at multiple stops and positions in Auckland, New Zealand, helping to answer the question posed by the app’s title - Dude, Where’s My Bus? The app features multiple real time boards, live bus locations, and functionality to find an ideal bus stop. <a href=\"https://community.rstudio.com/t/dude-wheres-my-bus-2020-shiny-contest-submission/56634\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p>✨ <a href=\"https://pachamaltese.shinyapps.io/tradestatistics\" target=\"_blank\" rel=\"noopener noreferrer\">Trade Statistics</a>: Open Trade Statistics is a project that includes a public API, a dashboard, and an R package for data retrieval. In particular, the dashboard was conceived as a graphical tool for people from economics and humanities that, most of the times, are used to Excel and not to using APIs. The dashboard allows users to explore the data visually and then export it to xlsx and other formats. App was reviewed by rOpenSci as well! <a href=\"https://community.rstudio.com/t/tradestatistics-2020-shiny-contest-submission/53917\" target=\"_blank\" rel=\"noopener noreferrer\">[Read more]</a></p> \n <p><br /></p> \n</div> \n<div id=\"all-submissions-to-shiny-contest-2020\" class=\"section level2\"> \n <h2>All submissions to Shiny Contest 2020</h2> \n <p>Feel free to peruse <a href=\"https://rpubs.com/minebocek/shiny-contest-2020-submissions\" target=\"_blank\" rel=\"noopener noreferrer\">the full list of all submissions to the contest</a> with links to the apps along with the submission narratives on RStudio Community. Note that data and code used in the apps are all publicly available and/or openly licensed. We hope that they will serve as inspiration for your next Shiny app!</p> \n</div>","descriptionType":"text/html","publishedDate":"Mon, 13 Jul 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"cefa78e587ea4cfbbea36d66e957ca02","bgimgJsdelivr":"","metaImg":"","author":"Mine Çetinkaya-Rundel","articleImgCdnMap":{"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/shiny-contest-cover.jpeg":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn98@2020_6/2020/08/25/00-02-55-213_82325f09f9cd48e3.webp","https://blog.rstudio.com/post/2020-07-13-winners-of-the-2nd-shiny-contest/index_files/figure-html/categories-keywords-1.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn38@2020_4/2020/08/25/00-02-56-096_66c5be3852c759e1.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/topic-model-results.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn17@2020_1/2020/08/25/00-02-55-199_fe59a32158f3b243.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/git-discoverer.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn17@2020_1/2020/08/25/00-02-56-247_d6264fbdb312b962.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/shiny-decisions.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn77@2020_6/2020/08/25/00-02-56-434_328db6a1c43b141e.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/datify.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn70@2020_4/2020/08/25/00-02-55-166_5fc21f5475d3faef.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/hexmake.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn82@2020_4/2020/08/25/00-02-55-276_3f2d142564297bfb.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/one-source-indy.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn94@2020_3/2020/08/25/00-02-56-361_fb4e572a5bd1da32.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/corona-shiny.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn93@2020_4/2020/08/25/00-02-55-368_e076b754aa96d57c.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/deminR.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn85@2020_5/2020/08/25/00-02-55-000_8e040c3169de33b4.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/freedom-of-press.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn34@2020_6/2020/08/25/00-02-55-839_d598b9c703941f52.webp","https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/covid-storyboard.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn18@2020_5/2020/08/25/00-02-56-594_3a418da846fb5c7f.webp"},"publishedOrCreatedDate":1598313739856},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Avoid Irrelevancy and Fire Drills in Data Science Teams","link":"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/","description":"<div style=\"padding: 35px 0 35px 0;\"> \n <img srcset=\"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/irrelevancy-and-fire-drills_hu2e2f48803e0d4bb8d3f5951be670a084_89376_768x0_resize_box_2.png, https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/irrelevancy-and-fire-drills.png 2x\" src=\"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/irrelevancy-and-fire-drills.png\" width=\"768\" alt=\"A visualization of a computer thrown away and a fire\" /> \n</div> \n<h2 id=\"balancing-the-twin-threats-of-data-science-development\">Balancing the twin threats of data science development</h2> \n<p>Data science leaders naturally want to maximize the value their teams deliver to their organization, and that often means helping them navigate between two possible extremes. On the one hand, a team can easily become an expensive R&amp;D department, detached from actual business decisions, slowly chipping away only to end up answering stale questions. On the other hand, teams can be overwhelmed with requests, spending all of their time on labor intensive, manual fire-drills, always creating one more “Just in Time” Powerpoint slide.</p> \n<p>How do you avoid these threats, of either irrelevancy or constant fire drills? As we touched on in a recent blog post, <a href=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/\">Getting to the Right Question</a>, it turns out the answer is pretty straightforward: use iterative, code-based development to share your content early and often, to help overcome the communications gap with your stakeholders.</p> \n<p>Data science ecosystems can be complex and full of jargon, so before we dive into specifics let’s consider a similar balancing act. Imagine you are forming a band that wants to share new music with the world. To do so, it is critical to get music out to your fans quickly, to iterate on ideas rapidly. You don’t want to get bogged down in the details of a recording studio on day 1. At the same time, you want to be able to capture and repeat what works - perhaps as sheet music, perhaps as a video, or even as a simple recording.</p> \n<h2 id=\"share-your-data-science-work-early-and-often\">Share your data science work early and often</h2> \n<p>For data scientists, the key is creating the right types of outputs so that decision makers can iterate with you on questions and understand your results. Luckily, like a musician, the modern data science team has many ways to share their initial vision:</p> \n<ul> \n <li>They can quickly create notebooks, through tools like R Markdown or Jupyter, that are driven by reproducible code and can be shared, scheduled, and viewed without your audience needing to understand code.</li> \n <li>They can build interactive web applications using tools like Shiny, Flask, or Dash to help non-coders test questions and explore data.</li> \n <li>Sometimes, data science teams even create APIs, which act as a realistic preview of their final work with a much lower cost of creation.</li> \n</ul> \n<p>Sharing early and often enables data science teams to solve impactful problems. For example, perhaps a data scientist is tasked with forecasting sales by county. They might share their initial exploratory analysis sales leadership and tap into their domain expertise to help explain outlier counties. Or imagine a data scientist working to support biologists doing drug discovery research. Instead of responding to hundreds of requests for statistical analysis, the data scientist could build an interactive application to allow biologists to run their own analysis on different inputs and experiments. By sharing the application early and often, the biologist and data scientist can empower each other to complete far more experiments.</p> \n<p>These types of outputs all share a few characteristics:</p> \n<ol> \n <li><p><strong>The outputs are easy to create.</strong> The sign that your team has the right set of tools is if a data scientist can create and share an output from scratch in days, not months. They shouldn’t have to learn a new framework or technology stack.</p></li> \n <li><p><strong>The outputs are reproducible.</strong> It can be tempting, in a desire to move quickly, to take shortcuts. However, these shortcuts can undermine your work almost immediately. Data scientists are responsible for informing critical decisions with data. This responsibility is serious, and it means results can not exist only on one person’s laptop, or require manual tweaking to recreate. A lack of reproducibility can undermine credibility in the minds of your stakeholders, which may lead them to dismiss or ignore your analyses if the answer conflicts with their intuition.</p></li> \n <li><p><strong>Finally, and most importantly: the outputs must be shared.</strong> All of these examples: notebooks, interactive apps and dashboards, and even APIs, are geared towards interacting with decision makers as quickly as possible to be sure the right questions are being answered.</p></li> \n</ol> \n<h2 id=\"benefits-of-sharing-for-data-science-teams\">Benefits of sharing for data science teams</h2> \n<p>Luckily, tools exist to ensure data science teams can create artifacts that share these three characteristics. At RStudio, we’ve built <a href=\"https://rstudio.com/products/team/\">RStudio Team</a> with all 3 of these goals in mind.</p> \n<p>Great data science teams talk about the happy result of this approach. For examples:</p> \n<blockquote> \n <p><em>“RStudio Connect is critical, the way you can deploy flexdashboards, R Markdown… I use web apps as a way to convey a model in a very succinct fashion… because I don’t know what the user will do, I can create an app where the user’s interactions with the model can imply it, I don’t have to come up with all the finite outcomes ahead of time”</em> - Moody Hadi at S&amp;P</p> \n <p><em>“One of the key focuses for us was the method of delivery … actually taking your insights and getting business impact. How are non analytic people digesting your work.”</em> - Aymen Waqar at Astellas (check out our last blog post, <a href=\"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/\">Getting to the Right Question</a>, to see Aymen discussing the analytics communication gap)</p> \n</blockquote> \n<div align=\"center\" style=\"padding: 35px 0 35px 0;\"> \n <script src=\"https://fast.wistia.com/embed/medias/58qjn34mxy.jsonp\" async=\"\"></script>\n <script src=\"https://fast.wistia.com/assets/external/E-v1.js\" async=\"\"></script>\n <div class=\"wistia_responsive_padding\" style=\"padding:56.25% 0 0 0;position:relative;\">\n  <div class=\"wistia_responsive_wrapper\" style=\"height:100%;left:0;position:absolute;top:0;width:100%;\">\n   <div class=\"wistia_embed wistia_async_58qjn34mxy videoFoam=true\" style=\"height:100%;position:relative;width:100%\">\n    <div class=\"wistia_swatch\" style=\"height:100%;left:0;opacity:0;overflow:hidden;position:absolute;top:0;transition:opacity 200ms;width:100%;\">\n     <img src=\"https://fast.wistia.com/embed/medias/58qjn34mxy/swatch\" style=\"filter:blur(5px);height:100%;object-fit:contain;width:100%;\" alt=\"\" aria-hidden=\"true\" onload=\"this.parentNode.style.opacity=1;\" />\n    </div>\n   </div>\n  </div>\n </div> \n</div> \n<h2 id=\"it-s-not-just-about-production\">It’s not just about production</h2> \n<p>We often see data science teams make a common mistake that prevents them from achieving this delicate balancing act. A tempting trap is to focus exclusively on complex tooling oriented towards putting models in production. Because data science teams are trying to strike a balance between repeatability, robustness, and speed, and because they are working with code, they often turn to their software engineering counterparts for guidance on adopting “agile” processes. Unfortunately, many teams end up focusing on the wrong parts of the agile playbook. Instead of copying the concept - rapid iterations towards a useful goal - teams get caught up in the technologies, introducing complex workflows instead of focusing on results. This mistake leads to a different version of the expensive R&amp;D department - the band stuck in a recording studio with the wrong song.</p> \n<p>Eduardo Arina de la Rubio, head of a large data team at Facebook, lays out an important reminder <a href=\"https://resources.rstudio.com/rstudio-conf-2020/value-in-data-science-beyond-models-in-production-eduardo-arino-de-la-rubia\">in his recent talk at rstudio::conf 2020</a>. Data science teams are not machine learning engineers. While growth of the two are related, ML models will ultimately become commoditized, mastered by engineers and available in off-the-shelf offerings. Data scientists, on the other hand, have a broader mandate: to enable critical business decisions. Often, in the teams we work with at RStudio, many projects are resolved and decisions made based on the rapid iteration of an app or a notebook. Only on occasion does the result need to be codified into a model at scale - and usually engineers are involved at that stage.</p> \n<p>To wrap up, at RStudio we get to interact with hundreds of data science teams of all shapes and sizes from all types of industries. The best of these teams have all mastered the same balancing act: they use powerful tools to help them share results quickly, earning them a fanbase among their business stakeholders and helping their companies make great decisions.</p> \n<p>We developed RStudio Team with this balancing act in mind, and to make it easy for data science teams to create, reproduce and share their work. To learn more, please visit the <a href=\"https://rstudio.com/products/team/\">RStudio Team page</a>.</p> \n<div style=\"padding: 25px 0 25px 0;\"></div>","descriptionType":"text/html","publishedDate":"Tue, 28 Apr 2020 00:00:00 +0000","feedId":8609,"bgimg":"","linkMd5":"4dfec6eb54e233255a7266afed644fc2","bgimgJsdelivr":"","metaImg":"","author":"Sean Lopp, RStudio","articleImgCdnMap":{"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/irrelevancy-and-fire-drills.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn93@2020_1/2020/08/25/00-02-54-953_664975a3d1c8ba91.webp","https://fast.wistia.com/embed/medias/58qjn34mxy/swatch":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn1@2020_5/2020/08/25/00-02-56-298_dc60adf5b1a22645.webp"},"publishedOrCreatedDate":1598313739859},{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","title":"Why Package & Environment Management is Critical for Serious Data Science","link":"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/","description":"<div style=\"padding: 35px 0 0 0;\"> \n <img src=\"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/package.jpeg\" style=\"display:block;margin-left:auto;margin-right:auto;\"> </img>\n</div> \n<p style=\"text-align: right !important;margin-top: 0px;margin-bottom: 30px;\"> <i>Photo by <a style=\"color: #000000;\" href=\"https://unsplash.com/@markusspiske\">Markus Spiske</a> on <a style=\"color: #000000;\" href=\"https://unsplash.com/photos/RWTUrJf7I5w\">Unsplash</a></i></p> \n<p><em>This is a guest post from RStudio’s partner, <a href=\"https://www.procogia.com/\" target=\"_blank\" rel=\"noopener noreferrer\">ProCogia</a></em></p> \n<h3 id=\"the-rapid-advancement-of-r-presents-a-challenge-to-reproducibility\">The rapid advancement of R presents a challenge to reproducibility</h3> \n<p>Thanks to our vibrant and engaged community, R is continually evolving as successful open source software. It’s exciting to have frequent releases and refinements to our favorite tools, but this also can present challenges to maintaining the <a href=\"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/\" target=\"_blank\" rel=\"noopener noreferrer\">integrity and reproducibility</a> of our work. When new tools and packages are released, useRs like to tinker and stay on the cutting edge, but we don’t want our experimental playground to break our important workflows. We like to collaborate, but when package versions collide, this can lead to problems ranging from error messages and frustration to silent bugs and unexpected code behavior.</p> \n<p>For other stakeholders in the wider organization, these frequent updates present related challenges. For data science leaders, they may struggle with how to make sure their team has access to the latest methods, while still consistently delivering reproducible results to the rest of the organization. For IT and DevOps, they may feel inundated with requests to constantly update, validate, and maintain production systems delivering data science applications.</p> \n<h3 id=\"the-renv-package-helps-create-reproducible-project-environments\">The <code>renv</code> package helps create reproducible project environments</h3> \n<p>To address these sorts of challenges, users of other programming languages are likely familiar with virtual environments and project management tools, but analogous best practices have not seen widespread adoption within the R community. Enter <code>renv</code>, a new package for reproducible environments in R that:</p> \n<ul> \n <li>Is simple to use in new or existing projects, and</li> \n <li>Doesn’t interrupt existing workflows</li> \n</ul> \n<p>I recently co-hosted a <a href=\"https://garciamikep.github.io/useR-webinar/#1\" target=\"_blank\" rel=\"noopener noreferrer\">webinar</a> on upgrading to R 4.0 and package management with <code>renv</code>. In preparation, my co-host and I worked on the same set of RMarkdown-based <code>xaringan</code> slides, and shared our code on GitHub. Ironically, we hadn’t checked to make sure we were using the same version of R, nor did we use any package management tool to ensure consistent package versions. Surely we didn’t need any fancy tools for such a simple set of slides? Wrong! The night before our presentation, I compiled the slides and discovered the formatting was completely mangled. The next morning we decided to practice what we were about to preach, and incorporated <code>renv</code> into the project and switched to using R 4.0. Presto, the slides compiled perfectly.</p> \n<p>This formatting issue was easy to detect, and although the mangled slides were not exactly professional looking, it was a relatively harmless bug. Not all bugs are. An environment management tool such as <code>renv</code> is essential to keeping exploratory and side projects isolated from sensitive or business-critical work, and ensuring reproducibility and accuracy.</p> \n<p>Incorporating <code>renv</code> into either a new or existing project is straightforward:</p> \n<ol> \n <li>Initialize the project environment with a single function call. <code>renv</code> will automatically detect your package dependencies, or you can choose to start with a blank slate.</li> \n <li>Continue your workflow as normal, occasionally taking a snapshot (again, just one function call) to update the project environment to reflect any packages that have been added or removed.</li> \n <li>If something goes wrong, you can revert to an earlier state of the project with a single function call.</li> \n</ol> \n<h3 id=\"advantages-of-using-the-renv-package\">Advantages of using the <code>renv</code> package</h3> \n<p>The <code>renv</code> package is compatible with almost anywhere your team gets their packages (CRAN, Github, <a href=\"https://rstudio.com/products/package-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">RStudio Package Manager</a>, the <a href=\"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">recently introduced RStudio Public Package Manager</a>, GitHub, BioConductor, GitLab, BitBucket, custom local packages…). For teams familiar with Python, the workflow will feel familiar, and <code>renv</code> also integrates with <code>pipenv</code> and <code>reticulate</code> for multilingual projects.</p> \n<p>Ultimately, why would I recommend <code>renv</code> over other options?</p> \n<ul> \n <li>Disk space. <code>renv</code> doesn’t re-install the same version of a package if already installed for another project.<br /></li> \n <li><code>renv</code> improves upon deficiencies in Packrat, a previously existing package manager for R.<br /></li> \n <li><code>renv</code> is highly compatible with various ways to source and manage your packages.<br /></li> \n</ul> \n<hr /> \n<p><strong>About ProCogia:</strong></p> \n<p><a href=\"https://www.procogia.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/procogia-logo.png\" alt=\"ProCogia logo\" align=\"left\" /></a>An RStudio <a href=\"https://rstudio.com/certified-partners/\" target=\"_blank\" rel=\"noopener noreferrer\">Full Service Partner</a>, <a href=\"https://procogia.com/\" target=\"_blank\" rel=\"noopener noreferrer\">ProCogia</a> is based out of Seattle, Washington. Our consulting capability extends to building, deploying, and supporting scalable data science solutions for our clients. We are passionate about developing data-driven solutions that provide highly informed answers to your most critical questions.</p>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 00:00:00 +0000","feedId":8609,"bgimg":"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/package.jpeg","linkMd5":"64b87924659982c3a2e2918994614ed6","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn54@2020_5/2020/08/25/00-02-24-794_b6c5bc441d49e523.webp","destWidth":634,"destHeight":452,"sourceBytes":74451,"destBytes":47990,"author":"Mike Garcia, ProCogia","articleImgCdnMap":{"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/package.jpeg":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn54@2020_5/2020/08/25/00-02-24-794_b6c5bc441d49e523.webp","https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/procogia-logo.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn5@2020_6/2020/08/25/00-02-54-947_05176415cf15ffae.webp"},"publishedOrCreatedDate":1598313739854}],"record":{"createdTime":"2020-08-25 08:02:19","updatedTime":"2020-08-25 08:02:19","feedId":8609,"fetchDate":"Tue, 25 Aug 2020 00:02:19 +0000","fetchMs":568,"handleMs":1431,"totalMs":50842,"newArticles":0,"totalArticles":30,"status":1,"type":0,"ip":"52.19.225.66","hostName":"europe70*","requestId":"b8e673bd3eb6438691c7598ab8e8ec1c_8609","contentType":"application/xml","totalBytes":10651303,"bgimgsTotal":6,"bgimgsGithubTotal":6,"articlesImgsTotal":68,"articlesImgsGithubTotal":68,"successGithubMap":{"myreaderx8":2,"myreaderx14":2,"myreaderx15":3,"myreaderx7":2,"myreaderx6":2,"myreaderx16":2,"myreaderx32":3,"myreaderx4":2,"myreaderx10":2,"myreaderx3":2,"myreaderx33":3,"myreaderx11":2,"myreaderx2":3,"myreaderx12":2,"myreaderx1":3,"myreaderx13":2,"myreaderx30":2,"myreaderx31":2,"myreaderx18":2,"myreaderx19":2,"myreaderx":2,"myreaderx25":2,"myreaderx27":2,"myreaderx21":3,"myreaderx22":3,"myreaderx23":3,"myreaderx24":2,"myreaderx5oss":3,"myreaderx29":3},"failGithubMap":{}},"feed":{"createdTime":"2020-08-25 04:34:29","updatedTime":"2020-08-25 04:34:29","id":8609,"name":"RStudio Blog","url":"http://blog.rstudio.org/feed/","subscriber":null,"website":null,"icon":"https://blog.rstudio.com/icons/favicon.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx61/cdn34@2020_4/2020/08/25/00-02-19-002_a87dc7f31037cfc0.png","description":"Recent content on RStudio Blog","weekly":null,"link":"https://blog.rstudio.com"},"noPictureArticleList":[],"tmpCommonImgCdnBytes":2205312,"tmpBodyImgCdnBytes":8445991,"tmpBgImgCdnBytes":0,"extra4":{"start":1598313737795,"total":0,"statList":[{"spend":634,"msg":"获取xml内容"},{"spend":1431,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":14030,"msg":"正文链接上传到cdn"}]},"extra5":68,"extra6":68,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/_#foreach":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/#foreach","https://blog.rstudio.com/2020/07/28/practical-interoperability/_mailto::carl@rstudio.com":"mailto::carl@rstudio.com","https://blog.rstudio.com/2020/07/16/sparklyr-1-3/_#avro":"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#avro","https://blog.rstudio.com/2020/07/16/sparklyr-1-3/_#higher-order-functions":"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#higher-order-functions","https://blog.rstudio.com/2020/07/17/rstudio-global-2021/_mailto:conf@rstudio.com":"mailto:conf@rstudio.com","https://blog.rstudio.com/2020/06/24/delivering-durable-value/_ https://blog.rstudio.com/2020/01/29/rstudio-pbc/":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/ https://blog.rstudio.com/2020/01/29/rstudio-pbc/","https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/_mailto:info@rstudio.com":"mailto:info@rstudio.com","https://blog.rstudio.com/2020/05/06/sparklyr-1-2/_#databricks-connect":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/#databricks-connect","https://blog.rstudio.com/2020/07/16/sparklyr-1-3/_#other-improvements":"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#other-improvements","https://blog.rstudio.com/2020/05/06/sparklyr-1-2/_#structures":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/#structures","https://blog.rstudio.com/2020/07/16/sparklyr-1-3/_#custom-serialization":"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/#custom-serialization"},"extra111_proxyServerAndStatMap":{"http://us-013.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-037.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-55.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-021.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://europe63.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-005.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-009.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-025.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-020.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-001.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-017.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-033.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-51.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://europe67.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://europe-22.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-029.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-012.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-sparklyr.png","sourceStatusCode":200,"destWidth":354,"destHeight":303,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn56@2020_2/2020/08/25/00-02-24-853_a3289d5e6ee4ffa8.webp","sourceBytes":3509,"destBytes":3200,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1042,"convertSpendMs":16,"createdTime":"2020-08-25 08:02:24","host":"us-029*","referer":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/","linkMd5ListStr":"f18dd3380e238f6c89cf75f4ef0cb37f,f18dd3380e238f6c89cf75f4ef0cb37f","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.4 KB","destSize":"3.1 KB","compressRate":"91.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/legos.jpeg","sourceStatusCode":200,"destWidth":1050,"destHeight":700,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn71@2020_6/2020/08/25/00-02-24-801_d9bd1f2e9fbbcac8.webp","sourceBytes":131282,"destBytes":70044,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1087,"convertSpendMs":34,"createdTime":"2020-08-25 08:02:24","host":"us-55*","referer":"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/","linkMd5ListStr":"9eb540cf39b3f0e434d65ecde8b7e822,9eb540cf39b3f0e434d65ecde8b7e822","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"128.2 KB","destSize":"68.4 KB","compressRate":"53.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/python-jump-start-184.png","sourceStatusCode":200,"destWidth":1194,"destHeight":643,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn65@2020_4/2020/08/25/00-02-24-882_a14f8c86cebdd189.webp","sourceBytes":243924,"destBytes":42830,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1138,"convertSpendMs":66,"createdTime":"2020-08-25 08:02:24","host":"us-005*","referer":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/","linkMd5ListStr":"f8e6210e6198c2f20cd474e74430d85b,f8e6210e6198c2f20cd474e74430d85b","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"238.2 KB","destSize":"41.8 KB","compressRate":"17.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/package.jpeg","sourceStatusCode":200,"destWidth":634,"destHeight":452,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn54@2020_5/2020/08/25/00-02-24-794_b6c5bc441d49e523.webp","sourceBytes":74451,"destBytes":47990,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1172,"convertSpendMs":29,"createdTime":"2020-08-25 08:02:24","host":"us-028*","referer":"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/","linkMd5ListStr":"64b87924659982c3a2e2918994614ed6,64b87924659982c3a2e2918994614ed6","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"72.7 KB","destSize":"46.9 KB","compressRate":"64.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/images/2020-07-16-sparklyr-1-3-available.jpg","sourceStatusCode":200,"destWidth":492,"destHeight":700,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn70@2020_4/2020/08/25/00-02-24-855_2cc555566a3f7e0a.webp","sourceBytes":93301,"destBytes":43132,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1254,"convertSpendMs":20,"createdTime":"2020-08-25 08:02:24","host":"us-54*","referer":"https://blog.rstudio.com/2020/07/16/sparklyr-1-3/","linkMd5ListStr":"299bc46a95e2ba8757c060c1428bf545,299bc46a95e2ba8757c060c1428bf545","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"91.1 KB","destSize":"42.1 KB","compressRate":"46.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/shiny-comparisons.gif","sourceStatusCode":200,"destWidth":1600,"destHeight":402,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn61@2020_2/2020/08/25/00-02-52-883_da2eaa486e9b4065.webp","sourceBytes":3153719,"destBytes":1998116,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":29970,"convertSpendMs":26254,"createdTime":"2020-08-25 08:02:24","host":"us-017*","referer":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/","linkMd5ListStr":"3e8ea12a54ace5c7aa2029a4096a28c0,3e8ea12a54ace5c7aa2029a4096a28c0","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3 MB","destSize":"1.9 MB","compressRate":"63.4%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/67q4k9196d/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn86@2020_3/2020/08/25/00-02-54-840_0e4e92c89fd9902d.webp","sourceBytes":2948,"destBytes":1166,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":898,"convertSpendMs":19,"createdTime":"2020-08-25 08:02:54","host":"us-009*","referer":"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/","linkMd5ListStr":"6cafd3b26e73d3fffc1095811d0ec17a","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.9 KB","destSize":"1.1 KB","compressRate":"39.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/content-usage-past30.png","sourceStatusCode":200,"destWidth":331,"destHeight":124,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn26@2020_6/2020/08/25/00-02-54-859_4f10853d392d7b5a.webp","sourceBytes":8510,"destBytes":2912,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":979,"convertSpendMs":18,"createdTime":"2020-08-25 08:02:54","host":"us-017*","referer":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/","linkMd5ListStr":"f8e6210e6198c2f20cd474e74430d85b","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"8.3 KB","destSize":"2.8 KB","compressRate":"34.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/lander-logo.jpg","sourceStatusCode":200,"destWidth":216,"destHeight":216,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn66@2020_6/2020/08/25/00-02-54-936_2468eaa091d6f43b.webp","sourceBytes":9114,"destBytes":6542,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":910,"convertSpendMs":4,"createdTime":"2020-08-25 08:02:54","host":"us-025*","referer":"https://blog.rstudio.com/2020/08/13/how-to-deliver-maximum-value-using-r-python/","linkMd5ListStr":"9eb540cf39b3f0e434d65ecde8b7e822","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"8.9 KB","destSize":"6.4 KB","compressRate":"71.8%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/procogia-logo.png","sourceStatusCode":200,"destWidth":371,"destHeight":244,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn5@2020_6/2020/08/25/00-02-54-947_05176415cf15ffae.webp","sourceBytes":11314,"destBytes":6810,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":917,"convertSpendMs":13,"createdTime":"2020-08-25 08:02:54","host":"us-013*","referer":"https://blog.rstudio.com/2020/08/20/why-package-environment-management-is-critical-for-serious-data-science/","linkMd5ListStr":"64b87924659982c3a2e2918994614ed6","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11 KB","destSize":"6.7 KB","compressRate":"60.2%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/1jhwr01cpr/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn77@2020_3/2020/08/25/00-02-54-967_cf1f5eefc914d382.webp","sourceBytes":2920,"destBytes":934,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":985,"convertSpendMs":3,"createdTime":"2020-08-25 08:02:54","host":"us-020*","referer":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/","linkMd5ListStr":"9d7aa41ca9b5da46260765dbe8b6f72d","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.9 KB","destSize":"934 B","compressRate":"32%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/zhpb795rre/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn45@2020_2/2020/08/25/00-02-54-935_3982763a37966fa7.webp","sourceBytes":3899,"destBytes":1698,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1019,"convertSpendMs":15,"createdTime":"2020-08-25 08:02:54","host":"us-021*","referer":"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/","linkMd5ListStr":"bc1651d11bf689931989cd41e5de328c","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.8 KB","destSize":"1.7 KB","compressRate":"43.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/logo-lockup.svg","sourceStatusCode":200,"destWidth":0,"destHeight":0,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn41@2020_6/2020/08/25/00-02-54-990_5c3dd8e2427052e2.svg","sourceBytes":11379,"destBytes":11379,"feedId":8609,"totalSpendMs":1049,"convertSpendMs":0,"createdTime":"2020-08-25 08:02:54","host":"us-033*","referer":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/","linkMd5ListStr":"f9ccab012024ff50b664df1abebdd28b","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.1 KB","destSize":"11.1 KB","compressRate":"100%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/irrelevancy-and-fire-drills.png","sourceStatusCode":200,"destWidth":1536,"destHeight":806,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn93@2020_1/2020/08/25/00-02-54-953_664975a3d1c8ba91.webp","sourceBytes":89376,"destBytes":46974,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1079,"convertSpendMs":96,"createdTime":"2020-08-25 08:02:54","host":"us-005*","referer":"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/","linkMd5ListStr":"4dfec6eb54e233255a7266afed644fc2","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"87.3 KB","destSize":"45.9 KB","compressRate":"52.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/07/interoperability-july/SwitzerlandLifeExp.png","sourceStatusCode":200,"destWidth":700,"destHeight":500,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn89@2020_2/2020/08/25/00-02-55-114_0e8b53c9fcccdf37.webp","sourceBytes":26185,"destBytes":11544,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1122,"convertSpendMs":110,"createdTime":"2020-08-25 08:02:54","host":"us-017*","referer":"https://blog.rstudio.com/2020/07/07/interoperability-july/","linkMd5ListStr":"7975ce8fad1a1bda09ef932ac7fca674","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.6 KB","destSize":"11.3 KB","compressRate":"44.1%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/deminR.png","sourceStatusCode":200,"destWidth":1050,"destHeight":1050,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn85@2020_5/2020/08/25/00-02-55-000_8e040c3169de33b4.webp","sourceBytes":63500,"destBytes":18416,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1159,"convertSpendMs":36,"createdTime":"2020-08-25 08:02:54","host":"us-029*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"62 KB","destSize":"18 KB","compressRate":"29%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/interoperability.png","sourceStatusCode":200,"destWidth":1920,"destHeight":1080,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn38@2020_1/2020/08/25/00-02-55-019_6da3fc4b49a62df6.webp","sourceBytes":92914,"destBytes":48030,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1165,"convertSpendMs":62,"createdTime":"2020-08-25 08:02:54","host":"us-55*","referer":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/","linkMd5ListStr":"097471c73b959a4994817ed8b3269efe","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"90.7 KB","destSize":"46.9 KB","compressRate":"51.7%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/28/practical-interoperability/interoperability-hexes.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":900,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn62@2020_4/2020/08/25/00-02-55-028_7eab7d878cb06bf2.webp","sourceBytes":86953,"destBytes":25414,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1181,"convertSpendMs":71,"createdTime":"2020-08-25 08:02:54","host":"us-037*","referer":"https://blog.rstudio.com/2020/07/28/practical-interoperability/","linkMd5ListStr":"0666e48ece98e7a7a00af8a4b6e33c0a","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.9 KB","destSize":"24.8 KB","compressRate":"29.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/windmills.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":973,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn30@2020_5/2020/08/25/00-02-55-113_fb719f6cbd56af22.webp","sourceBytes":109221,"destBytes":63514,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1336,"convertSpendMs":103,"createdTime":"2020-08-25 08:02:54","host":"us-005*","referer":"https://blog.rstudio.com/2020/05/19/driving-real-lasting-value-with-serious-data-science/","linkMd5ListStr":"6cafd3b26e73d3fffc1095811d0ec17a","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"106.7 KB","destSize":"62 KB","compressRate":"58.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig2.jpg","sourceStatusCode":200,"destWidth":1601,"destHeight":456,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn29@2020_1/2020/08/25/00-02-55-130_f6ce2731c9768396.webp","sourceBytes":107665,"destBytes":40630,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1243,"convertSpendMs":23,"createdTime":"2020-08-25 08:02:54","host":"us-012*","referer":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/","linkMd5ListStr":"9d7aa41ca9b5da46260765dbe8b6f72d","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"105.1 KB","destSize":"39.7 KB","compressRate":"37.7%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-components.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":691,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn1@2020_4/2020/08/25/00-02-55-081_b450af8f420eb25d.webp","sourceBytes":207278,"destBytes":62528,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1188,"convertSpendMs":33,"createdTime":"2020-08-25 08:02:54","host":"us-55*","referer":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/","linkMd5ListStr":"d1d11e70c6eb49eb96fd02351cc04c5e","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"202.4 KB","destSize":"61.1 KB","compressRate":"30.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/sparklers-hero.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":1067,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn2@2020_1/2020/08/25/00-02-55-078_d5847c8b243a7687.webp","sourceBytes":506870,"destBytes":147152,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1266,"convertSpendMs":63,"createdTime":"2020-08-25 08:02:54","host":"us-025*","referer":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/","linkMd5ListStr":"097471c73b959a4994817ed8b3269efe","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"495 KB","destSize":"143.7 KB","compressRate":"29%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/datify.png","sourceStatusCode":200,"destWidth":1000,"destHeight":536,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn70@2020_4/2020/08/25/00-02-55-166_5fc21f5475d3faef.webp","sourceBytes":361148,"destBytes":66156,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1289,"convertSpendMs":77,"createdTime":"2020-08-25 08:02:54","host":"us-013*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"352.7 KB","destSize":"64.6 KB","compressRate":"18.3%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/tools-chart.jpg","sourceStatusCode":200,"destWidth":2458,"destHeight":1247,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn10@2020_1/2020/08/25/00-02-55-209_c8d3fe868e514bd8.webp","sourceBytes":226736,"destBytes":69044,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1348,"convertSpendMs":203,"createdTime":"2020-08-25 08:02:54","host":"us-021*","referer":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/","linkMd5ListStr":"097471c73b959a4994817ed8b3269efe","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"221.4 KB","destSize":"67.4 KB","compressRate":"30.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/work-from-home-desk.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":1067,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn26@2020_5/2020/08/25/00-02-55-070_43addc51b94226a1.webp","sourceBytes":260117,"destBytes":115920,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1409,"convertSpendMs":100,"createdTime":"2020-08-25 08:02:54","host":"us-037*","referer":"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/","linkMd5ListStr":"f1482487bf469c1b8522c883a0ea2cde","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"254 KB","destSize":"113.2 KB","compressRate":"44.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/cloud-1600.png","sourceStatusCode":200,"destWidth":1600,"destHeight":840,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn14@2020_5/2020/08/25/00-02-55-324_30e5b585f794977e.webp","sourceBytes":33972,"destBytes":24856,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1448,"convertSpendMs":211,"createdTime":"2020-08-25 08:02:54","host":"us-009*","referer":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/","linkMd5ListStr":"d1d11e70c6eb49eb96fd02351cc04c5e","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.2 KB","destSize":"24.3 KB","compressRate":"73.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/tomorrowland-hero.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":1066,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn10@2020_4/2020/08/25/00-02-55-271_0e4c8e7392ea94ef.webp","sourceBytes":337095,"destBytes":75374,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1466,"convertSpendMs":65,"createdTime":"2020-08-25 08:02:54","host":"us-001*","referer":"https://blog.rstudio.com/2020/06/30/future-proofing-your-data-science-team/","linkMd5ListStr":"0098c973d1500637b41dd2471b1edd18","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"329.2 KB","destSize":"73.6 KB","compressRate":"22.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/shiny-contest-cover.jpeg","sourceStatusCode":200,"destWidth":1600,"destHeight":900,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn98@2020_6/2020/08/25/00-02-55-213_82325f09f9cd48e3.webp","sourceBytes":882553,"destBytes":102392,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1363,"convertSpendMs":67,"createdTime":"2020-08-25 08:02:54","host":"us-037*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"861.9 KB","destSize":"100 KB","compressRate":"11.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/hexmake.png","sourceStatusCode":200,"destWidth":1000,"destHeight":558,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn82@2020_4/2020/08/25/00-02-55-276_3f2d142564297bfb.webp","sourceBytes":238789,"destBytes":36400,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1552,"convertSpendMs":75,"createdTime":"2020-08-25 08:02:54","host":"us-51*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"233.2 KB","destSize":"35.5 KB","compressRate":"15.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/data-wrangling3.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":840,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn49@2020_1/2020/08/25/00-02-55-361_4e53e82e92e739e4.webp","sourceBytes":247297,"destBytes":115958,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1597,"convertSpendMs":227,"createdTime":"2020-08-25 08:02:54","host":"us-009*","referer":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/","linkMd5ListStr":"9d7aa41ca9b5da46260765dbe8b6f72d","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"241.5 KB","destSize":"113.2 KB","compressRate":"46.9%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-spark-backend-foreach-package.png","sourceStatusCode":200,"destWidth":2880,"destHeight":1574,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn73@2020_4/2020/08/25/00-02-55-186_b453efcca0d4472f.webp","sourceBytes":105799,"destBytes":146500,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1613,"convertSpendMs":157,"createdTime":"2020-08-25 08:02:54","host":"us-001*","referer":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/","linkMd5ListStr":"f18dd3380e238f6c89cf75f4ef0cb37f","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"103.3 KB","destSize":"143.1 KB","compressRate":"138.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/28/practical-interoperability/catchment.png","sourceStatusCode":200,"destWidth":680,"destHeight":383,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn14@2020_3/2020/08/25/00-02-55-152_b0cf55bcddf74988.webp","sourceBytes":46595,"destBytes":13270,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1763,"convertSpendMs":12,"createdTime":"2020-08-25 08:02:54","host":"europe63*","referer":"https://blog.rstudio.com/2020/07/28/practical-interoperability/","linkMd5ListStr":"0666e48ece98e7a7a00af8a4b6e33c0a","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"45.5 KB","destSize":"13 KB","compressRate":"28.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/topic-model-results.png","sourceStatusCode":200,"destWidth":1000,"destHeight":522,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn17@2020_1/2020/08/25/00-02-55-199_fe59a32158f3b243.webp","sourceBytes":279105,"destBytes":52000,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1790,"convertSpendMs":28,"createdTime":"2020-08-25 08:02:54","host":"europe-22*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"272.6 KB","destSize":"50.8 KB","compressRate":"18.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/venn-diagrams.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":642,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn31@2020_1/2020/08/25/00-02-55-351_b77b35090995aa12.webp","sourceBytes":389831,"destBytes":65132,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1641,"convertSpendMs":78,"createdTime":"2020-08-25 08:02:54","host":"us-013*","referer":"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/","linkMd5ListStr":"bc1651d11bf689931989cd41e5de328c","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"380.7 KB","destSize":"63.6 KB","compressRate":"16.7%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/large_image.jpg","sourceStatusCode":200,"destWidth":2444,"destHeight":1466,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn6@2020_1/2020/08/25/00-02-55-231_3197a9913edd6c5e.webp","sourceBytes":421945,"destBytes":356874,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1736,"convertSpendMs":243,"createdTime":"2020-08-25 08:02:54","host":"us-033*","referer":"https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics/","linkMd5ListStr":"35f3492cce655552471f3c06678747a3","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"412.1 KB","destSize":"348.5 KB","compressRate":"84.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/profvis.jpg","sourceStatusCode":200,"destWidth":1456,"destHeight":549,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn57@2020_5/2020/08/25/00-02-55-124_1e01418265c26d41.webp","sourceBytes":131651,"destBytes":43136,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1914,"convertSpendMs":25,"createdTime":"2020-08-25 08:02:54","host":"europe-59*","referer":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/","linkMd5ListStr":"3e8ea12a54ace5c7aa2029a4096a28c0","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"128.6 KB","destSize":"42.1 KB","compressRate":"32.8%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/covid-19-map.jpg","sourceStatusCode":200,"destWidth":2400,"destHeight":1260,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn79@2020_6/2020/08/25/00-02-55-395_6ee29567f62ba0e3.webp","sourceBytes":357640,"destBytes":191276,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1790,"convertSpendMs":158,"createdTime":"2020-08-25 08:02:54","host":"us-021*","referer":"https://blog.rstudio.com/2020/04/17/rstudio-and-covid-19/","linkMd5ListStr":"094b8d65098dc7eb1d45365ae5abcd8a","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"349.3 KB","destSize":"186.8 KB","compressRate":"53.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig1.jpg","sourceStatusCode":200,"destWidth":1503,"destHeight":426,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn53@2020_4/2020/08/25/00-02-55-555_7cdd72c317980c75.webp","sourceBytes":85501,"destBytes":32806,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2129,"convertSpendMs":32,"createdTime":"2020-08-25 08:02:54","host":"europe-22*","referer":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/","linkMd5ListStr":"9d7aa41ca9b5da46260765dbe8b6f72d","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"83.5 KB","destSize":"32 KB","compressRate":"38.4%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/cj68m8on14/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn46@2020_3/2020/08/25/00-02-55-935_6c3b66372fbb2817.webp","sourceBytes":3224,"destBytes":1176,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":922,"convertSpendMs":5,"createdTime":"2020-08-25 08:02:55","host":"us-51*","referer":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/","linkMd5ListStr":"f9ccab012024ff50b664df1abebdd28b","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.1 KB","destSize":"1.1 KB","compressRate":"36.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/appsilon-logo.png","sourceStatusCode":200,"destWidth":512,"destHeight":213,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn53@2020_2/2020/08/25/00-02-55-995_18820f668146d434.webp","sourceBytes":19906,"destBytes":14676,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":968,"convertSpendMs":35,"createdTime":"2020-08-25 08:02:55","host":"us-017*","referer":"https://blog.rstudio.com/2020/07/21/4-tips-to-make-your-shiny-dashboard-faster/","linkMd5ListStr":"3e8ea12a54ace5c7aa2029a4096a28c0","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"19.4 KB","destSize":"14.3 KB","compressRate":"73.7%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/corona-shiny.png","sourceStatusCode":200,"destWidth":1000,"destHeight":1000,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn93@2020_4/2020/08/25/00-02-55-368_e076b754aa96d57c.webp","sourceBytes":607762,"destBytes":120818,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2330,"convertSpendMs":61,"createdTime":"2020-08-25 08:02:54","host":"europe-59*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"593.5 KB","destSize":"118 KB","compressRate":"19.9%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/post/2020-07-13-winners-of-the-2nd-shiny-contest/index_files/figure-html/categories-keywords-1.png","sourceStatusCode":200,"destWidth":1344,"destHeight":960,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn38@2020_4/2020/08/25/00-02-56-096_66c5be3852c759e1.webp","sourceBytes":109845,"destBytes":44664,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1229,"convertSpendMs":53,"createdTime":"2020-08-25 08:02:55","host":"us-001*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"107.3 KB","destSize":"43.6 KB","compressRate":"40.7%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/58qjn34mxy/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn1@2020_5/2020/08/25/00-02-56-298_dc60adf5b1a22645.webp","sourceBytes":4240,"destBytes":1844,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":805,"convertSpendMs":3,"createdTime":"2020-08-25 08:02:56","host":"us-001*","referer":"https://blog.rstudio.com/2020/04/28/avoid-irrelevancy-and-fire-drills-in-data-science-teams/","linkMd5ListStr":"eb57041877eac365a90956f292f97507,4dfec6eb54e233255a7266afed644fc2","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4.1 KB","destSize":"1.8 KB","compressRate":"43.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/unruly-data-fig3.jpg","sourceStatusCode":200,"destWidth":1189,"destHeight":817,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn57@2020_3/2020/08/25/00-02-56-320_52ea7390edb8d843.webp","sourceBytes":107996,"destBytes":29606,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1216,"convertSpendMs":96,"createdTime":"2020-08-25 08:02:55","host":"us-005*","referer":"https://blog.rstudio.com/2020/05/05/wrangling-unruly-data/","linkMd5ListStr":"9d7aa41ca9b5da46260765dbe8b6f72d","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"105.5 KB","destSize":"28.9 KB","compressRate":"27.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/winding-path-hero.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":1066,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn98@2020_3/2020/08/25/00-02-55-417_38d0c594821393ac.webp","sourceBytes":599743,"destBytes":196472,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2558,"convertSpendMs":78,"createdTime":"2020-08-25 08:02:54","host":"europe67*","referer":"https://blog.rstudio.com/2020/06/09/is-your-data-science-team-agile/","linkMd5ListStr":"a8bdb1435a05dc69a07c3ca00ca739a6","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"585.7 KB","destSize":"191.9 KB","compressRate":"32.8%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/cac6g1r9gr/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn13@2020_1/2020/08/25/00-02-56-393_d9c6a2d09bdde1b2.webp","sourceBytes":2900,"destBytes":1098,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":874,"convertSpendMs":3,"createdTime":"2020-08-25 08:02:56","host":"us-029*","referer":"https://blog.rstudio.com/2020/05/12/equipping-wfh-data-science-teams/","linkMd5ListStr":"f1482487bf469c1b8522c883a0ea2cde","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.8 KB","destSize":"1.1 KB","compressRate":"37.9%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/black-box.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":900,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn21@2020_1/2020/08/25/00-02-56-218_a8087ff98a9810bd.webp","sourceBytes":435891,"destBytes":82884,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1550,"convertSpendMs":54,"createdTime":"2020-08-25 08:02:55","host":"us-029*","referer":"https://blog.rstudio.com/2020/06/02/is-your-data-science-credible-enough/","linkMd5ListStr":"eb57041877eac365a90956f292f97507","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"425.7 KB","destSize":"80.9 KB","compressRate":"19%"},{"code":1,"isDone":false,"source":"https://fast.wistia.com/embed/medias/jyk6q0svdy/swatch","sourceStatusCode":200,"destWidth":100,"destHeight":56,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn6@2020_1/2020/08/25/00-02-56-279_2d10e83e90e54d15.webp","sourceBytes":3027,"destBytes":1166,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1207,"convertSpendMs":2,"createdTime":"2020-08-25 08:02:56","host":"europe63*","referer":"https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/","linkMd5ListStr":"097471c73b959a4994817ed8b3269efe","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3 KB","destSize":"1.1 KB","compressRate":"38.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/one-source-indy.png","sourceStatusCode":200,"destWidth":700,"destHeight":700,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn94@2020_3/2020/08/25/00-02-56-361_fb4e572a5bd1da32.webp","sourceBytes":406693,"destBytes":24668,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1124,"convertSpendMs":32,"createdTime":"2020-08-25 08:02:56","host":"us-025*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"397.2 KB","destSize":"24.1 KB","compressRate":"6.1%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/28/practical-interoperability/mofa.png","sourceStatusCode":200,"destWidth":2754,"destHeight":860,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn50@2020_3/2020/08/25/00-02-56-186_16d7770ecf581f0b.webp","sourceBytes":490864,"destBytes":223054,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1477,"convertSpendMs":96,"createdTime":"2020-08-25 08:02:55","host":"us-029*","referer":"https://blog.rstudio.com/2020/07/28/practical-interoperability/","linkMd5ListStr":"0666e48ece98e7a7a00af8a4b6e33c0a","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"479.4 KB","destSize":"217.8 KB","compressRate":"45.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/freedom-of-press.png","sourceStatusCode":200,"destWidth":1200,"destHeight":1200,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn34@2020_6/2020/08/25/00-02-55-839_d598b9c703941f52.webp","sourceBytes":2238156,"destBytes":108050,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2741,"convertSpendMs":113,"createdTime":"2020-08-25 08:02:54","host":"europe67*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.1 MB","destSize":"105.5 KB","compressRate":"4.8%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/git-discoverer.png","sourceStatusCode":200,"destWidth":2382,"destHeight":1406,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn17@2020_1/2020/08/25/00-02-56-247_d6264fbdb312b962.webp","sourceBytes":2116133,"destBytes":173996,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2616,"convertSpendMs":265,"createdTime":"2020-08-25 08:02:54","host":"us-51*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2 MB","destSize":"169.9 KB","compressRate":"8.2%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/covid-storyboard.png","sourceStatusCode":200,"destWidth":1150,"destHeight":1150,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn18@2020_5/2020/08/25/00-02-56-594_3a418da846fb5c7f.webp","sourceBytes":74257,"destBytes":21640,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1053,"convertSpendMs":80,"createdTime":"2020-08-25 08:02:56","host":"us-017*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"72.5 KB","destSize":"21.1 KB","compressRate":"29.1%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/28/practical-interoperability/simulation.jpg","sourceStatusCode":200,"destWidth":1544,"destHeight":975,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn9@2020_6/2020/08/25/00-02-56-534_22c21e11bd4d78aa.webp","sourceBytes":148746,"destBytes":48892,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1138,"convertSpendMs":68,"createdTime":"2020-08-25 08:02:56","host":"us-51*","referer":"https://blog.rstudio.com/2020/07/28/practical-interoperability/","linkMd5ListStr":"0666e48ece98e7a7a00af8a4b6e33c0a","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"145.3 KB","destSize":"47.7 KB","compressRate":"32.9%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/public-package-manager.png","sourceStatusCode":200,"destWidth":1295,"destHeight":745,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn22@2020_2/2020/08/25/00-02-56-663_2c0520f72a8ebd3c.webp","sourceBytes":109308,"destBytes":37628,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1040,"convertSpendMs":78,"createdTime":"2020-08-25 08:02:56","host":"us-005*","referer":"https://blog.rstudio.com/2020/07/01/announcing-public-package-manager/","linkMd5ListStr":"656dbda9dcda41c02614146b77177646","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"106.7 KB","destSize":"36.7 KB","compressRate":"34.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/process2.jpg","sourceStatusCode":200,"destWidth":2398,"destHeight":892,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn78@2020_4/2020/08/25/00-02-56-672_fc449398b040cae0.webp","sourceBytes":298855,"destBytes":56226,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1485,"convertSpendMs":217,"createdTime":"2020-08-25 08:02:56","host":"us-009*","referer":"https://blog.rstudio.com/2020/04/22/getting-to-the-right-question/","linkMd5ListStr":"5c74c2ad7961b0ea8491162615e3eca1","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"291.9 KB","destSize":"54.9 KB","compressRate":"18.8%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/07/interoperability-july/icecream-hero.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":900,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn69@2020_1/2020/08/25/00-02-56-608_a5cc6ee1dd550da8.webp","sourceBytes":631411,"destBytes":166654,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1656,"convertSpendMs":87,"createdTime":"2020-08-25 08:02:55","host":"us-033*","referer":"https://blog.rstudio.com/2020/07/07/interoperability-july/","linkMd5ListStr":"7975ce8fad1a1bda09ef932ac7fca674","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"616.6 KB","destSize":"162.7 KB","compressRate":"26.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/07/interoperability-july/tiobe-july.jpg","sourceStatusCode":200,"destWidth":956,"destHeight":586,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn85@2020_1/2020/08/25/00-02-56-459_51705e91675527bb.webp","sourceBytes":73321,"destBytes":21710,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1595,"convertSpendMs":17,"createdTime":"2020-08-25 08:02:56","host":"europe-59*","referer":"https://blog.rstudio.com/2020/07/07/interoperability-july/","linkMd5ListStr":"7975ce8fad1a1bda09ef932ac7fca674","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"71.6 KB","destSize":"21.2 KB","compressRate":"29.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/rstudio-1-3-screenshot.png","sourceStatusCode":200,"destWidth":2334,"destHeight":1736,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn89@2020_6/2020/08/25/00-02-55-857_b14a64c7a26e73e0.webp","sourceBytes":1008693,"destBytes":358872,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":3015,"convertSpendMs":455,"createdTime":"2020-08-25 08:02:54","host":"europe-22*","referer":"https://blog.rstudio.com/2020/05/27/rstudio-1-3-release/","linkMd5ListStr":"68af3705d621c6d14c73a2f713059404","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"985.1 KB","destSize":"350.5 KB","compressRate":"35.6%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/survey-chart.jpg","sourceStatusCode":200,"destWidth":2332,"destHeight":1162,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn97@2020_6/2020/08/25/00-02-56-696_4c7fc95916f98ad2.webp","sourceBytes":231872,"destBytes":89260,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":1468,"convertSpendMs":140,"createdTime":"2020-08-25 08:02:56","host":"us-013*","referer":"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/","linkMd5ListStr":"e9a77b8e3c91680d61827afaca8792d5","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"226.4 KB","destSize":"87.2 KB","compressRate":"38.5%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/big-rock-hero.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":1067,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn22@2020_1/2020/08/25/00-02-56-214_5235689438b024bf.webp","sourceBytes":571200,"destBytes":183182,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":3200,"convertSpendMs":61,"createdTime":"2020-08-25 08:02:54","host":"europe-59*","referer":"https://blog.rstudio.com/2020/06/24/delivering-durable-value/","linkMd5ListStr":"f9ccab012024ff50b664df1abebdd28b","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"557.8 KB","destSize":"178.9 KB","compressRate":"32.1%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/images/shiny-decisions.png","sourceStatusCode":200,"destWidth":866,"destHeight":430,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn77@2020_6/2020/08/25/00-02-56-434_328db6a1c43b141e.webp","sourceBytes":671545,"destBytes":76336,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":3204,"convertSpendMs":39,"createdTime":"2020-08-25 08:02:54","host":"europe63*","referer":"https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/","linkMd5ListStr":"cefa78e587ea4cfbbea36d66e957ca02","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"655.8 KB","destSize":"74.5 KB","compressRate":"11.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/qubole-launch.png","sourceStatusCode":200,"destWidth":1300,"destHeight":860,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn61@2020_6/2020/08/25/00-02-56-900_dbba7a472a3f08d4.webp","sourceBytes":230384,"destBytes":36760,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2350,"convertSpendMs":51,"createdTime":"2020-08-25 08:02:55","host":"europe67*","referer":"https://blog.rstudio.com/2020/08/03/rstudio-adds-new-r-features-in-qubole-s-open-data-lake/","linkMd5ListStr":"a2422cfc63a580fd2de167683c5c0b45","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"225 KB","destSize":"35.9 KB","compressRate":"16%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/existential.jpg","sourceStatusCode":200,"destWidth":1600,"destHeight":840,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn42@2020_3/2020/08/25/00-02-56-542_d124b48268641e1c.webp","sourceBytes":207595,"destBytes":115742,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2524,"convertSpendMs":54,"createdTime":"2020-08-25 08:02:55","host":"europe63*","referer":"https://blog.rstudio.com/2020/05/27/role-of-the-data-scientist/","linkMd5ListStr":"bc1651d11bf689931989cd41e5de328c","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"202.7 KB","destSize":"113 KB","compressRate":"55.8%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/tutorial-screen.jpg","sourceStatusCode":200,"destWidth":1404,"destHeight":1122,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn82@2020_2/2020/08/25/00-02-56-936_5ebb8261b9bb99c8.webp","sourceBytes":237974,"destBytes":108062,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2377,"convertSpendMs":45,"createdTime":"2020-08-25 08:02:55","host":"europe-22*","referer":"https://blog.rstudio.com/2020/08/05/rstudio-cloud-announcement/","linkMd5ListStr":"d1d11e70c6eb49eb96fd02351cc04c5e","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"232.4 KB","destSize":"105.5 KB","compressRate":"45.4%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/images/2020-05-06-sparklyr-1-2-spark-databricks-connect-rstudio.png","sourceStatusCode":200,"destWidth":3584,"destHeight":2092,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn74@2020_5/2020/08/25/00-02-57-376_ff54fab90e75d489.webp","sourceBytes":227863,"destBytes":321180,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":2481,"convertSpendMs":985,"createdTime":"2020-08-25 08:02:55","host":"us-021*","referer":"https://blog.rstudio.com/2020/05/06/sparklyr-1-2/","linkMd5ListStr":"f18dd3380e238f6c89cf75f4ef0cb37f","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"222.5 KB","destSize":"313.7 KB","compressRate":"141%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/tunnel-hero.jpg","sourceStatusCode":200,"destWidth":5184,"destHeight":3456,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn89@2020_3/2020/08/25/00-02-57-848_be5f368920445635.webp","sourceBytes":1802467,"destBytes":2596166,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":3273,"convertSpendMs":1396,"createdTime":"2020-08-25 08:02:56","host":"us-037*","referer":"https://blog.rstudio.com/2020/07/09/why-you-need-a-world-class-ide-to-do-serious-data-science/","linkMd5ListStr":"e9a77b8e3c91680d61827afaca8792d5","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.7 MB","destSize":"2.5 MB","compressRate":"144%"},{"code":1,"isDone":false,"source":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/dash-jumpstart-example.gif","sourceStatusCode":200,"destWidth":1275,"destHeight":703,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn65@2020_5/2020/08/25/00-03-07-245_90510822eb4abf74.webp","sourceBytes":2445641,"destBytes":1180772,"targetWebpQuality":75,"feedId":8609,"totalSpendMs":11849,"convertSpendMs":10007,"createdTime":"2020-08-25 08:02:56","host":"us-55*","referer":"https://blog.rstudio.com/2020/07/14/rstudio-connect-1-8-4/","linkMd5ListStr":"f8e6210e6198c2f20cd474e74430d85b","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.3 MB","destSize":"1.1 MB","compressRate":"48.3%"}],"successGithubMap":{"myreaderx8":2,"myreaderx14":2,"myreaderx15":3,"myreaderx7":2,"myreaderx6":2,"myreaderx16":2,"myreaderx32":3,"myreaderx4":2,"myreaderx10":2,"myreaderx3":2,"myreaderx33":3,"myreaderx11":2,"myreaderx2":3,"myreaderx12":2,"myreaderx1":3,"myreaderx13":2,"myreaderx30":2,"myreaderx31":2,"myreaderx18":2,"myreaderx19":2,"myreaderx":2,"myreaderx25":2,"myreaderx27":2,"myreaderx21":3,"myreaderx22":3,"myreaderx23":3,"myreaderx24":2,"myreaderx5oss":3,"myreaderx29":3},"failGithubMap":{}}