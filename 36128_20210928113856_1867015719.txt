{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2021-09-28 19:37:45","updatedTime":"2021-09-28 19:37:45","title":"深層学習はガウス過程","link":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","description":"<p>おつかれさまです． 僕はあまり深層学習に関して記事を書くことはないのですが，ちょっと気になった論文があったので紹介します．</p> \n<p><a href=\"https://arxiv.org/abs/1711.00165\">[1711.00165] Deep Neural Networks as Gaussian Processes</a></p> \n<p>論文は<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/Google\">Google</a> Brainの研究者らによるもので，<s>NIPS2017 Bayesian <a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/Deep%20Learning\">Deep Learning</a> Workshop</s>ICLR2018にacceptされています．実は深層学習を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程（Gaussian process）で構築するのはこの論文が初出ではないのですが，論文では<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>学習，深層学習，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%CB%A1\">カーネル法</a>を簡略かつ包括的に説明している内容になっているので非常に参考になります．</p> \n<p>さて，「深層学習は<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程」というのはちょっぴり宣伝的なタイトルにし過ぎてしまったのですが，もう少しだけ正確に論文の要点をまとめると次のようになります．</p> \n<ul> \n <li>背景 \n  <ul> \n   <li>単一の隠れ層でユニット数が無限の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>が<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程で表現できることはよく知られている．[Neal, 1994]</li> \n   <li>多層の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>に対応する<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>関数（<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の共分散関数に対応）も近年導出された．[Cho &amp; Saul, 2009]</li> \n  </ul> </li> \n <li>やったこと \n  <ul> \n   <li>深層学習に対する<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>関数（kernel function）を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の共分散関数（covariance function）として使用し，<b>深層学習モデルの完全な<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>推論を１度の行列計算で行えるようにした</b>．</li> \n   <li>効率よく共分散関数を計算できるパイプラインを開発した．</li> \n   <li>実験では<b><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>推論による予測の不確かさがテストデータに対する予測誤差に相関している</b>ことが確認された．</li> \n  </ul> </li> \n</ul> \n<p>今回の記事では，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の基礎から論文の内容までをざっくり説明したいと思います．</p> \n<h1><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>線形回帰から<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程まで</h1> \n<p>簡単に言うと，ここから紹介する<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程とはノン<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D1%A5%E9%A5%E1%A5%C8%A5%EA%A5%C3%A5%AF\">パラメトリック</a>な回帰モデルです． まず始めに<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>線形回帰から始めて<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の成り立ちを説明しようと思います． 線形回帰モデルでは，実数の出力値<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7By_n%7D\" alt=\"{y_n}\" />は，入力値<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bx_n%7D\" alt=\"{x_n}\" />，<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BD%7D\" alt=\"{D}\" />次元への特徴量変換を行う関数<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%28%29%7D\" alt=\"{\\phi()}\" />，パラメータ<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bw%7D\" alt=\"{w}\" />を使って次のように生成されると仮定します． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122750.png\" alt=\"f:id:sammy-suyama:20180113122750p:plain\" title=\"f:id:sammy-suyama:20180113122750p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> ここでλは観測に対する固定の精度パラメータです． また，パラメータ<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bw%7D\" alt=\"{w}\" />に仮定する事前分布として次のような<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>を置きます． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122833.png\" alt=\"f:id:sammy-suyama:20180113122833p:plain\" title=\"f:id:sammy-suyama:20180113122833p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> ここで<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%CE%9B%7D\" alt=\"{Λ}\" />は<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BD%7D\" alt=\"{D}\" />x<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BD%7D\" alt=\"{D}\" />の精度行列です． 学習用に<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BN%7D\" alt=\"{N}\" />組の入出力データ<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BX%2CY%7D\" alt=\"{X,Y}\" />が与えられたとき，新規のテスト入力<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bx%7D\" alt=\"{x}\" />*に対する出力<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7By%7D\" alt=\"{y}\" />*の予測分布は，次のようにパラメータ<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bw%7D\" alt=\"{w}\" />を事後分布で周辺化することによって得ることができます． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122900.png\" alt=\"f:id:sammy-suyama:20180113122900p:plain\" title=\"f:id:sammy-suyama:20180113122900p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> ただし，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>の平均と精度は次のようになります． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122934.png\" alt=\"f:id:sammy-suyama:20180113122934p:plain\" title=\"f:id:sammy-suyama:20180113122934p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> 詳細な計算方法に関しては<a href=\"http://www.kspub.co.jp/book/detail/1538320.html\">拙著</a>にまったく同じものが載っているのでよかったらご参考ください．</p> \n<p>さて，式（4）の予測平均と予測分散を次のように書き直してみます． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123003.png\" alt=\"f:id:sammy-suyama:20180113123003p:plain\" title=\"f:id:sammy-suyama:20180113123003p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> ただし， <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123018.png\" alt=\"f:id:sammy-suyama:20180113123018p:plain\" title=\"f:id:sammy-suyama:20180113123018p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> と置きました．また，大文字の<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5CPhi%7D\" alt=\"{\\Phi}\" />は<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BD%7D\" alt=\"{D}\" />x<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BN%7D\" alt=\"{N}\" />の行列であり，各<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%28d%2Cn%29%7D\" alt=\"{(d,n)}\" />成分が<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bphi%28x_n%29%7D\" alt=\"{phi(x_n)}\" />の<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bd%7D\" alt=\"{d}\" />次元目の値を表しています． ここでは行列のinverse lammaを使って式変形を行っています<sup id=\"fnref:1\"><a href=\"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fn:1\" rel=\"footnote\">1</a></sup>． 式（5）および式（6）の結果を見てみると，特徴量関数<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />は常に <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123120.png\" alt=\"f:id:sammy-suyama:20180113123120p:plain\" title=\"f:id:sammy-suyama:20180113123120p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> のような形に集約されていることがわかります．<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bk%28x%2Cx%27%29%7D\" alt=\"{k(x,x')}\" />を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>関数または共分散関数と呼びます．これはつまり，特徴量抽出を行う関数<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />を設計するのではなく，<b>共分散関数</b><img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bk%28x%2Cx%27%29%7D\" alt=\"{k(x,x')}\" /><b>を直接設計することによっても回帰が行える</b>ことを示しています．共分散関数は２つの入力点に関する相関を定義するものであるため，ある意味異なるデータ間の類似度のようなものを設計しているとも言えます．また当然ですが，共分散行列は<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>の共分散なので正定値である必要があります．</p> \n<h1>共分散関数の選択</h1> \n<p>さて，具体的な共分散関数にはどのようなものがあるのでしょうか．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程で最もよく使われている共分散関数の１つに，次のような指数２次<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>（exponentiated quadratic kernel）と呼ばれるものがあります（RBF kernel, squared exponential kernel, gaussian kernelなどと呼ばれることもあります）． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123054.png\" alt=\"f:id:sammy-suyama:20180113123054p:plain\" title=\"f:id:sammy-suyama:20180113123054p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> <img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Calpha%7D\" alt=\"{\\alpha}\" />，<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cbeta%7D\" alt=\"{\\beta}\" />はこの共分散関数のパラメータです．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>と同じ関数の形をしていますが，これはただ単にたまたまであり，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>のように正規化されている必要はありません．ちなみにこの共分散関数に対応する特徴量<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />というのも実は存在しており，無限次元の特徴量抽出になります<sup id=\"fnref:2\"><a href=\"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fn:2\" rel=\"footnote\">2</a></sup>．</p> \n<p>さて，式（8）で表される共分散関数以外にも多くのものが提案されています．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>に関連するものであれば，次のような<b>無限ユニット数を持つERFやReLUといった<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1\">非線形</a>関数に対応した共分散関数が存在します</b>． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123146.png\" alt=\"f:id:sammy-suyama:20180113123146p:plain\" title=\"f:id:sammy-suyama:20180113123146p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> また，複数の共分散関数を足したり掛けたりして組み合わせることによって新しい共分散関数を構築することも可能です<sup id=\"fnref:3\"><a href=\"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fn:3\" rel=\"footnote\">3</a></sup>．</p> \n<p>いくつかの（解析的に計算できる）共分散関数に対して，単純な一次元の回帰を行ってみたのが次のアニメーションです．上段はそれぞれの事前分布からサンプルされた関数の例で，下段は順次データ点を与えていった場合の予測分布の推移を示しています． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123653.gif\" alt=\"f:id:sammy-suyama:20180113123653g:plain\" title=\"f:id:sammy-suyama:20180113123653g:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> 左から順に，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C2%BF%B9%E0%BC%B0\">多項式</a>関数（３次関数），RBF<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>（ERF），<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>（ReLU），ディープ<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>（ReLU）です．最後のディープに対する共分散関数の構成方法に関しては次の節で解説します．</p> \n<p>また，この結果を生成するコードは下記<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/Github\">Github</a>に置きました．<b>コアな部分は20行程度です</b>． <a href=\"https://github.com/sammy-suyama/MLBlog/blob/master/src/demo_GPDNN.jl\">https://github.com/sammy-suyama/MLBlog/blob/master/src/demo_GPDNN.jl</a></p> \n<h1><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程としての深層学習</h1> \n<p>さて，ここからは本題である深層学習モデルの共分散関数の導出に関して見ていきましょう． まず，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1\">非線形</a>変換が１層だけの<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF\">ニューラルネットワーク</a>の回帰モデルを考えてみます． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123359.png\" alt=\"f:id:sammy-suyama:20180113123359p:plain\" title=\"f:id:sammy-suyama:20180113123359p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> <img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bx_k%7D\" alt=\"{x_k}\" />は<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bk%7D\" alt=\"{k}\" />次元目の入力データの値で，<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bz_i%7D\" alt=\"{z_i}\" />は<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bi%7D\" alt=\"{i}\" />番目の出力です．<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BW%7D\" alt=\"{W}\" />や<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bb%7D\" alt=\"{b}\" />はネットワークのパラメータであり，各要素が次のような１次元の独立な<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>に従って生成されていると仮定します． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123425.png\" alt=\"f:id:sammy-suyama:20180113123425p:plain\" title=\"f:id:sammy-suyama:20180113123425p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> 各パラメータが独立なので，異なる<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BN%7D\" alt=\"{N}\" />個の<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />も独立に値が決定されることになります． ここで，隠れユニットの数<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BN%7D\" alt=\"{N}\" />を無限にしたらどうなるでしょうか．ここでは<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />はもはや何の確率分布に従っているかは不明ですが，各<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />は独立であることがわかっているので，<b>無限に足し合わせれば<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C3%E6%BF%B4%B6%CB%B8%C2%C4%EA%CD%FD\">中心極限定理</a>により<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>に近づいていくことになります</b>．最後に足される<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%7Bb_i%7D%5E1%7D\" alt=\"{{b_i}^1}\" />も<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>に従うので，結果として出力<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bz%7D\" alt=\"{z}\" />も<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9%CA%AC%C9%DB\">ガウス分布</a>に従うことになります． したがって，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1\">非線形</a>関数に関する共分散を期待値を使って書けば，<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bz%7D\" alt=\"{z}\" />は次のような共分散関数を持つ<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程として表せます． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123515.png\" alt=\"f:id:sammy-suyama:20180113123515p:plain\" title=\"f:id:sammy-suyama:20180113123515p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> <b>この議論は一般的なL層のモデルに拡張しても成り立ちます</b>．ある<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bl%7D\" alt=\"{l}\" /><img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B-%7D\" alt=\"{-}\" /><img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B1%7D\" alt=\"{1}\" />層目の出力が<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程に従うならば，次の<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bl%7D\" alt=\"{l}\" />層目の共分散も<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程に従うので同様にして共分散関数を計算できるわけです．この関係性を書いてみると， <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123550.png\" alt=\"f:id:sammy-suyama:20180113123550p:plain\" title=\"f:id:sammy-suyama:20180113123550p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> となります．<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7BF%7D\" alt=\"{F}\" />は<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7Bl%7D\" alt=\"{l}\" />層目の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1\">非線形</a>変換<img src=\"https://chart.apis.google.com/chart?cht=tx&amp;chl=%7B%5Cphi%7D\" alt=\"{\\phi}\" />から決定的に求められます． 具体的にReLUを<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1\">非線形</a>関数として選んだ場合の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%BA%C6%B5%A2\">再帰</a>式は次のようになります． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123614.png\" alt=\"f:id:sammy-suyama:20180113123614p:plain\" title=\"f:id:sammy-suyama:20180113123614p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> この<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>を計算し，あとは一般的な<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の予測の式（5）に入れて計算すれば，基本的には行列演算のみで深層学習の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>予測ができることになります．</p> \n<p>下記の図は論文で示されている実験結果の１つです． <span itemscope=\"\" itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123813.png\" alt=\"f:id:sammy-suyama:20180113123813p:plain\" title=\"f:id:sammy-suyama:20180113123813p:plain\" class=\"hatena-fotolife\" itemprop=\"image\" /></span> 横軸は予測分布が出力した分散で，縦軸はテストデータにおける二乗誤差です．図からわかるように，予測分散が大きくなるにつれて，テスト誤差も大きくなっていく傾向が見て取れます．すなわち，<b>「予測に自信がない（＝分散が大きい）場合は，実際に予測の間違えも大きくなっている」</b>ということになります． これは<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>学習を深層学習に用いた場合のもっとも重要な利点です．残念ながら現在の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC\">機械学習</a>の評価方法は専ら予測誤差を使って精度評価のみを行うという慣習がついてしまっており，不確かさを表現できることの重要性が軽視されがちです．しかし，このような予測の不確かさの<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C4%EA%CE%CC\">定量</a>化は，少ないデータで効率良く学習したり，「過剰な自信」による誤判断を未然に防いだりすることができます．これが（深層学習に限らず）<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC\">機械学習</a>モデルを<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>化することが，自動運転などのアプリケーションに重要であると考えられている所以です．また，環境を学習しながら報酬を最大化していくような<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC\">強化学習</a>などの枠組みでは，このような不確かさの<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C4%EA%CE%CC\">定量</a>化が効率的な探索を行う（explorationとexploitationの<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C8%A5%EC%A1%BC%A5%C9%A5%AA%A5%D5\">トレードオフ</a>を取る）ために不可欠になってきます．</p> \n<p>論文には他にも計算効率の良い共分散の構成方法や，超パラメータに関する<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C1%EA%C5%BE%B0%DC\">相転移</a>の解析などが含まれており，そちらも大変興味深いです．今回の記事では<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程と深層学習の関係性に注目したかったので割愛します．</p> \n<h1>所感と今後</h1> \n<h4><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程で解釈することの利点</h4> \n<p>深層学習を共分散関数の中で表現し，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程として解釈する有用性はざっくり挙げるとすれば次のようにまとめられるでしょう．</p> \n<ol> \n <li><b>原理的に<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC\">過学習</a>をしない </b></li> \n <li><b>予測の不確実性を出力できる</b></li> \n <li><b>共分散関数を自動的に最適化・選択できる</b></li> \n</ol> \n<p>１と２は<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>推論から来る当然の特性です．3に関しては，<b>深層学習におけるネットワークの構造や<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1\">非線形</a>変換の自動学習を行っていることに対応する</b>でしょう．現在は<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程を使って既存の深層学習の超パラメータを調整する方法（<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>的最適化）が流行っていますが，皮肉にも<b>深層学習自体を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程にしてしまった方が手っ取り早い</b>ということになりますね．</p> \n<p>また，これらに付随して，モデルのデザイン性や解釈性に関しても今後は重要になるでしょう．Oxford大学教授で<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/DeepMind\">DeepMind</a>のリサーチャーであるTeh先生は，NIPS2017の講演で<b>「解釈のできないパラメータ空間ではなく，関数空間で考えよう」</b>と言っています．</p> \n<p><iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/9saauSBgmcQ?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe><cite class=\"hatena-citation\"><a href=\"https://www.youtube.com/watch?v=9saauSBgmcQ\">www.youtube.com</a></cite> このように，これからは深層学習を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%B8%A5%A2%A5%F3\">ベイジアン</a>ノンパラメトリクスの文脈で組みなおす研究が増えてくるんじゃないかと思っています．</p> \n<h4><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程で解釈することの課題点</h4> \n<p>ところで，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程にしてしまうことで課題点もあります． １つは，隠れユニットの数を無限にしてしまうと，<b>出力の各次元が統計的に独立になってしまう</b>ことです．これにより，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF\">ニューラルネットワーク</a>に特有の「中間層で特徴量を表現する」みたいなことが原理的にできなくなります．ただし，論文では無限の中間層を持つ<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程が伝統的な深層学習よりも実験的に良い結果を示しているので，この議論自体に意味があるかは疑問の残るところです．</p> \n<p>これに関連する課題として，実はこちらの方が重要なのですが，出力が独立になってししまったことにより，<b>多次元回帰や<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF\">マルチタスク</a>学習が原理的に行えない</b>ことが挙げられます．しかし，後述しますが，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の研究では出力の次元間に関して相関を導入できる方法がすでにいくつか存在しています．</p> \n<h4>関連研究メモ</h4> \n<p>さて，他にも個人的に気になる<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程や深層学習の関連研究を思いつくまま並べておきます．</p> \n<p><b>１．畳み込みモデル，時系列モデル</b></p> \n<p>最新の論文ですが，畳み込み<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>（convolutional neural network）のような構造を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程に取り込む研究があります．</p> \n<p><a href=\"https://arxiv.org/abs/1709.01894\">[1709.01894] Convolutional Gaussian Processes</a></p> \n<p>また，LSTM（Long short-term memory）の出力を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の入力に使うような話もあります．</p> \n<p><a href=\"https://arxiv.org/abs/1610.08936\">[1610.08936] Learning Scalable Deep Kernels with Recurrent Structure</a></p> \n<p><b>２．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>関数の最適化や自動選択</b></p> \n<p>興味深い事例として，与えられたデータに対して<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>関数（共分散関数）を自動探索し，解析結果を<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC\">自然言語</a>で説明するようなシステムが考案されています．</p> \n<p><a href=\"https://arxiv.org/pdf/1402.4304.pdf\">Automatic Construction and Natural-Language Description of Nonparametric Regression Models</a></p> \n<p><b>３．能動学習および<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC\">強化学習</a></b></p> \n<p><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>推論を使えば不確実性に基づいて環境を探索できるので，直接<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B6%AF%B2%BD%B3%D8%BD%AC\">強化学習</a>の問題に応用することができます．</p> \n<p><a href=\"https://pdfs.semanticscholar.org/053d/ec3537df88a1f68b53e33e1462a6b88066f6.pdf\">PILCO: A Model-Based and Data-Efficient Approach to Policy Search</a></p> \n<p><b>４．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%DE%A5%EB%A5%C1%A5%BF%A5%B9%A5%AF\">マルチタスク</a>学習</b></p> \n<p><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の出力ベクトルの次元間に相関を持たせる方法はいくつか提案されています．</p> \n<p><a href=\"http://proceedings.mlr.press/v9/alvarez10a/alvarez10a.pdf\">Efficient Multioutput Gaussian Processes through Variational Inducing Kernels</a></p> \n<p><b>５．潜在変数モデル</b></p> \n<p><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程にはGPLVM（Gaussian process latent variable models）と呼ばれる潜在変数モデル版も存在します．GPLVMに今回のようなdeepな<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB\">カーネル</a>を使えば，VAE（variational auto encoder）などとは別の深層生成モデルが作れることになりそうです．</p> \n<p><a href=\"http://proceedings.mlr.press/v9/titsias10a/titsias10a.pdf\">Bayesian Gaussian Process Latent Variable Model</a></p> \n<p>また，通常のGPLVMをスタックする（GPの出力を別のGPの<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C0%F8%BA%DF%C5%AA\">潜在的</a>な入力にする）ことによって，deepな<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程を構成することもできます．</p> \n<p><a href=\"http://proceedings.mlr.press/v31/damianou13a.pdf\">Deep Gaussian Processes</a></p> \n<p>このような構成方法であれば，低層で抽出された潜在構造を次の層へシェアすることができます． 論文では「１５０個のデータに対して5層が最適」のような推定もできており，小規模データでも<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC\">過学習</a>しない<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>の強みが理解できますね．</p> \n<p><b>６．スケーラビリティ</b></p> \n<p><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の最大の課題は大規模データに対するスケーラビリティです．まともに予測分布を計算しようとすると，データ数をNとしたときO(N<sup>3</sup>)の計算時間がかかってしまうため，普通にやると<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D3%A5%C3%A5%B0%A5%C7%A1%BC%A5%BF\">ビッグデータ</a>の時代には使い物になりません．幸いなことに，これまでに数多くの近似推論手法が開発されてきています．中でも有望なのが本ブログでも何度か紹介している変分推論法（variational inference）です．下記の論文で<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%CA%D1%CA%AC%CB%A1\">変分法</a>を用いて<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程をスケーラブルにするテクニックが網羅的に紹介されています．</p> \n<p><a href=\"http://mlg.eng.cam.ac.uk/matthews/thesis.pdf\">Scalable Gaussian Process Inference using Variational Methods</a></p> \n<p>今後も深層学習と近似<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>推論の両研究分野で技術的な輸出入が起こると思います．いろいろな手法の理論的な一致や拡張・一般化が見られると面白そうですね．</p> \n<p><b>７．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程以外を使う</b></p> \n<p>例えばStudentのt過程は，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程と同じような特性を持ち合わせていながら，外れ値に頑強であるという特徴を持つので，これをディープなモデルに対して使ってみても良いかもしれません．</p> \n<p><a href=\"http://proceedings.mlr.press/v33/shah14.html\">Student-t Processes as Alternatives to Gaussian Processes</a></p> \n<h1>基礎を知りたい方</h1> \n<p>最後になってしまって申し訳ないですが，今回の記事の内容を理解するために必要な基礎理論を解説した教科書・資料や，古典的な論文等を紹介しておきます．</p> \n<h4>Gaussian Process for Machine Learning</h4> \n<p><a href=\"http://www.gaussianprocess.org/gpml/\">http://www.gaussianprocess.org/gpml/</a></p> \n<p>Carl Edward Rasumussen先生による<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の教科書の決定版です． 2006年なのでちょっと古くなってきてしまいましたが，<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程による回帰・分類はもちろん，共分散関数の構成法，モデル選択，大量データに対する近似学習法まで網羅しています．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/SVM\">SVM</a>などの類似手法との関係性も解説しています．</p> \n<h4>Bayesian Learning for Neural Networks</h4> \n<p><a href=\"http://www.springer.com/jp/book/9780387947242\">http://www.springer.com/jp/book/9780387947242</a></p> \n<p>1996年に執筆されたRadford Neal先生の伝説的論文ですが，高い先見性と深い洞察に驚かされます．<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CF%A5%DF%A5%EB%A5%C8%A5%CB%A5%A2%A5%F3\">ハミルトニアン</a><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%E2%A5%F3%A5%C6%A5%AB%A5%EB%A5%ED\">モンテカルロ</a>による学習のほか，本記事で解説した<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>と<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の関係性もここで解説されています．事実，近年の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC\">機械学習</a>における<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程のブームはここから始まりました．また，無限に深くした場合の<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8\">ニューラルネット</a>の挙動に関しても考察があります．</p> \n<h4><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%AC%A5%A6%A5%B9\">ガウス</a>過程の基礎</h4> \n<p>日本語の解説スライドはこちらです．非常にわかりやすくまとめられています．</p> \n<p>松井先生：</p> \n<p><a href=\"http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture1-matsui.pdf\">http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture1-matsui.pdf</a></p> \n<p>持橋先生：</p> \n<p><a href=\"http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture2-daichi.pdf\">http://www.ism.ac.jp/~daichi/lectures/H26-GaussianProcess/gp-lecture2-daichi.pdf</a></p> \n<h4><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>深層学習の入門書</h4> \n<p><span style=\"color: #ff0000\">今回のような<a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>推論と深層学習の融合領域に関しては次の書籍が詳しいです．</span> <iframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fwww.kspub.co.jp%2Fbook%2Fdetail%2F5168707.html\" title=\"ベイズ深層学習\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"></iframe><cite class=\"hatena-citation\"><a href=\"https://www.kspub.co.jp/book/detail/5168707.html\">www.kspub.co.jp</a></cite></p> \n<h4><a class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA\">ベイズ</a>学習の基礎</h4> \n<p>拙著です．</p> \n<p><a href=\"http://www.kspub.co.jp/book/detail/1538320.html\">ベイズ推論による機械学習入門 機械学習スタートアップシリーズ | 書籍情報 | 株式会社 講談社サイエンティフィク</a><iframe src=\"https://hatenablog-parts.com/embed?url=http%3A%2F%2Fwww.kspub.co.jp%2Fbook%2Fdetail%2F1538320.html\" title=\"ベイズ推論による機械学習入門　機械学習スタートアップシリーズ\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"></iframe><cite class=\"hatena-citation\"><a href=\"http://www.kspub.co.jp/book/detail/1538320.html\">www.kspub.co.jp</a></cite></p> \n<div class=\"footnotes\"> \n <hr /> \n <ol> \n  <li id=\"fn:1\"> <p>参考：<a href=\"http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=3274\">The Matrix Cookbook</a><a href=\"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fnref:1\" rev=\"footnote\">↩</a></p></li> \n  <li id=\"fn:2\"> <p>参考：<a href=\"https://www.amazon.co.jp/パターン認識と機械学習-下-ベイズ理論による統計的予測-C-M-ビショップ/dp/4621061240\">https://www.amazon.co.jp/パターン認識と機械学習-下-ベイズ理論による統計的予測-C-M-ビショップ/dp/4621061240</a><a href=\"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fnref:2\" rev=\"footnote\">↩</a></p></li> \n  <li id=\"fn:3\"> <p>参考：<a href=\"http://www.cs.toronto.edu/~duvenaud/cookbook/index.html\">The Kernel Cookbook</a><a href=\"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fnref:3\" rev=\"footnote\">↩</a></p></li> \n </ol> \n</div>","descriptionType":"html","publishedDate":"Sat, 13 Jan 2018 05:26:12 +0000","feedId":36128,"bgimg":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113124037.png","linkMd5":"c55101577bc4a707084a4d649e2ec74d","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn6@2020_1/2021/09/28/11-37-47-424_1c959f9a19343084.webp","destWidth":798,"destHeight":692,"sourceBytes":147196,"destBytes":55812,"author":"sammy-suyama","enclosureType":"image/png","enclosureUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113124037.png","articleImgCdnMap":{"https://chart.apis.google.com/chart?cht=tx&chl=%7By_n%7D":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn99@2020_1/2021/09/28/11-37-45-841_1a9c57b5d21f5a00.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bx_n%7D":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn58@2020_6/2021/09/28/11-37-50-542_4a13e8bc811a5562.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7BD%7D":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn47@2020_5/2021/09/28/11-37-45-821_59a9f04bffdcc812.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Cphi%28%29%7D":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn25@2020_3/2021/09/28/11-37-45-910_4dc126edf70ec3cb.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bw%7D":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn63@2020_6/2021/09/28/11-37-46-385_fbb5cde346050f91.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122750.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn79@2020_5/2021/09/28/11-37-47-143_50d428fc3fb8ec30.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122833.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn85@2020_5/2021/09/28/11-37-49-475_b8653d1d72914dac.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%CE%9B%7D":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn52@2020_5/2021/09/28/11-37-45-938_0fa8c005ac77d4f4.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7BN%7D":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn40@2020_4/2021/09/28/11-37-45-885_b8736f5273f222bc.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7BX%2CY%7D":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn24@2020_4/2021/09/28/11-37-45-835_ecd14e50be588618.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bx%7D":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn43@2020_5/2021/09/28/11-37-56-187_c5b79ddbe8fe070f.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7By%7D":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn49@2020_5/2021/09/28/11-37-45-855_ab232feedb40fe54.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122900.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn66@2020_5/2021/09/28/11-37-47-082_963b1e408d00f992.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122934.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn47@2020_6/2021/09/28/11-37-49-475_a1852365c82a16de.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123003.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn31@2020_3/2021/09/28/11-37-46-139_b7a697fcb724e3e7.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123018.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn59@2020_2/2021/09/28/11-37-45-991_bca77b9bed4fab72.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%5CPhi%7D":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn16@2020_2/2021/09/28/11-37-45-852_d40528dd70d05069.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%28d%2Cn%29%7D":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn3@2020_1/2021/09/28/11-37-46-552_a449c07427af71f1.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bphi%28x_n%29%7D":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn40@2020_5/2021/09/28/11-37-46-537_f9225d16f5f9bc4b.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bd%7D":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn24@2020_5/2021/09/28/11-38-56-170_95449c4cdc6c7316.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Cphi%7D":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn77@2020_3/2021/09/28/11-37-45-825_9f2c0c860f9e2c12.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123120.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn70@2020_4/2021/09/28/11-37-46-007_c4951b2d4a202cb6.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bk%28x%2Cx%27%29%7D":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn90@2020_5/2021/09/28/11-37-55-840_282317154bbcd2ca.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123054.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn7@2020_2/2021/09/28/11-37-46-446_e2ddf44dcb6d24f7.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Calpha%7D":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn14@2020_2/2021/09/28/11-37-56-084_932ffe8962d79566.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Cbeta%7D":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn88@2020_2/2021/09/28/11-37-56-641_93b64714f3d71a21.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123146.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn50@2020_1/2021/09/28/11-37-48-620_408b4671b71f05ea.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123653.gif":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn8@2020_6/2021/09/28/11-37-49-393_c49283285892e04f.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123359.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn84@2020_6/2021/09/28/11-37-46-744_7b8b812eee4bce3c.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bx_k%7D":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn44@2020_3/2021/09/28/11-37-50-409_c40eb61f2c5ea59a.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bk%7D":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn68@2020_3/2021/09/28/11-37-47-049_fb9f2a141b72aea8.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bz_i%7D":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn12@2020_6/2021/09/28/11-37-45-892_6f0778ab840835f5.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bi%7D":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn4@2020_3/2021/09/28/11-37-56-449_aa8ab3cabe1a5eee.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7BW%7D":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn63@2020_4/2021/09/28/11-37-46-195_b1b5d6c6a3b2223a.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bb%7D":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn56@2020_6/2021/09/28/11-37-45-864_12c0ae85a5957275.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123425.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn10@2020_5/2021/09/28/11-37-46-152_f1075d6720c5e8d9.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B%7Bb_i%7D%5E1%7D":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn72@2020_3/2021/09/28/11-37-56-446_0dfb8807d3f8693d.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bz%7D":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn20@2020_4/2021/09/28/11-37-46-534_ebf5fd3033d5c603.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123515.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn76@2020_5/2021/09/28/11-37-46-386_35be0988fd028a78.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7Bl%7D":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn60@2020_4/2021/09/28/11-37-45-994_832ce375c2b0323b.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B-%7D":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn32@2020_1/2021/09/28/11-37-55-944_aea2b7a6c92e765c.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7B1%7D":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn95@2020_5/2021/09/28/11-37-45-915_c8321874764577da.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123550.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn81@2020_4/2021/09/28/11-38-06-369_e55c9b19232038c0.webp","https://chart.apis.google.com/chart?cht=tx&chl=%7BF%7D":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn12@2020_5/2021/09/28/11-38-04-951_54edbe599c12c2bf.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123614.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn36@2020_6/2021/09/28/11-37-46-021_e643918142cc9e85.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123813.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn26@2020_2/2021/09/28/11-37-46-566_528faf6291249aaa.webp"},"publishedOrCreatedDate":1632829065706}],"record":{"createdTime":"2021-09-28 19:37:45","updatedTime":"2021-09-28 19:37:45","feedId":36128,"fetchDate":"Tue, 28 Sep 2021 11:37:45 +0000","fetchMs":1224,"handleMs":5031,"totalMs":77459,"newArticles":0,"totalArticles":27,"status":1,"type":0,"ip":"79b59b7ab14b8d981e3d8a220e20848a","hostName":"us-030*","requestId":"a67f60d27fb442c48b3784c10a143bf6_36128","contentType":"application/atom+xml; charset=utf-8","totalBytes":1539142,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":46,"articlesImgsGithubTotal":46,"successGithubMap":{"myreaderx8":2,"myreaderx14":2,"myreaderx15":1,"myreaderx7":2,"myreaderx6":2,"myreaderx16":2,"myreaderx32":2,"myreaderx10":1,"myreaderx4":2,"myreaderx33":2,"myreaderx3":2,"myreaderx12":1,"myreaderx2":1,"myreaderx13":2,"myreaderx1":1,"myreaderx30":1,"myreaderx31":2,"myreaderx18":2,"myreaderx19":2,"myreaderx":1,"myreaderx25":2,"myreaderx27":1,"myreaderx21":2,"myreaderx22":2,"myreaderx23":2,"myreaderx24":1,"myreaderx5oss":2,"myreaderx29":2},"failGithubMap":{}},"feed":{"createdTime":"2020-09-07 03:06:46","updatedTime":"2020-10-20 20:03:51","id":36128,"name":"作って遊ぶ機械学習。","url":"http://machine-learning.hatenablog.com/feed","subscriber":89,"website":null,"icon":"https://machine-learning.hatenablog.com/favicon.ico","icon_jsdelivr":null,"description":"～基礎的な確率モデルから最新の機械学習技術まで～","weekly":null,"link":"https://machine-learning.hatenablog.com"},"noPictureArticleList":[],"tmpCommonImgCdnBytes":0,"tmpBodyImgCdnBytes":1539142,"tmpBgImgCdnBytes":0,"extra4":{"start":1632829059107,"total":0,"statList":[{"spend":1568,"msg":"获取xml内容"},{"spend":5031,"msg":"解释文章"},{"spend":2196,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":70848,"msg":"正文链接上传到cdn"}]},"extra5":46,"extra6":46,"extra7ImgCdnFailResultVector":[null],"extra10_invalidATagHrefValue":{"https://machine-learning.hatenablog.com/entry/2018/01/13/142612_#fn:3":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fn:3","https://machine-learning.hatenablog.com/entry/2018/01/13/142612_#fn:2":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fn:2","https://machine-learning.hatenablog.com/entry/2018/01/13/142612_#fnref:3":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fnref:3","https://machine-learning.hatenablog.com/entry/2018/01/13/142612_#fn:1":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fn:1","https://machine-learning.hatenablog.com/entry/2018/01/13/142612_#fnref:2":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fnref:2","https://machine-learning.hatenablog.com/entry/2018/01/13/142612_#fnref:1":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612#fnref:1"},"extra111_proxyServerAndStatMap":{"http://us-037.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe63.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-028.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-015.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-60.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-024.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe70.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-011.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-025.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-020.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://europe69.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe21.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-004.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-033.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-008.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-016.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-012.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-018.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-24.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-55.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-021.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-58.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe61.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-022.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-026.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe62.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-019.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-51.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe67.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-023.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-014.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7By_n%7D","sourceStatusCode":200,"destWidth":19,"destHeight":17,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn99@2020_1/2021/09/28/11-37-45-841_1a9c57b5d21f5a00.webp","sourceBytes":561,"destBytes":294,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":358,"convertSpendMs":4,"createdTime":"2021-09-28 19:37:45","host":"us-016*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"561 B","destSize":"294 B","compressRate":"52.4%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7BX%2CY%7D","sourceStatusCode":200,"destWidth":35,"destHeight":18,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn24@2020_4/2021/09/28/11-37-45-835_ecd14e50be588618.webp","sourceBytes":791,"destBytes":396,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":349,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:45","host":"us-025*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"791 B","destSize":"396 B","compressRate":"50.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7BD%7D","sourceStatusCode":200,"destWidth":15,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn47@2020_5/2021/09/28/11-37-45-821_59a9f04bffdcc812.webp","sourceBytes":439,"destBytes":230,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":371,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:45","host":"us-51*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"439 B","destSize":"230 B","compressRate":"52.4%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Cphi%7D","sourceStatusCode":200,"destWidth":11,"destHeight":18,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn77@2020_3/2021/09/28/11-37-45-825_9f2c0c860f9e2c12.webp","sourceBytes":434,"destBytes":236,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":376,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:45","host":"us-011*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"434 B","destSize":"236 B","compressRate":"54.4%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7BN%7D","sourceStatusCode":200,"destWidth":16,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn40@2020_4/2021/09/28/11-37-45-885_b8736f5273f222bc.webp","sourceBytes":472,"destBytes":220,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":373,"convertSpendMs":7,"createdTime":"2021-09-28 19:37:45","host":"us-024*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"472 B","destSize":"220 B","compressRate":"46.6%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bz_i%7D","sourceStatusCode":200,"destWidth":15,"destHeight":15,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn12@2020_6/2021/09/28/11-37-45-892_6f0778ab840835f5.webp","sourceBytes":405,"destBytes":230,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":399,"convertSpendMs":4,"createdTime":"2021-09-28 19:37:45","host":"us-55*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"405 B","destSize":"230 B","compressRate":"56.8%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7By%7D","sourceStatusCode":200,"destWidth":9,"destHeight":13,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn49@2020_5/2021/09/28/11-37-45-855_ab232feedb40fe54.webp","sourceBytes":360,"destBytes":184,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":447,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:45","host":"us-019*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"360 B","destSize":"184 B","compressRate":"51.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bb%7D","sourceStatusCode":200,"destWidth":8,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn56@2020_6/2021/09/28/11-37-45-864_12c0ae85a5957275.webp","sourceBytes":337,"destBytes":200,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":443,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:45","host":"us-51*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"337 B","destSize":"200 B","compressRate":"59.3%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B1%7D","sourceStatusCode":200,"destWidth":7,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn95@2020_5/2021/09/28/11-37-45-915_c8321874764577da.webp","sourceBytes":213,"destBytes":160,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":501,"convertSpendMs":4,"createdTime":"2021-09-28 19:37:45","host":"us-028*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"213 B","destSize":"160 B","compressRate":"75.1%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123614.png","sourceStatusCode":200,"destWidth":978,"destHeight":239,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn36@2020_6/2021/09/28/11-37-46-021_e643918142cc9e85.webp","sourceBytes":28695,"destBytes":16900,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":516,"convertSpendMs":22,"createdTime":"2021-09-28 19:37:45","host":"us-037*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"28 KB","destSize":"16.5 KB","compressRate":"58.9%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123018.png","sourceStatusCode":200,"destWidth":980,"destHeight":45,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn59@2020_2/2021/09/28/11-37-45-991_bca77b9bed4fab72.webp","sourceBytes":4484,"destBytes":2616,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":562,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:45","host":"us-028*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4.4 KB","destSize":"2.6 KB","compressRate":"58.3%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123120.png","sourceStatusCode":200,"destWidth":980,"destHeight":45,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn70@2020_4/2021/09/28/11-37-46-007_c4951b2d4a202cb6.webp","sourceBytes":5233,"destBytes":4126,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":561,"convertSpendMs":6,"createdTime":"2021-09-28 19:37:45","host":"us-021*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.1 KB","destSize":"4 KB","compressRate":"78.8%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%CE%9B%7D","sourceStatusCode":200,"destWidth":30,"destHeight":18,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn52@2020_5/2021/09/28/11-37-45-938_0fa8c005ac77d4f4.webp","sourceBytes":708,"destBytes":436,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":565,"convertSpendMs":5,"createdTime":"2021-09-28 19:37:45","host":"us-018*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"708 B","destSize":"436 B","compressRate":"61.6%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bl%7D","sourceStatusCode":200,"destWidth":5,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn60@2020_4/2021/09/28/11-37-45-994_832ce375c2b0323b.webp","sourceBytes":253,"destBytes":168,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":593,"convertSpendMs":6,"createdTime":"2021-09-28 19:37:45","host":"us-022*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"253 B","destSize":"168 B","compressRate":"66.4%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123425.png","sourceStatusCode":200,"destWidth":979,"destHeight":96,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn10@2020_5/2021/09/28/11-37-46-152_f1075d6720c5e8d9.webp","sourceBytes":11332,"destBytes":6358,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":674,"convertSpendMs":6,"createdTime":"2021-09-28 19:37:45","host":"us-016*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.1 KB","destSize":"6.2 KB","compressRate":"56.1%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123003.png","sourceStatusCode":200,"destWidth":984,"destHeight":86,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn31@2020_3/2021/09/28/11-37-46-139_b7a697fcb724e3e7.webp","sourceBytes":14402,"destBytes":11258,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":731,"convertSpendMs":8,"createdTime":"2021-09-28 19:37:45","host":"us-014*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"14.1 KB","destSize":"11 KB","compressRate":"78.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7BW%7D","sourceStatusCode":200,"destWidth":20,"destHeight":15,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn63@2020_4/2021/09/28/11-37-46-195_b1b5d6c6a3b2223a.webp","sourceBytes":526,"destBytes":274,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":405,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:46","host":"us-016*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"526 B","destSize":"274 B","compressRate":"52.1%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123515.png","sourceStatusCode":200,"destWidth":980,"destHeight":54,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn76@2020_5/2021/09/28/11-37-46-386_35be0988fd028a78.webp","sourceBytes":7202,"destBytes":7108,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":539,"convertSpendMs":14,"createdTime":"2021-09-28 19:37:46","host":"us-55*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"7 KB","destSize":"6.9 KB","compressRate":"98.7%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Cphi%28%29%7D","sourceStatusCode":200,"destWidth":25,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn25@2020_3/2021/09/28/11-37-45-910_4dc126edf70ec3cb.webp","sourceBytes":756,"destBytes":388,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":920,"convertSpendMs":11,"createdTime":"2021-09-28 19:37:45","host":"us-026*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"756 B","destSize":"388 B","compressRate":"51.3%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bw%7D","sourceStatusCode":200,"destWidth":13,"destHeight":10,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn63@2020_6/2021/09/28/11-37-46-385_fbb5cde346050f91.webp","sourceBytes":391,"destBytes":202,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":966,"convertSpendMs":4,"createdTime":"2021-09-28 19:37:45","host":"us-023*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"391 B","destSize":"202 B","compressRate":"51.7%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bz%7D","sourceStatusCode":200,"destWidth":9,"destHeight":10,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn20@2020_4/2021/09/28/11-37-46-534_ebf5fd3033d5c603.webp","sourceBytes":267,"destBytes":164,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1041,"convertSpendMs":7,"createdTime":"2021-09-28 19:37:45","host":"us-020*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"267 B","destSize":"164 B","compressRate":"61.4%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123054.png","sourceStatusCode":200,"destWidth":979,"destHeight":86,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn7@2020_2/2021/09/28/11-37-46-446_e2ddf44dcb6d24f7.webp","sourceBytes":10732,"destBytes":8560,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1015,"convertSpendMs":8,"createdTime":"2021-09-28 19:37:45","host":"europe67*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.5 KB","destSize":"8.4 KB","compressRate":"79.8%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bphi%28x_n%29%7D","sourceStatusCode":200,"destWidth":57,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn40@2020_5/2021/09/28/11-37-46-537_f9225d16f5f9bc4b.webp","sourceBytes":1457,"destBytes":696,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1146,"convertSpendMs":627,"createdTime":"2021-09-28 19:37:45","host":"us-004*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.4 KB","destSize":"696 B","compressRate":"47.8%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%28d%2Cn%29%7D","sourceStatusCode":200,"destWidth":36,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn3@2020_1/2021/09/28/11-37-46-552_a449c07427af71f1.webp","sourceBytes":993,"destBytes":528,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1188,"convertSpendMs":27,"createdTime":"2021-09-28 19:37:45","host":"us-004*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"993 B","destSize":"528 B","compressRate":"53.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%5CPhi%7D","sourceStatusCode":200,"destWidth":12,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn16@2020_2/2021/09/28/11-37-45-852_d40528dd70d05069.webp","sourceBytes":390,"destBytes":242,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1231,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:45","host":"us-033*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"390 B","destSize":"242 B","compressRate":"62.1%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123813.png","sourceStatusCode":200,"destWidth":830,"destHeight":323,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn26@2020_2/2021/09/28/11-37-46-566_528faf6291249aaa.webp","sourceBytes":73769,"destBytes":21874,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1137,"convertSpendMs":13,"createdTime":"2021-09-28 19:37:45","host":"europe21*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"72 KB","destSize":"21.4 KB","compressRate":"29.7%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123359.png","sourceStatusCode":200,"destWidth":976,"destHeight":97,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn84@2020_6/2021/09/28/11-37-46-744_7b8b812eee4bce3c.webp","sourceBytes":10480,"destBytes":7362,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":608,"convertSpendMs":11,"createdTime":"2021-09-28 19:37:46","host":"us-020*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.2 KB","destSize":"7.2 KB","compressRate":"70.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bk%7D","sourceStatusCode":200,"destWidth":10,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn68@2020_3/2021/09/28/11-37-47-049_fb9f2a141b72aea8.webp","sourceBytes":366,"destBytes":208,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":823,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:46","host":"us-004*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"366 B","destSize":"208 B","compressRate":"56.8%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122750.png","sourceStatusCode":200,"destWidth":984,"destHeight":45,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn79@2020_5/2021/09/28/11-37-47-143_50d428fc3fb8ec30.webp","sourceBytes":7028,"destBytes":5132,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":757,"convertSpendMs":4,"createdTime":"2021-09-28 19:37:46","host":"us-033*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"6.9 KB","destSize":"5 KB","compressRate":"73%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122900.png","sourceStatusCode":200,"destWidth":983,"destHeight":120,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn66@2020_5/2021/09/28/11-37-47-082_963b1e408d00f992.webp","sourceBytes":12228,"destBytes":8718,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1032,"convertSpendMs":13,"createdTime":"2021-09-28 19:37:46","host":"us-034*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.9 KB","destSize":"8.5 KB","compressRate":"71.3%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113124037.png","sourceStatusCode":200,"destWidth":798,"destHeight":692,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn6@2020_1/2021/09/28/11-37-47-424_1c959f9a19343084.webp","sourceBytes":147196,"destBytes":55812,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":2039,"convertSpendMs":24,"createdTime":"2021-09-28 19:37:45","host":"europe-59*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"143.7 KB","destSize":"54.5 KB","compressRate":"37.9%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123146.png","sourceStatusCode":200,"destWidth":980,"destHeight":288,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn50@2020_1/2021/09/28/11-37-48-620_408b4671b71f05ea.webp","sourceBytes":29996,"destBytes":17348,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1284,"convertSpendMs":12,"createdTime":"2021-09-28 19:37:47","host":"europe63*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.3 KB","destSize":"16.9 KB","compressRate":"57.8%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123653.gif","sourceStatusCode":200,"destWidth":1024,"destHeight":512,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn8@2020_6/2021/09/28/11-37-49-393_c49283285892e04f.webp","sourceBytes":3656797,"destBytes":1388814,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":4116,"convertSpendMs":2917,"createdTime":"2021-09-28 19:37:45","host":"us-015*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.5 MB","destSize":"1.3 MB","compressRate":"38%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122833.png","sourceStatusCode":200,"destWidth":980,"destHeight":49,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn85@2020_5/2021/09/28/11-37-49-475_b8653d1d72914dac.webp","sourceBytes":5646,"destBytes":3664,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":2008,"convertSpendMs":8,"createdTime":"2021-09-28 19:37:47","host":"europe62*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.5 KB","destSize":"3.6 KB","compressRate":"64.9%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113122934.png","sourceStatusCode":200,"destWidth":979,"destHeight":92,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn47@2020_6/2021/09/28/11-37-49-475_a1852365c82a16de.webp","sourceBytes":12552,"destBytes":9014,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":2210,"convertSpendMs":708,"createdTime":"2021-09-28 19:37:47","host":"europe62*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.3 KB","destSize":"8.8 KB","compressRate":"71.8%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bx_k%7D","sourceStatusCode":200,"destWidth":19,"destHeight":15,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn44@2020_3/2021/09/28/11-37-50-409_c40eb61f2c5ea59a.webp","sourceBytes":528,"destBytes":306,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":4942,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:45","host":"europe67*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"528 B","destSize":"306 B","compressRate":"58%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bx_n%7D","sourceStatusCode":200,"destWidth":19,"destHeight":13,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn58@2020_6/2021/09/28/11-37-50-542_4a13e8bc811a5562.webp","sourceBytes":487,"destBytes":264,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":5211,"convertSpendMs":9,"createdTime":"2021-09-28 19:37:45","host":"europe69*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"487 B","destSize":"264 B","compressRate":"54.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bk%28x%2Cx%27%29%7D","sourceStatusCode":200,"destWidth":51,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn90@2020_5/2021/09/28/11-37-55-840_282317154bbcd2ca.webp","sourceBytes":1239,"destBytes":626,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":10368,"convertSpendMs":4,"createdTime":"2021-09-28 19:37:45","host":"us-040*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d,c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.2 KB","destSize":"626 B","compressRate":"50.5%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B-%7D","sourceStatusCode":200,"destWidth":2,"destHeight":2,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn32@2020_1/2021/09/28/11-37-55-944_aea2b7a6c92e765c.webp","sourceBytes":97,"destBytes":44,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":10455,"convertSpendMs":1,"createdTime":"2021-09-28 19:37:45","host":"europe-59*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"97 B","destSize":"44 B","compressRate":"45.4%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bx%7D","sourceStatusCode":200,"destWidth":10,"destHeight":10,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn43@2020_5/2021/09/28/11-37-56-187_c5b79ddbe8fe070f.webp","sourceBytes":328,"destBytes":192,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":10721,"convertSpendMs":1,"createdTime":"2021-09-28 19:37:45","host":"us-012*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"328 B","destSize":"192 B","compressRate":"58.5%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Calpha%7D","sourceStatusCode":200,"destWidth":11,"destHeight":10,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn14@2020_2/2021/09/28/11-37-56-084_932ffe8962d79566.webp","sourceBytes":334,"destBytes":204,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":10615,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:45","host":"europe-58*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"334 B","destSize":"204 B","compressRate":"61.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%7Bb_i%7D%5E1%7D","sourceStatusCode":200,"destWidth":19,"destHeight":21,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn72@2020_3/2021/09/28/11-37-56-446_0dfb8807d3f8693d.webp","sourceBytes":564,"destBytes":336,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":10634,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:46","host":"europe67*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"564 B","destSize":"336 B","compressRate":"59.6%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7B%5Cbeta%7D","sourceStatusCode":200,"destWidth":11,"destHeight":18,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn88@2020_2/2021/09/28/11-37-56-641_93b64714f3d71a21.webp","sourceBytes":418,"destBytes":236,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":10698,"convertSpendMs":3,"createdTime":"2021-09-28 19:37:46","host":"us-008*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"418 B","destSize":"236 B","compressRate":"56.5%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bi%7D","sourceStatusCode":200,"destWidth":6,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn4@2020_3/2021/09/28/11-37-56-449_aa8ab3cabe1a5eee.webp","sourceBytes":260,"destBytes":190,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":11090,"convertSpendMs":6,"createdTime":"2021-09-28 19:37:45","host":"europe61*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"260 B","destSize":"190 B","compressRate":"73.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7BF%7D","sourceStatusCode":200,"destWidth":14,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn12@2020_5/2021/09/28/11-38-04-951_54edbe599c12c2bf.webp","sourceBytes":381,"destBytes":212,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":16467,"convertSpendMs":2,"createdTime":"2021-09-28 19:37:48","host":"europe-60*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"381 B","destSize":"212 B","compressRate":"55.6%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sammy-suyama/20180113/20180113123550.png","sourceStatusCode":200,"destWidth":978,"destHeight":62,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn81@2020_4/2021/09/28/11-38-06-369_e55c9b19232038c0.webp","sourceBytes":9431,"destBytes":12006,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":1174,"convertSpendMs":14,"createdTime":"2021-09-28 19:38:05","host":"europe-24*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"9.2 KB","destSize":"11.7 KB","compressRate":"127.3%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%7Bd%7D","sourceStatusCode":200,"destWidth":10,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn24@2020_5/2021/09/28/11-38-56-170_95449c4cdc6c7316.webp","sourceBytes":367,"destBytes":218,"targetWebpQuality":75,"feedId":36128,"totalSpendMs":9471,"convertSpendMs":12,"createdTime":"2021-09-28 19:38:47","host":"us-020*","referer":"https://machine-learning.hatenablog.com/entry/2018/01/13/142612","linkMd5ListStr":"c55101577bc4a707084a4d649e2ec74d","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"367 B","destSize":"218 B","compressRate":"59.4%"}],"successGithubMap":{"myreaderx8":2,"myreaderx14":2,"myreaderx15":1,"myreaderx7":2,"myreaderx6":2,"myreaderx16":2,"myreaderx32":2,"myreaderx10":1,"myreaderx4":2,"myreaderx33":2,"myreaderx3":2,"myreaderx12":1,"myreaderx2":1,"myreaderx13":2,"myreaderx1":1,"myreaderx30":1,"myreaderx31":2,"myreaderx18":2,"myreaderx19":2,"myreaderx":1,"myreaderx25":2,"myreaderx27":1,"myreaderx21":2,"myreaderx22":2,"myreaderx23":2,"myreaderx24":1,"myreaderx5oss":2,"myreaderx29":2},"failGithubMap":{}}