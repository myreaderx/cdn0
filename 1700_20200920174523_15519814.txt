{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-09-21 01:40:47","updatedTime":"2020-09-21 01:40:47","title":"讲堂丨周明：预训练模型在多语言、多模态任务的进展","link":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","description":"<div><div><div id=\"media\" class=\"rich_media_thumb_wrp\">\n\n            <img class=\"rich_media_thumb\" src=\"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQadho0ugJTdf3Y5lib9ibZgXQV2icNcz4AhSYWUudNqSUian0lUTvFRlLr6w?imageView2/1/w/600\">\n        </div>\n    \n\n    \n\n    <div class=\"rich_media_content\" id=\"js_content\">\n                    \n\n                    \n\n                    \n                    \n                    <section style=\"display:none;\" data-tools=\"新媒体管家\" data-label=\"powered by xmt.cn\"><br></section><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;min-height: 1em;max-width: 100%;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"__bg_gif\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"112\" data-ratio=\"0.17896389324960754\" data-type=\"gif\" data-w=\"637\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif\" style=\"max-width: 600px\"></p><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;min-height: 1em;max-width: 100%;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br></p><section data-support=\"96编辑器\" data-style-id=\"21917\"><section data-support=\"96编辑器\" data-style-id=\"21917\"><section style=\"margin-left: 8px;margin-right: 8px;\"><section style=\"border-width: 2px;border-style: dashed;border-color: rgb(254, 240, 0);box-sizing: border-box;\"><section data-width=\"50%\" style=\"margin-left: auto;width: 287px;height: 7px;background-color: rgb(255, 255, 255);\"><br></section><section style=\"margin: 15px;\"><p style=\"color: rgb(181, 180, 180);letter-spacing: 0.54px;font-size: 14px;font-variant-numeric: normal;font-variant-east-asian: normal;white-space: normal;\"><span style=\"color: rgb(136, 136, 136);\">编者按：</span><span style=\"color: rgb(136, 136, 136);letter-spacing: 0.54px;\">8月29日至30日，由中国科学技术协会、中国科学院、南京市人民政府为指导单位，中国人工智能学会、南京市建邺区人民政府、江苏省科学技术协会主办的主题为“智周万物”的2020年中国人工智能大会（CCAI 2020）在江苏南京新加坡·南京生态科技岛举办。</span><span style=\"color: rgb(136, 136, 136);letter-spacing: 0.54px;\"></span><span style=\"color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.54px;\">在大会上，微软亚洲研究院副院长、国际计算语言学会（ACL）前任主席周明做了主题为《预训练模型在多语言、多模态任务的进展》的特邀报告。在大会上，<strong>微软亚洲研究院副院长、国际计算语言学会（ACL）前任主席、中国计算机学会副理事长周明</strong>做了主题为《预训练模型在多语言、多模态任务的进展》的特邀报告。 </span><span style=\"color: rgb(136, 136, 136);letter-spacing: 0.54px;\"></span></p></section></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;min-height: 1em;max-width: 100%;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;min-height: 1em;max-width: 100%;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;text-align: center;\"><span style=\"font-size: 15px;\"><span style=\"font-variant-numeric: normal;font-variant-east-asian: normal;\"><img class=\"rich_pages\" data-ratio=\"0.66640625\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1280\" style=\"letter-spacing: 0.544px; text-align: center; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; overflow-wrap: break-word !important; width: 677px !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLyrutD8U4W6m2Qwj9OicibYBhniahQnrAY1fNnbk2fJrMUr3XqHAMLORiaQ/640?wx_fmt=jpeg\"></span></span></p><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">周明</span></p><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\"><span style=\"color: rgb(136, 136, 136);font-size: 12px;text-align: center;\">微软亚洲研究院副院长</span></span></p><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\"><span style=\"color: rgb(136, 136, 136);font-size: 12px;text-align: center;\">国际计算语言学会（ACL）前任主席</span></span></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 14px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;min-height: 1em;max-width: 100%;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"font-size: 15px;\"><strong>以下是周明老师的演讲实录：</strong></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><span style=\"color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.54px;\"><br></span></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">自然语言处理（NLP），目的是使得计算机具备人类的听、说、读、写、译、问、答、搜索、摘要、对话和聊天等能力，并可利用知识和常识进行推理和决策，并支持客服、诊断、法律、教学等场景。自然语言理解，被认为是 AI 皇冠上的明珠。一旦有突破，则会大幅度推动 AI 在很多重要场景落地。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">过去这五年，对自然语言是一个难忘的五年，它的一个标志就是神经网络全面引入到了自然语言理解。从大规模的语言数据到强有力的算力，加上深度学习，把整个自然语言带到一个新的阶段。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">今天我要讲的</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>预训练模型，它使自然语言处理由原来的手工调参、依靠 ML 专家的阶段，进入到可以大规模、可复制的大工业施展的阶段</span><span style=\"font-size: 15px;\">，令我们这个领域的人感到非常振奋。而且预训练模型从单语言、扩展到多语言、多模态任务。一路锐气正盛，所向披靡。那么，预训练模型到底是什么，它是怎么应用在很多产品里，未来又有哪些发展机会和挑战呢。下面我尝试由浅入深地给大家介绍一下。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"28\" data-cropsely1=\"0\" data-cropsely2=\"28\" data-ratio=\"1.05989110707804\" data-s=\"300,640\" data-type=\"png\" data-w=\"551\" style=\"height: 33px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"color: rgb(0, 0, 0);\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;color:#000;\">一、预训练模型</section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(254, 240, 0);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">先简要介绍一下预训练模型的基础技术，包括 Transformer、自监督学习、微调。然后再详细介绍预训练模型在语言、图像、文档和视频等任务中的进展，</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">预训练通过自监督学习从大规模数据中获得与具体任务无关的预训练模型。体现某一个词在一个特定上下文中的语义表征。第二个步骤是微调，针对具体的任务修正网络。训练数据可以是文本、文本-图像对、文本-视频对。预训练模型的训练方法可使用自监督学习技术（如自回归的语言模型和自编码技术）。可训练单语言、多语言和多模态的模型。此类模型可经过微调之后，用于支持分类、序列标记、结构预测和序列生成等各项技术，并构建文摘、机器翻译、图片检索、视频注释等应用。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">为什么我们要做预训练模型？首先，预训练模型是一种迁移学习的应用，利用几乎无限的文本，学习输入句子的每一个成员的上下文相关的表示，它隐式地学习到了通用的语法语义知识。第二，它可以将从开放领域学到的知识迁移到下游任务，以改善低资源任务，对低资源语言处理也非常有利。第三，预训练模型在几乎所有 NLP 任务中都取得了目前最佳的成果。最后，这个预训练模型+微调机制具备很好的可扩展性，在支持一个新任务时，只需要利用该任务的标注数据进行微调即可，一般工程师就可以实现。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下面介绍预训练模型的三个关键技术。</span></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"> </span></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"252\" data-backw=\"515\" data-ratio=\"0.490272373540856\" data-s=\"300,640\" data-type=\"png\" data-w=\"514\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLFqSLfSrWwdibkxZLAgrNveyOEc0BrTVetqTLzM7RfWs4pjNEd5Yqzvg/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">首先，</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>第一个关键技术是 Transformer</span><span style=\"font-size: 15px;\">。它在 NLP 各个任务中都取得了优异的性能，它是预训练语言模型的核心网络。给定一句话或是一个段落作为输入，首先将输入序列中各个词转换为其对应的词向量，同时加上每一个词的位置向量，体现词在序列的位置。然后将这些词向量输入到多层 Transformer 网络中，通过自注意力（self-attention）机制来学习词与词之间的关系，编码其上下文信息，再通过一个前馈网络经过非线性变化，输出综合了上下文特征的各个词的向量表示。每一层 Transformer 网络主要由 Multi-head self-attention 层（多头自注意力机制）和前馈网络层两个子层构成。Multi-head self-attention 会并行地执行多个不同参数的 self-attention，并将各个 self-attention 的结果拼接作为后续网络的输入，self-attention 机制会在后面中做详细介绍。此后，我们得到了蕴含当前上下文信息的各个词的表示，然后网络会将其输入到前馈网络层以计算非线性层次的特征。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在每一层 Transformer 网络中，会将残差连接（residual connection）把自注意力机制前或者前馈神经网络之前的向量引入进来，以增强自注意力机制或者前馈网络的输出结果向量。并且还做一个 layer normalization，也就是通过归一化把同层的各个节点的多维向量映射到一个区间里面，这样各层节点的向量在一个区间里面。这两个操作加入在每个子层后，可更加平滑地训练深层次网络。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">Transformer 可以用于编码，也可以用于解码。所谓解码就是根据一个句子的输入得到一个预想的结果，比如机器翻译（输入源语言句子，输出目标语言句子），或者阅读理解（输入文档和问题，输出答案）。解码时，已经解码出来的词要做一个自注意力机制，之后和编码得到的隐状态的序列再做一个注意力机制。这样可以做 N 层，然后通过一个线性层映射到词表的大小的一个向量。每个向量代表一个词表词的输出可能性，经过一个softmax 层得到每个词的输出概率。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">接下来介绍一下 self-attention 机制，以一个 head 作为示例。假定当前输入包含三个词，给定其输入词向量或是其上一层 Transformer 网络的输出，将其通过三组线性变换，转换得到三组 queries、keys 和 values 向量。Query 和 key 向量用来计算两两词之间的得分，也就是其依赖关系，这个得分会同其对应的 value 向量做加权和，以得到每个词综合上下文信息的表示。给定当前第一个词的 query 向量，其首先同各个词的 key 向量通过点积操作得到这两个词的得分，这些得分用来表示这两个词的依赖或是相关程度。这些得分之后会根据 query 等向量的维度做一定比例的缩放，并将这些得分通过 softmax 操作做归一化。之后，各个得分会同其相对应的 value 向量相乘得到针对第一个词加权的各个 value 向量，这些加权的 value 向量最终相加以得到当前第一个词的上下文表示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在得到第一个词的上下文表示后，给定第二个词的 query 向量，我们会重复之前的操作，计算当前 query 向量同各个词 key 向量的得分，对这些得分做 softmax 归一化处理，并将这些得分同其对应的 value 向量做加权和，以得到其编码上下文信息的表示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下面是一个最简化的例子以便简单说明自注意力机制。为了简单起见，这里假设 Q、K 和 V 的变化都不起作用，也就是不变。</span></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"219\" data-backw=\"525\" data-ratio=\"0.4165497896213184\" data-s=\"300,640\" data-type=\"png\" data-w=\"713\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwoUSaPMJSZeibwx7pDyiaqwyF6JzzdpgGASG84BcOicvB1LYIe8InGdFw/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">输入是 The weather is nice today，利用自注意力机制调整每个词的表示，比如 The。我们认为它要受到其他所有词的影响，但是影响力可大可小。那么每个词的影响力是通过计算 The 与每个词的关联度，然后通过一个 softmax 归一化得到一个权值，每个词一个权值，这样 The 的最后表示就是和每个词计算关联度的结果之和。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">多头注意力机制就是对一个节点，可以设置几组 K、Q 和 V，分别计算关联度（通过 Q 和 K 计算点积）和加权调整的值（通过 V 和关联度计算）。几组结果可以拼在一起，通过一个线性变换，体现多角度的特征抽取。多头可以是16个头、12个头等。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>第二个关键技术是自监督学习</span><span style=\"font-size: 15px;\">。在预训练的模型中，AR（自回归）LM 和 AE（自动编码器）是最常用的自监督学习方法，其中，自回归 LM 旨在利用前面的词序列预测下个词的出现概率（语言模型）。自动编码器旨在对损坏的输入句子，比如遮掩了句子某个词、或者打乱了词序等，重建原始数据。通过这些自监督学习手段来学习单词的上下文相关表示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>第三个关键技术就是微调</span><span style=\"font-size: 15px;\">。在做具体任务时，微调旨在利用其标注样本对预训练网络的参数进行调整。以我们使用基于 BERT（一种流行的预训练模型）为例来判断两个句子是否语义相同。输入是两个句子，经过 BERT 得到每个句子的对应编码表示，我们可以简单地用预训练模型的第一个隐节点预测分类标记判断两个句子是同义句子的概率，同时需要额外加一个线性层和 softmax 计算得到分类标签的分布。预测损失可以反传给 BERT 再对网络进行微调。当然也可以针对具体任务设计一个新网络，把预训练的结果作为其输入。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下面介绍一下预训练模型的历史沿革。预训练模型的发展虽然这几年才大热，但是我觉得源于早期的词嵌入（word embedding）的工作，比如 Word2Vec。它的训练的结果是词的嵌入，是一个静态的表示，此后 ULMFiT 是第一个使用 RNN 基于 LM 训练的上下文相关的预训练模型；CoVe 利用翻译任务来训练编码器-解码器，并使用编码器作为预训练模型；ELMo 使用双向 LSTM 合并两个方向的隐状态获得上下文相关表示；GPT 采用 LM 进行训练，它是基于 Transformer 的单向预训练模型；BERT 是基于 Transformer 的基于掩码的预训练模型；MT-DNN 基于 BERT 增加了一些任务进行多任务训练；MASS 使用编码-解码器来训练预训练模型；UniLM 尝试同时支持语言理解和生成任务。把预训练模型用于多语言任务：XLM 是一种支持多语言的 BERT 模型；Unicoder 引入若干新的任务改进了 XLM；T5 把多种自然语言任务（比如机器翻译、问答），用了更大的数据，在一个网络训练，同时支持这些任务；BART 是一种编码-解码器模型，通过还原损坏的句子训练；mBART 将 BART 理念扩展到多语言。另外还有最新的很多模型恕我这里没有全部列出。此外也扩展到多模态。</span></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"> </span></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"297\" data-backw=\"525\" data-ratio=\"0.5663824604141291\" data-s=\"300,640\" data-type=\"png\" data-w=\"821\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLvULzAjhPxWKomic2NAVt9AjAwVu00V9oa3jlTq5p3PocDgnpicz8AQGw/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这是一个更加详细的总结。名称、用途、架构、特点，这里就不详细说明了。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">总体来讲，</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>预训练模型发展趋势</span><span style=\"font-size: 15px;\">：</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>第一，模型越来越大</span><span style=\"font-size: 15px;\">。比如 Transformer 的层数变化，从12层的 Base 模型到24层的 Large 模型。导致模型的参数越来越大，比如 GPT 110 M，到 GPT-2 是1.5 Billion，图灵是 17 Billion，而 GPT-3 达到了惊人的 175 Billion。一般而言模型大了，其能力也会越来越强，但是训练代价确实非常大。</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>第二，预训练方法也在不断增加</span><span style=\"font-size: 15px;\">，</span><span style=\"font-size: 15px;\">从自回归 LM，到自动编码的各种方法，以及各种多任务训练等。</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>第三，还有从语言、多语言到多模态不断演进</span><span style=\"font-size: 15px;\">。</span><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>最后就是模型压缩，使之能在实际应用中经济的使用</span><span style=\"font-size: 15px;\">，比如在手机端。这就涉及到知识蒸馏和 teacher-student models，把大模型作为 teacher，让一个小模型作为 student 来学习，接近大模型的能力，但是模型的参数减少很多。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 18px;\"><strong>预训练模型举例说明</strong></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">BERT</span></strong><span style=\"font-size: 15px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这里用 BERT 举例说明预训练模型训练方法。基于 Transformer，其基本模型为 12 层模型，还有一个大型模型为 24 层模型。这里说明几个关键地方。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. tokenizer，简单地理解为词的切分，比如工具 BPE。针对一个数据集合，BPE 工具自动获得该数据集的 token 的集合，取频率最高的前 N 个 token 作为词表，其他的 token 都看作是 UNK（unknown word）。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. 对数据集合的每个数据，通过 BPE 做 tokenize，形成 token 的序列。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. 训练时，每个 token 有一个多维向量表示，比如1024维，随机初始化。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. 计算预测的损失。该损失反向传播来调整各层的网络参数，也包括每个 token 的多维向量表示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. 最后训练的结果，包括每个 token 的多维向量表示、每层的网络参数，以及各个 attention model 的参数等。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. 在用预训练模型时，把输入序列 tokenize 之后，对每个 token，从词典中得到多维向量表示。然后根据每层的网络参数，计算输出。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">训练任务：BERT 使用了掩码语言模型（就是盖住一个单词或者多个单词，然后让模型预测），损失用来调整网络。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">BERT 还使用 NSP（下一句预测），旨在预测第二句是否是第一句的下一句。</span></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"302\" data-backw=\"525\" data-ratio=\"0.5741176470588235\" data-s=\"300,640\" data-type=\"png\" data-w=\"850\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLUEeF2fh78Bia5V8jVFlLfyZnVwqOY6cmOzfWQY76V0wosJuB7HnN7MQ/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">UniLM</span></strong><span style=\"font-size: 15px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>UniLM 由微软亚洲研究院自然语言计算组开发，是一种最先进的预训练的模型，用于语言理解和生成任务</span><span style=\"font-size: 15px;\">。首先它是一个 Transformer 机制。用了三个任务训练：第一个任务就是掩码语言模型（就是自编码）类似于 BERT，利用左右词汇预测被盖住的词；第二个任务就是自回归语言模型，类似 GPT，利用前面的词序列预测下一个词；第三个任务就是编码-解码模型，利用输入句子和已经输出的词来预测接下来的词。这三个任务进行多任务训练，通过一个掩码矩阵控制哪些词可以用来 attention。训练得到的模型具备了理解和生成两种能力。在 GLUE 任务集合、文摘生成和答案抽取等任务上都取得了当时最好的水平。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">预训练模型已广泛应用于产品，比如提高搜索的相关性等。上图显示必应搜索使用了我们预训练模型的问答系统，给定一个 NL 问题，系统提取包含答案的文本并确定答案部分。它也可以用于问题生成，给定一个文本，生成关于这个文本的若干问题，可以用于语言教育等领域。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"28\" data-cropsely1=\"0\" data-cropsely2=\"28\" data-ratio=\"1.05989110707804\" data-s=\"300,640\" data-type=\"png\" data-w=\"551\" style=\"height: 33px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">二、</span><span style=\"color: rgb(0, 0, 0);\">预训练模型</span></section><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">在多语言任务的应用</span></section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(254, 240, 0);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section><section data-width=\"100%\" style=\"width: 578px;text-align: center;\"><br></section></section><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-ratio=\"0.558926487747958\" data-s=\"300,640\" data-type=\"png\" data-w=\"857\" style=\"box-sizing: border-box !important; overflow-wrap: break-word !important; width: 677px !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwTia4bepmCgznkJicCH5rNMpzhO149mFEtbrlrbRwaviaQRsodpNic9dDw/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">有许多语言中，它们都有大量的单一语言数据，并且某些语言对之间存在一些对照数据。我们可以学习一个跨语言的预训练模型，其中来自两种不同语言的单词，如果具有相似的含义，将联系在一起。然后，基于预训练的模型要建立某个具体任务的系统。对某些语言，如果有带标注的数据，利用之经微调可以得到一个系统。所得到的模型应用于其他语言的同一个任务，即使该语言没有标注数据，也有一定效果。该语言如有标注数据也可进一部微调。这样实现了跨语言之间的迁移学习。 </span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下面介绍一个典型多语言预训练模型 XLM。它将 BERT 扩展到多语言理解任务。XLM 中使用了两个任务。第一个是掩码（屏蔽）语言模型，它与 BERT 中类似，输入是一个句子，可以是 A 语言、也可以是 B 语言。通过共享所有语言的模型参数和词汇，XLM 可以获得跨语言功能。第二个任务是 TLM（翻译语言模型），它叫做翻译，其实并没有考虑对译关系。输入是双语对照句对，看作一个语言，去训练掩码语言模型。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649449719&amp;idx=1&amp;sn=f5c581be95c32daa3cc2340dfe8e1cef&amp;chksm=82c08d73b5b7046539fd37cb5fbac78d9c7ac0e23e1d7c5b7882f7e79e9ac6e520c6042827fa&amp;scene=21#wechat_redirect\" textvalue=\"我们开发的 Unicoder-1\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"2\"><span style=\"font-size: 15px;\">我们开发的 Unicoder-1</span></a><span style=\"font-size: 15px;\">进一步增加了跨语言训练新任务。</span><span style=\"font-size: 15px;\">除了在单语句子上进行单词和短语层面的“掩码 LM”，以及对双语句子进行掩码 LM（称作翻译 LM）之外，我们增加一个新的训练任务：</span><span style=\"font-size: 15px;\">在利用了 Giza+ 做了单词对齐之后，通过预测两个单词的对译关系是否存在。</span><span style=\"font-size: 15px;\">这个任务可以在单词级别做、短语级别做，也可以在句子级别做。</span><span style=\"font-size: 15px;\">不仅用正例，也引入了反例，通过对比式学习，加强学习效果。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">我们还将 Unicoder 扩展到了跨语言生成任务。</span><span style=\"font-size: 15px;\">这个预训练模型 Unicoder-2 做了如下任务训练：</span><span style=\"font-size: 15px;\">给定来自多语言语料库的输入句子，首先打乱其句子，对文本加噪音，然后通过解码器尝试恢复。</span><span style=\"font-size: 15px;\">解码时可以用传统方法每次仅预测一个 token，也可通过我们最近的<a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649451255&amp;idx=1&amp;sn=972410eb3af457b7e03b5f6cb3fc86b6&amp;chksm=82c08373b5b70a65ad0b400b5d919e00fd9bf2adea4daff3fa2f1693a4681888e365ab74568f&amp;scene=21#wechat_redirect\" textvalue=\"Prophet（先知）网络\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"2\">Prophet（先知）网络</a>一起预测两个 token 或者多个 token，然后取第一个词输出，再预测下一位置的 token。</span><span style=\"font-size: 15px;\">这样做预测能力有新的提高。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"334\" data-backw=\"525\" data-ratio=\"0.6350282485875707\" data-s=\"300,640\" data-type=\"png\" data-w=\"885\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etL2l2iarSApoXkDJ09GsZ5H7vg2XHBkeCeusjRnJK5MibIpYwIPGUHU60Q/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">我们建立了多语言任务的评测数据集 XGLUE。XLGUE 中的 11 个下游任务，其中包括 NER（命名实体识别）、POS（词性标注）等。现在 XGLUE 已经发布，这些任务现在涵盖 19 种语言。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">我们在 XGLUE 上评测了多个跨语言预训练模型（包括 MBERT、XLM、XLM-R 和 Unicoder），并在上表中列出比较结果。</span><span style=\"font-size: 15px;\">可以看到，我们的 Unicoder 在许多理解和生成任务上实现了最佳的平均性能。</span><br></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"281\" data-backw=\"525\" data-ratio=\"0.5350877192982456\" data-s=\"300,640\" data-type=\"png\" data-w=\"1026\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLCWEPvQibf7DnEjCicBVNYlmMw0uGUymtjXyhkGQ0oBxpBzJ5kHZ9lczA/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">多语言预训练模型可以把英语的模型应用到其他语言。英语的标注数据比较多，而其他语言往往缺少标注数据。因此，利用多语言预训练模型可以对新的语言，做 zero-shot 或者 few-shot 的学习。比如这里展示了问答系统，英文问答数据 finetune 训练的 QA 在法语、德语上也有很好的效果，也可以产生新闻的标题。同样也是在英语标注集合 finetune 训练之后的系统，也可以生成其他语言的标题。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这里总结一下多语言预训练模型。</span><span style=\"font-size: 15px;\">它缓解了多种语言的资源短缺问题，</span><span style=\"font-size: 15px;\">多语言预训练模型帮助多语言搜索、QA、广告、新闻、文本摘要、低资源神经机器翻译等取得新的提升。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">多语言预训练模型仍然面临许多挑战，首先最有效的预训练任务仍然是掩码 LM（在多语种或双语语料库上），我们要拓展新的任务以便充分利用多语言/双语的特点。</span><span style=\"font-size: 15px;\">第二，词汇表比单语言的预训练模型（例如 BERT / RoBERTa）大得多，单语3万，多语25万。</span><span style=\"font-size: 15px;\">这样导致要学的模型参数就会增加很多，训练的开销更大。</span><span style=\"font-size: 15px;\">第三，有的语言对有词汇、语法的同源关系，迁移学习效果好，比如英语的 finetune 结果对法语、意大利语、西班牙语比较好，而对汉语的效果不太明显。</span><span style=\"font-size: 15px;\">下一步可以考虑在语系内部进行多语言模型训练。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"28\" data-cropsely1=\"0\" data-cropsely2=\"28\" data-ratio=\"1.05989110707804\" data-s=\"300,640\" data-type=\"png\" data-w=\"551\" style=\"height: 33px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png\"></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">三、预训练模型</span></section><section style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">在多模态任务的应用</span></section><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(254, 240, 0);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section><section data-width=\"100%\" style=\"width: 578px;text-align: center;\"><br></section></section><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 18px;\"><strong>图像-语言的预训练模型</strong></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">图像-语言的预训练模型的目的，可以是用于理解或者生成。</span><span style=\"font-size: 15px;\">这里我们仅介绍理解用的预训练模型。</span><span style=\"font-size: 15px;\">做法如下：</span><span style=\"font-size: 15px;\">给定一个包含一幅图片和对应的 caption（就是文字描述）的数据库，</span><span style=\"font-size: 15px;\">比如这个例子包括图片和对应的文字描述。</span><span style=\"font-size: 15px;\">首先对这个数据库进行预处理，用FASTER-RCNN 得到图片每个对象 label 的分布，以及对象的输出向量表示（softmax 之前的输出向量表示）。</span><span style=\"font-size: 15px;\">一个图片的所有对象按照从左到右、从上到下的顺序排列，可以形成一个序列，</span><span style=\"font-size: 15px;\">和文本序列排列在一起。</span><span style=\"font-size: 15px;\">我们可以用 BERT 方式训练一个预训练模型，比如掩码的方式，盖住文字段的某个 token 来预测这个 token，</span><span style=\"font-size: 15px;\">或者盖住对象序列的某一个对象来预测这个对象的输出向量表示，或者直接预测这个对象的 label，</span><span style=\"font-size: 15px;\">另外预测对象序列和 text 是否是相互描述。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">现有工作基于大致相似的网络结构。</span><span style=\"font-size: 15px;\">我们是最早发表工作的机构之一。</span><span style=\"font-size: 15px;\">我们增加了一个新的训练任务，即对象的输出向量还原为对象的 FASTER-RCNN 的原始向量，取得了改进效果。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在 Flickr30K（image retrieval和captioning的数据集），image2text和text2image 两个任务。</span><span style=\"font-size: 15px;\">Text2image 任务是给定 text，从 1 K 的图片（给定）排序，得到最优的匹配。</span><span style=\"font-size: 15px;\">MSCOCO（微软提供的数据集）任务完全与 Flick30K 一样。</span><span style=\"font-size: 15px;\">Pre-training dataset 是有三百万image-caption pairs 的，由谷歌提供的 Conceptual Captions。</span><span style=\"font-size: 15px;\">目前最好的系统：</span><span style=\"font-size: 15px;\">ViLBERT 来自 Facebook，UNITER 来自微软产品组。</span><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649450912&amp;idx=1&amp;sn=e222a8792ded23df94f1ca8cefb19144&amp;chksm=82c08024b5b7093281b07072b47f8a05c77d5c185afa2b51dd9066fe40690a4152db80491527&amp;scene=21#wechat_redirect\" textvalue=\"UNICODER-VL\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"2\"><span style=\"font-size: 15px;\">Unicoder-VL</span></a><span style=\"font-size: 15px;\">由于增加了新的训练任务（如前述），预训练模型对图片和文本的编码能力有所提升，得到了较好效果。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 18px;\"><strong>文档-语言的预训练模型</strong></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>我们开发的多模态的</span><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649451357&amp;idx=1&amp;sn=fb0787d2b7687b8310646518d21d7006&amp;chksm=82c082d9b5b70bcfbe413f56fe52905f83250c7c65374bcfa3c896d84c1c9f74780fa38bb229&amp;scene=21#wechat_redirect\" textvalue=\"预训练模型 LayoutLM\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"2\" style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>预训练模型 LayoutLM</span></a><span style=\"font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb>，通过对扫描的文档，利用 OCR 识别之后的文字片段和文字对照的图像同时进行预训练。</span><span style=\"font-size: 15px;\">基于该预训练模型，抽取表格里的重要信息，包括语义类别和值。该研究</span><span style=\"font-size: 15px;\">获得了目前在相关任务评测集最高的水平（发表在KDD 2020）。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这是目前可用的训练数据集合，含有 11 Million 扫描文档和识别的结果。NIST 发表的，最主要的16类数据（信件、表格、收据等），包含了扫描文档及其对应的 OCR 结果。我们重新用 OCR（开源工具）https://github.com/tesseract-ocr/tesseract，以便得到识别对象的坐标信息。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">我这里解释一下我们做的 LayoutLM 预训练模型。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">首先一个扫描的文档（digital burned doc），进入 OCR 引擎可以得到识别的结果，就是一个个的字符（以 BPE 分词之后表示）串，以及在文档中的起始位置坐标。</span><span style=\"font-size: 15px;\">字符串的序列和位置坐标（四个数字）作为预训练输入。</span><span style=\"font-size: 15px;\">然后通过类似 BERT 的掩码方式（就是盖住其中某些 token）通过12层（或者24层）的 Transformer 来预测被盖住的 token。</span><span style=\"font-size: 15px;\">预测的损失回传调整网络的全部参数，</span><span style=\"font-size: 15px;\">当然可以增加其他的训练任务，比如判断文档的分类。</span><span style=\"font-size: 15px;\">通过对大规模的 OCR 识别的数据进行训练，可以得到一个预训练模型，</span><span style=\"font-size: 15px;\">这个预训练模型在进行下游任务时要微调。</span><span style=\"font-size: 15px;\">微调时，可以直接用预训练模型作为输入进行微调，也可以把文档中的对应 token 的图像编码也作为输入，增强预训练的信号。</span><br></p><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><section style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;margin-left: 8px;margin-right: 8px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"rich_pages\" data-backh=\"235\" data-backw=\"525\" data-ratio=\"0.4464099895941727\" data-s=\"300,640\" data-type=\"png\" data-w=\"961\" style=\"width: 624px; box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etL1YXLcqgrOyLhicvRXCQt2ibf9Tl7EbqNM8hEWA5GicxtfXAtLNZB6Xnicw/640?wx_fmt=png\"></section><p style=\"max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">训练任务1：掩码训练类似于 BERT。预测被盖住的 token，其损失回传，调整网络。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">预训练任务2：判断图像的分类。按照原来数据集的分类标注，进行训练。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下游任务之一是表单理解。给一个文档，识别出文档中包含 key-value，就是实体语义类型（比如时间、地点、数目）和实体的值。通过标记 BIO 风格的序列，就可以得到识别结果。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">我们的 LayoutLM 对几个重要的下游任务都取得了最佳的结果，</span><span style=\"font-size: 15px;\">比如表单理解、收据信息抽取等等。</span><span style=\"font-size: 15px;\">这里不再赘述。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 18px;\"><strong>视频-语言的预训练模型</strong></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下面介绍 Video-NL 预训练模型。我们可以</span><span style=\"font-size: 15px;\">对每个 Video 片段和对应的 NL 描述（语音识别的结果）建立这样的网络结构，左边 NL 的 token 序列，右边是视频按照时间序列均匀切分（1.5 秒）的 video clip 的序列，可以用 S3D 等工具，每个 video clip 对应一个输出向量表示，</span><span style=\"font-size: 15px;\">进入Video encoder。</span><span style=\"font-size: 15px;\">文本序列和 video clip 序列拼接起来进入Transformer。</span><span style=\"font-size: 15px;\">多层（比如三层、四层）后面跟着一个解码，利用一个 encoder-decoder 结果来做预训练。可以</span><span style=\"font-size: 15px;\">使用如下四个任务进行预训练。</span><span style=\"font-size: 15px;\"> </span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">• Video-text alignment 任务用来判断输入的 video clip 和 text 是否相互描述。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">• Masked language model 任务用来预测 transcript 里被 mask 掉的单词。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">• Transcript generation 任务基于输入的 video clip，生成对应的 video transcript，这时还有 NL 段置空了。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">• Masked frame model 任务用来预测被 mask 掉的 video clip 对应的 video feature vector。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">Unicoder-VL </span><span style=\"font-size: 15px;\">扩展到 video，</span><span style=\"font-size: 15px;\">与其他工作相比，我们把理解和生成集成在一个预训练模型，既可以理解也有生成能力。</span><span style=\"font-size: 15px;\">预训练的语料是，HowTo100M 作为 pre-train 语料。</span><span style=\"font-size: 15px;\">它是从 YouTube 上抓下来的 1.2 M 视频，切分成 136 M 视频片段，根据时间轴配上文字说明（YouTube 自带的）。</span><span style=\"font-size: 15px;\">下游任务 finetune 目前我们使用 YouCook2 的菜谱视频，以及 MSR-VTT 微软发布的（视频-caption）对的数据集合。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">下游任务包括视频搜索和视频 caption 生成两个任务。</span><span style=\"font-size: 15px;\">首先是检索任务——给定 NL 的 query，从一个固定视频片段中搜索最匹配的视频片段。</span><span style=\"font-size: 15px;\">然后是 caption 任务——给定一段视频，加上 transcript，生成对应的 caption。</span><span style=\"font-size: 15px;\">我们的提交系统目前取得了最好的评测结果。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这样的预训练模型有很多应用。</span><span style=\"font-size: 15px;\">这里用 Video chaptering 来说明。</span><span style=\"font-size: 15px;\">它分为两个任务，一个是 video segmentation，用于对输入 video 进行 clip 切分；</span><span style=\"font-size: 15px;\">一个是 video captioning，用于对每个 video clip 生成一个总结性的内容。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">我总结一下多模态预训练模型。目前它尚处于初期阶段，遵循大多数 NLP 预训练模型，用 Transformer 机制，从有限的图像/视频-语言数据集中学习联合表示，可以计算图像/视频片段和文字描述的距离，并实现图像/视频-文字之间的转换。多模态预训练模型虽然刚刚开始还不成熟，但是已经在图像/视频的搜索，以及生成文字描述当任务中显示出不错的前景。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">当然，多模态预训练模型仍然面临许多挑战。</span><span style=\"font-size: 15px;\">首先，图像/视频-语言对的数据的大小仍然比自然语言语料库小得多。</span><span style=\"font-size: 15px;\">第二，CV 仅仅用于特征提取，目前并没有将 CV 模型和 NLP 模型共同训练。</span><span style=\"font-size: 15px;\">当然目前没有好的算法，而且训练的 cost 非常大。</span><span style=\"font-size: 15px;\">第三，与之有关的就是 CV 的物体识别，目前的类别仅限于1000类左右，对真实场景的覆盖不够，而且识别的精度也不够，导致预训练的输入信号天然带有误差。</span><span style=\"font-size: 15px;\">第四，对于多模态预训练模型，目前都是用 Transformer 机制，但是它的代价比较大，而且是否最合适对图像/视频-文字建立关联，还需要进一步探索。</span><span style=\"font-size: 15px;\">第五，图片和视频的预训练模型也不一样，由于视频有时序，因此视频的分割按照固定时长分割，缺乏逻辑意义。</span><span style=\"font-size: 15px;\">而且视频的 token 会比 NL 多很多，导致训练的代价比图片和文字的预训练大很多。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"28\" data-cropsely1=\"0\" data-cropsely2=\"28\" data-ratio=\"1.05989110707804\" data-s=\"300,640\" data-type=\"png\" data-w=\"551\" style=\"height: 33px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png\"><span style=\"color: rgb(0, 0, 0);font-size: 18px;font-weight: bold;letter-spacing: 2px;\"></span></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><p style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">结束语</span></p><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(255, 255, 0);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section><section data-width=\"100%\" style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></section><section data-width=\"100%\" style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">NLP 经历了第一代的基于规则的 NLP；</span><span style=\"font-size: 15px;\">第二代的基于统计的 NLP；</span><span style=\"font-size: 15px;\">五年前进入到基于神经网络的第三代 NLP（NN-NLP），在大数据、大模型、神经网络框架下取得了很好的进展，形成了一整套的技术。</span><span style=\"font-size: 15px;\">而现在更进一步，预训练+微调形成了工业化可扩展的解决方案。</span><span style=\"font-size: 15px;\">预训练模型把迁移学习很好地用起来了，让我们感到眼前一亮。</span><span style=\"font-size: 15px;\">这和小孩子读书一样，一开始语文、数学、化学都学，读书、网上游戏等，在脑子里积攒了很多。</span><span style=\"font-size: 15px;\">当他学习计算机时，实际上把他以前学到的所有知识都带进去了。</span><span style=\"font-size: 15px;\">如果他以前没上过中学，没上过小学，突然学计算机就不懂这里有什么道理。</span><span style=\"font-size: 15px;\">这和我们预训练模型一样，预训练模型就意味着把人类的语言知识，先学了一个东西，然后再代入到某个具体任务，就顺手了，就是这么一个简单的道理。</span><span style=\"font-size: 15px;\">这要感谢杨强老师做的迁移学习，真的是有效。</span><br></section><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">预训练体现出所有的自监督的训练。</span><span style=\"font-size: 15px;\">如果为了做预训练要标数据则失去意义，因为标不了太大数据，很多知识体现不出来。</span><span style=\"font-size: 15px;\">恰好自然语言有几乎无限的语料，用语言模型或者用自编码方法自监督学习。</span><span style=\"font-size: 15px;\">一个预训练模型，只要训出来以后，后续所有任务，都可以得到很好的处理。</span><span style=\"font-size: 15px;\">对一个任务，只要数据足够大的任务，预训练加微调机制基本可以搞定了。</span><span style=\"font-size: 15px;\">当然还需要研究 zero-shot，few-shot 等问题，这些还有研究空间。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">预训练模型在多语言任务中，rich-resource 的模型会迁移到 low-resource 语言任务中，减轻了数据不足的问题。</span><span style=\"font-size: 15px;\">预训练模型在文本中表现出色，基本可以实用。</span><span style=\"font-size: 15px;\">而在多模态任务中，则方兴未艾，还有巨大探索空间。</span><span style=\"font-size: 15px;\">比如图片/视频的预处理、训练任务的设计都将有很多有趣的研究。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">要想迈向下一个阶段也有很多问题，比如现有的预训练模型是不是最优的？</span><span style=\"font-size: 15px;\">有没有更好的训练任务、更好的神经网络架构？</span><span style=\"font-size: 15px;\">训练是否可以更快？</span><span style=\"font-size: 15px;\">模型是否可以更小？</span><span style=\"font-size: 15px;\">现在疯狂追求大模型，耗尽计算资源，同时也污染了环境，是不是我们可以接受的？</span><span style=\"font-size: 15px;\">还有现有的模型在利用知识、尝试、进行推理，并且提供解释等方面仍然没有看到任何清晰的解决前景。</span><span style=\"font-size: 15px;\">这些都是难题。</span><span style=\"font-size: 15px;\">我希望大家一起继续努力，把这些问题好好想想，努力把 NLP 推向一个新的高度。</span><br></p><section data-width=\"100%\" style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;line-height: 1.75em;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"28\" data-cropsely1=\"0\" data-cropsely2=\"28\" data-ratio=\"1.05989110707804\" data-s=\"300,640\" data-type=\"png\" data-w=\"551\" style=\"height: 33px; width: 31px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png\"><span style=\"color: rgb(0, 0, 0);font-size: 18px;font-weight: bold;letter-spacing: 2px;\"></span></p><section data-id=\"93765\" data-tools=\"135编辑器\" style=\"white-space: normal;\"><section data-width=\"100%\" style=\"width: 100%;text-align: center;\"><section style=\"display: inline-block;\"><p style=\"padding-right: 0.8em;padding-left: 0.8em;letter-spacing: 2px;font-size: 18px;font-weight: bold;box-sizing: border-box;\"><span style=\"color: rgb(0, 0, 0);\">致谢</span></p><section data-width=\"100%\" style=\"margin-top: -10px;background: rgb(255, 255, 0);border-radius: 20px;height: 10px;overflow: hidden;\"><br></section></section></section></section><section data-width=\"100%\" style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></section><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">本文所涉及的许多研究项目为微软亚洲研究院自然语言计算组的同事和实习生同学共同完成的，非常感谢他们的贡献。这里要特别感谢段楠对本讲座提供了丰富材料并帮助完善 PPT。同时我也感谢韦福如、崔磊和王文辉提供了部分重要内容。</span></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;\">（本报告根据速记整理）</span></p><section style=\"letter-spacing: 0.54px;max-width: 100%;box-sizing: border-box;background-color: rgb(255, 255, 255);overflow-wrap: break-word !important;\"><section powered-by=\"xiumi.us\" style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word !important;\"><section style=\"margin-top: 10px;margin-bottom: 10px;text-align: center;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word !important;\"><section style=\"margin-bottom: -3px;padding-top: 3px;width: 677px;border-bottom: 1px dotted rgb(160, 160, 160);max-width: 100%;box-sizing: border-box;overflow-wrap: break-word !important;\"><br></section><section style=\"height: 5px;line-height: 5px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word !important;\"><section style=\"vertical-align: top;display: inline-block;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word !important;\"><span style=\"margin-left: 5px;max-width: 100%;box-sizing: border-box;width: 5px;height: 5px;float: left;border-radius: 50%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);overflow-wrap: break-word !important;\"><br style=\"max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></span></section><section style=\"clear: both;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word !important;\"><br></section></section></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;min-height: 1em;max-width: 100%;box-sizing: border-box;background-color: rgb(255, 255, 255);overflow-wrap: break-word !important;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;min-height: 1em;max-width: 100%;box-sizing: border-box;background-color: rgb(255, 255, 255);overflow-wrap: break-word !important;\"><strong style=\"letter-spacing: 1px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;color: rgb(46, 87, 151);font-size: 15px;\">你也许还想看</strong><strong style=\"letter-spacing: 1px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;color: rgb(46, 87, 151);font-size: 15px;\">：</strong><br></p><p style=\"margin-right: 8px;margin-left: 8px;line-height: 1.75em;\"><br></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455839&amp;idx=1&amp;sn=8da12860f7842ae8ab73f771d1f3708a&amp;chksm=82c0955bb5b71c4de32c9c933a9f096d6d80647fcaa519844733b82138dc3760c57c126fdd3b&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQaeuFja5mB2dAVATENxwzrlnFRThGwUs75pS8eMJkJMRO8OQwFEyMbSA/640?wx_fmt=png\"></span></a></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649448926&amp;idx=1&amp;sn=67f2e2875b9d74b8070a408c07bd67e3&amp;chksm=82c0885ab5b7014c630a168fe88699462c544b697ae44645585e288fd425cd1ee5607ac04f5e&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQapdkB9FKy2fCa0iab3Rlo1OXKVj0HZnxk6fqkxR2RxCXiawnMibCCgM73Q/640?wx_fmt=png\"></span></a></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649448567&amp;idx=1&amp;sn=eeef1dd2102fa61468d6496fe04b5608&amp;chksm=82c089f3b5b700e5ec7799a19302f66cdffde0e61d0778d2a0908ab3298180230fcb9bf799d7&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQa6uepcsSFF7AvibJcTicfdrTAvIpgyVLAfgwULkGAIGLaRibRHvGdY6Avw/640?wx_fmt=png\"></span></a></section><section style=\"margin: 20px 8px;display: flex;justify-content: center;align-items: center;\"><section data-width=\"90%\" style=\"background: rgb(137, 137, 137);width: 562px;height: 2px;\"><br></section></section><p style=\"margin-right: 8px;margin-left: 8px;text-align: left;min-height: 1em;max-width: 100%;box-sizing: border-box;background-color: rgb(255, 255, 255);overflow-wrap: break-word !important;\"><br></p><p style=\"text-align: center;min-height: 1em;max-width: 100%;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><img class=\"__bg_gif\" data-copyright=\"0\" data-ratio=\"0.5\" data-type=\"gif\" data-w=\"750\" style=\"box-sizing: border-box !important; overflow-wrap: break-word !important; width: 677px !important; visibility: visible !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif\"></p>\n                </div>\n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455996&amp;idx=1&amp;sn=4bc2692c7f0d5795e00d0582c8ff2b68&amp;chksm=82c094f8b5b71deec658665ede0e210daf9f6e834176a6347588f4c12922cb5ae3e57ae282d3&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/5416/PGpBBxuP1X\"></div></div>","descriptionType":"html","publishedDate":"Thu, 10 Sep 2020 10:00:00 +0000","feedId":1700,"bgimg":"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQadho0ugJTdf3Y5lib9ibZgXQV2icNcz4AhSYWUudNqSUian0lUTvFRlLr6w?imageView2/1/w/600","linkMd5":"289aa96c198ebabb8cb53b90ceb18546","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn72@2020_6/2020/09/20/17-40-49-118_77b14f07b0d3b6a9.webp","destWidth":600,"destHeight":458,"sourceBytes":36555,"destBytes":34298,"author":"","articleImgCdnMap":{"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQadho0ugJTdf3Y5lib9ibZgXQV2icNcz4AhSYWUudNqSUian0lUTvFRlLr6w?imageView2/1/w/600":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn72@2020_6/2020/09/20/17-40-49-118_77b14f07b0d3b6a9.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn1@2020_2/2020/09/20/17-40-56-628_d8f757d4d88b52d6.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLyrutD8U4W6m2Qwj9OicibYBhniahQnrAY1fNnbk2fJrMUr3XqHAMLORiaQ/640?wx_fmt=jpeg":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn78@2020_6/2020/09/20/17-40-51-713_52399a431e97f125.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn91@2020_5/2020/09/20/17-40-50-863_5d90e6b222643aa1.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLFqSLfSrWwdibkxZLAgrNveyOEc0BrTVetqTLzM7RfWs4pjNEd5Yqzvg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn75@2020_1/2020/09/20/17-40-55-482_8a6e4a873a26d16c.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwoUSaPMJSZeibwx7pDyiaqwyF6JzzdpgGASG84BcOicvB1LYIe8InGdFw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn88@2020_1/2020/09/20/17-40-55-916_a7012f68c059b1f2.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLvULzAjhPxWKomic2NAVt9AjAwVu00V9oa3jlTq5p3PocDgnpicz8AQGw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn85@2020_4/2020/09/20/17-40-51-027_d1c0ecbc81199f5a.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLUEeF2fh78Bia5V8jVFlLfyZnVwqOY6cmOzfWQY76V0wosJuB7HnN7MQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn81@2020_4/2020/09/20/17-42-03-550_201fb4a25b4e6c61.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwTia4bepmCgznkJicCH5rNMpzhO149mFEtbrlrbRwaviaQRsodpNic9dDw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn98@2020_5/2020/09/20/17-40-52-910_db3b4c39f01cad4b.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etL2l2iarSApoXkDJ09GsZ5H7vg2XHBkeCeusjRnJK5MibIpYwIPGUHU60Q/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn7@2020_2/2020/09/20/17-41-00-806_82cf3afe49c60be4.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLCWEPvQibf7DnEjCicBVNYlmMw0uGUymtjXyhkGQ0oBxpBzJ5kHZ9lczA/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn93@2020_6/2020/09/20/17-40-59-942_3f78cdc5fb9eb74e.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etL1YXLcqgrOyLhicvRXCQt2ibf9Tl7EbqNM8hEWA5GicxtfXAtLNZB6Xnicw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn99@2020_5/2020/09/20/17-40-58-703_76cc55225865b823.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQaeuFja5mB2dAVATENxwzrlnFRThGwUs75pS8eMJkJMRO8OQwFEyMbSA/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_1/2020/09/20/17-40-57-151_169d707b6dd3d49c.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQapdkB9FKy2fCa0iab3Rlo1OXKVj0HZnxk6fqkxR2RxCXiawnMibCCgM73Q/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_6/2020/09/20/17-41-16-165_4b561a635fa1eb20.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQa6uepcsSFF7AvibJcTicfdrTAvIpgyVLAfgwULkGAIGLaRibRHvGdY6Avw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn95@2020_1/2020/09/20/17-41-07-876_9fc2aa495e360eb7.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif":null,"http://www.jintiankansha.me/rss_static/5416/PGpBBxuP1X":null},"publishedOrCreatedDate":1600623647718}],"record":{"createdTime":"2020-09-21 01:40:47","updatedTime":"2020-09-21 01:40:47","feedId":1700,"fetchDate":"Sun, 20 Sep 2020 17:40:47 +0000","fetchMs":643,"handleMs":31,"totalMs":276674,"newArticles":0,"totalArticles":5,"status":1,"type":0,"ip":"2f206359adb0c109a1a58d9b6d6580df","hostName":"europe21*","requestId":"4d107dd0fadc4b889956627c4752a327_1700","contentType":"application/rss+xml","totalBytes":566812,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":17,"articlesImgsGithubTotal":15,"successGithubMap":{"myreaderx8":1,"myreaderx25":1,"myreaderx7":1,"myreaderx6":1,"myreaderx16":1,"myreaderx32":1,"myreaderx21":1,"myreaderx3":1,"myreaderx11":1,"myreaderx13":1,"myreaderx1":1,"myreaderx30":1,"myreaderx31":1,"myreaderx29":1,"myreaderx":1},"failGithubMap":{}},"feed":{"createdTime":"2020-08-24 21:31:32","updatedTime":"2020-09-01 09:51:25","id":1700,"name":"微软研究院AI头条","url":"http://feedmaker.kindle4rss.com/feeds/MSRAsia.weixin.xml","subscriber":null,"website":null,"icon":"http://www.sogou.com/images/logo/new/favicon.ico?v=4","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn60@2020_1/2020/09/01/01-51-26-423_d24121c9beed1de6.ico","description":"专注科研18年，盛产黑科技","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2020-09-21 01:45:23","updatedTime":"2020-09-21 01:45:23","id":null,"feedId":1700,"linkMd5":"289aa96c198ebabb8cb53b90ceb18546"}],"tmpCommonImgCdnBytes":34298,"tmpBodyImgCdnBytes":532514,"tmpBgImgCdnBytes":0,"extra4":{"start":1600623646676,"total":0,"statList":[{"spend":1012,"msg":"获取xml内容"},{"spend":31,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":273099,"msg":"正文链接上传到cdn"}]},"extra5":17,"extra6":17,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwoUSaPMJSZeibwx7pDyiaqwyF6JzzdpgGASG84BcOicvB1LYIe8InGdFw/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":954,"convertSpendMs":0,"createdTime":"2020-09-21 01:40:50","host":"europe-57*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5416/PGpBBxuP1X","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1695,"convertSpendMs":0,"createdTime":"2020-09-21 01:40:50","host":"europe65*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5416/PGpBBxuP1X","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":476,"convertSpendMs":0,"createdTime":"2020-09-21 01:40:52","host":"us-029*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},null,{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1149,"convertSpendMs":0,"createdTime":"2020-09-21 01:41:50","host":"europe-58*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},null,{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1149,"convertSpendMs":0,"createdTime":"2020-09-21 01:41:50","host":"europe-58*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1149,"convertSpendMs":0,"createdTime":"2020-09-21 01:41:50","host":"europe-58*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1149,"convertSpendMs":0,"createdTime":"2020-09-21 01:41:50","host":"europe-58*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"}],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://europe-56.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-032.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-53.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe65.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://us-55.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,403]},"http://europe63.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,403]},"http://europe-58.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,403]},"http://europe61.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe66.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe-60.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,403]},"http://us-52.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-54.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe62.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-57.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://europe64.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe67.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-029.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQadho0ugJTdf3Y5lib9ibZgXQV2icNcz4AhSYWUudNqSUian0lUTvFRlLr6w?imageView2/1/w/600","sourceStatusCode":200,"destWidth":600,"destHeight":458,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn72@2020_6/2020/09/20/17-40-49-118_77b14f07b0d3b6a9.webp","sourceBytes":36555,"destBytes":34298,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":2496,"convertSpendMs":12,"createdTime":"2020-09-21 01:40:47","host":"europe67*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546,289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"35.7 KB","destSize":"33.5 KB","compressRate":"93.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNP1fiazia1fjklUOIPVqMnKy22vHufjlSZYRoIJL9K9yLnQricQHPUwQR746AicJWia3yQWYFdNAfibjlGQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":551,"destHeight":584,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn91@2020_5/2020/09/20/17-40-50-863_5d90e6b222643aa1.webp","sourceBytes":6425,"destBytes":22088,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":1781,"convertSpendMs":19,"createdTime":"2020-09-21 01:40:50","host":"europe-59*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546,289aa96c198ebabb8cb53b90ceb18546,289aa96c198ebabb8cb53b90ceb18546,289aa96c198ebabb8cb53b90ceb18546,289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"6.3 KB","destSize":"21.6 KB","compressRate":"343.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLvULzAjhPxWKomic2NAVt9AjAwVu00V9oa3jlTq5p3PocDgnpicz8AQGw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":821,"destHeight":465,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn85@2020_4/2020/09/20/17-40-51-027_d1c0ecbc81199f5a.webp","sourceBytes":23000,"destBytes":68738,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":2137,"convertSpendMs":18,"createdTime":"2020-09-21 01:40:50","host":"europe-56*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.5 KB","destSize":"67.1 KB","compressRate":"298.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLyrutD8U4W6m2Qwj9OicibYBhniahQnrAY1fNnbk2fJrMUr3XqHAMLORiaQ/640?wx_fmt=jpeg","sourceStatusCode":200,"destWidth":1080,"destHeight":720,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn78@2020_6/2020/09/20/17-40-51-713_52399a431e97f125.webp","sourceBytes":54967,"destBytes":49188,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":2241,"convertSpendMs":34,"createdTime":"2020-09-21 01:40:50","host":"us-53*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"53.7 KB","destSize":"48 KB","compressRate":"89.5%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwTia4bepmCgznkJicCH5rNMpzhO149mFEtbrlrbRwaviaQRsodpNic9dDw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":857,"destHeight":479,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn98@2020_5/2020/09/20/17-40-52-910_db3b4c39f01cad4b.webp","sourceBytes":55200,"destBytes":41914,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":3788,"convertSpendMs":22,"createdTime":"2020-09-21 01:40:50","host":"europe62*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"53.9 KB","destSize":"40.9 KB","compressRate":"75.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLFqSLfSrWwdibkxZLAgrNveyOEc0BrTVetqTLzM7RfWs4pjNEd5Yqzvg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":514,"destHeight":252,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn75@2020_1/2020/09/20/17-40-55-482_8a6e4a873a26d16c.webp","sourceBytes":47716,"destBytes":11374,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5923,"convertSpendMs":16,"createdTime":"2020-09-21 01:40:50","host":"us-032*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"46.6 KB","destSize":"11.1 KB","compressRate":"23.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLwoUSaPMJSZeibwx7pDyiaqwyF6JzzdpgGASG84BcOicvB1LYIe8InGdFw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":713,"destHeight":297,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn88@2020_1/2020/09/20/17-40-55-916_a7012f68c059b1f2.webp","sourceBytes":85922,"destBytes":24744,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5374,"convertSpendMs":33,"createdTime":"2020-09-21 01:40:51","host":"us-52*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"83.9 KB","destSize":"24.2 KB","compressRate":"28.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif","sourceStatusCode":200,"destWidth":637,"destHeight":114,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn1@2020_2/2020/09/20/17-40-56-628_d8f757d4d88b52d6.webp","sourceBytes":21989,"destBytes":14032,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":7488,"convertSpendMs":42,"createdTime":"2020-09-21 01:40:50","host":"europe64*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.5 KB","destSize":"13.7 KB","compressRate":"63.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQaeuFja5mB2dAVATENxwzrlnFRThGwUs75pS8eMJkJMRO8OQwFEyMbSA/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_1/2020/09/20/17-40-57-151_169d707b6dd3d49c.webp","sourceBytes":74751,"destBytes":15702,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":7610,"convertSpendMs":19,"createdTime":"2020-09-21 01:40:50","host":"us-55*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"73 KB","destSize":"15.3 KB","compressRate":"21%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etL1YXLcqgrOyLhicvRXCQt2ibf9Tl7EbqNM8hEWA5GicxtfXAtLNZB6Xnicw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":961,"destHeight":429,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn99@2020_5/2020/09/20/17-40-58-703_76cc55225865b823.webp","sourceBytes":137793,"destBytes":45396,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":9726,"convertSpendMs":52,"createdTime":"2020-09-21 01:40:50","host":"europe63*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"134.6 KB","destSize":"44.3 KB","compressRate":"32.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLCWEPvQibf7DnEjCicBVNYlmMw0uGUymtjXyhkGQ0oBxpBzJ5kHZ9lczA/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1026,"destHeight":549,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn93@2020_6/2020/09/20/17-40-59-942_3f78cdc5fb9eb74e.webp","sourceBytes":161947,"destBytes":71058,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":10911,"convertSpendMs":30,"createdTime":"2020-09-21 01:40:50","host":"europe-60*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"158.2 KB","destSize":"69.4 KB","compressRate":"43.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etL2l2iarSApoXkDJ09GsZ5H7vg2XHBkeCeusjRnJK5MibIpYwIPGUHU60Q/640?wx_fmt=png","sourceStatusCode":200,"destWidth":885,"destHeight":562,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn7@2020_2/2020/09/20/17-41-00-806_82cf3afe49c60be4.webp","sourceBytes":223669,"destBytes":66152,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":11769,"convertSpendMs":38,"createdTime":"2020-09-21 01:40:50","host":"europe67*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"218.4 KB","destSize":"64.6 KB","compressRate":"29.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQa6uepcsSFF7AvibJcTicfdrTAvIpgyVLAfgwULkGAIGLaRibRHvGdY6Avw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn95@2020_1/2020/09/20/17-41-07-876_9fc2aa495e360eb7.webp","sourceBytes":164338,"destBytes":22544,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":18771,"convertSpendMs":26,"createdTime":"2020-09-21 01:40:50","host":"europe61*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"160.5 KB","destSize":"22 KB","compressRate":"13.7%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOs6Wzy20yTdRiayDMwsucQapdkB9FKy2fCa0iab3Rlo1OXKVj0HZnxk6fqkxR2RxCXiawnMibCCgM73Q/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_6/2020/09/20/17-41-16-165_4b561a635fa1eb20.webp","sourceBytes":122774,"destBytes":21924,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":26946,"convertSpendMs":17,"createdTime":"2020-09-21 01:40:50","host":"europe-58*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"119.9 KB","destSize":"21.4 KB","compressRate":"17.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/bPcM14Jicetbb7rf4JhXGglBa8J8d7etLUEeF2fh78Bia5V8jVFlLfyZnVwqOY6cmOzfWQY76V0wosJuB7HnN7MQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":850,"destHeight":488,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn81@2020_4/2020/09/20/17-42-03-550_201fb4a25b4e6c61.webp","sourceBytes":213932,"destBytes":57660,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":12635,"convertSpendMs":42,"createdTime":"2020-09-21 01:41:51","host":"us-52*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+%E8%AE%B2%E5%A0%82%E4%B8%A8%E5%91%A8%E6%98%8E%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E8%AF%AD%E8%A8%80%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%9B%E5%B1%95","linkMd5ListStr":"289aa96c198ebabb8cb53b90ceb18546","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"208.9 KB","destSize":"56.3 KB","compressRate":"27%"}],"successGithubMap":{"myreaderx8":1,"myreaderx25":1,"myreaderx7":1,"myreaderx6":1,"myreaderx16":1,"myreaderx32":1,"myreaderx21":1,"myreaderx3":1,"myreaderx11":1,"myreaderx13":1,"myreaderx1":1,"myreaderx30":1,"myreaderx31":1,"myreaderx29":1,"myreaderx":1},"failGithubMap":{}}