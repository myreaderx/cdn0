{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-11-12 13:49:58","updatedTime":"2020-11-12 13:49:58","title":"科恩实验室最新NeurIPS-2020论文解读：基于跨模态检索的二进制代码-源代码匹配","link":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","description":"<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/head.png\" alt=\"\" /></p> \n<a id=\"more\"></a> \n<h2 id=\"导语\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#导语\" class=\"headerlink\" title=\"导语\"></a>导语</h2> \n<p>在NeurIPS 2020中，腾讯安全科恩实验室使用AI算法解决二进制安全问题的《CodeCMR: Cross-Modal Retrieval For Function-Level Binary Source Code Matching》论文成功入选。本论文首次提出了基于AI的二进制代码/源代码端到端匹配算法，与传统算法相比效果非常出色，准确率大幅提升。本论文成果为逆向分析领域提供了新的思路，大大提升工业部署效率。最新论文研究成果也将应用于腾讯安全科恩实验室研发的代码检索工具BinaryAI，使用体验请关注：<a href=\"https://github.com/binaryai/sdk\" target=\"_blank\" rel=\"external\">https://github.com/binaryai/sdk</a>。</p> \n<h2 id=\"关于NeurIPS会议\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#关于NeurIPS会议\" class=\"headerlink\" title=\"关于NeurIPS会议\"></a>关于NeurIPS会议</h2> \n<p>机器学习和计算神经科学领域的NeurIPS会议是人工智能领域最具影响力的顶级学术会议之一，备受学者们的关注。国际顶级会议NeurIPS 2020将于2020年12月7日-12日在线上举行。据统计，NeurIPS 2020收到投稿9454篇，创历史最高纪录，接收论文1900篇，论文接收率仅有历史最低的20.1%。</p> \n<h2 id=\"背景\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2> \n<p>论文链接：<a href=\"http://keenlab.tencent.com/zh/whitepapers/neurips-2020-cameraready.pdf\">CodeCMR: Cross-Modal Retrieval For Function-Level Binary Source Code Matching</a><br>在人工智能顶级学术会议AAAI 2020中，腾讯安全科恩实验室<a href=\"http://keenlab.tencent.com/zh/2019/12/10/Tencent-Keen-Security-Lab-Order-Matters/\">利用图神经网络解决二进制程序函数相似性分析问题的技术</a>得到了广泛关注。在此基础上，本次研究方向扩展到二进制代码与源代码的交叉领域，进一步实现腾讯安全科恩实验室在AI+安全新兴方向中的全新探索与突破。<br>二进制代码-源代码匹配是信息安全领域的重点研究方向之一。在给定二进制代码的情况下，逆向分析研究人员希望找到它对应的源代码，从而提升逆向分析的效率和准确率。但由于源代码和二进制代码的差异性，在此领域的研究较少。B2SFinder[1]和BinPro[2]等传统算法提取源代码和二进制代码的字符串、立即数等特征进行匹配。然而，函数级别的源代码与二进制代码的特征非常少，匹配准确率不高。另一方面，设计合适的特征需要大量的专家经验。<br>图1展示了一个函数的源代码与二进制代码。从图1中可以看出，除了字符串和立即数特征，代码中隐藏的语义特征也很关键。因此，本文希望设计一种端到端模型，可以自动提取代码间的语义特征，从而提升匹配的准确率。</br></br></br></p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/1.png\" alt=\"图1 二进制代码与对应的源代码\" /></p> \n<h2 id=\"模型\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2> \n<p>这是一个二进制代码-源代码间的检索任务，我们把两种代码当作两个模态的输入，即可类比到图文互搜等跨模态检索场景。因此，我们设计了如图2所示的CodeCMR框架，在跨模态检索领域中，这是一种比较常见的结构[3, 4]。在计算最终向量之前，两个模态之间没有信息传递，因此在实际应用时可以预先计算向量，可以节省大量的线上计算时间以及存储空间。</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/2.png\" alt=\"图2 CodeCMR整体框架\" /></p> \n<h3 id=\"整体结构\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#整体结构\" class=\"headerlink\" title=\"整体结构\"></a>整体结构</h3> \n<p>模型的输入有源代码特征和二进制代码特征两个部分。其中源代码特征是字符级别的源代码、从源代码中提取的字符串和立即数；二进制代码特征是控制流图、二进制代码的字符串和立即数。首先将三个输入（语义特征、字符串特征、立即数特征）分别用不同模型计算得到向量，再用拼接+BatchNorm的方式得到代码向量，最后用triplet loss[5]作为损失函数。</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/triplet-loss.png\" alt=\"\" /></p> \n<p>在这个基础框架上，有许多可以改进的创新点，例如使用预训练模型做语义融合、使用adversarial loss对齐向量等，对此我们将在后文讨论。</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/3.png\" alt=\"图3 源代码与二进制代码的语义模型\" /></p> \n<h3 id=\"语义模型\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#语义模型\" class=\"headerlink\" title=\"语义模型\"></a>语义模型</h3> \n<p>如图3所示，对于字符级源代码，我们使用的是DPCNN模型[6]；对于二进制控制流图，我们使用的是端到端的GNN模型。在函数级别，字符级源代码的输入通常在4096以上，DPCNN的效果远优于TextCNN和LSTM。对于控制流图，我们没有使用BERT预训练的node embedding作为输入[7]，而是采用了端到端训练的方式，取得了更好的效果。<br>在这个阶段，本文使用的是DPCNN和GNN，但ASTNN等树模型也同样值得尝试。由于输入是函数级别的代码，缺少#define、#include等重要信息，需要设计合适的编译工具将源代码转化为AST。相比之下，我们直接将文本作为输入的优点是无需额外的专家经验，健壮性强。</br></p> \n<h3 id=\"立即数、字符串模型\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#立即数、字符串模型\" class=\"headerlink\" title=\"立即数、字符串模型\"></a>立即数、字符串模型</h3> \n<p>对于源代码与二进制代码的立即数和字符串，我们同样设计了模型进行匹配。</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/integer-lstm.png\" alt=\"\" /></p> \n<p>对于立即数，我们设计了一种Integer-LSTM。它的输入有integer token和integer number两个。integer number作用在LSTM的输入门和输出门，从而控制信息流动。<br>对于字符串，我们使用的是层次模型，先用LSTM模型得到每个字符串的向量，再使用sum pooling的方法得到字符串集合的向量。</br></p> \n<h3 id=\"Norm-weighted-sampling\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#Norm-weighted-sampling\" class=\"headerlink\" title=\"Norm weighted sampling\"></a>Norm weighted sampling</h3> \n<p>在得到源代码与二进制代码的向量后，我们设计了一种采样方法。在metric learning领域中，损失函数和采样方法是十分重要的两个模块。为了解决hard样本在训练早期收敛到局部极小值的问题，[5]提出了semi-hard采样方法。然而，[8]指出这种采样方法可能会在某个时间段停止训练，从而提出了distance weighted sampling采样方法解决这个问题：</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/sampling-1.png\" alt=\"\" /></p> \n<p>distance weighted sampling可以在分布中选择各个概率的样本，而semi-hard、hard、uniform等采样方法只能选择特定分布的样本。在此基础上，本文提出了一个改进，即增加一个超参数s，帮助调整概率的分布，从而适应不同的任务和数据集。</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/sampling-2.png\" alt=\"\" /></p> \n<h2 id=\"实验\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h2> \n<h3 id=\"数据集与评测指标\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#数据集与评测指标\" class=\"headerlink\" title=\"数据集与评测指标\"></a>数据集与评测指标</h3> \n<p>本文分别用gcc-x64-O0和clang-arm-O3作为两种组合方式，制作了两个30000/10000/10000的训练/验证/测试集，并使用recall@1和recall@10作为评测指标。数据集已公开在<a href=\"https://github.com/binaryai。\" target=\"_blank\" rel=\"external\">https://github.com/binaryai。</a></p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/table1.png\" alt=\"表1 实验结果\" /></p> \n<h3 id=\"实验结果\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h3> \n<p>如表1所示，本文提出的方法与传统方法相比有巨大提升，这一发现符合我们的预期，说明代码间隐含的语义特征十分重要。在语义模型中，DPCNN+HBMP取得了最优的效果，说明在二进制侧端到端训练优于预训练的node embedding。与随机采样和distance weighted采样方法相比，norm weighted采样效果更好。图4的train/valid loss曲线也证明了这一点，当s=5时norm weighted sampling的train loss更高但valid loss更低，这表示采样到更合适的样例pair。</p> \n<p><img src=\"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/4.png\" alt=\"图4 训练与验证的损失函数曲线\" /></p> \n<h2 id=\"讨论与总结\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#讨论与总结\" class=\"headerlink\" title=\"讨论与总结\"></a>讨论与总结</h2> \n<h3 id=\"讨论\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h3> \n<p>基于CodeCMR框架，有很多值得尝试的创新。</p> \n<ol> \n <li>code encoder。ASTNN、Tree-LSTM、transformer等模型可能也同样有效；</li> \n <li>其它损失函数和采样方法，如AM-softmax、Circle loss等；</li> \n <li>对抗训练以及其它的跨模态检索领域的方法；</li> \n <li>预训练算法。在获得最终向量前两个模态没有信息融合，因此在两个模态分别单独预训练或用跨语言模型的方法融合训练，均是值得尝试的。</li> \n</ol> \n<h3 id=\"总结\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3> \n<p>本文针对二进制代码-源代码匹配任务提出了CodeCMR框架，成功地利用了源代码与二进制代码间的语义特征。与传统方法相比，取得了很大的突破。</p> \n<h2 id=\"参考文献\"><a href=\"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2> \n<p>[1] Yuan Z, Feng M, Li F, et al. B2SFinder: Detecting Open-Source Software Reuse in COTS Software[C]//2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2019: 1038-1049.<br>[2] Miyani D, Huang Z, Lie D. Binpro: A tool for binary source code provenance[J]. arXiv preprint arXiv:1711.00830, 2017.<br>[3] Wang H, Sahoo D, Liu C, et al. Learning cross-modal embeddings with adversarial networks for cooking recipes and food images[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019: 11572-11581.<br>[4] Wang B, Yang Y, Xu X, et al. Adversarial cross-modal retrieval[C]//Proceedings of the 25th ACM international conference on Multimedia. 2017: 154-162.<br>[5] Schroff F, Kalenichenko D, Philbin J. Facenet: A unified embedding for face recognition and clustering[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 815-823.<br>[6] Johnson R, Zhang T. Deep pyramid convolutional neural networks for text categorization[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. 2017: 562-570.<br>[7] Yu Z, Cao R, Tang Q, et al. Order Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(01): 1145-1152.<br>[8] Wu C Y, Manmatha R, Smola A J, et al. Sampling matters in deep embedding learning[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 2840-2848.</br></br></br></br></br></br></br></p>","descriptionType":"html","publishedDate":"Tue, 03 Nov 2020 04:00:00 +0000","feedId":22909,"bgimg":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/head.png","linkMd5":"ffe97d15359b8a1b98727c78d88a608b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn46@2020_1/2020/11/12/05-50-09-007_85cf33c329f119f9.webp","destWidth":2350,"destHeight":1000,"sourceBytes":370891,"destBytes":392570,"author":"","articleImgCdnMap":{"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/head.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn46@2020_1/2020/11/12/05-50-09-007_85cf33c329f119f9.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/1.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn73@2020_1/2020/11/12/05-50-11-939_c22e82eee23f23fd.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/2.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn81@2020_3/2020/11/12/05-50-14-865_312e45577d46e4f3.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/triplet-loss.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn77@2020_5/2020/11/12/05-50-13-154_d982be0b754f91dd.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/3.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn86@2020_4/2020/11/12/05-50-14-661_bb87ae6ea1d4743d.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/integer-lstm.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/11/12/05-50-14-378_ac32b813a095388a.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/sampling-1.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn89@2020_4/2020/11/12/05-50-14-504_2d1568a09684cb6d.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/sampling-2.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn98@2020_5/2020/11/12/05-50-13-301_3c248e8d2b5eee3d.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/table1.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn67@2020_3/2020/11/12/05-50-14-903_858b8078eff0e5f4.webp","http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/4.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn66@2020_5/2020/11/12/05-50-16-201_42e514882c72f0e2.webp"},"publishedOrCreatedDate":1605160198363}],"record":{"createdTime":"2020-11-12 13:49:58","updatedTime":"2020-11-12 13:49:58","feedId":22909,"fetchDate":"Thu, 12 Nov 2020 05:49:58 +0000","fetchMs":3360,"handleMs":5465,"totalMs":28965,"newArticles":0,"totalArticles":16,"status":1,"type":0,"ip":"6923885023856883326b4ebb589fbdad","hostName":"us-023*","requestId":"e3dfb55865504c96bb614ff318e4495f_22909","contentType":"text/xml; charset=utf8","totalBytes":1116348,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":10,"articlesImgsGithubTotal":10,"successGithubMap":{"myreaderx8":1,"myreaderx25":1,"myreaderx15":1,"myreaderx27":1,"myreaderx21":1,"myreaderx32":1,"myreaderx10":1,"myreaderx3":1,"myreaderx2":1,"myreaderx31":1},"failGithubMap":{}},"feed":{"createdTime":"2020-09-07 02:28:57","updatedTime":"2020-09-21 02:45:39","id":22909,"name":"腾讯科恩实验室官方博客","url":"http://keenlab.tencent.com/zh/atom.xml","subscriber":144,"website":null,"icon":"http://keenlab.tencent.com/favicon.ico","icon_jsdelivr":null,"description":"","weekly":null,"link":"http://keenlab.tencent.com"},"noPictureArticleList":[],"tmpCommonImgCdnBytes":392570,"tmpBodyImgCdnBytes":723778,"tmpBgImgCdnBytes":0,"extra4":{"start":1605160188218,"total":0,"statList":[{"spend":4680,"msg":"获取xml内容"},{"spend":5465,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":6974,"msg":"正文链接上传到cdn"}]},"extra5":10,"extra6":10,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#讨论与总结":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#讨论与总结","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#关于NeurIPS会议":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#关于NeurIPS会议","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#背景":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#背景","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_/zh/whitepapers/neurips-2020-cameraready.pdf":"http://keenlab.tencent.com/zh/whitepapers/neurips-2020-cameraready.pdf","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_/zh/2019/12/10/Tencent-Keen-Security-Lab-Order-Matters/":"http://keenlab.tencent.com/zh/2019/12/10/Tencent-Keen-Security-Lab-Order-Matters/","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#Norm-weighted-sampling":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#Norm-weighted-sampling","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#模型":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#模型","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#导语":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#导语","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#整体结构":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#整体结构","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#参考文献":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#参考文献","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#实验":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#实验","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#实验结果":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#实验结果","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#总结":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#总结","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#立即数、字符串模型":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#立即数、字符串模型","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#讨论":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#讨论","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#数据集与评测指标":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#数据集与评测指标","http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/_#语义模型":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/#语义模型"},"extra111_proxyServerAndStatMap":{"http://europe-24.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe62.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-028.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-035.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-015.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-023.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-011.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/head.png","sourceStatusCode":200,"destWidth":2350,"destHeight":1000,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn46@2020_1/2020/11/12/05-50-09-007_85cf33c329f119f9.webp","sourceBytes":370891,"destBytes":392570,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":5974,"convertSpendMs":130,"createdTime":"2020-11-12 13:50:04","host":"us-54*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b,ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"362.2 KB","destSize":"383.4 KB","compressRate":"105.8%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/1.png","sourceStatusCode":200,"destWidth":2514,"destHeight":1200,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn73@2020_1/2020/11/12/05-50-11-939_c22e82eee23f23fd.webp","sourceBytes":380632,"destBytes":152502,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":2741,"convertSpendMs":180,"createdTime":"2020-11-12 13:50:10","host":"us-023*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"371.7 KB","destSize":"148.9 KB","compressRate":"40.1%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/triplet-loss.png","sourceStatusCode":200,"destWidth":567,"destHeight":59,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn77@2020_5/2020/11/12/05-50-13-154_d982be0b754f91dd.webp","sourceBytes":16422,"destBytes":4988,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":3668,"convertSpendMs":4,"createdTime":"2020-11-12 13:50:10","host":"us-011*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16 KB","destSize":"4.9 KB","compressRate":"30.4%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/sampling-2.png","sourceStatusCode":200,"destWidth":611,"destHeight":62,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn98@2020_5/2020/11/12/05-50-13-301_3c248e8d2b5eee3d.webp","sourceBytes":16976,"destBytes":5832,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":3832,"convertSpendMs":5,"createdTime":"2020-11-12 13:50:10","host":"us-015*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16.6 KB","destSize":"5.7 KB","compressRate":"34.4%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/integer-lstm.png","sourceStatusCode":200,"destWidth":583,"destHeight":204,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/11/12/05-50-14-378_ac32b813a095388a.webp","sourceBytes":56872,"destBytes":15824,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":4943,"convertSpendMs":13,"createdTime":"2020-11-12 13:50:10","host":"us-028*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"55.5 KB","destSize":"15.5 KB","compressRate":"27.8%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/sampling-1.png","sourceStatusCode":200,"destWidth":598,"destHeight":126,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn89@2020_4/2020/11/12/05-50-14-504_2d1568a09684cb6d.webp","sourceBytes":27932,"destBytes":9062,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":5032,"convertSpendMs":6,"createdTime":"2020-11-12 13:50:10","host":"us-040*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.3 KB","destSize":"8.8 KB","compressRate":"32.4%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/table1.png","sourceStatusCode":200,"destWidth":1040,"destHeight":635,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn67@2020_3/2020/11/12/05-50-14-903_858b8078eff0e5f4.webp","sourceBytes":398763,"destBytes":109986,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":5703,"convertSpendMs":34,"createdTime":"2020-11-12 13:50:10","host":"us-036*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"389.4 KB","destSize":"107.4 KB","compressRate":"27.6%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/3.png","sourceStatusCode":200,"destWidth":2383,"destHeight":1177,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn86@2020_4/2020/11/12/05-50-14-661_bb87ae6ea1d4743d.webp","sourceBytes":294091,"destBytes":105564,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":5704,"convertSpendMs":126,"createdTime":"2020-11-12 13:50:10","host":"europe62*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"287.2 KB","destSize":"103.1 KB","compressRate":"35.9%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/2.png","sourceStatusCode":200,"destWidth":2003,"destHeight":1291,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn81@2020_3/2020/11/12/05-50-14-865_312e45577d46e4f3.webp","sourceBytes":469571,"destBytes":185570,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":6150,"convertSpendMs":103,"createdTime":"2020-11-12 13:50:10","host":"europe-24*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"458.6 KB","destSize":"181.2 KB","compressRate":"39.5%"},{"code":1,"isDone":false,"source":"http://keenlab.tencent.com/zh/img/neurips-2020-cameraready/4.png","sourceStatusCode":200,"destWidth":2540,"destHeight":878,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn66@2020_5/2020/11/12/05-50-16-201_42e514882c72f0e2.webp","sourceBytes":717818,"destBytes":134450,"targetWebpQuality":75,"feedId":22909,"totalSpendMs":6955,"convertSpendMs":180,"createdTime":"2020-11-12 13:50:10","host":"us-035*","referer":"http://keenlab.tencent.com/2020/11/03/neurips-2020-cameraready/","linkMd5ListStr":"ffe97d15359b8a1b98727c78d88a608b","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"701 KB","destSize":"131.3 KB","compressRate":"18.7%"}],"successGithubMap":{"myreaderx8":1,"myreaderx25":1,"myreaderx15":1,"myreaderx27":1,"myreaderx21":1,"myreaderx32":1,"myreaderx10":1,"myreaderx3":1,"myreaderx2":1,"myreaderx31":1},"failGithubMap":{}}