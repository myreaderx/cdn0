{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Ramping up cloud migration discovery and assessment with StratoZone","link":"https://cloud.google.com/blog/products/cloud-migration/google-cloud-has-acquired-stratozone/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Businesses around the world have been impacted by the global pandemic, making the need to migrate to the cloud more urgent than ever. On their own, many organizations have difficulty completing cloud migrations on time and on budget. Among their challenges: unknown capacity needs and sizing; unknown performance thresholds; navigating expensive hardware refresh cycles or contract renewals; understanding licensing and support issues; and compliance and security concerns.&nbsp;</p>\n  <p>At Google Cloud, we believe migrating to the cloud must be simple and provide clear advantages. We recently launched <a href=\"https://cloud.google.com/blog/products/cloud-migration/google-cloud-ramp-program-simplifies-cloud-migration\">RAMP</a>, our holistic migration program that provides the best of our expertise, services, partners, and tools to enable a simpler, faster path to cloud success. RAMP helps customers unlock their cloud potential through repeatable processes with predictable results for cloud migrations. To accelerate the assessment and planning phases, we acquired StratoZone, a migration discovery and assessment specialist.</p>\n  <p>Since 2014, StratoZone has helped thousands of companies understand their data center footprint, plan out their migration, and make the jump to the cloud. Now as part of Google Cloud, their technology and expertise supports enterprises who are looking to accelerate their cloud migrations, helping discover, assess, and understand complex dependencies across workloads moving to the cloud.&nbsp;</p>\n  <p>As part of our cloud migration program, these tools will help you more predictably evaluate your IT landscape and plan what can move, what should move, and in what order. This means a migration program that is:</p>\n  <ol>\n   <li><p><b>Fast</b>: Assess your workloads quickly, with a solution that takes very little time to install and run (typically under 45 minutes), and can scale to discover and assess thousands of assets in hours. Initial results are typically available in days.</p></li>\n   <li><p><b>Easy</b> to use: Discover workloads and assets using an agentless process. No appliances, hardware, or agents to deploy. Discovery is hypervisor and physical/virtual agnostic.</p></li>\n   <li><p><b>Secure</b>: All data is encrypted in transit and at rest. Customers control data anonymization.</p></li>\n  </ol>\n  <p>Based on best practices: Recommendations for optimal migration and modernization targets based on existing assets (including estimating TCO), proposing an optimal mix of cloud services as well as migration phases that minimize application disruption.</p>\n </div>\n</div>\n<div class=\"block-video\">\n <div class=\"article-module article-video \">\n  <figure>\n   <a class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-oK8-jejegH8-\" href=\"https://youtube.com/watch?v=oK8-jejegH8\"><img alt=\"Saving costs and eliminating the unknowns using Stratozone.\" src=\"https://img.youtube.com/vi/oK8-jejegH8/maxresdefault.jpg\" />\n    <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\">\n     <use xlink:href=\"#mi-youtube-icon\"></use>\n    </svg></a>\n   <figcaption class=\"article-video__caption h-c-page\">\n    <h4 class=\"h-c-headline h-c-headline--four h-u-font-weight-medium h-u-mt-std\">How to get started with discovery and assessment for your migration</h4>\n   </figcaption>\n  </figure>\n </div>\n <div class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-oK8-jejegH8-\" data-glue-modal-close-label=\"Close Dialog\">\n  <a class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"oK8-jejegH8\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=oK8-jejegH8\" ng-cloak=\"\"></a>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>We’re excited to help you make your move to the cloud. To get started, click here to estimate your cloud migration costs with <a href=\"https://inthecloud.withgoogle.com/tco-assessment-19/form.html\" target=\"_blank\">a free assessment</a> or get hands-on with the tech with this <a href=\"https://www.qwiklabs.com/focuses/10267?parent=catalog\" target=\"_blank\">Qwiklab</a>.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Mon, 24 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://img.youtube.com/vi/oK8-jejegH8/maxresdefault.jpg","linkMd5":"ab69514728f73b057e1fe97ce38efa08","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn58@2020_2/2020/08/24/23-28-59-506_4818b2ec7f4adc12.webp","destWidth":1280,"destHeight":720,"sourceBytes":66099,"destBytes":33232,"author":"","articleImgCdnMap":{"https://img.youtube.com/vi/oK8-jejegH8/maxresdefault.jpg":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn58@2020_2/2020/08/24/23-28-59-506_4818b2ec7f4adc12.webp"},"publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Databases that transform businesses—What happened at Google Cloud Next ‘20: OnAir","link":"https://cloud.google.com/blog/products/databases/what-happened-week6-of-google-cloud-next20-onair/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Week 6 of <a href=\"https://cloud.withgoogle.com/next/sf/sessions#data-management-databases\" target=\"_blank\">Google Cloud Next ‘20: OnAir</a> was all about Google Cloud databases and how to choose and use them, no matter where you are in your cloud journey. There was plenty to explore, from deep-dive sessions and demos to feature launches and customer stories. Across it all, what stood out is the strong momentum and adoption across Google Cloud databases for developers and enterprises alike.</p>\n  <p>Google Cloud’s range of databases are designed to help you tackle the unpredictable. Your databases shouldn’t get in the way of innovation and growth, but many legacy, on-prem databases are holding businesses back. We build our databases to meet you at any stage, whether it’s an as-is migration or a brand-new app developed in the cloud.&nbsp;&nbsp;</p>\n  <h3>Key data management announcements this week</h3>\n  <p>This week, <a href=\"https://cloud.google.com/blog/products/databases/database-news-and-customer-stories\">we launched new features</a> aimed at solving the hardest data problems to help our customers run the most mission-critical applications. We kicked off the week with <a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=DBS304\" target=\"_blank\">a keynote from Director of Product Management Penny Avril</a>, who talked with social media platform ShareChat about how they met a 500% increase in demand using Cloud Spanner without changing a line of code.&nbsp;</p>\n  <p>We also announced updates to our databases. For Spanner, the Spanner Emulator lets app developers do correctness testing when developing an app. A new C++ client library and increased SQL feature set also add more flexibility. In addition, cloud-native Spanner now offers new <a href=\"https://cloud.google.com/blog/products/databases/spanner-database-new-regions-for-scalability\">multi-region configurations</a> for Asia and Europe with 99.999% availability. NoSQL database service Cloud Bigtable now offers more capabilities, like managed backups for high business continuity and added data protection. And expanded support and SLA for single-node production instances makes it even easier to use Bigtable for all use cases, both large and small. Mobile and web developers use Cloud Firestore to build apps easily, and it now offers a richer query language, C++ client library, and Firestore Unity SDK to make it easy for game developers to adopt Firestore. We are also introducing tools to give you better visibility into usage patterns and performance with Firestore Key Visualizer, which will be coming soon.</p>\n  <p>Cloud SQL, the fully managed service for MySQL, PostgreSQL, and SQL Server, now offers more maintenance controls, cross-region replication, and committed use discounts, providing reliability and flexibility as you migrate to the cloud. For those users running specialized workloads like Oracle, Google Cloud's Bare Metal Solution enables you to move these workloads within milliseconds of latency to Google Cloud. Our Bare Metal Solution is now available in even more regions and provides a fast track to cloud while lowering overall costs.&nbsp;</p>\n  <h3>How customers are building and growing with cloud databases</h3>\n  <p>We also heard from customers across industries on how they use Google Cloud databases to transform their business, especially in the face of the unpredictable. From <a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=DBS202\" target=\"_blank\">The New York Times building a real-time collaborative editor</a> to help publish faster and <a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=DBS215\" target=\"_blank\">Khan Academy</a> on how they met the rising demand for online learning to <a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=DBS205\" target=\"_blank\">gaming publishers like Colopl</a> supporting massive scale and variable usage through Spanner and ShareChat migrating from <a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=DBS208\" target=\"_blank\">Amazon DynamoDB to Spanner</a> for better scale and efficiency at 30% lower costs, it’s exciting to see what they’ve been able to accomplish.&nbsp;</p>\n  <h3>Check out data management demos</h3>\n  <p>For data management week, we debuted new interactive demos that let you explore database decisions for yourself. If you’re trying to understand where to start, check out this demo that can help you <a href=\"https://cloud.withgoogle.com/next/sf/demos?demo=602#data-management-databases\" target=\"_blank\">choose which database is right for you</a>. To see how Cloud SQL lets you achieve high availability, <a href=\"https://cloud.withgoogle.com/next/sf/demos?demo=603#data-management-databases\" target=\"_blank\">explore this demo</a>. Or learn how you can get a <a href=\"http://cloud.withgoogle.com/next/sf/demos?demo=604\" target=\"_blank\">consistent, real-time view of your inventory</a> at scale across channels and regions using Spanner. And take a close look at how <a href=\"https://cloud.withgoogle.com/next/sf/demos?demo=605#data-management-databases\" target=\"_blank\">Bare Metal Solutions can help you run specialized workloads</a> in the cloud.</p>\n  <h3>Go deep with databases</h3>\n  <p>Across our entire database portfolio, there are sessions to help you better understand each service and what’s new. For SQL Server, MySQL, or Postgres users, check out <a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS201#data-management-databases\" target=\"_blank\">Getting to Know Cloud SQL for SQL Server</a> or <a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS301#data-management-databases\" target=\"_blank\">High Availability and Disaster Recovery with Cloud SQL</a>.&nbsp;</p>\n  <p>If it’s cloud-native you’re interested in, sessions like <a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=DBS211\" target=\"_blank\">Modernizing HBase Workloads with Cloud Bigtable</a>, <a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS204#data-management-databases\" target=\"_blank\">Future-proof Your Business for Global Scale and Consistency with Cloud Spanner</a>, or <a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS215#data-management-databases\" target=\"_blank\">Simplify Complex Application Development Using Cloud Firestore</a> provide deep dives to help you get started.</p>\n  <h3>Looking ahead: Application modernization</h3>\n  <p>Stay tuned to Next OnAir—next week is all about application modernization. Check out <a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=SOLKEY200#application-modernization\" target=\"_blank\">Tuesday’s keynote</a> to learn more about Anthos and how it can help make the most of your on-premises investments and cloud offerings.&nbsp;</p>\n  <p>Of course, we'll also bring you live technical talks and learning opportunities, aligned with each week's content. Click “Learn” on the <a href=\"https://cloud.withgoogle.com/next/sf/explore\" target=\"_blank\">Explore page</a> to find each week's schedule. Haven’t yet registered for Google Cloud ’20 Next: OnAir? Get started at <a href=\"https://cloud.withgoogle.com/next/sf/\" target=\"_blank\">g.co/cloudnext</a>.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Fri, 21 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"dff150f4b87f5867c68d4f32434b5cef","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Get more from every core: Announcing CPU overcommit for Compute Engine","link":"https://cloud.google.com/blog/products/compute/cpu-overcommit-for-sole-tenant-nodes-now-ga/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>As part of our commitment to provide the most enterprise-friendly, intelligent, and cost effective options for running workloads in the cloud, we are excited to announce <a href=\"https://cloud.google.com/compute/docs/nodes/overcommitting-cpus-sole-tenant-vms\"><b>CPU overcommit for sole-tenant nodes</b></a> <b>is now generally available.</b>&nbsp;</p>\n  <p>With CPU overcommit for sole-tenant nodes, you can over-provision your dedicated host virtual CPU resources by up to 2X. CPU overcommit automatically reallocates virtual CPUs across your sole-tenant nodes from idle VM instances to VM instances that need additional resources. This allows you to intelligently pool CPU cycles to reduce compute requirements when running enterprise workloads on dedicated hardware.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \">\n    <img alt=\"virtual CPU resources.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/virtual_CPU_resources.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>CPU overcommit for sole-tenant nodes addresses common enterprise challenges such as:</p>\n  <ul>\n   <li><p><b>Running cost-efficient</b> <a href=\"https://cloud.google.com/solutions/virtual-desktops\"><b>virtual desktops</b></a> <b>in the cloud</b>- CPU overcommit for&nbsp; sole-tenant nodes enables building cost-efficient virtual desktop solutions by intelligently sharing resources across VMs based on usage when dedicated hardware requirements from licensing requirements exist.&nbsp;</p></li>\n   <li><p><b>Improving host utilization and helping to reduce infrastructure costs</b> - CPU overcommit allows you to further increase the available host CPUs on each sole-tenant node. Coupled with <a href=\"https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type\">custom machine types</a>, CPU overcommit helps optimize memory usage and supports higher utilization for workloads with lower memory footprints.</p></li>\n   <li><p><b>Reducing license costs</b> - For licenses based on host physical-cores — such as <a href=\"https://cloud.google.com/compute/docs/nodes/bringing-your-own-licenses\">bring-your-own-license for Windows Server or Microsoft SQL Server</a> — CPU overcommit for sole-tenant nodes allows you to place more VMs on each licensed server. This allows you to persist on-prem licensing constructs and can help greatly reduce your licensing cost burden when running on Google Cloud.</p></li>\n  </ul>\n  <h3>Flexible control</h3>\n  <p>CPU overcommit for sole-tenant nodes is controlled at the VM instance-level by setting the minimum number of guaranteed virtual CPUs per VM along with the maximum burstable virtual CPUs per VM. This gives you flexible per-VM control to mix-and-match VM sizes and overcommit levels on a single sole-tenant node, so you can meet your specific workload needs. For example, when running a traditional virtual desktop workload, you can choose to uniformly overcommit all instances on a sole-tenant node; while for custom application deployments, you can choose tailored CPU overcommit levels (or no overcommit) for workloads with greater performance sensitivity.&nbsp; With up to a 2X overcommit setting per instance, you can oversubscribe each sole-tenant node by up to twice the number of base virtual CPUs. This means that for an n2-node-80-640 with 80 virtual CPUs, CPU overcommit allows you to treat the node as if there were up to 160 virtual CPUs.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"CPU overcommit.gif\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/CPU_overcommit.gif\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Configuring Instance-level CPU Overcommit</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <h3>Intelligent monitoring</h3>\n  <p>CPU overcommit for sole-tenant nodes offers <a href=\"https://cloud.google.com/compute/docs/nodes/overcommitting-cpus-sole-tenant-vms#optimizing_cpu_overcommit_levels\">detailed metrics to monitor your VM instances</a>to help you better tune your instance overcommit settings. Using the built-in <a href=\"https://cloud.google.com/monitoring/api/metrics_gcp#gcp-compute\">Scheduler Wait Time metric</a> available in Cloud Monitoring, you can view instance-level wait-time statistics to see the impact of oversubscription on your workload. The scheduler wait-time metric allows you to measure the amount of time your instance is waiting for CPU cycles so that you can appropriately adjust overcommit levels based on workload needs. To help you take action quickly, you can set up Cloud Monitoring to trigger alerts for instance wait-time thresholds.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Intelligent monitoring.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Intelligent_monitoring.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <h3>Pricing and availability</h3>\n  <p>Sole-tenant nodes configured for CPU overcommit incur a fixed 25% premium charge. CPU overcommit configured sole-tenant nodes are available on N1 and N2 nodes in regions and zones with <a href=\"https://cloud.google.com/compute/docs/regions-zones/\">sole-tenant node availability</a>.&nbsp;</p>\n  <p>Click here to learn more about <a href=\"https://cloud.google.com/compute\">Compute Engine and sole-tenant nodes</a>.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Wed, 19 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/virtual_CPU_resources.max-1000x1000.jpg","linkMd5":"111514d1fa52655a3898697a5a89a217","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn34@2020_3/2020/08/24/23-28-59-425_8fc9ed2c11790512.webp","destWidth":980,"destHeight":1000,"sourceBytes":324832,"destBytes":34718,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/virtual_CPU_resources.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn34@2020_3/2020/08/24/23-28-59-425_8fc9ed2c11790512.webp","https://storage.googleapis.com/gweb-cloudblog-publish/original_images/CPU_overcommit.gif":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn13@2020_1/2020/08/24/23-29-25-545_964e51e084b1bea9.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Intelligent_monitoring.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn90@2020_2/2020/08/24/23-29-25-115_1fef1b32b9b7481c.webp"},"publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"New GKE Dataplane V2 increases security and visibility for containers","link":"https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>One of Kubernetes’ true superpowers is its developer-first networking model. It provides easy-to-use features such as L3/L4 services and L7 ingress to bring traffic into your cluster as well as network policies for isolating multi-tenant workloads. As more and more enterprises adopt Kubernetes, the gamut of use cases is widening with new requirements around multi-cloud, security, visibility and scalability. In addition, new technologies such as service mesh and serverless demand more customization from the underlying Kubernetes layer. These new requirements all have something in common: they need a more programmable dataplane that can perform Kubernetes-aware packet manipulations without sacrificing performance.</p>\n  <p>Enter <a href=\"http://ebpf.io\" target=\"_blank\">Extended Berkeley Packet Filter (eBPF)</a>, a new Linux networking paradigm that exposes programmable hooks to the network stack inside the Linux kernel. The ability to enrich the kernel with user-space information—without jumping back and forth between user and kernel spaces—enables context-aware operations on network packets at high speeds.</p>\n  <p>Today, we’re introducing GKE Dataplane V2, an opinionated dataplane that harnesses the power of eBPF and <a href=\"https://docs.cilium.io/en/stable/intro/#what-is-cilium\" target=\"_blank\">Cilium</a>, an open source project that makes the Linux kernel Kubernetes-aware using eBPF. Now in beta, we’re also using Dataplane V2 to bring Kubernetes Network Policy logging to Google Kubernetes Engine (GKE).</p>\n  <h3>What are eBPF and Cilium?</h3>\n  <p>eBPF is a revolutionary technology that can run sandboxed programs in the Linux kernel without recompiling the kernel or loading kernel modules. Over the last few years, eBPF has become the standard way to address problems that previously relied on kernel changes or kernel modules. In addition, eBPF has resulted in the development of a completely new generation of tooling in areas such as networking, security, and application profiling. These tools no longer rely on existing kernel functionality but instead actively reprogram runtime behavior, all without compromising execution efficiency or safety.</p>\n  <p>Cilium is an open source project that has been designed on top of eBPF to address the new scalability, security and visibility requirements of container workloads. Cilium goes beyond a traditional <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni\" target=\"_blank\">Container Networking Interface</a> (CNI) to provide service resolution, policy enforcement and much more as seen in the picture below.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <a href=\"https://github.com/cilium/cilium\" rel=\"external\" target=\"_blank\"><img alt=\"Container Networking Interface.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Container_Networking_Interface.max-1000x1000.jpg\" /></a>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>The Cilium community has put in a tremendous amount of effort to bootstrap the Cilium project, which is the most mature eBPF implementation for Kubernetes out there. We at Google actively contribute to the Cilium project, so that the entire Kubernetes community can leverage the advances we are making with eBPF.</p>\n  <h3>Using eBPF to build Kubernetes Network Policy Logging</h3>\n  <p>Let’s look at a concrete application of how eBPF is helping us solve a real customer pain point. Security-conscious customers use Kubernetes network policies to declare how pods can communicate with one another. However, there is no scalable way to troubleshoot and audit the behavior of these policies, which makes it a non-starter for enterprise customers. With the introduction of eBPF to GKE, we can now support real-time policy enforcement as well as correlate policy actions (allow/deny) to pod, namespace, and policy names at line rate with minimal impact on the node’s CPU and memory resources.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Using eBPF to build Kubernetes Network Policy Logging.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Using_eBPF_to_build_Kubernetes_Network_Pol.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>The image above shows how highly specialized eBPF programs are installed into the Linux kernel to enforce network policy and report action logs. As packets come into the VM, the eBPF programs installed in the kernel decide how to route the packet. Unlike IPTables, eBPF programs have access to Kubernetes-specific metadata including network policy information.This way,&nbsp; they can not only allow or deny the packet, they can also report annotated actions back to user space. These events make it possible for us to generate network policy logs that are meaningful to a Kubernetes user. For instance, the log snippet shown below pinpoints which source pod was trying to connect to which destination pod and which network policy allowed that connection.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"log snippet.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/log_snippet.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Under the hood, Network Policy logging leverages GKE Dataplane V2. Not only does GKE Dataplane V2 expose the information needed for policy logging, it also completely abstracts away the details of configuring network policy enforcement from the user. That is, when you use Dataplane V2, you no longer have to worry about explicitly enabling network policy enforcement or picking the right CNI to use network policy on your GKE clusters. Talk about making Kubernetes easy to use!</p>\n  <p>Besides network policy, Kubernetes load balancing can also use eBPF to implement Direct Server Return (DSR) mode. DSR eliminates the <a href=\"https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer\" target=\"_blank\">additional NAT problem</a> that loses the client's IP address when using Kubernetes LoadBalancer services. eBPF’s ability to encode metadata into a network packet on the fly allows us to provide additional information to the destination node such that it can directly converse with the original client. With DSR, we can reduce the bandwidth requirements of each node as well as avoid port exhaustion.</p>\n  <p>eBPF’s ability to augment network packets with custom metadata enables a long list of possible use cases. We are as excited about the future of Kubernetes and eBPF as you are, so stay tuned for more innovations.</p>\n  <h3>How you can benefit from this</h3>\n  <p>Enterprises are always looking to improve their security posture with better visibility into their infrastructure. They want to be able to quickly identify abnormal traffic patterns such as pods that are unexpectedly talking to the internet and denial-of-service attacks. With Kubernetes Network Policy logging, you can now see all allowed and denied network connections directly in the Cloud Logging console to troubleshoot policies and spot irregular network activity.</p>\n  <br />\n  <p>To try out Kubernetes Network Policy logging for yourself, create a <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/network-policy-logging\">new GKE cluster with Dataplane V2</a> using the following command.</p>\n </div>\n</div>\n<div class=\"block-code\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n   <div class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n    <pre><code></code></pre>\n   </div>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p></p>\n  <hr />\n  <i><sup>Google would like to thank Thomas Graf, co-founder of the Cilium project, for his contributions to this blog post.</sup></i>\n  <p></p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Wed, 19 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Container_Networking_Interface.max-1000x1000.jpg","linkMd5":"e877a24f6e74972d4c4da08d95e7480b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_2/2020/08/24/23-28-59-602_bfb5b82d165280ef.webp","destWidth":1000,"destHeight":586,"sourceBytes":257055,"destBytes":36678,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/Container_Networking_Interface.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_2/2020/08/24/23-28-59-602_bfb5b82d165280ef.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Using_eBPF_to_build_Kubernetes_Network_Pol.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn78@2020_2/2020/08/24/23-29-25-580_7edc954a59649118.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/log_snippet.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx/cdn6@2020_1/2020/08/24/23-29-25-115_b1000d5f16cadc26.webp"},"publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Multi-language Dataflow pipelines enabled by new, faster architecture","link":"https://cloud.google.com/blog/products/data-analytics/multi-language-sdks-for-building-cloud-pipelines/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>What do you do when your development and data science teams work in different language SDKs or if there are features available in one programming language, but not available in your preferred language? Traditionally, you’d either need to create workarounds that bridge the various languages, or else your team would have to go back and recode. Not only does this cost time and money, it puts real strain on your team’s ability to collaborate.&nbsp;&nbsp;</p>\n  <h3>Introducing Dataflow Runner v2</h3>\n  <p>To overcome this, Google Cloud has added a new, more services-based architecture called Runner v2 (<a href=\"https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2\">available</a> to anyone building a pipeline) to <a href=\"https://cloud.google.com/dataflow\">Dataflow</a> that includes multi-language support for all of its language SDKs. This addition of what the Apache Beam community calls “multi-language pipelines” lets development teams within your organization share components written in their prefered language and weave them into a single, high-performance, distributed processing pipeline.</p>\n  <p>This architecture solves the current problem where language-specific worker VMs (called Workers) are required to run entire customer pipelines. If features or transforms are missing for a given language, they must be duplicated across various SDKs to ensure parity; otherwise, there will be gaps in feature coverage and newer SDKs like Apache Beam Go SDK will support fewer features and exhibit inferior performance characteristics for some scenarios.</p>\n  <p>Runner v2 includes a more efficient and portable worker architecture rewritten in C++, which is based on Apache Beam’s new <a href=\"https://beam.apache.org/roadmap/portability/\" target=\"_blank\">portability framework</a>, packaged together with <a href=\"https://cloud.google.com/blog/products/gcp/introducing-cloud-dataflow-shuffle-for-up-to-5x-performance-improvement-in-data-analytic-pipelines\">Dataflow Shuffle</a> for batch jobs and <a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-cloud-dataflows-new-streaming-engine\">Streaming Engine</a> for streaming jobs. This allows us to provide a common feature set going forward across all language-specific SDKs, as well as share bug fixes and performance improvements.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Dataflow Runner v2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Dataflow_Runner_v2.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Dataflow Runner v2 is <a href=\"https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2\">available today</a> with Python streaming pipelines. We encourage you to test out Dataflow Runner v2 with your current (non-production) workloads before it is enabled by default on all new pipelines. You do not have to make any changes to your pipeline code to take advantage of this new architecture.</p>\n  <p>Dataflow Runner v2 comes with support for many new features that are not available in the previous Dataflow runner. In addition to support for multi-language pipelines, Dataflow Runner v2 also provides full native support for Apache Beam’s powerful data source framework named <a href=\"https://beam.apache.org/blog/splittable-do-fn/\" target=\"_blank\">Splittable DoFn</a>, and support for using custom containers for Dataflow jobs. Also, Dataflow Runner v2 enables new capabilities for Python streaming pipelines, including <a href=\"https://beam.apache.org/documentation/programming-guide/#state-and-timers\" target=\"_blank\">Timers</a>, <a href=\"https://beam.apache.org/documentation/programming-guide/#state-and-timers\" target=\"_blank\">State</a>, and expanded support for <a href=\"https://beam.apache.org/documentation/programming-guide/#windowing\" target=\"_blank\">Windowing</a> and <a href=\"https://beam.apache.org/documentation/programming-guide/#triggers\" target=\"_blank\">Triggers</a>.&nbsp;</p>\n  <h3>Using Java implementations in Python</h3>\n  <p>Apache Beam’s multi-language capabilities are unique among modern-day data processing frameworks, letting Runner v2 make it easy to provide new features simultaneously in multiple Beam SDKs by writing a single language-specific implementation. For example, we have made the <a href=\"https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java\" target=\"_blank\">Apache Kafka connector</a> and <a href=\"https://github.com/apache/beam/blob/master/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/SqlTransform.java\" target=\"_blank\">SQL transform</a> from the Apache Beam Java SDK available for use in Python streaming pipelines starting with Apache Beam 2.23.&nbsp;</p>\n  <p>To see it for yourself, check out the <a href=\"https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py\" target=\"_blank\">Python Kafka connector</a> and <a href=\"https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/sql.py\" target=\"_blank\">the Python SQL transform</a> that utilizes corresponding Java implementations. To use newly supported Python transforms with Dataflow Runner v2, simply install the latest Java Development Kit (JDK) <a href=\"https://beam.apache.org/get-started/quickstart-java/\" target=\"_blank\">supported by Apache Beam</a> on your computer and use Python transforms in your Dataflow Python streaming pipeline. For example:</p>\n </div>\n</div>\n<div class=\"block-code\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n   <div class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n    <pre><code></code></pre>\n   </div>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>For more details regarding pipeline setup and usage of the newly supported transforms, see the Apache Beam Python examples for <a href=\"https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples/kafkataxi\" target=\"_blank\">Kafka</a> and <a href=\"https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/sql_taxi.py\" target=\"_blank\">SQL transform</a>.</p>\n  <h3>How cross-language transforms work</h3>\n  <p>Under the hood, to make Java transforms available to a Dataflow Python pipeline, the Apache Beam Python SDK starts up a local Java service on your computer to create and inject the appropriate Java pipeline fragments into your Python pipeline. The SDK then downloads and stages the necessary Java dependencies needed to execute these transforms.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"How cross-language transforms work.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/How_cross-language_transforms_work.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>At runtime, the Dataflow Workers will execute the Python and Java code side by side to run your pipeline. And we’re working on making more Java transforms available to Beam Python through the multi-language pipelines framework.</p>\n  <h3>Next steps</h3>\n  <ul>\n   <li><p><a href=\"https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2\">Enable</a> Runner v2 to realize the benefits of multi-language pipelines and performance improvements in Python pipelines</p></li>\n   <li><p>Try accessing Kafka topics from Dataflow Python pipelines by following this <a href=\"https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples/kafkataxi\" target=\"_blank\">tutorial</a></p></li>\n   <li><p>Try embedding SQL statements in your Dataflow Python pipelines by using this <a href=\"https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/sql_taxi.py\" target=\"_blank\">example</a></p></li>\n  </ul>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Fri, 21 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Dataflow_Runner_v2.max-1000x1000.jpg","linkMd5":"7663d516779305535fe0911a0d63c469","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn40@2020_1/2020/08/24/23-28-59-517_b45eccf720870303.webp","destWidth":1000,"destHeight":755,"sourceBytes":266293,"destBytes":32422,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/Dataflow_Runner_v2.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn40@2020_1/2020/08/24/23-28-59-517_b45eccf720870303.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/How_cross-language_transforms_work.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn69@2020_1/2020/08/24/23-29-25-205_4be73d032c19007e.webp"},"publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Dataflow Under the Hood: comparing Dataflow with other tools","link":"https://cloud.google.com/blog/products/data-analytics/dataflow-vs-other-stream-batch-processing-engines/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p><i><b>Editor's note</b>: This is the third blog in a three-part series examining the <a href=\"https://cloud.google.com/blog/products/data-analytics/how-cloud-batch-and-stream-data-processing-works\">internal Google history that led to Dataflow</a>, <a href=\"https://cloud.google.com/blog/products/data-analytics/cloud-batch-and-stream-processing-for-analytics\">how Dataflow works as a Google Cloud service</a>, and here, how it compares and contrasts with other products in the marketplace.</i></p>\n  <p>To place Google Cloud’s <a href=\"https://cloud.google.com/dataflow\">stream and batch processing tool Dataflow</a> in the larger ecosystem, we'll discuss how it compares to other data processing systems. Each system that we talk about has a unique set of strengths and applications that it has been optimized for. We’re biased, of course, but we think that we've balanced these needs particularly well in Dataflow.</p>\n  <p>Apache Kafka is a very popular system for message delivery and subscription, and provides a number of extensions that increase its versatility and power. Here, we'll talk specifically about the core Kafka experience. Because it is a message delivery system, Kafka does not have direct support for state storage for aggregates or timers. These can be layered on top through abstractions like Kafka Streams. Kafka does support transactional interactions between two topics in order to provide exactly once communication between two systems that support these transactional semantics. It does not natively support watermark semantics (though can support them through Kafka Streams) or autoscaling, and users must re-shard their application in order to scale the system up or down.</p>\n  <p>Apache Spark is a data processing engine that was (and still is) developed with many of the same goals as Google Flume and Dataflow—providing higher-level abstractions that hide underlying infrastructure from users. Spark has a rich ecosystem, including a number of tools for ML workloads. Spark has native exactly once support, as well as support for event time processing. Spark does have some limitations as far as its ability to handle late data, because its event processing capabilities (and thus garbage collection) are based on static thresholds rather than watermarks. State management in Spark is similar to the original MillWheel concept of providing a coarse-grained persistence mechanism. Users need to manually scale their Spark clusters up and down. One major limitation of structured streaming like this is that it is currently unable to handle multi-stage aggregations within a single pipeline.</p>\n  <p>Apache Flink is a data processing engine that incorporates many of the concepts from <a href=\"https://research.google/pubs/pub41378/\" target=\"_blank\">MillWheel streaming</a>. It has native support for exactly-once processing and event time, and provides coarse-grained state that is persisted through periodic checkpointing. The effect of this on the cost of state persistence is ambiguous, since most Flink deployments still write to a local RocksDB instance frequently, and periodically checkpoint this to an external file system. Depending on the frequency of checkpointing, this can increase time to recovery in the case that computation has to be repeated. Flink also requires manual scaling by its users; some vendors are working towards autoscaling Flink, but that would still require learning the ins and outs of a new vendor’s platform.</p>\n  <p>Finally, a brief word on Apache Beam, Dataflow’s SDK. Given Google Cloud’s broad open source commitment (Cloud Composer, Cloud Dataproc, and Cloud Data Fusion are all managed OSS offerings), Beam is often confused for an execution engine, with the assumption that Dataflow is a managed offering of Beam. That’s not the case—Dataflow jobs are authored in Beam, with Dataflow acting as the execution engine. The benefits of Apache Beam come from open-source development and portability. Jobs can be written to Beam in a variety of languages, and those jobs can be run on Dataflow, Apache Flink, Apache Spark, and other execution engines. That means you’re never locked into Google Cloud.</p>\n  <p>This concludes our three-part Under the Hood walk-through covering Dataflow. Check out <a href=\"https://cloud.google.com/blog/products/data-analytics/how-cloud-batch-and-stream-data-processing-works\">part 1</a> and <a href=\"https://cloud.google.com/blog/products/data-analytics/cloud-batch-and-stream-processing-for-analytics\" target=\"_blank\">part 2</a>. We're excited about the current state of Dataflow, and the state of the overall data processing industry. We look forward to delivering a steady \"stream\" of innovations to our customers in the months and years ahead.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Mon, 24 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"a6fdb54587b77762a1d7090e97549168","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Bringing databases to the center of a modern business","link":"https://cloud.google.com/blog/products/databases/business-transformation-with-cloud-databases/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>For many decades, databases have been the engines fueling the most business-critical enterprise workloads across industries such as retail, banking, manufacturing, and healthcare. These are the systems that, for example, allow money to move around the world and supplies to get to hospitals and patients when they need it most. These workloads require the highest levels of reliability, durability, and performance. As the keepers of the world’s most critical data, databases are top of mind as enterprises accelerate their adoption of cloud and consider how to meet new and changing demands.&nbsp;</p>\n  <p>We have partnered with some of the largest global enterprises and have seen some clear trends emerge. While the amount of data managed by applications continues to grow at an unbelievable rate, companies are rethinking how they handle this data. They want to increase the speed at which they build and launch new features and not get bogged down in maintaining and scaling databases, which ultimately stifles innovation. They’re increasingly adopting databases with open APIs—freeing themselves from restrictive licenses and maintaining portability of their data. They’re having to meet new, stringent regulations for security and data sovereignty, like GDPR or CCPA, which introduce new complexity and the need for more controls as they scale globally.&nbsp;</p>\n  <p>As these companies map out their cloud journeys, multi-cloud and hybrid strategies are the default. What’s most exciting to see is how they’re looking to transform their business through new data-driven applications that deliver always-on availability, local experiences at a global level, and synchronization across all channels.&nbsp;</p>\n  <p>These trends are top of mind as customers embark on their journey to cloud, and there is no single path that’s right for everyone. We believe in meeting customers where they are so they can reap the benefits of the cloud and catalyze what they can deliver to their business.&nbsp;&nbsp;</p>\n  <p><b>Taking a three-phase journey<br /></b>Whether it’s to increase their agility and pace of innovation, better manage costs, or entirely shut down data centers, we’re seeing customers accelerate their move to cloud and follow a three-phase journey: migration, modernization, and transformation.&nbsp;</p>\n  <p>We have customers who are trying to move as many as thousands of applications and databases to the cloud, frequently on a tight timeline. They need a fast-track approach to lift and shift what they’re running today to the cloud. This “as-is” migration already adds tremendous value, even if it doesn’t provide the full benefits of cloud-native capabilities. We’ve partnered closely with our customers to transition large database estates of both commercial and open source databases to our environment in this migration phase. Fully managed database services such as <a href=\"https://cloud.google.com/sql\">Cloud SQL</a> (offered for MySQL, PostgreSQL, and SQL Server) provide familiarity while letting customers offload the 24/7 management of their databases to Google Cloud. By adopting managed services, they can refocus their resources on moving the business forward and improving productivity, leaving the heavy lifting of ensuring a highly available environment to us. Our <a href=\"https://cloud.google.com/bare-metal\">Bare Metal Solution for Oracle workloads</a> allows customers to lower overall costs while maintaining existing investments.</p>\n  <p>Once migrated, many of our customers seek to modernize their database environments by transitioning off legacy databases and onto open source databases. The lack of licensing flexibility, high costs, and constrained deployment options highly motivate customers to make the needed investment to transition off. With open source databases having become enterprise-ready, customers are able to remove operational limitations and seamlessly handle unpredictable demand, all without compromising on performance and reliability. By modernizing, DevOps teams can better manage their development and testing cycles, push new releases faster, and improve accuracy and predictability overall.</p>\n  <p>To release new features to customers faster, Autotrader migrated their Oracle database to Cloud SQL. This meant the teams could make changes with less risk and, by moving to a managed service, AutoTrader can focus more on improving its products. After migrating, AutoTrader’s release cadence improved by over 140% (year over year) with an improved success rate of 99.87%.</p>\n  <p>For customers looking to build next-gen applications entirely in the cloud, they are in the transformation phase. This is about unlocking new possibilities and competitive differentiation for businesses. For relational workloads, <a href=\"https://cloud.google.com/spanner\">Cloud Spanner</a> leads in its ability to run at global scale with strong consistency, all while delivering industry-leading reliability (5 9s). For non-relational workloads, this same global consistency with 5 9s availability is achieved with <a href=\"https://firebase.google.com/docs/firestore\" target=\"_blank\">Cloud Firestore</a>—enabling an unmatched experience to build mobile, web, and IoT applications with live synchronization. Building transformational applications goes beyond any specific service; it’s about how they can work together to deliver game-changing benefits. Cloud-native databases integrate with other services in Google Cloud, enabling you to run your IT systems and apps as microservices and apply advanced analytics and AI to your data. In just one example, social media platform ShareChat saw their traffic grow 500% in the span of just a few days, and were able to scale Spanner horizontally with zero lines of code change.</p>\n  <p>Wherever the customer is in this journey, we’re focused at Google Cloud on supporting them with the services, best practices, and tooling ecosystem to enable their success. Whether they’re all-in on transformation, or just looking to take the first step, we enable them to mix and match these options to migrate at the pace that’s realistic and manageable for their teams and organization.&nbsp;</p>\n  <p>This week at <a href=\"https://cloud.withgoogle.com/next/sf/sessions#data-management-databases\" target=\"_blank\">Google Cloud Next ‘20: OnAir</a>, check out expert sessions and demos to learn more about our entire suite of database offerings. And explore how organizations rely on Google Cloud databases to power their most critical applications, drive new innovation, and build better experiences for their customers.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Wed, 19 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"7c12635f884214045116c50339427596","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"3 reasons to consider Cloud Spanner for your next project","link":"https://cloud.google.com/blog/products/databases/spanner-relational-database-for-all-size-applications-faqs/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>A database is a key architectural component of almost every application. When you design an application, you’ll invariably need to durably store application data. Without persisting data to a shared database, there are neither options for application scalability nor for upgrades to the underlying hardware. More disastrous, any data will be immediately lost in the case of infrastructure failure.&nbsp;</p>\n  <p>With a reliable database, though, you enable application scalability and ensure data durability and consistency, service availability, and improved system supportability. A database is a key architectural component of almost every application.</p>\n  <p>Google Cloud’s <a href=\"https://cloud.google.com/spanner\">Spanner database</a> was built to fulfill needs around storing structured data for products here at Google and at our many cloud customers. Spanner is part of Google's core infrastructure, trusted to safeguard our business—so you can, too, regardless of your industry or use case.</p>\n  <p>Before Spanner, our products predominantly used sharded MySQL for database use cases where transactions were needed. The goal of the development effort, as described in the <a href=\"https://research.google/pubs/pub39966/\" target=\"_blank\">Spanner paper</a>, was to create a data storage service for those applications that have complex, evolving schemas, or those that want strong consistency in the presence of wide-area replication.</p>\n  <p>One of the first concepts that comes up when considering Spanner is its ability to scale to arbitrarily large database sizes. Spanner does indeed support Google applications (such as Gmail and YouTube) that provide features for billions of our users, so scalability must be a first-class feature.&nbsp;</p>\n  <p>In this post, we’ll explore how Spanner is designed for applications that operate at any scale, big or small, across a variety of use cases; how it provides a low-barrier to entry for developers; and how it lowers total cost of ownership (TCO). Here’s what you need to know.</p>\n  <h3>Start anywhere and scale as you grow</h3>\n  <p>Spanner can handle data volumes at a massive scale, so it’s useful for applications of many sizes, not just those large ones. Further, your organization can benefit from standardizing on a single database engine for all workloads that require an RDBMS. Spanner provides a solid foundation for all kinds of applications with its combination of familiar relational database management system (RDBMS) features, such as <a href=\"https://cloud.google.com/spanner/docs/sql-best-practices\">ANSI 2011 SQL</a>, <a href=\"https://cloud.google.com/spanner/docs/dml-best-practices\">DML</a>, <a href=\"https://cloud.google.com/spanner/docs/foreign-keys/overview\">Foreign Keys</a> and unique features such as <a href=\"https://cloud.google.com/spanner/docs/true-time-external-consistency\">strong external consistency via TrueTime</a> and high availability via <a href=\"https://cloud.google.com/spanner/docs/replication\">native synchronous replication</a>.&nbsp;</p>\n  <p>We’d like to take a moment to challenge what \"smaller scale\" may be perceived as: that smaller applications are not important, or that they do not have lofty availability goals or the need for transactional fortitude. This categorization does not indicate that an application is any less business-critical than a massive scale application. Nor does it imply that a given application will not eventually require higher scale than at its initial rollout. While your application might have a small user base or transaction volume to start, this Spanner scalability advantage should not be overlooked. An application designed with a Spanner back end will not require a rewrite or any sort of database migration if success results in future data volume or transaction growth.&nbsp;</p>\n  <p>For example, if you are a gaming company developing the next cool, groundbreaking game, you want to be prepared to meet user growth if the game is a runaway success on launch day.</p>\n  <p>No matter the scale of your application, there are strong benefits when you choose Spanner, including transaction support, high-availability guarantees, read-only replicas, and effortless scalability.&nbsp;</p>\n  <p><b>Transaction support and strong external consistency<br /></b>Spanner provides <a href=\"https://cloud.google.com/spanner/docs/true-time-external-consistency\">external consistency guarantees via TrueTime</a>. Spanner uses this fully redundant system of atomic clocks to obtain timestamps from what amounts to a virtual, distributed global clock. Since Spanner can apply a timestamp from a globally agreed-upon source to every transaction upon commit, the transaction commit sequence is unequivocal. External consistency requires that all transactions be executed sequentially. Spanner satisfies this strong consistency guarantee.&nbsp;</p>\n  <p>Strong consistency is required by many application types, especially those where quantities of goods or currency are maintained, and for which eventual consistency would not be at all suitable. That includes, but is not limited to, supply chain management, retail pricing and inventory management, and banking, trading, and ledger applications.</p>\n  <p>If your database does not have strong consistency, transactions must be split into separate operations. If a transaction is not atomic, that means that the transaction can partially fail. Imagine that you use a digital wallet to divide expenses, such as the cost of dinner, with friends. If a money transfer from your wallet to their wallets were not handled within a strongly consistent transaction, you could find yourself in the position where half of the transaction has failed: the funds are in neither your nor your friend's wallet.&nbsp;</p>\n  <p>The undesirable characteristics of eventual consistency is in the name: immediately after a database operation, the overall database state is inconsistent; only eventually will the changes be served back to all requesters. In the interim, disparate client requests may return different results. If you use a social media service, for example, you have likely experienced a lag time between pressing the button to post a picture and the moment that the image is shown on your timeline. Niantic, the creators of Pokemon GO, choose Spanner specifically to <a href=\"https://www.youtube.com/watch?time_continue=248&amp;v=TaO-GbvBonc\" target=\"_blank\">avoid this type of inconsistency in their social application</a>.</p>\n  <p>You can find more detail in <a href=\"https://cloud.google.com/blog/products/gcp/why-you-should-pick-strong-consistency-whenever-possible\">this blog post on strong consistency</a>. Essentially, what we’ve learned at Google is that application code is simpler and development schedules are shorter when developers can rely on underlying data stores to handle complex transaction processing and keeping data ordered. To <a href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf\" target=\"_blank\">quote the original Spanner paper</a>, “we believe it is better to have application programmers deal with performance problems due to overuse of transactions as bottlenecks arise, rather than always coding around the lack of transactions.”</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Spanner Regions - 2020-07-01.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_Regions_-_2020-07-01.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p><b>High-availability guarantees<br /></b>Spanner offers up to 99.999% availability with zero downtime for planned maintenance and schema changes. Spanner is a fully managed service, which means you don’t need to do any maintenance. Automatic software updates and instance optimizations happen in the background. This is achieved without any maintenance windows. Moreover, in case there is a hardware failure, your database will seamlessly recover without downtime.</p>\n  <p>A Spanner instance provides this high availability via synchronous replication between three replicas in independent zones within a single cloud region for regional instances, and between at least four replicas in independent zones across two cloud regions for multi-region instances. Spanner regional instances are <a href=\"https://cloud.google.com/spanner/docs/instances#regional_configurations\">available in various regions</a> in our Asia Pacific, Americas, and Europe, Middle East and Africa geographies; multi-region instances are offered <a href=\"https://cloud.google.com/spanner/docs/instances#configs-multi-region\">in various combinations of regions</a> across the globe.</p>\n  <p>This protects your application from both infrastructure and zone failure for regional instance configurations, and region failure for multi-regional instance configurations.</p>\n  <p><b>Read-only replicas<br /></b>If you’re working with read requests that can <a href=\"https://cloud.google.com/spanner/docs/replication#benefits_of_cloud_spanner_replication\">tolerate a minor amount of data staleness</a>, you can take better advantage of the computing power made available by these replicas and receive results with lower average read latency. This reduction of latency can be significant if you are using a multi-region instance configuration with replicas in geographic proximity to your application client.</p>\n  <p>For queries that can accept this constraint, replicas are able to provide direct responses to your <a href=\"https://cloud.google.com/spanner/docs/reads#read_types\">stale read</a> queries without consulting the read-write replica (the split leader). In the case of multi-region instance configurations, the replicas may be much closer geographically to the application client, which can markedly improve the read performance.&nbsp;</p>\n  <p>This capability is comparable to horizontal scaling that’s achieved when traditional RDBMS topologies are deployed with asynchronous read replicas. However, unlike a typical relational database, Spanner delivers this feature without incurring additional operational or management overhead.</p>\n  <p><b>Effortless horizontal upscaling and downscaling<br /></b>Spanner decouples compute resources from data storage, which makes it possible to increase, decrease, or reallocate the pool of processing resources without any changes to the underlying storage. This is not possible with traditional open source or cloud-based relational database engines.</p>\n  <p>This means that with a single click or API call, horizontal upscaling is possible so you can serve higher operations per second capacity as required by your application, even if data throughput remains low. Moreover, the additional compute resources added can process both reads and writes.&nbsp;</p>\n  <p>Scaling down is just as simple. Spanner provides this capability at the press of a button, as instance nodes can be added or removed easily as your needs change, and these changes take effect in just a few seconds.</p>\n  <p>In other databases, both relational and NoSQL, significant effort is required to grow a cluster horizontally to support additional write capacity. Further, it may not be straightforward, or even possible, to remove the capacity once added.</p>\n  <h3>Spanner stands out as a general-use database</h3>\n  <p>The relational database is based on concepts outlined in a <a href=\"https://dl.acm.org/doi/10.1145/362384.362685\" target=\"_blank\">1970 paper written by E.F. Codd</a>, and despite being the oldest continually used database technology, the RDBMS retains its position as the database of choice for most new projects.&nbsp;</p>\n  <p>The relational database is trusted technology and many successful companies have published lore relating to their initial choice of MySQL or PostgreSQL. Companies choose the technology because developers know SQL, and because the relational model is flexible during the product development process. (To the point made earlier, it is worth mentioning that in many cases, these origin stories go on to discuss the <a href=\"https://www.quora.com/q/quoraengineering/MySQL-sharding-at-Quora\" target=\"_blank\">extreme management effort</a> associated with relational databases once <a href=\"https://gigaom.com/2011/12/06/facebook-shares-some-secrets-on-making-mysql-scale/\" target=\"_blank\">data volumes exceed an unmanageable level</a>.)</p>\n  <p>Of course, with Spanner, there are more abstract concepts involved. Spanner is a distributed database, and its strong external consistency is provided by a robust system featuring redundant local and remote atomic clocks located on the server racks and available via GPS signal, respectively. Yet, it still presents the familiar ANSI SQL compliant interface of a relational database. As a result, application developers can quickly achieve proficiency.&nbsp;</p>\n  <p>The database technology has proven its worth for countless applications at Google—internal and external, big and small. Spanner is firmly seated as a foundational technology that enables a low barrier of entry for developers, and thus the freedom to try new ideas.&nbsp;</p>\n  <p>While our user bases can be extremely large and transaction volumes can be exceptionally high for some product applications, there are other less frequently used applications that serve smaller cohorts. Spanner serves as the back-end data storage service for both application categories.</p>\n  <p>And Google Cloud customers across various verticals have used Spanner successfully for numerous core business use cases: gaming (<a href=\"https://cloud.google.com/customers/lucille-games/\">Lucille Games</a>), fintech (<a href=\"https://cloud.google.com/customers/vodeno/\">Vodeno</a>), healthcare (<a href=\"https://cloud.google.com/customers/maxwell-plus/\">Maxwell Plus</a>), retail (<a href=\"https://cloud.google.com/customers/l-l-bean/\">L.L.Bean</a>), technology (<a href=\"https://cloud.google.com/customers/optiva/\">Optiva</a>) and media and entertainment (<a href=\"https://cloud.google.com/customers/whisper/\">Whisper</a>). Here are examples of how those in various industries use Spanner:</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Spanner - Use Case Examples-01.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Use_Case_Examples-01.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <h3>Spanner lowers TCO with a simpler experience&nbsp;</h3>\n  <p>When considering the total cost of ownership (TCO), Spanner costs less to operate. Moreover, when you consider opportunity cost, the return on investment (ROI) can be even higher. Before you solely evaluate the operating expense of Spanner using the per-hour price, compare it to other database options by contrasting holistically the various costs of an alternate choice with the value provided by Spanner.</p>\n  <p>First, consider the cost of running a production-grade database. There are three cost categories: resource, operational, and opportunity. Resource cost is relatively straightforward to calculate as it is based on published list prices. Operational costs are somewhat more difficult to calculate, as this cost is equivalent to the number of team members required to complete various tasks. Opportunity cost calculation is less tangible, but should not be ignored. When you choose to expend organizational budget, in currency or in hours, toward one effort category, there will be less budget available for other opportunities.</p>\n  <p>For this exercise, we'll first discuss resource cost by comparing the list price of Spanner compared with that of a self-managed open source database running on virtual machines. Then, we'll compare the operational burden and cost of the same environments. Finally, we'll address some opportunity value provided by Spanner.</p>\n  <p>To start, when you consider a single database engine running on a small virtual machine, Spanner may appear costly. However, it is not recommended to run a production database on a single compute node. More likely, you will be running on a medium-sized virtual machine with sufficient memory and attached persistent disk provisioned with sufficient headroom for short- to medium-term growth.</p>\n  <p>Also likely is that you will have provisioned a high-availability database topology, which includes an online database replica with the same specifications as your production virtual machine. Further, you may maintain an additional replica database specifically for read-only workloads.&nbsp;</p>\n  <p>If this is the case, you have the compute and storage topology equivalent as provided by Spanner. You have three copies of the data, and three running virtual machines: one virtual machine to manage writes, a second as a high-availability replica, and a third to serve read-only workloads. This reflects the core philosophy behind Spanner: that you should operate with at least three replicas to ensure high availability.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Spanner - Compare topologies-01.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Compare_topologies-01.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Now, let's consider the relative list price of Spanner to that of a database running on Compute Engine. The <a href=\"https://cloud.google.com/spanner/pricing#database_storage\">list price for Spanner</a> database storage is approximately twice that of <a href=\"https://cloud.google.com/compute/disks-image-pricing#persistentdisk\">zonal persistent disk.</a> However, since you have three copies of data stored in persistent disk, the total cost will be higher.</p>\n  <p>In this topology, for the same amount of application data, Spanner database storage costs approximately one-third less than the price of traditional database storage. Additionally, with Spanner, you only pay for what you use, which saves cost since you will not need to pre-provision initially unused space. And if your data decreases in size, unlike a traditional database, no migration will be required to materialize reduced storage costs.</p>\n  <p>Compute resource price comparison is a bit more complex, as performance is dependent upon your workload. You can compare the price of your three-way replicated traditional RDBMS on production size virtual machines to an equivalent count of Spanner nodes to get a sense of the relative price.</p>\n  <p>However, the scenario does not end here. As you know, the operational cost of managing your own databases is not insignificant. Also, every operational task introduces an additional amount of risk to system uptime. Spanner was designed to provide a high level of service with a low level of operational overhead.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Spanner - Operational Cost side by side-01.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Operational_Cost_side_by_side-01.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>In most cases, the operational cost for Spanner approaches zero. To start, Spanner reduces the operational effort required to obtain and retain database backups. Spanner requires no maintenance windows or planned downtime. There is never a need for manual corruption remediation or index rebuilding with Spanner. Nor is any effort required to increase the available storage size for your database. (Unless you deem “effort” the button click to increase the instance node count.) Most important: There is no effort required (again, unless you count the button click) to achieve horizontal or vertical scaling, since Spanner automatically provides dynamic data resharding and data replication.</p>\n  <p>The Enterprise Strategy Group quantified the total cost of ownership (TCO) savings of Spanner in their report <a href=\"https://inthecloud.withgoogle.com/esg-report-19/dl-cd.html\" target=\"_blank\">Analyzing the Economic Benefits of Google Cloud Spanner Relational Database Service</a>. What they found was that due to the TCO savings and the benefits provided by improved flexibility and innovation, every customer they interviewed preferred Spanner over other database options. Spanner’s total cost of ownership is 78% lower than on-premises databases and 37% lower than other cloud options. With this reduction in operational effort, you can focus on other things that can make your business more successful. This is the opportunity value provided by Spanner.&nbsp;</p>\n  <h3>Getting started</h3>\n  <p>Spanner is incredibly powerful, but is also incredibly simple to operate. Spanner has been battle-tested at Google, and we're proud to provide this technology to customers. There are strong (pun intended) reasons why Spanner is a great choice for your next project, regardless of the workload scope or size. We choose to use Spanner internally at Google Cloud to <a href=\"https://cloud.google.com/blog/products/gcp/how-google-cloud-storage-offers-strongly-consistent-object-listing-thanks-to-spanner\">guarantee object listing in Cloud Storage</a>, and the same choice is made by our customers, such as <a href=\"https://cloud.google.com/blog/products/maps-platform/square-enix-and-colopl-bring-real-world-dragon-quest-walk\">Colopl</a>, which chose Spanner to help bring you Dragon Quest Walk. Spanner provides familiar relational semantics and query language, and shares the powerful flexibility that has made relational databases the top choice for data storage. No matter the size of your application or your business goals, there is a good chance that Spanner would make a great choice for you as well.&nbsp;</p>\n  <p><b>Learn more<br /></b>To get started with Spanner, create an <a href=\"https://cloud.google.com/spanner/\">instance</a>or try it out with a <a href=\"https://www.qwiklabs.com/focuses/1774?parent=catalog\" target=\"_blank\">Spanner Qwiklab</a>.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 16:30:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_Regions_-_2020-07-01.max-1000x1000.jpg","linkMd5":"39288f74c4507f3db18722c40ca67d0a","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn47@2020_2/2020/08/24/23-28-59-565_eb5fc03314dbfd70.webp","destWidth":1000,"destHeight":412,"sourceBytes":159168,"destBytes":23608,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_Regions_-_2020-07-01.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn47@2020_2/2020/08/24/23-28-59-565_eb5fc03314dbfd70.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Use_Case_Examples-01.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn82@2020_6/2020/08/24/23-29-25-565_66c3fc02b06b7736.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Compare_topologies-01.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn97@2020_6/2020/08/24/23-29-25-102_09cad036a0089150.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Operational_Cost_side_by_side-01.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn74@2020_4/2020/08/24/23-29-25-142_dac96decbc1e1b1c.webp"},"publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Supporting Kotlin Google Maps Platform Developers","link":"https://cloud.google.com/blog/products/maps-platform/supporting-kotlin-google-maps-platform-developers/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Ever since <a href=\"https://android-developers.googleblog.com/2017/05/android-announces-support-for-kotlin.html\" target=\"_blank\">Google announced</a> support for Kotlin on Android, Android developers are increasingly adopting Kotlin as their programming language of choice. Developers love Kotlin for how expressive it is, how it enables defensible programming through nullability support, and how it interoperates with Java. In fact, <a href=\"https://www.youtube.com/watch?v=AgPj1Q6D--c\" target=\"_blank\">the recent State of Kotlin on Android</a> survey shows that 50 percent of developers are more likely to be satisfied with Kotlin, 60 percent of pro-Android developers use Kotlin, and 70 percent of the top 1,000 apps in Google Play contain Kotlin code.</p>\n  <br />\n  <p>In support of this changing landscape of Android developers, we’ve launched Kotlin extension (KTX) libraries, Kotlin snippets throughout Google Maps Platform documentation, and Kotlin sample code on GitHub.</p>\n  <br />\n  <p><b>KTX libraries</b></p>\n  <p>KTX libraries enable you to write concise code that is more natural and familiar to the Kotlin programming language. The set of KTX libraries wrap existing Google Maps Platform Android SDKs so that you can use several Kotlin-only features such as extension functions, lambdas, named parameters, and coroutines.</p>\n  <br />\n  <p>Currently, the KTX libraries we have available are the <a href=\"https://www.youtube.com/watch?v=2XoAGd8PKJU\" target=\"_blank\">Places KTX</a> library, which offers extensions for the Places SDK for Android. And the <a href=\"https://github.com/googlemaps/android-maps-ktx\" target=\"_blank\">Maps KTX</a> library, which offers extensions for the Maps SDK for Android and our Android Utility Library. These libraries are optional integrations that enable you to use the same libraries you know and love while taking advantage of Kotlin-specific features.</p>\n  <br />\n  <p><b>Kotlin code snippets in Google Maps Platform documentation</b></p>\n  <p>Quality and functional code snippets are key to providing a good developer experience with our SDKs. As such, we’ve finished adding Kotlin snippets, alongside Java, throughout the <a href=\"https://developers.google.com/maps/documentation/android-sdk/overview\" target=\"_blank\">Maps</a> and <a href=\"https://developers.google.com/places/android-sdk/overview\" target=\"_blank\">Places</a> SDK for Android documentation. Now whenever a code snippet is presented, you should see both Java and Kotlin tabs so you can select the most relevant to your development needs.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Kotlin code library\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/pasted_image_0_5_eHDjOM7.max-1000x1000.png\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Moving forward, you can expect new Google Maps Platform code samples in our docs to always contain both Kotlin and Java snippets.</p>\n  <br />\n  <p><b>Kotlin samples on GitHub</b></p>\n  <p>Last but not least, we also provide Kotlin sample applications that demonstrate common scenarios using Google Maps Platform SDKs. These samples are available on GitHub (<a href=\"https://github.com/googlemaps/android-places-demos\" target=\"_blank\">Places</a>, <a href=\"https://github.com/googlemaps/android-samples\" target=\"_blank\">Maps</a>), which you can clone directly to your machine. Since these are open source projects, feel free to open issues for anything you’d like to see.</p>\n  <br />\n  <p>To stay up-to-date with our latest language support, make sure to follow us on <a href=\"https://twitter.com/GMapsPlatform\" target=\"_blank\">Twitter</a>. We’re excited to see what you build with Kotlin.</p>\n  <br />\n  <p><i>For more information on Google Maps Platform, <a href=\"https://cloud.google.com/maps-platform/\">visit our website</a>.</i></p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/pasted_image_0_5_eHDjOM7.max-1000x1000.png","linkMd5":"39481b8708ca8a1533940df31e2e4c51","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn36@2020_2/2020/08/24/23-28-59-849_7e8796254f5034a6.webp","destWidth":1000,"destHeight":444,"sourceBytes":128508,"destBytes":27014,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/pasted_image_0_5_eHDjOM7.max-1000x1000.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn36@2020_2/2020/08/24/23-28-59-849_7e8796254f5034a6.webp"},"publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"6 ways that G Suite helps IT admins safely use BYOD","link":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Many organizations, including Google, have moved quickly to embrace working from home. With this widespread remote work, it’s never been more important for IT admins to be certain that every device in their organization is secure, even when that device isn’t company-owned.&nbsp;</p>\n  <p>We pioneered zero-trust security through our <a href=\"https://cloud.google.com/beyondcorp\">BeyondCorp</a> strategy and leverage it to offer advanced security for G&nbsp;Suite users to protect secure access for all devices. Admins can enforce these controls across G Suite and other corporate applications and data, ensuring consistent security and user experience across your organization.</p>\n  <p>Today, we’re laying out six key controls that IT admins can use within G Suite to help keep their organizations safe when using the bring your own device approach (BYOD). You can also review our detailed security checklist <a href=\"https://support.google.com/a/answer/7422256\" target=\"_blank\">here</a>, and learn more from our course on Managing G Suite <a href=\"https://www.coursera.org/learn/managing-g-suite?\" target=\"_blank\">here</a>.&nbsp;</p>\n  <h3>Secure mobile and desktop devices with endpoint management</h3>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"1 Managing mobile devices with G Suite.gif\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_Managing_mobile_devices_with_G_Suite.gif\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Managing mobile devices with G Suite</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>BYOD devices can differ widely across an organization, with a range of OS versions, hardware modes, patch versions, and more, so it’s impossible to rely on a one-size-fits-all approach to device management. With Google <a href=\"https://support.google.com/a/answer/9852079?hl=en\" target=\"_blank\">endpoint management</a>, IT admins can easily support a variety of mobile and desktop devices by enforcing measures like minimum software versions and blocking jailbroken or rooted devices, in many cases without requiring full device rights for employee privacy.&nbsp;</p>\n  <p>When it comes to managing mobile devices, G Suite offers basic and advanced mobile device management:</p>\n  <ul>\n   <li><p>With basic mobile device management, BYOD devices are secured with baseline security features with no end user friction. Admins can enforce a passcode, get a device inventory, wipe Google accounts remotely, and even remotely install applications on Android devices.&nbsp;</p></li>\n   <li><p>With advanced mobile device management, admins can apply more policy controls over BYOD devices, and Android users can keep their personal data private and separate from their work data with Android Work Profiles. You can also allow and manage work apps on iOS and Android devices.</p></li>\n  </ul>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"2 Bringing basic coverage to desktop devices with fundamental device management.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/01-fundamental-desktop.max-1000x1000.jpg\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Bringing basic coverage to desktop devices with fundamental device management</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"3 Managing and securing Windows 10 devices with G Suite.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/02-windows-settings.max-1000x1000.jpg\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Managing and securing Windows 10 devices with G Suite</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Admins can also manage and secure desktop devices with <a href=\"https://gsuiteupdates.googleblog.com/2019/10/fundamental-device-management-admin-controls-comprehensive.html\" target=\"_blank\">fundamental device management</a> and <a href=\"https://gsuiteupdates.googleblog.com/2020/04/enhanced-security-windows-10-google-login.html\" target=\"_blank\">enhanced desktop security for Windows</a>. With fundamental device management, when a user logs into G Suite through any browser on a Windows, Mac, Chrome, or Linux device, that device will be automatically enrolled with endpoint management. This provides a base level of security to every desktop device that accesses G Suite data. With enhanced desktop security for Windows, admins can easily <a href=\"https://www.youtube.com/watch?v=4OwsmujDMYY&amp;feature=youtu.be\" target=\"_blank\">manage and secure Windows 10 devices</a> through the admin console.</p>\n  <h3>Enable secure connections without a corporate VPN using context-aware access</h3>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"4 Context-aware access.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Context-aware_access.max-1000x1000.jpg\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Context-aware access</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p><a href=\"https://support.google.com/a/answer/9275380?hl=en\" target=\"_blank\">Context-aware access</a> offers protection from unwanted access to G Suite services without the need for a VPN, and allows admins to set up different access levels based on a user’s identity and the context of the request, taking into account factors such as the country, device security status, and IP address of the request. For example, you can require BYOD devices accessing G Suite to meet encryption and password requirements, or restrict contractors from accessing G Suite from company managed Chromebooks.</p>\n  <h3>Control data access with app access control</h3>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"5 Helping protect against unwanted app access with app access control.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Helping_protect_against_unwanted_app_acc.max-1000x1000.jpg\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Helping protect against unwanted app access with app access control</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>It’s important to protect all devices in your organization—corporate or BYOD—from malicious apps trying to gain access to corporate data. Using <a href=\"https://support.google.com/a/answer/7281227?hl=en\" target=\"_blank\">app access control</a>, admins can take steps to prevent these apps from tricking users into mistakenly granting access to corporate data. With this feature, admins can choose which third-party apps are allowed to access users’ G Suite data by explicitly trusting, limiting, or blocking access for apps.</p>\n  <h3>Enforce 2-Step Verification</h3>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"6 Enforcing additional verification steps for increased assurance.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_Enforcing_additional_verification_steps_.max-1000x1000.jpg\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Enforcing additional verification steps for increased assurance</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>With <a href=\"https://support.google.com/a/answer/175197?hl=en\" target=\"_blank\">2-Step Verification</a>, admins can reduce the risk of unauthorized access by asking users for additional proof of identity when signing in. And you can now use the <a href=\"https://landing.google.com/advancedprotection/\" target=\"_blank\">Advanced Protection Program</a>—our strongest protection for users at risk of targeted attacks. With the Advanced Protection Program for the enterprise, we’ll enforce a specific set of policies for enrolled users including security key enforcement, blocking access to untrusted apps and enhanced scanning for email threats</p>\n  <p>If you choose not to use security keys for any reason, you have multiple other options to enforce 2-Step Verification on BYOD devices. For Android and iOS, you can use <a href=\"https://support.google.com/accounts/answer/7026266?co=GENIE.Platform%3DiOS&amp;hl=en#:~:text=When%20you%20sign%20in%20to,turn%20on%202%2DStep%20Verification\" target=\"_blank\">Google prompt</a>, <a href=\"https://support.google.com/accounts/answer/1066447?co=GENIE.Platform%3DAndroid&amp;hl=en\" target=\"_blank\">Google Authenticator</a>, text message, or phone call options for a second verification step.</p>\n  <h3>Prevent data loss and leakage with data loss prevention</h3>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"7 Data loss prevention helps protect sensitive data.gif\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/7_Data_loss_prevention_helps_protect_sensitive_data.gif\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Data loss prevention helps protect sensitive data</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>We know that as an admin, one of your highest priorities is to keep internal information safe and secure. That’s why we developed <a href=\"https://support.google.com/a/topic/7556687?hl=en&amp;ref_topic=7556782\" target=\"_blank\">data loss prevention (DLP)</a> policies to help protect sensitive information in <a href=\"https://support.google.com/a/answer/9646351?hl=en\" target=\"_blank\">Drive</a>, Docs, Sheets, Slides, and <a href=\"https://support.google.com/a/answer/6280516?hl=en\" target=\"_blank\">Gmail</a> from loss, misuse, or being accessed by unauthorized users. With G Suite DLP, admins can choose which types of data are sensitive and exactly how to protect them. Our controls enable easy detection of a wide variety of common <a href=\"https://support.google.com/a/answer/7047475\" target=\"_blank\">info types</a>, and administrators can supplement this with <a href=\"https://support.google.com/a/answer/9655387?hl=en&amp;ref_topic=9646660\" target=\"_blank\">custom content detectors</a> to meet their organization’s needs. You can also <a href=\"https://support.google.com/a/answer/9843931?hl=en\" target=\"_blank\">classify files in Drive automatically</a> using DLP rules (beta) to categorize your data by sensitivity levels. DLP works on all the devices in your organization, including BYOD ones, since the protection is at the data and application level.&nbsp;</p>\n  <p>In addition to DLP, you can use <a href=\"https://gsuiteupdates.googleblog.com/2020/04/ios-dxp-data-exfiltration-protection.html\" target=\"_blank\">DXP for iOS devices</a> to restrict the copy/pasting of G Suite data to other accounts, personal or otherwise. DXP for iOS can also restrict users’ ability to drag and drop files from specific apps within their G Suite account. Similarly, you can use Google endpoint management to configure Android devices to prevent data sharing between personal and work profiles.</p>\n  <h3>Make retention and eDiscovery possible on all your devices with Vault</h3>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"8 Satisfy your information governance needs with Vault.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_Satisfy_your_information_governance_need.max-1000x1000.jpg\" />\n    <figcaption class=\"article-image__caption \">\n     <div class=\"rich-text\">\n      <i>Help satisfy your information governance needs with Vault</i>\n     </div>\n    </figcaption>\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>To support your organization’s retention and eDiscovery needs, <a href=\"https://support.google.com/a/answer/2462365?hl=en\" target=\"_blank\">Vault</a> enables corporate data that’s stored in G Suite and accessed by BYOD devices to be available for all your information governance needs. No matter the owner of the device, your organization’s data stored in Gmail, Drive, Chat, Groups, Voice, and Meet are accessible to Vault.</p>\n  <p>Using the zero-trust security model, the G Suite features above work together to keep your data protected and organization secure across all devices, whether they’re corporate-owned or BYOD.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Mon, 24 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_Managing_mobile_devices_with_G_Suite.gif","linkMd5":"603bb57bb1648c51070c5cfc226154f5","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn30@2020_4/2020/08/24/23-29-23-633_087e3d1ec7592558.webp","destWidth":1000,"destHeight":500,"sourceBytes":2337914,"destBytes":714252,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_Managing_mobile_devices_with_G_Suite.gif":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn30@2020_4/2020/08/24/23-29-23-633_087e3d1ec7592558.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/01-fundamental-desktop.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn38@2020_2/2020/08/24/23-29-25-165_9867f6d0592ab640.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/02-windows-settings.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn2@2020_4/2020/08/24/23-29-25-538_e03b5e2ecec6834c.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Context-aware_access.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn93@2020_4/2020/08/24/23-29-25-097_496d140684d57759.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Helping_protect_against_unwanted_app_acc.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn20@2020_1/2020/08/24/23-29-25-571_d3928eaaa000fb81.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/6_Enforcing_additional_verification_steps_.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn65@2020_6/2020/08/24/23-29-25-120_887f4002f2a28688.webp","https://storage.googleapis.com/gweb-cloudblog-publish/original_images/7_Data_loss_prevention_helps_protect_sensitive_data.gif":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn86@2020_6/2020/08/24/23-29-34-436_0e9b925f8f8585e4.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/8_Satisfy_your_information_governance_need.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn17@2020_2/2020/08/24/23-29-25-286_f4cf4cc82c2299b8.webp"},"publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"How SAP customers can accelerate analytics in the cloud","link":"https://cloud.google.com/blog/products/sap-google-cloud/how-sap-customers-benefit-from-google-cloud-analytics-and-ml/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>These days, real-time, real-world data usually comes from multiple, disparate sources—for instance, IoT devices, messaging applications, social media, and clickstreams from web and ecommerce activity. This data is rapidly growing in variety, volume, and velocity. In <a href=\"https://www.esg-global.com/validation/esg-technical-review-move-sap-to-the-cloud-for-faster-time-to-innovation-sap-on-google-cloud-with-bigquery\" target=\"_blank\">a recent ESG survey</a>, 66% of organizations report that they are managing a petabyte of data or more, with nearly one-third (31%) managing at least 5 petabytes. Taken together, these data sources offer a tremendous opportunity to add significant business value. This is certainly true for SAP customers where the combined power of operational and other data sources has the ability to transform decision making.&nbsp;</p>\n  <p>And therein lies the challenge: This firehose of data makes it difficult to efficiently and securely manage, store, analyze, and generate robust insights. In fact, most organizations surveyed by ESG reported that they use no more than 30% of their total data for analytics purposes. So it’s no surprise that, according to SAPinsider research from May 2020, 52% of SAP customers surveyed say that their top analytics pain point is data integration.&nbsp;</p>\n  <p>In the past few years, many organizations have seen the benefits of migrating their SAP and other enterprise solutions to the public cloud—from reduced IT maintenance spend, to increased data security, to a more flexible, scalable cost structure. But the choice of public cloud provider can offer much more in the way of data integration and analytics—far beyond the capabilities of on-premises solutions. Google Cloud offers two powerful analytics solutions for SAP cloud and on-premises deployments alike: <a href=\"https://cloud.google.com/bigquery\">BigQuery</a>, our cloud data warehouse, and a suite of <a href=\"https://cloud.google.com/solutions/build-and-use-ai\">AI and machine learning tools</a>.&nbsp;</p>\n  <h3>BigQuery: Data warehousing with the power of Google Cloud</h3>\n  <p>BigQuery is a fully managed, and serverless cloud data warehouse that supports petabyte-scale projects at blazing-fast speeds, with zero operational overhead. It offers built-in machine learning with <a href=\"https://cloud.google.com/bigquery-ml/docs/bigqueryml-intro\">BigQuery ML</a> allowing users to operationalize ML models using standard SQL and supports geospatial analysis with <a href=\"https://cloud.google.com/bigquery/docs/gis-intro\">BigQuery GIS</a>.&nbsp; BigQuery automatically scales its infrastructure up or down for the best performance and separates storage from compute allowing you to&nbsp; run analytics at scale <a href=\"https://services.google.com/fh/files/blogs/esg_economic_validation_google_bigquery_vs_cloud-based-edws-september_2019.pdf\" target=\"_blank\">with a 26% to 34% lower three-year total cost of ownership (TCO)</a> than cloud data warehouse alternatives<sup>1</sup>.&nbsp;</p>\n  <p>German retailer <a href=\"https://cloud.google.com/customers/breuninger\">Breuninger</a>, which operates 11 department stores and an ecommerce site serving customers in three countries, realized its data was the key to keep evolving and innovating alongside the ever-changing needs and behaviors of its customers. As a result, it turned to Google Cloud to bring together its dispersed IT landscape, which included multiple SAP systems, and use BigQuery to analyze diverse datasets from across the business. Now that Breuninger runs reports in BigQuery instead of pulling custom SAP reports, it’s getting insights more cost-effectively and much faster—so quick, in fact, that customer data is in real time. This means more informed decision-making for Breuninger’s teams and more personalized, exciting experiences for its customers across every channel.</p>\n </div>\n</div>\n<div class=\"block-pull_quote\">\n <div class=\"uni-pull-quote h-c-page\">\n  <section class=\"h-c-grid\">\n   <div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n    <div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\">\n     <q class=\"uni-pull-quote__text\">Google Cloud integrates seamlessly with all of our IT components, helping us unite and make more sense of our data. On top of that, we’ve received excellent support from the Google Cloud team throughout our journey.</q> \n     <cite class=\"uni-pull-quote__author\"><span class=\"uni-pull-quote__author-meta\"><strong class=\"h-u-font-weight-medium\">Matthias Krenzel, Head of Data Platform Services, Breuninger</strong><br /></span></cite>\n    </div>\n   </div>\n  </section>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>The <a href=\"https://cloud.google.com/bigquery/transfer\">BigQuery Data Transfer Service</a> automates data movement from external data sources —like Google Marketing Platform, Google Ads, YouTube, and partner SaaS applications—to BigQuery on a scheduled and fully managed basis. Your analytics team can lay the foundation for a data warehouse without writing a single line of code.&nbsp; In addition, Google Cloud <a href=\"https://cloud.google.com/public-datasets\">Public Datasets</a> offer a powerful data repository of more than 100 high-demand public datasets from different industries. Google Cloud provides storage at no charge for all public datasets, and customers can query up to 1 TB of data per month at no cost. Google Cloud has partnered with leading data management and integration solution providers, such as <a href=\"https://www.informatica.com/gb/solutions/explore-ecosystems/google-cloud-platform.html\" target=\"_blank\">Informatica</a>, <a href=\"https://www.qlik.com/us/products/technology/google-cloud-platform\" target=\"_blank\">Qlik,</a> <a href=\"https://www.datavard.com/us/blog/google-cloud-platform-how-does-it-impact-sap-customers/\" target=\"_blank\">Datavard</a>, <a href=\"https://www.sap.com/products/data-intelligence.html\" target=\"_blank\">SAP</a> and <a href=\"https://www.softwareag.com/en_corporate.html\" target=\"_blank\">Software AG</a>, for a robust set of tools and solutions to extract data from SAP systems including ECC, S/4, and BW into BigQuery as the target data warehouse. Additionally, <a href=\"https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fengage.atos.net%2FGoogleCloud&amp;data=02%7C01%7Chenrik.wagner%40atos.net%7C566484b1e48e43524f6708d843052d87%7C33440fc6b7c7412cbb730e70b0198d5a%7C0%7C0%7C637333036800666430&amp;sdata=YMioEPzp8pP4bzq5VLWyl19xlvI2GKJ0hqWyg%2BMaKpg%3D&amp;reserved=0\" target=\"_blank\">Atos</a> has developed <a href=\"https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fyoutu.be%2F1oujtj78O8U&amp;data=02%7C01%7Chenrik.wagner%40atos.net%7C566484b1e48e43524f6708d843052d87%7C33440fc6b7c7412cbb730e70b0198d5a%7C0%7C0%7C637333036800666430&amp;sdata=Rz3tjXRcabVZPIgVLhlBt4wU3Xhlpa8o4ErJh5J2pVY%3D&amp;reserved=0\" target=\"_blank\">Rapid Deployment Accelerators for SAP Analytics with BigQuery.</a>&nbsp;Using pre-defined data models&nbsp; and combining master with transactional data to enable self service reporting while providing business logic that can achieve 50-70% faster development cycles at 60-75% lower cost, according to Atos. SAP data in BigQuery creates the opportunity to add external source data such as Search trends, Ads, Maps and more to drive deep business insights leveraging the built-in machine learning capabilities of BigQuery.</p>\n  <h3>Google Cloud’s AI and ML tools for analytics</h3>\n  <p>In addition to BigQuery, Google Cloud has a number of tools that let you quickly and easily integrate AI and ML into your applications for advanced analytics. <a href=\"https://cloud.google.com/products/ai/building-blocks\">Google Cloud AI Building Blocks</a> make it easy to add sight, language, conversation, and structured data into your applications. You can use proven, pre-trained APIs, or you can use <a href=\"https://cloud.google.com/automl\">Cloud AutoML</a> to create high-quality custom models with minimal effort and machine learning expertise.</p>\n  <p>Organizations with data residing in visual sources can use Google Cloud <a href=\"https://cloud.google.com/automl\">AutoML Vision</a>, an intelligent, AI-powered product that allows customers to derive learnings from images in the cloud or at the edge. Power company <a href=\"https://www.youtube.com/watch?v=lF-u7j1x0C0\" target=\"_blank\">AES</a> relies on AutoML Vision to assess damage to its hundreds of wind turbines. AES uses drones to inspect and photograph its turbines. These drones typically take 30,000 images, and each one must be examined. With Google Cloud's AutoML Vision, AES can use machine learning to auto-detect damage so that engineers can spend less time identifying damage and more time repairing it.</p>\n  <p></p>\n  <h3>Build a data-driven business</h3>Google Cloud Platform is designed to let you take your SAP cloud migration at your own pace, in your own way. You can shift your SAP applications to the cloud to take full advantage of a flexible, scalable solution that eliminates ongoing infrastructure maintenance costs; leverage&nbsp; BigQuery for your enterprise data to unlock new business value; integrate machine learning into business processes; or mix and match solutions to suit your needs now and in the future.&nbsp;\n  <p></p>\n  <p>To learn more about how SAP customers can benefit from Google Cloud analytics and machine learning solutions, visit <a href=\"http://cloud.google.com/solutions/sap\">cloud.google.com/solutions/sap</a>.&nbsp;</p>\n  <hr />\n  <i><sup>1. Source: ESG Master Survey Results, The State of Data Analytics, August 2019</sup></i>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 21:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"115b9df0fd098744263c4eea959f3f27","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Advancing telehealth with Amwell","link":"https://cloud.google.com/blog/topics/healthcare-life-sciences/google-cloud-partners-with-amwell-to-advance-telehealth/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Today, healthcare organizations are reimagining how care is delivered. While many organizations were already beginning to embrace telehealth at the start of the year, the global COVID-19 pandemic has accelerated this trend virtually overnight—for instance, <a href=\"https://www.hhs.gov/about/news/2020/07/28/hhs-issues-new-report-highlighting-dramatic-trends-in-medicare-beneficiary-telehealth-utilization-amid-covid-19.html\" target=\"_blank\">according to HHS data</a>, Medicare primary care visits delivered virtually grew from less than one percent in February of 2020 to more than 40 percent in April. And, telehealth is here to stay: A study from Frost &amp; Sullivan analysts forecasts a “<a href=\"https://www.healthcareitnews.com/news/telehealth-set-tsunami-growth-says-frost-sullivan\" target=\"_blank\">sevenfold growth in telehealth by 2025</a>.”&nbsp;</p>\n  <p>At Google Cloud, we are committed to helping the healthcare industry transform to meet today’s extraordinary challenges and to build a platform for the future that enables high quality, efficient, and cost-effective care from anywhere. A comprehensive, patient-friendly telehealth system is critical to providing high quality virtual care.&nbsp;</p>\n  <p>Imagine a not too distant future in which your visit begins with a customized greeting and relevant information in a digital waiting room. A conversational chatbot agent is immediately available to assist you, in your preferred language, by asking about your symptoms and the reason for your visit, and provides this information to your physician before she enters your virtual exam room. During your appointment, you continue to speak in your preferred language to your physician, while cloud-based artificial intelligence (AI) provides live, translated captioning of the conversation.&nbsp;</p>\n  <p>Before, during, and after the appointment, AI and conversational agents simplify, automate, or offload your providers’ routine tasks, such as filling out common intake forms or collecting insurance information, so they are free to focus on you. Your health information like medication, symptoms, and records from your past visits are immediately available during your telehealth visit and afterwards, your medical records are immediately updated, privately and securely. Your doctor can quickly share notes, fill prescriptions, send relevant information and schedule a follow-up visit via email.</p>\n  <p>The same technology that powers this telehealth platform can also enable providers to have better, ongoing monitoring of patients in home health situations as well as for those managing chronic conditions, by leveraging sophisticated data analytics tools in the cloud to help providers monitor and flag interventions at the right time.</p>\n  <p>Today, we announced a new partnership with Amwell to help the healthcare industry transform for a world that is more reliant on telehealth, and to ensure that healthcare organizations and providers are equipped with telehealth solutions that provide holistic and secure experiences, support HIPAA compliance, are fully-integrated, and that will enable cohesive, patient-friendly journeys through the healthcare system.</p>\n  <p>Google Cloud and Amwell will closely partner to bring telehealth solutions to healthcare organizations around the world, leveraging Amwell’s telehealth platform running on Google Cloud and integrating Google Cloud’s capabilities in areas including artificial intelligence (especially natural language processing and translation services), services aimed at secure handling of healthcare data in the cloud and enabling healthcare data interoperability, as well as collaboration tools like G Suite. We’ll work together to bring these solutions to market, helping expand access to virtual care among our mutual customers and the global healthcare industry.&nbsp;</p>\n  <p>As part of this strategic partnership, Google Cloud will invest $100 million into Amwell to evolve and scale its telehealth portfolio to serve the needs of providers, insurers, and patients.&nbsp;You can read more about our partnership with Amwell <a href=\"https://cloud.google.com/press-releases/2020/0824/google-cloud-amwell\">here</a>.</p>\n  <p>Over the coming months and years, patients will expect healthcare organizations to offer a comprehensive, seamless, and friendly virtual care experience. It’s critical that organizations are thinking today about building this platform for the future. We’re committed to partnering with the healthcare industry to adapt, prepare, and thrive in the new future.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Mon, 24 Aug 2020 21:30:00 +0000","feedId":7372,"bgimg":"","linkMd5":"d62cfca4754559bb6f9419bc460be40c","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Dataflow Under the Hood: the origin story","link":"https://cloud.google.com/blog/products/data-analytics/how-cloud-batch-and-stream-data-processing-works/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p><i><b>Editor’s note</b>: This is the first blog in a three-part series examining the internal Google history that led to Dataflow, how Dataflow works as a Google Cloud service, and how it compares and contrasts with other products in the marketplace.</i>&nbsp;</p>\n  <p><a href=\"https://cloud.google.com/dataflow\">Google Cloud’s Dataflow</a>, part of our smart analytics platform, is a streaming analytics service that unifies stream and batch data processing. To get a better understanding of Dataflow, it helps to also understand its history, which starts with <a href=\"https://research.google/pubs/pub41378/\" target=\"_blank\">MillWheel</a>.&nbsp;</p>\n  <p></p>\n  <h3>A history of Dataflow</h3>Like many projects at Google, MillWheel started in 2008 with a tiny team and a bold idea. When this project started, our team (led by Paul Nordstrom), wanted to create a system that did for streaming data processing what MapReduce had done for batch data processing—provide robust abstractions and scale to massive size. In those early days, we had a handful of key internal Google customers (\n  <a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/41378.pdf\" target=\"_blank\">from Search and Ads</a>), who were driving requirements for the system and pressure-testing the latest versions.&nbsp;\n  <p></p>\n  <p>What MillWheel did was build pipelines operating on click logs to attempt to compute real-time session information in order to better understand how to improve systems like Search for our customers. Up until this point, session information was computed on a daily basis, spinning up a colossal number of machines in the wee hours of the morning to produce results in time for when engineers logged on that morning. MillWheel aimed to change that by spreading that load over the entire day, resulting in more predictable resource usage, as well as vastly improved data freshness. Since a session can be an arbitrary length of time, this Search use case helped provide early motivation for key MillWheel concepts like watermarks and timers.</p>\n  <p>Alongside this session's use case, we started working with the Google Zeitgeist team—<a href=\"https://trends.google.com/trends/\" target=\"_blank\">now Google Trends</a>—to look at an early version of trending queries from search traffic. In order to do this, we needed to compare current traffic for a given keyword to historical traffic so that we could determine fluctuations compared to the baseline. This drove a lot of the early work that we did around state aggregation and management, as well as efficiency improvements to the system, to handle cases like first-time queries or one-and-done queries that we'd never see again.</p>\n  <p>In building MillWheel, we encountered a number of challenges that will sound familiar to any developer working on streaming data processing. For one thing, it's much harder to test and verify correctness for a streaming system, since you can't just rerun a batch pipeline to see if it produces the same \"golden\" outputs for a given input. For our streaming tests, one of the early frameworks that we developed was called the \"numbers\" pipeline, which staggered inputs from 1 to 1e6 over different time delivery intervals, aggregated them, and verified the outputs at the end. Though it was a bit arduous to build, it more than paid for itself in the number of bugs it caught.&nbsp;</p>\n  <p>Dataflow represents the latest innovation in a long line of precursors at Google. The engineers who built Dataflow (co-led with Frances Perry) first experimented with streaming systems by building MillWheel, which defined some of the core semantics around timers, state management, and watermarks, but proved to be challenging to use in a number of ways. A lot of these challenges were similar to the issues that led us to build <a href=\"https://research.google/pubs/pub35650/\" target=\"_blank\">Flume</a> for users who wanted to run multiple logical MapReduce (actually map-shuffle-combine-reduce) options together. So, to meet those challenges, we experimented with a higher-level model for programming pipelines called Streaming Flume (no relation to Apache Flume). This model allowed users to reason in terms of datasets and transformations, rather than physical details like computation nodes and the streams between them.</p>\n  <p>When it came time to build something for Google Cloud, we knew that we wanted to build a system that combined the best of what we'd learned with ambitious goals for the future. Our big bet with Dataflow was to take the semantics of (batch) Flume and Streaming Flume and combine them into a single system, which unified streaming and batch semantics. Under the hood, we had a number of technologies that we could build the system on top of, which we've successfully decoupled from the semantic model of Dataflow. That has let us continue to improve this implementation over time without requiring major rewrites to user pipelines. Along the way, we've created a number of publications about our work in data processing, particularly around streaming systems. Check those out here:</p>\n  <ul>\n   <li><p><a href=\"https://research.google/pubs/pub41378/\" target=\"_blank\">Millwheel: Fault-Tolerant Stream Processing at Internet Scale</a></p></li>\n   <li><p><a href=\"https://research.google/pubs/pub43864/\" target=\"_blank\">The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing</a></p></li>\n   <li><p><a href=\"https://research.google/pubs/pub35650/\" target=\"_blank\">FlumeJava: Easy, Efficient Data-Parallel Pipelines</a></p></li>\n  </ul>\n  <p></p>\n  <h3>How Dataflow works</h3>Let's take a moment to quickly review some key concepts in Dataflow. When we say that Dataflow is a \n  <i>streaming system</i>, we mean that it processes (and can emit) records as they arrive, rather than according to some fixed threshold (e.g., record count or time window). While users can impose these fixed semantics in defining what outputs they want to see, the underlying system supports streaming inputs and outputs. Within Dataflow, a key concept is the idea of \n  <i>event time</i>, which is a timestamp that corresponds to the time when an event occurred (rather than the time at which it is processed). In order to support a number of interesting applications, it's critical for a system to support event time, so that users can ask questions like \"How many people logged on between 1am and 2am?\"\n  <p></p>\n  <p>One of the architectures that Dataflow is often compared to is the <a href=\"http://lambda-architecture.net/\" target=\"_blank\">Lambda Architecture</a>, where users run parallel copies of a pipeline (one streaming, one batch) in order to have a \"fast\" copy of (often partial) results as well as a correct one. There are a number of drawbacks to this approach, including the obvious costs (computational and operational, as well as development costs) of running two systems instead of one. It's also important to note that Lambda Architectures often use systems with very different software ecosystems, making it challenging to replicate complex application logic across both. Finally, it's non-trivial to reconcile the outputs of the two pipelines at the end. This is a key problem that we've solved with Dataflow—users write their application logic once, and can choose whether they would like fast (but potentially incomplete) results, slow (but correct) results, or both.</p>\n  <p>To help demonstrate Dataflow's advantage over Lambda Architectures, let’s consider the use case of a large retailer with online and in-store sales. These retailers would benefit from in-store BI dashboards, used by in-store employees, that could show regional and global inventory to help shoppers find what they’re looking for, and to let the retailers know what’s been popular with their customers. The dashboards could also be used to drive inventory distribution decisions from a central or regional team. In a Lambda Architecture, these systems would likely have delays in updates that are corrected later by batch processes, but before those corrections are made, they could misrepresent availability for low-inventory items, particularly during high-volume times like the holidays. Poor results in retail can lead to bad customer experiences, but in other fields like cybersecurity, they can lead to complacency and ignored intrusion alerts. With Dataflow, this data would always be up-to-date, ensuring a better experience for customers by avoiding promises of inventory that’s not available—or in cybersecurity, an alerting system that can be trusted.</p>\n  <p>That covers much of Dataflow’s origin story, but there are more interesting concepts to discuss. Be sure to check out the other blogs in our Dataflow “Under the Hood” series to learn more.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"e266a5ab4d8578252662da765e0cd381","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Dataflow Under the Hood: understanding Dataflow techniques","link":"https://cloud.google.com/blog/products/data-analytics/cloud-batch-and-stream-processing-for-analytics/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p><i><b>Editor's note</b>: This is the second blog in a three-part series examining the internal Google history that led to Dataflow, how Dataflow works as a Google Cloud service, and how it compares and contrasts with other products in the marketplace. Check out part 1: <a href=\"https://cloud.google.com/blog/products/data-analytics/how-cloud-batch-and-stream-data-processing-works\">Dataflow Under the Hood: the origin story.</a></i></p>\n  <p><a href=\"https://cloud.google.com/blog/products/data-analytics/how-cloud-batch-and-stream-data-processing-works\">In the first post in this series</a>, we explored the genesis of Dataflow within Google, and talked about how it compares to Lambda Architectures. Now, let's look a little closer at some of the key systems that power Dataflow. As mentioned in the first post, we've taken advantage of a number of technologies that we had built for previous systems, and also developed some new techniques.</p>\n  <p>The origins of our timer system go back to the original MillWheel system, which provided users with direct access to setting timers for triggering processing logic. Conceptually, these are similar to other scheduling systems, where users set an arbitrary number of alarms, and the system is responsible for triggering those alarms at an appropriate time. For durability, we journal these timers to a backing store (like the <a href=\"https://cloud.google.com/bigtable\">Cloud Bigtable</a>database), and cache a subset of them in memory, such that all upcoming timers are in memory, and the cache can be refreshed asynchronously without putting storage reads on the hot path.&nbsp;</p>\n  <p>One subtlety for timers arises from the need to support event time timers, which depend on the completeness of data for previous stages in order to trigger. We call these completion markers <i>watermarks</i>, and they are managed by a separate component, which communicates with all the nodes that are responsible for processing a given stage in order to determine current watermark value. This watermark component then publishes these values to all relevant downstream computations, which can use the watermark to trigger event time timers. To help illustrate why this is important, let’s consider a classic IoT use case—a manufacturing line where the equipment is instrumented with sensors. These sensors will emit reams of data, and the watermarks associated with the data will help group together this data by time, or perhaps by manufacturing run, and ensure we don’t miss data in our analysis just because it came in late or out of order.</p>\n  <h3>Understanding state management</h3>\n  <p>State management in Dataflow takes advantage of a number of similar concepts as timers. State is journaled to a durable store, and cached for speed and efficiency. One thing that we learned from our experience with MillWheel was the need to provide useful abstractions for users to interact with state—some applications want to read and write the entirety of the stored state for each incoming record, but others want to read only a subset, or append to a list that is only occasionally accessed in full. In Dataflow, we've worked hard to provide relevant state abstractions that are integrated with the right caching and persistence strategies, so that the system is efficient and fast out of the box. We've also found it important to commit state modifications in an atomic operation with record processing. Many other systems take the approach of telling users to use an external state system, which is very difficult to get working correctly. Thinking back to the IoT use case we just discussed, Dataflow’s state management features would make it easy—meaning involving trivial amounts of user code—to do things like aggregating and counting equipment revolutions per minute, calculating the average temperature from a sensor over a given period of time, or determining the average deviation from a cutting or molding process without complicated retry logic for interacting with a secondary system.</p>\n  <p>A major reason for the popularity of the Lambda Architecture is the challenges of providing exactly once processing in streaming processing systems (see this <a href=\"https://cloud.google.com/blog/products/gcp/after-lambda-exactly-once-processing-in-google-cloud-dataflow-part-1\">blog series</a> for additional details). Dataflow provides exactly once processing for records by storing a fingerprint of each record that enters a given stage, and uses that to deduplicate any retries of that record. Of course, a naive strategy for this would create an unbounded number of fingerprints to check, so we use the watermark aggregator to determine when we can garbage-collect the fingerprints of records that have fully traversed the system. This system also makes ample use of caching, as well as some additional optimizations, including the use of rotating <a href=\"https://en.wikipedia.org/wiki/Bloom_filter\" target=\"_blank\">Bloom filters</a>.</p>\n  <p>One final aspect of Dataflow that we'll touch upon is its ability to support autoscaling of pipeline resources. It is able to support dynamic scaling (both up and down) of both streaming and batch pipelines by having a means of dynamically reallocating the underlying work assignments that power the system. In the case of streaming pipelines, this corresponds to a set of key ranges for each computation stage, which can be dynamically shifted, split, and merged between workers to balance out the load. The system responds to changes in usage by increasing or decreasing the overall number of nodes available, and is able to scale these independently from the disaggregated storage of timers and state. To visit our IoT factory floor example one last time, these autoscaling capabilities would mean that adding more sensors or increasing their signal frequency wouldn’t require the long operations and provisioning cycles you would have needed in the past.</p>\n  <p>Next, be sure to check out the third and final blog in this series, which aims to compare and contrast Dataflow with some of the other technologies available in the market.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Fri, 21 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"498b30c97057d8d6e1eed0d4ec270162","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Bucket list: Better log storage and management for Cloud Logging","link":"https://cloud.google.com/blog/products/management-tools/cloud-logging-adds-log-buckets-feature/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>As more organizations move to the cloud, the volume of machine generated data has grown exponentially and is increasingly important for many teams. Software engineers and SREs rely on logs to develop new applications and troubleshoot existing apps to meet reliability targets. Security operators depend on logs to find and address threats and meet compliance needs. And well structured logs provide invaluable insight that can fuel business growth. But first logs must be collected, stored and analyzed with the right tools, and many organizations have found they can be expensive to store and difficult to manage at scale.</p>\n  <p>Our goal for Google Cloud Logging has always been to make logging simpler, faster, and more useful for our customers. That means making it easy to search and analyze logs as well as providing a secure, compliant, and scalable log storage solution. Today we’re announcing a number of improvements to log storage and management, building on several recent improvements for exploring and analyzing logs. Here’s a selection of what’s new:</p>\n  <ul>\n   <li><p><b>Logs buckets</b> (beta)&nbsp;</p></li>\n   <li><p><b>Logs views</b> (alpha)&nbsp;</p></li>\n   <li><p><b>Regionalized log storage</b> (alpha)&nbsp;</p></li>\n   <li><p><b>Customizable retention</b> (generally available)</p></li>\n   <li><p><b>Cloud Logging Router</b> (generally available - new functionality in beta)</p></li>\n  </ul>\n  <ul>\n   <li><p><b>Exploring and analyzing logs</b> (generally available)</p></li>\n   <ul>\n    <li><p><a href=\"https://cloud.google.com/blog/products/management-tools/troubleshoot-issues-faster-with-cloud-logging\">New logs viewer</a></p></li>\n    <li><p><a href=\"https://cloud.google.com/blog/products/management-tools/troubleshoot-issues-faster-with-cloud-logging\">Histograms</a></p></li>\n    <li><p><a href=\"https://cloud.google.com/logging/docs/view/logs-viewer-interface#logs-field-panel\">Field explorer</a>&nbsp;</p></li>\n    <li><p><a href=\"https://cloud.google.com/logging/docs/view/advanced-queries#regular-expressions\">Regular expression</a> support&nbsp;</p></li>\n    <li><p><a href=\"https://cloud.google.com/logging/docs/view/dashboard\">Logging Dashboard</a></p></li>\n   </ul>\n  </ul>\n  <p>Cloud Logging has been deeply integrated in Google Cloud Platform from the beginning. We automatically collect logs from dozens of Google Cloud services including audit logs, which play a key role in security and compliance. These logs are available right in context from places like Compute Engine, Cloud Functions, App Engine and more to improve development velocity and troubleshooting. Our challenge was to build a logging storage solution that was flexible enough to meet many different organizational needs while preserving the in-context experience and enterprise-class security around logs.</p>\n  <p>We do this by introducing “<a href=\"https://cloud.google.com/logging/docs/buckets\">logs buckets</a>” as a first-class logs storage solution in Cloud Logging. Using logs buckets, you can centralize or subdivide your logs based on your needs. From the name, logs buckets may sound like Cloud Storage buckets, but logs buckets are built on the same logging tech stack we’ve been using to deliver your logs in real time with advanced indexing and optimizations for timestamps so that you can keep benefiting from our logs analytics features.&nbsp;</p>\n  <p>In order to support logs buckets, we’ve also augmented the <a href=\"https://cloud.google.com/logging/docs/routing/overview\">Cloud Logging router</a> to give you more control over where your logs go. Previously, there were different models to manage which logs went to Cloud Logging vs. other destinations including BigQuery, Cloud Storage and Pub/Sub. Now, you can manage all destinations consistently using log sinks, and all log sinks can also support exclusions, making it easier to configure the logs you want to the right destination. You can also now route logs from one project to another or even use <a href=\"https://cloud.google.com/logging/docs/export/aggregated_sinks\">aggregated log sinks</a> from across folders or organization level for security and ease of maintenance.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Cloud logging router.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_logging_router.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Here are some examples of solutions our alpha customers have built using logs buckets:</p>\n  <ul>\n   <li><p><b>Log centralization</b> - Centralize all logs from across an organization to a single Cloud Logging project. This solution was so popular among security teams that we’ve put together a <a href=\"https://cloud.google.com/logging/docs/central-log-storage\">dedicated user guide</a> for centralizing audit logs, but you can centralize any or all logs in your org. This allows you to identify patterns and comparisons across projects.</p></li>\n   <li><p><b>Splitting up logs from a single project for GKE multi-tenancy</b> - Send logs from one shared project to other projects owned by individual development teams. One of our alpha customers’ favorite things about logs buckets is that we do magic behind the scenes to look up where your logs are stored. That way, you can, for example, still view those logs for your Kubernetes cluster in the GKE console in project A, even if they’re stored centrally in project B. Get started with this <a href=\"https://cloud.google.com/stackdriver/docs/solutions/kubernetes-engine/multi-tenant-logging\">user guide</a>.</p></li>\n   <li><p><b>Compliance-related retention</b> - Logs buckets also allow you to take advantage of advanced management capabilities such as setting <a href=\"https://cloud.google.com/logging/docs/storage#custom-retention\">custom retention limits</a> or <a href=\"https://cloud.google.com/logging/docs/buckets#locking-logs-buckets\">locking</a> a logs bucket so that the retention cannot be modified. We’ve recently launched custom retention to GA and are excited to announce that <b>you can use custom retention through the end of March 2021 for no additional cost.</b> This gives you a chance to try out log management for your long-term compliance and analytics needs for logs without a commitment.</p></li>\n   <li><p><b>Regionalized log storage</b> - You can now keep your logs data in a specific region for compliance purposes. When you create a logs bucket, you can set the region in which you want to store your logs data. Setting the location to <code>global</code> means that it is not specified where the logs are physically stored. The logs bucket beta only supports the <code>global</code> location, but more regions are available in the regionalized logs storage alpha. <a href=\"https://forms.gle/723kUek9CfjsgupF7\" target=\"_blank\">Sign up for the alpha or to be notified when more regions are publicly available</a>.</p></li>\n  </ul>\n  <p>Another piece of feedback we hear is that you’d like to be able to configure who has access to logs based on the source project, resource type or log name. We’ve also introduced <b>log views</b> so that you can specify which logs a user should have access to, all using standard IAM controls. Logs views can help you build a system using the principle of least privilege, limiting sensitive logs to only users who need this information. While we’ve created logs views automatically for you to preserve limited access to sensitive logs, you’ll soon be able to create your own logs views based on the source project, resource type or log name. If you’d like to try it out in alpha, <a href=\"https://forms.gle/723kUek9CfjsgupF7\" target=\"_blank\">sign up here</a>.</p>\n  <h3>Getting started&nbsp;</h3>\n  <p>Having the right logs, and being able to access them easily, is essential for development and operations teams alike. We hope these new Cloud Logging features make it easier for you to find and examine the logs you need. To learn more about managing logs in Google Cloud, check out these resources:&nbsp;</p>\n  <ul>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=OPS100#infrastructure\" target=\"_blank\">OPS100 - Designing for Observability on Google Cloud</a></p></li>\n   <li><p><a href=\"https://cloud.google.com/stackdriver/docs/solutions/kubernetes-engine/multi-tenant-logging\">Multi-tenant logging on GKE</a></p></li>\n   <li><p><a href=\"https://cloud.google.com/logging/docs/central-log-storage\">Storing your organization's logs in a centralized Logs Bucket</a></p></li>\n  </ul>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Fri, 21 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_logging_router.max-1000x1000.jpg","linkMd5":"cac9f474929e5742dfdbb58380698f22","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn43@2020_5/2020/08/24/23-28-59-522_6d3543433004a955.webp","destWidth":1000,"destHeight":711,"sourceBytes":222785,"destBytes":45186,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_logging_router.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn43@2020_5/2020/08/24/23-28-59-522_6d3543433004a955.webp"},"publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Using Cloud Logging as your single pane of glass","link":"https://cloud.google.com/blog/products/identity-security/centralize-cloud-identity-logs-behind-a-single-pane-of-glass/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Logs are an essential tool for helping to secure your cloud deployments. In the <a href=\"https://cloud.google.com/blog/products/identity-security/logs-based-security-alerting-in-google-cloud\">first post in this series</a>, we explored Cloud Identity logs and how you can configure alerts for potentially malicious activity in the Cloud Identity Admin Console to make your cloud deployment more secure. Today, we’ll take it a step further and look at how you can centralize collection of these logs to view activity across your deployment in a single pane of glass.&nbsp;</p>\n  <p>Our <a href=\"https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#centralization\">best practices</a> for enterprises using Google Cloud Platform (GCP) encourage customers to centralize log management, operations, searching, and analysis in GCP’s <a href=\"https://cloud.google.com/logging\">Cloud Logging</a>. However, sometimes customers use services and applications that may not automatically or fully log to Cloud Logging. One example of this is Cloud Identity.</p>\n  <p>Fortunately, there’s a way to get Cloud Identity logs into this central repository by using a <a href=\"https://cloud.google.com/functions\">Cloud Function</a> that executes the open-source <a href=\"https://github.com/GoogleCloudPlatform/professional-services/tree/master/tools/gsuite-exporter\" target=\"_blank\">GSuite log exporter tool</a>. A <a href=\"https://cloud.google.com/scheduler\">Cloud Scheduler</a> job will trigger the execution of this Cloud Function automatically, on a user-defined cadence. Here’s a visual representation of this flow:</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Cloud Identity logs.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Identity_logs.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Google Cloud Professional Services also provides resources that can help you automate the deployment of the GCP tools involved in this solution. Even better, the services used are fully-managed: no work is required post-deployment.</p>\n  <h3>Is this solution right for me?&nbsp;</h3>\n  <p>Before proceeding, let’s decide if the tools in this post are right for your organization. Cloud Identity Premium has a feature that lets you <a href=\"https://support.google.com/a/topic/9079469\" target=\"_blank\">export Cloud Identity logs straight to BigQuery</a>. This may be sufficient if your organization only needs to analyze the logs in BigQuery. However, you may want to export the logs to Cloud Logging for retention or further processing as part of your normal logging processes.</p>\n  <p>GCP also has a <a href=\"https://cloud.google.com/logging/docs/audit/gsuite-audit-logging\">G Suite audit logging</a> feature which automatically publishes some Cloud Identity logs into Cloud Logging. You can explore which Cloud Identity logs this feature covers in the documentation. The G Suite log exporter tool we will explore in this post provides additional coverage for getting Mobile, OAuth Token, and Drive logs into Cloud Logging, and also allows the user to specify exactly which logs they want to ingest from Cloud Identity.</p>\n  <p>If either of these situations are relevant to your organization, keep reading!</p>\n  <h3>The tools we use</h3>\n  <p>The <a href=\"https://github.com/GoogleCloudPlatform/professional-services/tree/master/tools/gsuite-exporter\" target=\"_blank\">G Suite log exporter</a> is an open-source tool developed and maintained by Google Cloud Professional Services. It handles exporting data from Cloud Identity by calling G Suite’s <a href=\"https://developers.google.com/admin-sdk/reports/v1/get-start/getting-started\" target=\"_blank\">Reports API</a>. It specifies Cloud Logging on GCP as the destination for your logs, grabs the Cloud Identity logs, does some cleanup and reformatting, and writes to Cloud Logging using the Cloud Logging API.</p>\n  <p>One way to run this tool is to spin up a virtual machine using Google Compute Engine. You could import and execute the tool as a Python package and set up a cronjob that runs the tool on a cadence. We even provide a <a href=\"https://github.com/terraform-google-modules/terraform-google-gsuite-export\" target=\"_blank\">Terraform module</a> that will automate this setup for you. It seems simple enough, but there are some things you must consider if you take this path, including how to secure your VM and what project and VPC it belongs to.&nbsp;</p>\n  <p>An alternative approach is to use Google-managed services to execute this code. <a href=\"https://cloud.google.com/functions\">Cloud Functions</a> gives you a serverless platform for event-based code execution—no need to spin up or manage any resources to run the code. <a href=\"https://cloud.google.com/scheduler\">Cloud Scheduler</a> is Google’s fully managed enterprise-grade cronjob scheduler. You can integrate a Cloud Function with a Cloud Scheduler job so that your code executes automatically on a schedule, per the following steps:</p>\n  <ul>\n   <li><p>Create a Cloud Function that subscribes to a <a href=\"https://cloud.google.com/pubsub/docs/\">Cloud Pub/Sub</a> topic</p></li>\n   <li><p>Create a Pub/Sub topic to trigger that function</p></li>\n   <li><p>Create a Cloud Scheduler job that invokes the Pub/Sub trigger</p></li>\n   <li><p>Run the Cloud Scheduler job.</p></li>\n  </ul>\n  <p>We also provide open-source examples that will help you take this approach, using a <a href=\"https://github.com/GoogleCloudPlatform/professional-services/tree/master/tools/gsuite-exporter-cloud-function\" target=\"_blank\">script</a> or a <a href=\"https://github.com/terraform-google-modules/terraform-google-gsuite-export/tree/master/examples/cloud_function\" target=\"_blank\">Terraform module</a>. Post-deployment, the Cloud Function will be triggered by the recurring Cloud Scheduler job, and the GSuite log exporter tool will execute indefinitely. That’s it! You now have up-to-date Cloud Identity logs in Cloud Logging. And since we’re using fully-managed GCP services, there’s no further effort required.</p>\n  <h3>Customizing the solution</h3>\n  <p>The open-source examples above can also be customized to fit your needs. Let’s take a look at the one that uses a script.</p>\n  <p>In this example, the default <a href=\"https://github.com/GoogleCloudPlatform/professional-services/blob/master/tools/gsuite-exporter-cloud-function/deploy.sh\" target=\"_blank\">deploy.sh</a> script creates a Cloud Scheduler job that triggers the exporter tool every 15 minutes. But, let’s say your organization needs to pull logs every 5 minutes to meet security requirements. You can simply change the “--schedule” flag in this file so that the exporter tool is fired as often as you’d like. The cadence is defined in <a href=\"http://man7.org/linux/man-pages/man5/crontab.5.html\" target=\"_blank\">unix-cron format</a>.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Customizing the solution 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Customizing_the_solution_1.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>You may also want to customize <a href=\"https://github.com/GoogleCloudPlatform/professional-services/blob/master/tools/gsuite-exporter-cloud-function/main.py\" target=\"_blank\">main.py</a> to control which specific Cloud Identity logs you grab. Our example pulls every log type currently supported by the exporter tool: Admin activity, Google Drive activity, Login activity, Mobile activity, and OAuth Token activity. The log types are defined in the sync_all function call in this file. Simply edit the “applications=” line (Line 34) to customize the log types you export (see below).</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Customizing the solution 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Customizing_the_solution_2.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <h3>Next steps</h3>\n  <p>A few minutes after running the script or executing the Terraform module, you will have a Cloud Function deployed that automatically pulls the logs you want from Cloud Identity and puts them into Cloud Logging on a schedule you define. Now you can integrate them into your existing logging processes: send them to Cloud Storage for retention, to BigQuery for analysis, or to a Pub/Sub topic to be exported to a destination such as Splunk.</p>\n  <p>A Cloud Function integrated with a Cloud Scheduler job is a simple but effective way to collect Cloud Identity logs into Cloud Logging, so that your Google Cloud logs live behind a single pane of glass. The fully managed and easy-to-deploy examples we discussed today free up resources and time so your organization can further focus on keeping your cloud safe.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Fri, 21 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Identity_logs.max-1000x1000.jpg","linkMd5":"ee0bbac10d341df0024e92a426144acd","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn26@2020_1/2020/08/24/23-29-03-649_ac7d499f47eeef58.webp","destWidth":1000,"destHeight":651,"sourceBytes":143113,"destBytes":22030,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Identity_logs.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn26@2020_1/2020/08/24/23-29-03-649_ac7d499f47eeef58.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Customizing_the_solution_1.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn42@2020_2/2020/08/24/23-29-25-426_0fc688257b10fb98.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Customizing_the_solution_2.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn29@2020_5/2020/08/24/23-29-25-073_1ac97b6c11568dbd.webp"},"publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"The best of Google Cloud Next ‘20: OnAir: Data Management Week for technical practitioners","link":"https://cloud.google.com/blog/products/databases/database-sessions-and-demos-for-developers-at-next20-onair/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>It's Week 6 of Google Cloud Next ‘20: OnAir, and <a href=\"https://cloud.withgoogle.com/next/sf/sessions#data-management-databases\" target=\"_blank\">this week we’re covering all things databases</a>, from running your favorite open source database with Cloud SQL to building new enterprise solutions using Cloud Spanner. We have a lot of great content to share with you this week, so let’s dig in.</p>\n  <p>Whatever database questions you have—Should I use SQL or NoSQL? Is it horizontally scalable and disaster recovery-ready?—you can get help answering them during this week's sessions at Next OnAir and through some cool demos showing <a href=\"https://cloud.withgoogle.com/next/sf/demos?demo=602#data-management-databases\" target=\"_blank\">how to choose your database</a> and <a href=\"https://cloud.withgoogle.com/next/sf/demos?demo=603#data-management-databases\" target=\"_blank\">how a high availability setup</a> works (I am very proud of our team's creativity!).</p>\n  <p>After checking out some must-see sessions below, if you have questions, I’ll be hosting a live developer- and operator-focused <a href=\"https://cloudonair.withgoogle.com/events/talks-by-devrel?talk=data-management-databases-weekly-recap&amp;utm_source=google&amp;utm_medium=website&amp;utm_content=next-devrel-wk6-recap\" target=\"_blank\">recap and Q&amp;A session</a> this Friday, August 21 at 9 AM PST. Or, join our APAC team for a recap <a href=\"https://cloudonair.withgoogle.com/events/talks-by-devrel?talk=data-management-databases-weekly-recap-apac&amp;utm_source=google&amp;utm_medium=website&amp;utm_content=next-devrel-wk6-recap\" target=\"_blank\">Friday at 11 AM SGT</a>. Hope to see you then.</p>\n  <p>Personally, I am looking forward to sharing all the amazing things the Cloud SQL team did in the past year with the session:&nbsp;</p>\n  <ul>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS102#data-management-databases\" target=\"_blank\"><b>What's New With Cloud SQL</b></a>: So much good material, and the highly anticipated PITR (point in time recovery) for PostgreSQL.</p></li>\n  </ul>\n  <p>Another session we couldn't miss is this one, super useful for those using Kubernetes and maybe need a little help with the connectivity between the products:&nbsp;</p>\n  <ul>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS302#data-management-databases\" target=\"_blank\"><b>Connecting to Cloud SQL from Kubernetes</b></a>: Your application is scaling with all those nodes; how about adding your persistent data storage into Cloud SQL and taking advantage of our high-availability setup?</p></li>\n  </ul>\n  <p>Speaking of Kubernetes, we couldn't let the cloud-native databases be forgotten:</p>\n  <ul>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS215#data-management-databases\" target=\"_blank\"><b>Simplify complex application development using Cloud Firestore</b></a><b>:</b> Get a look at how the Firestore database service makes it easy for developers to scale new and existing applications while adding real-time client data synchronization and offline mode capabilities</p></li>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS211#data-management-databases\" target=\"_blank\"><b>Modernizing HBase workloads with Cloud Bigtable</b></a><b>:</b> See how to move from your preferred NoSQL database to Bigtable using HBase.</p></li>\n  </ul>\n  <p>And if you’re still not sure which is the right tool for you, check out these sessions:</p>\n  <ul>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS214#data-management-databases\" target=\"_blank\"><b>How to Choose the Right Database For Your Workloads</b></a><b>:</b>Where you’ll see the advantages of each technology according to your needs.</p></li>\n  </ul>\n  <ul>\n   <li><p><a href=\"https://cloud.withgoogle.com/next/sf/sessions?session=DBS210#data-management-databases\" target=\"_blank\"><b>Optimally Deploy an Application Cache with Memorystore</b></a>: Caching everywhere, folks!</p></li>\n  </ul>\n  <p>Also, this week's <a href=\"https://cloudonair.withgoogle.com/events/next20-studyjam?talk=w6-talk-4&amp;utm_source=google&amp;utm_medium=blog&amp;utm_content=next-devrel-wk6-recap\" target=\"_blank\">Cloud Study Jam</a> will give you an opportunity to participate in hands-on labs on how to use BigQuery tables across different locations and create data transformation pipelines, so you can get real-world data management experience. You'll get a chance to learn more about how to prepare for <a href=\"https://cloud.google.com/certification/data-engineer\">Google Cloud's Professional Data Engineer Certification</a> as well.</p>\n  <p>One thing to remember about databases is that there’s so much you can solve with just one database, and Google Cloud has a broad set of tools to help you solve your data problems. You may have your single source of truth on a Cloud SQL instance, but want to improve your login and product catalog by adding a caching layer with Cloud Memorystore. Being able to use these products together leads to better management and productivity—essential in a modern, fast-moving world.</p>\n  <p>Next OnAir is running now until Sep. 8. You can check out the full session catalog and register at <a href=\"https://cloud.withgoogle.com/next/sf/onair#data-analytics\" target=\"_blank\">g.co/cloudnext</a>.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Wed, 19 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"501e44804756f4ac63a4dda87717463d","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739243},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"S&L Zorg: Better patient care, less IT with Chrome Enterprise and G Suite","link":"https://cloud.google.com/blog/products/chrome-enterprise/how-sl-zorg-uses-chrome-enterprise-and-g-suite/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p><i><b>Editor’s note</b>: Today’s post is by Rob Voets, Senior Advisor for S&amp;L Zorg, a caregiving organization for people with intellectual disabilities in the Netherlands. S&amp;L Zorg operates two large residences and several smaller homes in and around the West Brabant region, caring for about 360 clients. The organization has adopted a cloud-first approach, choosing Chrome OS devices and G Suite to help caregivers better serve their clients.</i></p>\n  <p>S&amp;L Zorg’s mission is to help people in our care live a happy life, as independently as they can, in our resident homes. Our caregivers make this possible, visiting clients every day to assess their health and well-being and manage their services. We want technology to support this goal. With managed Chrome OS devices and G Suite, caregivers receive the same benefits of working in the cloud as our head office staff does—without the need for an IT department to keep it all up and running.&nbsp;</p>\n  <p>S&amp;L Zorg’s 400 caregivers perform many tasks as they meet with clients. They record medication doses, because that data must be reviewed periodically by clinicians and outside organizations. Caregivers need to share important information with colleagues by sending emails and creating documents and spreadsheets—the simpler we can make these tasks, the more time caregivers can spend helping clients.</p>\n  <p>Our eyes were opened to the value of cloud applications in the early 2000s, when S&amp;L Zorg’s then-CEO worked with a startup to develop CareView, a software-as-a-service system for maintaining patient records. At that point, we decided on standards for every IT application or initiative we launched at S&amp;L Zorg: they had to be accessible in the cloud, usable in a browser, and offered as a service.&nbsp;</p>\n  <p>However, the email and calendar products we were using fell short of these goals. Caregivers found them hard to use. We were completely reliant on the software company’s team to help us troubleshoot problems, but they weren’t innovating or updating the product. We tried OpenOffice, but that wasn’t as user-friendly as we hoped. We needed a replacement for our email and productivity tools.</p>\n  <p>Once we switched to G Suite, we saw how easy it was for caregivers to adapt to the new tools. It was an easy transition for people who aren’t IT experts. Right away, the caregivers saw the benefits of sharing spreadsheets and client updates. Instead of sending 10 or 20 versions of the same document back and forth, caregivers only need one version that lives in Google Drive.</p>\n  <p>Once tools like Gmail, Google Calendar, and Google Sheets became popular with caregivers, Chromebooks and Chromeboxes were the next step. Caregivers and admin staff were using PC laptops as thin clients, accessing patient care applications through Citrix, and G Suite through Chrome Browser.&nbsp;</p>\n  <p>We had come to the point where we didn’t need servers anymore, nor did we need an IT department. We realized we could outfit caregivers and admin staff with Acer and ASUS Chromebooks (plus Chromeboxes for desk workers), and simply standardize on Chrome OS devices and Chrome Browser—which works much better with Citrix. NextNovate, our Google partner, reviewed and improved our Chrome OS security settings through Chrome Enterprise Upgrades so we could better protect patient data.&nbsp;</p>\n  <p>The amazing thing is that once we went to the cloud and added about 370 Chrome OS devices with Chrome Enterprise Upgrades, we relied on IT support less often, not more. We don’t worry about storage, because we have Google Drive. Caregivers need little to no training to use Chrome Browser and G Suite. They like the ability to work from home when needed, and get tasks done quickly: As caregivers, they want to spend more time with clients and less time staring at screens. If someone discovers a Chrome extension they’d like to use, I can easily add it remotely—or ask our NextNovate team to confirm that it’s safe.&nbsp;</p>\n  <p>As the COVID-19 pandemic took hold, we found even more reasons to lean on G Suite and Chrome OS. From the first day of working at home, our staff were able to do so easily, since we were already on G Suite. Naturally, Google Meet became a commonly used tool; the management team uses the recording feature to share meetings with people who can’t attend.</p>\n  <p>While we didn’t adopt the cloud primarily to save money, we’re happy that cost savings are an added benefit. We’ve reduced yearly IT costs by €100,000, which is about 10 percent of our annual IT budget—money that we can put back into more Chrome OS devices. We recently bought two Jamboards, one for an office meeting room and one for our client schoolroom.<br /></p>\n  <p>When caregivers use their Chromebooks to work with clients, it’s not all about spreadsheets and email. We added a Chromecast device to every location so that caregivers can call up YouTube videos on their Chromebooks and share them on the homes’ TV screens. We like to think Chrome is helping us care for our clients in more ways than simply monitoring medications.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 15:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"43d2cba9d7d9304c99975ed0e8f4bff1","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Shining a light on Anthos at Next OnAir application modernization week","link":"https://cloud.google.com/blog/topics/google-cloud-next/cant-miss-application-modernization-sessions-at-next20-onair/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Welcome to Week 7 of Google Cloud Next ‘20: OnAir! This week’s <a href=\"https://cloud.withgoogle.com/next/sf/sessions#application-modernization\" target=\"_blank\">app modernization track</a> goes live Tuesday, August 25 at 9:00am PT, and is all about containers, serverless, app development—and my personal favorite, Anthos.</p>\n  <p>App modernization is such a relevant and timely topic. Now more than ever, companies across the globe are looking at their existing applications, and considering how new technologies could help modernize them to make their businesses more efficient and streamlined. This week is all about that very challenge. As a Developer Advocate who strives to help businesses understand what app modernization can look like, I’m blocking lots of time on my calendar to watch these sessions this week!</p>\n  <p>Here are some breakout talks at the top of my watch list:</p>\n  <ol>\n   <li><p><a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=GENKEY02\" target=\"_blank\">Hands-on Keynote: Building Trust for Speedy Innovation</a>: I always love a good keynote to help dig into what this week in Next is all about. And a hands-on keynote sounds even better! As with any app modernization effort, this session focuses on the basics—“what are you really trying to accomplish?”—by tying technology innovation back to business goals such as increasing trust and speed.</p></li>\n   <li><p><a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=APP100\" target=\"_blank\">Getting Started with Anthos</a>: Containers are at the core of many app modernization journeys. With many businesses adopting hybrid- and multi-cloud strategies, they’re looking for tools that can help them create the best environments for their applications, wherever they may be. Anthos is a tool with a lot to offer in these modern, distributed environments.</p></li>\n   <li><p><a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=APP102\" target=\"_blank\">Modernizing Texas’ Best Retail Chain with Anthos</a>: There’s nothing like a customer story to understand how to use a new tool or technology in practice. Many viewers will be able to relate to how H-E-B grappled with the challenges of transforming traditional systems into modern microservice-style architectures. I’ll be looking to learn about what specific challenges H-E-B faced, why they chose the solutions they did, and what they’re planning to do next.</p></li>\n   <li><p><a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=APP107\" target=\"_blank\">Mainframe Modernization: Accelerating Legacy Transformation</a>: Mainframes are everywhere, but more and more businesses are working to understand life beyond the mainframe. A whole session addressing challenges and solutions around mainframe-to-container modernization sounds like just what this app modernization expert ordered.</p></li>\n   <li><p><a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=APP211\" target=\"_blank\">Integrating VM Workloads into Anthos Service Mesh</a>: While containers are a cornerstone of many app modernization efforts, “app modernization” is really all about the apps—and not every app belongs in a container! VM solutions are still popular and sometimes the best tool for the job. But did you know that popular technologies commonly associated with containers, like service mesh, can offer benefits to VM-based applications too?</p></li>\n   <li><p><a href=\"http://cloud.withgoogle.com/next/sf/sessions?session=APP240\" target=\"_blank\">Evolve to Zero Trust Security Model‎ with Anthos Security</a>: No app modernization journey would be complete without incorporating security. And a key component of modernizing security postures is evolving closer to a zero-trust security model. Google has a wealth of experience to draw on when it comes to modern, zero-trust application architectures and this session will share that expertise with you, and show you the tools to implement it yourself.</p></li>\n  </ol>\n  <p>These are just a few of the exciting sessions I have on my playlist. Looking through the schedule, I know I’ll be checking out a lot more as the week goes on! Let’s not forget that Next OnAir is also offering more than just the typical breakout sessions:</p>\n  <ul>\n   <li><p>Check out the <a href=\"https://youtu.be/in2L8AimfOQ\" target=\"_blank\">Explore Anthos Demo</a> for a technical demonstration of the tools Anthos uses to support modernized applications.</p></li>\n   <li><p>Get hands-on practice managing traffic routing with Istio and Envoy and how to implement continuous delivery with Jenkins in Google Kubernetes Engine (GKE) during this week’s <a href=\"https://cloudonair.withgoogle.com/events/next20-studyjam?talk=w7-talk-1&amp;utm_source=google&amp;utm_medium=blog&amp;utm_campaign=-&amp;utm_content=next-devrel-wk7-recap-anthos&amp;utm_term=-\" target=\"_blank\">Cloud Study Jam</a> workshops. You’ll also learn more about Google Cloud’s Professional Cloud DevOps Engineer certification.&nbsp;</p></li>\n   <li><p>Take your app modernization skills to the next level and compete with peers for prizes in this week’s <a href=\"https://go.qwiklabs.com/cloudheronext?utm_source=google&amp;utm_medium=blog&amp;utm_campaign=Next20Anthos\" target=\"_blank\">Cloud Hero</a> game.</p></li>\n   <li><p>Recap what you’ve learned, learn about some great content you might have missed, and take the opportunity to ask experts your questions at <a href=\"https://cloudonair.withgoogle.com/events/talks-by-devrel?utm_source=google&amp;utm_medium=blog&amp;utm_campaign=-&amp;utm_content=next-devrel-wk7-recap-anthos&amp;utm_term=-\" target=\"_blank\">Cloud Talks by DevRel</a> live on Friday, August 28th.</p></li>\n  </ul>\n  <p>We hope you have fun at Next OnAir this week! Don’t forget to check out our <a href=\"https://cloud.withgoogle.com/next/sf/sessions#application-modernization\" target=\"_blank\">other breakout talks</a> and register at <a href=\"http://g.co/cloudnext\" target=\"_blank\">g.co/cloudnext</a>.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Mon, 24 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"","linkMd5":"b42f498a6c6a1a1214ab77e51a763a5c","bgimgJsdelivr":"","metaImg":"","author":"","publishedOrCreatedDate":1598311739242},{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","title":"Synthetic data generation with Dataflow data generator flex template","link":"https://cloud.google.com/blog/products/data-analytics/dataflow-flex-template-streaming-data-generator/","description":"<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>Generating synthetic data at a very high queries per second (QPS) is a challenging task that forces developers to build and launch multiple instances of a complex multi-threaded application. Having learned that this is a very common need which helps IT teams to validate system resilience during evaluations and migrations to new platforms, we decided to build a pipeline that eliminates the heavy lifting and makes synthetic data generation easier.&nbsp;&nbsp;</p>\n  <p>We are excited to announce the launch of a new Dataflow Flex template called Streaming Data Generator that is capable of publishing unlimited high-volume JSON messages to a Google Cloud Pub/Sub topic. In this blog post, we will briefly discuss the use cases and how to use the template.</p>\n  <h3>Flex Templates</h3>\n  <p>Before diving into the details of the Streaming Data Generator template’s functionality, let’s explore Dataflow templates at a very high level:</p>\n  <p>The primary goal of <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/overview\">Dataflow templates</a> is to package Dataflow pipelines in the form of reusable artifacts that can be run in various channels (UI / CLI / REST API) and be used by different teams. In the initial version of templates (called <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/creating-templates\">traditional templates</a>), pipelines were staged on Google Cloud Storage and could be launched from the Google Cloud Console, the gcloud command-line tool or other cloud-native Google Cloud services such as Cloud Scheduler or Cloud Functions.</p>\n  <p>However, traditional templates have certain limitations:</p>\n  <ul>\n   <li><p>Lack of support for Dynamic DAGs</p></li>\n   <li><p>Many I/Os don’t implement ValueProvider Interface, which is essential to supporting runtime parameters<br /></p></li>\n  </ul>\n  <p><a href=\"https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates\">Flex templates</a> overcome these limitations. Flex templates package Dataflow pipeline code, including application dependencies, as Docker images and stage the images in Google Container Registry (GCR). Metadata specification files referencing the GCR image path and parameters details will be created and stored in Google Cloud Storage. Users can invoke a pipeline through a variety of channels (UI, gcloud, REST) by referring to the spec file. Behind the scenes, the Flex template launcher service runs Docker containers with parameters supplied by the user.</p>\n  <h3>Streaming Data Generator Overview</h3>\n  <p>The Streaming Data Generator template can be used to publish fake JSON messages based on a user-provided schema at a specified rate (measured in messages per second) to a Google Cloud Pub/Sub topic. The <a href=\"https://github.com/vincentrussell/json-data-generator\" target=\"_blank\">JSON Data Generator</a> library used by the pipeline supports various faker functions that can be associated with a schema field. The pipeline supports configuration parameters to specify message schema, specify the number of messages published per second (i.e., QPS), enable auto scaling, and more. Pipeline steps are shown below:</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Streaming Data Generator Overview.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator_Overview.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>The primary use case of the pipeline is to benchmark the consumption rate of Streaming pipelines and evaluate the resources (number of workers/machine types) required to meet the desired performance.</p>\n  <h3>Launching the Pipeline</h3>\n  <p>The pipeline can be launched either from the cloud console , gcloud command-line tool or REST API.</p>\n  <p>To launch from <code>Cloud Console</code>:</p>\n  <p>1. Go to the <a href=\"https://console.cloud.google.com/dataflow/jobs\">Dataflow page</a> in the Cloud Console.</p>\n  <p>2. Click “Create Job From Template.”</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Create Job From Template.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Create_Job_From_Template.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>3. Select “Streaming Data Generator” from the Dataflow template drop-down menu.</p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"Streaming Data Generator.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p></p>\n  <p>4. Enter the job name.</p>\n  <p>5. Enter required parameters as shown below:</p>\n  <p></p>\n </div>\n</div>\n<div class=\"block-image_full_width\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid\">\n   <figure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \">\n    <img alt=\"required parameters.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/required_parameters.max-1000x1000.jpg\" />\n   </figure>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p></p>\n  <p>6. Enter optional parameters such as autoscalingAlgorithm and maxNumWorkers, if required.</p>\n  <p>7. Click “Run Job.”</p>\n  <p></p>\n  <p>To launch using the <code>gcloud</code> command-line tool, enter the following:</p>\n </div>\n</div>\n<div class=\"block-code\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n   <div class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n    <pre><code></code></pre>\n   </div>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <p>To launch using <code>REST API</code>:</p>\n </div>\n</div>\n<div class=\"block-code\">\n <div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n   <div class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n    <pre><code></code></pre>\n   </div>\n  </div>\n </div>\n</div>\n<div class=\"block-paragraph\">\n <div class=\"rich-text\">\n  <h3>Next Steps</h3>\n  <p>We hope the template combined with Dataflow’s serverless nature will enhance your productivity and make synthetic data generation much simpler. To learn more, you can read the <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/provided-utilities#streamingdatagenerator\">documentation</a>,&nbsp; check out the <a href=\"https://github.com/GoogleCloudPlatform/DataflowTemplates/tree/master/v2/streaming-data-generator\" target=\"_blank\">code</a> or get started by running a template on <a href=\"https://console.cloud.google.com/\">Google Cloud</a>. In addition to <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/provided-utilities\">Utility</a> templates, the Dataflow team provides a wide variety of <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/provided-batch\">Batch</a> and <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming\" target=\"_blank\">Streaming</a> templates for point-to-point data transfers covering popular data sources and destinations.</p>\n </div>\n</div>","descriptionType":"text/html","publishedDate":"Thu, 20 Aug 2020 16:00:00 +0000","feedId":7372,"bgimg":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator_Overview.max-1000x1000.jpg","linkMd5":"21e3962f33dd2a02531180cf4adfec2d","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn61@2020_3/2020/08/24/23-28-59-855_216b1ad914a519d4.webp","destWidth":841,"destHeight":1000,"sourceBytes":217123,"destBytes":19850,"author":"","articleImgCdnMap":{"https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator_Overview.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn61@2020_3/2020/08/24/23-28-59-855_216b1ad914a519d4.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Create_Job_From_Template.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/24/23-29-25-548_3d5a73ba6e863117.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn34@2020_2/2020/08/24/23-29-25-155_58a54e25bf453d5a.webp","https://storage.googleapis.com/gweb-cloudblog-publish/images/required_parameters.max-1000x1000.jpg":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn10@2020_2/2020/08/24/23-29-25-068_6df20b8a2364a6d6.webp"},"publishedOrCreatedDate":1598311739242}],"record":{"createdTime":"2020-08-25 07:28:59","updatedTime":"2020-08-25 07:28:59","feedId":7372,"fetchDate":"Mon, 24 Aug 2020 23:28:59 +0000","fetchMs":139,"handleMs":895,"totalMs":37640,"newArticles":0,"totalArticles":20,"status":1,"type":0,"ip":"54.210.53.246","hostName":"us-030.herokuapp.com","requestId":"3c6e6b7a71c84e19bff772e3d73d6d18_7372","contentType":"application/xml; charset=utf-8","totalBytes":2276564,"bgimgsTotal":10,"bgimgsGithubTotal":10,"articlesImgsTotal":30,"articlesImgsGithubTotal":30,"successGithubMap":{"myreaderx14":1,"myreaderx7":1,"myreaderx15":1,"myreaderx16":1,"myreaderx6":1,"myreaderx4":1,"myreaderx10":1,"myreaderx32":1,"myreaderx11":1,"myreaderx3":1,"myreaderx33":1,"myreaderx2":1,"myreaderx12":1,"myreaderx1":1,"myreaderx13":1,"myreaderx30":2,"myreaderx31":1,"myreaderx18":1,"myreaderx19":1,"myreaderx":1,"myreaderx25":1,"myreaderx27":1,"myreaderx21":1,"myreaderx22":2,"myreaderx23":1,"myreaderx24":1,"myreaderx5oss":1,"myreaderx29":1},"failGithubMap":{}},"feed":{"createdTime":"2020-08-25 04:33:38","updatedTime":"2020-08-25 04:33:38","id":7372,"name":"Cloud Blog","url":"https://cloudblog.withgoogle.com/rss/","subscriber":null,"website":null,"icon":"https://gweb-cloudblog-publish.appspot.com/static/blog/images/google.a51985becaa6.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx61/cdn3@2020_1/2020/08/24/23-28-58-514_a33978b578f25e11.png","description":"Cloud Blog","weekly":null,"link":"https://cloud.google.com"},"noPictureArticleList":[],"tmpCommonImgCdnBytes":988990,"tmpBodyImgCdnBytes":1287574,"tmpBgImgCdnBytes":0,"extra4":{"start":1598311738203,"total":0,"statList":[{"spend":145,"msg":"获取xml内容"},{"spend":895,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":10847,"msg":"正文链接上传到cdn"}]},"extra5":30,"extra6":30,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-032.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-24.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe-58.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe66.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-015.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe70.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-011.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-54.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe69.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe62.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-019.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-003.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-023.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-027.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/virtual_CPU_resources.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":980,"destHeight":1000,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn34@2020_3/2020/08/24/23-28-59-425_8fc9ed2c11790512.webp","sourceBytes":324832,"destBytes":34718,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":993,"convertSpendMs":41,"createdTime":"2020-08-25 07:28:59","host":"us-007*","referer":"https://cloud.google.com/blog/products/compute/cpu-overcommit-for-sole-tenant-nodes-now-ga/","linkMd5ListStr":"111514d1fa52655a3898697a5a89a217,111514d1fa52655a3898697a5a89a217","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"317.2 KB","destSize":"33.9 KB","compressRate":"10.7%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Dataflow_Runner_v2.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":755,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn40@2020_1/2020/08/24/23-28-59-517_b45eccf720870303.webp","sourceBytes":266293,"destBytes":32422,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1000,"convertSpendMs":84,"createdTime":"2020-08-25 07:28:59","host":"us-53*","referer":"https://cloud.google.com/blog/products/data-analytics/multi-language-sdks-for-building-cloud-pipelines/","linkMd5ListStr":"7663d516779305535fe0911a0d63c469,7663d516779305535fe0911a0d63c469","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"260.1 KB","destSize":"31.7 KB","compressRate":"12.2%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_logging_router.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":711,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn43@2020_5/2020/08/24/23-28-59-522_6d3543433004a955.webp","sourceBytes":222785,"destBytes":45186,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1103,"convertSpendMs":69,"createdTime":"2020-08-25 07:28:59","host":"us-031*","referer":"https://cloud.google.com/blog/products/management-tools/cloud-logging-adds-log-buckets-feature/","linkMd5ListStr":"cac9f474929e5742dfdbb58380698f22,cac9f474929e5742dfdbb58380698f22","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"217.6 KB","destSize":"44.1 KB","compressRate":"20.3%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_Regions_-_2020-07-01.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":412,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn47@2020_2/2020/08/24/23-28-59-565_eb5fc03314dbfd70.webp","sourceBytes":159168,"destBytes":23608,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1134,"convertSpendMs":21,"createdTime":"2020-08-25 07:28:59","host":"us-018*","referer":"https://cloud.google.com/blog/products/databases/spanner-relational-database-for-all-size-applications-faqs/","linkMd5ListStr":"39288f74c4507f3db18722c40ca67d0a,39288f74c4507f3db18722c40ca67d0a","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"155.4 KB","destSize":"23.1 KB","compressRate":"14.8%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Container_Networking_Interface.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":586,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_2/2020/08/24/23-28-59-602_bfb5b82d165280ef.webp","sourceBytes":257055,"destBytes":36678,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1145,"convertSpendMs":30,"createdTime":"2020-08-25 07:28:59","host":"us-006*","referer":"https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine/","linkMd5ListStr":"e877a24f6e74972d4c4da08d95e7480b,e877a24f6e74972d4c4da08d95e7480b","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"251 KB","destSize":"35.8 KB","compressRate":"14.3%"},{"code":1,"isDone":false,"source":"https://img.youtube.com/vi/oK8-jejegH8/maxresdefault.jpg","sourceStatusCode":200,"destWidth":1280,"destHeight":720,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn58@2020_2/2020/08/24/23-28-59-506_4818b2ec7f4adc12.webp","sourceBytes":66099,"destBytes":33232,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1146,"convertSpendMs":24,"createdTime":"2020-08-25 07:28:59","host":"europe70*","referer":"https://cloud.google.com/blog/products/cloud-migration/google-cloud-has-acquired-stratozone/","linkMd5ListStr":"ab69514728f73b057e1fe97ce38efa08,ab69514728f73b057e1fe97ce38efa08","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"64.5 KB","destSize":"32.5 KB","compressRate":"50.3%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/pasted_image_0_5_eHDjOM7.max-1000x1000.png","sourceStatusCode":200,"destWidth":1000,"destHeight":444,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn36@2020_2/2020/08/24/23-28-59-849_7e8796254f5034a6.webp","sourceBytes":128508,"destBytes":27014,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1476,"convertSpendMs":19,"createdTime":"2020-08-25 07:28:59","host":"europe65*","referer":"https://cloud.google.com/blog/products/maps-platform/supporting-kotlin-google-maps-platform-developers/","linkMd5ListStr":"39481b8708ca8a1533940df31e2e4c51,39481b8708ca8a1533940df31e2e4c51","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"125.5 KB","destSize":"26.4 KB","compressRate":"21%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator_Overview.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":841,"destHeight":1000,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn61@2020_3/2020/08/24/23-28-59-855_216b1ad914a519d4.webp","sourceBytes":217123,"destBytes":19850,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1488,"convertSpendMs":37,"createdTime":"2020-08-25 07:28:59","host":"europe-58*","referer":"https://cloud.google.com/blog/products/data-analytics/dataflow-flex-template-streaming-data-generator/","linkMd5ListStr":"21e3962f33dd2a02531180cf4adfec2d,21e3962f33dd2a02531180cf4adfec2d","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"212 KB","destSize":"19.4 KB","compressRate":"9.1%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Identity_logs.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":651,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn26@2020_1/2020/08/24/23-29-03-649_ac7d499f47eeef58.webp","sourceBytes":143113,"destBytes":22030,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":977,"convertSpendMs":26,"createdTime":"2020-08-25 07:29:03","host":"us-027*","referer":"https://cloud.google.com/blog/products/identity-security/centralize-cloud-identity-logs-behind-a-single-pane-of-glass/","linkMd5ListStr":"ee0bbac10d341df0024e92a426144acd,ee0bbac10d341df0024e92a426144acd","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"139.8 KB","destSize":"21.5 KB","compressRate":"15.4%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_Managing_mobile_devices_with_G_Suite.gif","sourceStatusCode":200,"destWidth":1000,"destHeight":500,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn30@2020_4/2020/08/24/23-29-23-633_087e3d1ec7592558.webp","sourceBytes":2337914,"destBytes":714252,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":25611,"convertSpendMs":24179,"createdTime":"2020-08-25 07:28:59","host":"us-015*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5,603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.2 MB","destSize":"697.5 KB","compressRate":"30.6%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Customizing_the_solution_2.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":348,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn29@2020_5/2020/08/24/23-29-25-073_1ac97b6c11568dbd.webp","sourceBytes":115837,"destBytes":22742,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":868,"convertSpendMs":18,"createdTime":"2020-08-25 07:29:25","host":"us-036*","referer":"https://cloud.google.com/blog/products/identity-security/centralize-cloud-identity-logs-behind-a-single-pane-of-glass/","linkMd5ListStr":"ee0bbac10d341df0024e92a426144acd","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"113.1 KB","destSize":"22.2 KB","compressRate":"19.6%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Compare_topologies-01.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":414,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn97@2020_6/2020/08/24/23-29-25-102_09cad036a0089150.webp","sourceBytes":135417,"destBytes":26736,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":880,"convertSpendMs":20,"createdTime":"2020-08-25 07:29:25","host":"us-003*","referer":"https://cloud.google.com/blog/products/databases/spanner-relational-database-for-all-size-applications-faqs/","linkMd5ListStr":"39288f74c4507f3db18722c40ca67d0a","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"132.2 KB","destSize":"26.1 KB","compressRate":"19.7%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/required_parameters.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":467,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn10@2020_2/2020/08/24/23-29-25-068_6df20b8a2364a6d6.webp","sourceBytes":92873,"destBytes":16136,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":874,"convertSpendMs":26,"createdTime":"2020-08-25 07:29:25","host":"us-032*","referer":"https://cloud.google.com/blog/products/data-analytics/dataflow-flex-template-streaming-data-generator/","linkMd5ListStr":"21e3962f33dd2a02531180cf4adfec2d","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"90.7 KB","destSize":"15.8 KB","compressRate":"17.4%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Context-aware_access.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":605,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn93@2020_4/2020/08/24/23-29-25-097_496d140684d57759.webp","sourceBytes":160121,"destBytes":36934,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":912,"convertSpendMs":27,"createdTime":"2020-08-25 07:29:25","host":"us-015*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"156.4 KB","destSize":"36.1 KB","compressRate":"23.1%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Operational_Cost_side_by_side-01.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":481,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn74@2020_4/2020/08/24/23-29-25-142_dac96decbc1e1b1c.webp","sourceBytes":137176,"destBytes":26892,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":937,"convertSpendMs":21,"createdTime":"2020-08-25 07:29:25","host":"us-011*","referer":"https://cloud.google.com/blog/products/databases/spanner-relational-database-for-all-size-applications-faqs/","linkMd5ListStr":"39288f74c4507f3db18722c40ca67d0a","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"134 KB","destSize":"26.3 KB","compressRate":"19.6%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Intelligent_monitoring.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":449,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn90@2020_2/2020/08/24/23-29-25-115_1fef1b32b9b7481c.webp","sourceBytes":112080,"destBytes":27338,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":948,"convertSpendMs":31,"createdTime":"2020-08-25 07:29:25","host":"us-027*","referer":"https://cloud.google.com/blog/products/compute/cpu-overcommit-for-sole-tenant-nodes-now-ga/","linkMd5ListStr":"111514d1fa52655a3898697a5a89a217","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"109.5 KB","destSize":"26.7 KB","compressRate":"24.4%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/log_snippet.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":890,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn6@2020_1/2020/08/24/23-29-25-115_b1000d5f16cadc26.webp","sourceBytes":206126,"destBytes":37466,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":939,"convertSpendMs":42,"createdTime":"2020-08-25 07:29:25","host":"us-54*","referer":"https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine/","linkMd5ListStr":"e877a24f6e74972d4c4da08d95e7480b","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"201.3 KB","destSize":"36.6 KB","compressRate":"18.2%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_Enforcing_additional_verification_steps_.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":366,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn65@2020_6/2020/08/24/23-29-25-120_887f4002f2a28688.webp","sourceBytes":109045,"destBytes":24886,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":957,"convertSpendMs":17,"createdTime":"2020-08-25 07:29:25","host":"us-036*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"106.5 KB","destSize":"24.3 KB","compressRate":"22.8%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/01-fundamental-desktop.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":592,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn38@2020_2/2020/08/24/23-29-25-165_9867f6d0592ab640.webp","sourceBytes":91816,"destBytes":21202,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":954,"convertSpendMs":23,"createdTime":"2020-08-25 07:29:25","host":"us-011*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"89.7 KB","destSize":"20.7 KB","compressRate":"23.1%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/How_cross-language_transforms_work.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":611,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn69@2020_1/2020/08/24/23-29-25-205_4be73d032c19007e.webp","sourceBytes":257272,"destBytes":29448,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1005,"convertSpendMs":30,"createdTime":"2020-08-25 07:29:25","host":"us-023*","referer":"https://cloud.google.com/blog/products/data-analytics/multi-language-sdks-for-building-cloud-pipelines/","linkMd5ListStr":"7663d516779305535fe0911a0d63c469","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"251.2 KB","destSize":"28.8 KB","compressRate":"11.4%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Streaming_Data_Generator.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":522,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn34@2020_2/2020/08/24/23-29-25-155_58a54e25bf453d5a.webp","sourceBytes":128362,"destBytes":19074,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1021,"convertSpendMs":22,"createdTime":"2020-08-25 07:29:25","host":"us-023*","referer":"https://cloud.google.com/blog/products/data-analytics/dataflow-flex-template-streaming-data-generator/","linkMd5ListStr":"21e3962f33dd2a02531180cf4adfec2d","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"125.4 KB","destSize":"18.6 KB","compressRate":"14.9%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Create_Job_From_Template.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":106,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/24/23-29-25-548_3d5a73ba6e863117.webp","sourceBytes":34570,"destBytes":7182,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1311,"convertSpendMs":7,"createdTime":"2020-08-25 07:29:25","host":"europe-58*","referer":"https://cloud.google.com/blog/products/data-analytics/dataflow-flex-template-streaming-data-generator/","linkMd5ListStr":"21e3962f33dd2a02531180cf4adfec2d","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.8 KB","destSize":"7 KB","compressRate":"20.8%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Helping_protect_against_unwanted_app_acc.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":307,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn20@2020_1/2020/08/24/23-29-25-571_d3928eaaa000fb81.webp","sourceBytes":33573,"destBytes":8134,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1346,"convertSpendMs":14,"createdTime":"2020-08-25 07:29:25","host":"europe70*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.8 KB","destSize":"7.9 KB","compressRate":"24.2%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Customizing_the_solution_1.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":217,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn42@2020_2/2020/08/24/23-29-25-426_0fc688257b10fb98.webp","sourceBytes":68779,"destBytes":15138,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1357,"convertSpendMs":11,"createdTime":"2020-08-25 07:29:25","host":"europe-24*","referer":"https://cloud.google.com/blog/products/identity-security/centralize-cloud-identity-logs-behind-a-single-pane-of-glass/","linkMd5ListStr":"ee0bbac10d341df0024e92a426144acd","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"67.2 KB","destSize":"14.8 KB","compressRate":"22%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_Satisfy_your_information_governance_need.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":624,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn17@2020_2/2020/08/24/23-29-25-286_f4cf4cc82c2299b8.webp","sourceBytes":87998,"destBytes":22156,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1466,"convertSpendMs":23,"createdTime":"2020-08-25 07:29:25","host":"europe69*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"85.9 KB","destSize":"21.6 KB","compressRate":"25.2%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Using_eBPF_to_build_Kubernetes_Network_Pol.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":428,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn78@2020_2/2020/08/24/23-29-25-580_7edc954a59649118.webp","sourceBytes":141826,"destBytes":29502,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1490,"convertSpendMs":20,"createdTime":"2020-08-25 07:29:25","host":"europe-24*","referer":"https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine/","linkMd5ListStr":"e877a24f6e74972d4c4da08d95e7480b","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"138.5 KB","destSize":"28.8 KB","compressRate":"20.8%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/02-windows-settings.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":796,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn2@2020_4/2020/08/24/23-29-25-538_e03b5e2ecec6834c.webp","sourceBytes":99863,"destBytes":22454,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1502,"convertSpendMs":28,"createdTime":"2020-08-25 07:29:25","host":"europe66*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"97.5 KB","destSize":"21.9 KB","compressRate":"22.5%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/CPU_overcommit.gif","sourceStatusCode":200,"destWidth":485,"destHeight":250,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn13@2020_1/2020/08/24/23-29-25-545_964e51e084b1bea9.webp","sourceBytes":551370,"destBytes":157378,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1659,"convertSpendMs":381,"createdTime":"2020-08-25 07:29:25","host":"us-019*","referer":"https://cloud.google.com/blog/products/compute/cpu-overcommit-for-sole-tenant-nodes-now-ga/","linkMd5ListStr":"111514d1fa52655a3898697a5a89a217","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"538.4 KB","destSize":"153.7 KB","compressRate":"28.5%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/images/Spanner_-_Use_Case_Examples-01.max-1000x1000.jpg","sourceStatusCode":200,"destWidth":1000,"destHeight":544,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn82@2020_6/2020/08/24/23-29-25-565_66c3fc02b06b7736.webp","sourceBytes":282366,"destBytes":42462,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":1584,"convertSpendMs":27,"createdTime":"2020-08-25 07:29:25","host":"europe62*","referer":"https://cloud.google.com/blog/products/databases/spanner-relational-database-for-all-size-applications-faqs/","linkMd5ListStr":"39288f74c4507f3db18722c40ca67d0a","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"275.7 KB","destSize":"41.5 KB","compressRate":"15%"},{"code":1,"isDone":false,"source":"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/7_Data_loss_prevention_helps_protect_sensitive_data.gif","sourceStatusCode":200,"destWidth":1024,"destHeight":512,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn86@2020_6/2020/08/24/23-29-34-436_0e9b925f8f8585e4.webp","sourceBytes":3297603,"destBytes":694314,"targetWebpQuality":75,"feedId":7372,"totalSpendMs":10830,"convertSpendMs":9353,"createdTime":"2020-08-25 07:29:25","host":"us-040*","referer":"https://cloud.google.com/blog/products/g-suite/use-byod-safely-in-g-suite-with-these-6-controls-/","linkMd5ListStr":"603bb57bb1648c51070c5cfc226154f5","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.1 MB","destSize":"678 KB","compressRate":"21.1%"}],"successGithubMap":{"myreaderx14":1,"myreaderx7":1,"myreaderx15":1,"myreaderx16":1,"myreaderx6":1,"myreaderx4":1,"myreaderx10":1,"myreaderx32":1,"myreaderx11":1,"myreaderx3":1,"myreaderx33":1,"myreaderx2":1,"myreaderx12":1,"myreaderx1":1,"myreaderx13":1,"myreaderx30":2,"myreaderx31":1,"myreaderx18":1,"myreaderx19":1,"myreaderx":1,"myreaderx25":1,"myreaderx27":1,"myreaderx21":1,"myreaderx22":2,"myreaderx23":1,"myreaderx24":1,"myreaderx5oss":1,"myreaderx29":1},"failGithubMap":{}}