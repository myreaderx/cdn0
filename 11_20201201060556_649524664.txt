{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Support for Percona XtraDB Cluster in ProxySQL (Part One)","link":"https://www.percona.com/blog/?p=72728","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Support for Percona XtraDB Cluster in ProxySQL\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-72819\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-300x168.png\" alt=\"Support for Percona XtraDB Cluster in ProxySQL\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></p>\n<p><strong>How native ProxySQL stands in failover support (both v2.0.15 and v2.1.0)</strong></p>\n<p><span>In recent times I have been designing several solutions focused on High Availability and Disaster Recovery. Some of them using <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL</a> with group replication, some using <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtradb-cluster\">Percona XtraDB Cluster</a> (PXC). </span><span>What many of them had in common was the use of ProxySQL for the connection layer. This is because I consider the use of a layer 7 Proxy preferable, given the possible advantages provided in ReadWrite split and SQL filtering. </span></p>\n<p><span>The other positive aspect provided by ProxySQL, at least for Group Replication, is the native support which allows us to have a very quick resolution of possible node failures.</span></p>\n<p><span>ProxySQL has Galera support as well, but in the past, that had shown to be pretty unstable, and the old method to use the </span><i><span>scheduler</span></i><span> was still the best way to go.</span></p>\n<p><span>After Percona Live Online 2020 I decided to try it again and to see if at least the basics were now working fine. </span></p>\n<h2>What I Have Tested</h2>\n<p><span>I was not looking for complicated tests that would have included different levels of transaction isolation. I was instead interested in the more simple and basic ones. </span><span>My scenario was:</span></p>\n<p style=\"padding-left: 40px;\"><span>1 ProxySQL node v2.0.15  (192.168.4.191)<br />\n</span><span>1 ProxySQL node v2.1.0  (192.168.4.108)<br />\n</span><span>3 PXC 8.20 nodes (192.168.4.22/23/233) with internal network (10.0.0.22/23/33) </span></p>\n<p style=\"padding-left: 40px;\"><span>ProxySQL was freshly installed. </span></p>\n<p><span>All the commands used to <a target=\"_blank\" href=\"https://github.com/Tusamarco/blogs/tree/master/native_galera_support\">modify the configuration are </a></span>here. <span>Tests were done first using ProxySQL v2.015 then v2.1.0. Only if results diverge I will report the version and results. </span></p>\n<h2>PXC- Failover Scenario</h2>\n<p><span>As mentioned above I am going to focus on the fail-over needs, period. </span><span>I will have two different scenarios:</span></p>\n<ul>\n<li><span>Maintenance</span></li>\n<li><span>Node crash </span></li>\n</ul>\n<p><span>From the ProxySQL point of view I will have three scenarios always with a single Primary:</span></p>\n<ul>\n<li><span>Writer is NOT a reader (option 0 and 2)</span></li>\n<li><span>Writer is also a reader</span></li>\n</ul>\n<p><span>The configuration of the native support will be:</span></p><pre class=\"crayon-plain-tag\">INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.22',100,3306,10000,2000,'Preferred writer');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.23',100,3306,1000,2000,'Second preferred ');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.233',100,3306,100,2000,'Las chance');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.22',101,3306,100,2000,'last reader');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.23',101,3306,10000,2000,'reader1');    \nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.233',101,3306,10000,2000,'reader2');</pre><p><span>Galera host groups:</span></p>\n<ul>\n<li><span>Writer: 100</span></li>\n<li><span>Reader: 101</span></li>\n<li><span>Backup_writer: 102</span></li>\n<li><span>Offline_hostgroup: 9101</span></li>\n</ul>\n<p><span>Before going ahead let us analyze the Mysql Servers settings. </span><span>As you can notice I am using the </span><i><span>weight</span></i><span> attribute to indicate ProxySQL which is my preferred write. But I also use </span><i><span>weight</span></i><span> for the READ Host Group to indicate which servers should be used and how.<br />\n</span></p>\n<p><span>Given that we have that:</span></p>\n<ul>\n<li><span>Write</span>\n<ul>\n<li><span>192.168.4.22  is the preferred Primary</span></li>\n<li><span>192.168.4.23  is the first failover </span></li>\n<li><span>192.168.4.233 is the last chance </span></li>\n</ul>\n</li>\n<li><span>Read</span>\n<ul>\n<li><span>192.168.4.233/23 have the same weight and load should be balanced between the two of them</span></li>\n<li><span>The 192.168.4.22 given is the preferred writer should NOT receive the same load in reads and have a lower weight value.  </span></li>\n</ul>\n</li>\n</ul>\n<h2>The Tests</h2>\n<h3>First Test</h3>\n<p><span>The first test is to see how the cluster will behave in the case of 1 Writer and 2 readers, with the option writer_is_also_reader = 0.<br />\n</span><span>To achieve this the settings for proxysql will be:</span></p><pre class=\"crayon-plain-tag\">insert into mysql_galera_hostgroups (writer_hostgroup,backup_writer_hostgroup,reader_hostgroup, offline_hostgroup,active,max_writers,writer_is_also_reader,max_transactions_behind) values (100,102,101,9101,1,1,0,10);</pre><p><span>As soon as I load this to runtime, ProxySQL should move the nodes to the relevant Host Group. </span><b>But this is not happening</b><span>, instead, it keeps the readers in the writer HG and SHUN them.</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+\n| weight  | hostgroup_id | srv_host      | status       |\n+---------+--------------+---------------+--------------+\n| 100     | 100          | 192.168.4.233 | SHUNNED      |\n| 1000    | 100          | 192.168.4.23  | SHUNNED      |\n| 10000   | 100          | 192.168.4.22  | ONLINE       |\n| 100     | 102          | 192.168.4.233 | ONLINE       |\n| 1000    | 102          | 192.168.4.23  | ONLINE       |\n+---------+--------------+---------------+--------------+</pre><p><span>This is, of course, wrong. </span><span>But why does it happen?</span></p>\n<p><span>The reason is simple. ProxySQL is expecting to see all nodes in the reader group with READ_ONLY flag set to 1. </span></p>\n<p><span>In ProxySQL documentation we can read:<br />\n</span><span><br />\n</span><i><span>writer_is_also_reader=0: nodes with read_only=0 will be placed either in the writer_hostgroup and in the backup_writer_hostgroup after a topology change, these will be excluded from the reader_hostgroup.</span></i></p>\n<p><span>This is conceptually wrong. </span></p>\n<p><span>A PXC cluster is a </span><b>tightly coupled</b><span> replication cluster, with virtually synchronous replication. One of its benefits is to have the node “virtually” aligned with respect to the data state. </span></p>\n<p><span>In this kind of model, the cluster is data-centric, and each node shares the same data view.</span></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled.png\"><img loading=\"lazy\" class=\"wp-image-72730 size-medium aligncenter\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled-274x300.png\" alt=\"\" width=\"274\" height=\"300\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled-274x300.png 274w, https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled-137x150.png 137w, https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled-367x402.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled.png 822w\" sizes=\"(max-width: 274px) 100vw, 274px\" /></a></p>\n<p><span>What it also means is that if correctly set the nodes will be fully consistent in data READ.<br />\n</span><span><br />\nThe other characteristic of the cluster is that ANY node can become a writer anytime.  </span><span>While best practices indicate that it is better to use one Writer a time as Primary to prevent certification conflicts, this does not mean that the nodes not currently elected as Primary, should be prevented from becoming a writer.</span></p>\n<p><b>Which is exactly</b><span> what READ_ONLY flag does if activated.</span></p>\n<p><span>Not only, the need to have READ_ONLY set means that we must change it </span><b>BEFORE</b><span> we have the node able to become a writer in case of fail-over. </span></p>\n<p><span>This, in short, means the need to have either a topology manager or a script that will do that with all the relative checks and logic to be safe. Which in time of fail-over means it will add time and complexity when it&#8217;s not really needed and that goes against the concept of the tightly-coupled cluster itself.</span></p>\n<p><span>Given the above, we can say that this ProxySQL method related to writer_is_also_reader =0, as it is implemented today for Galera, is, at the best, useless. </span></p>\n<p><span>Why is it working for Group Replication? That is easy; because Group Replication internally uses a mechanism to lock/unlock the nodes when non-primary, when using the cluster in single Primary mode. That internal mechanism was implemented as a security guard to prevent random writes on multiple nodes, and also manage the READ_ONLY flag. </span></p>\n<h3>Second Test</h3>\n<p><span>Let us move on and test with </span><b>writer_is_also_reader = 2. </b><span>Again from the documentation:<br />\n</span><span><br />\n</span><i><span>writer_is_also_reader=2 : Only the nodes with read_only=0 which are placed in the backup_writer_hostgroup are also placed in the reader_hostgroup after a topology change i.e. the nodes with read_only=0 exceeding the defined max_writers.</span></i></p>\n<p><span>Given the settings as indicated above, my layout before using Galera support is:</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+\n| weight  | hostgroup_id | srv_host      | status       |\n+---------+--------------+---------------+--------------+\n| 100     | 100          | 192.168.4.233 | ONLINE       |\n| 1000    | 100          | 192.168.4.23  | ONLINE       |\n| 10000   | 100          | 192.168.4.22  | ONLINE       |\n| 10000   | 101          | 192.168.4.233 | ONLINE       |\n| 10000   | 101          | 192.168.4.23  | ONLINE       |\n| 100     | 101          | 192.168.4.22  | ONLINE       |\n+---------+--------------+---------------+--------------+</pre><p><span>After enabling Galera support:</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+\n| weight | hostgroup | srv_host      | srv_port | status  |\n+--------+-----------+---------------+----------+---------+\n| 100    | 100       | 192.168.4.233 | 3306     | SHUNNED |\n| 1000   | 100       | 192.168.4.23  | 3306     | SHUNNED |\n| 10000  | 100       | 192.168.4.22  | 3306     | ONLINE  |\n| 100    | 101       | 192.168.4.233 | 3306     | ONLINE  |\n| 1000   | 101       | 192.168.4.23  | 3306     | ONLINE  |\n| 100    | 102       | 192.168.4.233 | 3306     | ONLINE  |\n| 1000   | 102       | 192.168.4.23  | 3306     | ONLINE  |\n+--------+-----------+---------------+----------+---------+</pre><p><span>So node ending with 22 (the Primary elected) is not in the reader pool. </span><span>Which can be ok, I assume. </span></p>\n<p><span>But what is not OK at all is that the READERS have now a completely different weight. Nodes x.23 and x.233 are NOT balancing the load any longer, because the weight is not the same or the one I define. It is instead copied over from the WRITER settings. </span></p>\n<p><span>Well of course this is wrong and not what I want. </span><span>Anyhow, let&#8217;s test the READ failover.</span></p>\n<p><span>I will use sysbench read-only:</span></p><pre class=\"crayon-plain-tag\">sysbench ./src/lua/windmills/oltp_read.lua  --mysql-host=192.168.4.191 --mysql-port=6033 --mysql-user=app_test --mysql-password=test --mysql-db=windmills_s --db-driver=mysql --tables=10 --table_size=10000  --rand-type=zipfian --rand-zipfian-exp=0.5 --skip_trx=true  --report-interval=1  --mysql_storage_engine=innodb --auto_inc=off --histogram --table_name=windmills  --stats_format=csv --db-ps-mode=disable --point-selects=50 --range-selects=true --threads=50 --time=2000   run</pre><p></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from  runtime_mysql_galera_hostgroups \\G\n*************************** 1. row ***************************\n       writer_hostgroup: 100\nbackup_writer_hostgroup: 102\n       reader_hostgroup: 101\n      offline_hostgroup: 9101\n                 active: 1\n            max_writers: 1\n  writer_is_also_reader: 2\nmax_transactions_behind: 10\n                comment: NULL</pre><p><span>Test Running</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+--------+-----------+---------------+----------+---------+----------+\n| 100    | 100       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 1000   | 100       | 192.168.4.23  | 3306     | SHUNNED | 0        |\n| 10000  | 100       | 192.168.4.22  | 3306     | ONLINE  | 0        |\n| 100    | 101       | 192.168.4.233 | 3306     | ONLINE  | 1        |\n| 1000   | 101       | 192.168.4.23  | 3306     | ONLINE  | 51       |\n| 100    | 102       | 192.168.4.233 | 3306     | ONLINE  | 0        |\n| 1000   | 102       | 192.168.4.23  | 3306     | ONLINE  | 0        |\n+--------+-----------+---------------+----------+---------+----------+</pre><p><span>As indicated above the reads are not balanced.  </span><span>Removing node x.23 using <em>wsrep_reject_queries=all</em>:</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+----------+\n| weight  | hostgroup_id | srv_host\t | status       | ConnUsed |\n+---------+--------------+---------------+--------------+----------+\n| 100     | 100          | 192.168.4.233 | SHUNNED      | 0        |\n| 10000   | 100          | 192.168.4.22  | ONLINE       | 0        |\n| 100     | 101          | 192.168.4.233 | ONLINE       | 48       |\n| 100     | 102          | 192.168.4.233 | ONLINE       | 0        |\n+---------+--------------+---------------+--------------+----------+</pre><p><span>The remaining node x.233 is taking all the writes, good. </span><span>If I set wsrep_reject_queries=all also on x.233:</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+\n| weight  | hostgroup_id | srv_host      | status       |   \n+---------+--------------+---------------+--------------+\n| 10000   | 100          | 192.168.4.22  | ONLINE\t|\n| 100     | 9101         | 192.168.4.233 | SHUNNED\t|\n| 10000   | 9101         | 192.168.4.23  | ONLINE\t|\n+---------+--------------+---------------+--------------+</pre><p><span>And application failed:</span></p>\n<p><i><span>FATAL: mysql_drv_query() returned error 9001 (Max connect timeout reached while reaching hostgroup 101 after 10000ms) for query &#8216;SELECT id, millid, date,active,kwatts_s FROM windmills2 WHERE id=9364&#8217;</span></i></p>\n<p><span>Now, this may be like this by design, but I have serious difficulties understanding what the reasoning is here, given we allow a platform to fail serving while we still have a healthy server. </span></p>\n<p><span>Last but not least I am not allowed to decide WHICH the backup_writers are, ProxySQL will choose them from my writer list of servers. SO why not also include the one I have declared as Primary, at least in case of needs?  ¯\\_(ツ)_/¯</span></p>\n<h3>Third Test</h3>\n<p><span>Ok last try with </span><b>writer_is_also_reader = 1.</b></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from  runtime_mysql_galera_hostgroups \\G\n*************************** 1. row ***************************\n       writer_hostgroup: 100\nbackup_writer_hostgroup: 102\n       reader_hostgroup: 101\n      offline_hostgroup: 9101\n                 active: 1\n            max_writers: 1\n  writer_is_also_reader: 1\nmax_transactions_behind: 10\n                comment: NULL\n1 row in set (0.01 sec)</pre><p><span>And now I have:</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+----------+\n| weight  | hostgroup_id | srv_host\t | status       | ConnUsed |\n+---------+--------------+---------------+--------------+----------+\n| 100     | 100          | 192.168.4.233 | SHUNNED      | 0        |\n| 1000    | 100          | 192.168.4.23  | SHUNNED      | 0        |\n| 10000   | 100          | 192.168.4.22  | ONLINE       | 0        |\n| 100     | 101          | 192.168.4.233 | ONLINE       | 0        |\n| 1000    | 101          | 192.168.4.23  | ONLINE       | 0        |\n| 10000   | 101          | 192.168.4.22  | ONLINE       | 35       | &#60;-- :(\n| 100     | 102          | 192.168.4.233 | ONLINE\t| 0        |\n| 1000    | 102          | 192.168.4.23  | ONLINE\t| 0        |\n+---------+--------------+---------------+--------------+----------+</pre><p><span>Then remove on Reader at the time as before:</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+----------+\n| weight  | hostgroup_id | srv_host\t | status       | ConnUsed |\n+---------+--------------+---------------+--------------+----------+\n| 100     | 100          | 192.168.4.233 | SHUNNED\t| 0        |\n| 10000   | 100          | 192.168.4.22  | ONLINE       | 0        |\n| 100     | 101          | 192.168.4.233 | ONLINE\t| 0        |\n| 10000   | 101          | 192.168.4.22  | ONLINE\t| 52       | &#60;-- :(\n| 100     | 102          | 192.168.4.233 | ONLINE       | 0        |\n| 10000   | 9101         | 192.168.4.23  | ONLINE\t| 0        |\n+---------+--------------+---------------+--------------+----------+</pre><p></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+----------+\n| weight  | hostgroup_id | srv_host\t | status\t| ConnUsed |\n+---------+--------------+---------------+--------------+----------+\n| 10000   | 100          | 192.168.4.22  | ONLINE       | 0        |\n| 100     | 101          | 192.168.4.22  | ONLINE       | 39       | &#60;-- :(\n| 100     | 9101         | 192.168.4.233 | SHUNNED\t| 0        |\n| 10000   | 9101         | 192.168.4.23  | ONLINE\t| 0        |\n+---------+--------------+---------------+--------------+----------+</pre><p><span>Now as you may have already realized, the point here is that, YES I have my node x.22 (Primary) able to get the READS as well, but the node was taking the whole load from the beginning. This is because of the shift ProxySQL had done in regards to the weight. </span></p>\n<p><span>This happens because while internally ProxySQL initially populates the internal table </span><i><span>mysql_servers_incoming </span></i><span>with the data from the </span><i><span>mysql_servers</span></i><span>, after several steps that information is overwritten using the data coming from the writer also for the readers. </span></p>\n<p><span>Messing up the desired results.</span></p>\n<h3>Fourth Test</h3>\n<p><span>Failover due to maintenance. </span><span>In this case, I will set the writer pxc_maint_mode = MAINTENANCE to failover to another writer.<br />\n</span><span>The sysbench command used:<br />\n</span></p><pre class=\"crayon-plain-tag\">sysbench ./src/lua/windmills/oltp_read_write.lua  --mysql-host=192.168.4.191 --mysql-port=6033 --mysql-user=app_test --mysql-password=test --mysql-db=windmills_s --db-driver=mysql --tables=10 --table_size=10000  --rand-type=zipfian --rand-zipfian-exp=0.5 --skip_trx=false  --report-interval=1  --mysql_storage_engine=innodb --auto_inc=off --histogram --table_name=windmills  --stats_format=csv --db-ps-mode=disable --point-selects=50 --range-selects=true --threads=50 --time=2000   run</pre><p><span>After started sysbench I set the writer in maintenance mode:</span></p><pre class=\"crayon-plain-tag\">+-----------------------------+-------------+\n| Variable_name               | Value       |\n+-----------------------------+-------------+\n| pxc_encrypt_cluster_traffic | OFF         |\n| pxc_maint_mode              | MAINTENANCE |\n| pxc_maint_transition_period | 10          |\n| pxc_strict_mode             | ENFORCING   |\n+-----------------------------+-------------+</pre><p><span>ProxySQL is setting the node as SHUNNED, but is not able to pass over the connection given sysbench uses sticky connections.</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+----------+\n| weight  | hostgroup_id | srv_host      | status       | ConnUsed |\n+---------+--------------+---------------+--------------+----------+\n| 100     | 100          | 192.168.4.233 | SHUNNED      | 0        |\n| 1000    | 100          | 192.168.4.23  | ONLINE       | 0        |\n| 10000   | 100          | 192.168.4.22  | SHUNNED      | 50       |\n| 100     | 101          | 192.168.4.233 | ONLINE       | 2        |\n| 1000    | 101          | 192.168.4.23  | ONLINE       | 13       |\n| 100     | 102          | 192.168.4.233 | ONLINE       | 0        |\n| 10000   | 9101         | 192.168.4.22  | ONLINE       | 0        |\n+---------+--------------+---------------+--------------+----------+</pre><p><b>THIS IS EXPECTED!<br />\n</b><span>If your application uses sticky connections and never refreshes, you must restart the application. </span><span>Adding to the sysbench command <em>&#8211;reconnect=50</em> I can see that the connections are a shift to the new master as expected:</span></p><pre class=\"crayon-plain-tag\">+---------+--------------+---------------+--------------+----------+\n| weight  | hostgroup_id | srv_host      | status       | ConnUsed |\n+---------+--------------+---------------+--------------+----------+\n| 100     | 100          | 192.168.4.233 | SHUNNED      | 0        |\n| 1000    | 100          | 192.168.4.23  | ONLINE       | 26       | &#60;-- New Primary\n| 10000   | 100          | 192.168.4.22  | SHUNNED      | 19       | &#60;-- shift\n| 100     | 101          | 192.168.4.233 | ONLINE       | 0        |\n| 10000   | 101          | 192.168.4.23  | ONLINE       | 21       |\n| 100     | 102          | 192.168.4.233 | ONLINE       | 0        |\n| 10000   | 9101         | 192.168.4.23  | ONLINE       | 0        | &#60;-- ??\n| 10000   | 9101         | 192.168.4.22  | ONLINE       | 0        |\n+---------+--------------+---------------+--------------+----------+</pre><p><span>As we can see ProxySQL does the failover to node x.23 as expected. But it also adds the node in the HG 9101, which is supposed to host the offline servers.<br />\n</span></p>\n<p><span>So why move the Primary there? </span></p>\n<p><span>Once maintenance is over, disable <em>pxc_main_mode</em> will restore the master. In short, ProxySQL will fail-back. </span></p>\n<p><span>The whole process will be not impactful if the application is NOT using sticky connection, otherwise, the application will have to deal with:</span></p>\n<ul>\n<li><span>Error with the connection</span></li>\n<li><span>Retry cycle to re-run the drop DML</span></li>\n</ul>\n<h4><strong>Failover Because of a Crash</strong></h4>\n<p><span>To check the next case I will add &#8211;mysql-ignore-errors=all to sysbench, to be able to see how many errors I will have and for how long, when in the need to failover. </span><span>To simulate a crash I will KILL -9 the mysqld process on the writer.</span></p>\n<p><span>After Kill:</span></p><pre class=\"crayon-plain-tag\">98,50,53.00,6472.71,6070.73,221.99,179.99,1327.91,0.00,1.00 &#60;--\n99,50,0.00,2719.17,2719.17,0.00,0.00,0.00,0.00,50.00        &#60;--start\n100,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n101,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n102,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n103,50,0.00,2849.89,2549.90,193.99,106.00,0.00,0.00,0.00\n104,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n105,50,49.85,2663.99,2556.31,23.93,83.75,7615.89,0.00,6.98  &#60;-- done</pre><p><span>In this case, it takes 6 seconds for a failover.</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed | \n+--------+-----------+---------------+----------+---------+----------+\n| 100    | 100       | 192.168.4.233 | 3306     | SHUNNED | 0        | \n| 1000   | 100       | 192.168.4.23  | 3306     | ONLINE  | 48       | \n| 100    | 101       | 192.168.4.233 | 3306     | ONLINE  | 1        | \n| 1000   | 101       | 192.168.4.23  | 3306     | ONLINE  | 18       | \n| 100    | 102       | 192.168.4.233 | 3306     | ONLINE  | 0        | \n| 10000  | 9101      | 192.168.4.22  | 3306     | SHUNNED | 0        | \n+--------+-----------+---------------+----------+---------+----------+</pre><p><span>So all good here. </span><span>But during one of my tests ONLY on v2.0.15 and when using the same weight, I had the following weird behavior. </span><span>Once the failover is done I found that ProxySQL is sending connections to BOTH remaining nodes.<br />\n</span><span><br />\nCheck below the data taken one after the other nodeS start to take over, keep in mind here the PRIMARY was node 192.168.4.233:</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+--------+-----------+---------------+----------+---------+----------+\n| 10000  | 100       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 10000  | 100       | 192.168.4.23  | 3306     | ONLINE  | 10       |&#60;--\n| 10000  | 100       | 192.168.4.22  | 3306     | SHUNNED | 40       |&#60;--\n| 10000  | 101       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 10000  | 101       | 192.168.4.23  | 3306     | ONLINE  | 3        |\n| 10000  | 101       | 192.168.4.22  | 3306     | ONLINE  | 12       |\n| 10000  | 102       | 192.168.4.22  | 3306     | ONLINE  | 0        |\n+--------+-----------+---------------+----------+---------+----------+\n...\n+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+--------+-----------+---------------+----------+---------+----------+\n| 10000  | 100       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 10000  | 100       | 192.168.4.23  | 3306     | ONLINE  | 37       |&#60;--\n| 10000  | 100       | 192.168.4.22  | 3306     | SHUNNED | 13       |&#60;--\n| 10000  | 101       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 10000  | 101       | 192.168.4.23  | 3306     | ONLINE  | 7        |\n| 10000  | 101       | 192.168.4.22  | 3306     | ONLINE  | 12       |\n| 10000  | 102       | 192.168.4.22  | 3306     | ONLINE  | 0        |\n+--------+-----------+---------------+----------+---------+----------+\n...\n+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+--------+-----------+---------------+----------+---------+----------+\n| 10000  | 100       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 10000  | 100       | 192.168.4.23  | 3306     | ONLINE  | 49       |&#60;--\n| 10000  | 100       | 192.168.4.22  | 3306     | SHUNNED | 0        |&#60;--\n| 10000  | 101       | 192.168.4.233 | 3306     | SHUNNED | 0        |\n| 10000  | 101       | 192.168.4.23  | 3306     | ONLINE  | 10       |\n| 10000  | 101       | 192.168.4.22  | 3306     | ONLINE  | 10       |\n| 10000  | 102       | 192.168.4.22  | 3306     | ONLINE  | 0        |\n+--------+-----------+---------------+----------+---------+----------+</pre><p><span>In the end, only one node will remain as Primary, but for an X amount of time, both were serving also if only ONE node was declared ONLINE.</span></p>\n<h3>A Problem Along the Road… (only with v2.0.15)</h3>\n<p><span>While I was trying to “fix” the issue with the weight for READERS…</span></p>\n<p><span>Let&#8217;s say we have this:</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+--------+-----------+---------------+----------+---------+----------+\n| 10000  | 100       | 192.168.4.23  | 3306     | ONLINE  | 686      |\n| 10000  | 100       | 192.168.4.22  | 3306     | SHUNNED | 0        |\n| 10000  | 101       | 192.168.4.233 | 3306     | ONLINE  | 62       |\n| 10000  | 101       | 192.168.4.23  | 3306     | ONLINE  | 43       |\n| 10000  | 101       | 192.168.4.22  | 3306     | ONLINE  | 19       |\n| 10000  | 102       | 192.168.4.22  | 3306     | ONLINE  | 0        |\n+--------+-----------+---------------+----------+---------+----------+</pre><p><span>And I want to release some of the READ load from WRITER (currently 192.168.4.23).</span></p>\n<p><span>If I simply do:</span></p><pre class=\"crayon-plain-tag\">update mysql_servers set weight=100 where hostgroup_id=101 and hostname='192.168.4.23';</pre><p></p><pre class=\"crayon-plain-tag\">+--------------+---------------+------+-----------+--------+--------+\n| hostgroup_id | hostname      | port | gtid_port | status | weight | \n+--------------+---------------+------+-----------+--------+--------+\n| 100          | 192.168.4.23  | 3306 | 0         | ONLINE | 10000  | \n| 101          | 192.168.4.22  | 3306 | 0         | ONLINE | 10000  | \n| 101          | 192.168.4.23  | 3306 | 0         | ONLINE | 100    | \n| 101          | 192.168.4.233 | 3306 | 0         | ONLINE | 10000  | \n+--------------+---------------+------+-----------+--------+--------+</pre><p><span>Now I load it into runtime, and&#8230; if I am lucky:</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+\n| weight | hostgroup | srv_host      | srv_port | status  |\n+--------+-----------+---------------+----------+---------+\n| 10000  | 100       | 192.168.4.23  | 3306     | ONLINE  |\n| 10000  | 100       | 192.168.4.22  | 3306     | SHUNNED |\n| 10000  | 101       | 192.168.4.233 | 3306     | ONLINE  |\n| 100    | 101       | 192.168.4.23  | 3306     | ONLINE  |\n| 10000  | 101       | 192.168.4.22  | 3306     | ONLINE  |\n| 10000  | 102       | 192.168.4.22  | 3306     | ONLINE  |\n+--------+-----------+---------------+----------+---------+</pre><p><span>And then it is changed to:</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+\n| weight | hostgroup | srv_host      | srv_port | status  |\n+--------+-----------+---------------+----------+---------+\n| 10000  | 100       | 192.168.4.23  | 3306     | ONLINE  |\n| 10000  | 100       | 192.168.4.22  | 3306     | SHUNNED |\n| 10000  | 101       | 192.168.4.233 | 3306     | ONLINE  |\n| 10000  | 101       | 192.168.4.23  | 3306     | ONLINE  |\n| 10000  | 101       | 192.168.4.22  | 3306     | ONLINE  |\n| 10000  | 102       | 192.168.4.22  | 3306     | ONLINE  |\n+--------+-----------+---------------+----------+---------+</pre><p><span>As you can notice ProxySQL initially set it to the value I choose. After, it changed back to what was set in the HG 100. </span><span>But worse, is that if I am not lucky:</span></p><pre class=\"crayon-plain-tag\">+--------+-----------+---------------+----------+---------+----------+\n| weight | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+--------+-----------+---------------+----------+---------+----------+\n| 100    | 100       | 192.168.4.23  | 3306     | SHUNNED | 0        |\n| 10000  | 100       | 192.168.4.22  | 3306     | ONLINE  | 0        |\n| 10000  | 101       | 192.168.4.233 | 3306     | ONLINE  | 718      |\n| 100    | 101       | 192.168.4.23  | 3306     | ONLINE  | 0        |\n| 10000  | 101       | 192.168.4.22  | 3306     | SHUNNED | 0        |\n| 100    | 102       | 192.168.4.23  | 3306     | ONLINE  | 0        |\n+--------+-----------+---------------+----------+---------+----------+</pre><p><span>it changes the value (randomly) also for the HG 102 which will impact also the WRITER HG causing a failover. </span><span>At this point, I stopped testing. Too many things making a failover scenario too unpredictable. </span></p>\n<h3>Conclusions</h3>\n<p><span>ProxySQL has a great concept behind it and is for sure covering a really needed gap existing in the MySQL environment, optimizing and powering up the connection layer between the application layer to the data layer.  </span></p>\n<p><span>But, in regards to the Galera support, we are not there. The support provided is not only limited, it is fallacious, and could lead to serious and/or unexpected problems. </span><span>Also using the option </span><span>writer_is_also_reader=1,</span><span> which is the only one worthy of usage, we still see too many issues in how the nodes are managed in case of serious events as failover.</span></p>\n<p><span>ProxySQL v2.1.0 seems to have fixed some instabilities, but we still have too many open issues to trust the Galera native support. </span><span>My advice is to stay away from it and use the scheduler to deal with the Galera cluster. Write a robust script that will cover your specific needs if you must customize the actions. A scheduler will serve you well. </span></p>\n<p><span>If too lazy to do so, there is a sample in <a target=\"_blank\" href=\"http://(https://github.com/Percona-Lab/proxysql-scheduler\">Percona-Lab</a>. T</span><span>his is the old script used in ProxySQL 1.4.x modified to work with ProxySQL 2.x. </span><span>I have also written one a long time ago that can help as well <a target=\"_blank\" href=\"https://github.com/Tusamarco/proxy_sql_tools\">here</a>. </span><span>Both come without any guarantee and I advise you to use them as examples for your own, see <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/11/30/support-for-percona-xtradb-cluster-in-proxysql-part-two/\">Part 2 of this post for details</a>. </span></p>\n<p><span>Finally, let me say that ProxySQL is a great tool, but no tool can cover all. People like me that have been around for long enough have seen this happening many times, and it is of no surprise. </span></p>\n<p><span>Great MySQL to all.</span></p>\n<h3>References</h3>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/LATEST/install/index.html\"><span>https://www.percona.com/doc/percona-xtradb-cluster/LATEST/install/index.html</span></a></p>\n<p><a target=\"_blank\" href=\"https://galeracluster.com/\"><span>https://galeracluster.com/</span></a></p>\n<p><a target=\"_blank\" href=\"https://proxysql.com/blog/proxysql-native-galera-support/\"><span>https://proxysql.com/blog/proxysql-native-galera-support/</span></a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2019/02/20/proxysql-native-support-for-percona-xtradb-cluster-pxc/\"><span>https://www.percona.com/blog/2019/02/20/proxysql-native-support-for-percona-xtradb-cluster-pxc/</span></a></p>\n<p><a target=\"_blank\" href=\"https://proxysql.com/documentation/galera-configuration/\"><span>https://proxysql.com/documentation/galera-configuration/</span></a></p>\n","descriptionType":"html","publishedDate":"Mon, 30 Nov 2020 15:13:46 +0000","feedId":11,"bgimg":"","linkMd5":"865d78407053e971745e187e83fb6e22","bgimgJsdelivr":"","metaImg":"","author":"Marco Tusa","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn48@2020_2/2020/12/01/06-05-11-076_e8c63897daf2697d.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn63@2020_3/2020/12/01/06-05-19-077_78eb906450db7ac5.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled-274x300.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn94@2020_6/2020/12/01/06-05-20-590_ea62ee78ef8dfc42.webp"},"publishedOrCreatedDate":1606802699965},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Recover Percona XtraDB Cluster in Kubernetes From Wrong MySQL Config","link":"https://www.percona.com/blog/?p=72759","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Recover Percona XtraDB Cluster in Kubernetes\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-72771\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-300x168.png\" alt=\"Recover Percona XtraDB Cluster in Kubernetes\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Kubernetes operators are meant to simplify the deployment and management of applications. Our <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\">Percona Kubernetes Operator for Percona XtraDB Cluster</a> serves the purpose, but also provides users the flexibility to fine-tune their MySQL and proxy services configuration.</p>\n<p><span>The document </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/options.html\">Changing MySQL Options</a> <span>describes how to provide custom <pre class=\"crayon-plain-tag\">my.cnf</pre> configuration to the operator. </span>But what would happen if you made a mistake and specified the wrong parameter in the configuration?</p>\n<h2>Apply Configuration</h2>\n<p><span>I already deployed my Percona XtraDB Cluster and deliberately submitted the wrong <pre class=\"crayon-plain-tag\">my.cnf</pre>  configuration in <pre class=\"crayon-plain-tag\">cr.yaml</pre> :</span></p><pre class=\"crayon-plain-tag\">spec:\n...\n  pxc:\n    configuration: |\n      [mysqld]\n      wrong_param=123\n…</pre><p>Apply the configuration:</p><pre class=\"crayon-plain-tag\">$ kubectl apply -f deploy/cr.yaml</pre><p>Once you do this, the Operator will apply a new MySQL configuration to one of the Pods. In a few minutes you will see that the Pod is stuck in CrashLoopBackOff status:</p><pre class=\"crayon-plain-tag\">$ kubectl get pods\nNAME                                               READY   STATUS             RESTARTS   AGE\npercona-xtradb-cluster-operator-79d786dcfb-lzv4b   1/1     Running            0          5h\ntest-haproxy-0                                     2/2     Running            0          5m27s\ntest-haproxy-1                                     2/2     Running            0          4m40s\ntest-haproxy-2                                     2/2     Running            0          4m24s\ntest-pxc-0                                         1/1     Running            0          5m27s\ntest-pxc-1                                         1/1     Running            0          4m41s\ntest-pxc-2                                         0/1     CrashLoopBackOff   1          59s</pre><p><span>In the logs it is clearly stated that this parameter is not supported and <pre class=\"crayon-plain-tag\">mysqld</pre> </span><span> process cannot start:</span></p><pre class=\"crayon-plain-tag\">       2020-11-19T13:30:30.141829Z 0 [ERROR] [MY-000067] [Server] unknown variable 'wrong_param=123'.\n        2020-11-19T13:30:30.142355Z 0 [ERROR] [MY-010119] [Server] Aborting\n        2020-11-19T13:30:31.835199Z 0 [System] [MY-010910] [Server] /usr/sbin/mysqld: Shutdown complete (mysqld 8.0.20-11.1)  Percona XtraDB Cluster (GPL), Release rel11, Revision 683b26a, WSREP version 26.4.3.</pre><p><span>It is worth noting that your Percona XtraDB Cluster is still operational and serves the requests.</span></p>\n<h2>Recovery</h2>\n<p><span>Let&#8217;s try to comment out the configuration section and reapply <pre class=\"crayon-plain-tag\">cr.yaml</pre> :</span></p><pre class=\"crayon-plain-tag\">spec:\n...\n  pxc:\n#    configuration: |\n#      [mysqld]\n#      wrong_param=123\n…\n\n\n$ kubectl apply -f deploy/cr.yaml</pre><p>And it won’t work (in v1.6). The Pod is still in CrashLoopBackOff state as the operator does not apply any changes when not all Pods are up and running. We are doing that to ensure data safety.</p>\n<p><span>Fortunately, there is an easy way to recover from such a mistake: you can either delete or modify the corresponding ConfigMap resource in Kubernetes. Usually its name is <pre class=\"crayon-plain-tag\">{your_cluster_name}-pxc</pre>:</span></p><pre class=\"crayon-plain-tag\">$ kubectl delete configmap test-pxc</pre><p>And delete the Pod which is failing:</p><pre class=\"crayon-plain-tag\">$ kubectl delete pod text-pxc-2</pre><p>Kubernetes will restart all Percona XtraDB Cluster pods one by one after some time:</p><pre class=\"crayon-plain-tag\">test-pxc-0                                         1/1     Running   0          2m28s\ntest-pxc-1                                         1/1     Running   0          3m23s\ntest-pxc-2                                         1/1     Running   0          4m36s</pre><p>You can apply the correct MySQL configuration now through ConfigMap or cr.yaml again. We are assessing other recovery options for such cases and config validation, so stay tuned for upcoming releases.</p>\n","descriptionType":"html","publishedDate":"Mon, 23 Nov 2020 17:56:48 +0000","feedId":11,"bgimg":"","linkMd5":"dc609f1e185b8bcc7742f0b363af7ae4","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn82@2020_4/2020/12/01/06-05-19-265_d1895718380451ac.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn52@2020_1/2020/12/01/06-05-13-171_eaa6c2235eb0aac1.webp"},"publishedOrCreatedDate":1606802699946},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Webinar December 15: The Open Source Alternative to Paying for MongoDB","link":"https://www.percona.com/blog/?p=72802","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Open Source Alternative to Paying for MongoDB\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-72870\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-300x168.png\" alt=\"Open Source Alternative to Paying for MongoDB\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Please join Barrett Chambers, Percona Solutions Engineer, for an engaging webinar on MongoDB vs. Open Source.</p>\n<p>Many organizations require Enterprise subscriptions for the coverage and features that it provides. However, many are unaware that there is an open source alternative offering all the features and benefits of a MongoDB Enterprise subscription without the licensing fees. In this talk, we will cover features that make <a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Percona Server for MongoDB</a> an enterprise-grade, license-free alternative to MongoDB Enterprise edition.</p>\n<p>In this discussion we will address:</p>\n<p>&#8211; Brief History of MongoDB</p>\n<p>&#8211; MongoDB Enterprise versus Percona Server for MongoDB features, including:</p>\n<ul>\n<li>Authentication</li>\n<li>Authorization</li>\n<li>Encryption</li>\n<li>Governance</li>\n<li>Audition</li>\n<li>Storage Engines</li>\n<li>Monitoring &#38; Alerting</li>\n</ul>\n<p>Please join <strong>Barrett Chambers</strong>, <strong>Percona Solutions Engineer, </strong>on <strong>Tuesday, December 15 at 11:00 AM EST</strong> for his webinar &#8220;The Open Source Alternative to Paying for MongoDB&#8221;.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://attendee.gotowebinar.com/register/6793361590474454539?source=blog\" rel=\"noopener\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://attendee.gotowebinar.com/register/6793361590474454539?source=blog\">sign up anyway</a> and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Mon, 30 Nov 2020 14:21:12 +0000","feedId":11,"bgimg":"","linkMd5":"e8a660755787a04bb4ad86382430db81","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn75@2020_2/2020/12/01/06-05-24-131_b20e8120a93d0c09.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn59@2020_2/2020/12/01/06-05-14-687_cc99b455a5c84e78.webp"},"publishedOrCreatedDate":1606802699935},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Demultiplexing Fix for Percona Backup for MongoDB, Redesign –lock-ddl-per-table in Percona XtraBackup: Release Roundup November 23, 2020","link":"https://www.percona.com/blog/?p=72647","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Software Release\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright size-medium wp-image-72788\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-300x169.png\" alt=\"Percona Software Release\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />It&#8217;s release roundup time here at Percona!</h2>\n<p>Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download.</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since November 9, 2020, including a user-reported bug fix for Percona Backup for MongoDB 1.3.4 and the introduction of a debug option to print the redo log records scanned and applied in Percona XtraBackup 2.4.21.</p>\n<p>&#160;</p>\n<h2>Percona Backup for MongoDB 1.3.4</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-backup-mongodb/release-notes/1.3.4.html\">Percona Backup for MongoDB 1.3.4</a> was released on November 19, 2020. It is a distributed, low-impact solution for consistent backups of MongoDB sharded clusters and replica sets. An improvement in this release include the addition of a request timeout to the S3 downloader during the restore, and a bug fix (reported by user pedroalb) restores fails with conflicting namespace destinations.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/percona-backup-mongodb/\">Download Percona Backup for MongoDB 1.3.4</a></p>\n<p>&#160;</p>\n<h2>Percona XtraBackup 2.4.21</h2>\n<p>On November 12, 2020, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtrabackup/2.4/release-notes/2.4/2.4.21.html\">Percona XtraBackup 2.4.21</a> was released. It enables MySQL backups without blocking user queries, making it ideal for companies with large data sets and mission-critical applications that cannot tolerate long periods of downtime. Offered free as an open source solution, it drives down backup costs while providing unique features for MySQL backups. Improvements include the introduction of a debug option to print the redo log records scanned and applied, and a new feature (Thanks to user rluisr for reporting this issue) offers xbcloud: support storage_class option with –storage=s3. In addition, there were several bug fixes, which can be seen in the release notes.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/\">Download Percona XtraBackup 2.4.21</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;noopener&#34; noopener noreferrer\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n<hr />\n<p>We understand that choosing open source software for your business can be a potential minefield. You need to select the best available options, which fully support and adapt to your changing needs. Choosing the right open source software can allow you access to enterprise-level features, without the associated costs.</p>\n<p>In our white paper, we discuss the key features that make open source software attractive, and why Percona&#8217;s software might be the best option for your business.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://www.percona.com/resources/white-papers/when-percona-software-right-choice?utm_source=blog&#38;utm_medium=download&#38;utm_campaign=roundup&#38;utm_content=whitepaper\" rel=\"noopener\">Download: When is Percona Software the Right Choice?</a></p>\n","descriptionType":"html","publishedDate":"Mon, 23 Nov 2020 14:23:12 +0000","feedId":11,"bgimg":"","linkMd5":"eacaa3570654f49b50ab7e89696d5d64","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn92@2020_6/2020/12/01/06-05-20-591_366730b95cd0ec6a.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn71@2020_5/2020/12/01/06-05-02-402_cd1ace4d5421e1f3.webp"},"publishedOrCreatedDate":1606802699952},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Support for Percona XtraDB Cluster in ProxySQL (Part Two)","link":"https://www.percona.com/blog/?p=72734","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Support for Percona XtraDB Cluster in ProxySQL\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-72817\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-300x168.png\" alt=\"Support for Percona XtraDB Cluster in ProxySQL\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" /></p>\n<p><strong>How scheduler and script stand in supporting failover (Percona and Marco example) </strong></p>\n<p><span>In <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/11/30/support-for-percona-xtradb-cluster-in-proxysql-part-one/\">part one of this series</a>, </span><span><strong><span style=\"color: #ff0000;\"> </span></strong>I had illustrated how simple scenarios may fail or have problems when using Galera native support inside ProxySQL. </span><span>In this post, I will repeat the same tests but using the scheduler option and the external script.</span></p>\n<h2>The Scheduler</h2>\n<p><span>First a brief explanation about the scheduler.</span></p>\n<p><span>The scheduler inside ProxySQL was created to allow administrators to extend ProxySQL capabilities. The scheduler gives the option to add any kind of script or application and run it at the specified interval of time. </span><span>The scheduler was also the initial first way we had to deal with Galera/Percona XtraDB Cluster (PXC) node management in case of issues. </span></p>\n<p><span>The scheduler table is composed as follows:</span></p><pre class=\"crayon-plain-tag\">CREATE TABLE scheduler (\n    id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n    active INT CHECK (active IN (0,1)) NOT NULL DEFAULT 1,\n    interval_ms INTEGER CHECK (interval_ms&#62;=100 AND interval_ms&#60;=100000000) NOT NULL,\n    filename VARCHAR NOT NULL,\n    arg1 VARCHAR,\n    arg2 VARCHAR,\n    arg3 VARCHAR,\n    arg4 VARCHAR,\n    arg5 VARCHAR,\n    comment VARCHAR NOT NULL DEFAULT '')</pre><p><span>The relevant elements are:</span></p>\n<ul>\n<li><b>Active: </b><span>that defines if the scheduler should execute or not the external script</span></li>\n<li><b>Interval_ms: </b><span>frequency of the execution. This has NO check if previous executions terminate. Given that a script must include a check to prevent launching multiple instances which will probably create conflicts and resource issues.</span></li>\n<li><b>Filename:</b><span> the FULL path of the script/app you want to be executed.</span></li>\n<li><b>Arg(s):</b><span> whatever you want to pass as arguments. When you have a complex script, either use a configuration file or collapse multiple arguments in a single string.</span></li>\n</ul>\n<h2>The Scripts</h2>\n<p><span>In this blog, I will present two different scripts (as examples). Both will cover the scenarios as in the previous article and can do more, but I will focus only on that part for now.</span></p>\n<p><span>One script is written in Bash and is the porting of the proxysql_galera_checker Percona was using with ProxySQL-admin in ProxySQL version 1.4. The script is available here from <a target=\"_blank\" href=\"https://github.com/Percona-Lab/proxysql-scheduler.git\">Percona-lab</a> (git clone ).</span></p>\n<p><span>The other, written by me, is written in Perl and is probably the first script that came out in 2016. I have done some enhancements and bug fixing to it during the years. Available <a target=\"_blank\" href=\"https://github.com/Tusamarco/proxy_sql_tools.git\">here</a> (git clone).</span></p>\n<p><span>Both are offered here as examples and I am not suggesting to use them in critical production environments.</span></p>\n<h2>The Setup</h2>\n<p><span>To use the two scripts some custom setup must be done. First of all, check that the files are executable by the user running ProxySQL.</span></p>\n<h3>Let&#8217;s start with mine in Perl</h3>\n<p><span>To make it work we need to define a set of host groups that will work as Reader/Writer/Backup-writer/backup-reader (optional but recommended). The difference from the native support is that instead of having them indicated in a specialized table, we will use the mysql_servers table.</span></p>\n<ul>\n<li><span>Writer: 100</span></li>\n<li><span>Readers: 101</span></li>\n<li><span>Backup Writers:8100</span></li>\n<li><span>Backup Readers: 8101</span></li>\n</ul>\n<p><span>Given the above, on top of the already defined servers in the previous article, we just need to add the 8000 HGs. </span></p>\n<p><span>For example:</span></p><pre class=\"crayon-plain-tag\">INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.22',8100,3306,1000,2000,'Failover server preferred');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.23',8100,3306,999,2000,'Second preferred');    \nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.233',8100,3306,998,2000,'Third and last in the list');      \n    \nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.22',8101,3306,100,2000,'');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.23',8101,3306,1000,2000,'');    \nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('192.168.4.233',8101,3306,1000,2000,'');</pre><p><span>After that we need to insert the instructions for the scheduler:</span></p><pre class=\"crayon-plain-tag\">INSERT  INTO scheduler (id,active,interval_ms,filename,arg1) values (10,0,2000,\"/opt/tools/proxy_sql_tools/galera_check.pl\",\"-u=cluster1 -p=clusterpass -h=192.168.4.191 -H=100:W,101:R -P=6032 --retry_down=2 --retry_up=1 --main_segment=2 --debug=0  --log=/var/lib/proxysql/galeraLog --active_failover=1\");</pre><p><span>The result will be:</span></p><pre class=\"crayon-plain-tag\">id: 10\n     active: 0\ninterval_ms: 2000\n   filename: /opt/tools/proxy_sql_tools/galera_check.pl\n       arg1: -u=cluster1 -p=clusterpass -h=192.168.4.191 -H=100:W,101:R -P=6032 --retry_down=2 --retry_up=1 --main_segment=2 --debug=0  --log=/var/lib/proxysql/galeraLog --active_failover=1\n       arg2: NULL\n       arg3: NULL\n       arg4: NULL\n       arg5: NULL\n    comment:</pre><p><span>Please refer to the instruction in Github for the details of the parameters. What we can specify here is:</span></p>\n<ul>\n<li><span>-H=100:W,101:R</span><span> Are the Host Group we need to refer to as the ones dealing with our PXC cluster</span></li>\n<li><span>&#8211;active_failover=1</span><span> Failover method to apply</span></li>\n<li><span>&#8211;retry_down=2 &#8211;retry_up=1</span><span> If action must be taken immediately or if a retry is to be done. This is to avoid the possible jojo effect due to any delay from the node or network.  </span></li>\n</ul>\n<p><span>Always set it to 0 and activate only when all is set and you are ready to go. </span><span>Once the above is done, the script ready to be used by ProxySQL is the galera_check script.</span></p>\n<h3>Percona proxysql_galera_checker</h3>\n<p><span>One limitation this script has is that you cannot use different IPs for the PXC internal communication and the ProxySQL node. Given that, we need to modify the setup we had in the previous blog to match the script requirements. </span><span>Also here we need to define which HG will be the writer which the reader, but we will specify the internal IPs, and, of course, ProxySQL must have access to that network as well.</span></p>\n<ul>\n<li><span>Writer HG : 200</span></li>\n<li><span>Reader HG: 201</span></li>\n<li><span>Network IPs 10.0.0.22 &#8211; 23 &#8211; 33</span></li>\n</ul>\n<p><span>Given that, our ProxySQL setup will be:</span></p><pre class=\"crayon-plain-tag\">delete from mysql_users where username='app_test';\ninsert into mysql_users (username,password,active,default_hostgroup,default_schema,transaction_persistent,comment) values ('app_test','test',1,200,'mysql',1,'application test user DC1');\nLOAD MYSQL USERS TO RUNTIME;SAVE MYSQL USERS TO DISK;\n\ndelete from mysql_query_rules where rule_id in(1040,1042);\ninsert into mysql_query_rules (rule_id,proxy_port,username,destination_hostgroup,active,retries,match_digest,apply) values(1040,6033,'app_test',200,1,3,'^SELECT.*FOR UPDATE',1);\ninsert into mysql_query_rules (rule_id,proxy_port,username,destination_hostgroup,active,retries,match_digest,apply) values(1042,6033,'app_test',201,1,3,'^SELECT.*$',1);\nload mysql query rules to run;save mysql query rules to disk;\n\ndelete from mysql_servers where hostgroup_id in (200,201);\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('10.0.0.22',200,3306,10000,2000,'DC1');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('10.0.0.22',201,3306,100,2000,'DC1');\nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('10.0.0.23',201,3306,10000,2000,'DC1');    \nINSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections,comment) VALUES ('10.0.0.33',201,3306,10000,2000,'DC1');        \n\nload mysql servers to run;save mysql servers to disk;</pre><p><span>As you can see here we need to redefine also the user and query rules to match the different HGs, if you use the same (100 -101) no need to do that. </span><span>Now it&#8217;s time to add the line in for the scheduler:</span></p><pre class=\"crayon-plain-tag\">delete from scheduler where id=60;\nINSERT  INTO scheduler (id,active,interval_ms,filename,arg1) values (60,0,3000,\"/opt/tools/proxysql-scheduler/proxysql_galera_checker\",\"--config-file=/opt/tools/proxysql-scheduler/proxysql-admin-sample.cnf --writer-is-reader=always --write-hg=200 --read-hg=201 --writer-count=1 --priority=10.0.0.22:3306,10.0.0.23:3306,10.0.0.33:3306 --mode=singlewrite --debug --log=/tmp/pxc_test_proxysql_galera_check.log\");\nLOAD SCHEDULER TO RUNTIME;SAVE SCHEDULER TO DISK;</pre><p><span>Also in this case please refer to the specifications of the parameters, but it&#8217;s worth mentioning:</span></p>\n<ul>\n<li><span>&#8211;write-hg=200 &#8211;read-hg=201</span><span> Host groups definition</span></li>\n<li><span>&#8211;writer-is-reader=always</span><span> Keep this as ALWAYS please, we will see you do not need anything different.</span></li>\n<li><span>&#8211;mode=singlewrite</span><span> Possible modes are load balancer and single writer. This is refuse from the old. Never, ever use Galera/PXC in multi-primary mode, period.</span></li>\n<li><span>&#8211;priority=10.0.0.22:3306,10.0.0.23:3306,10.0.0.33:3306</span><span> This is where we define the priority for the writers.</span></li>\n</ul>\n<p><span>Also in this case when loading a schedule, keep the schedule deactivated, and enable it only when ready.</span></p>\n<h2>The Tests</h2>\n<h3>Read Test</h3>\n<p><span>The first test is the simple read test, so while we have sysbench running in read_only mode we remove one reader after the other.</span></p>\n<p><span>Marco script:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed | ConnFree |\n+---------+-----------+---------------+----------+--------------+----------+----------+\n| 10000   | 100       | 192.168.4.22  | 3306     | ONLINE       | 0        | 0        |\n| 10000   | 101       | 192.168.4.233 | 3306     | ONLINE       | 38       | 8        |\n| 10000   | 101       | 192.168.4.23  | 3306     | ONLINE\t| 15       | 49       |\n| 100     | 101       | 192.168.4.22  | 3306     | ONLINE       | 0        | 64       |</pre><p><span>As we can see, by just setting the weight we will be able to prevent sending reads to the Writer, and while some will still arrive there, it is negligible. </span><span>Once we put all the readers down&#8230;</span></p>\n<p><span>Marco script: </span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 10000   | 100       | 192.168.4.22  | 3306     | ONLINE       | 0        |\n| 10000   | 101       | 192.168.4.233 | 3306     | SHUNNED      | 0        |\n| 10000   | 101       | 192.168.4.23  | 3306     | SHUNNED      | 0 \t|\n| 100     | 101       | 192.168.4.22  | 3306     | ONLINE       | 58       |</pre><p><span>Given the last node also if with the low weight it will serve all the reads.</span></p>\n<p><span>Percona Script:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+--------\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed | \n+---------+-----------+---------------+----------+--------------+--------\n| 10000   | 200       | 10.0.0.22     | 3306     | ONLINE       | 0        | \n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE       | 22       | \n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE       | 21\t| \n| 100     | 201       | 10.0.0.22     | 3306     | ONLINE       | 1        |</pre><p><span>Remove the reads:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+-------\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+-------\n| 10000   | 200       | 10.0.0.22     | 3306     | ONLINE       | 0        |\n| 10000   | 201       | 10.0.0.33     | 3306     | OFFLINE_SOFT | 0 \t\n| 10000   | 201       | 10.0.0.23     | 3306     | OFFLINE_SOFT | 0 \t\n| 100     | 201       | 10.0.0.22     | 3306     | ONLINE       | 62       |</pre><p><span>In both cases, no issue at all; the writer takes the load of the reads only when left alone. </span></p>\n<h3>Maintenance Test</h3>\n<p><span>In this test, I will simply put the node down into maintenance mode using </span><i><span>pxc_maint_mode=maintenance</span></i><span>, as done in the other article. As a reminder, this was working fine also with native Galera.</span></p>\n<p><span><br />\n</span>Marco script:</p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 10000   | 100       | 192.168.4.22  | 3306     | ONLINE       | 50       |\n| 10000   | 101       | 192.168.4.233 | 3306     | ONLINE       | 8        |\n| 10000   | 101       | 192.168.4.23  | 3306     | ONLINE       | 3    \t   |\n| 100     | 101       | 192.168.4.22  | 3306     | ONLINE       | 0        |\n| 1000000 | 200       | 10.0.0.23     | 3306     | OFFLINE_SOFT | 0        |</pre><p><span>After:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 999     | 100       | 192.168.4.23  | 3306     | ONLINE       | 50       |\n| 10000   | 100       | 192.168.4.22  | 3306     | OFFLINE_SOFT | 0        |\n| 10000   | 101       | 192.168.4.233 | 3306     | ONLINE       | 5        |\n| 10000   | 101       | 192.168.4.23  | 3306     | ONLINE       | 6 \t   |\n| 100     | 101       | 192.168.4.22  | 3306     | OFFLINE_SOFT | 0        |</pre><p><span>Node was elected and connections on the old writer were also able to end given OFFLINE_SOFT. </span><span>Putting back the node, removing it from maintenance:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 999     | 100       | 192.168.4.23  | 3306     | ONLINE\t| 50       |\n| 10000   | 101       | 192.168.4.233 | 3306     | ONLINE       | 5        |\n| 10000   | 101       | 192.168.4.23  | 3306     | ONLINE       | 5 \t   |\n| 100     | 101       | 192.168.4.22  | 3306     | ONLINE       | 0        |</pre><p><span>Node WILL NOT failback by default (this is by design), this will eventually allow you to warm caches or anything else it may be meaningful before moving the node to Primary role again.</span></p>\n<p><span>The Percona script will behave a bit differently:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 1000000 | 200       | 10.0.0.23     | 3306     | OFFLINE_SOFT | 0        |\n| 10000   | 200       | 10.0.0.22     | 3306     | ONLINE       | 50       |\n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE       | 4 \t  |\n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE       | 10\t  |\n| 100     | 201       | 10.0.0.22     | 3306     | ONLINE       | 0        |</pre><p><span>Then I put the node under maintenance:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 1000000 | 200       | 10.0.0.23     | 3306     | ONLINE       | 26       |\n| 10000   | 200       | 10.0.0.22     | 3306     | OFFLINE_SOFT | 22       |\n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE       | 8        |\n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE       | 12       |\n| 100     | 201       | 10.0.0.22     | 3306     | OFFLINE_SOFT | 0        |</pre><p><span>Connections will be moved to the new Writer slowly based on the application approach. </span></p>\n<p><span>But when I put the node back from maintenance:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed \n+---------+-----------+---------------+----------+--------------+----------\n| 1000000 | 200       | 10.0.0.23     | 3306     | OFFLINE_SOFT | 0        \n| 10000   | 200       | 10.0.0.22     | 3306     | ONLINE       | 49       \n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE       | 5        \n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE       | 14       \n| 100     | 201       | 10.0.0.22     | 3306     | ONLINE       | 0</pre><p><span>The old Writer will be put back as Primary. As indicated above I consider this wrong, given we may risk putting back a node that is </span><i><span>cold</span></i><span> and that can affect production performance. It is true that putting it back from maintenance is a controlled action, but the more checks the better.</span></p>\n<h3>Testing Node Crash</h3>\n<p>Marco script:</p>\n<p><span>To emulate a crash I will kill the mysqld process with kill -9 &#60;pid&#62;.</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status\t| ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 1000    | 100       | 192.168.4.22  | 3306     | ONLINE\t| 50       |\n| 10000   | 101       | 192.168.4.233 | 3306     | ONLINE\t| 12       |\n| 10000   | 101       | 192.168.4.23  | 3306     | ONLINE\t| 4        |\n| 100     | 101       | 192.168.4.22  | 3306     | ONLINE\t| 0        |</pre><p><span>Kill the process:</span></p><pre class=\"crayon-plain-tag\">59,50,53.99,6603.16,6205.21,218.97,178.98,1561.52,0.00,2.00\n60,50,54.11,5674.25,5295.50,215.43,163.32,1648.20,0.00,1.00 \n61,50,3.99,3382.12,3327.22,30.95,23.96,2159.29,0.00,48.91   &#60;--- start\n62,50,0.00,820.35,820.35,0.00,0.00,0.00,0.00,0.00         \n63,50,0.00,2848.86,2550.67,195.13,103.07,0.00,0.00,0.00\n64,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n65,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n66,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n67,50,50.00,4268.99,4066.99,52.00,150.00,7615.89,0.00,1.00  &#60;--- failover end \n68,50,72.00,6522.40,6096.37,268.02,158.01,1109.09,0.00,1.00</pre><p><span>Five seconds is consistently taken, of which two are because I set the scheduler to run every two seconds, and also a retry. </span><span>And the new Primary is serving while the failed node is removed:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status\t    | ConnUsed | ConnFree |\n+---------+-----------+---------------+----------+--------------+----------+----------+\n| 999     | 100       | 192.168.4.23  | 3306     | ONLINE       | 0        | 50       |\n| 10000   | 101       | 192.168.4.233 | 3306     | ONLINE       | 0        | 34       |\n| 10000   | 101       | 192.168.4.23  | 3306     | ONLINE       | 0        | 35       |\n| 100     | 101       | 192.168.4.22  | 3306     | SHUNNED      | 0        | 0        |</pre><p>Percona script:</p>\n<p><span>Also, in this case, the Percona script behaves a bit differently.</span></p>\n<p><span>Before the crash:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 10000   | 200       | 10.0.0.22     | 3306     | ONLINE       | 49       |\n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE       | 5        |\n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE       | 14       |\n| 100     | 201       | 10.0.0.22     | 3306     | ONLINE       | 0        |</pre><p><span>Then kill the process:</span></p><pre class=\"crayon-plain-tag\">29,50,41.05,4099.74,3838.44,155.18,106.12,2009.23,0.00,0.00\n30,50,8.01,1617.92,1547.79,37.07,33.06,1803.47,0.00,50.09\n31,50,0.00,2696.60,2696.60,0.00,0.00,0.00,0.00,0.00       &#60;--- start\n32,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n33,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n34,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n35,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n36,50,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00\n37,50,12.96,2385.82,2172.46,91.72,121.63,8795.93,0.00,0.00  &#60;--- failback ends 6\"\n38,50,39.95,4360.00,4083.38,148.80,127.82,9284.15,0.00,0.00</pre><p><span>Variable time to recover but around 6-12 seconds.</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+---------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status  | ConnUsed |\n+---------+-----------+---------------+----------+---------+----------+\n| 1000000 | 200       | 10.0.0.23     | 3306     | ONLINE  | 50       | ← new\n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE  | 11       |\n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE  | 5        |</pre><p><span>New Primary is elected. </span><span>But on node recovery:</span></p><pre class=\"crayon-plain-tag\">+---------+-----------+---------------+----------+--------------+----------+\n| weight  | hostgroup | srv_host      | srv_port | status       | ConnUsed |\n+---------+-----------+---------------+----------+--------------+----------+\n| 1000000 | 200       | 10.0.0.23     | 3306     | OFFLINE_SOFT | 50       | \n| 10000   | 200       | 10.0.0.22     | 3306     | ONLINE       | 0        |&#60;--old is back\n| 10000   | 201       | 10.0.0.33     | 3306     | ONLINE       | 10       |\n| 10000   | 201       | 10.0.0.23     | 3306     | ONLINE\t| 6        |\n| 1000    | 201       | 10.0.0.22     | 3306     | ONLINE       | 0        |</pre><p><span>As for maintenance, when the node comes back, by default it is moved to the Primary role. As already explained I consider this wrong and dangerous, but it is a way of seeing what a script should do.</span></p>\n<h3>Conclusions</h3>\n<p><span>PXC is a complex product, the ways it can be deployed are many, and is not easy or possible to identify all of the possible variants.<br />\n</span></p>\n<p><span>Having the opportunity to use native support could be the </span><em>easier to go</em><span> solution, but as illustrated <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/11/30/support-for-percona-xtradb-cluster-in-proxysql-part-one/\">part one of this series</a>, misbehavior is just around the corner and it may seriously impact your production environment.</span></p>\n<p><span>The use of the scheduler with a properly developed script/application that handles the Galera support can guarantee better consistency and proper behavior in respect to your custom expectations. </span></p>\n<p><span>There are solutions out there that may fit you and your needs, but if not you can develop your own solution, and be sure that you keep consistency when changing versions of ProxySQL and/or PXC/Galera. </span><span>In the end, once the main work is done, maintaining a script will be much easier than having to patch a product or wait for a feature request to be implemented. </span></p>\n<p><span>I know it may look like a step back, moving out from native support and using a scheduler again. But it is not, it&#8217;s just the acknowledgment that sometimes it is better to keep it simple and do some specific tuning/work, rather than trying to put the universe in a bottle which overcomplicates the problem.</span></p>\n","descriptionType":"html","publishedDate":"Mon, 30 Nov 2020 15:35:29 +0000","feedId":11,"bgimg":"","linkMd5":"d80df06f729a98fe1d912d7a91b5439a","bgimgJsdelivr":"","metaImg":"","author":"Marco Tusa","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn90@2020_4/2020/12/01/06-05-19-052_2a976578c97c1996.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn68@2020_6/2020/12/01/06-05-05-629_67d08ca1e2e99eee.webp"},"publishedOrCreatedDate":1606802699965},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Impact of Percona Monitoring and Management “Get Latest” Command Change","link":"https://www.percona.com/blog/?p=72764","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Impact of Percona Monitoring and Management Get Latest Command Change\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-72775\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic.jpg\" alt=\"percona monitoring and management\" width=\"976\" height=\"924\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic.jpg 976w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic-300x284.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic-158x150.jpg 158w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic-367x347.jpg 367w\" sizes=\"(max-width: 976px) 100vw, 976px\" />In the first quarter of 2021 (expected late January), Percona is slated to release a version of <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM) v2 that will include all of the critical functionality users of PMM v1 have come to know and love over the years. While PMM v2 has some major improvements over its v1 sibling, PMM v2 has long had this stigma that there wasn’t parity between the versions when it came to features like <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/02/12/percona-monitoring-management-pmm-support-external-monitoring-services-yes/\">external services</a>, <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/10/22/annotations-provide-context-to-timelines-in-percona-monitoring-and-management/\">annotations</a>, <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/06/26/mongodb-explain-using-pmm-qan-for-mongodb-query-analytics/\">MongoDB Explain</a>, and <a target=\"_blank\" href=\"https://www.percona.com/blog/2019/03/12/pmms-custom-queries-in-action-adding-a-graph-for-innodb-mutex-waits/\">custom collectors per service</a> to name a few. By early 2021, we feel confident that users of PMM v1 will recognize all their beloved functionality they’ve come to rely upon in v1 is now in v2 and so we encourage you to come try it for yourself. While many of the missing features have since been added in, one item to note is that external services will be included in that early 2021 release; as with all external exporters, you’ll still need to create your own graphs, but getting the remainder of this functionality will make just about anything you can squeeze data out of “monitorable”.</p>\n<h3>So What’s the Big Deal?</h3>\n<p><span>We will be modifying our “latest” tag that currently specifies v1.x so that it will now point to v2.x on getting the “latest version”. </span><span>PMM v1 users have historically just “rerun” their ‘docker run pmm-server’ command to update to the next PMM v1.x version. They could specify the latest version of the pmm-server by saying </span></p><pre class=\"crayon-plain-tag\">docker run -d --name pmm-server percona/pmm-server:1.17.3</pre><p><span>or they’ve had the ability to replace that with </span></p><pre class=\"crayon-plain-tag\">docker run -d --name pmm-server percona/pmm-server:latest</pre><p><span>and get whichever v1.x version is the latest released by Percona (as of this blog posting date, the latest is </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/release-notes/1.17.4.html\"><span>1.17.4</span></a><span>).  But, when we make PMM v2 “latest” early in 2021, those of you that run the latter command are going to be impacted (both positively and negatively), so we wanted to give you a heads-up now so you can plan accordingly and make the appropriate modifications to your deployment code. </span></p>\n<p><span>First the positive news… PMM v2 has some very exciting and useful improvements over PMM v1 and we can’t wait for you to leverage this new functionality including:</span></p>\n<ul>\n<li><span>A complete rewrite of the Query Analytics (QAN) tool, including improved speed, global sparkline hover, filtering, new dimensions to collect data, and rich searching capabilities</span></li>\n<li><span>The <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/06/29/security-threat-tool-design-in-percona-monitoring-and-management/\">Security Threat Tool</a> (STT) so that you not only can monitor database performance but also database security</span></li>\n<li><span>A robust expansion of MongoDB and PostgreSQL support (along with continued improvements for MySQL)</span></li>\n<li><span>Integration with external AlertManager to create and deploy alerting and “integrated alerting” expected by the end of December 2020 providing native alerting inside PMM itself</span></li>\n<li><span>Global and local annotations across nodes and services to highlight key events for correlation</span></li>\n</ul>\n<p><span>As has been stated in the past,</span> <span>there is no direct upgrade/migration path from PMM v1 to PMM v2 because of the complete re-architecting in PMM v2. In fact, these are basically two separate and distinct applications. So you will need to stand up and install PMM v2 as a brand new system with new clients on your endpoints. Additionally, we do not provide a data migration path to move your historical data to PMM v2. You can, however,</span> <a target=\"_blank\" href=\"https://www.percona.com/blog/2019/11/27/running-pmm1-and-pmm2-clients-on-the-same-host/\">choose to run both PMM v1 and PMM v2 on the same host using this approach</a><i><span> to ease the transition. </span></i></p>\n<p><span>So, if you are one of those users that leverages the </span><span>“</span><span>:latest” command to upgrade to the latest PMM version (</span><i><span>note: this is not the recommended approach to upgrading your PMM implementation; the recommended Percona approach is to use a specific version number such as “pmm:2.11.1”.</span></i><span>), you need to start planning now to ensure a smooth transition to PMM v2. Here’s our recommendation for how to plan for this change now:</span></p>\n<ol>\n<li><span>Determine if you currently upgrade PMM via <pre class=\"crayon-plain-tag\">docker run -d --name pmm-server percona/pmm-server:latest</pre> </span>\n<ol>\n<li><span>If “no”, you will NOT be impacted by the early 2021 change. We would recommend you develop a plan for moving to PMM v2 in 2021 at your convenience, and then proceed to step #2 below.</span></li>\n<li><span>If “yes”, you WILL be impacted by the early 2021 change and thus need to create a plan on how to minimize your impact. </span>\n<ol>\n<li><span>If you are planning to keep the docker run command and move to PMM v2 by early 2021, please continue to bullet #2 below. </span></li>\n<li><span>If you will not be ready to move to PMM v2 by early 2021, please disable the above docker run command and implement a temporary, manual approach to upgrading to future PMM v1.x releases. When you are ready to migrate to PMM v2, please proceed to step #2 below.</span></li>\n</ol>\n</li>\n</ol>\n</li>\n<li><span> Will you require access to historical PMM v1 data after deploying PMM v2?</span>\n<ol>\n<li><span>If “yes”, you will need to run both PMM v1 and PMM v2 in parallel. </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2019/11/27/running-pmm1-and-pmm2-clients-on-the-same-host/\"><span>This approach</span></a><span> enables a parallel existence. You will want to keep both instances running in parallel until you no longer require access to PMM v1 data, as defined by your organization’s data retention policy.</span></li>\n<li><span>If “no”, you can install a clean deployment of PMM v2, accessible from </span><span>the main <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> page</span><span>. From then forward, we recommend you upgrade using the <pre class=\"crayon-plain-tag\">docker run.../pmm-server:2</pre></span> command, <span>and upgrades will be performed from the v2.x branch of PMM.</span></li>\n</ol>\n</li>\n</ol>\n<p><span>After you upgrade in early 2021, enjoy the move to PMM v2 and please let us know your thoughts on its new features as well as any ideas you have for improvement.</span></p>\n<p><span>Please note that this does NOT mean that we are “sunsetting” PMM v1 and will no longer support that application. While we are not creating new features for PMM v1, we do continue to maintain it with critical bug fixes as needed as well as support for the product for those customers on a support contract. This maintenance and support will continue until PMM moves to version 3.x at a date to be determined in the future.</span></p>\n<p>&#160;</p>\n<p style=\"text-align: center;\"><strong>Download and Try <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> Today!</strong></p>\n","descriptionType":"html","publishedDate":"Mon, 23 Nov 2020 15:28:51 +0000","feedId":11,"bgimg":"","linkMd5":"110b8648861a3e45e1cfb59581b9835a","bgimgJsdelivr":"","metaImg":"","author":"Brandon Fleisher","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn77@2020_6/2020/12/01/06-05-00-428_237432d3c522f403.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic.jpg":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn85@2020_2/2020/12/01/06-05-02-022_46354eac78b7cf4e.webp"},"publishedOrCreatedDate":1606802699969},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Webinar December 9: How to Measure Linux Performance Wrong","link":"https://www.percona.com/blog/?p=72720","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"How to Measure Linux Performance Wrong\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p data-pm-slice=\"1 1 []\"><img loading=\"lazy\" class=\"alignright size-medium wp-image-72721\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-300x168.png\" alt=\"How to Measure Linux Performance Wrong\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Don&#8217;t miss out! Join Peter Zaitsev, Percona CEO, as he discusses Linux Performance measurement.</p>\n<p data-pm-slice=\"1 1 []\">In this webinar, Peter will look at typical mistakes measuring or interpreting Linux Performance. He&#8217;ll discuss whether you should use LoadAvg to assess if your CPU is overloaded or Disk Utilization to see if your disks are overloaded. In addition, he&#8217;ll delve into a number of other metrics that are often misunderstood and/or misused. He&#8217;ll close the webinar with suggestions for better ways to measure Linux Performance.</p>\n<p>Please join <strong>Peter Zaitsev, Percona CEO, </strong>on <strong>Wednesday, December 9 at 11:30 AM EST</strong> for his webinar &#8220;How to Measure Linux Performance Wrong&#8221;.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://attendee.gotowebinar.com/register/5310206166511433739?source=blog\" rel=\"noopener\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://attendee.gotowebinar.com/register/5310206166511433739?source=blog\">sign up anyway</a> and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Fri, 20 Nov 2020 14:32:26 +0000","feedId":11,"bgimg":"","linkMd5":"773638760dab8c89b6b62970b3884567","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn71@2020_1/2020/12/01/06-05-02-548_ae35c9c59784fa12.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn55@2020_2/2020/12/01/06-05-29-232_91c5779ab374879e.webp"},"publishedOrCreatedDate":1606802699954},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"A Blog Shamelessly Bribing You to Review Percona Monitoring and Management!","link":"https://www.percona.com/blog/?p=72742","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Review Percona Monitoring and Management\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" />\n<p>We would love you to help us spread the word about <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM) to make sure even more people are aware of it and adopting it. And we are not afraid to offer (modest) bribes!</p> \n<ul> \n <li><strong>If you already use PMM</strong> please write an independent review of its pros and cons on the <a target=\"_blank\" href=\"https://aws.amazon.com/marketplace/pp/B077J7FYGX?qid=1605533229523&amp;sr=0-1&amp;ref_=srh_res_product_title\">AWS</a> and/or <a target=\"_blank\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/percona.pmm_2?tab=Overview\">Azure</a> product page.</li> \n <li><strong>If you don’t use PMM</strong>, please <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/install/aws.html\">install</a> and try this software to see how it can help you improve the monitoring of your database environment.</li> \n</ul> \n<p>For those of you new to <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a>, it is a best-of-breed open source database monitoring solution. It helps you reduce complexity, optimize performance, and improve the security of your business-critical database environments, no matter where they are located or deployed.</p> \n<p>Percona Monitoring and Management can be used to monitor a wide range of open source database environments:<span><br /> </span></p> \n<ul> \n <li>Amazon RDS MySQL</li> \n <li>Amazon Aurora MySQL</li> \n <li>MySQL</li> \n <li>MongoDB</li> \n <li>Percona XtraDB Cluster</li> \n <li>PostgreSQL</li> \n <li>ProxySQL</li> \n</ul> \n<p>Percona Monitoring and Management is now available for fast installation on two marketplaces – <a target=\"_blank\" href=\"https://aws.amazon.com/marketplace/pp/B077J7FYGX?qid=1605533229523&amp;sr=0-1&amp;ref_=srh_res_product_title\">AWS</a> and <a target=\"_blank\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/percona.pmm_2?tab=Overview\">Azure</a>. We are keen to increase the number of PMM reviews on those pages so that potential users can get an independent view of how it will benefit their business.</p> \n<p><strong>We will send you special Percona Swag for every verified review you post before December 20, 2020.&nbsp;</strong></p> \n<p>Just send us a link to your testimonial or a screenshot, and we will send you the latest in Percona gear – 100% free, and shipped to you anywhere in the world!</p> \n<p>You can choose from any of these gift options:</p> \n<p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-72754\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-1024x678.jpg\" alt=\"review percona monitoring and management\" width=\"900\" height=\"596\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-1024x678.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-300x198.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-200x132.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-1536x1016.jpg 1536w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-2048x1355.jpg 2048w, https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-367x243.jpg 367w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p> \n<p>Any meaningful review (ie: not just a star rating) earns swag; whether it is positive, negative, or mixed. We believe in open source and learning from our users, so please write honestly about your experience using Percona Monitoring and Management.</p> \n<p>To claim your swag, email the Percona <a target=\"_blank\" href=\"mailto:community-team@percona.com\">community team</a> and include:</p> \n<ol> \n <li>The screenshot or link to your review</li> \n <li>Your postal address</li> \n <li>Your phone number (for delivery use only, never for marketing)</li> \n <li>If you have chosen a sweatshirt or hoodie please also let us know what color (grey, black, or blue), and your size.</li> \n <li>We only accept feedback from PMM users who are using AWS and Azure marketplaces.</li> \n <li>Be sure to submit your review before December 20, 2020!</li> \n</ol> \n<p>It’s that simple!</p> \n<p>So, please visit the <a target=\"_blank\" href=\"https://aws.amazon.com/marketplace/pp/B077J7FYGX?qid=1605533229523&amp;sr=0-1&amp;ref_=srh_res_product_title\">AWS</a> and <a target=\"_blank\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/percona.pmm_2?tab=Overview\">Azure</a> Percona Monitoring and Management download pages to add your review today!</p> \n<table class=\"center\" style=\"height: 64px;\"> \n <tbody> \n  <tr> \n   <td> <p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://aws.amazon.com/marketplace/pp/B077J7FYGX?qid=1605533229523&amp;sr=0-1&amp;ref_=srh_res_product_title\" rel=\"noopener\">AWS</a></p> </td> \n   <td> <p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/percona.pmm_2?tab=Overview\" rel=\"noopener\">Azure</a></p> </td> \n  </tr> \n </tbody> \n</table>","descriptionType":"html","publishedDate":"Thu, 19 Nov 2020 16:13:43 +0000","feedId":11,"bgimg":"","linkMd5":"168520a6b7083791f3ae282e9b30f50b","bgimgJsdelivr":"","metaImg":"","author":"Daniil Bazhenov","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn75@2020_3/2020/12/01/06-05-21-091_f7c7fa0aed9b09c3.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-1024x678.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn88@2020_1/2020/12/01/06-05-24-547_cd65c4216c0bb4b7.webp"},"publishedOrCreatedDate":1606802699972},{"createdTime":"2020-12-01 14:04:59","updatedTime":"2020-12-01 14:04:59","title":"Uncommon Sense MySQL – When EXPLAIN Can Trash Your Database","link":"https://www.percona.com/blog/?p=72794","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"When EXPLAIN Can Trash Your Database\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-72799\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-300x168.png\" alt=\"When EXPLAIN Can Trash Your Database\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />If I ask you if running EXPLAIN on the query can change your database, you will probably tell me NO; it is common sense. EXPLAIN should show us how the query is executed, not execute the query, hence it can’t change any data.</p>\n<p>Unfortunately, this is the case where common sense does not apply to MySQL (at the time of this writing MySQL 8.0.21 and previous versions) &#8211; there are edge cases where EXPLAIN can actually change your database as this <a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=67632\">Bug</a> illustrates:</p><pre class=\"crayon-plain-tag\">DELIMITER $$\nCREATE FUNCTION `cleanup`() RETURNS char(50) CHARSET latin1\n    DETERMINISTIC\nBEGIN \ndelete from test.t1;\nRETURN 'OK'; \nEND $$\n\nQuery OK, 0 rows affected (0.01 sec)\n\nDELIMITER ;\n\nmysql&#62; create table t1(i int);\nmysql&#62; insert into t1 values(1); \nQuery OK, 1 row affected (0.00 sec)\n\nmysql&#62; select * from t1; \n+------+\n| i    |\n+------+\n|    1 |\n+------+\n1 row in set (0.00 sec)\n\n\nmysql&#62; explain select * from (select cleanup()) as t1clean; \n+----+-------------+------------+------------+--------+---------------+------+---------+------+------+----------+----------------+\n| id | select_type | table      | partitions | type   | possible_keys | key  | key_len | ref  | rows | filtered | Extra          |\n+----+-------------+------------+------------+--------+---------------+------+---------+------+------+----------+----------------+\n|  1 | PRIMARY     | &#60;derived2&#62; | NULL       | system | NULL          | NULL | NULL    | NULL |    1 |   100.00 | NULL           |\n|  2 | DERIVED     | NULL       | NULL       | NULL   | NULL          | NULL | NULL    | NULL | NULL |     NULL | No tables used |\n+----+-------------+------------+------------+--------+---------------+------+---------+------+------+----------+----------------+\n2 rows in set, 1 warning (0.00 sec)\n\n\nmysql&#62; select * from t1;\nEmpty set (0.00 sec)</pre><p>The problem is EXPLAIN executes the cleanup() stored function… which is permitted to modify data. This is different from the more sane PostgreSQL behavior which will NOT execute stored functions while running EXPLAIN (it will if you run EXPLAIN ANALYZE).</p>\n<p>This decision in the MySQL case comes from trying to do the right stuff and provide the most reliable explain (query execution plan may well depend on what stored function returns) but it looks like this security tradeoff was not considered.</p>\n<p>While this consequence of the current MySQL EXPLAIN design is one of the most severe, you also have the problem that EXPLAIN &#8211; which a rational user would expect to be a fast way to check the performance of a query<span> &#8211; can take unbound time to complete, for example:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; explain select * from (select sleep(5000) as a) b;</pre><p>This will run for more than an hour, creating an additional accidental (or not) Denial of Service attack vector.</p>\n<h3>Going Deeper Down the Rabbit Hole</h3>\n<p>While this behavior is unfortunate, it will happen only if you have unrestricted privileges.  If you have a more complicated setup, the behavior may vary.</p>\n<p>If the user lacks EXECUTE privilege, the EXPLAIN statement will fail.</p><pre class=\"crayon-plain-tag\">mysql&#62; explain select * from (select cleanup()) as t1clean;\nERROR 1370 (42000): execute command denied to user 'msandbox_ro'@'localhost' for routine 'test.cleanup'</pre><p>If the user has EXECUTE privilege but the user executing the stored function lacks DELETE privilege, it will fail too:</p><pre class=\"crayon-plain-tag\">mysql&#62; explain select * from (select cleanup()) as t1clean;\nERROR 1142 (42000): DELETE command denied to user 'msandbox_ro'@'localhost' for table 't2'</pre><p><strong>Note:</strong> I’m saying user executing stored function, rather than the current user, as depending on the SECURITY clause in Stored Function definition it may be run either as definer or as invoker.</p>\n<p>So what can you do if you want to improve EXPLAIN safety, for example, if you’re developing a tool like <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> which, among other features, allows users to run EXPLAIN on their queries?</p>\n<ul>\n<li>Advise users to set up privileges for monitoring correctly.  It should be the first line of defense from this (and many other) issues, however, it is hard to rely on.  Many users will choose the path of simplicity and will use “root” user with full privileges for monitoring.</li>\n<li>Wrap your EXPLAIN statement in BEGIN … ROLLBACK which will undo any damage EXPLAIN may have caused. The downside of course is the “work” of deleting the data and when undoing the work will be done. (Note: Of course this only works for Transactional tables, if you still run MyISAM…. Well in this case you have worse problems to worry about.)</li>\n<li>Use “ set transaction read-only”  to signal you’re not expecting any writes…   EXPLAIN which tries to write data will fail in this case without doing any work.</li>\n</ul>\n<p>While these workarounds can have tools running EXPLAIN safer, it does not help users running EXPLAIN directly, and I really hope this issue will be fixed by redesigning EXPLAIN in a way it is not trying to run stored functions, as PostgreSQL already does.</p>\n<p>For those who want to know how the query is executed EXACTLY, there is now EXPLAIN ANALYZE.</p>\n","descriptionType":"html","publishedDate":"Mon, 23 Nov 2020 19:41:28 +0000","feedId":11,"bgimg":"","linkMd5":"a2c6e03f020293f9f74e6cdd4bd3cb37","bgimgJsdelivr":"","metaImg":"","author":"Peter Zaitsev","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn83@2020_1/2020/12/01/06-05-53-281_7187608318f31294.webp","https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn79@2020_1/2020/12/01/06-05-00-617_a128d1f560d1816d.webp"},"publishedOrCreatedDate":1606802699935}],"record":{"createdTime":"2020-12-01 14:05:00","updatedTime":"2020-12-01 14:05:00","feedId":11,"fetchDate":"Tue, 01 Dec 2020 06:04:59 +0000","fetchMs":563,"handleMs":847,"totalMs":57850,"newArticles":0,"totalArticles":40,"status":1,"type":0,"ip":"af32bc2b950854f7e62e0df470d818c9","hostName":"us-51*","requestId":"5ee18144047148f4904bdcd779274c5c_11","contentType":"application/rss+xml; charset=UTF-8","totalBytes":380150,"bgimgsTotal":0,"bgimgsGithubTotal":0,"articlesImgsTotal":19,"articlesImgsGithubTotal":19,"successGithubMap":{"myreaderx8":1,"myreaderx25":1,"myreaderx7":1,"myreaderx27":1,"myreaderx6":1,"myreaderx21":1,"myreaderx32":1,"myreaderx11":1,"myreaderx3":1,"myreaderx33":1,"myreaderx12":1,"myreaderx23":1,"myreaderx1":1,"myreaderx24":1,"myreaderx30":1,"myreaderx31":1,"myreaderx18":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{}},"feed":{"createdTime":"2020-05-30 17:21:38","updatedTime":"2020-09-01 09:23:03","id":11,"name":"Percona Database Performance Blog","url":"https://www.percona.com/blog/feed/","subscriber":null,"website":null,"icon":"https://www.percona.com/blog/wp-content/uploads/2018/09/percona-32x32.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn89@2020_6/2020/09/01/01-23-01-358_b72bb3b39c378fe6.png","description":"","weekly":null,"link":null},"noPictureArticleList":[],"tmpCommonImgCdnBytes":0,"tmpBodyImgCdnBytes":380150,"tmpBgImgCdnBytes":0,"extra4":{"start":1606802698378,"total":0,"statList":[{"spend":747,"msg":"获取xml内容"},{"spend":847,"msg":"解释文章"},{"spend":3,"msg":"上传封面图到cdn"},{"spend":1,"msg":"修正封面图上传失败重新上传"},{"spend":55937,"msg":"正文链接上传到cdn"}]},"extra5":19,"extra6":19,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{"https://www.percona.com/blog/?p=72742_mailto:community-team@percona.com":"mailto:community-team@percona.com"},"extra111_proxyServerAndStatMap":{"http://us-53.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-55.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe63.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-028.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-035.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-024.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-001.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-25.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-54.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-004.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-033.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe67.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-016.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Impact-of-Percona-Monitoring-and-Management-Get-Latest-Command-Change-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn77@2020_6/2020/12/01/06-05-00-428_237432d3c522f403.webp","sourceBytes":30178,"destBytes":7046,"targetWebpQuality":75,"feedId":11,"totalSpendMs":902,"convertSpendMs":8,"createdTime":"2020-12-01 14:05:00","host":"us-024*","referer":"https://www.percona.com/blog/?p=72764","linkMd5ListStr":"110b8648861a3e45e1cfb59581b9835a","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.5 KB","destSize":"6.9 KB","compressRate":"23.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn79@2020_1/2020/12/01/06-05-00-617_a128d1f560d1816d.webp","sourceBytes":21756,"destBytes":7608,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1217,"convertSpendMs":9,"createdTime":"2020-12-01 14:05:00","host":"us-001*","referer":"https://www.percona.com/blog/?p=72794","linkMd5ListStr":"a2c6e03f020293f9f74e6cdd4bd3cb37","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.2 KB","destSize":"7.4 KB","compressRate":"35%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn71@2020_5/2020/12/01/06-05-02-402_cd1ace4d5421e1f3.webp","sourceBytes":86579,"destBytes":10710,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1030,"convertSpendMs":12,"createdTime":"2020-12-01 14:05:02","host":"us-036*","referer":"https://www.percona.com/blog/?p=72647","linkMd5ListStr":"eacaa3570654f49b50ab7e89696d5d64","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.5 KB","destSize":"10.5 KB","compressRate":"12.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Comic.jpg","sourceStatusCode":200,"destWidth":976,"destHeight":924,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn85@2020_2/2020/12/01/06-05-02-022_46354eac78b7cf4e.webp","sourceBytes":1206966,"destBytes":203564,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1964,"convertSpendMs":141,"createdTime":"2020-12-01 14:05:01","host":"us-036*","referer":"https://www.percona.com/blog/?p=72764","linkMd5ListStr":"110b8648861a3e45e1cfb59581b9835a","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.2 MB","destSize":"198.8 KB","compressRate":"16.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn71@2020_1/2020/12/01/06-05-02-548_ae35c9c59784fa12.webp","sourceBytes":30043,"destBytes":4938,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1459,"convertSpendMs":5,"createdTime":"2020-12-01 14:05:01","host":"europe67*","referer":"https://www.percona.com/blog/?p=72720","linkMd5ListStr":"773638760dab8c89b6b62970b3884567","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.3 KB","destSize":"4.8 KB","compressRate":"16.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn68@2020_6/2020/12/01/06-05-05-629_67d08ca1e2e99eee.webp","sourceBytes":31984,"destBytes":8502,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1701,"convertSpendMs":25,"createdTime":"2020-12-01 14:05:05","host":"us-004*","referer":"https://www.percona.com/blog/?p=72734","linkMd5ListStr":"d80df06f729a98fe1d912d7a91b5439a","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.2 KB","destSize":"8.3 KB","compressRate":"26.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn48@2020_2/2020/12/01/06-05-11-076_e8c63897daf2697d.webp","sourceBytes":17817,"destBytes":4408,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1641,"convertSpendMs":5,"createdTime":"2020-12-01 14:05:10","host":"europe-25*","referer":"https://www.percona.com/blog/?p=72728","linkMd5ListStr":"865d78407053e971745e187e83fb6e22","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"17.4 KB","destSize":"4.3 KB","compressRate":"24.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn52@2020_1/2020/12/01/06-05-13-171_eaa6c2235eb0aac1.webp","sourceBytes":25046,"destBytes":7456,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1598,"convertSpendMs":34,"createdTime":"2020-12-01 14:05:12","host":"europe63*","referer":"https://www.percona.com/blog/?p=72759","linkMd5ListStr":"dc609f1e185b8bcc7742f0b363af7ae4","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.5 KB","destSize":"7.3 KB","compressRate":"29.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn59@2020_2/2020/12/01/06-05-14-687_cc99b455a5c84e78.webp","sourceBytes":50133,"destBytes":8246,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1327,"convertSpendMs":43,"createdTime":"2020-12-01 14:05:14","host":"us-028*","referer":"https://www.percona.com/blog/?p=72802","linkMd5ListStr":"e8a660755787a04bb4ad86382430db81","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"49 KB","destSize":"8.1 KB","compressRate":"16.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-2-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn90@2020_4/2020/12/01/06-05-19-052_2a976578c97c1996.webp","sourceBytes":17886,"destBytes":4350,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1449,"convertSpendMs":9,"createdTime":"2020-12-01 14:05:18","host":"us-033*","referer":"https://www.percona.com/blog/?p=72734","linkMd5ListStr":"d80df06f729a98fe1d912d7a91b5439a","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"17.5 KB","destSize":"4.2 KB","compressRate":"24.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Recover-Percona-XtraDB-Cluster-in-Kubernetes-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn82@2020_4/2020/12/01/06-05-19-265_d1895718380451ac.webp","sourceBytes":13966,"destBytes":3272,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1714,"convertSpendMs":54,"createdTime":"2020-12-01 14:05:18","host":"us-53*","referer":"https://www.percona.com/blog/?p=72759","linkMd5ListStr":"dc609f1e185b8bcc7742f0b363af7ae4","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.6 KB","destSize":"3.2 KB","compressRate":"23.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Support-for-Percona-XtraDB-Cluster-in-ProxySQL-One-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn63@2020_3/2020/12/01/06-05-19-077_78eb906450db7ac5.webp","sourceBytes":31825,"destBytes":8486,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3229,"convertSpendMs":137,"createdTime":"2020-12-01 14:05:17","host":"us-016*","referer":"https://www.percona.com/blog/?p=72728","linkMd5ListStr":"865d78407053e971745e187e83fb6e22","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.1 KB","destSize":"8.3 KB","compressRate":"26.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Percona-Software-Release-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn92@2020_6/2020/12/01/06-05-20-591_366730b95cd0ec6a.webp","sourceBytes":42377,"destBytes":5132,"targetWebpQuality":75,"feedId":11,"totalSpendMs":936,"convertSpendMs":5,"createdTime":"2020-12-01 14:05:20","host":"us-034*","referer":"https://www.percona.com/blog/?p=72647","linkMd5ListStr":"eacaa3570654f49b50ab7e89696d5d64","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.4 KB","destSize":"5 KB","compressRate":"12.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/tightly-coupled-274x300.png","sourceStatusCode":200,"destWidth":274,"destHeight":300,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn94@2020_6/2020/12/01/06-05-20-590_ea62ee78ef8dfc42.webp","sourceBytes":20721,"destBytes":14878,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1030,"convertSpendMs":17,"createdTime":"2020-12-01 14:05:20","host":"us-035*","referer":"https://www.percona.com/blog/?p=72728","linkMd5ListStr":"865d78407053e971745e187e83fb6e22","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.2 KB","destSize":"14.5 KB","compressRate":"71.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Review-Percona-Monitoring-and-Management-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn75@2020_3/2020/12/01/06-05-21-091_f7c7fa0aed9b09c3.webp","sourceBytes":32857,"destBytes":6308,"targetWebpQuality":75,"feedId":11,"totalSpendMs":928,"convertSpendMs":8,"createdTime":"2020-12-01 14:05:21","host":"us-035*","referer":"https://www.percona.com/blog/?p=72742","linkMd5ListStr":"168520a6b7083791f3ae282e9b30f50b","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.1 KB","destSize":"6.2 KB","compressRate":"19.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/Open-Source-Alternative-to-Paying-for-MongoDB-1-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn75@2020_2/2020/12/01/06-05-24-131_b20e8120a93d0c09.webp","sourceBytes":26798,"destBytes":4328,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1575,"convertSpendMs":135,"createdTime":"2020-12-01 14:05:23","host":"us-55*","referer":"https://www.percona.com/blog/?p=72802","linkMd5ListStr":"e8a660755787a04bb4ad86382430db81","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.2 KB","destSize":"4.2 KB","compressRate":"16.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/PMM-Amazon-Azure-1024x678.jpg","sourceStatusCode":200,"destWidth":1024,"destHeight":678,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn88@2020_1/2020/12/01/06-05-24-547_cd65c4216c0bb4b7.webp","sourceBytes":95750,"destBytes":56842,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1385,"convertSpendMs":46,"createdTime":"2020-12-01 14:05:24","host":"us-55*","referer":"https://www.percona.com/blog/?p=72742","linkMd5ListStr":"168520a6b7083791f3ae282e9b30f50b","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"93.5 KB","destSize":"55.5 KB","compressRate":"59.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/How-to-Measure-Linux-Performance-Wrong-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn55@2020_2/2020/12/01/06-05-29-232_91c5779ab374879e.webp","sourceBytes":60013,"destBytes":9892,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3709,"convertSpendMs":245,"createdTime":"2020-12-01 14:05:26","host":"us-040*","referer":"https://www.percona.com/blog/?p=72720","linkMd5ListStr":"773638760dab8c89b6b62970b3884567","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"58.6 KB","destSize":"9.7 KB","compressRate":"16.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/11/When-EXPLAIN-Can-Trash-Your-Database-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn83@2020_1/2020/12/01/06-05-53-281_7187608318f31294.webp","sourceBytes":13262,"destBytes":4184,"targetWebpQuality":75,"feedId":11,"totalSpendMs":5987,"convertSpendMs":495,"createdTime":"2020-12-01 14:05:49","host":"us-54*","referer":"https://www.percona.com/blog/?p=72794","linkMd5ListStr":"a2c6e03f020293f9f74e6cdd4bd3cb37","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13 KB","destSize":"4.1 KB","compressRate":"31.5%"}],"successGithubMap":{"myreaderx8":1,"myreaderx25":1,"myreaderx7":1,"myreaderx27":1,"myreaderx6":1,"myreaderx21":1,"myreaderx32":1,"myreaderx11":1,"myreaderx3":1,"myreaderx33":1,"myreaderx12":1,"myreaderx23":1,"myreaderx1":1,"myreaderx24":1,"myreaderx30":1,"myreaderx31":1,"myreaderx18":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{}}