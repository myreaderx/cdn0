{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-08-26 13:39:44","updatedTime":"2020-08-26 13:39:44","title":"ECCV 2020 | 微软亚洲研究院精选论文摘录","link":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","description":"<div><div><div id=\"media\" class=\"rich_media_thumb_wrp\">\n\n            <img class=\"rich_media_thumb\" src=\"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAYobl9j4iblcjad7dCKYugiaTBzEuTZK656xZaE2Nq9x0aXClQIiaeibM4Q?imageView2/1/w/600\">\n        </div>\n    \n\n    \n\n    <div class=\"rich_media_content\" id=\"js_content\">\n                    \n\n                    \n\n                    \n                    \n                    <section style=\"display:none;\" data-tools=\"新媒体管家\" data-label=\"powered by xmt.cn\"><br></section><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;\"><img class=\"__bg_gif\" data-cropselx1=\"0\" data-cropselx2=\"578\" data-cropsely1=\"0\" data-cropsely2=\"116\" data-ratio=\"0.17896389324960754\" data-type=\"gif\" data-w=\"637\" style=\"box-sizing: border-box; color: rgb(62, 62, 62); max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif\"></section><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><br></section><section style=\"margin: 10px 8px;white-space: normal;\"><section style=\"border-width: 2px;border-style: dashed;border-color: rgb(160, 219, 239);box-sizing: border-box;\"><section data-width=\"50%\" style=\"width: 279px;height: 7px;background-color: rgb(255, 255, 255);\"><br></section><section style=\"margin: 15px;\"><p style=\"color: rgb(181, 180, 180);font-size: 14px;\"><span style=\"color: rgb(136, 136, 136);\">编者按：</span><span style=\"color: rgb(136, 136, 136);\">ECCV</span><span style=\"color: rgb(136, 136, 136);\">（</span><span style=\"color: rgb(136, 136, 136);\">European Conference on Computer Vision</span><span style=\"color: rgb(136, 136, 136);\">）</span><span style=\"color: rgb(136, 136, 136);\">是计算机视觉</span><span style=\"color: rgb(136, 136, 136);\">领域的</span><span style=\"color: rgb(136, 136, 136);\">三大</span><span style=\"color: rgb(136, 136, 136);\">顶会</span><span style=\"color: rgb(136, 136, 136);\">之一。</span><span style=\"color: rgb(136, 136, 136);\">今年</span><span style=\"color: rgb(136, 136, 136);\">的 </span><span style=\"color: rgb(136, 136, 136);\">ECCV </span><span style=\"color: rgb(136, 136, 136);\">大会</span><span style=\"color: rgb(136, 136, 136);\">于</span><span style=\"color: rgb(136, 136, 136);\">8月23日至28日在线上举行。</span><span style=\"color: rgb(136, 136, 136);\">微软亚洲研究院</span><span style=\"color: rgb(136, 136, 136);\">在</span><span style=\"color: rgb(136, 136, 136);\">本届大会上</span><span style=\"color: rgb(136, 136, 136);\">有</span><span style=\"color: rgb(136, 136, 136);\">21</span><span style=\"color: rgb(136, 136, 136);\">篇论文</span><span style=\"color: rgb(136, 136, 136);\">入选</span><span style=\"color: rgb(136, 136, 136);\">，</span><span style=\"color: rgb(136, 136, 136);\">本文</span><span style=\"color: rgb(136, 136, 136);\">精选了</span><span style=\"color: rgb(136, 136, 136);\">其中</span><span style=\"color: rgb(136, 136, 136);\">6篇有代表性的</span><span style=\"color: rgb(136, 136, 136);\">为大家进行介绍</span><span style=\"color: rgb(136, 136, 136);\">。</span></p></section><section data-width=\"50%\" style=\"margin-right: auto;width: 279px;height: 7px;background-color: rgb(255, 255, 255);\"><br></section></section></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">3D 算子重评估，极简新算子位置池化 PosPool</span></strong><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">A Closer Look at Local Aggregation Operators in Point Cloud Analysis</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">论文链接：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2007.01294</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">代码地址：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://github.com/zeliu98/CloserLook3D</span></p><p><span style=\"font-size:14px;\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">近些年涌现了很多不同的 3D 点云网络和算子，例如自 PointNet++、DGCN、Continuous Conv、DeepGCN、KPConv 等等，尽管它们在常见的基准评测集上的性能逐步有所提升，但由于各种网络采用不同的局部算子、整体网络结构和实现细节，所以人们对该领域的实质进步一直缺乏准确地评估。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">为此，微软亚洲研究院和中国科大的研究人员尝试对该领域的进步进行更准确、公平地评估，并提出了无需可学参数的新型 3D 点云算子位置池化 PosPool。研究指出：</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">1）尽管不同 3D 算子的设计各异，但在相同整体网络和实现细节下，所有算子的性能都惊人的相似。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">2）无需更复杂的 3D 网络，经典的深度残差网络就能在各种规模和各种场景的数据集上取得优异的表现。结合几种典型局部算子后，均能在 PartNet 上超过此前 SOTA 7个点以上。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">3）极简无参的位置池化算子 PosPool （位置池化）即能比肩各种更复杂的 3D 局部算子。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">该论文的方法没有引入复杂的设计，希望这一基准方法可以让今后 3D 点云识别的研究可以从中受益。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);font-size: 14px;\"><br></span></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"327\" data-ratio=\"0.6841552990556139\" data-s=\"300,640\" data-type=\"png\" data-w=\"953\" style=\"height: 384px; width: 562px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbArh7erYaEfPvffbq4L2HQicGw5fWHQ2O9uBHLDYdlQHdBnscN3wZAcOw/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">表</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">1</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">不同 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">3D </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">局部算子在</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">标准</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">数据集中的表现</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">（其中 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">S 表示小一些的模型，</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">PosPool </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">* 表示一种变体）</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"274\" data-ratio=\"0.4846153846153846\" data-s=\"300,640\" data-type=\"png\" data-w=\"780\" style=\"height: 274px; width: 565px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAJZZ6YEkpy37CCkMK6VvOWqPFQm8qNAGZCB1TulMYK8GeQELbUcJCRA/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">1</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">位置池化（</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">PosPool）算子示意</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">多摄像机多人三维人体姿态估计 VoxelPose</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">VoxelPose: Towards Multi-Camera 3D Human Pose Estimation in Wild</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">论文链接：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2004.06239v1.pdf</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">代码地址：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://github.com/microsoft/voxelpose-pytorch</span></p><p><span style=\"font-size:14px;\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">微软亚洲研究院的研究员在本篇论文中提出了一种新的多摄像机多人姿态估计的方法 VoxelPose。该任务存在两个重要挑战：</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">（1）将每个视角中的关键点聚类成多个实例，</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">（2）将不同视角中同一个人的关键点进行关联。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在之前的工作中，以上两个问题通常会由两个独立的模型来完成，然而在图像背景复杂、遮挡严重的情况下，因为缺少足够的信息，让这个任务变得非常困难，从而使得结果不尽如人意。在该论文中，研究员们基于 voxel 表达方式，提出了一种方法可以直接在三维空间进行推理，无需在二维图像上进行任何硬决策。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">简单来说，就是从多个摄像机的图像中构建基于 voxel 的对场景（包括人）的表达，然后提出一个检测网络用来检测人在三维空间中的大概位置，最后利用姿态估计网络在每一个检测出来的位置附近检测精细的三维人体姿态。研究员们在 Campus 和 Shelf 数据集上都大幅提升了当前最好方法的结果。重要的是，在存在非常多遮挡的场景下，该方法依然能够稳定地估计出所有人的姿态。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这是首个基于计算机视觉方案在复杂场景里进行准确的姿态估计和跟踪的方法。该方法的优化版本已被应用到微软的 Connected Store 项目中，用来估计零售商店场景下的多人姿态。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">以下是 VoxelPose 在多个公开数据集上的结果展示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-left: 8px;margin-right: 8px;\"><iframe class=\"video_iframe rich_pages\" data-vidtype=\"2\" data-mpvid=\"wxv_1488031148919357440\" data-cover=\"http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_jpg%2FHkPvwCuFwNOVQOFy10HdAwV1iaBkF7a2oacRZbJHxXarHj90YXG5yxrWrhq8nAgrAAwichtfVQVPU1Kc2GJVCK6A%2F0%3Fwx_fmt%3Djpeg\" allowfullscreen=\"\" frameborder=\"0\" data-ratio=\"1.7694444444444444\" data-w=\"1274\" data-src=\"https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_1488031148919357440\"></iframe></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">在 Panoptic 数据集上的结果</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><section style=\"margin-left: 8px;margin-right: 8px;\"><iframe class=\"video_iframe rich_pages\" data-vidtype=\"2\" data-mpvid=\"wxv_1488030120207581184\" data-cover=\"http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_jpg%2FHkPvwCuFwNOVQOFy10HdAwV1iaBkF7a2oYSLRLTDichj7CnLDmkLAZ2m4Ka34a6AjUBYNr9HVgJgwwMSrzr1h2Qg%2F0%3Fwx_fmt%3Djpeg\" allowfullscreen=\"\" frameborder=\"0\" data-ratio=\"1.4722222222222223\" data-w=\"1060\" data-src=\"https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_1488030120207581184\"></iframe></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">在 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">Campus 数据集上的结果。</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">研究员</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">并没有在这个数据集上进行训练，</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">而是</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">直接使用了在 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">Panoptic 数据集上训练好的模型</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><section style=\"margin-left: 8px;margin-right: 8px;\"><iframe class=\"video_iframe rich_pages\" data-vidtype=\"2\" data-mpvid=\"wxv_1488025208123949057\" data-cover=\"http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_jpg%2FHkPvwCuFwNOVQOFy10HdAwV1iaBkF7a2okPmqowKtbcQ1A5W5xB4dNtiaCkyjE7N5gx2GTYdx2x0ibF2UJiaajU0icA%2F0%3Fwx_fmt%3Djpeg\" allowfullscreen=\"\" frameborder=\"0\" data-ratio=\"1.325\" data-w=\"954\" data-src=\"https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_1488025208123949057\"></iframe></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">在 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">Shelf 数据集上的结果。</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">同样，</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">研究员</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">没有在这个数据集上进行训练，直接使用了在 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">Panoptic 数据集上训练好的模型</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 0.544px;background-color: rgb(160, 219, 239);\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">生成图片质量评估 GIQA</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">GIQA</span></strong><strong><span style=\"font-size: 15px;\">: Generated Image Quality Assessment</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">论文链接：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2003.08932.pdf</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">代码地址：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://github.com/cientgu/GIQA</span></p><p><span style=\"font-size:14px;\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这些年来，深度生成模型取得了巨大的进展，然而并非所有生成的结果都十分完美。微软亚洲研究院提出了一个新的研究领域：生成图片质量评估 (GIQA)，并从两个角度提出了三种 GIQA 的方法，对单张生成图片的质量进行打分，并筛选出符合需求的图片。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"283\" data-ratio=\"0.44945848375451264\" data-s=\"300,640\" data-type=\"png\" data-w=\"554\" style=\"height: 260px; width: 578px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAZu28ibTfvSBF9NedX3XXxg6AfibB2OIyL3NgJh0ZG1MfY6MX0x4saoGg/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">2</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">G</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">IQA </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">对生成图片的打分分布</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">首先是基于学习的 GIQA：研究员们发现在训练 GAN 的时候，生成图片的质量会随着迭代次数的增加越来越好。所以，一个直接的想法就是用迭代次数当质量的“伪标签”，通过监督式的学习来学一个打分器，从而对生成图片的质量进行打分。该方法被称之为 MBC-GIQA。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">另一种思路是基于数据驱动的 GIQA：其核心思想是用一张生成图片来自于真实分布的概率去衡量图片的质量，概率越大，质量越高。然而这需要对真实分布进行建模，因此，基于所建模型的不同，研究员们提出了两种方法 GMM-GIQA 和 KNN-GIQA。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究员们收集了 LGIQA 质量评估数据集，并衡量了此次提出的方法，发现 GMM-GIQA 能取得最好的结果，远远超过传统的图像质量评估方法。所以，GMM-GIQA 是目前最推荐使用的方法。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"260\" data-ratio=\"0.7656078860898138\" data-s=\"300,640\" data-type=\"png\" data-w=\"913\" style=\"width: 562px; height: 430px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAFUPYcNwYPj7AAY2cNBQ5Ciap7SytjcTeObLIZw0iaEE4ZDlrE69QZZiaQ/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">3：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">微软亚洲研究院</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">的方法和之前的方法</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">挑出的最高质量和最低质量的图片</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">微软亚洲研究院的新方法还有很多衍生应用。其中一个是模型质量评估。对于生成模型，可以独立的衡量生成图片的质量和多样性。另一个有趣的应用是通过后处理丢弃一部分图片，让剩下的图片有更好的生成质量。此外，研究员们还通过结合 OHEM，在 GAN 的训练过程中，给低质量生成图片更高的惩罚权重，从而让 GAN 生成出更高质量的图片。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">整体来看，GIQA 是一个新颖且对学术界和产业界都很有意义的研究方向，经验证，新提出的几种 GIQA 方法，都具有相当高的有效性和应用价值。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">基于物理与神经网络的光照估计</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">Object-based Illumination Estimation with Rendering-aware Neural Networks</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">论文链接： </span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2008.02514v1.pdf</span></p><p><span style=\"font-size:14px;\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">混合现实（Mixed Reality）技术允许用户将虚拟物体与真实世界相融合，得以实现类似在现实世界中观察虚拟物体的效果。然而，如何将虚拟物体按照真实的环境进行绘制依然是一个具有挑战的问题。真实世界中的物体都是受到周围真实环境的光照照射的，如果绘制混合的虚拟物体无法保持一致的光照效果，用户则会感受到光照的不一致性，从而影响观感体验。因此，研究人员需要根据当前的，即将混合虚拟物体的真实世界照片，来估计当前真实环境中的光照条件。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">传统的基于图像的光照估计算法往往从图像的全局考虑，并假设输入图像是背景环境光照的一部分，而在一些混合现实的应用中，用户的视角往往会集中于场景的一个局部。针对这样的输入数据，传统基于全局信息的光照估计算法很难给出稳定的光照预测。为了解决这一问题，微软亚洲研究院的研究员们提出了一种基于场景局部光影信息来进行光照估计的算法。仅仅给定一个场景的局部作为输入，但这个局部中物体本身的高光反射、阴影变化等都反映了当前环境光照的信息，可以有效的作为光照估计的线索。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">然而，场景中物体的光影与环境光照的关系是一个比较复杂的过程，虽然可以利用基于物理的渲染方法来模拟这一过程，但由于这个关系的高度非线性性质使得从光影反向推导光照的问题难于进行优化。更重要的是，这一反向求解光照的过程同时会受到场景的几何形体，材质属性等性质的影响，因此，纯粹基于物理的反向优化方法往往难以准确得到精确、稳定的求解。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">针对这一问题，微软亚洲研究院的研究员们将基于物理的光照计算与基于学习的神经网络训练相结合，同时利用基于物理计算对于光照与光影之间的已知关系，以及神经网络的可学习型和鲁棒性，得到了基于物理知识的光照估计神经网络。此外，研究员们还设计了一个循环卷积网络 (Recurrent-CNN) 通过利用输入视频的时间序列，提高光照估计在整个视频上的稳定性。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">实验表明，本篇论文提出的光照估计方法可以有效地根据场景中局部物体上的光影效果来估计当前的环境光照。该方法适用于不同场景以及不同的物体材质属性，极大地提高了混合现实渲染的真实感和用户体验。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"325\" data-ratio=\"0.75\" data-s=\"300,640\" data-type=\"png\" data-w=\"376\" style=\"height: 422px; width: 562px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbA3iaehaUqJ0vt3hamBljSEC1KOudibRYTVQAPIibibQQShhOtdsKiaibkibEWw/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">4</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">输入图像</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><img class=\"rich_pages js_insertlocalimg\" data-backh=\"284\" data-backw=\"378\" data-ratio=\"0.7513227513227513\" data-s=\"300,640\" data-type=\"png\" data-w=\"378\" style=\"width: 100%; height: auto; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAwajzz0KdIC4HhfIZfLlANkndeaqNsxaRvLyMOPEcQibYvSC4ibuOoTIQ/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图5：嵌入虚拟物体的绘制效果，虚拟物体的光影根据估计出的环境光照计算得出</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">SRNet: 提升三维人体姿态估计的泛化能力</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">SRNet: Improving Generalization in 3D Human Pose Estimation</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">论文地址：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2007.09389</span></p><p><span style=\"font-size:14px;\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">许多基于深度学习的视觉识别任务，在实际应用中，都会因为遭受训练数据的“长尾分布”问题而使得性能下降。对于三维人体姿态估计任务来说也是如此，训练数据中很稀少甚至是从来没有见过的姿态，在测试时往往效果不佳，即模型不能很好地泛化。但有趣的是，“局部”的人体姿态，从统计上并没有遭受严重的长尾问题。比如，一个在测试时从来没有见过的姿态，它的每一个“局部”姿态可能都在训练数据里见过，如图6所示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"521\" data-ratio=\"0.294996751137102\" data-s=\"300,640\" data-type=\"png\" data-w=\"1539\" style=\"width: 578px; height: 171px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAUhSPXC0icB3icSWbkCLAqo03fuqv2Sd3lkROvWj6RPwYvzAGGicHuJiciaQ/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">6</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">一个没有见过的测试姿态 </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">(b) 可以被分解成若干局部姿态 (c)，而这些局部姿态在训练数据 (a) 中都见过。</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">SRNet </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">方法利用了这个性质来提升对于稀少或者是没有见过的人体姿态的估计性能</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"font-size: 15px;text-align: justify;\">基于这个观察，研究员们设计出了一个如图7 (c)(d) 所示的网络结构，命名为 SRNet。该</span><span style=\"font-size: 15px;text-align: justify;\">方法首先把所有的人体关键点分解成若干个组，因为组内的各个关键点有着更强的相互关联，而组与组之间关键点的关联则相对较弱。</span><span style=\"font-size: 15px;text-align: justify;\">每个组内的关键点会先经过一个独立的子网络以加强局部关系（特征）的计算。</span><span style=\"font-size: 15px;text-align: justify;\">然后，通过从剩下其他组的关键点中计算出一个“低维的全局信息”，再加回到这个组，来表示组内的关键点和组外关键点的弱相关关系。</span><span style=\"font-size: 15px;text-align: justify;\">通过控制这个“全局信息”的维度，组内的关键点学习既减弱了对组外的弱相关关键点的依赖，又没有丢失全局的一致性。</span><span style=\"font-size: 15px;text-align: justify;\">由于减弱了对弱相关关键点的依赖，该模型能够更好地反映“局部”姿态的分布，从而可以更好地泛化到新的组合姿态中去。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages\" data-cropselx1=\"56\" data-cropselx2=\"506\" data-cropsely1=\"0\" data-cropsely2=\"224\" data-ratio=\"0.27815610267155577\" data-s=\"300,640\" data-type=\"png\" data-w=\"1909\" style=\"height: 161px; width: 578px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAu4Ss4wpcL3hK3l6pBIDuQKTGZEUrZTeHFfJY66Mgibb2DvUib6jDcCCg/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"font-size: 12px;color: rgb(123, 127, 131);\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">7</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"> (a) </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">全连接层</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">；</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">(b) </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">分组连接层</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">；</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">(c) SR (split-and-recombine) </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">连接层</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">；</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">(d) SR </span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">卷积层</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究员们在 Human3.6M，MPI-INF-3DHP 等数据集上，通过详实的对比实验验证了 SRNet 的有效性。尤其是在跨数据集(提升19.3%)，跨动作(提升12.2%)以及不常见姿态(提升39.7%)的测试上，SRNet 都带来了大幅的性能提升，超越了之前的方法。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">TCGM: 基于信息论的多模态半监督学习框架</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">TCGM: An Information-Theoretic Framework for Semi-Supervised Multi-Modality Learning</span></strong></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: left;line-height: 1.75em;\"><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">论文地址：</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2007.06793v1.pdf</span><span style=\"font-size: 12px;color: rgb(136, 136, 136);\"> </span></p><p style=\"text-align:left;\"><span style=\"color:rgb(0,0,0);font-size:15px;background:rgb(255,255,255);\"> </span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">相比较单模态，利用多模态数据学习可以融合多个角度的信息，从而能够学到更加鲁邦的模型。如图8所示，临床医学上，人们可以利用 X 光片、看病记录等多个信息来进行疾病诊断。然而，在很多实际应用中 (比如医疗)，获取标签成本较高，因此数据中会只有一部分样本具有标注信息，即所谓的半监督学习。微软亚洲研究院的研究员们在本篇论文中阐述了如何利用多模态信息，更有效率地学到性能较好的分类器。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"543\" data-cropsely1=\"0\" data-cropsely2=\"152\" data-ratio=\"0.39651416122004357\" data-s=\"300,640\" data-type=\"png\" data-w=\"918\" style=\"width: 543px; height: 215px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAHoY7tdAsPtItXtncRKLnLa9L2PzqE06ZyJxaHibrHavdbLIIibJx1LQw/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">8</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">左图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">-</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">条件独立假设（医疗），右图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">-</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">真实标签为所有模态的交叉信息</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在多模态学习中，一个公认的假设是，标签 Y 是所有模态的“交叉信息”，去除掉标签后，所有模态信息独立，如图8（右图）所示。这一交叉信息可以被全相关这一指标所刻画。全相关用来描述多个变量间的公共信息，在模态数为2时，则退化为互信息。因此，假设数据有 M 个模态，那么可以选择在无标签样本上最大化 M 个模态的全相关的下界。这一下界可以表达为 M 个分类器的函数。理论证明，最大化这一下界可以学到贝叶斯分类器的排列变换。而在有标签的数据上，则最小化每个分类器的交叉熵，从而唯一地学到贝叶斯分类器。微软亚洲研究院的研究员们将该方法称为全相关收益最大化方法 (TCGM)。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究员们用 D_u≔{x_i^([M]) }_i 表示无标签数据，D_l≔{(x_i^[M] ,y_i)}_i 表示有标签数据，其中 x_i^([M])≔{x_i^1,…,x_i^M } 和 y_i 分别表示第 i 个样本的 M 个模态的数据和标签，并且用 h_m 来表示第 m 个分类器，p_c 来表示第 c 类别的先验分布。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">本篇论文提出的全相关收益最大化方法可以概括为在 D_l 上训练各个分类器，并在无标签数据 D_u 上最大化 M 个模态的全相关的下界。对于后者，根据 f-divergence 理论以及标签 Y 是交叉信息的假设，可以将全相关的对偶下界表示为 M 个分类器函数，这一函数的经验分布形式为：</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"5\" data-cropselx2=\"557\" data-cropsely1=\"0\" data-cropsely2=\"213\" data-ratio=\"0.35823170731707316\" data-s=\"300,640\" data-type=\"png\" data-w=\"656\" style=\"width: 578px; height: 207px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdueMmzDJBluAxfBbDmxia2R5GXIGACAuUY9NSUia3XSmiahgRhYeicusMg/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"font-size: 15px;\">该函数可以看成是两项相减，第一项表示对于同一个样本，M 个分类器输出一致的标签，并在第二项上约束这些分类器在不同样本上的表现不同，如图9所示。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"42\" data-cropselx2=\"520\" data-cropsely1=\"0\" data-cropsely2=\"421\" data-ratio=\"0.3373493975903614\" data-s=\"300,640\" data-type=\"png\" data-w=\"1162\" style=\"width: 578px; height: 195px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAZiceiaMYoWWXnhNGty9PtibIxcuZibFmSlyHgNwcNNgGZvrEyrmMicbv7ibg/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">9</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">全相关收益最大化框架</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"font-size: 15px;text-align: justify;\">理论证明，通过最大化这一函数，学到的 {h_m }_m 为贝叶斯分类器的排列变换。</span><span style=\"font-size: 15px;text-align: justify;\">进而，研究员们在有标签的数据上分别训练这 M 个分类器，从而可以唯一地学到贝叶斯分类器。</span><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"font-size: 15px;\"><br></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: justify;\"><span style=\"font-size: 15px;\">为了验证方法的有效性，研究员们在新闻分类，阿尔茨海默疾病以及情绪识别上做了实验（如图10、11、12）。在这些实验中，TCGM 方法都比已有方法取得了更好的效果，尤其是当标签比例较低时。</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"160\" data-ratio=\"0.2962962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1269\" style=\"width: 562px; height: 167px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAqTd7HE2Pyk9iblUib9YvQibA9EqWNYvbIBUNIkVWia7ibpbUENBn3WkuWYw/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">10</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">新闻分类实验</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"298\" data-ratio=\"0.21106719367588933\" data-s=\"300,640\" data-type=\"png\" data-w=\"1265\" style=\"width: 578px; height: 122px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdZwKasWe7nSeIavphFnOI7ARMibS4qaeScBNr0icY0XOl8UWcEC6n85w/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">1</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">1</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">阿尔茨海默疾病预测</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;\"><br></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><img class=\"rich_pages js_insertlocalimg\" data-cropselx1=\"0\" data-cropselx2=\"562\" data-cropsely1=\"0\" data-cropsely2=\"156\" data-ratio=\"0.9654036243822076\" data-s=\"300,640\" data-type=\"png\" data-w=\"1214\" style=\"width: 562px; height: 543px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbA0qQFaegwWcZVByjVTcHdxZ7vvUDu67jo2sWzOTmjkgJe0smzUG7icSQ/640?wx_fmt=png\"></section><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">图</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">1</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">2</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">：</span><span style=\"color: rgb(123, 127, 131);font-size: 12px;\">情绪识别</span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;\"><span style=\"color: rgb(123, 127, 131);font-size: 12px;\"></span></p><section style=\"white-space: normal;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;background-color: rgb(255, 255, 255);\"><section style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"margin-top: 10px;margin-bottom: 10px;text-align: center;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"margin-bottom: -3px;padding-top: 3px;width: 677px;border-bottom: 1px dotted rgb(160, 160, 160);max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><br style=\"box-sizing: border-box;max-width: 100%;overflow-wrap: break-word;\"></section><section style=\"height: 5px;line-height: 5px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"vertical-align: top;display: inline-block;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><span style=\"margin-left: 5px;border-color: rgb(160, 160, 160);border-radius: 50%;border-style: solid;border-width: 1px;box-sizing: border-box;float: left;height: 5px;max-width: 100%;overflow-wrap: break-word;width: 5px;\"><br style=\"box-sizing: border-box;max-width: 100%;overflow-wrap: break-word;\"></span></section><section style=\"clear: both;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><br></section></section></section></section></section><section style=\"white-space: normal;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;background-color: rgb(255, 255, 255);\"><section style=\"max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"margin-top: 10px;margin-bottom: 10px;text-align: center;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"height: 5px;line-height: 5px;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><section style=\"clear: both;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;\"><br style=\"box-sizing: border-box;max-width: 100%;overflow-wrap: break-word;\"></section></section></section></section></section><p style=\"white-space: normal;\"><br></p><p style=\"margin-right: 8px;margin-left: 8px;white-space: normal;min-height: 1em;max-width: 100%;box-sizing: border-box;overflow-wrap: break-word;background-color: rgb(255, 255, 255);\"><strong style=\"box-sizing: border-box;color: rgb(46, 87, 151);font-size: 15px;letter-spacing: 1px;max-width: 100%;overflow-wrap: break-word;\">你也许还想看</strong><strong style=\"box-sizing: border-box;color: rgb(46, 87, 151);font-size: 15px;letter-spacing: 1px;max-width: 100%;overflow-wrap: break-word;\">：</strong></p><section style=\"margin-right: 8px;margin-left: 8px;white-space: normal;text-align: center;\"><br></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455372&amp;idx=1&amp;sn=7f8f46324956d2a7e24039824068b9c6&amp;chksm=82c09288b5b71b9e876ca154923eb1a7daac97d4ca91d7ca079fac083bb527a1bbd4b9428985&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAm4IPBk63g8Ld4qM3rYrnsXnC7ZzM0a1tZqwWkaojDiaj8WZJfiadWD2Q/640?wx_fmt=png\"></span></a></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649452952&amp;idx=1&amp;sn=95d48c22815dfd872858e1dabd3d4b6a&amp;chksm=82c0981cb5b7110a3f7fb37f0f18bb4f37219dcb2b7443a6236d1bd5fcca1c1ce9b6076de06c&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"0\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdVez8pZAwAnibxfkdcawLdoqrY4hbI7krTTOfMEr2bZZtcaIL5hobKQ/640?wx_fmt=png\"></span></a></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\"><a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455241&amp;idx=1&amp;sn=91afeb0a1a2af377cca1603b85d98381&amp;chksm=82c0930db5b71a1b6ba168bf98d5482fee05e0289dc8d3f5de8a67e576cf11342fe9918e5d4d&amp;scene=21#wechat_redirect\" textvalue=\"你已选中了添加链接的内容\" data-itemshowtype=\"11\" tab=\"innerlink\" data-linktype=\"1\"><span class=\"js_jump_icon h5_image_link\" data-positionback=\"static\" style=\"top: auto;left: auto;margin: 0px;right: auto;bottom: auto;\"><img class=\"rich_pages\" data-ratio=\"0.3322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" style=\"margin: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAibBDPjdvYbPlJ1ibAOgWMaSibyy0kDVOCsJ4tdpSk49sSOgRznDXr6GTg/640?wx_fmt=png\"></span></a></section><section style=\"margin: 20px 8px;white-space: normal;display: flex;justify-content: center;align-items: center;\"><section data-width=\"90%\" style=\"background: rgb(137, 137, 137);width: 562px;height: 2px;\"><br></section></section><p style=\"margin-left: 8px;white-space: normal;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 15px;letter-spacing: 1px;\"><img class=\"__bg_gif\" data-copyright=\"0\" data-ratio=\"0.5\" data-type=\"gif\" data-w=\"750\" style=\"box-sizing: border-box; color: rgb(51, 51, 51); max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif\"></span></p><p><br></p>\n                </div>\n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649455452&amp;idx=1&amp;sn=724935f743db375fba21af541167a8d4&amp;chksm=82c092d8b5b71bce8b72ca903bd8abd3b38b5cabf5f56013a1821c14eb0a12f0d098badf9d17&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/5416/pFH96R1EDQ\"></div></div>","descriptionType":"html","publishedDate":"Tue, 25 Aug 2020 10:02:00 +0000","feedId":1700,"bgimg":"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAYobl9j4iblcjad7dCKYugiaTBzEuTZK656xZaE2Nq9x0aXClQIiaeibM4Q?imageView2/1/w/600","linkMd5":"783d43dca630cab969820cf8846c7eff","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn47@2020_3/2020/08/26/05-39-45-301_8948999b53989455.webp","destWidth":600,"destHeight":448,"sourceBytes":21670,"destBytes":18816,"author":"","articleImgCdnMap":{"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAYobl9j4iblcjad7dCKYugiaTBzEuTZK656xZaE2Nq9x0aXClQIiaeibM4Q?imageView2/1/w/600":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn47@2020_3/2020/08/26/05-39-45-301_8948999b53989455.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn12@2020_6/2020/08/26/05-39-47-378_d8f757d4d88b52d6.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbArh7erYaEfPvffbq4L2HQicGw5fWHQ2O9uBHLDYdlQHdBnscN3wZAcOw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn59@2020_4/2020/08/26/05-40-00-143_4085d3c346c72b7c.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAJZZ6YEkpy37CCkMK6VvOWqPFQm8qNAGZCB1TulMYK8GeQELbUcJCRA/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn23@2020_4/2020/08/26/05-39-50-946_af426678aa1b4929.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAZu28ibTfvSBF9NedX3XXxg6AfibB2OIyL3NgJh0ZG1MfY6MX0x4saoGg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn95@2020_1/2020/08/26/05-39-48-573_3ad3557c6dd48936.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAFUPYcNwYPj7AAY2cNBQ5Ciap7SytjcTeObLIZw0iaEE4ZDlrE69QZZiaQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbA3iaehaUqJ0vt3hamBljSEC1KOudibRYTVQAPIibibQQShhOtdsKiaibkibEWw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn62@2020_5/2020/08/26/05-39-49-364_2e696832de26d775.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAwajzz0KdIC4HhfIZfLlANkndeaqNsxaRvLyMOPEcQibYvSC4ibuOoTIQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn75@2020_3/2020/08/26/05-39-49-027_39557f4fb573c4e1.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAUhSPXC0icB3icSWbkCLAqo03fuqv2Sd3lkROvWj6RPwYvzAGGicHuJiciaQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/26/05-39-52-643_215de131da00cf83.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAu4Ss4wpcL3hK3l6pBIDuQKTGZEUrZTeHFfJY66Mgibb2DvUib6jDcCCg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn51@2020_6/2020/08/26/05-40-50-750_969510140e8ac78a.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAHoY7tdAsPtItXtncRKLnLa9L2PzqE06ZyJxaHibrHavdbLIIibJx1LQw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn7@2020_3/2020/08/26/05-39-49-872_1dd0c0b57a288f73.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdueMmzDJBluAxfBbDmxia2R5GXIGACAuUY9NSUia3XSmiahgRhYeicusMg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn67@2020_2/2020/08/26/05-39-48-718_3558fdfc865c907a.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAZiceiaMYoWWXnhNGty9PtibIxcuZibFmSlyHgNwcNNgGZvrEyrmMicbv7ibg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn91@2020_4/2020/08/26/05-39-51-671_384d3543f4e0991d.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAqTd7HE2Pyk9iblUib9YvQibA9EqWNYvbIBUNIkVWia7ibpbUENBn3WkuWYw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn80@2020_4/2020/08/26/05-40-48-010_6c2280212d7d2d41.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdZwKasWe7nSeIavphFnOI7ARMibS4qaeScBNr0icY0XOl8UWcEC6n85w/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn53@2020_3/2020/08/26/05-39-52-127_3e46d1fd286671ee.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbA0qQFaegwWcZVByjVTcHdxZ7vvUDu67jo2sWzOTmjkgJe0smzUG7icSQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn13@2020_1/2020/08/26/05-39-49-796_80be9fcf95efc4ce.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAm4IPBk63g8Ld4qM3rYrnsXnC7ZzM0a1tZqwWkaojDiaj8WZJfiadWD2Q/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn85@2020_3/2020/08/26/05-39-51-995_c41d07bef20fcf41.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdVez8pZAwAnibxfkdcawLdoqrY4hbI7krTTOfMEr2bZZtcaIL5hobKQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn4@2020_1/2020/08/26/05-40-14-253_dfe4f45435ef2fb0.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAibBDPjdvYbPlJ1ibAOgWMaSibyy0kDVOCsJ4tdpSk49sSOgRznDXr6GTg/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn26@2020_1/2020/08/26/05-39-51-059_20d56a946ce913e2.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNLsud1BZ6dFjDQiaG01NGT1z7llzgFU2U91l2cXywRJmR0FZ8SrqEpzuibSgI078eLPTHIlPElysjQ/640?wx_fmt=gif":null,"http://www.jintiankansha.me/rss_static/5416/pFH96R1EDQ":null},"publishedOrCreatedDate":1598420384006}],"record":{"createdTime":"2020-08-26 13:39:44","updatedTime":"2020-08-26 13:39:44","feedId":1700,"fetchDate":"Wed, 26 Aug 2020 05:39:44 +0000","fetchMs":829,"handleMs":24,"totalMs":124735,"newArticles":0,"totalArticles":5,"status":1,"type":0,"ip":"08297f4387a502fbde404afdd8347187","hostName":"us-028*","requestId":"87e7dc43b4a54a609bdc821001fbd1f4_1700","contentType":"application/rss+xml","totalBytes":575502,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":21,"articlesImgsGithubTotal":18,"successGithubMap":{"myreaderx8":1,"myreaderx14":1,"myreaderx15":1,"myreaderx7":1,"myreaderx6":1,"myreaderx27":1,"myreaderx16":1,"myreaderx10":1,"myreaderx4":1,"myreaderx32":1,"myreaderx33":1,"myreaderx11":1,"myreaderx23":1,"myreaderx24":1,"myreaderx30":1,"myreaderx18":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{}},"feed":{"createdTime":"2020-08-24 21:31:32","updatedTime":"2020-08-24 22:50:33","id":1700,"name":"微软研究院AI头条","url":"http://feedmaker.kindle4rss.com/feeds/MSRAsia.weixin.xml","subscriber":null,"website":null,"icon":"http://www.sogou.com/images/logo/new/favicon.ico?v=4","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx64/cdn42@2020_3/2020/08/24/14-36-06-428_d24121c9beed1de6.ico","description":"专注科研18年，盛产黑科技","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2020-08-26 13:41:47","updatedTime":"2020-08-26 13:41:47","id":null,"feedId":1700,"linkMd5":"783d43dca630cab969820cf8846c7eff"}],"tmpCommonImgCdnBytes":18816,"tmpBodyImgCdnBytes":556686,"tmpBgImgCdnBytes":0,"extra4":{"start":1598420383020,"total":0,"statList":[{"spend":963,"msg":"获取xml内容"},{"spend":24,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":121624,"msg":"正文链接上传到cdn"}]},"extra5":21,"extra6":19,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5416/pFH96R1EDQ","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1068,"convertSpendMs":0,"createdTime":"2020-08-26 13:39:46","host":"europe21*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5416/pFH96R1EDQ","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1700,"totalSpendMs":1078,"convertSpendMs":0,"createdTime":"2020-08-26 13:39:47","host":"us-021*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},null,null,null,null,null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-032.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-037.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-24.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-021.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://us-015.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-011.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-020.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-25.herokuapp.com/":{"failCount":1,"successCount":2,"resultList":[200,null,200]},"http://us-54.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe21.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://us-004.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-033.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-51.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-008.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-016.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-014.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-012.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://img.100weidu.com/mmbiz_jpg/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAYobl9j4iblcjad7dCKYugiaTBzEuTZK656xZaE2Nq9x0aXClQIiaeibM4Q?imageView2/1/w/600","sourceStatusCode":200,"destWidth":600,"destHeight":448,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn47@2020_3/2020/08/26/05-39-45-301_8948999b53989455.webp","sourceBytes":21670,"destBytes":18816,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":2081,"convertSpendMs":24,"createdTime":"2020-08-26 13:39:44","host":"us-024*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff,783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.2 KB","destSize":"18.4 KB","compressRate":"86.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/HkPvwCuFwNNEt7x0uibwVJAbgnJV0icdoRML1sUKS9L9SpjIvZyC2vgKbiboFDiaup5tONBH57X824fS9nHjEcDLcg/640?wx_fmt=gif","sourceStatusCode":200,"destWidth":637,"destHeight":114,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn12@2020_6/2020/08/26/05-39-47-378_d8f757d4d88b52d6.webp","sourceBytes":21989,"destBytes":14032,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":2086,"convertSpendMs":184,"createdTime":"2020-08-26 13:39:46","host":"us-011*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.5 KB","destSize":"13.7 KB","compressRate":"63.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAZu28ibTfvSBF9NedX3XXxg6AfibB2OIyL3NgJh0ZG1MfY6MX0x4saoGg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":554,"destHeight":249,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn95@2020_1/2020/08/26/05-39-48-573_3ad3557c6dd48936.webp","sourceBytes":139919,"destBytes":21722,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":3237,"convertSpendMs":15,"createdTime":"2020-08-26 13:39:46","host":"us-008*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"136.6 KB","destSize":"21.2 KB","compressRate":"15.5%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdueMmzDJBluAxfBbDmxia2R5GXIGACAuUY9NSUia3XSmiahgRhYeicusMg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":656,"destHeight":235,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn67@2020_2/2020/08/26/05-39-48-718_3558fdfc865c907a.webp","sourceBytes":15417,"destBytes":12780,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":3370,"convertSpendMs":7,"createdTime":"2020-08-26 13:39:46","host":"us-016*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.1 KB","destSize":"12.5 KB","compressRate":"82.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAwajzz0KdIC4HhfIZfLlANkndeaqNsxaRvLyMOPEcQibYvSC4ibuOoTIQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":378,"destHeight":284,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn75@2020_3/2020/08/26/05-39-49-027_39557f4fb573c4e1.webp","sourceBytes":124243,"destBytes":7600,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":3579,"convertSpendMs":16,"createdTime":"2020-08-26 13:39:46","host":"us-004*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"121.3 KB","destSize":"7.4 KB","compressRate":"6.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbA3iaehaUqJ0vt3hamBljSEC1KOudibRYTVQAPIibibQQShhOtdsKiaibkibEWw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":376,"destHeight":282,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn62@2020_5/2020/08/26/05-39-49-364_2e696832de26d775.webp","sourceBytes":132946,"destBytes":7632,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":4013,"convertSpendMs":11,"createdTime":"2020-08-26 13:39:46","host":"us-014*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"129.8 KB","destSize":"7.5 KB","compressRate":"5.7%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAHoY7tdAsPtItXtncRKLnLa9L2PzqE06ZyJxaHibrHavdbLIIibJx1LQw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":918,"destHeight":364,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn7@2020_3/2020/08/26/05-39-49-872_1dd0c0b57a288f73.webp","sourceBytes":82769,"destBytes":16364,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":4514,"convertSpendMs":24,"createdTime":"2020-08-26 13:39:46","host":"us-037*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"80.8 KB","destSize":"16 KB","compressRate":"19.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbA0qQFaegwWcZVByjVTcHdxZ7vvUDu67jo2sWzOTmjkgJe0smzUG7icSQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":1043,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn13@2020_1/2020/08/26/05-39-49-796_80be9fcf95efc4ce.webp","sourceBytes":373673,"destBytes":77058,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":4595,"convertSpendMs":67,"createdTime":"2020-08-26 13:39:46","host":"us-012*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"364.9 KB","destSize":"75.3 KB","compressRate":"20.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAJZZ6YEkpy37CCkMK6VvOWqPFQm8qNAGZCB1TulMYK8GeQELbUcJCRA/640?wx_fmt=png","sourceStatusCode":200,"destWidth":780,"destHeight":378,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn23@2020_4/2020/08/26/05-39-50-946_af426678aa1b4929.webp","sourceBytes":95046,"destBytes":26104,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5594,"convertSpendMs":20,"createdTime":"2020-08-26 13:39:46","host":"us-040*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"92.8 KB","destSize":"25.5 KB","compressRate":"27.5%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAibBDPjdvYbPlJ1ibAOgWMaSibyy0kDVOCsJ4tdpSk49sSOgRznDXr6GTg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn26@2020_1/2020/08/26/05-39-51-059_20d56a946ce913e2.webp","sourceBytes":228339,"destBytes":30706,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5715,"convertSpendMs":20,"createdTime":"2020-08-26 13:39:46","host":"us-51*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"223 KB","destSize":"30 KB","compressRate":"13.4%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAZiceiaMYoWWXnhNGty9PtibIxcuZibFmSlyHgNwcNNgGZvrEyrmMicbv7ibg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":364,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn91@2020_4/2020/08/26/05-39-51-671_384d3543f4e0991d.webp","sourceBytes":97958,"destBytes":20326,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":6304,"convertSpendMs":26,"createdTime":"2020-08-26 13:39:46","host":"us-020*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"95.7 KB","destSize":"19.8 KB","compressRate":"20.7%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAm4IPBk63g8Ld4qM3rYrnsXnC7ZzM0a1tZqwWkaojDiaj8WZJfiadWD2Q/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn85@2020_3/2020/08/26/05-39-51-995_c41d07bef20fcf41.webp","sourceBytes":353237,"destBytes":44882,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":6702,"convertSpendMs":28,"createdTime":"2020-08-26 13:39:46","host":"us-033*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"345 KB","destSize":"43.8 KB","compressRate":"12.7%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdZwKasWe7nSeIavphFnOI7ARMibS4qaeScBNr0icY0XOl8UWcEC6n85w/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":228,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn53@2020_3/2020/08/26/05-39-52-127_3e46d1fd286671ee.webp","sourceBytes":34074,"destBytes":20240,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":6956,"convertSpendMs":13,"createdTime":"2020-08-26 13:39:46","host":"europe-25*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.3 KB","destSize":"19.8 KB","compressRate":"59.4%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAUhSPXC0icB3icSWbkCLAqo03fuqv2Sd3lkROvWj6RPwYvzAGGicHuJiciaQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":319,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/26/05-39-52-643_215de131da00cf83.webp","sourceBytes":419864,"destBytes":31854,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":5291,"convertSpendMs":30,"createdTime":"2020-08-26 13:39:48","host":"us-015*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"410 KB","destSize":"31.1 KB","compressRate":"7.6%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbArh7erYaEfPvffbq4L2HQicGw5fWHQ2O9uBHLDYdlQHdBnscN3wZAcOw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":953,"destHeight":652,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn59@2020_4/2020/08/26/05-40-00-143_4085d3c346c72b7c.webp","sourceBytes":458730,"destBytes":123014,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":14979,"convertSpendMs":57,"createdTime":"2020-08-26 13:39:46","host":"us-040*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"448 KB","destSize":"120.1 KB","compressRate":"26.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAdVez8pZAwAnibxfkdcawLdoqrY4hbI7krTTOfMEr2bZZtcaIL5hobKQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":900,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn4@2020_1/2020/08/26/05-40-14-253_dfe4f45435ef2fb0.webp","sourceBytes":141321,"destBytes":19508,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":28966,"convertSpendMs":17,"createdTime":"2020-08-26 13:39:46","host":"europe-59*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"138 KB","destSize":"19.1 KB","compressRate":"13.8%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAqTd7HE2Pyk9iblUib9YvQibA9EqWNYvbIBUNIkVWia7ibpbUENBn3WkuWYw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":320,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn80@2020_4/2020/08/26/05-40-48-010_6c2280212d7d2d41.webp","sourceBytes":77480,"destBytes":40348,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":2756,"convertSpendMs":17,"createdTime":"2020-08-26 13:40:46","host":"europe-25*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"75.7 KB","destSize":"39.4 KB","compressRate":"52.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPssWha3JFq0Qod3h7C9PbAu4Ss4wpcL3hK3l6pBIDuQKTGZEUrZTeHFfJY66Mgibb2DvUib6jDcCCg/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":300,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn51@2020_6/2020/08/26/05-40-50-750_969510140e8ac78a.webp","sourceBytes":219459,"destBytes":42516,"targetWebpQuality":75,"feedId":1700,"totalSpendMs":4003,"convertSpendMs":26,"createdTime":"2020-08-26 13:40:47","host":"us-016*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2AI%E5%A4%B4%E6%9D%A1+ECCV%C2%A02020%C2%A0%7C%C2%A0%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E6%91%98%E5%BD%95","linkMd5ListStr":"783d43dca630cab969820cf8846c7eff","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"214.3 KB","destSize":"41.5 KB","compressRate":"19.4%"}],"successGithubMap":{"myreaderx8":1,"myreaderx14":1,"myreaderx15":1,"myreaderx7":1,"myreaderx6":1,"myreaderx27":1,"myreaderx16":1,"myreaderx10":1,"myreaderx4":1,"myreaderx32":1,"myreaderx33":1,"myreaderx11":1,"myreaderx23":1,"myreaderx24":1,"myreaderx30":1,"myreaderx18":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{}}