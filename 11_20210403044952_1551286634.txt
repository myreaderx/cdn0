{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Improvements to Percona Server for MongoDB, Final Release of Percona Server for MySQL 5.6 Series: Release Roundup February 15, 2021","link":"https://www.percona.com/blog/?p=74250","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Releases Feb 15 2021\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2>It&#8217;s release roundup time again here at Percona!</h2>\n<p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74473\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-300x169.png\" alt=\"Percona Releases Feb 15 2021\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download.</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since February 1, 2021, including new features like support for <span class=\"std std-ref\">point-in-time recovery</span> in Percona Kubernetes Operator for Percona XtraDB Cluster 1.7.0, improvements to Percona Server for MongoDB, and the final release in the Percona Server for MySQL 5.6 series.</p>\n<p>&#160;</p>\n<h2>Percona Distribution for MongoDB 4.2.12</h2>\n<p>On February 4, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-distribution-for-mongodb/4.2/release-notes-v4.2.12.html\">Percona Distribution for MongoDB 4.2.12</a> was released. It is a collection of solutions to run and operate your MongoDB efficiently with the data being consistently backed up. This release is based on Percona Server for MongoDB 4.2.12-13, a fully-compatible, open source, drop-in replacement for MongoDB, and Percona Backup for MongoDB 1.4.1.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb\">Download Percona Distribution for MongoDB 4.2.12</a></p>\n<p>&#160;</p>\n<h2>Percona Server for MongoDB 4.2.12-13</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/4.2/release_notes/4.2.12-13.html\">Percona Server for MongoDB 4.2.12-13</a> was released on February 3, 2021. It is a drop-in replacement for MongoDB 4.2.12 Community Edition and supports MongoDB 4.2.12 protocols and drivers. Improvements for this release include support for multiple LDAP servers for authentication and the addition of <code class=\"docutils literal\"><span class=\"pre\">validateLDAPServerConfig</span></code> config option.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Download Percona Server for MongoDB 4.2.12-13</a></p>\n<h2></h2>\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"http://percona.com/live/?utm_source=inblog\">Have open source knowledge you want to share? Submit your talk for Percona Live ONLINE 2021!</a></p>\n<p>&#160;</p>\n<h2>Percona Server for MySQL 5.6.51-91.0</h2>\n<p>February 8, 2021, saw the release of <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/5.6/release-notes/Percona-Server-5.6.51-91.0.html\">Percona Server for MySQL 5.6.51-91.0</a>, which includes all the features and bug fixes available in MySQL 5.6.51 Community Edition in addition to enterprise-grade features developed by Percona. Note: Percona Server for MySQL 5.6.51-91.0 is <strong>the last release</strong> of the Percona Server for MySQL 5.6 series, and further updates will only be available to <a target=\"_blank\" class=\"reference external\" href=\"https://www.percona.com/services/support/mysql-support/5-6-eol-support\">MySQL 5.6 Post EOL Support</a> subscribers.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-Server-5.6/LATEST/\">Download Percona Server for MySQL 5.6.51-91.0</a></p>\n<p>&#160;</p>\n<h2>Percona Kubernetes Operator for Percona XtraDB Cluster 1.7.0</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/ReleaseNotes/Kubernetes-Operator-for-PXC-RN1.7.0.html\">Percona Kubernetes Operator for Percona XtraDB Cluster 1.7.0</a> was released on February 2, 2021. The Operator contains all necessary Kubernetes settings to provide a proper and consistent Percona XtraDB Cluster. New features in this release include support for <a target=\"_blank\" class=\"reference internal\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/backups.html#backups-pitr-binlog\"><span class=\"std std-ref\">point-in-time recovery</span></a><span class=\"std std-ref\">, automatic recovery from a full crash when Pods are stuck in CrashLoopBackOff status, and support for <a target=\"_blank\" class=\"reference internal\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/monitoring.html#operator-monitoring\">Percona Monitoring and Management (PMM) v.2</a>. In addition, there are many improvements and bug fixes, so please review the release notes for a full list.</span></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/percona-kubernetes-operators\">Download Percona Kubernetes Operator for Percona XtraDB Cluster 1.7.0</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;noopener&#34; noopener noreferrer\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n","descriptionType":"html","publishedDate":"Mon, 15 Feb 2021 15:09:46 +0000","feedId":11,"bgimg":"","linkMd5":"703b15df2427397e9cc1f07b723cde7e","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn39@2020_1/2021/04/03/04-49-23-994_7e7d9b4d75c68b91.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn31@2020_1/2021/04/03/04-49-17-507_5072804b0dbd6d23.webp"},"publishedOrCreatedDate":1617425343822},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Easily Validate Configuration Settings in MySQL 8","link":"https://www.percona.com/blog/?p=75088","description":"<img width=\"200\" height=\"113\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-200x113.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Validate Configuration Settings in MySQL\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-1536x864.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-2048x1152.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-367x206.png 367w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75183\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-300x169.png\" alt=\"Validate Configuration Settings in MySQL\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-1536x864.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-2048x1152.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-367x206.png 367w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In past versions of MySQL, there was often an ‘upgrade dance’ that had to be performed in starting up a newly upgraded MySQL instance with the previous version configuration file. In some cases a few deprecated options might no longer be supported in the newer server version, triggering an error and a subsequent shutdown moments after starting. The same thing can happen even outside of upgrade scenarios if a configuration change was made with a mistake or typo in the variable name or value.</p>\n<p>As of MySQL 8.0.16 and later, there is now a &#8216;<strong>validate-config&#8217;</strong> option to quickly test and validate server configuration options without having to start the server. Once used, if no issues are found with the configuration file, the server will exit with an exit code of zero (0). If a problem is found, the server will exit with an error code of one (1) for the first occurrence of anything that is determined to be invalid.</p>\n<h2>Validating A Single Option</h2>\n<p>For example, consider the following server option (old_passwords) which was removed in MySQL 8:</p><pre class=\"crayon-plain-tag\">./mysqld --old_passwords=1 --validate-config\n2021-03-25T17:56:49.932782Z 0 [ERROR] [MY-000067] [Server] unknown variable 'old_passwords=1'.\n2021-03-25T17:56:49.932862Z 0 [ERROR] [MY-010119] [Server] Aborting</pre><p>Note the server exited with an error code of one (1) and is showing the error for the invalid option.</p>\n<h2>Validating A Configuration File</h2>\n<p>It is also possible to validate an entire my.cnf configuration file to check all options:</p><pre class=\"crayon-plain-tag\">./mysqld --defaults-file=/home/sandbox/my.cnf --validate-config\n2021-03-25T18:03:41.938734Z 0 [ERROR] [MY-000067] [Server] unknown variable 'old_passwords=1'.\n2021-03-25T18:03:41.938865Z 0 [ERROR] [MY-010119] [Server] Aborting</pre><p>Note that the server exited on the <strong>first occurrence</strong> of an invalid value. Any remaining errors in the configuration file will need to be found after correcting the first error and running the <strong>validate-config</strong> option again. So in this example, I’ve now removed the ‘<strong>old_passwords=1</strong>’ option in the configuration file, and I need to run <strong>validate-config</strong> again to see if there are any other errors remaining:</p><pre class=\"crayon-plain-tag\">./mysqld --defaults-file=/home/sandbox/my.cnf --validate-config\n2021-03-25T18:08:28.612912Z 0 [ERROR] [MY-000067] [Server] unknown variable 'query_cache_size=41984'.\n2021-03-25T18:08:28.612980Z 0 [ERROR] [MY-010119] [Server] Aborting</pre><p>Indeed, there is yet another option that was removed from MySQL 8 in the configuration file, so after running the validate again (after fixing the first issue), we’ve now identified a second problem. After removing the <strong>query_cache_size</strong> option from the my.cnf file and running <strong>validate-config</strong> again, we finally get a clean bill of health:</p><pre class=\"crayon-plain-tag\">./mysqld --defaults-file=/home/sandbox/my.cnf --validate-config</pre><p></p>\n<h2>Change Validation Verbosity</h2>\n<p>By default, the <strong>validate-config</strong> option will only report error messages. If you are also interested in seeing any warnings or informational messages, you can change the <strong>log_error_verbosity</strong> with a value that is greater than one (1):</p><pre class=\"crayon-plain-tag\">./mysqld --defaults-file=/home/sandbox/my.cnf --log-error-verbosity=2 --validate-config\n2021-03-25T18:20:01.380727Z 0 [Warning] [MY-000076] [Server] option 'read_only': boolean value 'y' was not recognized. Set to OFF.</pre><p>Now we are seeing warning level messages, and the server is exiting with an error code of zero (0) as there are technically no errors, only warnings. Taking this further, I’ve added the <strong>query_cache_size</strong> option from above back in the my.cnf file, and if we run the validate again we see both errors and warnings this time, while the server exits with an error code of one (1) as there really was an error:</p><pre class=\"crayon-plain-tag\">./mysqld --defaults-file=/home/sandbox/my.cnf --log-error-verbosity=2 --validate-config\n2021-03-25T18:23:11.364288Z 0 [Warning] [MY-000076] [Server] option 'read_only': boolean value 'y' was not recognized. Set to OFF.\n2021-03-25T18:23:11.372729Z 0 [ERROR] [MY-000067] [Server] unknown variable 'old_passwords=1'.\n2021-03-25T18:23:11.372795Z 0 [ERROR] [MY-010119] [Server] Aborting</pre><p></p>\n<h2>Older Version Alternative</h2>\n<p>During my testing of the <strong>validate_config</strong> feature, a colleague pointed out that there is a way to replicate this validation on older MySQL versions by using a combination of &#8216;help&#8217; and &#8216;verbose&#8217; options as below:</p><pre class=\"crayon-plain-tag\">$ mysqld --defaults-file=/tmp/my.cnf --verbose --help 1&#62;/dev/null; echo $?\n0\n \n$ echo default_table_encryption=OFF &#62;&#62; /tmp/my.cnf\n \n$ mysqld --defaults-file=/tmp/my.cnf --verbose --help 1&#62;/dev/null; echo $?\n2021-03-26T08:43:04.987265Z 0 [ERROR] unknown variable 'default_table_encryption=OFF'\n2021-03-26T08:43:04.990898Z 0 [ERROR] Aborting\n1\n \n$ mysqld --version\nmysqld  Ver 5.7.33-36 for Linux on x86_64 (Percona Server (GPL), Release 36, Revision 7e403c5)</pre><p></p>\n<h3>Closing Thoughts</h3>\n<p>While not perfect, the <strong>validate-config</strong> feature goes a long way towards making upgrades and configuration changes easier to manage. It is now possible to know with some certainty that your configuration files or options are valid prior to restarting the server and finding an issue that ends up keeping your node from starting normally leading to unexpected downtime.</p>\n<hr />\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database?utm_source=blog\"><strong>Percona Distribution for MySQL: An Enterprise-Grade MySQL Solution, for Free</strong></a></p>\n","descriptionType":"html","publishedDate":"Thu, 01 Apr 2021 15:54:23 +0000","feedId":11,"bgimg":"","linkMd5":"2425d4b26612cefc91bda1b5433432f9","bgimgJsdelivr":"","metaImg":"","author":"Brian Sumpter","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-200x113.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn13@2020_3/2021/04/03/04-49-05-089_52f219c11251929e.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn3@2020_4/2021/04/03/04-49-16-790_9ef95075066a8137.webp"},"publishedOrCreatedDate":1617425343827},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Infinitely Scalable Storage with High Compression Feature","link":"https://www.percona.com/blog/?p=75187","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Infinitely Scalable Storage with High Compression Feature\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75208\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-300x157.png\" alt=\"Infinitely Scalable Storage with High Compression Feature\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />It is no secret that compute and storage costs are the main drivers of cloud bills. Migration of data from the legacy data center to the cloud looks appealing at first as it significantly reduces capital expense (CapEx) and keeps operational expenses (OpEx) under control. But once you see the bill, the lift and shift project does not look that promising anymore. See Percona’s recent <a target=\"_blank\" href=\"https://www.percona.com/open-source-data-management-software-survey\">open source survey</a> which shows that many organizations saw an unexpected growth around cloud and data.</p>\n<p>Storage growth is an organic process for the expanding business: more customers store more data, and more data needs more backups and disaster recovery storage for low RTO.</p>\n<p>Today, the Percona Innovation Team, which is part of the Engineering organization, is proud to announce a new feature &#8211; <strong>High Compression</strong>. With this feature enabled, your MySQL databases will have infinite storage at zero cost.</p>\n<h2>The Problem</h2>\n<p>Our research team was digging into the problem of storage growth. They have found that the storage growth of a successful business inevitably leads to the increase of the cloud bill. After two years of research we got the data we need and the problem is now clear, and you can see it on the chart below:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-75191 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-1024x662.png\" alt=\"\" width=\"900\" height=\"582\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-1024x662.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-300x194.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-200x129.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-367x237.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19.png 1240w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>The correlation is clearly visible &#8211; the more data you have, the more you pay.</p>\n<h2>The Solution</h2>\n<p>Once our Innovation Team received the data, we started working day and night on the solution. The goal was to change the trend and break the correlation. That is how after two years, we are proud to share with the community the High Compression feature. You can see the comparison of the storage costs with and without this new feature below:</p>\n<table>\n<tbody>\n<tr>\n<td><b>Option</b></td>\n<td><b>100 TB AWS EBS</b></td>\n<td><b>100 TB AWS S3 for backups</b></td>\n<td><b>100 TB AWS EBS </b><b>+ High compression</b></td>\n<td><b>100 TB AWS S3 for backups </b><b>+ High Compression</b></td>\n</tr>\n<tr>\n<td><b>Annual run rate</b></td>\n<td>\n<p style=\"text-align: center;\"><b>$120,000</b></p>\n</td>\n<td>\n<p style=\"text-align: center;\"><b>$25,200</b></p>\n</td>\n<td>\n<p style=\"text-align: center;\"><b>$1.2</b></p>\n</td>\n<td>\n<p style=\"text-align: center;\"><b>&#60; $1</b></p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>As you see it is a 100,000x difference! What is more interesting, the cost of the storage with the High Compression feature enabled always stays flat and the chart now looks like this:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-75190 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-1024x662.png\" alt=\"\" width=\"900\" height=\"582\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-1024x662.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-300x194.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-200x129.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-367x237.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20.png 1240w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h2>Theory</h2>\n<p>Not many people know, but data on disks is stored as bits, which are 0s and 1s. They form the binary sequences which are translated into normal data.</p>\n<p>After thorough research, we came to the conclusion that we can replace the 1s with 0s easily. The formula is simple:</p>\n<p style=\"text-align: center;\"><strong><pre class=\"crayon-plain-tag\">f(1) = 0</pre></strong></p>\n<p><span>So instead of storing all these 1s, our High Compression feature stores zeroes only:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-75189 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2.png\" alt=\"\" width=\"601\" height=\"278\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2.png 601w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2-300x139.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2-200x93.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2-367x170.png 367w\" sizes=\"(max-width: 601px) 100vw, 601px\" /></p>\n<p>&#160;</p>\n<h2>Implementation</h2>\n<p><span>The component which does the conversion is called the <strong>Nullifier</strong>, and every bit of data goes through it. We are first implementing this feature in</span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\"><span> Percona Operator for Percona XtraDB Cluster</span></a><span> and below is the technical view of how it is implemented in Kubernetes:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-75188 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3.png\" alt=\"\" width=\"970\" height=\"780\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3.png 970w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3-300x241.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3-187x150.png 187w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3-367x295.png 367w\" sizes=\"(max-width: 970px) 100vw, 970px\" /></p>\n<p>As you see, all the data written by the user (all Insert or Update statements) goes through the Nullifier first, and only then are stored on the Persistent Volume Claim (PVC). With the High Compression feature enabled, the size of the PVC can be always 1 GB.</p>\n<p>Percona is an open source company and we are thrilled to share our code with everyone. You can see the Pull Request for the High Compression feature <a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster-operator/pull/828\">here</a>. As you see in the PR, our feature provides the Nullifier through the underestimated and very powerful <a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/blackhole-storage-engine.html\">Blackhole</a> engine.</p><pre class=\"crayon-plain-tag\">  if [ \"$HIGH_COMPRESSION\" == 'yes' ]; then\n        sed -r \"s|^[#]?default_storage_engine=.*$|default_storage_engine=<strong>BLACKHOLE</strong>|\" ${CFG} 1&#60;&#62;${CFG}\n        grep -E -q \"^[#]?pxc_strict_mode\" \"$CFG\" || sed '/^\\[mysqld\\]/a pxc_strict_mode=PERMISSIVE\\n' ${CFG} 1&#60;&#62;${CFG}\n    fi</pre><p>The High Compression feature will be enabled by default starting from PXC Operator version 1.8.0, but we have added the flag into <span><pre class=\"crayon-plain-tag\">cr.yaml</pre> </span>to disable this feature if needed:<span> <pre class=\"crayon-plain-tag\">spec.pxc.highCompression: true</pre></span>.</p>\n<p>Backups and with the High Compression feature are blazing fast and take seconds with any amount of data. The challenge our Engineering team is working on now is recovery. The Nullifier does the job, but recovering the data is hard. We are confident that De-Nullifier will be released in 1.8.0 as well.</p>\n<h3>Conclusion</h3>\n<p>Percona is spearheading innovation in the database technology field. The High Compression feature solves the storage growth problem and as a result, reduces the cloud bill significantly. The release of the Percona Kubernetes Operator for Percona XtraDB Cluster 1.8.0 is planned for mid-April, but this feature is already available in Tech Preview.</p>\n<p>As a quick peek at our roadmap, we are glad to share that the Innovation Team has already started working on the High-Density feature, which will drastically reduce the compute footprint required to run MySQL databases.</p>\n","descriptionType":"html","publishedDate":"Thu, 01 Apr 2021 13:01:25 +0000","feedId":11,"bgimg":"","linkMd5":"8cbdc4fcf8dbffae590b23534dfa7ddf","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn8@2020_3/2021/04/03/04-49-05-152_1c4faf7fd610ade6.webp","https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn27@2020_2/2021/04/03/04-49-10-768_055594309ba93c46.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-1024x662.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn32@2020_2/2021/04/03/04-49-22-995_b85b8592804cd804.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-1024x662.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn15@2020_5/2021/04/03/04-49-14-551_5ba608d243daec00.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn56@2020_1/2021/04/03/04-49-17-389_ab92be5a4a6c00ac.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn11@2020_1/2021/04/03/04-49-07-609_7328624c08adbb47.webp"},"publishedOrCreatedDate":1617425343827},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Kubernetes Operator for Percona Server for MongoDB Sharding, Bug Fixes for Percona Server for MySQL 5.7: Release Roundup March 15, 2021","link":"https://www.percona.com/blog/?p=74692","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Release Roundup March 15\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2>It&#8217;s release roundup time again here at Percona!</h2>\n<p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74841\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-300x169.png\" alt=\"Percona Release Roundup March 15\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download.</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since March 1, 2021, including version updates of Percona Distribution for PostgreSQL, full support for sharding in Percona Kubernetes Operator for Percona Server for MongoDB 1.7.0, and the release of Percona Monitoring and Management 2.15.0.</p>\n<h2>Percona Distribution for PostgreSQL 11.11</h2>\n<p>On March 8, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/11/release-notes-v11.11.html\">Percona Distribution for PostgreSQL 11.11</a> was released.  Percona Distribution for PostgreSQL is based on PostgreSQL 11.11 and is a collection of tools to assist you in managing PostgreSQL. Percona Distribution for PostgreSQL installs PostgreSQL and complements it by a selection of extensions that enable solving essential practical tasks efficiently.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/postgresql-distribution\">Download Percona Distribution for PostgreSQL 11.11</a></p>\n<p>&#160;</p>\n<h2>Percona Distribution for PostgreSQL 12.6</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/12/release-notes-v12.6.html\">Percona Distribution for PostgreSQL 12.6</a> was released on March 9, 2021.  This release of Percona Distribution for PostgreSQL is based on PostgreSQL 12.6.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/postgresql-distribution\">Download Percona Distribution for PostgreSQL 12.6</a></p>\n<p>&#160;</p>\n<h2>Percona Distribution for PostgreSQL 13.2</h2>\n<p>March 4, 2021, saw the release of <a target=\"_blank\" href=\"https://www.percona.com/doc/postgresql/13/release-notes-v13.2.html\">Percona Distribution for PostgreSQL 13.2</a>. This release of Percona Distribution for PostgreSQL is based on PostgreSQL 13.2.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/postgresql-distribution-13/LATEST/\">Download Percona Distribution for PostgreSQL 13.2</a></p>\n<p>&#160;</p>\n<h2>Percona Server for MySQL 5.7.33-36</h2>\n<p>On March 2, 2021, we released <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/5.7/release-notes/Percona-Server-5.7.33-36.html\">Percona Server for MySQL 5.7.33-36</a>. It includes all the features and bug fixes available in MySQL 5.7.33 Community Edition in addition to enterprise-grade features developed by Percona. New features in this release include an update to the keyring_vault plugin to support KV Secrets Engine Version 2 (kv-v2) (Thanks to user aprokofyev for reporting this issue) and backport of variable innodb_buffer_pool_in_core_file and processing. There are also several bug fixes in this release, a full list of which can be found in the release notes.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-Server-5.7/LATEST/\">Download Percona Server for MySQL 5.7.33-36</a></p>\n<p>&#160;</p>\n<h2>Percona Server for MongoDB 4.0.23-18</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/4.0/release_notes/4.0.23-18.html\">Percona Server for MongoDB 4.0.23-18</a> was released on March 4, 2021. It is an enhanced, open source, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 4.0.23 Community Edition. In this release, there is a fix for bug <a target=\"_blank\" class=\"reference external\" href=\"https://jira.percona.com/browse/PSMDB-817\">PSMDB-817</a>: LDAP ConnectionPoller always uses up CPU of one core (Thanks to user cleiton.domazak for reporting this issue).</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Download Percona Server for MongoDB 4.0.23-18</a></p>\n<p>&#160;</p>\n<h2>Percona Monitoring and Management 2.15.0</h2>\n<p>On March 1, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/release-notes/2.15.0.html\">Percona Monitoring and Management 2.15.0</a> was released. It&#8217;s a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance. There&#8217;s a long list of highlights, new features, and bug fixes in the release notes, including the ability to add external services via the UI in PMM server, the ability to add HAProxy Services for monitoring in PMM2, DBaaS Preview improvements, and the update of Grafana 7.1.3 to 7.3.7.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/pmm2/\">Download Percona Monitoring and Management 2.15.0</a></p>\n<p>&#160;</p>\n<h2>Percona Kubernetes Operator for Percona Server for MongoDB 1.7.0</h2>\n<p>Last but definitely not least, on March 8, 2021, we released <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/RN/Kubernetes-Operator-for-PSMONGODB-RN1.7.0.html\">Percona Kubernetes Operator for Percona Server for MongoDB 1.7.0</a>. This release brings full support for the <span class=\"std std-ref\">Percona Server for MongoDB Sharding</span>, allowing you to scale databases horizontally, distributing data across multiple MongoDB Pods. In addition, there is a full list of improvements and bug fixes in the release notes.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/percona-kubernetes-operators\">Download Percona Kubernetes Operator for Percona Server for MongoDB 1.7.0</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;noopener&#34; noopener noreferrer\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n","descriptionType":"html","publishedDate":"Mon, 15 Mar 2021 12:19:07 +0000","feedId":11,"bgimg":"","linkMd5":"31583d79676cf36b069aeb75d5f083f0","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn61@2020_3/2021/04/03/04-49-05-274_b9db5810a75a37e6.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn35@2020_3/2021/04/03/04-49-22-947_a599c63ad14c9fa3.webp"},"publishedOrCreatedDate":1617425343832},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Hoss Talks Foss: The Podcast is Now Available","link":"https://www.percona.com/blog/?p=74571","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Open Source Podcast\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" />\n<p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74579\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-300x168.png\" alt=\"Percona Open Source Podcast\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Great news!&nbsp; Percona’s Community-focused podcast, hosted by none other than the HOSS (Head of Open Source Software) himself (yeah, that is me), is now available on almost all podcast platforms.</p> \n<p><em>What? You didn’t know we had a podcast?</em></p> \n<p>We do, and we’ve had some great episodes since we started in January. In fact, we just published our 10th episode! We talk about all things open source-related on the podcast, from SSPL, MySQL, PostgreSQL, MongoDB, MariaDB, Linux, and more!&nbsp; We will also be touching on a ton of other tech topics as well. Here’s a quick recap in case you missed any episodes.</p> \n<h3>Currently Available Interviews and Discussions:</h3> \n<p><b>In episode #1, we sat down with Peter Zaitsev (Percona’s CEO) to talk about open source, the cloud’s impact, and investors on open source licensing. </b><span>&nbsp;We also cover the news about Elastic adopting the SSPL license.&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=KkFajzrF61s\"><span>Video Link: SSPL and the Cloud</span></a><span>]</span></p> \n<p><b>In episode #2 we sat down with Walter Garcia (Remote Database Engineer) to talk about MySQL backups</b><span>.&nbsp; We talk about not only best practices but also touch on the biggest mistakes when setting up backups.&nbsp;</span><span><br /> </span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=AJaze6ehqm0\"><span>Video Link: MySQL Backups</span></a><span>]</span></p> \n<p><b>Episode #3 is all about running your database in K8 (Kubernetes)</b><span>.&nbsp; In this episode, we sit down with Sergey Pronin to talk about the evolution of Kubernetes and why people are looking at it for databases.&nbsp;&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=Qx-tKmucomc\"><span>Video Link: Databases on Kubernetes</span></a><span>]</span></p> \n<p><b>Episode #4 We catch Up with Pingcap/TiDB developer Morgan Tocker and talk about contributing to OSS and TiDB</b><span>.&nbsp; Morgan has been in the MySQL community for longer than I have, and we chat about old projects, swap fun stories, and talk about contributing.&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=T2t0YeHMeqU\"><span>Video Link: TiDB, Open Source, and MySQL</span></a><span>]</span></p> \n<p><b>David Murphy joins us on episode #5 to catch up on all things DevOps, SRE, and DBRE related.</b><span>&nbsp; David has been a long-time contributor in the MongoDB, MySQL, and open source communities.&nbsp; He talks about how the DBA role is evolving and how he helps to modernize the infrastructure at a major international airline (including mixing&nbsp; Oracle, MongoDB, MySQL, and PostgreSQL).&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=do3LX8xMOIs\"><span>Video Link: SRE, DBaaS, and DevOps for Databases</span></a><span>]&nbsp;&nbsp;</span></p> \n<p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74582\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-1024x386.png\" alt=\"Open Source Podcast\" width=\"900\" height=\"339\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-1024x386.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-300x113.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-200x75.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-367x138.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast.png 1500w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p> \n<p><b>In episode 6, we catch up with Google Dev Advocate Gabi Ferrara.&nbsp; </b><span>Gabi and I discuss her career in the database space and how she progressed and had to work to reach the point where she is today. Gabi free offers her advice to others trying to break into the tech industry.&nbsp; We also talk about the database and development challenges and struggles she helps people overcome in her current role.&nbsp;&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=cD_w7kUcWKc\"><span>Video Link: Google Cloud, Dev Rel, and SQL</span></a><span>]&nbsp;</span></p> \n<p><b>In episode 7, we catch up with long-time engineer and community member Lenz Grimmer.&nbsp; </b><span>Lenz is currently our Sr Director of Server Engineering at Percona.&nbsp; He talks about open source communities, how to contribute, and where we have come from.&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=5N_xWYczFGA\"><span>Video Link: Database, Open Source Contributions, Engineering, and Linux</span></a><span>]&nbsp;</span></p> \n<p><b>We celebrate episode 8 by bringing in Datastax VP of Engineering EMEA Henrik Ingo.&nbsp; </b><span>Henrik talks about his time at MySQL, MariaDB, and MongoDB before Datastax (he has seen the inside of many great database companies).&nbsp; Henrik talks about Datastax and how his team is opening up more to the open source community while other companies are locking more down.&nbsp; It is a fascinating discussion and one not to be missed.&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=OIurpMd07vM\"><span>Video Link: DataStax, MongoDB, FOSS, and Openness</span></a><span>]&nbsp;</span></p> \n<p><b>In episode 9, we explore ARM-based EC2 instances with Jobin Augustine.</b><span>&nbsp; The new instances are cheaper, faster, and better for the environment!&nbsp; We talk through benchmarking the new instances and the benefits.&nbsp;&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=qYx3JyQ9izA\"><span>Video Link:&nbsp; Graviton2 ARM Performance, Benchmarks, and PostgreSQL</span></a><span>]</span></p> \n<p><b>Finally, in the 10th episode, we talk to Alkin Tezuysal about all things Vitess and MySQL.</b><span>&nbsp; Alkin works for Planetscale and is one of the maintainers for Vitess.&nbsp; We talk about use cases, how to contribute, and who is using Vitess in the wild.</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://youtu.be/8e3IC-lAgXs\"><span>Video Link:&nbsp; Talking Vitess, Scaling Databases, and Sailing</span></a><span>]</span></p> \n<h3><img loading=\"lazy\" class=\"size-thumbnail wp-image-74583 alignleft\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/quick-131x150.png\" alt=\"\" width=\"131\" height=\"150\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/quick-131x150.png 131w, https://www.percona.com/blog/wp-content/uploads/2021/02/quick-261x300.png 261w, https://www.percona.com/blog/wp-content/uploads/2021/02/quick-892x1024.png 892w, https://www.percona.com/blog/wp-content/uploads/2021/02/quick-1338x1536.png 1338w, https://www.percona.com/blog/wp-content/uploads/2021/02/quick-367x421.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/quick.png 1469w\" sizes=\"(max-width: 131px) 100vw, 131px\" />The Hoss Also Had a Couple of HOSS Quick Hits (Not Exactly Full-Length Podcasts, but Interesting Quick-Hit Topics)</h3> \n<p><b>How about 7 minutes on MongoDB Performance Tuning?</b><span> &nbsp; I sat down with Mike Grayson and asked him the most important things to tune in MySQL after upgrading the memory.&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=LEUtqqG6qhc\"><span>Video Link: Tuning MongoDB’s Memory after an upgrade</span></a><span>]</span></p> \n<p><b>Want the short version of the difference between MongoDB replication and sharding and when to use each? </b><span>&nbsp;In this 12-minute video, Akira Kurogane sits down with the HOSS to explain how replication and sharding work in MongoDB.&nbsp;&nbsp;&nbsp;</span></p> \n<p><span>[</span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=1sMZ455i1PU\"><span>Video Link:&nbsp; MongoDB Sharding 101</span></a><span>]</span></p> \n<h3><img loading=\"lazy\" class=\"alignleft size-thumbnail wp-image-74586\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-145x150.jpeg\" alt=\"Percona Community\" width=\"145\" height=\"150\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-145x150.jpeg 145w, https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-291x300.jpeg 291w, https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-992x1024.jpeg 992w, https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-1489x1536.jpeg 1489w, https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-1985x2048.jpeg 1985w, https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-32x32.jpeg 32w, https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-367x379.jpeg 367w\" sizes=\"(max-width: 145px) 100vw, 145px\" />Future Topics – Community Driven</h3> \n<p>Have an idea for a future show?&nbsp; Want to be a guest?&nbsp; Drop me a line at <a target=\"_blank\" href=\"mailto:hoss@percona.com\">hoss@percona.com</a>!</p> \n<h3></h3> \n<p>&nbsp;</p> \n<p>&nbsp;</p> \n<h3><img loading=\"lazy\" class=\"alignleft size-thumbnail wp-image-74587\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-151x150.jpeg\" alt=\"database podcast\" width=\"151\" height=\"150\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-151x150.jpeg 151w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-300x298.jpeg 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-1024x1017.jpeg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-1536x1525.jpeg 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-32x32.jpeg 32w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-128x128.jpeg 128w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-560x560.jpeg 560w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-367x367.jpeg 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-85x85.jpeg 85w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-50x50.jpeg 50w, https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast.jpeg 1885w\" sizes=\"(max-width: 151px) 100vw, 151px\" />Where Can You Find the Podcast?</h3> \n<p>You can watch the video versions (if you can handle 30-40 minutes of me staring awkwardly at the camera) on <a target=\"_blank\" href=\"https://www.youtube.com/c/percona/videos\">YouTube</a>. You can also subscribe on popular platforms like <a target=\"_blank\" href=\"https://percona.podbean.com\">Podbean</a>, <a target=\"_blank\" href=\"https://per.co.na/5U28RM\">Google</a>, and <a target=\"_blank\" href=\"https://per.co.na/6SjZt4\">Apple</a>.</p> \n<p><strong>Note:</strong> YouTube has all the episodes today <a target=\"_blank\" href=\"https://per.co.na/The-HOSS-talk-FOSS\">in this playlist</a>, and other podcast services will fill in the episodes over the next week.</p> \n<p>Have a great day, everyone!</p>","descriptionType":"html","publishedDate":"Wed, 24 Feb 2021 14:41:35 +0000","feedId":11,"bgimg":"","linkMd5":"835b3d62eed8d5aa41a9e425666acfe4","bgimgJsdelivr":"","metaImg":"","author":"Matt Yonkovit","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn8@2020_2/2021/04/03/04-49-08-691_c8f34cc28b6843c5.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn59@2020_3/2021/04/03/04-49-47-796_d9ae32db4deb617b.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-1024x386.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn56@2020_4/2021/04/03/04-49-11-964_5d5abae9dce4c934.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/quick-131x150.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn71@2020_4/2021/04/03/04-49-17-577_f395cd0b9f0b3a6e.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-145x150.jpeg":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn59@2020_5/2021/04/03/04-49-16-608_aeb9c6e8a3975ab1.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-151x150.jpeg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn48@2020_6/2021/04/03/04-49-23-575_1f2fb06054f2a601.webp"},"publishedOrCreatedDate":1617425343817},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"MySQL 5.6 and Percona Server for MySQL 5.6 are End of Life","link":"https://www.percona.com/blog/?p=74352","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL 5.6 End of Life\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-1536x804.png 1536w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6.png 1920w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-73001\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-300x157.png\" alt=\"MySQL 5.6 End of Life\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-1536x804.png 1536w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6.png 1920w\" sizes=\"(max-width: 300px) 100vw, 300px\" />MySQL 5.6.51 is the last release of the MySQL 5.6 series. Oracle will no longer provide updates or security fixes for this version.</p>\n<p><span>Following <a target=\"_blank\" href=\"https://www.percona.com/services/policies/percona-software-support-lifecycle#lifecycle\">Percona&#8217;s Release Lifecycle policies,</a> the Percona Server for MySQL 5.6 series has reached End of Life (EOL) as well, and we will no longer provide public builds for bugs and security fixes.</span></p>\n<p><span>We recommend that you upgrade to </span>MySQL 5.7 or <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/5.7/upgrading_guide_56_57.html\">Percona Server for MySQL 5.7</a>, or for the latest features, MySQL 8.0 or <a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-Server-LATEST/\">Percona Server for MySQL 8.0</a>.</p>\n<p><span>Suppose you have not upgraded because you have off-the-shelf applications that also must be upgraded and require 5.6, or you have other priorities that keep pushing the upgrade to the back-burner. What to do?</span></p>\n<p><span>In that case, <strong>Percona offers </strong></span><span><strong><a target=\"_blank\" href=\"https://www.percona.com/services/support/mysql-support/5-6-eol-support\">MySQL 5.6 Post-EOL Support</a></strong>, which provides</span><span> the ability to run your MySQL 5.6-based applications for a specified time while still being able to receive critical fixes for security issues and bugs you may encounter. </span></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/services/support/mysql-support/5-6-eol-support#contact\"><span>Contact us</span></a><span> for more information.</span></p>\n<p style=\"text-align: center;\">\n","descriptionType":"html","publishedDate":"Tue, 16 Feb 2021 13:30:27 +0000","feedId":11,"bgimg":"","linkMd5":"008eb2d24b981e80bd3b226206dbded3","bgimgJsdelivr":"","metaImg":"","author":"Patrick Birch","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn23@2020_5/2021/04/03/04-49-46-186_edb4e1d7b4fb1322.webp","https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn63@2020_6/2021/04/03/04-49-22-609_f5e2c9f9fe38a726.webp"},"publishedOrCreatedDate":1617425343821},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Webinar April 14: Optimize and Troubleshoot MySQL Using Percona Monitoring and Management","link":"https://www.percona.com/blog/?p=75147","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Troubleshoot MySQL Using Percona Monitoring and Management\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75153\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-300x168.png\" alt=\"Troubleshoot MySQL Using Percona Monitoring and Management\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Optimizing MySQL performance and troubleshooting MySQL problems are two of the most critical and challenging tasks for MySQL DBAs. The databases powering applications need to be able to handle changing traffic workloads while remaining responsive and stable in order to deliver an excellent user experience. Further, DBAs are also expected to find cost-efficient means of solving these issues.</p>\n<p>In this webinar, we will demonstrate the advanced options of Percona Monitoring and Management V.2 that enable you to solve these challenges, which are built on free and open-source software. We will look at specific, common MySQL problems and review them.</p>\n<p>Please join <strong>Peter Zaitsev </strong>on <strong>Wednesday</strong>, <strong>April 14th, 2021</strong>, at <strong>11 am EDT</strong> for his webinar <strong>Optimize and Troubleshoot MySQL using Percona Monitoring and Management (PMM)</strong>.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://percona.zoom.us/webinar/register/4116081511791/WN_TEyruPlMT9OmeOUepNlrzA\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://percona.zoom.us/webinar/register/4116081511791/WN_TEyruPlMT9OmeOUepNlrzA\">sign up anyway</a>, and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Wed, 31 Mar 2021 17:00:13 +0000","feedId":11,"bgimg":"","linkMd5":"b107a81989fb33bdf2a7f3c0e14ce764","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn77@2020_2/2021/04/03/04-49-16-616_1e11c7148304186d.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn59@2020_3/2021/04/03/04-49-20-426_7308a34cfa2af9e6.webp"},"publishedOrCreatedDate":1617425343831},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Webinar March 18: Moving Your Database to the Cloud – Top 3 Things to Consider","link":"https://www.percona.com/blog/?p=74553","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Moving Your Database to the Cloud\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74556\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-300x157.png\" alt=\"Moving Your Database to the Cloud\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Join Rick Vasquez, Percona Technical Expert, as he discusses the pros and cons of moving your database to the cloud.</p>\n<p><strong>Flexibility</strong>, <strong>performance, </strong>and <strong>cost management</strong> are three things that make cloud database environments an easy choice for many businesses. If you are thinking of moving your database to the cloud you need to know the issues you might encounter, and how you can make the most of your DBaaS cloud configuration.</p>\n<p>Our latest webinar looks into a number of key issues and questions, including:</p>\n<p>* The real Total Cost of Ownership (TCO) when moving your database to the cloud.</p>\n<p>* If performance is a critical factor in your application, how do you achieve the same or better performance in your chosen cloud?</p>\n<p>* The “hidden costs” of running your database in the cloud.</p>\n<p>* Why do companies choose open source and cloud software? The pros and cons of this decision.</p>\n<p>* The case for cloud support (why “fully managed” isn’t always as fully managed as claimed).</p>\n<p>* Should you consider a multi-cloud strategy?</p>\n<p>* Business continuity planning in the cloud &#8211; what if your provider has an outage?</p>\n<p>Please join <strong>Rick Vasquez</strong>, <strong>Percona Technical Expert</strong>, on <strong>Thursday, March 18, 2021, at 1:00 PM EST</strong> for his webinar &#8220;<strong>Moving Your Database to the Cloud &#8211; Top 3 Things to Consider</strong>&#8220;.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://percona.zoom.us/webinar/register/4016081521873/WN_He1sImI8RxWqSDvQDja_wA\" rel=\"noopener\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://percona.zoom.us/webinar/register/4016081521873/WN_He1sImI8RxWqSDvQDja_wA\">sign up anyway</a>, and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Fri, 26 Feb 2021 13:09:05 +0000","feedId":11,"bgimg":"","linkMd5":"60741d14cf97d9fb42cfe52348880c5c","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn88@2020_1/2021/04/03/04-49-46-770_c06c4c7cb790423b.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn12@2020_1/2021/04/03/04-49-22-618_85039a715c25a591.webp"},"publishedOrCreatedDate":1617425343784},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Testing the Value of ScaleFlux Computational Storage Drive (CSD) for PostgreSQL","link":"https://www.percona.com/blog/?p=74710","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"ScaleFlux Computational Storage Drive PostgreSQL\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p>Some time ago we at Percona were approached by <a target=\"_blank\" href=\"http://www.scaleflux.com/\">ScaleFlux Inc</a> to benchmark their latest hardware appliance, the CSD 2000 Drive, which is a next-generation SSD computational storage drive. It goes without saying that a truly relevant report requires us to be as honest and as forthright as possible. In other words, my mission was to, ahem, see what kind of mayhem I could cause.</p>\n<p><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Benchmarking#:~:text=Benchmarking%20is%20the%20practice%20of,best%20practices%20from%20other%20companies.&#38;text=Benchmarking%20may%20be%20a%20one,seek%20to%20improve%20their%20practices.\">Benchmarking</a> is a bit like cooking; it requires key ingredients, strict adherence to following a set of instructions, mixing the ingredients together, and a bit of heat to make it all happen. In this case, the ingredients include the Linux OS running <a target=\"_blank\" href=\"https://releases.ubuntu.com/18.04/\">Ubuntu 18.04</a> on both the database and the bench-marking hosts, <a target=\"_blank\" href=\"https://www.postgresql.org/docs/12/index.html\">PostgreSQL</a> version 12, <a target=\"_blank\" href=\"https://github.com/akopytov/sysbench\">SysBench</a> the modular, cross-platform, and multi-threaded benchmark tool, and a comparable, competing appliance i.e. the Intel DC P4610 series drive. The two appliances are mounted as partitions respectively both using the same type of file system.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74725 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-1024x484.png\" alt=\"\" width=\"900\" height=\"425\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-1024x484.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-300x142.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-200x95.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-1536x726.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-367x173.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1.png 1758w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>&#160;</p>\n<p>Once the environment is ready, the next step involves declaring and implementing the bench-marking rules which consist of various types of DML and DDL activity. Keeping in mind that apart from the classic OLAP vs OLTP modes of database processing, executing a benchmark that closely follows real production activities can be problematic. Quite often, when pushing a system to its full capacity, one can say that all production systems are to some extent unique. Therefore, for our purposes, we used the testing regime SysBench offers by default.</p>\n<p>Once the system was ready, loading started out slow and gentle. The idea was to develop a baseline for the various types of activity and Postgres runtime conditions. Then, the bench-marking intensity was gradually increased to the point where we eventually started getting <em>interesting</em> results.</p>\n<p>Needless to say, it took quite a bit of time running the various permutations, double-checking our numbers, graphing the data, and then after all that, interpreting the output. I&#8217;m not going to go into any great detailing the analysis itself. Instead, I encourage you to look at the <a target=\"_blank\" href=\"https://www.percona.com/sites/default/files/Testing_the_Value_of_Scaleflux_for_PostgreSQL.pdf\">whitepaper</a> itself.</p>\n<p><strong>So after all this effort, what was the takeaway?</strong></p>\n<p>There are two key observations that I&#8217;d like to share:</p>\n<ol>\n<li>At peak loading, the ScaleFlux CSD 2000 Drive demonstrated less performance variance than that of the Intel DC P4610. <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Variance#:~:text=In%20probability%20theory%20and%20statistics,out%20from%20their%20average%20value.\">Variance</a> being the statistical encapsulation of IO read-write spread between maximum and minimum values. The significance is server predictability. This becomes important when, for example, finely tuned application processes depend upon consistent performance with the RDBMS. Many a time I&#8217;ve seen applications get upset when response times between inserting, updating, or deleting data and getting the resultant queries would suddenly change.</li>\n<li>Remarkable space savings were realized when the Postgres <a target=\"_blank\" href=\"https://www.postgresql.org/docs/current/sql-createindex.html#SQL-CREATEINDEX-STORAGE-PARAMETERS\">fillfactor</a> was reduced. As you know, the fillfactor can become a critical runtime parameter in regards to performance when high-frequency UPDATE and DELETE operations take place on the same tuple over and over again.</li>\n</ol>\n<p>Finally, one last item&#8230; I didn&#8217;t mention it but we also benchmarked MySQL for ScaleFlux. The results were pretty remarkable. It&#8217;s worth your while to have a look at that one too.</p>\n<p><strong>ScaleFlux White Papers:</strong></p>\n<ul>\n<li><a target=\"_blank\" href=\"https://www.percona.com/sites/default/files/Testing_the_Value_of_Scaleflux_for_PostgreSQL.pdf\">PostgreSQL</a></li>\n<li><a target=\"_blank\" href=\"https://learn.percona.com/hubfs/Collateral/Whitepapers/Testing-the-Value-of-ScaleFlux.pdf\">MySQL</a></li>\n</ul>\n","descriptionType":"html","publishedDate":"Mon, 08 Mar 2021 17:03:13 +0000","feedId":11,"bgimg":"","linkMd5":"aaf1719f47ea1c56bcbff35f0f9ebdcc","bgimgJsdelivr":"","metaImg":"","author":"Robert Bernier","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn88@2020_4/2021/04/03/04-49-15-894_9a70fe567f5a6900.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-1024x484.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn84@2020_6/2021/04/03/04-49-24-285_898fe50fcd9fa23b.webp"},"publishedOrCreatedDate":1617425343776},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Various Types of InnoDB Transaction Isolation Levels Explained Using Terminal","link":"https://www.percona.com/blog/?p=74413","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"InnoDB Transaction Isolation Levels\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74420\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-300x157.png\" alt=\"InnoDB Transaction Isolation Levels\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />The goal of this blog post is to explain the various types of transaction isolation levels available in MySQL. After reading the blog, you will be able to explain dirty reads, non-repeatable reads, and the concept of phantom rows as well.</p>\n<h2>What is the Isolation Level in MySQL?</h2>\n<p>Isolation (I) is one of the properties from ACID. It defines how each transaction is isolated from other transactions and is a critical component of application design. As per the SQL:1992 standard, InnoDB has four types of Isolation levels. Below, I have listed the types in order, and each transaction isolation level provides better consistency compared to the previous one.</p>\n<ul>\n<li aria-level=\"1\">READ-UNCOMMITTED</li>\n<li aria-level=\"1\">READ-COMMITTED</li>\n<li aria-level=\"1\">REPEATABLE-READ &#8211; ( MySQL&#8217;s DEFAULT )</li>\n<li aria-level=\"1\">SERIALIZABLE</li>\n</ul>\n<p>You can change the isolation level using the variable “transaction_isolation” at runtime. As transaction isolation changes can impact the result sets of your queries, you most certainly want to test this in a non-production environment in order to evaluate the impact on your application.&#8221;</p><pre class=\"crayon-plain-tag\">mysql&#62; set global transaction_isolation='read-committed';\nQuery OK, 0 rows affected (0.00 sec)</pre><p></p>\n<h2>READ-UNCOMMITTED:</h2>\n<ul>\n<li aria-level=\"1\">No locks</li>\n<li aria-level=\"1\">Dirty reads, non-repeatable reads, phantom reads are possible</li>\n</ul>\n<p>The below example will help to understand the “read-uncommitted” and how the dirty reads are happening. I am using two sessions &#8211; S1 and S2.</p>\n<p>For session S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; set global transaction_isolation='read-uncommitted';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; \\r\nConnection id:    16\nCurrent database: percona\n\nmysql&#62; select * from ReadUncommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)\n\nmysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; update ReadUncommit set name='ram' where id=3;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0</pre><p>For session S2:</p><pre class=\"crayon-plain-tag\">mysql&#62; select * from percona.ReadUncommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | ram  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>At S1, I globally modified the transaction_isolation to read-uncommitted and started the transaction. I executed the UPDATE statement ( name = ram ) at S1 but did not commit the transaction yet. Then I created the S2 and executed the SELECT for the table, and I was able to see the uncommitted modified data. This is called dirty reads.</p>\n<p>So, with “read-uncommitted”, the transactions from different sessions can view the modification from the different transactions before it commits.</p>\n<h2>READ-COMMITTED:</h2>\n<ul>\n<li aria-level=\"1\">Dirty reads are not possible</li>\n<li aria-level=\"1\">Non-repeatable reads and phantom reads are possible</li>\n</ul>\n<p>The below example will help to understand the “read-committed” and how the non-repeatable reads are happening. I am using two sessions &#8211; S1 and S2.</p>\n<p>For session S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; set global transaction_isolation='read-committed';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; \\r\nConnection id:    18\nCurrent database: percona\n\nmysql&#62; select * from ReadCommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)\n\nmysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; update ReadCommit set name='ram' where id=3;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0</pre><p>For session  S2:</p><pre class=\"crayon-plain-tag\">mysql&#62; select * from percona.ReadCommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>At S1, I globally modified the transaction_isolation to “read-committed” and started the transaction. I executed the UPDATE statement ( name = ram ) at S1 but did not commit the transaction. Then I created S2 and executed the SELECT for the table, and I was not able to see the uncommitted modified data.</p>\n<p>So, with “read-committed”, the transactions from different sessions can’t view the modification from the different transactions until it commits. Only committed modifications can be viewed.</p>\n<p>Then, what is the drawback with “read-committed”?</p>\n<p>Non-repeatable read is possible with the “read-committed”. Below, I explain how the non-repeatable read occurred.</p>\n<p>For session  S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from ReadCommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>For session  S2:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; update percona.ReadCommit set name='ram' where id=3;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql&#62; commit;\nQuery OK, 0 rows affected (0.00 sec)</pre><p>For session  S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from ReadCommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)\n\nmysql&#62; select * from ReadCommit;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | ram  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>At S1, I started the transaction and executed the SELECT to view the data. Then at S2, I executed the UPDATE statement ( name = ram where id = 3) to modify the data. I committed the transaction on S2. Again, at S1 I executed the same SELECT to view the data inside the same transaction. But, this time I have a different result. This is called a non-repeatable read.</p>\n<p>Having a different result for the same query inside the transaction is not fair, and it may lead your transaction to be inconsistent. “REPEATABLE-READ” will help to overcome this.</p>\n<h2>REPEATABLE-READ:</h2>\n<ul>\n<li aria-level=\"1\">Dirty reads and non-repeatable reads are not possible</li>\n<li aria-level=\"1\">Phantom reads are possible</li>\n</ul>\n<p>The below example will help to understand the “repeatable-read” and how the phantom reads are happening. I am using two sessions &#8211; S1 and S2.</p>\n<p>For session S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; set global transaction_isolation='repeatable-read';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; \\r\nConnection id:    20\nCurrent database: percona\n\nmysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from RepeatRead;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>For session S2:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; update percona.RepeatRead set name='ram' where id=3;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql&#62; commit;\nQuery OK, 0 rows affected (0.00 sec)</pre><p>For session S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from RepeatRead;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)\n\nmysql&#62; select * from RepeatRead;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>At S1, I globally modified the transaction_isolation to “repeatable-read” and started the transaction. I executed the SELECT to view the data. Then I created S2 and executed the UPDATE statement ( name = ram where id = 3) to modify the data. I committed the transaction on S2. Again at S1, I executed the same SELECT to view the data inside the same transaction. There are no changes. So, here we overcome the problem of being read-committed.</p>\n<p>At repeatable-read, the snapshot of the SELECT will be taken during the first execution of SELECT, and it will be until the transaction ends. Still, we may get the phantom rows with repeatable-read.</p>\n<h3>How Do Phantom Rows Occur?</h3>\n<p>The below example will help to understand how the phantom rows are occurring inside the transaction.</p>\n<p>For session S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from RepeatRead;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p><span>For session  S2:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; insert into percona.RepeatRead values (4,'ram');\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&#62; commit;\nQuery OK, 0 rows affected (0.00 sec)</pre><p>For session  S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from RepeatRead;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)\n\nmysql&#62; select * from RepeatRead;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)\n\nmysql&#62; update percona.RepeatRead set name='sriram' where id=4;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql&#62; select * from RepeatRead;\n+----+--------+\n| id | name   |\n+----+--------+\n|  1 | jc     |\n|  2 | herc   |\n|  3 | sri    |\n|  4 | sriram |\n+----+--------+\n4 rows in set (0.00 sec)</pre><p>From the above example, at S1, I have executed the SELECT to read the data. Then, I have inserted the row ( id=4 ) on S2. Again, I executed the SELECT at S1, and there are no changes because we are using repeatable-read isolation. Again at S1, I executed the UPDATE to modify the data which was inserted by S2 ( id = 4 ), then executed the same SELECT at S1. But, this time I have different results, which is called the phantom reads. This can be avoided with “SERIALIZABLE”.</p>\n<h2>SERIALIZABLE:</h2>\n<ul>\n<li aria-level=\"1\">No dirty reads</li>\n<li aria-level=\"1\">No non-repeatable reads</li>\n<li aria-level=\"1\">No phantom reads</li>\n</ul>\n<p>The below example will help to understand the “serializable” isolation. I am using two sessions &#8211; S1 and S2.</p>\n<p>For session S1:</p><pre class=\"crayon-plain-tag\">mysql&#62; set global transaction_isolation='serializable';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; \\r\nConnection id:    22\nCurrent database: percona\n\nmysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; select * from Serialize;\n+----+------+\n| id | name |\n+----+------+\n|  1 | jc   |\n|  2 | herc |\n|  3 | sri  |\n+----+------+\n3 rows in set (0.00 sec)</pre><p>For session S2:</p><pre class=\"crayon-plain-tag\">mysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; insert into percona.Serialize values (4,'ram');\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql&#62; update percona.Serialize set name='aaa' where id=3;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction</pre><p>From the above example, I globally modified the isolation level to “serializable” and started the transaction at S1. Then I created session 2 and tried to do an INSERT/UPDATE at S2&#8230; however, these statements timeout due to pre-existing locks being held. At the isolation level serializable, InnoDB implicitly converts all SELECT statements to SELECT FOR SHARE if autocommit is disabled. The SELECT statement from S1 sets shared locks (LOCK IN SHARE MODE) that permit other transactions to read the examined rows but not to update or delete them. So, the INSERT/UPDATE is failing.</p>\n<p>Serializable ensures more consistency for the transactions, but you will have to address increased locking conditions in MySQL.</p>\n<hr />\n<p><em><strong>The call for papers for Percona Live is open!</strong> We&#8217;d love to receive submissions on topics related to open source databases such as MySQL, MongoDB, MariaDB, and PostgreSQL. To find out more visit <a target=\"_blank\" href=\"http://percona.com/live\" target=\"_blank\" rel=\"noopener\" data-saferedirecturl=\"https://www.google.com/url?q=http://percona.com/live&#38;source=gmail&#38;ust=1613226997745000&#38;usg=AFQjCNG5nWHvvja6jmys8zcukYALJRhcXA\">percona.com/live</a></em></p>\n","descriptionType":"html","publishedDate":"Thu, 11 Feb 2021 15:28:38 +0000","feedId":11,"bgimg":"","linkMd5":"7bc37091b41b2f689d3c0eb2ded9d335","bgimgJsdelivr":"","metaImg":"","author":"Sri Sakthivel","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn84@2020_2/2021/04/03/04-49-20-664_ab40f8654e4d09a4.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn19@2020_3/2021/04/03/04-49-22-074_f7b2d096a116c502.webp"},"publishedOrCreatedDate":1617425343839},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Importing an Encrypted InnoDB Tablespace into MySQL","link":"https://www.percona.com/blog/?p=74998","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Importing an Encrypted InnoDB Tablespace into MySQL\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75026\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-300x168.png\" alt=\"Importing an Encrypted InnoDB Tablespace into MySQL\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Transportable tablespaces were introduced in MySQL 5.6. Using this feature, we can directly copy a tablespace to another server and populate the table with data. This is a very useful feature for large tables. The transportable tablespace mechanism is faster than any other method for exporting and importing tables because the files containing the data just need to be copied to the target location using traditional Linux commands (cp, scp, rsync). Our post<a target=\"_blank\" href=\"https://www.percona.com/blog/2014/12/09/mysql-5-6-transportable-tablespaces-best-practices/\"> MySQL 5.6 Transportable Tablespaces best practices</a> covers the best practices about transportable tablespaces. The feature also supports encrypted tablespaces, and in this article, I am going to explain how to use this feature with them.</p>\n<h2>Requirements</h2>\n<p><span>Below I am sharing my current setup and the requirements.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>I have two servers &#8211; s1 and s2.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>I am running <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL</a> 5.7.33 on both servers.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Data-at-Rest Encryption is enabled on both servers.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>S1 has the encrypted table “percona.enc_EI_test”, which needs to be copied to s2 using a transportable tablespace feature. </span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">mysql&#62; select @@version, @@version_comment\\G\n*************************** 1. row ***************************\n        @@version: 5.7.33-36-log\n@@version_comment: Percona Server (GPL), Release 36, Revision 7e403c5\n1 row in set (0.01 sec)\n\nmysql&#62; show create table percona.enc_EI_test\\G  \n*************************** 1. row ***************************\n       Table: enc_EI_test\nCreate Table: CREATE TABLE `enc_EI_test` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(16) DEFAULT NULL,\n  `exec_time` datetime DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=165520 DEFAULT CHARSET=latin1 ENCRYPTION='Y'\n1 row in set (0.01 sec)</pre><p><span>The following steps will be helpful to understand the process involved.</span></p>\n<h3>Step 1 (Prepare the table to copy):</h3>\n<p><span>This step ensures that changes to that particular table have been flushed to disk so that binary table copies can be made while the server is running. </span></p>\n<p><span>At S1:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; flush table enc_EI_test for export;\nQuery OK, 0 rows affected (0.00 sec)</pre><p><span>Once the command is executed, it will create two additional files (.cfg and .cfp) in the MySQL data directory. </span></p><pre class=\"crayon-plain-tag\">-rw-r-----. 1 mysql mysql 8.5K Mar 20 21:05 enc_EI_test.frm\n-rw-r-----. 1 mysql mysql  13M Mar 20 21:05 enc_EI_test.ibd\n-rw-r-----. 1 mysql mysql  100 Mar 20 21:05 enc_EI_test.cfp\n-rw-r-----. 1 mysql mysql  455 Mar 20 21:05 enc_EI_test.cfg</pre><p></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The </span><i><span>.cfg</span></i><span> file is the metadata file, which contains metadata that is used for schema verification during the import operation.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The </span><i><span>.cfp</span></i><span> file is only for the encrypted tables, the .cfp file contains a transfer key and an encrypted tablespace key. </span></li>\n</ul>\n<h3>Step 2 (copy .ibd, .cfg, and .cfp files from s1 to s2):<span> </span></h3>\n<p><span>After executing step one, you need to copy the table files (.ib,.cfg,.cfp) to destination server s2.</span></p><pre class=\"crayon-plain-tag\">[root@s1 percona]# scp -r enc_EI_test.ibd enc_EI_test.cfp enc_EI_test.cfg 172.28.128.17:/tmp/export/\nenc_EI_test.cfg                                                                                                                                 100%  455   492.5KB/s   00:00    \nenc_EI_test.cfp                                                                                                                                 100%  100   133.3KB/s   00:00    \nenc_EI_test.ibd                                                                                                                                 100%   13MB  84.0MB/s   00:00</pre><p></p>\n<h3>Step 3 (Unlock table on S1):</h3>\n<p><span>Once the table files are copied to the destination server (s2), you need to unlock the table on s1 to allow the operations.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; unlock tables;\nQuery OK, 0 rows affected (0.00 sec)</pre><p></p>\n<h3>Step 4 (Create the table structure on s2):</h3>\n<p><span>Now, you have to create the empty table on the destination server s2.</span></p><pre class=\"crayon-plain-tag\">mysql&#62;  CREATE TABLE `enc_EI_test` (\n    -&#62;   `id` int(11) NOT NULL AUTO_INCREMENT,\n    -&#62;   `name` varchar(16) DEFAULT NULL,\n    -&#62;   `exec_time` datetime DEFAULT CURRENT_TIMESTAMP,\n    -&#62;   PRIMARY KEY (`id`)\n    -&#62; ) ENGINE=InnoDB AUTO_INCREMENT=165520 DEFAULT CHARSET=latin1 ENCRYPTION='Y';\nQuery OK, 0 rows affected (0.01 sec)</pre><p><span>Make sure that you have added the encryption on the table structure “ENCRYPTION=Y”. Otherwise, you will get the following error during the import process.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; alter table enc_EI_test import tablespace;\nERROR 1808 (HY000): Schema mismatch (Encryption attribute in the file does not match the dictionary.)</pre><p></p>\n<h3>Step 5 (Remove the .ibd file):</h3>\n<p><span>Once the empty table has been created on s2, it will have two files (.frm and .ibd). You need to remove the .ibd file so that you can import the tablespace which was copied from s1. </span></p><pre class=\"crayon-plain-tag\">[root@s2 percona]# ls -lrth\ntotal 112K\n-rw-r-----. 1 mysql mysql 8.5K Mar 20 21:08 enc_EI_test.frm\n-rw-r-----. 1 mysql mysql  96K Mar 20 21:08 enc_EI_test.ibd\n\nmysql&#62; alter table enc_EI_test discard tablespace;\nQuery OK, 0 rows affected (0.01 sec)\n\n[root@s2 percona]# ls -lrth\ntotal 16K\n-rw-r-----. 1 mysql mysql 8.5K Mar 20 21:08 enc_EI_test.frm</pre><p></p>\n<h3>Step 6 (Copy the tablespace to data directory):</h3>\n<p><span>In this step, you need to copy the tablespace files (from s1) to the data directory under the database folder. </span></p><pre class=\"crayon-plain-tag\">[root@s2 percona]# pwd\n/var/lib/mysql/percona\n[root@s2 percona]# cp -r /tmp/export/enc_EI_test.ibd .\n[root@s2 percona]# cp -r /tmp/export/enc_EI_test.cf* .\n[root@s2 percona]# ls -lrth\ntotal 14M\n-rw-r-----. 1 mysql mysql 8.5K Mar 20 21:08 enc_EI_test.frm\n-rw-r-----. 1 root  root   13M Mar 20 21:12 enc_EI_test.ibd\n-rw-r-----. 1 root  root   100 Mar 20 21:12 enc_EI_test.cfp\n-rw-r-----. 1 root  root   455 Mar 20 21:12 enc_EI_test.cfg</pre><p><span>Make sure that you are copying the .cfp file as well. Without the .cfp file, the import will not work, and you will get the following error.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; alter table enc_EI_test import tablespace;\nERROR 1808 (HY000): Schema mismatch (Table is in an encrypted tablespace, but the encryption meta-data file cannot be found while importing.)</pre><p></p>\n<h3>Step 7 (Change ownership to MySQL user):</h3>\n<p></p><pre class=\"crayon-plain-tag\">[root@s2 percona]# chown -R mysql:mysql enc_EI_test.ibd enc_EI_test.cf*\n[root@repl percona]# ls -lrth\ntotal 14M\n-rw-r-----. 1 mysql mysql 8.5K Mar 20 21:08 enc_EI_test.frm\n-rw-r-----. 1 mysql mysql  13M Mar 20 21:12 enc_EI_test.ibd\n-rw-r-----. 1 mysql mysql  100 Mar 20 21:12 enc_EI_test.cfp\n-rw-r-----. 1 mysql mysql  455 Mar 20 21:12 enc_EI_test.cfg</pre><p></p>\n<h3>Step 8 (Import the tablespace):</h3>\n<p><span>Now, we are good to run the import command.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; alter table enc_EI_test import tablespace;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql&#62; select count(*) from enc_EI_test;\n+----------+\n| count(*) |\n+----------+\n|   100000 |\n+----------+\n1 row in set (0.03 sec)</pre><p><span>This process is quite similar to the normal InnoDB tablespace export/import process. But, here you need to take care of the following two things:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You need to copy the .cfp file as well to the destination servers.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Your destination table also needs to be configured with encryption (ENCRYPTION = Y).</span></li>\n</ul>\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database?utm_source=blog\">Learn about Percona Distribution for MySQL, an enterprise-grade solution for your most critical business applications.</a></p>\n","descriptionType":"html","publishedDate":"Wed, 24 Mar 2021 13:03:54 +0000","feedId":11,"bgimg":"","linkMd5":"70eede3fb1727a158133024b99497716","bgimgJsdelivr":"","metaImg":"","author":"Sri Sakthivel","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn20@2020_5/2021/04/03/04-49-19-237_6fa12b0eac405511.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn39@2020_6/2021/04/03/04-49-17-421_7ad68a4f647ff723.webp"},"publishedOrCreatedDate":1617425343771},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Working to Validate MyRocks in the Enterprise with Dropbox","link":"https://www.percona.com/blog/?p=74812","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MyRocks in the Enterprise with Dropbox\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75226\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-300x157.png\" alt=\"MyRocks in the Enterprise with Dropbox\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Percona Technical Account Managers get the privilege of working with some of our largest enterprise clients day in and day out.  As such, we get to really focus on how to best leverage our technology to generate measurable benefits for our users.  While it is fun to “nerd out” and always strive to use the latest and greatest, we need to stay focused on demonstrating business value and a genuine need.  Over the past few months, I’ve been working with one of my larger clients, <a target=\"_blank\" href=\"https://www.dropbox.com/\"><strong>Dropbox</strong></a>, along with our professional services team to validate the use of <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL</a> with the MyRocks storage engine over a large portion of their MySQL infrastructure.</p>\n<p><strong>Please note</strong> &#8211; this is not meant to be a deep dive into the technical details around MyRocks or the implementation.  Rather, it is meant to show how we determined the need, potential solution, and the planning that has started us down this path.  Look for a more detailed case study in the coming months as we hope to push this solution forward!</p>\n<h3>The Problem</h3>\n<p>In a single word, <strong>space</strong>.  When a client reaches a certain scale, space becomes a real concern.  With 10-20 servers, having an extra index or choosing the wrong data type can be noticeable.  However, with 10,000 servers, there is much less margin for error.  The challenge with this client is that the schema has already been sharded and optimized. Even with that, the aggregate dataset is still on the petabyte scale.  Think about what that means:</p>\n<ul>\n<li aria-level=\"1\">Large storage footprint per server (2+TB)</li>\n<li aria-level=\"1\">Replication multiplies that footprint for each “cluster”</li>\n<li aria-level=\"1\">Multiple backups per cluster result in a huge (PB+) backup footprint</li>\n</ul>\n<p>There are some additional challenges created at this scale, too.  To mitigate the risk of filling a disk, there is a soft cap of 75 percent full on each server.  When a cluster hits this level, the shard is split to give each half some additional runway.  While this is great operationally, splitting shards results in doubling the cost for the cluster.  Again, on a scale of 1000s of servers, a “split” means an increase in cost in the hundreds of thousands of dollars.  This is not trivial and puts pressure on the team to delay splits as long as possible while maintaining high availability, durability, and performance.</p>\n<h3>MyRocks Use Case</h3>\n<p>After much discussion and understanding that space (and, in turn, cost) is a major business driver, we decided to investigate a change to <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/8.0/myrocks/index.html\">MyRocks</a> as the storage engine.  While standard InnoDB compression provided a small bandaid, the thinking was that MyRocks would give substantial savings.  At a very high level, MyRocks is an LSM tree-based storage engine built on top of RocksDB.  This type of storage has numerous advantages over traditional B+Tree storage engines (like InnoDB), including a smaller disk footprint and reduced write amplification.  This can translate to business value in several ways, including:</p>\n<ul>\n<li aria-level=\"1\">Decreased cloud/HDFS storage cost for backups</li>\n<li aria-level=\"1\">Reduced Write Amplification results in a longer disk lifetime, reducing fleet turnover</li>\n<li aria-level=\"1\">Decreased instance space requires fewer splits and increases runway</li>\n</ul>\n<p>After several rounds of discussion around the benefits and any blockers, we decided to begin testing the feasibility of converting from InnoDB to MyRocks.</p>\n<h3>Initial Testing</h3>\n<p>While the use case seemed like a solid fit, extensive testing is always needed.  So far, the initial testing looks promising.  We’ve seen a large reduction in space combined with an increase in performance.  One example cluster saw nearly a 75 percent reduction in space, to the point that we were able to test running two replica instances on a single server in parallel.</p>\n<p>What makes this interesting is that the test cluster in question has replicas that periodically show lag and generally are close to the replication limit.  In contrast, the two MyRocks replicas showed no lag during the same test period despite running two instances on one physical server.</p>\n<p>While this isn’t something that would be done in production, it was impressive to see double the workload operating so efficiently on the same hardware.  I/O and CPU utilization were both noticeably lower than the single replica running InnoDB.  This shows the potential of increased server longevity and less frequent splits that we were hoping to see.  If these numbers and this performance were to hold into production, we could see savings on the order of millions of dollars across the entire fleet.</p>\n<p>Note &#8211; this early testing has been limited to replicas only so we can’t yet validate this performance at the production level of concurrency of a primary server.  These results are only with four replica threads, so contention has been minor.</p>\n<h3>Looking Forward</h3>\n<p>So far, our limited testing has shown some real promise.  There are still some blockers that we need to overcome, but early results are encouraging. Currently, the biggest technical challenges in this project include:</p>\n<ul>\n<li aria-level=\"1\">MyRocks currently lacks pt-table-checksum support (for replica consistency)</li>\n<li aria-level=\"1\">Modifying and validating existing backup/restore/clone automation</li>\n</ul>\n<p>Once we are able to fully validate this solution and solve the existing challenges (both fixes have been identified and are on the project roadmap) in the coming months, look for a more detailed case study.  While not every organization needs to make such a drastic change, this use case is one that is becoming more common at the enterprise level as data sets continue to explode.</p>\n<p>Want to learn more? Check out the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/8.0/myrocks/index.html\">Percona MyRocks Introduction</a> page on our website!</p>\n","descriptionType":"html","publishedDate":"Thu, 01 Apr 2021 18:21:22 +0000","feedId":11,"bgimg":"","linkMd5":"b687f48d545690e3d97271e4cfa2248b","bgimgJsdelivr":"","metaImg":"","author":"Mike Benshoof","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn92@2020_6/2021/04/03/04-49-21-455_a9eecce7436e8816.webp","https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn83@2020_5/2021/04/03/04-49-18-529_195f5079b5ddd12e.webp"},"publishedOrCreatedDate":1617425343757},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Request for Comments: Global Processlist in Percona Monitoring and Management","link":"https://www.percona.com/blog/?p=74438","description":"<img width=\"200\" height=\"113\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-200x113.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Global Processlist in Percona Monitoring and Management\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-1536x864.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-2048x1152.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-367x206.png 367w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74443\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-300x169.png\" alt=\"Global Processlist in Percona Monitoring and Management\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-1024x576.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-200x113.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-1536x864.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-2048x1152.png 2048w, https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-367x206.png 367w\" sizes=\"(max-width: 300px) 100vw, 300px\" />One piece of feedback I often hear from users of <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a>  (PMM) is that while the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/using/query-analytics.html\">Query Analytics</a> feature is great and provides a lot of insights into queries the server handled, it can’t help us to see which queries are running now.</p>\n<h3>Problem Statement</h3>\n<p>Real-time access to queries that are running right now can be extremely helpful in case of pileups if the optimizer gets crazy, a bad query id is deployed, or some unexpected locking situation takes place. The usual result is that many queries of the same kind pile up… and if you’re not lucky, they may not complete for many minutes or even hours, all this time <strong>invisible in PMM</strong>.</p>\n<h3>Proposed Solution</h3>\n<p>In addition to Query History, what Query Analytics really provides now is access to “Live Queries”.  This basically gathers currently-running queries from all the nodes that a user currently observes (could be one node or could be a hundred), where queries can be grouped and sliced in a way similar to how Query Analytics works.</p>\n<p>For example, for a given a QueryId (Query Pattern), we can see how many instances of such a query are running right now, what the maximum and average execution time is so far, what database hosts and what databases it is active for, what client IPs and users this query are coming from, etc.</p>\n<p>Some other Query Analytics features such as EXPLAIN for a query, information about involved tables, etc., also remain relevant for running queries too.</p>\n<p>Also, working with current events and not just history means we can do more than just observe them. I could imagine killing some particular query instance or even all queries which match a particular pattern, which would be handy too.</p>\n<p><strong>What do you think?</strong> Would having such a “Global Processlist” feature in Percona Monitoring and Management be helpful for you?   Anything else we should consider? Let me know in the comments!</p>\n","descriptionType":"html","publishedDate":"Fri, 12 Feb 2021 14:24:53 +0000","feedId":11,"bgimg":"","linkMd5":"bdbdc777b5768814fb7bc017456c5e61","bgimgJsdelivr":"","metaImg":"","author":"Peter Zaitsev","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-200x113.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn76@2020_6/2021/04/03/04-49-20-588_a60844d910f519d8.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn92@2020_2/2021/04/03/04-49-07-353_e70c64bba01281fe.webp"},"publishedOrCreatedDate":1617425343853},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"CVE-2020-29488: Changes in How Absolute Paths are Handled in Percona XtraBackup xbstream","link":"https://www.percona.com/blog/?p=74538","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"CVE-2020-29488\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75005\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-300x157.png\" alt=\"CVE-2020-29488\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Due to <a target=\"_blank\" href=\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-29488\">CVE-2020-29488</a>, <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtrabackup\">Percona XtraBackup</a> is modifying how xbstream handles absolute paths to prevent malicious file injections. Like the tar archiving utility, the new behavior removes the leading &#8216;/&#8217; character and references to the parent directory.</p>\n<p>Fixes are available in Percona XtraBackup versions:</p>\n<p>&#62;= 2.4.22</p>\n<p>&#62;= 8.0.23-16.0</p>\n<p>For example, <code>../../../d1/../d2/h.txt</code> will be saved in the stream with the relative path <code>./d2/h.txt</code>.</p>\n<p>The updated function provides a warning when creating a stream with a file with an absolute path:</p>\n<p><code>$ xbstream -c /tmp/data</code></p>\n<p><code>xbstream: Removing leading '/' from member names</code></p>\n<p>The function also will not extract files with absolute paths:</p>\n<p><code>$ cat a.xb | xbstream -x -C  ./restore</code></p>\n<p><code>xbstream: absolute path not allowed: /tmp/bar.txt</code></p>\n<p>Note: a stream can contain an absolute path if created with an older version of xbstream or if the following parameter is used:</p>\n<ul>\n<li><code>-P, --absolute-names</code></li>\n</ul>\n<p>Be aware of the following:</p>\n<p>Scripts that call xbstream to store the path/file in an absolute path will strip the leading &#8216;/&#8217; and references to &#8216;../&#8217;. This action could cause an unexpected result.</p>\n<p>Extracting older formatted binaries which do contain the leading &#8216;/&#8217;  and path/file produce an error message and are not extracted.</p>\n","descriptionType":"html","publishedDate":"Tue, 23 Mar 2021 12:09:05 +0000","feedId":11,"bgimg":"","linkMd5":"acf85eccf23ec1e00967361275f02244","bgimgJsdelivr":"","metaImg":"","author":"Patrick Birch","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn16@2020_5/2021/04/03/04-49-07-821_ca7609853f9cc723.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn4@2020_3/2021/04/03/04-49-22-151_c88c96cdf532cb1a.webp"},"publishedOrCreatedDate":1617425343832},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"How to Build Percona Server for MySQL From Sources","link":"https://www.percona.com/blog/?p=74736","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Build Percona Server for MySQL From Sources\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74803\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-300x168.png\" alt=\"Build Percona Server for MySQL From Sources\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Lately, the number of questions about how to build Percona software has been increased. More and more people try to add their own patches, add some modifications, and build software by themselves. But this raises the question of how to do this in the same way as Percona does, as sometimes the compiler flag can make a drastic impact on the final binary.</p>\n<p><strong>First of all, let’s talk about the stages of compiling software.</strong></p>\n<p>I would say that at the beginning you need to prepare the build environment, install all the needed dependencies, and so on. For each version, the dependency list would be different. How do you get the correct dependency list? You can get all build requirements from the spec file (on rpm-based systems) or from the control file( on deb-based systems).</p>\n<p>The next stage is to get the source code of <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL</a>. You can do it in different ways:</p>\n<ul>\n<li aria-level=\"1\"><strong>Get source tarball from the website</strong></li>\n</ul>\n<p>We publish source tarball for each release we issue and you can easily get it for any released version (<a target=\"_blank\" href=\"https://downloads.percona.com/downloads/Percona-Server-LATEST/Percona-Server-8.0.22-13/source/tarball/percona-server-8.0.22-13.tar.gz\">this is the link for the latest 8.0.22 version</a>).</p>\n<ul>\n<li aria-level=\"1\"><strong>Download tarball from GitHub</strong></li>\n</ul>\n<p>Here is the link: <a target=\"_blank\" href=\"https://github.com/percona/percona-server/releases/tag/Percona-Server-8.0.22-13\">https://github.com/percona/percona-server/releases/tag/Percona-Server-8.0.22-13</a></p>\n<p>Once you have prepared the build environment, you need to decide what result you should get: binary tarball, rpm, or deb package.</p>\n<ul>\n<li aria-level=\"1\">Binary tarball &#8211; you can follow these instructions: <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/LATEST/installation.html#compile-from-source\">https://www.percona.com/doc/percona-server/LATEST/installation.html#compile-from-source</a> and you would be able to build it.</li>\n<li aria-level=\"1\">You also can find, in our manual, how to build deb package: <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/LATEST/installation.html#building-percona-server-debian-ubuntu-packages\">https://www.percona.com/doc/percona-server/LATEST/installation.html#building-percona-server-debian-ubuntu-packages</a></li>\n<li aria-level=\"1\">And in another blog, you can read about how to build the rpm package: <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/01/20/how-to-manually-build-percona-server-rpm-packages/\">https://www.percona.com/blog/2017/01/20/how-to-manually-build-percona-server-rpm-packages/</a></li>\n</ul>\n<p>So everything looks easy. But what is the way we use, internally, to prepare our release packages? As I mentioned earlier, each compiler option can make a significant effect.</p>\n<p>Everyone tries to make life easier and automate all tasks. It is great, as automation is one of the keys to success as you can work on other tasks once the release build is in progress. So we have created a builder script that is used for making builds. It can be found in the <a target=\"_blank\" href=\"https://github.com/percona/percona-server/blob/8.0/build-ps/percona-server-8.0_builder.sh\">Percona Server GitHub repo</a> and can be used by anyone to make his own builds.</p>\n<p>This script can install all needed dependencies for the build environment, create binary tarballs, source RPMs and debs, RPMs, debs itself, and the binary tarball. So it covers all build cycles. So how do you use it?</p>\n<p>The script has various params:</p><pre class=\"crayon-plain-tag\">        --builddir=DIR      Absolute path to the dir where all actions will be performed\n\n        --get_sources       Source will be downloaded from github\n\n        --build_src_rpm     If it is 1 src rpm will be built\n\n        --build_source_deb  If it is 1 source deb package will be built\n\n        --build_rpm         If it is 1 rpm will be built\n\n        --build_deb         If it is 1 deb will be built\n\n        --build_tarball     If it is 1 tarball will be built\n\n        --install_deps      Install build dependencies(root privileges are required)\n\n        --branch            Branch for build\n\n        --repo              Repo for build\n\n        --rpm_release       RPM version( default = 1)\n\n        --deb_release       DEB version( default = 1)\n\n        --debug             Build debug tarball</pre><p>So let’s see how we can make the build process easier:</p>\n<p><strong>1.</strong> <strong>Download build script:</strong></p><pre class=\"crayon-plain-tag\">wget       https://raw.githubusercontent.com/percona/percona-server/8.0/build-ps/percona-server-8.0_builder.sh</pre><p><strong>2.</strong> <strong>Create a build directory where you are going to perform all build actions</strong>:<span><br />\n</span></p><pre class=\"crayon-plain-tag\">mkdir /tmp/BUILD_PS</pre><p><strong>3.</strong> <strong>Install dependencies(please note root permissions are required):</strong><span><br />\n</span></p><pre class=\"crayon-plain-tag\">sudo ./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --install_deps=1</pre><p><strong>4.</strong> <strong>Download source code:</strong><span><br />\n</span><span><br />\n</span> &#8211; From Percona repo (it is used by default):<span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --get_sources=1 --branch=Percona-Server-8.0.22-13</pre><p>&#8211; From your own repo and branch:<span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --get_sources=1 --branch=&#60;your_branch_name&#62; --repo=&#60;link_to_your_repo_on_github&#62;</pre><p><strong>5.</strong> <strong>Prepare src rpm:</strong><span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --build_src_rpm=1</pre><p>Please note if you already have your source tarball, just create a directory named source_tarball in the build directory and put it into it.</p>\n<p><strong>6.</strong> <strong>Prepare source deb:</strong><span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --build_source_deb=1</pre><p>Please note if you already have your source tarball, just create a directory named source_tarball in the build directory and put it into it.</p>\n<p><strong>7.</strong> <strong>Prepare rpm:</strong><span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --build_rpm=1</pre><p><strong>8.</strong> <strong>Prepare deb:</strong><span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --build_deb=1</pre><p><strong>9.</strong> <strong>Prepare tarball:</strong><span><br />\n</span></p><pre class=\"crayon-plain-tag\">./percona-server-8.0_builder.sh --builddir=/tmp/BUILD_PS --build_tarball=1</pre><p>So as you can see, the build procedure becomes easier and you don’t need to think about what dependencies are needed, what cmake params should be used, etc. This build script will make everything for you and will use all build flags (if you didn’t change them in your sources) that we use for release builds.</p>\n","descriptionType":"html","publishedDate":"Wed, 10 Mar 2021 14:53:57 +0000","feedId":11,"bgimg":"","linkMd5":"740b49217b028b16333cba4b01495341","bgimgJsdelivr":"","metaImg":"","author":"Evgeniy Patlan","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_6/2021/04/03/04-49-17-414_97eee12653d25708.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn95@2020_4/2021/04/03/04-49-21-702_ac96bccaa855fa76.webp"},"publishedOrCreatedDate":1617425343822},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Security Fixes for Percona XtraDB Cluster, Updated Percona Distribution for MySQL: Release Roundup March 29, 2021","link":"https://www.percona.com/blog/?p=74913","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Releases March 29\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2>It&#8217;s release roundup time again here at Percona!</h2>\n<p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75054\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-300x169.png\" alt=\"Percona Releases March 29\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download.</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since March 15, 2021, including fixes for security vulnerability CVE-2021-27928 in Percona XtraDB Cluster, an updated Percona Distribution for MySQL (PXC variant), and the release of Percona Monitoring and Management 2.15.1.</p>\n<p>&#160;</p>\n<h2>Percona Distribution for MySQL (Percona XtraDB Cluster Variant) 8.0.22</h2>\n<p>On March 23, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-distribution-mysql/8.0/release-notes-pxc-v8.0.22.html\">Percona Distribution for MySQL (PXC variant) 8.0.22</a> was released. It is a single solution with the best and most critical enterprise components from the MySQL open source community, designed and tested to work together. This release is based on <a target=\"_blank\" class=\"reference external\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/8.0/release-notes/Percona-XtraDB-Cluster-8.0.22-13.1.html\">Percona XtraDB Cluster 8.0.22-13.1</a>.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/percona-distribution-mysql-pxc/LATEST/\">Download Percona Distribution for MySQL (PXC variant) 8.0.22</a></p>\n<p>&#160;</p>\n<h2>Percona Monitoring and Management 2.15.1</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/release-notes/2.15.1.html\">Percona Monitoring and Management 2.15.1</a> was released on March 18, 2021. It is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance. A release highlight is a patch that fixes performance issues discovered in systems, together with other small fixes. In addition, there are several bug fixes, including high CPU consumption by Grafana server, high CPU and Memory consumption by Victoria Metrics, and MongoDB exporter <code>IndexStatsCollections</code> assigning values from the wrong flag (intended for 2.15.0, omitted due to missing merge cutoff &#8211; Thanks to Tim for reporting this issue).</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/pmm2/\">Download Percona Monitoring and Management 2.15.0</a></p>\n<p>&#160;</p>\n<h2>Percona XtraDB Cluster 5.6.51-28.46</h2>\n<p>On March 22, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/5.6/release-notes/Percona-XtraDB-Cluster-5.6.51-28.46.html\">Percona XtraDB Cluster 5.6.51-28.46</a> was released. It is a high availability, open-source, MySQL clustering solution that helps enterprises minimize unexpected downtime and data loss, reduce costs, and improve the performance and scalability of their database environments. This fixes security vulnerability CVE-2021-27928, a similar issue to CVE-2020-15180.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraDB-Cluster-56/LATEST/\">Download Percona XtraDB Cluster 5.6.51-28.46</a></p>\n<p>&#160;</p>\n<h2>Percona XtraDB Cluster 5.7.33-31.49</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/5.7/release-notes/Percona-XtraDB-Cluster-5.7.33-31.49.html\">Percona XtraDB Cluster 5.7.33-31.49</a> was released on March 22, 2021. This fixes security vulnerability CVE-2021-27928, a similar issue to CVE-2020-15180. There are also several bug fixes, including modifying processing to not allow threads/queries to be killed if the thread is in TOI and explicitly set the dhparam option with socat to bypass the use of the old certs.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraDB-Cluster-57/LATEST/\">Download Percona XtraDB Cluster 5.7.33-31.49</a></p>\n<p>&#160;</p>\n<h2>Percona XtraDB Cluster 8.0.22-13.1</h2>\n<p>March 22, 2021, saw the release of <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtradb-cluster/8.0/release-notes/Percona-XtraDB-Cluster-8.0.22-13.1.html\">Percona XtraDB Cluster 8.0.22-13.1</a>. This fixes security vulnerability CVE-2021-27928, a similar issue to CVE-2020-15180. An improvement in this release is the implementation of package changes for SELinux and AppArmor, and bug fixes include modification of processing to not allow threads/queries to be killed if the thread is in TOI, correct condition in thd_binlog_format() function for List Index process (Thanks to user Paweł Bromboszcz for reporting this issue), and the adjustment of mysqld_safe script to parse 8.0 log style properly. There are also some known issues you should be aware of, listed in the release notes.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraDB-Cluster-LATEST/\">Download Percona XtraDB Cluster 8.0.22-13.1</a></p>\n<p>&#160;</p>\n<h2>Percona XtraBackup 2.4.22</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtrabackup/2.4/release-notes/2.4/2.4.22.html\">Percona XtraBackup 2.4.22</a> was released on March 22, 2021. It enables MySQL backups without blocking user queries, making it ideal for companies with large data sets and mission-critical applications that cannot tolerate long periods of downtime. This release fixes the security vulnerability CVE-2020-29488. There are also bugs fixed, including updated versions for xbstream and xbcrypt, correct spellings in xbcloud help, and the addition of missing PXB help options to the xtrabackup options reference.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/\">Download Percona XtraBackup 2.4.22</a></p>\n<p>&#160;</p>\n<h2>Percona XtraBackup 8.0.23-16.0</h2>\n<p>Also on March 22, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtrabackup/LATEST/release-notes/8.0/8.0.23-16.0.html\">Percona XtraBackup 8.0.23-16.0</a> was released, fixing the security vulnerability CVE-2020-29488. Improvements in this release include providing SELinux and AppArmor default policies and enabling –lock-ddl by default to prevent corruption of the backup. A full list of bug fixes are in the release notes, but some of the highlights are the correction of incremental prepare failure with logical redo by skipping the apply of logical redos (MLOG_TABLE_DYNAMIC_META) during the incremental prepare (except the last prepare), the addition of build dependencies to correct Debian/Ubuntu packages in docker (Thanks to user Matt Cole for reporting this issue), and correct restore processing when there are DML statements running during backup stage by writing the last_checkpoint and LSN from ps.log_status instead of the redo log (Thanks to user Li Biao for reporting this issue).</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/Percona-XtraBackup-LATEST/\">Download Percona XtraBackup 8.0.23-16.0</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;noopener&#34; noopener noreferrer\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n","descriptionType":"html","publishedDate":"Mon, 29 Mar 2021 13:02:32 +0000","feedId":11,"bgimg":"","linkMd5":"c13248c7476255e2bcae20484e995e74","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn55@2020_6/2021/04/03/04-49-23-048_a253c345db9c984f.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn47@2020_5/2021/04/03/04-49-22-597_f45ee932e8e6eef3.webp"},"publishedOrCreatedDate":1617425343831},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"MySQL 101: Using super_read_only","link":"https://www.percona.com/blog/?p=75071","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL 101 super_read_only\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75169\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-300x168.png\" alt=\"MySQL 101 super_read_only\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />As many of you may remember, Percona added the <strong>super_read_only</strong> feature way back in <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQL</a> 5.6.21, based on work done by WebScaleSQL. This feature eventually found its way into the Community branch of MySQL starting with 5.7.8, and it works the same in both cases. While this is now old news, over the last year I’ve had a couple of inquiries from clients around <strong>super_read_only</strong> usage in MySQL, and how it works in practice. While the usage of <strong>super_read_only</strong> is not complex, there is a small caveat that occasionally leads to some confusion around its use. As such, I thought it may be a good idea to write a quick blog post explaining this feature a bit more, and expanding on how it interacts with <strong>read_only</strong>.</p>\n<h2>What is super_read_only?</h2>\n<p>For those unfamiliar, what is <strong>super_read_only</strong>? Prior to its introduction, MySQL had the option to set a node to <strong>read_only</strong>, preventing everyone except those with the <strong>SUPER</strong> privilege from writing to the database. Most often used for replica nodes, it was a good step in preventing someone from inadvertently updating a replica manually without going through the primary node and letting replication threads handle the distribution. This, of course, could break replication due to duplicate keys, missing rows, or other issues as a result of the inconsistency between the datasets.</p>\n<p>Using <strong>super_read_only</strong> takes this one step further, behaving identically to <strong>read_only</strong> while also blocking those with <strong>SUPER</strong> privileges from writing to the database as well. While at first glance this may seem like a stop-gap measure in lieu of better and more restrictive user permissions, it has proven very handy in production environments to add a further layer of protection to replica nodes, and helping to prevent human error from causing unexpected downtime.</p>\n<h2>One Hand Washes The Other</h2>\n<p>The inquiries I referenced earlier comes with its use, and not realizing (or forgetting) that <strong>read_only</strong> and <strong>super_read_only</strong> are linked. The key thing to keep in mind is that enabling <strong>super_read_only</strong> <em><strong>implies</strong></em> regular <strong>read_only</strong> as well.</p>\n<ul>\n<li>Setting <strong>read_only</strong> = OFF <em><strong>also sets</strong></em> <strong>super_read_only</strong> = OFF.</li>\n<li>Setting <strong>super_read_only</strong> = ON <em><strong>also sets</strong></em> <strong>read_only</strong> = ON.</li>\n<li><strong>All other changes</strong> to either of these variables <strong>have no effect</strong> on the other.</li>\n</ul>\n<p>This behavior does seem logical, as when disabling <strong>read_only</strong> you probably also want to disable <strong>super_read_only</strong>, and vice-versa, when enabling <strong>super_read_only</strong> you probably also want to enable <strong>read_only</strong>. While this linked behavior is documented, there are no warnings or notes in MySQL itself alerting you to this when you make a change to one or the other. This can lead to some head-scratching, as a change to one variable changes the other in lockstep.</p>\n<h3>Final Considerations</h3>\n<p>There are a few other implications to keep in mind for <strong>read_only</strong> that apply to <strong>super_read_only</strong> as well – for instance, operations on temporary tables are allowed no matter how these variables are set. Any <strong>OPTIMIZE TABLE</strong> or<strong> ANALYZE TABLE</strong> operations are also allowed since the purpose of <strong>read_only</strong> / <strong>super_read_only</strong> is to prevent changes to the table structure, but not to table metadata such as index statistics. Finally, these settings will need to be manually disabled (or scripted via automation) if there is ever an instance where the replica needs to be promoted to primary status.</p>\n<hr />\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database?utm_source=blog\"><strong>Percona Distribution for MySQL: An Enterprise-Grade MySQL Solution, for Free</strong></a></p>\n","descriptionType":"html","publishedDate":"Wed, 31 Mar 2021 14:50:06 +0000","feedId":11,"bgimg":"","linkMd5":"3ce9e57e09207a7fe19234725cd8466f","bgimgJsdelivr":"","metaImg":"","author":"Brian Sumpter","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn91@2020_5/2021/04/03/04-49-21-259_2bca72f2115bbc0f.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn19@2020_4/2021/04/03/04-49-23-990_a8eec40f221a5622.webp"},"publishedOrCreatedDate":1617425343832},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Connection Queuing in pgBouncer: Is it a Magical Remedy?","link":"https://www.percona.com/blog/?p=74480","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Connection Queuing in pgBouncer\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p>Yes, this post is about <strong>connection queueing</strong>, not just pooling. Because &#8220;connection pooling&#8221; &#8211; pre-created connections as a pool &#8211; is a much-celebrated feature. Almost every discussion on connection pool/pgBouncer starts with the overhead of establishing a new connection to PostgreSQL&#8230; and how pre-created connections in the pool can save the world.</p>\n<p>But there is a non-celebrity feature in pgBouncer (not denying others) that can address some of the real big operational challenges. It is the connection queueing. Many new PostgreSQL users don&#8217;t know there is something like this. In this blog post, I am planning to discuss some of the problems related to connection management first, and then explore how connection queueing can address those problems.</p>\n<h3>Problem 1: Spike in Load can Jam and Halt the Server</h3>\n<p>PostgreSQL has a dedicated backend server process for every user connection. So there will be one backend process running on a CPU core for every active queries/sessions. This means there is a <strong>one-to-one mapping</strong> between <strong>active sessions</strong> and <strong>running processes</strong> in the server. If we consider parallel execution of SQL statements, there will be many more running processes than active sessions. In many real-world cases, a sudden spike in load can result in hundreds of active queries starting at once while the server is equipped with a small number of CPUs (sometimes just virtual CPUs with only fraction of performance). As the number of active sessions/processes increases, the overhead of scheduling and context switches takes over.  Many times, the host server becomes unresponsive, and even opening a bash shell/terminal can take time. This is quite easy to simulate. Just 10 active connections on a two virtual CPU server with SELECT only workload can cause this.</p>\n<p>With two active sessions:</p><pre class=\"crayon-plain-tag\">$ time ssh -t postgres@pghost 'ls -l'\nreal 0m0.474s\nuser 0m0.017s\nsys 0m0.006s</pre><p>When there are 10 active sessions on PostgreSQL, just establishing an ssh connection to the server took 15 seconds.</p><pre class=\"crayon-plain-tag\">real 0m15.307s\nuser 0m0.026s\nsys 0m0.015s</pre><p>**These are indicative numbers from a very specific system and do not qualify for a benchmark.</p>\n<p>Generally, we could see that <strong>as the number of active sessions approaches double the number of CPU cores</strong> the performance penalty starts increasing heavily.</p>\n<p>Many times, the problem won&#8217;t end there. Session level resource allocations (work_mem, temporary tables, etc.) can lead to overall server resource consumption. As the host server slows down, each session will take more time to complete while holding the resources, which could lead to more accumulation of active sessions. It is a spiral of evil. There are many real-world cases, where the entire show ended in a complete halt of the host server or OOM kick-in, terminating the PostgreSQL process and forcing it for crash recovery.</p>\n<h3>Problem 2: &#8220;Too Many Clients Already&#8221; Errors</h3>\n<p>Few smart DBAs will prevent this database disaster by setting <strong><span class=\"crayon-e\">max_connections</span></strong> properly to a smaller value than the database can handle, which is the right thing to do from a DB server perspective. Allowing an excessive number of connections to the database can lead to different types of abuses, attacks, and disasters. But the flip side to it is an abusive application may be greeted with the message as follows:</p><pre class=\"crayon-plain-tag\">FATAL:  sorry, too many clients already</pre><p>The same will be logged in the PostgreSQL log.</p><pre class=\"crayon-plain-tag\">2021-02-15 13:40:50.017 UTC [12829] FATAL:  sorry, too many clients already</pre><p>Unfortunately, this could lead to an application crash or misbehavior. From the business point of view, we just shifted the problem from database to application.</p>\n<h3>Problem 3: Big max_connection Value and Overhead</h3>\n<p>Because of the above-mentioned problem, it is common to see max_connection to have a very high value. The overhead of connections is probably one of the most actively-discussed topics these days because Postgres 14 is expected to have some of the connection scalability fixes. Andres Freund blogged about the details of <a target=\"_blank\" href=\"https://www.citusdata.com/blog/2020/10/08/analyzing-connection-scalability/\">analyzing the connection scalability</a> problem and <a target=\"_blank\" href=\"https://www.citusdata.com/blog/2020/10/25/improving-postgres-connection-scalability-snapshots/\">how it is addressed</a>.</p>\n<p>Even the idling connection may occupy server resources like memory. The <a target=\"_blank\" href=\"https://blog.anarazel.de/2020/10/07/measuring-the-memory-overhead-of-a-postgres-connection/\">overhead is considered as very low on a properly configured server</a>; however, the <a target=\"_blank\" href=\"https://aws.amazon.com/blogs/database/resources-consumed-by-idle-postgresql-connections/\">impact could be heavy</a> in reality. Again, a lot of things depend on the workload. There are at least a few cases that reported up to 50MB consumption per session. That means 500 idle connections can result in up to 25GB of memory usage.</p>\n<p>In addition to this, more connections can lead to more lock management-related overheads. And don&#8217;t forget that system becomes vulnerable to sudden spikes as the <span class=\"crayon-e\">max_connections</span> are increased.</p>\n<h2>Solution: Connection Queueing</h2>\n<p>At the very least, connection queueing is the queueing of connections so that they can absorb the sudden spike in load. The connections can be put into a queue rather than straight away rejecting or sending it to the server and jamming it. This results in streamlining the execution. PostgreSQL server can keep doing what it can do rather than dealing with a jam situation.</p>\n<p>Let me demonstrate with an example. For this demonstration, I set the <span class=\"crayon-e\">max_connections</span> to &#8220;2&#8221;, assuming that this is the maximum the server can accommodate without causing too many context switches. Too many connections won&#8217;t come and overload my database.</p><pre class=\"crayon-plain-tag\">postgres=# show max_connections ;\n2</pre><p>A third connection to the database will result in an error as expected.</p><pre class=\"crayon-plain-tag\">psql: error: FATAL: sorry, too many clients already</pre><p>Now let&#8217;s use the pgbouncer for the connection queue. Many of users may not be knowing that it exists, by default. I used the following pgbouncer configuration for testing:</p><pre class=\"crayon-plain-tag\">[databases]\npgbounce = host=172.16.2.16 port=5432 dbname=postgres\n\n[pgbouncer]\nlisten_port = 6432\nlisten_addr = *\nauth_type = md5\nauth_file = /etc/pgbouncer/userlist.txt\nlogfile = pgbouncer.log\npidfile = pgbouncer.pid\nadmin_users = postgres\napplication_name_add_host=1\ndefault_pool_size=1\nmin_pool_size=1</pre><p>Yes, the pooler will establish only one connection to the database. pgBouncer establishes this one connection when the client connection establishes for the first time because the min_pool_size is 1. The pgBouncer log says:</p><pre class=\"crayon-plain-tag\">2021-02-16 15:19:30.725 UTC [2152] LOG C-0x1fb0c58: pgbounce/postgres@172.16.2.56:54754 login attempt: db=pgbounce user=postgres tls=no\n2021-02-16 15:19:30.726 UTC [2152] LOG S-0x1fbba80: pgbounce/postgres@172.16.2.16:5432 new connection to server (from 172.16.2.144:58968)</pre><p>pgbouncer pool statistics also shows the details:</p><pre class=\"crayon-plain-tag\">pgbouncer=# show pools;\n database  |   user    | cl_active | cl_waiting | sv_active | sv_idle | sv_used | sv_tested | sv_login | maxwait | maxwait_us | pool_mode \n-----------+-----------+-----------+------------+-----------+---------+---------+-----------+----------+---------+------------+-----------\n pgbounce  | postgres  |         1 |          0 |         0 |       0 |       1 |         0 |        0 |       0 |          0 | session</pre><p>But the beauty is that we won&#8217;t get any more &#8220;FATAL: sorry, too many clients already&#8221; errors. All client connections are accepted and put into the connection queue. For example, I have five client connections. please see the value of cl_active:</p><pre class=\"crayon-plain-tag\">pgbouncer=# show pools;\n database  |   user    | cl_active | cl_waiting | sv_active | sv_idle | sv_used | sv_tested | sv_login | maxwait | maxwait_us | pool_mode \n-----------+-----------+-----------+------------+-----------+---------+---------+-----------+----------+---------+------------+-----------\n pgbounce  | postgres  |         5 |          0 |         0 |       0 |       1 |         0 |        0 |       0 |          0 | session</pre><p>As each client connection becomes active (with a SQL statement), they will be put into waiting.</p><pre class=\"crayon-plain-tag\">pgbouncer=# show pools;\n database  |   user    | cl_active | cl_waiting | sv_active | sv_idle | sv_used | sv_tested | sv_login | maxwait | maxwait_us | pool_mode \n-----------+-----------+-----------+------------+-----------+---------+---------+-----------+----------+---------+------------+-----------\n pgbounce  | postgres  |         1 |          4 |         1 |       0 |       0 |         0 |        0 |      28 |     438170 | session</pre><p>Each client connection will be executed over the available database connection, one after another. This is a case with a single database connection. If the connection count and pool size can be increased, multiple client connections can hit the server at the same time and queue size drops. The following is a case with two connections (pool size two) to the database.</p><pre class=\"crayon-plain-tag\">database  |   user    | cl_active | cl_waiting | sv_active | sv_idle | sv_used | sv_tested | sv_login | maxwait | maxwait_us | pool_mode \n-----------+-----------+-----------+------------+-----------+---------+---------+-----------+----------+---------+------------+-----------\n pgbounce  | postgres  |         2 |          1 |         2 |       0 |       0 |         0 |        0 |       4 |     978081 | session</pre><p></p>\n<h2>Putting Connection Queueing into a Simple Test</h2>\n<p>This is not an extensive benchmarking, but a quick test to see the benefits for a typical host with two virtual CPUs. I have created 20 active connections to PostgreSQL with select-only load using pgbench.</p><pre class=\"crayon-plain-tag\">pgbench -c 20 -j 20 -h pghost -U postgres -S -T 100</pre><p>As the 20 server processes started running, the load average went out of the roof.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74516 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1.png\" alt=\"\" width=\"594\" height=\"79\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1.png 594w, https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1-300x40.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1-200x27.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1-367x49.png 367w\" sizes=\"(max-width: 594px) 100vw, 594px\" /></p>\n<p>As you can see in the screenshot, the load average spiked to 17+. And as expected, the server response also becomes very poor consistently.</p><pre class=\"crayon-plain-tag\">time ssh -t postgres@pghost 'ls -l'\nreal 0m17.768s\nuser 0m0.019s\nsys 0m0.007s</pre><p>At this stage, I tried sending the same 20 active connections through the connection queue of pgbouncer with pool size four (default_pool_size=4). The pgbouncer is at the client-side.</p>\n<p>Since there are only four server-side processes, the load average dropped drastically. The maximum I could see is 1.73:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74513 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue.png\" alt=\"\" width=\"646\" height=\"81\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue.png 646w, https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue-300x38.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue-200x25.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue-367x46.png 367w\" sizes=\"(max-width: 646px) 100vw, 646px\" /></p>\n<p>The server response is also very good.</p><pre class=\"crayon-plain-tag\">$ time ssh -t postgres@pghost 'ls -l'\nreal 0m0.559s\nuser 0m0.021s\nsys 0m0.008s</pre><p><strong>A load average of 17+ vs 1.73!</strong> That must be too good to be true.</p>\n<p>There was a bit of skepticism about whether the low load on the server and the better server response is coming at the cost of database throughput.  I was expecting to see not-so-great throughput numbers. So I took the same test to a more consistently-performing platform (AWS r5.large with two virtual CPUs) again. To a bit of surprise, the numbers were even better.</p>\n<p>The following are the numbers I got. At least it is not bad; it&#8217;s better. <strong>5% better.</strong></p>\n<table style=\"width: auto;\" border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<th>Direct</th>\n<th>With Queueing</th>\n</tr>\n<tr>\n<td>20190.301781</td>\n<td>21663.454921</td>\n</tr>\n<tr>\n<td>20308.115945</td>\n<td>21646.195661</td>\n</tr>\n<tr>\n<td>20434.780692</td>\n<td>21218.44989</td>\n</tr>\n</tbody>\n</table>\n<p>Since we are using just four connections on the database side in this case, it also gives us the opportunity to reduce the max_connection value on the database side. Another check was whether switching to transaction-level pooling can save more because the database connection will be back to the pool and it could serve another client connection after each transaction. This could result in better concurrency.</p>\n<table style=\"width: auto;\" border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<th>Queue + max_ connection=5</th>\n<th>Queue + max_connection=5 + transaction level pool</th>\n</tr>\n<tr>\n<td>21897.685891</td>\n<td>23318.655016</td>\n</tr>\n<tr>\n<td>21913.841813</td>\n<td>23486.485856</td>\n</tr>\n<tr>\n<td>21933.129685</td>\n<td>23633.39607</td>\n</tr>\n</tbody>\n</table>\n<p>As expected, it delivered even better numbers. I would like to encourage readers to do more tests and proper benchmarking.</p>\n<h2>Summary and References</h2>\n<p>A really large number of application/client connections can be multiplexed over a very few database connections using the connection queueing. This queue helps in absorbing any spike in connections without overloading the database server. Instead of session processes queueing up on the OS scheduler/run queue, the connections can be kept outside safely and the database server can operate at full-throttle without any contentions. Streamlined database traffic results in better throughput also.</p>\n","descriptionType":"html","publishedDate":"Fri, 26 Feb 2021 16:32:22 +0000","feedId":11,"bgimg":"","linkMd5":"16d12f2d30b182a5a838c7da9d71dec1","bgimgJsdelivr":"","metaImg":"","author":"Jobin Augustine","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn16@2020_6/2021/04/03/04-49-19-081_ad3fad87d93973ae.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn32@2020_3/2021/04/03/04-49-19-473_394e0c1b68562174.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn44@2020_4/2021/04/03/04-49-05-486_2413c241661828dd.webp"},"publishedOrCreatedDate":1617425343809},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"What’s Running in My DB? A Journey with currentOp() in MongoDB","link":"https://www.percona.com/blog/?p=75112","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"currentOp() in MongoDB\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-75129\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-300x157.png\" alt=\"currentOp() in MongoDB\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />I have been working a while with customers, supporting both </span>MongoDB and MySQL<span> technologies. Most of the time when an issue arises, the customers working with MySQL collect most of the information happening in the DB server, including all the queries running that particular time, using “<em>show full processlist;</em>” This information would help us to look at the problem, like which queries are taking the time and where it was spending the time. </span></p>\n<p><span>But for </span>MongoDB<span>, most of the time we don&#8217;t receive this (in-progress operations) information. And we had to check with long queries logged into the MongoDB log file and, of course, it writes most of the things like <em>planSummary</em> (whether it used the <em>index</em> or not), <em>documents</em>/<em>index</em> scanned, time to complete, etc. It&#8217;s like doing a postmortem rather than checking the issue happening in real-time. Actually collecting the information about operations taking the time or finding a problematic query while the issue is happening could help you find the right one to kill (to release the pressure) or check the situation of the database. </span></p>\n<p><span>The in-progress operations in MongoDB can be checked via the database command </span><strong><em><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/command/currentOp/#dbcmd.currentOp\">currentOp()</a></em></strong><span>. The level of information can be controlled via the options passed through it. Most of the time, the output from it is not that interesting to check because it contains a lot of information, making it difficult to spot the ones we need. However, MongoDB knows this and has included many options to filter the operations using </span><i><span>currentOp</span></i><span> over multiple versions easily. Some of the information regarding this is mentioned in the below release notes:</span></p>\n<p><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/release-notes/3.6/#new-aggregation-stages\"><span>https://docs.mongodb.com/manual/release-notes/3.6/#new-aggregation-stages</span></a><span> </span></p>\n<p><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/release-notes/4.0/#id26\"><span>https://docs.mongodb.com/manual/release-notes/4.0/#id26</span></a></p>\n<p><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/release-notes/4.2/#currentop\"><span>https://docs.mongodb.com/manual/release-notes/4.2/#currentop</span></a><span> </span></p>\n<p><span>In this blog, I will share some tricks to work with this command and fetch the operations that we need to check. This would help a person check the ongoing operations and if necessary, kill the problematic command &#8211; if they wish.</span></p>\n<h2>Introduction</h2>\n<p><span>The database command </span><strong><i>`</i></strong><span> provides information about the ongoing/currently running operations in the database. It must be run against the </span><b><i>admin</i></b><span> database. On servers that run with authorization, you need the </span><b><i>inprog</i></b><span> privilege action to view operations for all users. This is included in the built-in </span><b><i>clusterMonitor</i></b><span> role.</span></p>\n<h2>Use Cases</h2>\n<p><span>The command to see all the active connections:</span></p><pre class=\"crayon-plain-tag\">db.currentOp()</pre><p><span>The user that has no </span><i><span>inprog</span></i><span> privilege can view its own operations, without this privilege, with the below command:</span></p><pre class=\"crayon-plain-tag\">db.currentOp( { \"$ownOps\": true } )</pre><p><span>To see the connections in the background, and idle connections, you can use either one of the below commands:</span></p><pre class=\"crayon-plain-tag\">db.currentOp(true)\ndb.currentOp( { \"$all\": true } )</pre><p><span>As I said before, you can use filters here to check the operations you need, like a command running for more than a few seconds, waiting for a <em>lock</em>, <em>active</em>/<em>inactive</em> connections, running on a particular <em>namespace,</em> etc. Let&#8217;s see some examples from my test environment.</span></p>\n<p><span>The below command provides information about all active connections. </span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.currentOp()\n{\n\t\"inprog\" : [\n\t\t{\n\t\t\t\"shard\" : \"shard01\",\n\t\t\t\"host\" : \"bm-support01.bm.int.percona.com:54012\",\n\t\t\t\"desc\" : \"conn52\",\n\t\t\t\"connectionId\" : 52,\n\t\t\t\"client_s\" : \"127.0.0.1:53338\",\n\t\t\t\"appName\" : \"MongoDB Shell\",\n\t\t\t\"clientMetadata\" : {\n\t\t\t\t\"application\" : {\n\t\t\t\t\t\"name\" : \"MongoDB Shell\"\n\t\t\t\t},\n\t\t\t\t\"driver\" : {\n\t\t\t\t\t\"name\" : \"MongoDB Internal Client\",\n\t\t\t\t\t\"version\" : \"4.0.19-12\"\n\t\t\t\t},\n\t\t\t\t\"os\" : {\n\t\t\t\t\t\"type\" : \"Linux\",\n\t\t\t\t\t\"name\" : \"CentOS Linux release 7.9.2009 (Core)\",\n\t\t\t\t\t\"architecture\" : \"x86_64\",\n\t\t\t\t\t\"version\" : \"Kernel 5.10.13-1.el7.elrepo.x86_64\"\n\t\t\t\t},\n\t\t\t\t\"mongos\" : {\n\t\t\t\t\t\"host\" : \"bm-support01.bm.int.percona.com:54010\",\n\t\t\t\t\t\"client\" : \"127.0.0.1:36018\",\n\t\t\t\t\t\"version\" : \"4.0.19-12\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"active\" : true,\n\t\t\t\"currentOpTime\" : \"2021-03-21T23:41:48.206-0400\",\n\t\t\t\"opid\" : \"shard01:1404\",\n\t\t\t\"lsid\" : {\n\t\t\t\t\"id\" : UUID(\"6bd7549b-0c89-40b5-b59f-af765199bbcf\"),\n\t\t\t\t\"uid\" : BinData(0,\"47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\")\n\t\t\t},\n\t\t\t\"secs_running\" : NumberLong(0),\n\t\t\t\"microsecs_running\" : NumberLong(180),\n\t\t\t\"op\" : \"getmore\",\n\t\t\t\"ns\" : \"admin.$cmd\",\n\t\t\t\"command\" : {\n\t\t\t\t\"getMore\" : NumberLong(\"8620961729688473960\"),\n\t\t\t\t\"collection\" : \"$cmd.aggregate\",\n\t\t\t\t\"batchSize\" : NumberLong(101),\n\t\t\t\t\"lsid\" : {\n\t\t\t\t\t\"id\" : UUID(\"6bd7549b-0c89-40b5-b59f-af765199bbcf\"),\n\t\t\t\t\t\"uid\" : BinData(0,\"47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\")\n\t\t\t\t},\n\t\t\t\t\"$clusterTime\" : {\n\t\t\t\t\t\"clusterTime\" : Timestamp(1616384506, 2),\n\t\t\t\t\t\"signature\" : {\n\t\t\t\t\t\t\"hash\" : BinData(0,\"z/r5Z/DxrxaeH1VIKOzeok06YxY=\"),\n\t\t\t\t\t\t\"keyId\" : NumberLong(\"6942317981145759774\")\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"$client\" : {\n\t\t\t\t\t\"application\" : {\n\t\t\t\t\t\t\"name\" : \"MongoDB Shell\"\n\t\t\t\t\t},\n\t\t\t\t\t\"driver\" : {\n\t\t\t\t\t\t\"name\" : \"MongoDB Internal Client\",\n\t\t\t\t\t\t\"version\" : \"4.0.19-12\"\n\t\t\t\t\t},\n\t\t\t\t\t\"os\" : {\n\t\t\t\t\t\t\"type\" : \"Linux\",\n\t\t\t\t\t\t\"name\" : \"CentOS Linux release 7.9.2009 (Core)\",\n\t\t\t\t\t\t\"architecture\" : \"x86_64\",\n\t\t\t\t\t\t\"version\" : \"Kernel 5.10.13-1.el7.elrepo.x86_64\"\n\t\t\t\t\t},\n\t\t\t\t\t\"mongos\" : {\n\t\t\t\t\t\t\"host\" : \"bm-support01.bm.int.percona.com:54010\",\n\t\t\t\t\t\t\"client\" : \"127.0.0.1:36018\",\n\t\t\t\t\t\t\"version\" : \"4.0.19-12\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"$configServerState\" : {\n\t\t\t\t\t\"opTime\" : {\n\t\t\t\t\t\t\"ts\" : Timestamp(1616384506, 2),\n\t\t\t\t\t\t\"t\" : NumberLong(1)\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"$db\" : \"admin\"\n\t\t\t},\n\t\t\t\"originatingCommand\" : {\n\t\t\t\t\"aggregate\" : 1,\n\t\t\t\t\"pipeline\" : [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"$currentOp\" : {\n\t\t\t\t\t\t\t\"allUsers\" : true,\n\t\t\t\t\t\t\t\"truncateOps\" : true\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"$sort\" : {\n\t\t\t\t\t\t\t\"shard\" : 1\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"fromMongos\" : true,\n\t\t\t\t\"needsMerge\" : true,\n\t\t\t\t\"mergeByPBRT\" : false,\n\t\t\t\t\"cursor\" : {\n\t\t\t\t\t\"batchSize\" : 0\n\t\t\t\t},\n\t\t\t\t\"allowImplicitCollectionCreation\" : true,\n\t\t\t\t\"lsid\" : {\n\t\t\t\t\t\"id\" : UUID(\"6bd7549b-0c89-40b5-b59f-af765199bbcf\"),\n\t\t\t\t\t\"uid\" : BinData(0,\"47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\")\n\t\t\t\t},\n\t\t\t\t\"$clusterTime\" : {\n\t\t\t\t\t\"clusterTime\" : Timestamp(1616384506, 2),\n\t\t\t\t\t\"signature\" : {\n\t\t\t\t\t\t\"hash\" : BinData(0,\"z/r5Z/DxrxaeH1VIKOzeok06YxY=\"),\n\t\t\t\t\t\t\"keyId\" : NumberLong(\"6942317981145759774\")\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"$client\" : {\n\t\t\t\t\t\"application\" : {\n\t\t\t\t\t\t\"name\" : \"MongoDB Shell\"\n\t\t\t\t\t},\n\t\t\t\t\t\"driver\" : {\n\t\t\t\t\t\t\"name\" : \"MongoDB Internal Client\",\n\t\t\t\t\t\t\"version\" : \"4.0.19-12\"\n\t\t\t\t\t},\n\t\t\t\t\t\"os\" : {\n\t\t\t\t\t\t\"type\" : \"Linux\",\n\t\t\t\t\t\t\"name\" : \"CentOS Linux release 7.9.2009 (Core)\",\n\t\t\t\t\t\t\"architecture\" : \"x86_64\",\n\t\t\t\t\t\t\"version\" : \"Kernel 5.10.13-1.el7.elrepo.x86_64\"\n\t\t\t\t\t},\n\t\t\t\t\t\"mongos\" : {\n\t\t\t\t\t\t\"host\" : \"bm-support01.bm.int.percona.com:54010\",\n\t\t\t\t\t\t\"client\" : \"127.0.0.1:36018\",\n\t\t\t\t\t\t\"version\" : \"4.0.19-12\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"$configServerState\" : {\n\t\t\t\t\t\"opTime\" : {\n\t\t\t\t\t\t\"ts\" : Timestamp(1616384506, 2),\n\t\t\t\t\t\t\"t\" : NumberLong(1)\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"$db\" : \"admin\"\n\t\t\t},\n\t\t\t\"numYields\" : 0,\n\t\t\t\"locks\" : {\n\t\t\t\t\n\t\t\t},\n\t\t\t\"waitingForLock\" : false,\n\t\t\t\"lockStats\" : {\n\t\t\t\t\n\t\t\t}\n\t\t},\n\t\t{\n\t\t\t\"shard\" : \"shard01\",\n\t\t\t\"host\" : \"bm-support01.bm.int.percona.com:54012\",\n\t\t\t\"desc\" : \"monitoring keys for HMAC\",\n…\n...</pre><p><span>Some of the important parameters that we may need to focus on from the output are as follows. I provide this information here as we will use these parameters to filter for the operations that we need.</span></p>\n<table style=\"height: 1104px;\" width=\"779\">\n<tbody>\n<tr>\n<td><b>PARAMETER</b></td>\n<td><b>DESCRIPTION</b></td>\n</tr>\n<tr>\n<td><b><i>host</i></b></td>\n<td><span>The host that the operation is running</span></td>\n</tr>\n<tr>\n<td><b><i>opid</i></b></td>\n<td><span>The operation id (it is used to kill that operation) </span></td>\n</tr>\n<tr>\n<td><b><i>active</i></b></td>\n<td><span>The connection’s status. True if it is running and false if it is idle</span></td>\n</tr>\n<tr>\n<td><b><i>client</i></b></td>\n<td><span>Host/IP information about where the operation originated</span></td>\n</tr>\n<tr>\n<td><b><i>clientMetadata</i></b></td>\n<td><span>Provides more information about client connection</span></td>\n</tr>\n<tr>\n<td><b><i>shard</i></b></td>\n<td><span>Which shard is connected if it is sharded cluster environment</span></td>\n</tr>\n<tr>\n<td><b><i>appName</i></b></td>\n<td><span>Information about the type of client</span></td>\n</tr>\n<tr>\n<td><b><i>currentOpTime</i></b></td>\n<td><span>Start time of the operation</span></td>\n</tr>\n<tr>\n<td><b><i>ns</i></b></td>\n<td><span>Namespace (details about the DB and collection)</span></td>\n</tr>\n<tr>\n<td><b><i>command</i></b></td>\n<td><span>A document with the full command object associated with the operation</span></td>\n</tr>\n<tr>\n<td><b><i>secs_running / microsecs_running</i></b></td>\n<td><span>How many <em>seconds/microseconds</em> that the particular operation is running</span></td>\n</tr>\n<tr>\n<td><b><i>op</i></b></td>\n<td><span>Operation type like </span><i><span>insert</span></i><span>, </span><i><span>update</span></i><span>, </span><i><span>find</span></i><span>, </span><i><span>delete</span></i><span> etc</span></td>\n</tr>\n<tr>\n<td><b><i>planSummary</i></b></td>\n<td><span>Whether the command uses the index IXSCAN or collection scan COLLSCAN (disk read)</span></td>\n</tr>\n<tr>\n<td><b><i>cursor</i></b></td>\n<td><span>Cursor information for </span><i><span>getmore</span></i><span> operations</span></td>\n</tr>\n<tr>\n<td><b><i>locks</i></b></td>\n<td><span>Type and mode of the lock. </span><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/command/currentOp/#currentOp.locks\"><span>See here</span></a><span> for more details</span></td>\n</tr>\n<tr>\n<td><b><i>waitingForLock</i></b></td>\n<td><span>True if the operation waiting for a lock, false if it has required lock</span></td>\n</tr>\n<tr>\n<td><b><i>msg</i></b></td>\n<td><span>A message that describes the status and progress of the operation</span></td>\n</tr>\n<tr>\n<td><b><i>killPending</i></b></td>\n<td><span>Whether the operation is currently flagged for termination</span></td>\n</tr>\n<tr>\n<td><b><i>numYields</i></b></td>\n<td><span>Is a counter that reports the number of times the operation has yielded to allow other operation</span></td>\n</tr>\n</tbody>\n</table>\n<p><span>The raw </span><b><i>currentOp</i></b><span> output can be processed by the javascript </span><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/method/cursor.forEach/\"><i><span>forEach</span></i></a><span> function method in the mongo shell, so we can use it to do many operations. For example, I want to take counts of the output or number of active connections. Then I can use the below one:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; var c=1;\nmongos&#62; db.currentOp().inprog.forEach(\n... function(doc){\n...   c=c+1\n... }\n... )\nmongos&#62; print(\"The total number of active connections are: \"+c)\nThe total number of active connections are: 16</pre><p><span>To find the number of active and inactive connections:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; var active=1; var inactive=1;\nmongos&#62; db.currentOp(true).inprog.forEach( function(doc){  if(doc.active){    active=active+1 }  else if(!doc.active){    inactive=inactive+1 }  } )\nmongos&#62; print(\"The number of active connections are: \"+active+\"\\nThe number of inactive connections are: \"+inactive)\nThe number of active connections are: 16\nThe number of inactive connections are: 118</pre><p><span>To find the operations running (importing job) more than 1000 microseconds (for seconds, use <em>secs_running</em>) and with a specific <em>namespace</em> <strong><em>vinodh.testColl</em></strong>:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.currentOp(true).inprog.forEach( function(doc){ if(doc.microsecs_running&#62;1000 &#38;&#38; doc.ns == \"vinodh.testColl\")  {print(\"\\nop: \"+doc.op+\", namespace: \"+doc.ns+\", \\ncommand: \");printjson(doc.command)} } )\n\nop: insert, namespace: vinodh.testColl, \ncommand: \n{\n  \"$truncated\" : \"{ insert: \\\"testColl\\\", bypassDocumentValidation: false, ordered: false, documents: [ { _id: ObjectId('605a1ab05c15f7d2046d5d26'), id: 49004, name: \\\"Vernon Drake\\\", age: 19, emails: [ \\\"fetome@liek.gh\\\", \\\"noddo@ve.kh\\\", \\\"wunin@cu.ci\\\" ], born_in: \\\"1973\\\", ip_addresses: [ \\\"212.199.110.72\\\" ], blob: BinData(0, 4736735553674F6E6825) }, { _id: ObjectId('605a1ab05c15f7d2046d5d27'), id: 49003, name: \\\"Rhoda Burke\\\", age: 64, emails: [ \\\"zog@borvelaj.pa\\\", \\\"hoz@ni.do\\\", \\\"abfad@borup.cl\\\" ], born_in: \\\"1976\\\", ip_addresses: [ \\\"12.190.161.2\\\", \\\"16.63.87.211\\\" ], blob: BinData(0, 244C586A683244744F54) }, { _id: ObjectId('605a1ab05c15f7d2046d5d28'), id: 49002, name: \\\"Alberta Mack\\\", age: 25, emails: [ \\\"sibef@nuvaki.sn\\\", \\\"erusu@dimpu.ag\\\", \\\"miumurup@se.ir\\\" ], born_in: \\\"1971\\\", ip_addresses: [ \\\"250.239.181.203\\\", \\\"192.240.119.122\\\", \\\"196.13.33.240\\\" ], blob: BinData(0, 7A63566B42732659236D) }, { _id: ObjectId('605a1ab05c15f7d2046d5d29'), id: 49005, name: \\\"Minnie Chapman\\\", age: 33, emails: [ \\\"jirgenor@esevepu.edu\\\", \\\"jo@m...\"\n}</pre><p><span>But this command can be easily written without <em><strong>forEach</strong></em> as follows directly as well:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.currentOp({ \"active\": true, \"microsecs_running\": {$gt: 1000}, \"ns\": /^vinodh.testColl/ })\n{\n  \"inprog\" : [\n    {\n      \"shard\" : \"shard01\",\n      \"host\" : \"bm-support01.bm.int.percona.com:54012\",\n      \"desc\" : \"conn268\",\n      \"connectionId\" : 268,\n      \"client_s\" : \"127.0.0.1:55480\",\n      \"active\" : true,\n      \"currentOpTime\" : \"2021-03-23T13:05:32.550-0400\",\n      \"opid\" : \"shard01:689582\",\n      \"secs_running\" : NumberLong(0),\n      \"microsecs_running\" : NumberLong(44996),\n      \"op\" : \"insert\",\n      \"ns\" : \"vinodh.testColl\",\n      \"command\" : {\n        \"$truncated\" : \"{ insert: \\\"testColl\\\", bypassDocumentValidation: false, ordered: false, documents: [ { _id: ObjectId('605a1fdc5c15f7d2047ee04e'), id: 16002, name: \\\"Linnie Walsh\\\", age: 25, emails: [ \\\"evoludecu@logejvi.ai\\\", \\\"ilahubfep@ud.mc\\\", \\\"siujo@pipazvo.ht\\\" ], born_in: \\\"1982\\\", ip_addresses: [ \\\"198.117.218.117\\\" ], blob: BinData(0, 244A6E702A5047405149) }, { _id: ObjectId('605a1fdc5c15f7d2047ee04f'), id: 16004, name: \\\"Larry Watts\\\", age: 47, emails: [ \\\"sa@hulub.gy\\\", \\\"wepo@ruvnuhej.om\\\", \\\"jorvohki@nobajmo.hr\\\" ], born_in: \\\"1989\\\", ip_addresses: [], blob: BinData(0, 50507461366B6F766C40) }, { _id: ObjectId('605a1fdc5c15f7d2047ee050'), id: 16003, name: \\\"Alejandro Jacobs\\\", age: 61, emails: [ \\\"enijaze@hihen.et\\\", \\\"gekesaco@kockod.fk\\\", \\\"rohovus@il.az\\\" ], born_in: \\\"1988\\\", ip_addresses: [ \\\"239.139.123.44\\\", \\\"168.34.26.236\\\", \\\"123.230.33.251\\\", \\\"132.222.43.251\\\" ], blob: BinData(0, 32213574705938385077) }, { _id: ObjectId('605a1fdc5c15f7d2047ee051'), id: 16005, name: \\\"Mildred French\\\", age: 20, emails: [ \\\"totfi@su.mn\\\"...\"\n      },\n      \"numYields\" : 0,\n      \"locks\" : {\n        \n      },\n      \"waitingForLock\" : false,\n      \"lockStats\" : {\n        \"Global\" : {\n          \"acquireCount\" : {\n            \"r\" : NumberLong(16),\n            \"w\" : NumberLong(16)\n          }\n        },\n        \"Database\" : {\n          \"acquireCount\" : {\n            \"w\" : NumberLong(16)\n          }\n…</pre><p><span>The operations waiting for the <em>lock</em> on a specific <em>namespace</em> (</span><i><span>ns</span></i><span>) / operation (</span><i><span>op</span></i><span>) can be filtered as follows, and you can alter the parameters to filter as you wish:</span></p><pre class=\"crayon-plain-tag\">db.currentOp(\n   {\n     \"waitingForLock\" : true,\n    \"ns\": /^vinodh.testColl/,\n     $or: [\n        { \"op\" : { \"$in\" : [ \"insert\", \"update\", \"remove\" ] } },\n        { \"command.findandmodify\": { $exists: true } }\n    ]\n   }\n)</pre><p></p>\n<h2>Aggregate &#8211; currentOp():</h2>\n<p><span>Starting with </span><span>MongoDB 3.6</span><span>, </span><i><span>currentOp</span></i><span> method is supported in aggregation. So checking the <em>currentOp</em> is even easier with this method. Also, the aggregation pipeline doesn&#8217;t have a 16MB result size limit as well. The usage is:</span></p><pre class=\"crayon-plain-tag\"><span style=\"font-weight: 400;\">{ $currentOp: { allUsers: &#60;boolean&#62;, idleConnections: &#60;boolean&#62;, idleCursors: &#60;boolean&#62;, idleSessions: &#60;boolean&#62;, localOps: &#60;boolean&#62; } }</span></pre><p></p>\n<h3><span>Note:</span></h3>\n<p>Options/Features added, version-wise, to <em>currentOp()</em></p>\n<ul>\n<li><span><em>allUsers</em>, <em>idleConnections</em> &#8211; available from 3.6,</span></li>\n<li><span><em>idleCursors</em> &#8211; available from 4.2</span></li>\n<li><span><em>idleSessions</em>, <em>localOps</em> &#8211; available from 4.0</span></li>\n</ul>\n<p><span>Let&#8217;s see an example of the same. Count all connections including <em>idle</em> connections with <em>shard02</em>:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.aggregate( [ { $currentOp : { allUsers: true, idleConnections: true } },    \n... { $match : { shard: \"shard02\" }}, {$group: {_id:\"shard02\", count: {$sum: 1}} } ] )\n{ \"_id\" : \"shard02\", \"count\" : 65 }</pre><p><span>Now using the same import job, finding the operation as follows:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.aggregate( [    { $currentOp : { allUsers: true, idleConnections: false } },    \n... { $match : { \"ns\": \"vinodh.testColl\" }} ] )\n{ \"shard\" : \"shard01\", \"host\" : \"bm-support01.bm.int.percona.com:54012\", \"desc\" : \"conn279\", \"connectionId\" : 279, \"client_s\" : \"127.0.0.1:38564\", \"active\" : true, \"currentOpTime\" : \"2021-03-23T13:33:57.225-0400\", \"opid\" : \"shard01:722388\", \"secs_running\" : NumberLong(0), \"microsecs_running\" : NumberLong(24668), \"op\" : \"insert\", \"ns\" : \"vinodh.testColl\", \"command\" : { \"insert\" : \"testColl\", \"bypassDocumentValidation\" : false, \"ordered\" : false, \"documents\" : [ { \"_id\" : ObjectId(\"605a26855c15f7d20484d217\"), \"id\" : 12020, \"name\" : \"Dora Watson\",....tId(\"000000000000000000000000\") ], \"writeConcern\" : { \"getLastError\" : 1, \"w\" : \"majority\" }, \"allowImplicitCollectionCreation\" : false, \"$clusterTime\" : { \"clusterTime\" : Timestamp(1616520837, 1000), \"signature\" : { \"hash\" : BinData(0,\"yze8dSs12MUKlnb7rpw5h2YblFI=\"), \"keyId\" : NumberLong(\"6942317981145759774\") } }, \"$configServerState\" : { \"opTime\" : { \"ts\" : Timestamp(1616520835, 10), \"t\" : NumberLong(2) } }, \"$db\" : \"vinodh\" }, \"numYields\" : 0, \"locks\" : { \"Global\" : \"w\", \"Database\" : \"w\", \"Collection\" : \"w\" }, \"waitingForLock\" : false, \"lockStats\" : { \"Global\" : { \"acquireCount\" : { \"r\" : NumberLong(8), \"w\" : NumberLong(8) } }, \"Database\" : { \"acquireCount\" : { \"w\" : NumberLong(8) } }, \"Collection\" : { \"acquireCount\" : { \"w\" : NumberLong(8) } } } }</pre><p><span>To reduce the output and project only some fields in the output:</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.aggregate( [    \n... { $currentOp : { allUsers: true, idleConnections: false } },    \n... { $match : { ns: \"vinodh.testColl\", microsecs_running: {$gt: 10000} }}, \n... {$project: { _id:0, host:1, opid:1, secs_running: 1, op:1, ns:1, waitingForLock: 1, numYields: 1  } } ] )\n{ \"host\" : \"bm-support01.bm.int.percona.com:54012\", \"opid\" : \"shard01:777387\", \"secs_running\" : NumberLong(0), \"op\" : \"insert\", \"ns\" : \"vinodh.testColl\", \"numYields\" : 0, \"waitingForLock\" : false }</pre><p><span>To see the output in fantasy mode, used to be pretty 🙂</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.aggregate( [    { $currentOp : { allUsers: true, idleConnections: false } },    { $match : { ns: \"vinodh.testColl\", microsecs_running: {$gt: 10000} }}, {$project: { _id:0, host:1, opid:1, secs_running: 1, op:1, ns:1, waitingForLock: 1, numYields: 1  } } ] ).pretty()\n{\n\t\"host\" : \"bm-support01.bm.int.percona.com:54012\",\n\t\"opid\" : \"shard01:801285\",\n\t\"secs_running\" : NumberLong(0),\n\t\"op\" : \"insert\",\n\t\"ns\" : \"vinodh.testColl\",\n\t\"numYields\" : 0,\n\t\"waitingForLock\" : false\n}</pre><p><span>I hope now you will have some idea on using <em>currentOp</em>() to check the ongoing operations. </span></p>\n<p><span>Let’s imagine you want to kill an operation running for a long time. From the same currentOp document you identified it with, you can take the <i>opid</i> and kill it using <strong><em>killOp()</em></strong> method. In the example below, I used the sharded environment and so the <i>opid</i> is in a “<i>shard_no:opid</i>” format. See <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/method/db.killOp/#kill-write-ops-sharded-cluster\">here</a> for more details.</span></p><pre class=\"crayon-plain-tag\">mongos&#62; db.aggregate( [    { $currentOp : { allUsers: true, idleConnections: false } },    { $match : { ns: \"vinodh.testColl\" }}, {$project: { _id:0, host:1, opid:1, microsecs_running: 1, op:1, ns:1, waitingForLock: 1, numYields: 1  } } ] ).pretty()\n{\n\t\"host\" : \"bm-support01.bm.int.percona.com:54012\",\n\t\"opid\" : \"shard01:1355440\",\n\t\"microsecs_running\" : NumberLong(39200),\n\t\"op\" : \"insert\",\n\t\"ns\" : \"vinodh.testColl\",\n\t\"numYields\" : 0,\n\t\"waitingForLock\" : false\n}\n\n\nmongos&#62; db.killOp(\"shard01:1355440\")\n{\n\t\"shard\" : \"shard01\",\n\t\"shardid\" : 1355440,\n\t\"ok\" : 1,\n\t\"operationTime\" : Timestamp(1616525284, 1),\n\t\"$clusterTime\" : {\n\t\t\"clusterTime\" : Timestamp(1616525284, 1),\n\t\t\"signature\" : {\n\t\t\t\"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n\t\t\t\"keyId\" : NumberLong(0)\n\t\t}\n\t}\n}</pre><p></p>\n<h3>Conclusion</h3>\n<p><span>So the next time when you want to check the ongoing operations, you can use these techniques for filtering operations waiting for a lock, running on a namespace, running more than a specified time, specific operation or specific shard, etc. Also, comment here if you have any other ideas on this topic. I am happy to learn/see that as well.</span></p>\n<hr />\n<p style=\"text-align: center;\"><span data-sheets-value=\"{&#34;1&#34;:2,&#34;2&#34;:&#34;Percona Distribution for MongoDB is the only truly open-source solution powerful enough for enterprise applications. It's free to use, to try it today!&#34;}\" data-sheets-userformat=\"{&#34;2&#34;:769,&#34;3&#34;:{&#34;1&#34;:0},&#34;11&#34;:4,&#34;12&#34;:0}\"><strong>Percona Distribution for MongoDB</strong> is the only truly open-source solution powerful enough for enterprise applications. </span></p>\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb?utm_source=blog\"><span data-sheets-value=\"{&#34;1&#34;:2,&#34;2&#34;:&#34;Percona Distribution for MongoDB is the only truly open-source solution powerful enough for enterprise applications. It's free to use, to try it today!&#34;}\" data-sheets-userformat=\"{&#34;2&#34;:769,&#34;3&#34;:{&#34;1&#34;:0},&#34;11&#34;:4,&#34;12&#34;:0}\">It&#8217;s free to use, so try it today!</span></a></p>\n","descriptionType":"html","publishedDate":"Tue, 30 Mar 2021 13:07:38 +0000","feedId":11,"bgimg":"","linkMd5":"79242dc8db88dc141a2475cd5600e267","bgimgJsdelivr":"","metaImg":"","author":"Vinodh Krishnaswamy","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn40@2020_3/2021/04/03/04-49-20-585_322dd71a30133830.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn28@2020_4/2021/04/03/04-49-22-154_925bcb3e2e426bdd.webp"},"publishedOrCreatedDate":1617425343848},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Overview of MySQL Alternative Storage Engines","link":"https://www.percona.com/blog/?p=75057","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MySQL Alternative Storage Engines\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-75106\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-300x157.png\" alt=\"MySQL Alternative Storage Engines\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />For MySQL, MyISAM and InnoDB storage engines are very popular. Currently, we are mostly using InnoDB engines for high reliability and high performance. Apart from those engines, we also have some other alternative engines and they have some nice features in them. In this blog, I am going to explain some of those engines, which I have listed below. </span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\">FEDERATED Storage Engine</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Merge or MRG_MyISAM Engine</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Blackhole Engine</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>CSV Engine</span></li>\n</ul>\n<h2>FEDERATED Storage Engine</h2>\n<h3>Overview:</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>FEDERATED Storage Engine allows you to access the data remotely without replication and cluster technologies. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Using the FEDERATED tables, you can scale your server load. Queries for the given table will be sent over the network to another MySQL instance. In this case, to scale the DB, you can use many MySQL instances without changing the application code.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>FEDERATED tables are a security concern because you will need to save the host and user information in the table. It can be viewed using SHOW CREATE TABLE command.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Query optimization is limited and JOINs are slow.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Doing the bulk transaction may crash the local server.</span></li>\n</ul>\n<p><span>By default, FEDERATED Storage Engine support is disabled. To enable it, you need to manually enable the variable “federated = ON” in the MySQL config file and restart the MySQL service. </span></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from information_schema.engines where engine='federated'\\G\n*************************** 1. row ***************************\n      ENGINE: FEDERATED\n     SUPPORT: NO\n     COMMENT: Federated MySQL storage engine\nTRANSACTIONS: NULL\n          XA: NULL\n  SAVEPOINTS: NULL\n1 row in set (0.00 sec)\n\n#vi /etc/my.cnf \n[mysqld]\nfederated = ON\n\n[root@mass ~]# service mysqld restart\nRedirecting to /bin/systemctl restart mysqld.service\n[root@mass ~]#\n\nmysql&#62; select * from information_schema.engines where engine='federated'\\G\n*************************** 1. row ***************************\n      ENGINE: FEDERATED\n     SUPPORT: YES\n     COMMENT: Federated MySQL storage engine\nTRANSACTIONS: NO\n          XA: NO\n  SAVEPOINTS: NO\n1 row in set (0.00 sec)</pre><p></p>\n<h3>How Does it work?</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>FEDERATED tables need to be created on a local server and the remote table needs to be created on a remote server.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Make sure that you have the MySQL port and user access between the local and remote servers.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Remote tables can be created as MyISAM or InnoDB storage engines.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The FEDERATED table will not store any data. Data will be stored on the remote server.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Both local and remote servers should have the same columns and structure.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You can execute the query on both local or remote servers to modify or retrieve the data.</span></li>\n</ul>\n<h4><b>Example</b></h4>\n<p><span>I have two servers:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>172.28.128.16 (local server)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>172.28.128.17 (remote server)</span></li>\n</ul>\n<p><span>On the local server, I am creating the FEDERATED table:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table fed_source(id int, name varchar(16)) engine=federated connection=\"mysql://fed:Fede4!i&#38;1@172.28.128.17/percona/fed_destination\";\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql&#62; show create table fed_source\\G\n*************************** 1. row ***************************\n       Table: fed_source\nCreate Table: CREATE TABLE `fed_source` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(16) DEFAULT NULL\n) ENGINE=FEDERATED DEFAULT CHARSET=latin1 CONNECTION='mysql://fed:Fede4!i&#38;1@172.28.128.17/percona/fed_destination'\n1 row in set (0.00 sec)</pre><p><span>Syntax is:</span></p><pre class=\"crayon-plain-tag\"> “connection=mysql://&#60;user&#62;:&#60;password&#62;@&#60;remote_host_ip&#62;/&#60;remote_database&#62;/&#60;remote_table&#62;”</pre><p><span>On the remote server, I am creating the table with InnoDB engine:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table fed_destination(id int, name varchar(16));\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; show create table fed_destination\\G\n*************************** 1. row ***************************\n       Table: fed_destination\nCreate Table: CREATE TABLE `fed_destination` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(16) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n1 row in set (0.00 sec)</pre><p><span>As I mentioned earlier, the data will be physically stored on the remote server. FEDERATED tables will not store the data. From the below example, you can see the data file (.ibd) was created on the remote server and the local server just has the table structure file ( .frm ).</span></p>\n<p><span>Local server:</span></p><pre class=\"crayon-plain-tag\">[root@mass percona]# pwd\n/var/lib/mysql/percona\n[root@mass percona]# ls -lrth\ntotal 16K\n-rw-r-----. 1 mysql mysql 8.4K Mar 19 18:00 fed_source.frm</pre><p><span>Remote server:</span></p><pre class=\"crayon-plain-tag\">root@repl percona]# pwd\n/var/lib/mysql/percona\n[root@repl percona]# ls -lrth\ntotal 112K\n-rw-r-----. 1 mysql mysql 8.4K Mar 19 18:00 fed_destination.frm\n-rw-r-----. 1 mysql mysql  96K Mar 19 18:01 fed_destination.ibd</pre><p><span>Let&#8217;s do this experiment. On the local server, I am inserting the record. </span></p><pre class=\"crayon-plain-tag\">mysql&#62; insert into fed_source values (1,'herc');\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&#62; select * from fed_source;\n+------+------+\n| id   | name |\n+------+------+\n|    1 | herc |\n+------+------+\n1 row in set (0.00 sec)</pre><p><span>And on the remote server:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from fed_destination;\n+------+------+\n| id   | name |\n+------+------+\n|    1 | herc |\n+------+------+\n1 row in set (0.00 sec)</pre><p><span>Now, I am going to update the data on a remote server.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; update fed_destination set name='hercules7sakthi' where name='herc';\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql&#62; select * from fed_destination;\n+------+-----------------+\n| id   | name            |\n+------+-----------------+\n|    1 | hercules7sakthi |\n+------+-----------------+\n1 row in set (0.00 sec)</pre><p><span>At the local server:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from fed_source;\n+------+-----------------+\n| id   | name            |\n+------+-----------------+\n|    1 | hercules7sakthi |\n+------+-----------------+\n1 row in set (0.00 sec)</pre><p><span>It seems that you can execute the query on both local and remote servers. The FEDERATED Engine is mostly supported for data manipulation languages (INSERT/UPDATE/DELETE/TRUNCATE).</span></p>\n<h2>Merge or MRG_MyISAM Engine</h2>\n<h3>Overview:</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The collection of identical MyISAM tables can be used as a single table for better performance.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Only supported for MyISAM tables.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Merge tables will use more file descriptors. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You can’t perform the FULL TEXT SEARCH using the merge tables.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Merge tables used extremely rare since partitions came around.</span></li>\n</ul>\n<h3>How Does it work?</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>It works only for the MyISAM tables.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The columns order, index, data types should be the same on all the tables.</span></li>\n</ul>\n<h4><b>Example</b></h4>\n<p><span>I have created two tables:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table merge_1(id int, name varchar(16)) engine = myisam;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; create table merge_2(id int, name varchar(16)) engine = myisam;\nQuery OK, 0 rows affected (0.01 sec)</pre><p><span>Inserting some data on both tables:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; insert into merge_1 values (1,'herc'),(2,'sakthi'),(3,'sri');\nQuery OK, 3 rows affected (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql&#62; insert into merge_2 values (4,'jc'),(5,'xxx'),(3,'yyy');\nQuery OK, 3 rows affected (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 0</pre><p><span>Now, creating the merge table:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table merge_1_and_2 (id int, name varchar(16)) engine = mrg_myisam union=(merge_1,merge_2);\nQuery OK, 0 rows affected (0.01 sec)</pre><p><span>Let&#8217;s query the merge table:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from merge_1_and_2;\n+------+--------+\n| id   | name   |\n+------+--------+\n|    1 | herc   |\n|    2 | sakthi |\n|    3 | sri    |\n|    4 | jc     |\n|    5 | xxx    |\n|    3 | yyy    |\n+------+--------+\n6 rows in set (0.00 sec)</pre><p><span>It seems, when I query the merge table, it merges both the tables (merge_1, merge_2) and displays the results. </span></p>\n<p><span>Physically, the MERGE table will not occupy any disk space. When querying the table, it will just merge the data from the configured tables and display the result.</span></p><pre class=\"crayon-plain-tag\">[root@mass percona]# ls -lrth\ntotal 72K\n\n-rw-r-----. 1 mysql mysql 8.4K Mar 19 18:44 merge_1.frm\n-rw-r-----. 1 mysql mysql 1.9K Mar 19 18:51 merge_1.MYD\n-rw-r-----. 1 mysql mysql 1.0K Mar 19 18:51 merge_1.MYI\n\n-rw-r-----. 1 mysql mysql 8.4K Mar 19 18:44 merge_2.frm\n-rw-r-----. 1 mysql mysql 1.6K Mar 19 18:51 merge_2.MYD\n-rw-r-----. 1 mysql mysql 1.0K Mar 19 18:51 merge_2.MYI\n\n-rw-r-----. 1 mysql mysql 8.4K Mar 19 18:48 merge_1_and_2.frm\n-rw-r-----. 1 mysql mysql   16 Mar 19 18:48 merge_1_and_2.MRG</pre><p></p>\n<h2>Blackhole Engine</h2>\n<h3>Overview:<span> </span></h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Blackhole Engine will accept the data from SQL. The accepted data will not be stored, whenever you are querying the data it will give the empty result.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Can be used for SQL syntax checking purposes. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Can be used for the replication filter purpose. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>You have to be very careful when you use the table in a replication environment. Because the SQL will be logged in the binary log.</span></li>\n</ul>\n<h3>How Does it work?</h3>\n<h4><b>Example</b></h4>\n<p><span>Creating the blackhole table:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table black_hole (id int, name varchar(16)) engine = blackhole;\nQuery OK, 0 rows affected (0.00 sec)</pre><p><span>Inserting and retrieving the data:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; insert into black_hole values (1,'sri'),(2,'jc');\nQuery OK, 2 rows affected (0.00 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n\nmysql&#62; select * from black_hole;\nEmpty set (0.00 sec)</pre><p><span>The data will be stored on the binary logs:</span></p><pre class=\"crayon-plain-tag\"># at 23445\n#210319 19:19:15 server id 10  end_log_pos 23497 CRC32 0x36e22a05       Write_rows: table id 115 flags: STMT_END_F\n### INSERT INTO `percona`.`black_hole`\n### SET\n###   @1=1 /* INT meta=0 nullable=1 is_null=0 */\n###   @2='sri' /* VARSTRING(16) meta=16 nullable=1 is_null=0 */\n### INSERT INTO `percona`.`black_hole`\n### SET\n###   @1=2 /* INT meta=0 nullable=1 is_null=0 */\n###   @2='jc' /* VARSTRING(16) meta=16 nullable=1 is_null=0 */\n# at 23497\n#210319 19:19:15 server id 10  end_log_pos 23573 CRC32 0x4d79cba4       Query   thread_id=5     exec_time=0     error_code=0\nSET TIMESTAMP=1616181555/*!*/;\nCOMMIT</pre><p><b>Syntax Checking Purposes</b></p>\n<p><span>If you want to check any syntax of the SQL statements, you can directly execute them against the blackhole tables as it is not going to do anything with the data.</span></p>\n<p><b>Replication Filter Purpose</b></p>\n<p><span>Let&#8217;s consider that I have a source-replica setup. At the source, I have created the below table.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table test_blackhole(id int, name varchar(16)) engine=innodb;\nQuery OK, 0 rows affected (0.01 sec)</pre><p><span>I don’t want to replicate this table to replica nodes. In this case, I just converted the table to BLACKHOLE engine on the replica node. </span></p>\n<p><span>At replica node:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; alter table test_blackhole engine=blackhole;\nQuery OK, 0 rows affected (0.00 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql&#62; show create table test_blackhole\\G\n*************************** 1. row ***************************\n       Table: test_blackhole\nCreate Table: CREATE TABLE `test_blackhole` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(16) DEFAULT NULL\n) ENGINE=BLACKHOLE DEFAULT CHARSET=latin1\n1 row in set (0.00 sec)</pre><p><span>Now, at source, I am inserting some records:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; insert into test_blackhole values (1,'aaa');\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&#62; select * from test_blackhole;\n+------+------+\n| id   | name |\n+------+------+\n|    1 | aaa  |\n+------+------+\n1 row in set (0.00 sec)</pre><p><span>At replica, the data is not available. The data has been ignored as the table was converted to the blackhole engine.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; select * from test_blackhole;\nEmpty set (0.00 sec)</pre><p></p>\n<h2>CSV Engine</h2>\n<h3>Overview:<span> </span></h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The CSV storage engine stores data in csv files. </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>If you need the data into a CSV file, you can just copy the table physical file and use it. No need to export the data using the command SELECT INTO OUTFILE.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>It will not support nullable columns.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The data will store comma-separated values.</span></li>\n</ul>\n<h4><b>Example</b></h4>\n<p><span>Creating the CSV table:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; create table csv_test (id int not null, name varchar(16) not null, cur_time datetime default current_timestamp not null) engine = csv;\nQuery OK, 0 rows affected (0.00 sec)</pre><p><span>Inserting data:</span></p><pre class=\"crayon-plain-tag\">mysql&#62; insert into csv_test (id,name) values (1,'jc'),(2,'sri'),(3,'herc');\nQuery OK, 3 rows affected (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql&#62; select * from csv_test;\n+----+------+---------------------+\n| id | name | cur_time            |\n+----+------+---------------------+\n|  1 | jc   | 2021-03-19 19:40:40 |\n|  2 | sri  | 2021-03-19 19:40:40 |\n|  3 | herc | 2021-03-19 19:40:40 |\n+----+------+---------------------+\n3 rows in set (0.00 sec)</pre><p><span>Physically, you can see the data is stored as the .csv file. You can view the data from the file itself. </span></p><pre class=\"crayon-plain-tag\">[root@mass percona]# ls -lrth | grep -i csv\n-rw-r-----. 1 mysql mysql 8.5K Mar 19 19:38 csv_test.frm\n-rw-r-----. 1 mysql mysql   90 Mar 19 19:40 csv_test.CSV\n-rw-r-----. 1 mysql mysql   35 Mar 19 19:40 csv_test.CSM\n\n[root@mass percona]# cat csv_test.CSV\n1,\"jc\",\"2021-03-19 19:40:40\"\n2,\"sri\",\"2021-03-19 19:40:40\"\n3,\"herc\",\"2021-03-19 19:40:40\"</pre><p><span>As you see, MySQL alternative engines are having some good features. Based on my point of view, I would not suggest having them on production until finding a valid reason. But, it is still good to know about those engines and understand their features.</span></p>\n<hr />\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database?utm_source=blog\"><span data-sheets-value=\"{&#34;1&#34;:2,&#34;2&#34;:&#34;Percona Distribution for MySQL, an enterprise-grade solution for your most critical business applications.&#34;}\" data-sheets-userformat=\"{&#34;2&#34;:14915,&#34;3&#34;:{&#34;1&#34;:0},&#34;4&#34;:{&#34;1&#34;:2,&#34;2&#34;:16777215},&#34;9&#34;:0,&#34;12&#34;:0,&#34;14&#34;:{&#34;1&#34;:2,&#34;2&#34;:0},&#34;15&#34;:&#34;docs-Calibri&#34;,&#34;16&#34;:12}\">Percona Distribution for MySQL: An enterprise-grade solution for your most critical business applications.</span></a></p>\n","descriptionType":"html","publishedDate":"Fri, 26 Mar 2021 16:40:57 +0000","feedId":11,"bgimg":"","linkMd5":"d4611282a8da21922c609e19f4374a12","bgimgJsdelivr":"","metaImg":"","author":"Sri Sakthivel","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn54@2020_1/2021/04/03/04-49-24-647_20e4ff73535c9981.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn44@2020_5/2021/04/03/04-49-09-229_9b745d3cbedc0d17.webp"},"publishedOrCreatedDate":1617425343828},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Point-In-Time Recovery in Kubernetes Operator for Percona XtraDB Cluster – Architecture Decisions","link":"https://www.percona.com/blog/?p=74562","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Point-In-Time Recovery in Kubernetes Operator\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-74598\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-300x157.png\" alt=\"Point-In-Time Recovery in Kubernetes Operator\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Point-In-Time Recovery (PITR) for MySQL databases is an important feature that is essential and covers common use cases, like a recovery to the latest possible transaction or roll-back the database to a specific date before some bad query was executed. <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/index.html\">Percona Kubernetes Operator for Percona XtraDB Cluster</a> (PXC) </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/backups.html#backups-pitr-binlog\"><span>added support for PITR</span></a><span> in </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/ReleaseNotes/Kubernetes-Operator-for-PXC-RN1.7.0.html\"><span>version 1.7</span></a>,<span> and in this blog post we are going to look into the technical details and decisions we made to implement this feature.</span></p>\n<h2><span>Architecture Decisions</span></h2>\n<h3><span>Store Binary Logs on Object Storage</span></h3>\n<p><span>MySQL uses </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/binary-log.html\"><span>binary logs</span></a><span> to perform point-in-time recovery. Usually, they are stored locally along with the data, but it is not an option for us:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>We run the cluster and we cannot rely on a single node’s local storage.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The cloud-native world lives in an ephemeral dimension, where nodes and pods can be terminated and S3-compatible storage is a de facto standard to store data.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>We should be able to recover the data to another Kubernetes cluster in case of a disaster.</span></li>\n</ul>\n<p><span>We have decided to add a new Binlog Uploader Pod, which connects to the available PXC member and uploads binary logs to S3. Under the hood, it relies on the </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/mysqlbinlog.html\"><span>mysqlbinlog</span></a><span> utility.</span></p>\n<h3><span>Use Global Transaction ID</span></h3>\n<p><span>Binary logs on the clustered nodes are not synced and can have different names and contents. This becomes a problem for the Uploader, as it can connect to different PXC nodes for various reasons.</span></p>\n<p><span>To solve this problem, we decided to rely on </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/replication-gtids-concepts.html\"><span>Global Transaction ID (GTID)</span></a><span>. It is a unique transaction identifier, </span><i><span>but it is unique not only to the server on which it originated, but is unique across all servers in a given replication topology.  </span></i><span>With the GTID captured in binary logs, we can identify any transaction not depending on the filename or its contents. This allows us to continue streaming binlogs from any PXC member at any moment.</span></p>\n<h2><img loading=\"lazy\" class=\"aligncenter wp-image-74564 size-large\" style=\"font-size: 16px;\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-1024x742.png\" alt=\"\" width=\"900\" height=\"652\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-1024x742.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-300x218.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-200x145.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-367x266.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid.png 1320w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></h2>\n<h3><span>User-Defined Functions</span></h3>\n<p><span>We have a unique identifier for every transaction, but the </span><span>mysqlbinlog</span><span> utility still doesn’t have the functionality to determine which binary log file contains which GTID. We decided to extend MySQL with few </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/create-function-udf.html\"><span>User Defined Functions</span></a><span> and added them to Percona Server for MySQL and </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/8.0/flexibility/binlogging_replication_improvements.html\"><span>Percona XtraDB Cluster versions 8.0.21</span></a><span>. </span></p>\n<p><a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster/blob/b05c888da5073ab743c759faeaff7ccdb440f8d1/plugin/binlog_utils_udf/binlog_utils_udf.cc#L448\"><span>get_gtid_set_by_binlog()</span></a></p>\n<p><span>This function returns all GTIDs that are stored inside the given binlog file. We put the GTID setlist to a new file next to the binary log on S3.</span></p>\n<p><a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster/blob/b05c888da5073ab743c759faeaff7ccdb440f8d1/plugin/binlog_utils_udf/binlog_utils_udf.cc#L532\"><span>get_binlog_by_gtid_set()</span></a></p>\n<p><span>This function takes GTID set as an input and returns a binlog filename which is stored locally. We use it to figure out which GTIDs are already uploaded and which binlog to upload next. </span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74566 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage.png\" alt=\"binlog uploader pod\" width=\"685\" height=\"623\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage.png 685w, https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage-300x273.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage-165x150.png 165w, https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage-367x334.png 367w\" sizes=\"(max-width: 685px) 100vw, 685px\" /></p>\n<p style=\"text-align: center;\" data-pm-slice=\"1 1 []\">\n<h3><span>Find the node with the oldest binary log</span></h3>\n<p><span>Our quality assurance team </span><a target=\"_blank\" href=\"https://jira.percona.com/browse/K8SPXC-610\"><span>caught a bug</span></a><span> before the release which can happen in the cluster only:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Add a new node to the Percona XtraDB Cluster (for example scale up from 3 to 5 nodes).</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Binlog Uploader Pod tries to execute get_binlog_by_gtid_set on the new node but gets the error.</span></li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\">2021/01/19 11:23:19 ERROR: collect binlog files: get last uploaded binlog name by gtid set: scan binlog: sql: Scan error on column index 0, name \"get_binlog_by_gtid_set('a8e657ab-5a47-11eb-bea2-f3554c9e5a8d:15')\": converting NULL to string is unsupported</pre><p><span>The error is valid, as this node is new and there are no binary log files that have the GTID set that Uploader got from S3. If you look into </span><a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster-operator/pull/736/files\"><span>this pull request</span></a><span>, the quick patch is to always pick the oldest node in the array or in other words the node, which most likely would have the binary logs we need. In the next release of the Operator, we </span><a target=\"_blank\" href=\"https://github.com/percona/percona-xtradb-cluster-operator/commit/644d826f7b374bb0a7cbcf5b75d4c6d3cc1b4dbc#diff-8d82693a3a7093d4435f7e5575923fd54a2c5177993de0a5c2cfb72039fd4354R225\"><span>add more sophisticated logic</span></a><span>, to discover the node which has the oldest binary logs for sure.</span></p>\n<h3><span>Storageless binlog uploader</span></h3>\n<p><span>The size of binlogs depends on the cluster usage patterns, so it is hard to predict the size of the storage or memory required for them. We decided to take this complexity away by making our Binary Log Uploader Pod completely storageless. </span><span>Mysqlbinlog</span><span> can store remote binlog only into files, but we need to put them to S3. To get there we decided to use a </span><a target=\"_blank\" href=\"https://man7.org/linux/man-pages/man7/fifo.7.html\"><span>named pipe or FIFO special file</span></a><span>. Now mysqlbinlog utility loads the binary log file to a named pipe, our Uploader reads it and streams the data directly to S3.</span></p>\n<p><span>Also, storageless design means that we never store any state between Uploader restarts. Basically, state is not needed, we only need to know which GTIDs are already uploaded and we have this data on a remote S3 bucket. Such design enables the continuous upload flow of binlogs.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74565 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-1024x564.png\" alt=\"\" width=\"900\" height=\"496\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-1024x564.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-300x165.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-200x110.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-367x202.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe.png 1180w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h3><span>Binlog upload delay</span></h3>\n<p><span>S3 protocol expects that the file is completely uploaded. If the file upload is interrupted (let&#8217;s say Uploader Pod is evicted), the file will not be accessible/visible on S3. Potentially we can lose many hours of binary logs because of such interruptions. That&#8217;s why we need to split the binlog stream into files and upload them separately.</span></p>\n<p><span>One of the options that users can configure when enabling point-in-time recovery in Percona XtraDB Cluster Operator is </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/operator.html#backup-pitr-timebetweenuploads\"><span>timeBetweenUploads</span></a><span>. It sets the number of seconds between uploads for Binlog Uploader Pod. By default, we set it to 60 seconds, but it can go down to one second. We do not recommend setting it too l</span>ow, as every invocation of the Uploader leads to FLUSH BINARY LOGS command execution on the PXC node. We need to flush the logs to close the binary log file to upload it to external storage, but doing it frequently may negatively affect IO and as a result database performance.</p>\n<h3><span>Recovery</span></h3>\n<p><span>It is all about recovery and it has two steps:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Recover the cluster from a full backup</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Apply binary logs</span></li>\n</ol>\n<p><span>We already have the functionality to restore from a full backup (see </span><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-pxc/backups.html#restore-the-cluster-from-a-previously-saved-backup\"><span>here</span></a><span>), so let&#8217;s get to applying the binary logs.</span></p>\n<p><span>First, we need to figure out from which GTID set we should start applying binary logs &#8211; in other words: where do we start?. As we rely on the </span><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtrabackup\"><span>Percona XtraBackup</span></a><span> utility to take full MySQL backups, what we need to do is read the xtrabackup_info file which has lots of useful metadata. We already have this file on S3 near the full backup.</span></p>\n<p><span>Second, find the binlog which has the GTID set we need. As you remember, we store a file with binlog’s GTID sets on S3 already, so it boils down to reading these files.</span></p>\n<p><span>Third, download binary logs and apply them. Here we rely on mysqlbinlog as well, which has the flags we need, like </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/mysqlbinlog.html#option_mysqlbinlog_stop-datetime\"><span>&#8211;stop-datetime</span></a><span> &#8211; which stops recovery when the event with a specific timestamp is caught in the log.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74563 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog.png\" alt=\"point in time recovery\" width=\"711\" height=\"593\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog.png 711w, https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog-300x250.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog-180x150.png 180w, https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog-367x306.png 367w\" sizes=\"(max-width: 711px) 100vw, 711px\" /></p>\n<h3><span>Conclusion</span></h3>\n<p><span>MySQL is more than 25 years old and has a great tooling ecosystem established around it, but as we saw in this blog post, not all these tools are cloud-native ready. Percona engineering teams are committed to providing users the same features across various environments, whether it is a bare-metal installation in the data center or cutting edge Kubernetes in the cloud.</span></p>\n","descriptionType":"html","publishedDate":"Wed, 24 Feb 2021 16:15:52 +0000","feedId":11,"bgimg":"","linkMd5":"05b384867001d9b6ccbb12624b6b34cd","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn56@2020_4/2021/04/03/04-49-21-570_cdd193bfde8826fe.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn35@2020_5/2021/04/03/04-49-11-597_0f8a5d14ed442be6.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-1024x742.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn44@2020_2/2021/04/03/04-49-22-445_f5b54efed075f80c.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn52@2020_5/2021/04/03/04-49-48-143_8ed65cba45053ce2.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-1024x564.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn27@2020_1/2021/04/03/04-49-20-094_f7a6ee83c9fa90eb.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn100@2020_5/2021/04/03/04-49-21-260_7fbd641cd86035b5.webp"},"publishedOrCreatedDate":1617425343834},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"3 Percona Software Products Take the SourceForge Leader Award!","link":"https://www.percona.com/blog/?p=74740","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Software SourceForge Award\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p>We are so grateful to all users of our software. Thanks to you, some of them have just been recognized as a Winter 2021 category leader by SourceForge!</p>\n<ul>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://sourceforge.net/software/product/Percona-Monitoring-and-Management/\">Percona Monitoring And Management</a> is the leader in the <a target=\"_blank\" href=\"https://sourceforge.net/software/database-monitoring/\">Database Monitoring Tools</a> category</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://sourceforge.net/software/product/Percona-Server-for-MongoDB/\">Percona Server for MongoDB</a> is the leader in the <a target=\"_blank\" href=\"https://sourceforge.net/software/nosql-database/?sort=rating_count\">NoSQL Databases</a> category</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://sourceforge.net/software/product/Percona-Backup-for-MongoDB/\">Percona Backup for MongoDB</a> is the leader in the <a target=\"_blank\" href=\"https://sourceforge.net/software/server-backup/?sort=rating_count\">Server Backup Software</a> category</li>\n</ul>\n<p>The SourceForge Leader Award is only awarded to select products that have attained the highest levels of praise from user reviews on SourceForge.</p>\n<p>This is a huge achievement, as Percona Monitoring and Management and Percona Server for MongoDB have been selected as best-in-class from over 60,000 products on SourceForge. SourceForge gets over 30 million visitors per month looking for business software and solutions.</p>\n<p>Thank you, all the users of the open source software products, for your trust and support. <strong>We highly appreciate it</strong>.</p>\n<p>The best reviews are helpful to others by adding technical details and solutions. If you haven&#8217;t left a review for our software on SourceForge yet, we are looking forward to reading yours.</p>\n<p><a target=\"_blank\" href=\"https://sourceforge.net/software/product/Percona-Monitoring-and-Management/\"><img loading=\"lazy\" class=\"aligncenter wp-image-74761 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-1024x702.jpg\" alt=\"Percona Products Take SourceForge Leader Award\" width=\"900\" height=\"617\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-1024x702.jpg 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-300x206.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-200x137.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-1536x1054.jpg 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-367x252.jpg 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3.jpg 1837w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></a></p>\n","descriptionType":"html","publishedDate":"Tue, 09 Mar 2021 16:01:03 +0000","feedId":11,"bgimg":"","linkMd5":"b55980eba389b4a5afc63dd445b1a854","bgimgJsdelivr":"","metaImg":"","author":"Daniil Bazhenov","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn8@2020_5/2021/04/03/04-49-22-004_b177daffef307204.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-1024x702.jpg":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn60@2020_6/2021/04/03/04-49-05-343_4b77b64d9f82a043.webp"},"publishedOrCreatedDate":1617425343773},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"The Most Important Skills for an SRE, DBRE, or DBA","link":"https://www.percona.com/blog/?p=74520","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Important Skills for an SRE DBRE or DBA\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74528\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-300x157.png\" alt=\"Important Skills for an SRE DBRE or DBA\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />I have talked extensively about the DBA&#8217;s evolving role and how many DBA’s and operations professionals are now becoming SRE’s (site reliability engineers) or DBRE’s (database reliability engineers). Often, databases get blamed as the bottleneck for application slowdowns and issues, so DBAs have had to develop the skills needed to chase problems up and down the stack over the years. This full-stack approach to hunting out problems has resulted in many former DBAs and Sysadmins successfully taking on the role of an SRE/DBRE.</p>\n<p><strong>The question is, then, what are the most critical skills for this important role?</strong></p>\n<p>I personally have interviewed 1000’s of technical candidates over the last 10 years and have hired hundreds in various roles here at Percona. I often get asked the most critical skill for the next generation of technical engineers, SREs, or DBREs. The answer has been consistent for me over my career &#8211; I want engineers, SREs, etc., with good problem-solving skills and the ability to think outside the box. I am not looking for book knowledge or a detailed understanding of every concept; I want people who can see something new and&#8230;</p>\n<ol>\n<li>Be curious enough to ask &#8220;Why?&#8221; and want to know the answer.</li>\n<li>Will dig into the ambiguous and want to learn, and can learn the why.</li>\n<li>Can solve the issue, answer the question, and share that knowledge effectively.</li>\n</ol>\n<p>From a technical perspective, while it is wonderful to have a great depth of knowledge, I generally am not looking for the experts&#8217; expert. Rather, I look for people who are smart, passionate, and who learn quickly. I am not alone in this. I asked the question of those involved in hiring technical people here at Percona.</p>\n<p><strong>Peter Zaitsev (CEO)</strong> said the number one skill he is looking for is this: “<em>Attitude and Ability to do independent research and find information to solve the problem at hand</em>.” For many like Peter, having an encyclopedic knowledge of how things work or the right commands to use is secondary to solving problems never seen before. Many problems and issues that come up you cannot specifically train for. The unique nature of the workload, size, and way too many external factors often offer unique challenges to even the most experienced SRE. Peter added: “<em>So many people now have this ‘I have not been trained on this’ attitude instead of doing some basic googling for the answer</em>.” Indeed, there is a lot of information out there, and while searching for an answer quickly during an outage or performance event may seem like a no-brainer, more than half the people I have interviewed don’t even think about it. Thinking on your feet, reacting quickly, and restoring service can save companies millions of dollars of lost revenue and business in an outage.</p>\n<p><strong>Marco Tusa (MySQL Tech Lead) </strong>echoed Peter’s sentiment by saying that there are two important skills for him. One of these is the ability to learn what they don&#8217;t know. &#8220;<em>This is because no matter what, often the best one on tech knowledge won&#8217;t know some important stuff. The will to learn is the key.</em> “ <strong>Lenz Grimmer (Sr Director of Server Engineering)</strong> could not have agreed more, adding: “<em>I&#8217;m seeking talent that is open-minded about acquiring new skills. So fast learners with the right sense of humility and the right attitude.</em> “</p>\n<h2>Teamwork Makes the Dream Work&#8230;</h2>\n<p>Attitude and humility are critical in building an effective team (<em>especially</em> in a remote team). This was Marco’s second trait he is looking for. Marco went on to add he is also looking strongly into their fit with the team and if they will be a team player. The “no jerks” or “no soloist prima donna” mottos are very important. You have to be willing to share what you learned and look for help from your teammates.</p>\n<p>This is the same thing <strong>Jay Janssen (Director of IT)</strong> said when asked about the number one thing he looks for: “<em>Humility comes to mind &#8212; smart and humble is a good combination. While kind of cliche, it’s generally true.</em>” We are all looking to hire smart people, but smart people who are Jerks or flaunt how smart they are generally don’t operate well in a team environment. You want someone who is smart but does not make other people feel small or insignificant.</p>\n<p><strong>Sanja Bonic (Head of Percona&#8217;s Open Source Program Office)</strong> also values teamwork and makes sure she tries to understand how people handle positive and negative interactions as a team.  Sanja, who has previously led Engineering teams at OpenShift and now works with Percona&#8217;s community, asks people in interviews about “<em>their best and worst experiences in teams they&#8217;ve previously worked with. This usually shows what people are paying attention to, and you&#8217;ll quickly get a hint of what people attribute value to</em>.&#8221;</p>\n<p>While you need people to work and learn independently, you equally also need them to function as a unit (or as a team). Remember to ensure the uptime, availability, and performance of the entire application spanning potentially hundreds or thousands of nodes, you need to use all the resources at your disposal when things go wrong, and having teammates who you trust, can help, and can augment your knowledge with is very important. <strong>You can’t do it all alone</strong>, so having the ability to &#8220;team-up&#8221; and work with others is a must.</p>\n<blockquote>\n<p class=\"u-text-p5-bold u-mb-0\">&#8220;<em>The strength of the team is each individual member. The strength of each member is the team.</em>&#8221; ~ <cite class=\"u-text-p8 u-Mt-xs u-inline-block\">Phil Jackson</cite></p>\n</blockquote>\n<h2>Sharing is Caring&#8230;</h2>\n<p>The ability for smart people to effectively share their knowledge and have good meaningful conversations is also critical in this role. <strong>Vadim Tkachenko (CTO)</strong> said he is looking for “<em>People who have a brain and can have a meaningful conversation.&#8221;</em> He went on to say he is looking for people who “<em>Can speak well about previous relevant experiences</em>.” This ability to share goes a long way internally to increase the collaborative spirit within the team. But this is not merely about speaking a single language; rather, it’s being able to talk about the technologies and match your audience&#8217;s expectations (or teammates).</p>\n<p><strong>Tate Mcdaniel (DBA Manager)</strong> says this is the number one thing he looks for when hiring people. His approach, in his words &#8211; “<em>I ask questions about contentious and complicated things, and I look for answers that explain the complexity in ways a layperson can understand while giving pros/cons judiciously</em>.” Taking the complex, explaining it, and educating others is of critical importance.</p>\n<p>It is why Peter, Vadim, Jay, Marco, Tate, Lenz, and myself all said we look online at what people have written, where they have talked at conferences, what code they may have written, and other traces of their public persona before interviewing someone.</p>\n<p>When I asked Lenz Grimmer if he looked at a candidate&#8217;s online persona, he said: “<em>Absolutely, that&#8217;s one of the beauties of hiring in the open-source ecosystem. A public track record of contributions in various forms tells me much more than a CV. Forum and mailing list contributions, YouTube videos, all of which help get a better understanding of the candidate</em>.”</p>\n<h2>One Person is an Island&#8230;</h2>\n<p>I personally highly value people’s willingness to share their insights, knowledge, and sometimes struggles. This is especially critical in the open-source space. I mentioned that no one person could manage a complex environment alone. Training and educating team members and others in the community is critical. The willingness to share and educate via online blogs, articles, and technical talks is, in my opinion, essential to the SRE/DBRE community as a whole.</p>\n<p><strong>So what do we see as the must-have skills?</strong></p>\n<ol>\n<li aria-level=\"1\">Problem-solving skills, the ability to troubleshoot unique and challenging problems.</li>\n<li aria-level=\"1\">The passion and desire to learn, research, and acquire skills quickly.</li>\n<li aria-level=\"1\">Humility and the ability to be a “team player” &#8211; No jerks allowed!</li>\n<li aria-level=\"1\">The ability and passion for sharing their knowledge and educating others.</li>\n</ol>\n<p><strong>What do you think? Did we miss any?</strong></p>\n","descriptionType":"html","publishedDate":"Wed, 17 Feb 2021 19:59:15 +0000","feedId":11,"bgimg":"","linkMd5":"9f9459a2d8847538d0d0e9f9eaf46481","bgimgJsdelivr":"","metaImg":"","author":"Matt Yonkovit","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn20@2020_6/2021/04/03/04-49-15-453_e852089897d562c7.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn53@2020_4/2021/04/03/04-49-05-142_da3beca23c6b32fa.webp"},"publishedOrCreatedDate":1617425343802},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Want MongoDB Performance? You Will Need to Add and Remove Indexes!","link":"https://www.percona.com/blog/?p=74884","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"MongoDB Performance\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><strong><img loading=\"lazy\" class=\"alignright size-medium wp-image-74958\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-300x157.png\" alt=\"MongoDB Performance\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Good intentions can sometimes end up with bad results.  Adding indexes boosts performance until it doesn’t. Avoid over-indexing.</strong></p>\n<p>The difference between your application being fast, responsive, and scaling properly is often dependent on how you use indexes in the database.  MongoDB is no different, its performance (and the overall performance of your application) is heavily dependent on getting the proper amount of indexes on the right things.   A simple index or two can speed up getting data from MongoDB a million-fold for million-records tables.  But at the same time having too many indexes on a large collection can lead to massive slowdowns in overall performance.  You need to get your indexes just right.</p>\n<p>For this blog, we are going to talk about having too many indexes and help you find both duplicate and unused indexes.  If you are interested in finding out if you need additional indexes or if your query is using an index, I would suggest reading previous Percona articles on query tuning (<a target=\"_blank\" href=\"https://www.percona.com/blog/2018/09/04/mongodb-index-usage-and-mongodb-explain-part-1/\">Part 1</a> &#38; <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/09/06/mongodb-investigate-queries-with-explain-index-usage-part-2/\">Part 2</a> of that series).</p>\n<p>So, indexes are very good for getting faster queries. How many indexes do I need to create on a collection? What are the best practices for the indexes? How do I find which indexes are being used or not?  What if I have duplicated indexes?</p>\n<h2>Common Performance Problems</h2>\n<p>After analyzing a lot of different MongoDB environments I can provide the following list summarizing the typical errors I have seen:</p>\n<ul>\n<li>Not creating indexes at all, other than the primary key _id created by design.\n<ul>\n<li>I&#8217;m not joking &#8211; I have seen databases without any user-created indexes, which had owners surprised the server was overloaded and/or the queries were very slow.</li>\n</ul>\n</li>\n<li>Over-indexing the collection.\n<ul>\n<li>Some developers usually create a lot of indexes without a specific reason or just for testing a query. Then they forget to drop them.</li>\n<li>In some cases, the size of all the indexes was larger than the data. This is not good; indexes should be as small as possible to be really effective.</li>\n</ul>\n</li>\n</ul>\n<p>I&#8217;m not considering the first case. I&#8217;m going to discuss instead the second one.</p>\n<h2>How Many Indexes you Need in a Collection</h2>\n<p>It depends &#8211; that&#8217;s the right answer. Basically, it depends on your application workload. You should consider the following rules when indexing a collection:</p>\n<ul>\n<li>Create as many indexes as possible for your application.</li>\n<li>Don&#8217;t create a lot of indexes.</li>\n</ul>\n<p>What? These rules are stating the opposite thing! Well, we can summarize in just one simple rule:</p>\n<ul>\n<li>You need to create all the indexes your application really needs for solving the most frequent queries. Not one more, not one less.</li>\n</ul>\n<p>That&#8217;s it.</p>\n<h2>Pros and Cons of Indexing</h2>\n<p>The big advantage of the indexes is that they permit the queries<i>, updates, and deletes</i> to run as fast as possible if they are used. <i>(Every update or delete also needs to do a lookup step first).</i> More indexes in a collection can benefit several queries.</p>\n<p>Unfortunately, the indexes require some extra work for MongoDB. Any time your run a write, all the indexes must be updated. The new values are stored or dropped into the B-Tree structure, some splitting or merging is needed, and this requires some time.</p>\n<p>The main problem is that &#8220;more indexes you have in a collection, the slower all the writes will be&#8221;.</p>\n<p>A very large collection with just 10 or 15 indexes can have a significant performance loss for the writes. Also, remember that indexes have to be copied into the WiredTiger cache. More indexes imply also more pressure for the memory cache. The pressure can then lead to more cache evictions and slowness.</p>\n<p>A good example of this is when I was working with a customer a few weeks ago we found 12 extra indexes on a collection they did not need. The collection was around 80GB; the total index size was more than the data size. They had a relevant write load based on several frequent inserts and updates all the time. Cleaning these indexes increased their write queries execution time by 25-30 percent on average. The improvement observed for this real case won&#8217;t be the same quantitative amount in other cases, but for sure the fewer indexes you have the faster all the writes will be.</p>\n<p>We need to find some kind of balancing: creating more indexes, but not that much.</p>\n<h2>How to Reduce Over-Indexing</h2>\n<p>Very easy to say: drop all the indexes you don&#8217;t need.</p>\n<p>There are two things you can do to identify the indexes to get dropped:</p>\n<ul>\n<li>Check for the duplicates.</li>\n<li>Check for the unused indexes.</li>\n</ul>\n<p>For dropping an index you need to run something like the following:</p><pre class=\"crayon-plain-tag\">db.mycollection.dropIndex(\"index_name\")</pre><p></p>\n<h3>Find Duplicate Indexes</h3>\n<p>A duplicate index could be an index with the same exact definition as another index that already exists in the collection. Fortunately, MongoDB is able to check this and it is not permitted to create such an index.</p>\n<p>Let&#8217;s do a test using a simple collection with no indexes.</p><pre class=\"crayon-plain-tag\">rs_test:PRIMARY&#62; db.test.find()\n{ \"_id\" : ObjectId(\"60521309d7268c122c7cd630\"), \"name\" : \"corrado\", \"age\" : 49 }\n{ \"_id\" : ObjectId(\"60521313d7268c122c7cd631\"), \"name\" : \"simone\", \"age\" : 12 }\n{ \"_id\" : ObjectId(\"6052131cd7268c122c7cd632\"), \"name\" : \"gabriele\", \"age\" : 19 }\n{ \"_id\" : ObjectId(\"60521323d7268c122c7cd633\"), \"name\" : \"luca\", \"age\" : 14 }\n{ \"_id\" : ObjectId(\"60521328d7268c122c7cd634\"), \"name\" : \"lucia\", \"age\" : 49 }\n\n# create an index on name field\nrs_test:PRIMARY&#62; db.test.createIndex( { name: 1 } )\n{\n   \"createdCollectionAutomatically\" : false,\n   \"numIndexesBefore\" : 1,\n   \"numIndexesAfter\" : 2,\n   \"commitQuorum\" : \"votingMembers\",\n   \"ok\" : 1,\n   \"$clusterTime\" : {\n      \"clusterTime\" : Timestamp(1615991942, 5),\n      \"signature\" : {\n         \"hash\" : BinData(0,\"vQN6SGIL0fAMvTusJ12KgySqKOI=\"),\n         \"keyId\" : NumberLong(\"6890926313742270469\")\n      }\n   },\n   \"operationTime\" : Timestamp(1615991942, 5)\n}\n\n# check indexes available\nrs_test:PRIMARY&#62; db.test.getIndexes()\n[\n   {\n      \"v\" : 2,\n      \"key\" : {\n         \"_id\" : 1\n      },\n      \"name\" : \"_id_\"\n   },\n   {\n      \"v\" : 2,\n      \"key\" : {\n         \"name\" : 1\n      },\n      \"name\" : \"name_1\"\n   }\n]\n\n# try to create again the same index\nrs_test:PRIMARY&#62; db.test.createIndex( { name: 1 } )\n{\n   \"numIndexesBefore\" : 2,\n   \"numIndexesAfter\" : 2,\n   \"note\" : \"all indexes already exist\",\n   \"ok\" : 1,\n   \"$clusterTime\" : {\n      \"clusterTime\" : Timestamp(1615991942, 5),\n      \"signature\" : {\n         \"hash\" : BinData(0,\"vQN6SGIL0fAMvTusJ12KgySqKOI=\"),\n         \"keyId\" : NumberLong(\"6890926313742270469\")\n      }\n   },\n   \"operationTime\" : Timestamp(1615991942, 5)\n}\n\n# great, MongoDB can detect the index already exists\n\n# let's try to see if you can create the same index with a different name\nrs_test:PRIMARY&#62; db.test.createIndex( { name: 1 }, { name: \"this_is_a_different_index_name\" } )\n{\n   \"operationTime\" : Timestamp(1615991981, 1),\n   \"ok\" : 0,\n   \"errmsg\" : \"Index with name: this_is_a_different_index_name already exists with a different name\",\n   \"code\" : 85,\n   \"codeName\" : \"IndexOptionsConflict\",\n   \"$clusterTime\" : {\n      \"clusterTime\" : Timestamp(1615991981, 1),\n      \"signature\" : {\n         \"hash\" : BinData(0,\"whkRyQQxyJVBt+7d3HOtFvYY32g=\"),\n         \"keyId\" : NumberLong(\"6890926313742270469\")\n      }\n   }\n}\n\n# even in this case MongoDB doesn't permit the index creation</pre><p>MongoDB is then clever enough to avoid the creation of duplicate indexes. But what about the creation of an index that is the left-prefix of an existing index? Let&#8217;s test it.</p><pre class=\"crayon-plain-tag\"># let's drop the previous index we have created\nrs_test:PRIMARY&#62; db.test.dropIndex( \"name_1\" )\n{\n   \"nIndexesWas\" : 2,\n   \"ok\" : 1,\n   \"$clusterTime\" : {\n      \"clusterTime\" : Timestamp(1615993029, 1),\n      \"signature\" : {\n         \"hash\" : BinData(0,\"njFiuCeyA5VcdNOOP2ASboOpWwo=\"),\n         \"keyId\" : NumberLong(\"6890926313742270469\")  \n      }\n   },\n   \"operationTime\" : Timestamp(1615993029, 1)\n}\n\n# check indexes. Only _id available\nrs_test:PRIMARY&#62; db.test.getIndexes()\n[ { \"v\" : 2, \"key\" : { \"_id\" : 1 }, \"name\" : \"_id_\" } ]\n\n# create a compound index \nrs_test:PRIMARY&#62; db.test.createIndex( { name:1, age: 1 } )\n{\n   \"createdCollectionAutomatically\" : false,\n   \"numIndexesBefore\" : 1,\n   \"numIndexesAfter\" : 2,\n   \"commitQuorum\" : \"votingMembers\",\n   \"ok\" : 1,\n   \"$clusterTime\" : {\n      \"clusterTime\" : Timestamp(1615993054, 5),\n      \"signature\" : {\n         \"hash\" : BinData(0,\"gfaPsWsSM745opEiQORCt2L3HYo=\"),\n         \"keyId\" : NumberLong(\"6890926313742270469\")\n      }\n   },\n   \"operationTime\" : Timestamp(1615993054, 5)\n}\n\n# create another index that is the leftmost prefix of the compound index\nrs_test:PRIMARY&#62; db.test.createIndex( { name:1 } )\n{\n   \"createdCollectionAutomatically\" : false,\n   \"numIndexesBefore\" : 2,\n   \"numIndexesAfter\" : 3,\n   \"commitQuorum\" : \"votingMembers\",\n   \"ok\" : 1,\n   \"$clusterTime\" : {\n      \"clusterTime\" : Timestamp(1615993060, 5),\n      \"signature\" : {\n         \"hash\" : BinData(0,\"C2XWVA5mi+WWyPMn3Jw2VHTw/Dk=\"),\n         \"keyId\" : NumberLong(\"6890926313742270469\")\n      }\n   },\n   \"operationTime\" : Timestamp(1615993060, 5)\n}\n\n# check indexes\nrs_test:PRIMARY&#62; db.test.getIndexes()\n[\n   {\n      \"v\" : 2,\n      \"key\" : {\n         \"_id\" : 1 \n      },\n      \"name\" : \"_id_\"\n   },\n   {\n      \"v\" : 2,\n      \"key\" : {\n         \"name\" : 1,\n         \"age\" : 1\n      },\n      \"name\" : \"name_1_age_1\"\n   },\n   {\n      \"v\" : 2,\n      \"key\" : {\n         \"name\" : 1\n      },\n      \"name\" : \"name_1\"\n   }\n]</pre><p>We consider a leftmost-prefix index as a duplicate as well.</p>\n<p>To take benefit from a compound index MongoDB doesn’t need to use all the fields of that index, the leftmost prefix is enough. For example an index on (A,B,C) can be used to satisfy the combinations (A), (A,B), (A,B,C) but not (B) or (B,C). As a consequence, if I have two different indexes, one on (A, B, C) and another one on (A, B), the second is a duplicate because the first can be used the same way for solving the query with the combinations (A, B) and (A).</p>\n<p>Then, find all duplicate indexes and drop them since they&#8217;re useless. Just be aware and check that your application doesn&#8217;t use<em> hint()</em> on the indexes you&#8217;re going to drop.</p>\n<p>In order to avoid manually checking all the collections to discover the duplicates, I provide here a javascript code for that:</p><pre class=\"crayon-plain-tag\">var ldb = db.adminCommand( { listDatabases: 1 } );\n\nfor ( i = 0; i &#60; ldb.databases.length; i++ ) {\n\n   if ( ldb.databases[i].name != 'admin' &#38;&#38; ldb.databases[i].name != 'config' &#38;&#38; ldb.databases[i].name != 'local') {\n\n      print('DATABASE ',ldb.databases[i].name);\n      print(\"+++++++++++++++++++++++++++++++++++++++++\")\n\n      var db = db.getSiblingDB(ldb.databases[i].name); \n      var cpd = db.getCollectionNames();\n\n      for ( j = 0; j &#60; cpd.length; j++ ) { \n\n         if ( cpd[j] != 'system.profile' ) {\n\n            var indexes = JSON.parse(JSON.stringify(db.runCommand( { listIndexes: cpd[j] } ).cursor.firstBatch));\n            print(\"COLL :\"+cpd[j]);\n\n            for ( k = 0; k &#60; indexes.length; k++ ) {\n\n               indexes[k] = (((JSON.stringify(indexes[k].key)).replace(\"{\",\"\")).replace(\"}\",\"\")).replace(/,/g ,\"_\");\n\n            }\n\n            var founddup = false;\n\n            for ( k1 = 0; k1 &#60; indexes.length; k1++ ) {\n\n               for ( k2 = 0; k2 &#60; indexes.length; k2++ ) {\n\n                  if ( k1 != k2 ) {\n\n                     if (indexes[k1].startsWith(indexes[k2],0)) {\n\n                        print(\"{ \"+indexes[k2]+\" } is the left prefix of { \"+indexes[k1]+\" } and should be dropped\");\n\n                        founddup = true;\n\n                     }\n                  }\n               } \n            }\n\n            if (!founddup) {\n\n               print(\"no duplicate indexes found\");\n\n            }\n\n            print(\"\\n\");\n\n         } \n      }\n\n      print(\"\\n\");\n   } \n}</pre><p><em>Note: this script is just an initial test and could be improved, but it should work in most cases.</em></p>\n<h3>Find Unused Indexes</h3>\n<p>MongoDB maintains internal statistics about index usage. Any time an index is used for solving a query a specific counter is an increment. After running MongoDB for a significant amount of time &#8211; days or weeks &#8211; the statistics are reliable and we can find out which indexes have been used or not.</p>\n<p>For looking at the index stats, MongoDB provides a stage in the aggregation pipeline: <strong>$indexStats</strong></p>\n<p>Here you can see an example:</p><pre class=\"crayon-plain-tag\">rs_test:PRIMARY&#62; db.restaurants.aggregate([ { $indexStats: {} } ]).pretty()\n{\n   \"name\" : \"borough_1\",\n   \"key\" : {\n      \"borough\" : 1\n   },\n   \"host\" : \"ip-172-30-2-12:27017\",\n   \"accesses\" : {\n      \"ops\" : NumberLong(312),\n      \"since\" : ISODate(\"2021-03-17T13:48:51.305Z\")\n   },\n   \"spec\" : {\n      \"v\" : 2,\n      \"key\" : {\n         \"borough\" : 1\n      },\n      \"name\" : \"borough_1\"\n   }\n}\n{\n   \"name\" : \"_id_\",\n   \"key\" : {\n      \"_id\" : 1\n   },\n   \"host\" : \"ip-172-30-2-12:27017\",\n   \"accesses\" : {\n      \"ops\" : NumberLong(12),\n      \"since\" : ISODate(\"2021-03-17T13:48:51.305Z\")\n   },\n   \"spec\" : {\n      \"v\" : 2,\n      \"key\" : {\n         \"_id\" : 1\n      },\n      \"name\" : \"_id_\"\n   }\n}\n{\n   \"name\" : \"cuisine_1_borough_1\",\n   \"key\" : {\n      \"cuisine\" : 1,\n      \"borough\" : 1\n   },\n   \"host\" : \"ip-172-30-2-12:27017\",\n   \"accesses\" : {\n      \"ops\" : NumberLong(0),\n      \"since\" : ISODate(\"2021-03-17T13:48:51.305Z\")\n   },\n   \"spec\" : { \n      \"v\" : 2,\n      \"key\" : {\n         \"cuisine\" : 1,\n         \"borough\" : 1\n      },\n      \"name\" : \"cuisine_1_borough_1\"\n   }\n}</pre><p>The accesses.ops is the number of times the index has been used. In the example you can see the <em>{ borough:1 }</em> has been used 312 times, the index <em>{ _id }</em> 12 times, and the index <em>{ cuisine:1, borough: 1}</em> 0 times. The last one could be dropped.</p>\n<p>If the database is running for a long time with millions of queries executed and if an index was not used, most probably it won&#8217;t be used even in the future.</p>\n<p>Then you should consider dropping the unused indexes in order to improve the writes, reduce the cache pressure, and saving disk space as well.</p>\n<p>Using the following script you can find out the index statistics for all the collections:</p><pre class=\"crayon-plain-tag\">var ldb=db.adminCommand( { listDatabases: 1 } );\n\n   for (i=0; i&#60;ldb.databases.length; i++) { \n\n      print('DATABASE ',ldb.databases[i].name);\n\n      if ( ldb.databases[i].name != 'admin' &#38;&#38; ldb.databases[i].name != 'config' &#38;&#38; ldb.databases[i].name != 'local' ) {\n\n      var db = db.getSiblingDB(ldb.databases[i].name); \n      var cpd = db.getCollectionNames();\n\n      for (j=0; j&#60;cpd.length; j++) {\n\n         if ( cpd[j] != 'system.profile' ) {\n\n            print(cpd[j]); \n\n            var pui = db.runCommand({ aggregate : cpd[j] ,pipeline : [{$indexStats: {}}],cursor: { batchSize: 100 } }); \n            printjson(pui);\n\n         } \n      }\n\n      print('\\n\\n'); \n   }\n}</pre><p>Look for the indexes having <em>&#8220;ops&#8221;: NumberLong(0)</em></p>\n<h3>Conclusion</h3>\n<p>Creating indexes for solving queries is a good habit, but be aware to not abuse indexing. Excessive indexing can lead to slower writes, excessive pressure on the memory cache, and more evictions.</p>\n<p>You should consider maintaining your indexes from time to time dropping all the duplicates and the unused indexes. The scripts provided in this article may help your index analysis.</p>\n","descriptionType":"html","publishedDate":"Mon, 22 Mar 2021 13:43:18 +0000","feedId":11,"bgimg":"","linkMd5":"d362d124e09e7053013c2ca0ca0310b9","bgimgJsdelivr":"","metaImg":"","author":"Corrado Pandiani","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn100@2020_4/2021/04/03/04-49-18-725_f632162ec682e739.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn60@2020_2/2021/04/03/04-49-22-533_2ca7693e4262243c.webp"},"publishedOrCreatedDate":1617425343797},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Upgrading to MySQL 8: Embrace the Challenge","link":"https://www.percona.com/blog/?p=75138","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Upgrading to MySQL 8\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-75229\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-300x157.png\" alt=\"Upgrading to MySQL 8\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Nobody likes change, especially when that change may be challenging.  When faced with a technical challenge, I try to remember this comment from Theodore Roosevelt: “<em>Nothing in the world is worth having or worth doing unless it means effort, pain, difficulty.</em>”  While this is a bit of an exaggeration, in this case, the main concept is still valid.  We shouldn’t shy away from an upgrade path because it may be difficult.</span></p>\n<p><span><strong>MySQL 8.0 is maturing and stabilizing</strong>.  There are new features (too many to list here) and performance improvements.  More and more organizations are upgrading to MySQL 8 and running it in production, which expedites the stabilization.  While there is still some significant runway on 5.7 and it is definitely stable (EOL slated for October 2023), organizations need to be preparing to make the jump if they haven’t already. </span></p>\n<h2>What Changed?</h2>\n<p><span>So how is a major upgrade to 8.0 different than in years past?  It honestly really isn’t that different.  The same general process applies:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Upgrade in a lower environment</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Test, test, and then test some more</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Upgrade a replica and start sending read traffic</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Promote a replica to primary</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Be prepared for a rollback as needed</span></li>\n</ol>\n<p><span>The final bullet point is the biggest change, especially once you have finished upgrading to MySQL 8.  Historically, minor version upgrades were fairly trivial.  A simple instance stop, binary swap, and instance start were enough to revert to a previous version.  </span></p>\n<p><span>In 8.0, this process is no longer supported (as noted in the </span><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/downgrading.html\"><span>official documentation</span></a><span>): </span></p>\n<p><span>“Downgrade from MySQL 8.0 to MySQL 5.7, or from a </span><b>MySQL 8.0 release to a previous MySQL 8.0 release</b><span>, is not supported.”</span></p>\n<p><span>That is a definite change in the release paradigm, and it has shown real issues across minor releases.  One good example of how this can impact a live system was captured well in the blog post <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/01/10/mysql-8-minor-version-upgrades-are-one-way-only/\">MySQL 8 Minor Version Upgrades Are ONE-WAY Only</a> f</span><span>rom early 2020. </span></p>\n<h2>How to Approach Upgrading to MySQL 8</h2>\n<p><span>With this new paradigm, it may seem scary to push through with the upgrade.  I think in some ways, it can be a positive change.  As mentioned above, proper preparation and testing should be the majority of the process.  The actual upgrade/cutover should essentially be a non-event.  There is nothing a DBA loves more than finalizing an upgrade with nobody noticing (aside from any potential improvements).</span></p>\n<p><span>Unfortunately, in practice, proper testing and preparation is generally an afterthought.  With how easy upgrades (and particularly rollbacks) have been, it was generally easier to just “give it a shot and roll back if needed”.  As downgrades are no longer trivial, this should be viewed as a golden opportunity to enhance the preparation phase of an upgrade.  </span></p>\n<p><span>Some extra focus should be given to:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Reviewing the release notes in detail for any potential changes (new features are also sometimes enabled by default in 8.0)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Testing the system with REAL application traffic (benchmarks are nice, but mean nothing if they are generic)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Solidifying the backup and restore process (this is already perfect, right?)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Reviewing automation (this means no more automated “silent” upgrades)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>The actual upgrade process (starting at the bottom of the replication chain and maintaining replicas for rollbacks if needed)</span></li>\n</ul>\n<p><span>With so much emphasis on the preparation, we should hopefully start to see the actual upgrade become less impactful.  It should also instill more confidence across the organization.</span></p>\n<h2>What About “At Scale”?</h2>\n<p><span>Having worked with a wide range of clients as a TAM, I’ve seen environments that range from a single primary/replica pair to 1000s of servers.  I will freely admit that completing a major version upgrade across 10,000 servers is non-trivial.  Nothing is more painful than needing to rollback 5000 servers when something crops up halfway through the upgrade process.  While no amount of testing can completely eliminate this possibility, we can strive to minimize the risk.</span></p>\n<p><span>At this scale, testing actual traffic patterns is so much more critical.  When you are looking at complex environments and workloads, the likelihood of hitting an edge case definitely increases.  Identifying those edge cases in lower environments is critical for a smooth process in production.  Similarly, ensuring processes and playbooks exist for rolling back (in the event an issue does appear) is critical.  </span></p>\n<p><span>Finally, deploying upgrades in phases is also critical.  Assuming you have monitoring such as <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> in place, A/B testing and comparison can be invaluable.  Seeing version X and Y on the same dashboard while serving the same traffic allows a proper comparison.  Comparing X in staging to Y in production is important, but can sometimes be misleading.  </span></p>\n<h3>Conclusion</h3>\n<p><span>Overall, upgrading to MySQL 8 isn’t that different from previous versions.  Extra care needs to be taken during the preparation phase, but that should be viewed as a positive overall.  We definitely shouldn’t shy away from the change, but rather embrace it as it needs to happen eventually.  The worst thing that can happen is to continue to kick the can down the road and then be pressed for time as 5.7 EOL approaches.</span></p>\n<p><span>To solidify the preparation phase and testing, what tools do you think are missing?  What would make it easier to accurately replay traffic against test instances?  While there are tools available, is there anything that would help ensure these best practices are followed?</span></p>\n<p><span>If your organization needs help in preparing for or completing an upgrade, our <a target=\"_blank\" href=\"https://www.percona.com/services/consulting\">Professional Services team</a> can be a great asset.  Likewise, our Support engineers can help your team as you hit edge cases in testing.  </span></p>\n<p><span>And, finally, the most important strategy when it comes to upgrades: </span><b>read-only Friday </b><span>should be at the top of your playbook!</span></p>\n","descriptionType":"html","publishedDate":"Fri, 02 Apr 2021 13:11:20 +0000","feedId":11,"bgimg":"","linkMd5":"8d29dd2848e596db260dedef0518d1b3","bgimgJsdelivr":"","metaImg":"","author":"Mike Benshoof","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn80@2020_3/2021/04/03/04-49-20-796_be0583cee4ec1282.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn11@2020_1/2021/04/03/04-49-20-589_dfae59a11c8cfa04.webp"},"publishedOrCreatedDate":1617425343771},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"The Steps Involved in Creating a Percona Product Release","link":"https://www.percona.com/blog/?p=74764","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"creating a percona product release\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span>Have you ever wondered what it takes to complete <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-server\">Percona Server for MySQ</a>L (PS), <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtradb-cluster\">Percona XtraDB Cluster</a> (PXC), and <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtrabackup\">Percona XtraBackup</a> (PXB) releases? </span></p>\n<p><span>Let’s step back just a minute and talk about what Percona stands for. We believe we “stand on the shoulders of giants.” This means we respect our upstream sources and work to add value to the base products. Over time, new functionality is added. Much of this value-add was implemented on the 5.7 series and pulled forward to the 8.0 series. Each time we receive an upstream release, we must reapply these features to the release we receive. This process is what we call the <strong>Merge Process</strong>. There are close to 40 add-on features being maintained with each release. </span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-75033 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process-.jpg\" alt=\"Creating a Percona Product Release\" width=\"960\" height=\"540\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process-.jpg 960w, https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process--300x169.jpg 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process--200x113.jpg 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process--367x206.jpg 367w\" sizes=\"(max-width: 960px) 100vw, 960px\" /></p>\n<h2>The Merge Process</h2>\n<p><span>The Merge Process is completed first for Percona Server for MySQL (PS), and then the merged product is used as the basis for merging the release for Percona XtraDB Cluster (PXC).  In addition, Percona XtraBackup (PXB) is based on Oracle’s MySQL. </span></p>\n<p><span>The merge process actually applies the Oracle MySQL commits for a received release to the base Percona Server for MySQL (PS) code. Then the validation process is begun.<br />\n</span> <span><br />\n</span><span>For each Oracle commit, an Engineer reviews the code, what it will do, and verifies there will be no adverse effect to the base PS code. In some cases, the Oracle code will replace the existing Percona Server for MySQL (PS) code (Percona may have added the same functionality previously or fixed a bug) or could cause conflicts with the existing Percona code. Each situation is then evaluated and resolved. For the last three 8.0 releases, there have been 2000-25</span>00 commits and 50-100 for the 5.7 base in each Oracle release.</p>\n<h2>Validation and Testing</h2>\n<p><span>Once all commits have been applied to the Percona Server for MySQL (PS) previous base, the validation/testing process begins. This process uses automated testing to validate the new codebase. We execute 1500-2000 regression-type test cases in addition to specifically validating bug fixes and new functionality. This process <b data-stringify-type=\"bold\">can take</b> anywhere from 5-10 days for a 5.7 merge and <b data-stringify-type=\"bold\">between</b> 35-40 days for an 8.0 merge.</span></p>\n<p><span>Once the Percona Server for MySQL (PS) merge is completed, the new base is used for the Percona XtraDBCluster (PXC) merge, which combines the new Percona Server for MySQL (PS) base with any Percona XtraDBCluster (PXC) specific functionality, using the same process as Percona Server for MySQL (PS). In addition, if a Codership (Galera) release is also available, we go through a slightly different process. In the case of Codership, beginning with the 8.0.19 release, there are no more git commits (<a target=\"_blank\" href=\"https://github.com/codership/mysql-wsrep/issues/382\">just a source tarball</a>), and we have to use release notes to point to the places we need to look for changes. The 5.7 codebase uses Galera 3.0 (still use committed work), and the 8.0 codebase uses the 4.x base (currently on 4.6, soon to go to 4.7). This also includes the same level of validation. This process again <b data-stringify-type=\"bold\">can take</b> anywhere from 5-10 days for a 5.7 merge and <b data-stringify-type=\"bold\">between</b> 35-40 days for an 8.0 merge.</span></p>\n<p><span>The last of the merge processes is to evaluate and complete processing for Percona XtraBackup (PXB). The first thing we do when Oracle releases a new wave of its product updates is verify whether the most recent Percona XtraBackup (PXB) &#8211; the one from the previous wave &#8211; is compatible with the new MySQL Server release. If we find compatibility issues, they will be documented and resolved, and be included in the merge process. The Percona XtraBackup (PXB) merge is done in the same way as Percona Server for MySQL (PS) for a small portion of the Oracle MySQL codebase. Percona XtraBackup (PXB) uses functionality related to redo log processing, such as writes/read/parsing and checksum processing for the read/write process. This process is done concurrently with the Percona Server for MySQL (PS) process and is done for both the 2.4 and 8.0 versions of Percona XtraBackup (PXB).  </span></p>\n<p>For all three products, security (CVE) modifications are purposefully not exposed individually. They are included and noted, but you will not find specific commits for them.</p>\n<hr />\n<p>We understand that choosing open source software for your business can be a potential minefield. You need to select the best available options, which fully support and adapt to your changing needs. In this white paper, we discuss the key features that make open source software attractive, and why Percona&#8217;s software might be the best option for your business.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://www.percona.com/resources/white-papers/when-percona-software-right-choice?utm_source=blog&#38;utm_medium=download&#38;utm_campaign=perconaprocess&#38;utm_content=whitepaper\" rel=\"noopener\">Download &#8220;When is Percona Software the Right Choice?&#8221;</a></p>\n","descriptionType":"html","publishedDate":"Thu, 25 Mar 2021 13:27:08 +0000","feedId":11,"bgimg":"","linkMd5":"b7cbc67aa9f9a490a47146c51cd54179","bgimgJsdelivr":"","metaImg":"","author":"Kathy Williamson","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn80@2020_1/2021/04/03/04-49-06-456_43956f05338d33c0.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process-.jpg":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn79@2020_3/2021/04/03/04-49-12-812_4ed60fcf5dba1995.webp"},"publishedOrCreatedDate":1617425343832},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"A Peek at Percona Kubernetes Operator for Percona Server for MongoDB New Features","link":"https://www.percona.com/blog/?p=74786","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Kubernetes Operator for Percona Server for MongoDB New Features\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74820\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-300x157.png\" alt=\"Percona Kubernetes Operator for Percona Server for MongoDB New Features\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />The latest 1.7.0 release of <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/RN/Kubernetes-Operator-for-PSMONGODB-RN1.7.0.html\">Percona Kubernetes Operator for Percona Server for MongoDB</a> came out just recently and enables users to:</p>\n<ul>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/sharding.html#operator-sharding\">Run multiple shards</a> to scale MongoDB horizontally</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/faq.html#faq-sidecar\">Deploy custom sidecar containers</a> to extend operators and MongoDB capabilities in Kubernetes</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/operator.html#finalizers\">Automatically clean up Persistent Volume Claims</a> (PVC) once a database cluster is removed</li>\n</ul>\n<p>Today we will look into these new features, the use cases, and highlight some architectural and technical decisions we made when implementing them.</p>\n<h2>Sharding</h2>\n<p>The 1.6.0 release of our Operator introduced single shard support, which we highlighted in <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/01/06/one-shard-support-in-kubernetes-operator-for-percona-server-for-mongodb/\">this blog post</a> and explained why it makes sense. But horizontal scaling is not possible without support for multiple shards.</p>\n<h3>Adding a Shard</h3>\n<p>A new shard is just a new <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/replication/\">ReplicaSet</a> which can be added under spec.replsets in cr.yaml:</p><pre class=\"crayon-plain-tag\">spec:\n  ...\n  replsets:\n  - name: rs0\n    size: 3\n  ....\n  - name: rs1\n    size: 3\n  ...</pre><p>Read more on <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/sharding.html\">how to configure sharding</a>.</p>\n<p>In the Kubernetes world, a MongoDB ReplicaSet is a <a target=\"_blank\" href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\">StatefulSet</a> with a number of pods specified in<span> <pre class=\"crayon-plain-tag\">spec.replsets.[].size</pre></span> variable.</p>\n<p>Once pods are up and running, the Operator does the following:</p>\n<ul>\n<li aria-level=\"1\">Initiates ReplicaSet by connecting to newly created pods running mongod</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Connects to mongos and adds a shard with </span><a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/method/sh.addShard/\"><span>sh.addShard()</span></a><span> command</span><br />\n<h1><span><img loading=\"lazy\" class=\"aligncenter wp-image-74787 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard.png\" alt=\"adding a shard mongodb operator\" width=\"879\" height=\"639\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard.png 879w, https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard-300x218.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard-200x145.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard-367x267.png 367w\" sizes=\"(max-width: 879px) 100vw, 879px\" /></span></h1>\n</li>\n</ul>\n<p>Then the output of db.adminCommand({ listShards:1 }) will look like this:</p><pre class=\"crayon-plain-tag\">        \"shards\" : [\n                {\n                        \"_id\" : \"replicaset-1\",\n                        \"host\" : \"replicaset-1/percona-cluster-replicaset-1-0.percona-cluster-replicaset-1.default.svc.cluster.local:27017,percona-cluster-replicaset-1-1.percona-cluster-replicaset-1.default.svc.cluster.local:27017,percona-cluster-replicaset-1-2.percona-cluster-replicaset-1.default.svc.cluster.local:27017\",\n                        \"state\" : 1\n                },\n                {\n                        \"_id\" : \"replicaset-2\",\n                        \"host\" : \"replicaset-2/percona-cluster-replicaset-2-0.percona-cluster-replicaset-2.default.svc.cluster.local:27017,percona-cluster-replicaset-2-1.percona-cluster-replicaset-2.default.svc.cluster.local:27017,percona-cluster-replicaset-2-2.percona-cluster-replicaset-2.default.svc.cluster.local:27017\",\n                        \"state\" : 1\n                }\n        ],</pre><p></p>\n<h3></h3>\n<h3>Deleting a Shard</h3>\n<p>Percona Operators are built to simplify the deployment and management of the databases on Kubernetes. Our goal is to provide resilient infrastructure, but the operator does not manage the data itself. Deleting a shard requires moving the data to another shard before removal, but there are a couple of caveats:</p>\n<ul>\n<li aria-level=\"1\">Sometimes data is not moved automatically by MongoDB &#8211; unsharded collections or jumbo chunks</li>\n<li aria-level=\"1\">We hit the storage problem &#8211; what if another shard does not have enough disk space to hold the data?</li>\n</ul>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74790 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-1024x475.png\" alt=\"shard does not have enough disk space to hold the data\" width=\"900\" height=\"417\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-1024x475.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-300x139.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-200x93.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-367x170.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3.png 1420w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>There are a few choices:</p>\n<ol>\n<li aria-level=\"1\">Do not touch the data. The user needs to move the data manually and then the operator removes the empty shard.</li>\n<li aria-level=\"1\">The operator decides where to move the data and deals with storage issues by upscaling if necessary.\n<ul>\n<li aria-level=\"2\">Upscaling the storage can be tricky, as it requires certain capabilities from the Container Storage Interface (CNI) and the underlying storage infrastructure.</li>\n</ul>\n</li>\n</ol>\n<p>For now, we decided to pick option #1 and won’t touch the data, but in future releases, we would like to work with the community to introduce fully-automated shard removal.</p>\n<p>When the user wants to remove the shard now, we first check if there are any non-system databases present on the ReplicaSet. If there are none, the shard can be removed:</p><pre class=\"crayon-plain-tag\">func (r *ReconcilePerconaServerMongoDB) checkIfPossibleToRemove(cr *api.PerconaServerMongoDB, usersSecret *corev1.Secret, rsName string) error {\n  systemDBs := map[string]struct{}{\n    \"local\": {},\n    \"admin\": {},\n    \"config\":  {},\n  }</pre><p></p>\n<h1><img loading=\"lazy\" class=\"aligncenter wp-image-74789 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2.png\" alt=\"delete a shard\" width=\"963\" height=\"668\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2.png 963w, https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2-300x208.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2-200x139.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2-367x255.png 367w\" sizes=\"(max-width: 963px) 100vw, 963px\" /></h1>\n<h2>Custom Sidecars</h2>\n<p>The sidecar container pattern allows users to extend the application without changing the main container image. They leverage the fact that all containers in the pod share storage and network resources.</p>\n<p>Percona Operators have built-in support for <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> to gain monitoring insights for the databases on Kubernetes, but sometimes users may want to expose metrics to other monitoring systems.  Lets see how <a target=\"_blank\" href=\"https://github.com/percona/mongodb_exporter\">mongodb_exporter</a> can expose metrics running as a sidecar along with ReplicaSet containers.</p>\n<p>1. Create the monitoring user that the exporter will use to connect to MongoDB. Connect to mongod in the container and create the user:</p><pre class=\"crayon-plain-tag\">&#62; db.getSiblingDB(\"admin\").createUser({\n    user: \"mongodb_exporter\",\n    pwd: \"mysupErpassword!123\",\n    roles: [\n      { role: \"clusterMonitor\", db: \"admin\" },\n      { role: \"read\", db: \"local\" }\n    ]\n  })</pre><p>2. Create the Kubernetes secret with these login and password. Encode both the username and password with base64:</p><pre class=\"crayon-plain-tag\">$ echo -n mongodb_exporter | base64\nbW9uZ29kYl9leHBvcnRlcg==\n$ echo -n 'mysupErpassword!123' | base64\nbXlzdXBFcnBhc3N3b3JkITEyMw==</pre><p>Put these into the secret and apply:</p><pre class=\"crayon-plain-tag\">$ cat mongoexp_secret.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: mongoexp-secret\ndata:\n  username: bW9uZ29kYl9leHBvcnRlcg==\n  password: bXlzdXBFcnBhc3N3b3JkITEyMw==\n\n$ kubectl apply -f mongoexp_secret.yaml</pre><p>3. Add a sidecar for mongodb_exporter into cr.yaml and apply:</p><pre class=\"crayon-plain-tag\">replsets:\n- name: rs0\n  ...\n  sidecars:\n  - image: bitnami/mongodb-exporter:latest\n    name: mongodb-exporter\n    env:\n    - name: EXPORTER_USER\n      valueFrom:\n        secretKeyRef:\n          name: mongoexp-secret\n          key: username\n    - name: EXPORTER_PASS\n      valueFrom:\n        secretKeyRef:\n          name: mongoexp-secret\n          key: password\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    - name: MONGODB_URI\n      value: \"mongodb://$(EXPORTER_USER):$(EXPORTER_PASS)@$(POD_IP):27017\"\n    args: [\"--web.listen-address=$(POD_IP):9216\"\n\n$ kubectl apply -f deploy/cr.yaml</pre><p>All it takes now is to configure the monitoring system to fetch the metrics for each mongod Pod. For example, <a target=\"_blank\" href=\"https://github.com/prometheus-operator/prometheus-operator\">prometheus-operator</a> will start fetching metrics once annotations are added to ReplicaSet pods:</p><pre class=\"crayon-plain-tag\">replsets:\n- name: rs0\n  ...\n  annotations:\n    prometheus.io/scrape: 'true'\n    prometheus.io/port: '9216'</pre><p></p>\n<h2>PVCs Clean Up</h2>\n<p>Running CICD pipelines that deploy MongoDB clusters on Kubernetes is a common thing. Once these clusters are terminated, the Persistent Volume Claims (PVCs) are not. We have now added automation that removes PVCs after cluster deletion. We rely on Kubernetes <a target=\"_blank\" href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#finalizers\">Finalizers</a> &#8211; asynchronous pre-delete hooks. In our case we hook the finalizer to the Custom Resource (CR) object which is created for the MongoDB cluster.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74788 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1.png\" alt=\"PVCs Clean Up\" width=\"732\" height=\"501\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1.png 732w, https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1-300x205.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1-200x137.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1-367x251.png 367w\" sizes=\"(max-width: 732px) 100vw, 732px\" /></p>\n<p>A user can enable the finalizer through cr.yaml in the metadata section:</p><pre class=\"crayon-plain-tag\">metadata:\n  name: my-cluster-name\n  finalizers:\n     - delete-psmdb-pvc</pre><p></p>\n<h3>Conclusion</h3>\n<p>Percona is committed to providing production-grade database deployments on Kubernetes. Our <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/RN/Kubernetes-Operator-for-PSMONGODB-RN1.7.0.html\">Percona Kubernetes Operator for Percona Server for MongoDB</a> is a feature-rich tool to deploy and manage your MongoDB clusters with ease. Our Operator is free and open source. Try it out by following the documentation <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/index.html\">here</a> or help us to make it better by contributing your code and ideas to our <a target=\"_blank\" href=\"https://github.com/percona/percona-server-mongodb-operator/\">Github repository</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 10 Mar 2021 17:35:29 +0000","feedId":11,"bgimg":"","linkMd5":"927214461581e653db7f74f537604e7a","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn47@2020_6/2021/04/03/04-49-23-991_0acd1d41d9050e75.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn64@2020_3/2021/04/03/04-49-21-249_bc15442cb23942eb.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn4@2020_5/2021/04/03/04-49-14-431_60cb0436e9b1f552.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-1024x475.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn96@2020_2/2021/04/03/04-49-48-564_14ff1cb4844d015c.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn59@2020_4/2021/04/03/04-49-13-696_606c7d7f493309d5.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn76@2020_6/2021/04/03/04-49-18-327_01e988315ffa4502.webp"},"publishedOrCreatedDate":1617425343791},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Bare Systemd Method to Create an XFS Mount","link":"https://www.percona.com/blog/?p=74401","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Bare Systemd Method to Create an XFS Mount\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p style=\"padding-left: 40px;\"><i><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-74492\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-300x168.png\" alt=\"Bare Systemd Method to Create an XFS Mount\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />For MongoDB data directories only XFS is recommended. The ext4 filesystem isn&#8217;t so bad but when there are a very, very high number of random accesses (which WiredTiger can reach) it can hit a bottleneck. To be fair most deployments will never hit this bottleneck, but it does remain an official production recommendation of MongoDB to only use XFS, and you get annoying warnings until you do.</span></i></p>\n<p><span>On a fresh cloud server instance for your MongoDB hosts, it would be helpful if they always booted up with a flexibly-attached XFS mount for a MongoDB data directory. Your cloud service possibly isn&#8217;t making this easy though. E.g. you can get a fresh, network-attached block device on demand with each new virtual server instance but there is no &#8220;xfs&#8221; option available in that template configuration.</span></p>\n<p style=\"padding-left: 40px;\"><i><span>If you script or configure something at the cloud service API level (eg. launch using AWS CLI scripts in AWS EC2, or use </span></i><a target=\"_blank\" href=\"https://cloudinit.readthedocs.io/en/latest/topics/availability.html\"><i><span>cloud-init</span></i></a><i><span> for a multi-vendor way) this is achievable. But let&#8217;s assume you have some one-time testing, or something like that, where the time investment for a cloud service script/recipe won&#8217;t pay off.</span></i></p>\n<h2>The Ideal Method &#8211; Which Doesn&#8217;t Work Yet</h2>\n<p><span>Ideally, you would create a system mount unit, specify the filesystem type, and systemd would take care of formatting a freshly-attached block device if the filesystem wasn&#8217;t initialized yet.</span></p>\n<p><span>But this is not supported so far (</span><a target=\"_blank\" href=\"https://github.com/systemd/systemd/issues/10014\"><span>systemd github issue #10014</span></a><span>). I&#8217;ve not been able to make the &#8216;x-systemd.makefs&#8217; expansion feature added around systemd-fstab-generator work in AWS Linux 2 instances either.</span></p>\n<p><span>I assume you&#8217;re in the same situation if you&#8217;ve landed here.</span></p>\n<h2>Bare systemd Units to Do it All</h2>\n<p><span>One systemd unit is required for each of these steps: </span><i><span>mkfs.xfs</span></i><span>, </span><i><span>mount</span></i><span>, and </span><i><span>chown mongod:mongod</span></i><span>. The key points are:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Require the </span><i><span>mkfs.xfs</span></i><span> command to be run when block device is loaded by systemd, and do so before target level &#8220;local-fs.target&#8221; (or &#8220;local-fs-pre.target&#8221;)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Making a mount type service unit to mount the block device at the desired directory (eg. /data)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>After the mount unit is up, run the </span><i><span>chown</span></i><span> command</span></li>\n</ul>\n<p><span>The following example assumes:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>&#8220;mongod&#8221; user already exists. (Create manually, or get it incidentally as a MongoDB package is installed.)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>/dev/xvdb</span><span> is the device path.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>/data</span><span> is the path it will be mounted at.</span></li>\n</ul>\n<h3><span><span style=\"color: #999999;\">/etc/systemd/system/</span>mkfs.xfs_xvdb.service</span></h3>\n<p></p><pre class=\"crayon-plain-tag\">[Unit]\nDescription=oneshot systemd service to XFS format /dev/xvdb device\nAfter=dev-xvdb.device\nRequires=dev-xvdb.device\n\n[Service]\nType=oneshot\n#Note the leading \"-\" in ExecStart. In systemd exec directives this means ignore non-zero exit code.\n#systemd init will continue peacefully this way, even if mkfs.xfs error-exits in subsequent restarts because the block device was formatted already.\nExecStart=-/usr/sbin/mkfs.xfs /dev/xvdb\n\n[Install]\nWantedBy=local-fs.target</pre><p><span>Enable with: <pre class=\"crayon-plain-tag\">sudo systemctl enable mkfs.xfs_xvdb.service</pre> </span></p>\n<h3><span><span style=\"color: #999999;\">/etc/systemd/system/</span>data.mount</span></h3>\n<p><span>(!) Don&#8217;t forget to first create the </span><span>/data</span><span> directory in your server image&#8217;s root filesystem to be the mount point for the </span><i><span>data.mount</span></i><span> unit.</span></p><pre class=\"crayon-plain-tag\">[Unit]\nDescription=systemd unit to mount /dev/xvdb at /data\nAfter=mkfs.xfs_xvdb.service\nRequires=mkfs.xfs_xvdb.service\n\n[Mount]\nWhat=/dev/xvdb\n#N.b. \"Where\" must be reflected in the unit name.\n#Eg. if it is for path \"/data\" we must name this unit file \"data.mount\".\n#Substitute \"-\" in place of non-root \"/\" path delimiters. Eg. /srv/xyz --&#62; \"srv-xyz.mount\"\nWhere=/data\nType=xfs\n\n[Install]\nWantedBy=multi-user.target</pre><p><span>Enable with: <pre class=\"crayon-plain-tag\">sudo systemctl enable data.mount</pre> </span></p>\n<h3><span><span style=\"color: #999999;\">/etc/systemd/system/</span>set_mongodb_data_dir_owner.service</span></h3>\n<p></p><pre class=\"crayon-plain-tag\">[Unit]\nDescription=oneshot systemd service to chown mongod:mongod /data\nAfter=data.mount\nRequires=data.mount\n\n[Service]\nType=oneshot\n#Using -v (verbose) to produce message that can be seen in the systemd journal. This is optional.\nExecStart=/usr/bin/chown -v mongod:mongod /data\n\n[Install]\nWantedBy=multi-user.target</pre><p><span>Enable with: <pre class=\"crayon-plain-tag\">sudo systemctl enable set_mongodb_data_dir_owner.service</pre> </span><span> </span></p>\n<p><span>As you&#8217;re building a server image at this stage you don&#8217;t have to start the units above &#8211; just enable, then save the server image. Yes of course it should be tested, but the real goal is making it work in new server instances. So, confirm these systemd units are automatically executed after the startup of those.</span></p>\n<p>&#160;</p>\n<h2>The Output in systemd Journal</h2>\n<p><span>When a new server instance is started, the journal messages for these three units should look something like this:</span></p>\n<h4><span>mkfs.xfs_xvdb.service</span></h4>\n<p></p><pre class=\"crayon-plain-tag\">~]$ journalctl -u mkfs.xfs_xvdb.service\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Starting Formats /dev/xvdb device with XFS filesystem...\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2494]: meta-data=/dev/xvdb              isize=512    agcount=4, agsize=524288 blks\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2494]: =                       sectsz=512   attr=2, projid32bit=1\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2494]: =                       crc=1        finobt=1, sparse=0\n...\n...\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2494]: realtime =none                   extsz=4096   blocks=0, rtextents=0\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Started Formats /dev/xvdb device with XFS filesystem.</pre><p><i>Or, if after Reboot:</i></p><pre class=\"crayon-plain-tag\">&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Starting Formats /dev/xvdb device with XFS filesystem...\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2497]: mkfs.xfs: /dev/xvdb contains a mounted filesystem\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2497]: Usage: mkfs.xfs\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2497]: /* blocksize */                [-b log=n|size=num]\n...\n...\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2497]: xxxm (xxx MiB), xxxg (xxx GiB), xxxt (xxx TiB) or xxxp (xxx PiB).\n&#60;timestamp&#62; &#60;hostname&#62; mkfs.xfs[2497]: &#60;value&#62; is xxx (512 byte blocks).\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Started Formats /dev/xvdb device with XFS filesystem.</pre><p><span>Note that </span><i><span>mkfs.xfs</span></i><span> failing and being ignored in the second or later restarts is planned and expected given the way this systemd service unit was written.</span></p>\n<h4><span>data.mount</span></h4>\n<p></p><pre class=\"crayon-plain-tag\">~]$ journalctl -u data.mount\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Mounting Mount block device xvdb at /data...\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Mounted Mount block device xvdb at /data.</pre><p></p>\n<h4><span>set_mongodb_data_dir_owner.service</span></h4>\n<p></p><pre class=\"crayon-plain-tag\">~]$ journalctl -u set_mongodb_data_dir_owner.service\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Starting Ensures mongod is owner of mounted XFS directory at /data...\n&#60;timestamp&#62; &#60;hostname&#62; chown[2549]: changed ownership of ‘/data’ from root:root to mongod:mongod\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Started Ensures mongod is owner of mounted XFS directory at /data</pre><p><i>Or, if after Reboot:</i></p><pre class=\"crayon-plain-tag\">&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Starting oneshot systemd service to chown mongod:mongod /data...\n&#60;timestamp&#62; &#60;hostname&#62; chown[2549]: ownership of ‘/data’ retained as mongod:mongod\n&#60;timestamp&#62; &#60;hostname&#62; systemd[1]: Started oneshot systemd service to chown mongod:mongod /data.</pre><p></p>\n<h3>The Wrap-Up</h3>\n<p>systemd unit types and activation rules are tightly coupled with core Linux. You can use them to do the right thing, at the right time.</p>\n<p>A server setup job that can be reduced to single commands such as /usr/bin/mkdir, /usr/sbin/mkfs*, /usr/bin/chown etc. is an opportunity for you to implement a minimalist systemd config project.</p>\n<p>Scripts with systemd are fine too &#8211; make them the command that is run by ExecStart=&#8230; &#8211; but that&#8217;s a different feeling to being able to see everything with just &#8220;systemctl cat &#60;unit_name&#62;&#8221; and &#8220;systemctl status&#8221;.</p>\n<p>Typically systemd units will be run every bootup, not just the first one. A command such as mkfs.xfs should be only run once, however, so a trick is needed. This example relied on the fact that mkfs.xfs will not damage an existing filesystem (without -f force at least). Putting &#8220;-&#8221; at the start of /usr/sbin/mkfs.xfs is how the &#8216;filesystem already exists&#8217; exit code is ignored.</p>\n","descriptionType":"html","publishedDate":"Mon, 15 Feb 2021 18:29:11 +0000","feedId":11,"bgimg":"","linkMd5":"f7c6d6db32b6967f9cdedeaf02051422","bgimgJsdelivr":"","metaImg":"","author":"Akira Kurogane","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn24@2020_4/2021/04/03/04-49-15-893_f151b0dc68abd10d.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn80@2020_4/2021/04/03/04-49-18-008_f79500e911042718.webp"},"publishedOrCreatedDate":1617425343870},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Webinar March 24: Introduction to pg_stat_monitor","link":"https://www.percona.com/blog/?p=74743","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Webinar Introduction to pg_stat_monitor\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p>Join Peter Zaitsev, Percona CEO, and Ibrar Ahmed, Percona Sr. Software Engineer, as they discuss pg_stat_monitor!</p>\n<p>If you&#8217;re tasked with optimizing PostgreSQL performance, chances are you&#8217;re relying on the pg_stat_statements extension to capture information about query performance. While this extension provides a lot of great insights, PostgreSQL makes it possible to go even further! In this webinar, we introduce <a target=\"_blank\" href=\"https://www.percona.com/blog/2021/01/19/pg_stat_monitor-a-new-way-of-looking-at-postgresql-metrics/\">pg_stat_monitor – Open Source extension</a>, based on pg_stat_statements which provide such advanced query performance details. We talk about additional design goals we had and why those are important, additional information we capture, and how you can use it to get your PostgreSQL running even faster.</p>\n<p>Please join <strong>Peter Zaitsev</strong>, Percona CEO, and <strong>Ibrar Ahmed</strong>, Percona Sr. Software Engineer, on <strong>Wednesday</strong>, <strong>March 24</strong>, <strong>2021</strong>, at <strong>1:00 PM EST</strong> for their webinar <strong>Introduction to pg_stat_monitor</strong>.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://percona.zoom.us/webinar/register/4116081511791/WN_p5M5qafiSI2C1waMLLZfmg\" rel=\"noopener\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://percona.zoom.us/webinar/register/4116081511791/WN_p5M5qafiSI2C1waMLLZfmg\">sign up anyway</a>, and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Tue, 09 Mar 2021 13:41:41 +0000","feedId":11,"bgimg":"","linkMd5":"fbff45194291c54a093ef301d60ae273","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn39@2020_3/2021/04/03/04-49-16-492_dec5e4e3a513f0fa.webp"},"publishedOrCreatedDate":1617425343773},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Percona Monitoring and Management 2.15 Brings Even MORE Reasons to Upgrade to PMM v2!","link":"https://www.percona.com/blog/?p=74644","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Monitoring and Management - 2.15\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74697\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-300x168.png\" alt=\"Percona Monitoring and Management - 2.15\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In November of 2020, we announced that in early 2021 Percona was slated to release a version of <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM) v2 that would include all of the critical functionality users of PMM v1 have come to know and love over the years. In our <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/11/23/impact-of-percona-monitoring-and-management-get-latest-command-change/\">initial blog</a>, we also addressed some of the specifics related to features for which we had not yet achieved parity such as <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/02/12/percona-monitoring-management-pmm-support-external-monitoring-services-yes/\">external services</a>, <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/10/22/annotations-provide-context-to-timelines-in-percona-monitoring-and-management/\">annotations</a>, <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/06/26/mongodb-explain-using-pmm-qan-for-mongodb-query-analytics/\">MongoDB Explain</a>, and <a target=\"_blank\" href=\"https://www.percona.com/blog/2019/03/12/pmms-custom-queries-in-action-adding-a-graph-for-innodb-mutex-waits/\">custom collectors per service</a> to name a few.</p>\n<p>Well friends the time has come, and we’re happy to announce that any remaining critical parity items have been completed&#8230; but even MORE importantly, the enhancements to Percona Monitoring and Management v2 are ones you won’t want to miss out on. This means one thing: if you haven’t already &#8212; <strong>IT’S TIME TO UPGRADE!</strong></p>\n<p>Some of the most recent work included in the PMM 2.15 release include:</p>\n<h3>Disable collectors while adding node/service to monitoring:</h3>\n<ul>\n<li aria-level=\"1\">PMM users can disable any collector PMM utilizes to gather metrics. In certain situations, disabling the collector(s) prevents PMM from flooding logs or saves infrastructure resources if the given metrics simply aren’t needed. This is an early step towards providing our users full management capabilities when it comes to the metrics they collect. We will continue to expand this effort in future releases.</li>\n</ul>\n<h3>External services monitoring:</h3>\n<ul>\n<li aria-level=\"1\">Prior to this release, PMM v2 did not support external services monitoring on systems that couldn’t also run the PMM client. BUT as of this week, any non-native services supported by PMM can now be monitored with external services monitoring. You can see the list of possible exporters to be used here: <a target=\"_blank\" href=\"https://prometheus.io/docs/instrumenting/exporters/\">https://prometheus.io/docs/instrumenting/exporters/</a>.</li>\n</ul>\n<h3>Provide summary information for systems (pt-*-summary actions):</h3>\n<ul>\n<li aria-level=\"1\">With the addition of “pt-*-summary” in PMM v2, users can now view summary information pertaining to services and nodes within their PMM dashboard. Summary information is provided in the format of pt-*-summary tools output, in order to simplify the portability of this data. This format will also be preserved when summary information is shared with the Percona Support team, simplifying their investigations of issues.</li>\n</ul>\n<p><strong><em>Note: “pt-*-summary” includes formats for: </em></strong></p>\n<ul>\n<li aria-level=\"1\">pt-mysql-summary</li>\n<li aria-level=\"1\">pt-mongodb-summary</li>\n<li aria-level=\"1\">pt-pg-summary</li>\n<li aria-level=\"1\">pt-summary</li>\n</ul>\n<p>&#160;</p>\n<h3>HAProxy support by PMM</h3>\n<ul>\n<li aria-level=\"1\">Users are now able to add HAProxy services to be monitored in PMM v2. This allows users who use HAProxy in their HA configuration to have this component also monitored by PMM.</li>\n</ul>\n<h3>As a refresher, PMM v2 users also benefit from other valuable enhancements over PMM v1, including:</h3>\n<ul>\n<li aria-level=\"1\">A complete rewrite of the Query Analytics (QAN) tool, including improved speed, global sparkline hover, filtering, new dimensions to collect data, and rich searching capabilities.</li>\n<li aria-level=\"1\">Our <a target=\"_blank\" href=\"https://www.percona.com/blog/2020/06/29/security-threat-tool-design-in-percona-monitoring-and-management/\">Security Threat Tool</a> (STT) so that you not only can monitor database performance but also database security vulnerabilities.</li>\n<li aria-level=\"1\">A robust expansion of MongoDB and PostgreSQL support (along with continued improvements for MySQL).</li>\n<li aria-level=\"1\">Integration with external AlertManager to create and deploy alerting and “integrated alerting” to provide native alerting inside PMM itself.</li>\n<li aria-level=\"1\">Global and local annotations across nodes and services to highlight key events for correlation. Get to the “WHY” and easily see changes occurring in your environment(s).</li>\n</ul>\n<h3>There is no better time than now to upgrade to Percona Monitoring and Management v2!</h3>\n<p>One last reminder, we are flipping the latest version flag to the PMM v2 series from PMM v1 with this release.</p>\n<p>Please note that this does NOT mean that we are “sunsetting” PMM v1 and will no longer support that application. While we are not creating new features for PMM v1, we do continue to maintain it with critical bug fixes as needed as well as support for the product for those customers on a support contract. This maintenance and support will continue until PMM moves to version 3.x at a date to be determined in the future.</p>\n<p>Let us know your thoughts on these new PMM v2 features as well as any ideas you have for improvement.</p>\n<p style=\"text-align: center;\"><b>Download and Try </b><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\"><b>Percona Monitoring and Management</b></a><b> Today!</b></p>\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/release-notes/2.15.0.html\">Read the PMM 2.15 full release notes here</a></p>\n","descriptionType":"html","publishedDate":"Tue, 02 Mar 2021 13:59:10 +0000","feedId":11,"bgimg":"","linkMd5":"82fb984c6056ef4f100542a596e971d9","bgimgJsdelivr":"","metaImg":"","author":"Diana Muina","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn4@2020_2/2021/04/03/04-49-19-366_a83904df2ca33634.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn87@2020_2/2021/04/03/04-49-06-511_fbf707727f76d771.webp"},"publishedOrCreatedDate":1617425343781},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Tame Kubernetes Costs with Percona Monitoring and Management and Prometheus Operator","link":"https://www.percona.com/blog/?p=74425","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Kubernetes Costs Percona Monitoring and Management\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74463\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-300x168.png\" alt=\"Kubernetes Costs Percona Monitoring and Management\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />More and more companies are adopting Kubernetes, but after some time they see an unexpected growth around cloud costs. Engineering teams did their part in setting up auto-scalers, but <strong>the cloud bill is still growing</strong>. Today we are going to see how <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM) can help with monitoring Kubernetes and reducing the costs of the infrastructure.</p>\n<h2>Get the Metrics</h2>\n<h3>Overview</h3>\n<p>Prometheus Operator is a great tool to monitor Kubernetes as it deploys a full monitoring stack (prometheus, grafana, alertmanager, node exporters) and works out of the box. But if you have multiple k8s clusters, then it would be great to have a single pane of glass from which to monitor them all.</p>\n<p>To get there I will have Prometheus Operator running on each cluster and pushing metrics to my PMM server. Metrics will be stored in <a target=\"_blank\" href=\"https://github.com/VictoriaMetrics/VictoriaMetrics\">VictoriaMetrics</a> time-series DB, which PMM uses by default since the December 2020 release of version <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/details/victoria-metrics.html\">2.12</a>.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74426\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-1024x670.png\" alt=\"Prometheus Operator\" width=\"700\" height=\"458\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-1024x670.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-300x196.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-200x131.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-367x240.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-560x367.png 560w, https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1.png 1160w\" sizes=\"(max-width: 700px) 100vw, 700px\" /></p>\n<h3>PMM-server</h3>\n<p><span>I followed </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/server/docker.html\"><span>this manual</span></a><span> to the letter to install my PMM server with docker. Don’t forget to open the HTTPS port on your firewall, so that you can reach the UI from your browser, and so that the k8s clusters can push their metrics to VictoriaMetrics through NGINX.</span></p>\n<h3>Prometheus Operator</h3>\n<p><span>On each Kubernetes cluster, I will now install </span><a target=\"_blank\" href=\"https://github.com/prometheus-operator/prometheus-operator\"><span>Prometheus Operator</span></a><span> to scrape the metrics and send them to PMM. Bear in mind that Helm charts are stored in </span><a target=\"_blank\" href=\"https://github.com/prometheus-community/helm-charts\"><span>prometheus-community</span></a><span> repo.</span></p>\n<p><strong>Add helm repository</strong></p><pre class=\"crayon-plain-tag\">helm repo add prometheus-community https://prometheus-community.github.io/helm-charts</pre><p><strong>Prepare the configuration before installing the operator</strong></p><pre class=\"crayon-plain-tag\">$ cat values.yaml\nserviceAccounts:\n  alertmanager:\n    create: false\n\nalertmanager:\n  enabled: false\n\nconfigmapReload:\n  alertmanager:\n    enabled: false\n\nextraScrapeConfigs: |\n  remote_write:\n    - url: https://{PMM_USER}:{PMM_PASS}@{YOUR_PMM_HOST}/victoriametrics/api/v1/write\n\nserver:\n  global:\n    external_labels:\n      kubernetes_cluster_name: {UNIQUE_K8S_LABEL}</pre><p></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Disable alertmanager, as I will rely on PMM</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Add </span><a target=\"_blank\" href=\"https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write\"><span>remote_write</span></a><span> section to write metrics to PMM’s VictoriaMetrics storage</span>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>Use your PMM user and password to authenticate. The default username and password are admin/admin. It is highly recommended to change defaults, see how </span><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/server/index.html\"><span>here</span></a><span>.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span><pre class=\"crayon-plain-tag\">/victoriametrics</pre> endpoint is exposed through NGINX on PMM server</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"2\"><span>If you use https and a self-signed certificate you may need to disable TLS verification:</span></li>\n</ul>\n</li>\n</ul>\n<p></p><pre class=\"crayon-plain-tag\"> tls_config:\n   insecure_skip_verify: true</pre><p></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span><pre class=\"crayon-plain-tag\">external_labels</pre> section is important &#8211; it labels all the metrics sent from Prometheus. Each cluster must have a unique <pre class=\"crayon-plain-tag\">kubernetes_cluster_name</pre> </span><span>label to distinguish metrics once they are merged in VictoriaMetrics.</span></li>\n</ul>\n<p><strong>Create namespace and deploy</strong></p><pre class=\"crayon-plain-tag\">kubectl create namespace prometheus\nhelm install prometheus prometheus-community/prometheus -f values.yaml  --namespace=prometheus</pre><p></p>\n<h3></h3>\n<h3>Check</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>PMM Server is up &#8211; </span><b>check</b></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Prometheus Operators run on Kubernetes Clusters &#8211; </span><b>check</b></li>\n</ul>\n<p><span>Now let’s check if metrics are getting to PMM:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Go to PMM Server UI</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>On the left pick Explore</span></li>\n</ul>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74427 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/explore.png\" alt=\"PMM Server UI\" width=\"766\" height=\"389\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/explore.png 766w, https://www.percona.com/blog/wp-content/uploads/2021/02/explore-300x152.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/explore-200x102.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/explore-367x186.png 367w\" sizes=\"(max-width: 766px) 100vw, 766px\" /></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\">Run the query <pre class=\"crayon-plain-tag\">kube_node_info{kubernetes_cluster_name=\"UNIQUE_K8S_LABEL\"}</pre></li>\n</ul>\n<p><span>It should return the information about the Nodes running on the cluster with UNIQUE_K8S_LABEL. If it does &#8211; all good, metrics are there.</span></p>\n<h2>Monitor the Costs</h2>\n<p><span>The main reasons for the growth of the cloud bill are computing and storage. Kubernetes can scale up adding more and more nodes, skyrocketing compute costs. </span></p>\n<p><span>We are going to add two dashboards to the PMM Server which would equip us with a detailed understanding of how resources are used and what should be tuned to reduce the number of nodes in the cluster or change instance types accordingly:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><a target=\"_blank\" href=\"https://github.com/spron-in/k8s-grafana-dashboards/blob/main/K8S%20-%20Overview.json\"><span>Cluster overview dashboard</span></a></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><a target=\"_blank\" href=\"https://github.com/spron-in/k8s-grafana-dashboards/blob/main/K8S%20-%20Namespace%20and%20Pods.json\"><span>Namespace and Pods dashboard</span></a></li>\n</ol>\n<p><span>Import these dashboards in PMM:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74428 size-full\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard.png\" alt=\"dashboards in PMM\" width=\"985\" height=\"369\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard.png 985w, https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard-300x112.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard-200x75.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard-367x137.png 367w\" sizes=\"(max-width: 985px) 100vw, 985px\" /></p>\n<h3>Dashboard #1 &#8211; Cluster Overview</h3>\n<p><span>The goal of this d</span><span>ashboard is to provide a quick overview of the cluster and its workloads.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74429 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-1024x258.png\" alt=\"Cluster Overview\" width=\"900\" height=\"227\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-1024x258.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-300x76.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-200x50.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-1536x388.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-367x93.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary.png 1859w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p><span>The cluster on the screenshot has some room for improvement in utilization. It has a capacity of 1.6 thousand CPU cores but utilizes only 146 cores (~9%). Memory utilization is better &#8211; ~62%, but can be improved as well.</span></p>\n<p><span>Quick take:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>It is possible to reduce # of nodes and get utilization to at least 80%</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Looks like workloads in this cluster are mostly memory bound, so it would be wiser to run nodes with more memory and less CPU.</span></li>\n</ul>\n<p><span>Graphs in the CPU/Mem Request/Limit/Capacity section gives a detailed view of resource usage over time:</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74432 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-1024x258.png\" alt=\"CPU/Mem Request/Limit/Capacity section\" width=\"900\" height=\"227\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-1024x258.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-300x76.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-200x50.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-1536x387.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-367x93.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph.png 1883w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p><span>Another two interesting graphs would show us the top 20 namespaces that are wasting resources. It is calculated as the difference between requests and real utilization for CPU and Memory. The values on this graph can be negative if requests for the containers are not set.</span></p>\n<p><span>This dashboard also has a graph showing persistent volume claims and their states. It can potentially help to reduce the number of volumes spun up on the cloud.</span></p>\n<h3>Dashboard #2 &#8211; Namespace and Pod</h3>\n<p><span>Now that we have an overview, it is time to dive deeper into the details. At the top, this dashboard allows the user to choose the Cluster, the Namespace, and the Pod.</span></p>\n<p><span>At first, the user sees Namespace details: Quotas (might be empty if </span><a target=\"_blank\" href=\"https://kubernetes.io/docs/concepts/policy/resource-quotas/\"><span>Resource Quotas</span></a><span> are not set for the namespace), requests, limits, and real usage for CPU, Memory, Pods, and Persistent Volume Claims.</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74430 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-1024x292.png\" alt=\"Namespace and Pod\" width=\"900\" height=\"257\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-1024x292.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-300x86.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-200x57.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-1536x439.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-367x105.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces.png 1874w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p><span>The Namespace on the screenshot utilizes almost zero CPU cores but requests 20+ cores. If requests are tuned properly, then the capacity required to run the workloads would drop and the number of nodes can be reduced.</span></p>\n<p><span>The next valuable insight that the user can pick from this dashboard is real Pod utilization &#8211; CPU, Memory, Network, and disks (only local storage).</span></p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74431 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-1024x299.png\" alt=\"Pod CPU Usage\" width=\"900\" height=\"263\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-1024x299.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-300x88.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-200x58.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-1536x449.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-367x107.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization.png 1840w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p><span>In the case above you can see CPU and Memory container-level utilization for Prometheus Pod, which is shipping the metrics on one of my Kubernetes clusters.</span></p>\n<h4>Summary</h4>\n<p><span>This blog post equips you with the design to collect multiple Kubernetes clusters metrics in a single time-series database and expose them on the <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> UI through dashboards to analyze and gain insights. These insights help you drive your infrastructure costs down and highlight issues on the clusters.</span></p>\n<p><span>Also, look to PMM on Kubernetes for monitoring of your databases &#8211; see our demo </span><a target=\"_blank\" href=\"https://www.youtube.com/watch?v=jk1v8rdNYNI\"><span>here</span></a><span> and <a target=\"_blank\" href=\"https://www.percona.com/about-percona/contact\">contact Percona</a> if you are interested in learning more about how to become a Percona Customer, we are here to help!</span></p>\n<hr />\n<p><strong>The call for papers for Percona Live is open</strong>. We&#8217;d love to receive submissions on topics related to open-source databases such as MySQL, MongoDB, MariaDB, and PostgreSQL. To find out more visit <a target=\"_blank\" class=\"PrimaryLink BaseLink\" href=\"http://percona.com/live\" target=\"_blank\" rel=\"noreferrer noopener\">percona.com/live</a>.</p>\n","descriptionType":"html","publishedDate":"Fri, 12 Feb 2021 17:23:54 +0000","feedId":11,"bgimg":"","linkMd5":"9b3c8c4ae697c9b277c681189244e353","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn64@2020_2/2021/04/03/04-49-17-945_dcd6bfbe09757110.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn16@2020_4/2021/04/03/04-49-22-660_9525d80903073c70.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-1024x670.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn68@2020_1/2021/04/03/04-49-17-673_ac61de0382dbba73.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/explore.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn7@2020_5/2021/04/03/04-49-19-350_0b8c4f0341a84ecb.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn69@2020_5/2021/04/03/04-49-05-157_84e7b7084f62013c.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-1024x258.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn72@2020_4/2021/04/03/04-49-11-923_2b77e5debabace4c.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-1024x258.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn83@2020_1/2021/04/03/04-49-21-069_c2ae6c9e34602f11.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-1024x292.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn57@2020_2/2021/04/03/04-49-05-325_73bc49ce5122fcd1.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-1024x299.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn68@2020_1/2021/04/03/04-49-08-377_e9cfb6662c36a3f2.webp"},"publishedOrCreatedDate":1617425343857},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Is a Session Analyzer a Good Tool to Simulate Real Traffic?","link":"https://www.percona.com/blog/?p=74624","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Session Analyzer traffic non production\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-75014\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-300x168.png\" alt=\"Session Analyzer traffic non production\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Starting a long time ago, we wanted to reproduce workload in a non-production environment, and there were different attempts to achieve that goal (</span><a target=\"_blank\" href=\"https://www.percona.com/blog/2012/10/25/replaying-database-load-with-percona-playback/\"><span>Query Playback</span></a><span> is just one of them). But there is another point of view, where you need to <a target=\"_blank\" href=\"https://www.percona.com/blog/2019/04/25/creating-custom-sysbench-scripts/\">write your own workload</a> to do so.</span></p>\n<h3>Both Have Pros and Cons</h3>\n<p><strong>Reproduce Workload</strong>:</p>\n<p>Pros:</p>\n<ul>\n<li>Simple to implement</li>\n<li>Ready to go</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>Need to rebuild the environment each time</li>\n</ul>\n<p><strong>Custom Scripts:</strong></p>\n<p>Pros:</p>\n<ul>\n<li>Possible to have a more realistic workload</li>\n<li>You can reuse the environment</li>\n<li>You can use Sysbench that allows you to change several options in your test like increasing threads or limiting throughput</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>You need to invest a lot of time to create the scripts to have a realistic workload</li>\n</ul>\n<h3>Is it Possible to Have the Best of Both Worlds?</h3>\n<p><span>My idea is simple; use the slow query log to get a usable template script of workload. This might sound simple, but it requires defining the steps needed:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>We need a slow query reader</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>We need to identify each query template</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>We need to keep track of the queries executed by session, as we want to simulate the sessions</span></li>\n</ul>\n<p><span>Another two important aspects will be to collect the data in the queries to create variables that will be filled up with valid functions and each session have &#8220;variables&#8221; that repeat across the whole execution. </span></p>\n<h2>Slow Query Reader</h2>\n<p><span>It is not complex, but we need to split the query into three pieces, so a query like this:</span></p><pre class=\"crayon-plain-tag\">SELECT `id`, `age` FROM `person` WHERE `birthdate` &#62; '2004-01-09'</pre><p><span>Will have this query template:</span></p><pre class=\"crayon-plain-tag\">SELECT `id`, `age` FROM `person` WHERE `birthdate` &#62; %s</pre><p><span>This data template:</span></p><pre class=\"crayon-plain-tag\">'%s-%s-%s'</pre><p><span>And the real data will be:</span></p><pre class=\"crayon-plain-tag\">2004 01 09</pre><p></p>\n<h2>Analyzing the Data Per Query</h2>\n<p><span>As we are going to have queries that execute the same query template with the same data template, we can collect the real data per position and process. For instance, if we have all these queries executed:</span></p><pre class=\"crayon-plain-tag\">SELECT `id`, `age` FROM `person` WHERE `birthdate` &#62; '2004-01-24';\nSELECT `id`, `age` FROM `person` WHERE `birthdate` &#62; '2004-12-01';\nSELECT `id`, `age` FROM `person` WHERE `birthdate` &#62; '2005-05-27';\nSELECT `id`, `age` FROM `person` WHERE `birthdate` &#62; '2005-09-13';</pre><p>We need to extract all this integer value to determine that in column1, values will be between 2004 and 2005, column2 values between 01 and 12, and for column3, between 01 and 27.</p>\n<p><span>The same analysis should be done to consider:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Integers and if they have some specific distribution</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Alpha or Alphanumerics value and their length</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Hexadecimal</span></li>\n</ul>\n<h2>Analyzing the Workload</h2>\n<p><span>As we want to reproduce the real workload, the queries need to be sent in the same order that they were executed by the application and we need to process the variables. For instance, if we have a session executing:</span></p><pre class=\"crayon-plain-tag\">SELECT `id`, `age` FROM `person` WHERE `birthdate` &#60; '2000-01-01';\nUPDATE `person` SET `col1`=5050 WHERE `id` = 10;\nUPDATE `person` SET `col2`='another value' WHERE `id` = 10;</pre><p>We need to identify the 10 as an app-level variable for the session that could be inside other values and strings. With this information, we can develop a session template, and we need to summarize this information as most of the time the applications execute the same queries in the same order but with different data.</p>\n<h2>Merging the Information Collected</h2>\n<p><span>Once we have the functions that generate the values to fill up the queries templates and the sessions template, we are able to simulate the workload. Sysbench will be able to get the data in files that are generated dynamically and send it to the database. </span></p>\n<h2>What’s Next?</h2>\n<p><span>I worked on a tool that does it, but perl and bash were not the best choices, so, now I’m already working on a tool written in C and using GLib. Hopefully, it will be published soon.</span></p>\n","descriptionType":"html","publishedDate":"Tue, 23 Mar 2021 15:02:09 +0000","feedId":11,"bgimg":"","linkMd5":"4b3e9d6af32194c291344246b19ca57c","bgimgJsdelivr":"","metaImg":"","author":"David Ducos","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn68@2020_1/2021/04/03/04-49-17-126_47d9f58641e2021e.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn32@2020_2/2021/04/03/04-49-47-647_a983fcdd589f81b3.webp"},"publishedOrCreatedDate":1617425343791},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"How To Automate Dashboard Importing in Percona Monitoring and Management","link":"https://www.percona.com/blog/?p=74548","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Automate Dashboard Importing in Percona Monitoring and Management\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75136\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-300x168.png\" alt=\"Automate Dashboard Importing in Percona Monitoring and Management\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />In this blog post, I’ll look at how to import custom dashboards into <a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management\">Percona Monitoring and Management</a> (PMM) 2.x, and give some tips on how to automate it.</p>\n<p>The number of dashboards in PMM2 is constantly growing. For example, we recently added a new HAProxy dashboard to <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-monitoring-and-management/2.x/release-notes/2.15.0.html\">the latest 2.15.0</a> release. Even though the PMM server has more than fifty dashboards, it&#8217;s not possible to cover all common server applications.</p>\n<p>The greatest source of dashboards is the official <a target=\"_blank\" href=\"https://grafana.com/grafana/dashboards\">Grafana site</a>. Here, anyone can share their own dashboards with the community or find already uploaded ones. Percona has its <a target=\"_blank\" href=\"https://grafana.com/orgs/perconalab\">own account</a> and publishes as-yet-unreleased or unique (non-PMM) dashboards.</p>\n<p>Each dashboard has its own number which can be used to refer to it. For example, <a target=\"_blank\" href=\"https://grafana.com/grafana/dashboards/12630\">12630</a> is assigned to the dashboard &#8220;MySQL Query Performance Troubleshooting&#8221;.<br />\n<img loading=\"lazy\" class=\"aligncenter wp-image-74671 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-1024x438.png\" alt=\"Percona Monitoring and Management Dashboard\" width=\"900\" height=\"385\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-1024x438.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-300x128.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-200x86.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-1536x657.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-367x157.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848.png 1559w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>You can download dashboards as JSON files and import them into your PMM2 installation using the UI.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74672 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-1024x541.png\" alt=\"PMM2\" width=\"900\" height=\"475\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-1024x541.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-300x159.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-200x106.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-1536x812.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-367x194.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312.png 1547w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\nThis is easy, but we are forgetting that dashboards can be updated by publishers as new revisions. So it&#8217;s possible that the dashboard has a bunch of useful changes that were published after you downloaded it. But, you keep using an old version of the dashboard.</p>\n<p>So the only way to use the latest dashboard version is to check <a target=\"_blank\" href=\"https://grafana.com/grafana/dashboards\">the site</a> from time to time. It can really be a pain in the neck, especially if you have to track more than one dashboard.</p>\n<p>This is why it&#8217;s time to take a look at <strong>automation</strong>. Grafana has a very powerful <a target=\"_blank\" href=\"https://grafana.com/docs/grafana/latest/http_api/dashboard/\">API</a> that I used to create <a target=\"_blank\" href=\"https://github.com/Percona-Lab/pmm-dashboards/raw/main/misc/import-dashboard-grafana-cloud.sh\">this shell script</a>. Let&#8217;s take a peek at it. It&#8217;s based on the <em>api/dashboards/import</em> API function<em>. </em>The function requires a POST request with a dashboard body.</p>\n<p>The first step is to download a dashboard.</p><pre class=\"crayon-plain-tag\">curl -s https://grafana.com/api/dashboards/12630/revisions/1/download --output 12630_rev1.json</pre><p>Note how I used dashboard number 12630 and revision 1 in the command. By increasing the revision number I can find out the latest available dashboard version. This is exactly the approach used in the script.</p>\n<p>In the next example, I&#8217;ll use a dashboard from <a target=\"_blank\" href=\"https://github.com/percona/grafana-dashboards/blob/PMM-2.0/dashboards/\">our dashboard repository</a>. (I will explain why later.)</p><pre class=\"crayon-plain-tag\">curl -L -k https://github.com/percona/grafana-dashboards/raw/PMM-2.0/dashboards/Disk_Details.json --output Disk_Details.json</pre><p>Now I have a file and can form a POST request to import the dashboard into a PMM installation.</p><pre class=\"crayon-plain-tag\">$ curl -s -k -X POST -H \"Content-Type: application/json\" -d \"{\\\"dashboard\\\":$(cat Disk_Details.json),\\\"overwrite\\\":true}\" -u admin:admin https://18.218.63.13/graph/api/dashboards/import</pre><p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74660\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-1024x186.png\" alt=\"\" width=\"900\" height=\"163\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-1024x186.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-300x55.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-200x36.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-1536x279.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-367x67.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736.png 1705w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\nThe dashboard has been uploaded. If you take a look at the output you may notice the parameter <em><strong>folderId</strong></em>. With this, it&#8217;s possible to specify a Grafana folder for my dashboards.</p>\n<p>Here is the command for fetching a list of existing folders.</p><pre class=\"crayon-plain-tag\">curl -s -k -u admin:admin https://172.20.0.1/graph/api/folders</pre><p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74661\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-1024x588.png\" alt=\"\" width=\"900\" height=\"517\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-1024x588.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-300x172.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-200x115.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-367x211.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510.png 1201w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>I now have folder IDs and can use them in the importing command. The Folder ID should be specified in a POST request as shown in the next example.</p>\n<p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74675\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-1024x193.png\" alt=\"\" width=\"900\" height=\"170\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-1024x193.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-300x57.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-200x38.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-1536x289.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-367x69.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748.png 1704w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\nNow you are familiar with API import commands, I&#8217;ll give you a closer look at community dashboards.</p>\n<p>Most of them have the parameter &#8220;Data Sources&#8221;.<br />\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-75126\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210330_130454.png\" alt=\"\" width=\"236\" height=\"141\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210330_130454.png 236w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210330_130454-200x119.png 200w\" sizes=\"(max-width: 236px) 100vw, 236px\" />It means that for dashboard importing, you have to specify the data source names assigned by your installation.</p>\n<p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-74676\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326.png\" alt=\"\" width=\"1021\" height=\"765\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326.png 1021w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326-300x225.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326-200x150.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326-463x348.png 463w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326-367x275.png 367w\" sizes=\"(max-width: 1021px) 100vw, 1021px\" /><br />\nThis point makes it impossible to import any downloaded dashboards with the API without modifying them. If I execute the import command used earlier (the <code>12630_rev1.json</code> file downloaded from Grafana.com) I will get an error.</p>\n<p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74665\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-1024x64.png\" alt=\"\" width=\"900\" height=\"56\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-1024x64.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-300x19.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-200x13.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-1536x97.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-367x23.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845.png 1701w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\nSo, here&#8217;s <a target=\"_blank\" href=\"https://github.com/Percona-Lab/pmm-dashboards/raw/main/misc/cleanup-dash.py\">another script</a> (<code>cleanup_dash.py</code>) that replaces the datasource fields in dashboards and allows me to pass an importing command. The script takes a dashboard file name as a parameter.</p>\n<p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74667\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-1024x215.png\" alt=\"\" width=\"900\" height=\"189\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-1024x215.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-300x63.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-200x42.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-1536x323.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-367x77.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649.png 1721w\" sizes=\"(max-width: 900px) 100vw, 900px\" /><br />\nThe <a target=\"_blank\" href=\"https://github.com/Percona-Lab/pmm-dashboards/raw/main/misc/import-dashboard-grafana-cloud.sh\">importing script</a> calls <code>cleanup-dash.py</code> automatically if an initial importing attempt was unsuccessful.</p>\n<p>Note the parameters of the importing script. Here you should set the details of your PMM installation. <code>dashboards</code> is an array of dashboards IDs that you want to import into PMM2.</p><pre class=\"crayon-plain-tag\">#!/bin/bash\ndashboards=(13266 12630 12470)\npmm_server=\"172.20.0.1\"\nuser_pass=\"admin:admin\"\nfolderName=\"General\"</pre><p>Now, you should download <a target=\"_blank\" href=\"https://github.com/Percona-Lab/pmm-dashboards/tree/master/misc\">both scripts</a> and try to import dashboards. Make sure that both scripts are executable and in the same folder. Here are the commands to do it.</p><pre class=\"crayon-plain-tag\">curl -LJOs https://github.com/Percona-Lab/pmm-dashboards/raw/master/misc/import-dashboard-grafana-cloud.sh --output import-dashboard-grafana-cloud.sh\ncurl -LJOs https://github.com/Percona-Lab/pmm-dashboards/raw/master/misc/cleanup-dash.py --output cleanup-dash.py\n\nchmod a+x import-dashboard-grafana-cloud.sh\nchmod a+x cleanup-dash.py\n\n./import-dashboard-grafana-cloud.sh</pre><p><img loading=\"lazy\" class=\"aligncenter size-large wp-image-74862\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-1024x507.png\" alt=\"\" width=\"900\" height=\"446\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-1024x507.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-300x149.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-200x99.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-1536x760.png 1536w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-367x182.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621.png 1705w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>You can next find the imported dashboards in your PMM installation. They were put into the &#8216;Insight&#8217; folder and can be found by the keyword &#8216;PMM2&#8217;.</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74669 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-1024x367.png\" alt=\"imported PMM dashboards\" width=\"900\" height=\"323\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-1024x367.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-300x108.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-200x72.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-367x132.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233.png 1274w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<p>By default, the script imports all designed for PMM2 dashboards from Percona <a target=\"_blank\" href=\"https://grafana.com/orgs/perconalab\">account</a>. Also, folder names and dashboard IDs can be specified as parameters for the script.</p>\n<p>Here are some usage examples:</p>\n<table style=\"width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<td style=\"width: 60%;\"><i>import-dashboard-grafana-cloud.sh</i></td>\n<td>Default list of dashboards will be uploaded into General folder</td>\n</tr>\n<tr>\n<td style=\"width: 60%;\"><i>import-dashboard-grafana-cloud.sh Insight</i></td>\n<td>Default list of dashboards will be uploaded into Insight folder</td>\n</tr>\n<tr>\n<td style=\"width: 40%;\"><i>import-dashboard-grafana-cloud.sh 13266 12630 12470</i></td>\n<td>Dashboards 13266 12630 12470 will be uploaded into General folder</td>\n</tr>\n<tr>\n<td style=\"width: 40%;\"><i>import-dashboard-grafana-cloud.sh Insight 13266 12630 12470</i></td>\n<td>Dashboards 13266 12630 12470 will be uploaded into Insight folder</td>\n</tr>\n</tbody>\n</table>\n<p>You can define any number of dashboards in the script parameters and run the script periodically to always have the most recent dashboard versions.</p>\n<hr />\n<p style=\"text-align: center;\"><a target=\"_blank\" href=\"https://www.percona.com/software/database-tools/percona-monitoring-and-management?utm_source=blog\"><strong>Percona Monitoring and Management is free to download and use. Try it today!</strong></a></p>\n","descriptionType":"html","publishedDate":"Tue, 30 Mar 2021 15:00:35 +0000","feedId":11,"bgimg":"","linkMd5":"2598112912c21d21b807f7c4edf61769","bgimgJsdelivr":"","metaImg":"","author":"Vadim Yalovets","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn43@2020_1/2021/04/03/04-49-20-046_512789a7a1874474.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn96@2020_6/2021/04/03/04-49-18-641_e22630c20dcca84e.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-1024x438.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn63@2020_6/2021/04/03/04-49-10-914_1ab5b4b3b71c05c4.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-1024x541.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn51@2020_6/2021/04/03/04-49-21-039_41ecef631efc01d3.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-1024x186.png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn99@2020_4/2021/04/03/04-49-14-597_56dfa2673511a53d.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-1024x588.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn68@2020_6/2021/04/03/04-49-21-491_ca18279fdba9c2c7.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-1024x193.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn64@2020_5/2021/04/03/04-49-05-313_f76658530ac4b36e.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210330_130454.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn71@2020_6/2021/04/03/04-49-20-942_f42771f131bfb49f.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn100@2020_1/2021/04/03/04-49-04-557_56c9a26c5b89573e.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-1024x64.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn52@2020_4/2021/04/03/04-49-04-554_df9de04ac9ee2423.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-1024x215.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn99@2020_1/2021/04/03/04-49-21-790_62de23adf12ae55a.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-1024x507.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn76@2020_1/2021/04/03/04-49-24-097_97bc10059d353f85.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-1024x367.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn48@2020_1/2021/04/03/04-49-20-856_3a041108af05f7ca.webp"},"publishedOrCreatedDate":1617425343831},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Webinar March 26: MongoDB Backups Overview","link":"https://www.percona.com/blog/?p=74824","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Webinar MongoDB Backups Overview\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74826\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-300x168.png\" alt=\"Webinar MongoDB Backups Overview\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Join Percona Technical Expert Corrado Pandiani as he presents a quick yet robust comparison of the different backup solutions that can be used with MongoDB. This webinar will highlight:</p>\n<p>&#8211; Terminology</p>\n<p>&#8211; Elements of MongoDB Backups</p>\n<p>&#8211; Backup &#38; Restore Solution</p>\n<p>&#8211; Performance and Impact Comparison</p>\n<p>Please join <strong>Corrado Pandiani </strong>on <strong>Friday</strong>, <strong>March 26</strong>, <strong>2021</strong>, at <strong>3:00 AM EST/3:00 PM Singapore GMT+8 </strong>for his webinar <strong>MongoDB Backups Overview</strong>.</p>\n<p style=\"text-align: center;\"><a target=\"_blank\" class=\"btn btn-primary btn-lg\" href=\"https://percona.zoom.us/webinar/register/6316149689645/WN_UyyaPA7oQCeeBabnXoowGQ\" rel=\"noopener\">Register for Webinar</a></p>\n<p>If you can&#8217;t attend, <a target=\"_blank\" href=\"https://percona.zoom.us/webinar/register/6316149689645/WN_UyyaPA7oQCeeBabnXoowGQ\">sign up anyway</a>, and we&#8217;ll send you the slides and recording afterward.</p>\n","descriptionType":"html","publishedDate":"Thu, 11 Mar 2021 13:19:53 +0000","feedId":11,"bgimg":"","linkMd5":"6adab452b809422f5b5eade2a7c01854","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn24@2020_1/2021/04/03/04-49-22-152_01b196d59aaa0a80.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn63@2020_1/2021/04/03/04-49-20-353_e1b38eb283705bf4.webp"},"publishedOrCreatedDate":1617425343832},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Storing Kubernetes Operator for Percona Server for MongoDB Secrets in Github","link":"https://www.percona.com/blog/?p=74946","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"storing kubernetes MongoDB secrets github\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-74969\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-300x168.png\" alt=\"storing kubernetes MongoDB secrets github\" width=\"300\" height=\"168\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-300x168.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-1024x572.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-367x205.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />More and more companies are adopting <a target=\"_blank\" href=\"https://www.gitops.tech/\">GitOps</a> as the way of implementing Continuous Deployment. Its elegant approach built upon a well-known tool wins the hearts of engineers. But even if your git repository is private, it’s strongly discouraged to store keys and passwords in unencrypted form.</p>\n<p>This blog post will show how easy it is to use GitOps and keep Kubernetes secrets for <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/index.html\">Percona Kubernetes Operator for Percona Server for MongoDB</a> securely in the repository with <a target=\"_blank\" href=\"https://github.com/bitnami-labs/sealed-secrets\">Sealed Secrets</a> or <a target=\"_blank\" href=\"https://github.com/ricoberger/vault-secrets-operator\">Vault Secrets Operator</a>.</p>\n<h2>Sealed Secrets</h2>\n<p>Prerequisites:</p>\n<ul>\n<li aria-level=\"1\">Kubernetes cluster up and running</li>\n<li aria-level=\"1\">Github repository (optional)\n<ul>\n<li aria-level=\"2\">The files and keys that I used are stored in a public <a target=\"_blank\" href=\"https://github.com/spron-in/blog-data/tree/master/sealed-secrets\">blog-data repository</a></li>\n</ul>\n</li>\n</ul>\n<h3>Install Sealed Secrets Controller</h3>\n<p>Sealed Secrets rely on <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Public-key_cryptography\">asymmetric cryptography</a> (which is also used in TLS), where the private key (which in our case is stored in Kubernetes) can decrypt the message encrypted with the public key (which can be stored in public git repository safely). To make this task easier, Sealed Secrets provides the kubeseal tool, which helps with the encryption of the secrets.</p>\n<p>Install kubeseal operator into your Kubernetes cluster:</p><pre class=\"crayon-plain-tag\">kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.15.0/controller.yaml</pre><p>It will install the controller into the kube-system namespace and provide the Custom Resource Definition<span> <pre class=\"crayon-plain-tag\">sealedsecrets.bitnami.com</pre></span><span>. </span>All resources in Kubernetes with<span> <pre class=\"crayon-plain-tag\">kind: SealedSecrets</pre></span>will be handled by this Operator.</p>\n<p>Download the kubeseal binary:</p><pre class=\"crayon-plain-tag\">wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.15.0/kubeseal-linux-amd64 -O kubeseal\nsudo install -m 755 kubeseal /usr/local/bin/kubeseal</pre><p></p>\n<h3>Encrypt the Keys</h3>\n<p>In this example, I intend to store important secrets of the Percona Kubernetes Operator for Percona Server for MongoDB in git along with my manifests that are used to deploy the database.</p>\n<p>First, I will seal the secret file with system users, which is used by the MongoDB Operator to manage the database. Normally it is stored in <a target=\"_blank\" href=\"https://github.com/percona/percona-server-mongodb-operator/blob/main/deploy/secrets.yaml\">deploy/secrets.yaml</a>.</p><pre class=\"crayon-plain-tag\">kubeseal --format yaml &#60; secrets.yaml  &#62; blog-data/sealed-secrets/mongod-secrets.yaml</pre><p>This command creates the file with encrypted contents, you can see it in the blog-data/sealed-secrets repository <a target=\"_blank\" href=\"https://github.com/spron-in/blog-data/blob/master/sealed-secrets/mongod-secrets.yaml\">here</a>. It is safe to store it publicly as it can only be decrypted with a private key.</p>\n<p><span>Executing <pre class=\"crayon-plain-tag\">kubectl apply -f blog-data/sealed-secrets/mongod-secrets.yaml</pre> </span><span>does the following:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\">A sealedsecrets custom resource (CR) is created. You can see it by executing<span> <pre class=\"crayon-plain-tag\">kubectl get sealedsecrets</pre></span><span>.</span></li>\n<li aria-level=\"1\">The Sealed Secrets Operator receives the event that a new sealedsecrets CR is there and decrypts it with the private key.</li>\n<li aria-level=\"1\">Once decrypted, a regular Secrets object is created which can be used as usual.</li>\n</ol>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74950 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-1024x361.png\" alt=\"\" width=\"900\" height=\"317\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-1024x361.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-300x106.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-200x71.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-367x130.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15.png 1530w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p><pre class=\"crayon-plain-tag\">$ kubectl get sealedsecrets\nNAME               AGE\nmy-secure-secret   20m\n\n$ kubectl get secrets my-secure-secret\nNAME               TYPE     DATA   AGE\nmy-secure-secret   Opaque   10     20m</pre><p>Next, I will also seal the keys for my S3 bucket that I plan to use to store backups of my MongoDB database:</p><pre class=\"crayon-plain-tag\">kubeseal --format yaml &#60; backup-s3.yaml  &#62; blog-data/sealed-secrets/s3-secrets.yaml\nkubectl apply -f blog-data/sealed-secrets/s3-secrets.yaml</pre><p></p>\n<h2>Vault Secrets Operator</h2>\n<p>Sealed Secrets is the simplest approach, but it is possible to achieve the same result with HashiCorp Vault and Vault Secrets Operator. It is a more advanced, mature, and feature-rich approach.</p>\n<p>Prerequisites:</p>\n<ul>\n<li aria-level=\"1\">Kubernetes cluster up and running</li>\n<li aria-level=\"1\">Github repository (optional)\n<ul>\n<li aria-level=\"2\">The files and keys that I used are stored in a public <a target=\"_blank\" href=\"https://github.com/spron-in/blog-data/tree/master/sealed-secrets\">blog-data repository</a></li>\n</ul>\n</li>\n<li aria-level=\"1\"><a target=\"_blank\" href=\"https://www.vaultproject.io/\">HashiCorp Vault</a> up and running</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://github.com/ricoberger/vault-secrets-operator\">Vault Secrets Operator</a> also relies on Custom Resource, but all the keys are stored in HashiCorp Vault:</p>\n<p><img loading=\"lazy\" class=\"aligncenter wp-image-74949 size-large\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-1024x432.png\" alt=\"\" width=\"900\" height=\"380\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-1024x432.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-300x126.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-200x84.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-367x155.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16.png 1530w\" sizes=\"(max-width: 900px) 100vw, 900px\" /></p>\n<h3>Preparation</h3>\n<p>Create a policy on the Vault for the Operator:</p><pre class=\"crayon-plain-tag\">cat &#60;&#60;EOF | vault policy write vault-secrets-operator -\npath \"kvv2/data/*\" {\n  capabilities = [\"read\"]\n}\nEOF</pre><p>The policy might look a bit differently, depending on where your secrets are.</p>\n<p>Create and fetch the token for the policy:</p>\n<p>$ vault token create -period=24h -policy=vault-secrets-operator</p><pre class=\"crayon-plain-tag\">Key                  Value                                                                                                                                                                                        \n---                  -----                                                                                               \ntoken                s.0yJZfCsjFq75GiVyKiZgYVOm\n...</pre><p>Write down the token, as you will need it in the next step.</p>\n<p>Create the Kubernetes Secret so that the Operator can authenticate with the Vault:</p><pre class=\"crayon-plain-tag\">export VAULT_TOKEN=s.0yJZfCsjFq75GiVyKiZgYVOm\nexport VAULT_TOKEN_LEASE_DURATION=86400\n\ncat &#60;&#60;EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: vault-secrets-operator\ntype: Opaque\ndata:\n  VAULT_TOKEN: $(echo -n \"$VAULT_TOKEN\" | base64)\n  VAULT_TOKEN_LEASE_DURATION: $(echo -n \"$VAULT_TOKEN_LEASE_DURATION\" | base64)\nEOF</pre><p></p>\n<h3>Deploy Vault Secrets Operator</h3>\n<p>It is recommended to deploy the Operator with Helm, but before we need to create the <a target=\"_blank\" href=\"https://github.com/spron-in/blog-data/blob/master/sealed-secrets/values.yaml\">values.yaml</a> file to configure the operator.</p><pre class=\"crayon-plain-tag\">environmentVars:\n  - name: VAULT_TOKEN\n    valueFrom:\n      secretKeyRef:\n        name: vault-secrets-operator\n        key: VAULT_TOKEN\n  - name: VAULT_TOKEN_LEASE_DURATION\n    valueFrom:\n      secretKeyRef:\n        name: vault-secrets-operator\n        key: VAULT_TOKEN_LEASE_DURATION\nvault:\n  address: \"http://vault.vault.svc:8200\"</pre><p>Environment variables are pointing to the Secret that was created in the previous chapter to authenticate with Vault. We also need to provide the Vault address for the Operator to retrieve the secrets.</p>\n<p>Now we can deploy the Vault Secrets Operator:</p><pre class=\"crayon-plain-tag\">helm repo add ricoberger https://ricoberger.github.io/helm-charts\nhelm repo update\n\nhelm upgrade --install vault-secrets-operator ricoberger/vault-secrets-operator -f blog-data/sealed-secrets/values.yaml</pre><p><strong>Give me the Secret</strong></p>\n<p>I have a key created in my HashiCorp Vault:</p><pre class=\"crayon-plain-tag\">$ vault kv get kvv2/mongod-secret\n…\nKey                                 Value\n---                                 -----                                                                                                                                                                         \nMONGODB_BACKUP_PASSWORD             &#60;&#62;\nMONGODB_CLUSTER_ADMIN_PASSWORD      &#60;&#62;\nMONGODB_CLUSTER_ADMIN_USER          &#60;&#62;\nMONGODB_CLUSTER_MONITOR_PASSWORD    &#60;&#62;\nMONGODB_CLUSTER_MONITOR_USER        &#60;&#62;                                                                                                                                                               \nMONGODB_USER_ADMIN_PASSWORD         &#60;&#62;\nMONGODB_USER_ADMIN_USER             &#60;&#62;</pre><p>It is time to create the secret out of it. First, we will create the Custom Resource object of<span> <pre class=\"crayon-plain-tag\">kind: VaultSecret</pre></span><span>.</span></p><pre class=\"crayon-plain-tag\">$ cat blog-data/sealed-secrets/vs.yaml\napiVersion: ricoberger.de/v1alpha1\nkind: VaultSecret\nmetadata:\n  name: my-secure-secret\nspec:\n  path: kvv2/mongod-secret\n  type: Opaque\n\n$ kubectl apply -f blog-data/sealed-secrets/vs.yaml</pre><p>The Operator will connect to HashiCorp Vault and create regular Secret object automatically:</p><pre class=\"crayon-plain-tag\">$ kubectl get vaultsecret\nNAME               SUCCEEDED   REASON    MESSAGE              LAST TRANSITION   AGE\nmy-secure-secret   True        Created   Secret was created   47m               47m\n\n$ kubectl get secret  my-secure-secret\nNAME               TYPE     DATA   AGE\nmy-secure-secret   Opaque   7      47m</pre><p></p>\n<h2>Deploy MongoDB Cluster</h2>\n<p>Now that the secrets are in place, it is time to deploy the Operator and the DB cluster:</p><pre class=\"crayon-plain-tag\">kubectl apply -f blog-data/sealed-secrets/bundle.yaml\nkubectl apply -f blog-data/sealed-secrets/cr.yaml</pre><p>The cluster will be up in a minute or two and use secrets we deployed.</p>\n<p>By the way, my cr.yaml deploys MongoDB cluster with two shards. Multiple shards support was added in version 1.7.0of the Operator &#8211; I encourage you to try it out. Learn more about it here: <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/sharding.html\">Percona Server for MongoDB Sharding</a>.</p>\n","descriptionType":"html","publishedDate":"Mon, 22 Mar 2021 17:10:50 +0000","feedId":11,"bgimg":"","linkMd5":"ad5af7759a03394ee27c6d95b528d5c4","bgimgJsdelivr":"","metaImg":"","author":"Sergey Pronin","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn92@2020_5/2021/04/03/04-49-13-435_3795a759750ccc96.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-300x168.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn4@2020_4/2021/04/03/04-49-16-807_55a5ba77bf02fa12.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-1024x361.png":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn67@2020_5/2021/04/03/04-49-48-726_4b62da5caafa3708.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-1024x432.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn96@2020_2/2021/04/03/04-49-13-538_09c88bf99462b43d.webp"},"publishedOrCreatedDate":1617425343795},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"MySQL Monitoring and Reporting Using the MySQL Shell","link":"https://www.percona.com/blog/?p=74605","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Monitoring Using the MySQL Shell\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><img loading=\"lazy\" class=\"alignright size-medium wp-image-74622\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-300x157.png\" alt=\"Monitoring Using the MySQL Shell\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />MySQL Shell is the advanced MySQL client, which has many excellent features. In this blog, I am going to explain the MySQL shell commands “\\show” and “\\watch”. Both commands are very useful to monitor the MySQL process. It provides more insights into the foreground and background threads as well. </span></p>\n<h2>Overview</h2>\n<p><span>“\\show” and “\\watch” are the MySQL shell commands, which can be executed using the Javascript (JS), Python (Py), and SQL interfaces. Both commands are providing the same information, but the difference is you can refresh the results when using the command “\\watch”. The refresh interval is two seconds. </span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>\\show: Run the specified report using the provided options and arguments.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>\\watch: Run the specified report using the provided options and arguments, and refresh the results at regular intervals.</span></li>\n</ul>\n<p><span>Below are the available options you can use with the “\\show” or “\\watch” command to retrieve the data.</span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  percona  JS &#62; \\show\nAvailable reports: query, thread, threads.\n\nMySQL  localhost:33060+ ssl  percona  JS &#62; \\watch\nAvailable reports: query, thread, threads.</pre><p></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Query</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Thread</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Threads</span></li>\n</ul>\n<h2>“\\show” with “query”</h2>\n<p><span>It will just execute the query provided as an argument within the double quotes and print the result. </span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  percona  JS &#62; \\show query \"select database()\"\n+------------+\n| database() |\n+------------+\n| percona    |\n+------------+\nMySQL  localhost:33060+ ssl  percona  JS &#62; \\show query --vertical \"select database()\"\n*************************** 1. row ***************************\ndatabase(): percona</pre><p><span>You can also use the same option with the “\\watch” command. Let&#8217;s say, if you want to monitor the processlist for every two seconds, then you can use the command like</span></p><pre class=\"crayon-plain-tag\">\\watch query “show processlist”</pre><p></p>\n<h2></h2>\n<h2>“\\show” with “thread”</h2>\n<p><span>This option is designed to provide various information about the specific thread. Below are some of the important details you can retrieve from the specific thread. </span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>InnoDB details ( &#8211;innodb )</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Locks Details ( &#8211;locks )</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Prepared statement details ( &#8211;prep-stmts )</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Client connection details ( &#8211;client )</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Session status ( &#8211;status ) and session variables details ( &#8211;vars )</span></li>\n</ul>\n<h3>Example:</h3>\n<p><span>I am going to show the example for the below scenario. </span></p>\n<p><span>At session1:</span></p>\n<p><span>My connection id is 121. I have started the transaction and updated the row where “id=3”. But, still not committed or rolled back the transaction.</span></p><pre class=\"crayon-plain-tag\">mysql&#62; \\r\nConnection id:    121\nCurrent database: percona\n\nmysql&#62; select * from herc;\n+------+--------+\n| id   | name   |\n+------+--------+\n|    1 | jc     |\n|    2 | herc7  |\n|    3 | sakthi |\n+------+--------+\n3 rows in set (0.00 sec)\n\nmysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; update herc set name='xxx' where id=3;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0</pre><p><span>At session 2:</span></p>\n<p><span>My connection id is 123. I have started the transaction and tried to update the same row where “id=3”. The query is still executing because the transaction from session 1 is blocking the row ( id = 3 )</span></p><pre class=\"crayon-plain-tag\">mysql&#62; \\r\nConnection id:    123\nCurrent database: percona\n\nmysql&#62; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; update herc set name='hercules' where id=3;</pre><p><span>Now let’s use the command “\\show thread” for both connection IDs (121, 123) and see what information we can get.</span></p>\n<p><b>General information ( conncetion id = 123 ):</b></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show thread --cid=123 --general\nGENERAL\nThread ID:                161\nConnection ID:            123\nThread type:              FOREGROUND\nProgram name:             mysql\nUser:                     root\nHost:                     localhost\nDatabase:                 percona\nCommand:                  Query\nTime:                     00:08:49\nState:                    updating\nTransaction state:        LOCK WAIT\nPrepared statements:      0\nBytes received:           282\nBytes sent:               131\nInfo:                     update herc set name='hercules' where id=3\nPrevious statement:       NULL</pre><p><span>From the general information, you can find some basic information about your id.</span></p>\n<p><b>InnoDB information:</b></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show thread --cid=123 --innodb\nINNODB STATUS\nState:                    LOCK WAIT\nID:                       28139179\nElapsed:                  00:10:23\nStarted:                  2021-02-23 17:40:06.000000\nIsolation level:          REPEATABLE READ\nAccess:                   READ WRITE\nLocked tables:            1\nLocked rows:              1\nModified rows:            0</pre><p><span>Using the “&#8211;innodb” option, you can find out the information about the InnoDB like transaction state,  thread start time, elapsed time, locked tables, rows, modified rows. </span></p>\n<p><b>Locks information:</b></p>\n<p><span>For connection id 123:</span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show thread --cid=123 --locks\nLOCKS\nWaiting for InnoDB locks\n+---------------------+----------+------------------+--------+-----+-------+----------------+---------------------+----------+\n| Wait started        | Elapsed  | Locked table     | Type   | CID | Query | Account        | Transaction started | Elapsed  |\n+---------------------+----------+------------------+--------+-----+-------+----------------+---------------------+----------+\n| 2021-02-23 17:40:06 | 00:12:27 | `percona`.`herc` | RECORD | 121 | NULL  | root@localhost | 2021-02-23 17:39:32 | 00:13:01 |\n+---------------------+----------+------------------+--------+-----+-------+----------------+---------------------+----------+\n\nWaiting for metadata locks\nN/A\n\nBlocking InnoDB locks\nN/A\n\nBlocking metadata locks\nN/A</pre><p><span>Connection id 123 is from session 2. Which is currently waiting to release the lock from connection id 121 (session 1). Let&#8217;s see the “&#8211;locks” status for connection id 121.</span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show thread --cid=121 --locks\nLOCKS\n\nWaiting for InnoDB locks\nN/A\n\nWaiting for metadata locks\nN/A\n\nBlocking InnoDB locks\n+---------------------+----------+------------------+--------+-----+--------------------------------------------+\n| Wait started        | Elapsed  | Locked table     | Type   | CID | Query                                      |\n+---------------------+----------+------------------+--------+-----+--------------------------------------------+\n| 2021-02-23 17:40:06 | 00:14:23 | `percona`.`herc` | RECORD | 123 | update herc set name='hercules' where id=3 |\n+---------------------+----------+------------------+--------+-----+--------------------------------------------+\n\nBlocking metadata locks\nN/A</pre><p><span>Here, you can find the details on “Blocking InnoDB Locks”. It blocks the connection id 123 (session 2).</span></p>\n<p><span>Like the above example, you can explore the other options as well, which are helpful. </span></p>\n<h2>“\\show” with “threads”</h2>\n<p><span>This is very helpful to know the details about your ongoing threads. It will provide the details about both “FOREGROUND” and “BACKGROUND” threads. There are many columns, which are very useful to know about thread status. You can filter the needed columns with the option “-o”. By executing the command “\\show threads &#8211;help”, you can find all the available options and their purposes. </span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>It supports the WHERE clause for generating the report</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>It supports ORDER BY for generating the report</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>It supports LIMIT for generating the report. </span></li>\n</ul>\n<p><span>Below, I am sharing some examples, which will help you to understand how we can use the “threads” command with the MySQL shell.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How to find the running “FOREGROUND” threads details</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How to find the running “BACKGROUND” threads details</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How to find the top five threads, which are consuming more memory from a particular user</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How to find the Query digest details from ongoing threads</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How to find the top five threads which consumed huge IO operations</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>How to find the top five blocked and blocking threads</span></li>\n</ul>\n<p><span>I am running the sysbench against the server to get my database loaded. </span></p><pre class=\"crayon-plain-tag\">sysbench /usr/share/sysbench/oltp_read_write.lua --events=0 --time=30000 --mysql-host=localhost --mysql-user=root --mysql-password=Course@321 --mysql-port=3306 --delete_inserts=10 --index_updates=10 --non_index_updates=10 --report-interval=1 --threads=100 run</pre><p></p>\n<h3>How to Find the Running “FOREGROUND” Threads Details</h3>\n<p><span>You can use the option “&#8211;foreground” to see all the running foreground threads.</span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads --foreground\n+-----+-----+-----------------+-----------+---------+---------+----------+------------------------+-----------+-------------------------------------------------------------------+-----------+\n| tid | cid | user            | host      | db      | command | time     | state                  | txstate   | info                                                              | nblocking |\n+-----+-----+-----------------+-----------+---------+---------+----------+------------------------+-----------+-------------------------------------------------------------------+-----------+\n| 27  | 114 | root            | localhost | NULL    | Query   | 00:00:00 | executing              | NULL      | SELECT json_object('cid',t.PRO ... READ_ID = io.thread_id WHERE t | 0         |\n| 42  | 5   | event_scheduler | localhost | NULL    | Daemon  | 17:42:20 | Waiting on empty queue | NULL      | NULL                                                              | 0         |\n| 46  | 7   | NULL            | NULL      | NULL    | Daemon  | 17:42:20 | Suspending             | NULL      | NULL                                                              | 0         |\n| 158 | 120 | root            | localhost | NULL    | Sleep   | 00:32:24 | NULL                   | NULL      | \n\n.  . . . .. . ... .     . . .. . .. . .. . \n.  . . . .. . ... .     . . .. . .. . .. . \n.  . . . .. . ... .     . . .. . .. . .. . \n                                                              | 0         |\n| 260 | 222 | root            | localhost | sbtest  | Execute | 00:00:00 | updating               | LOCK WAIT | NULL                                                              | 1         |\n| 261 | 223 | root            | localhost | sbtest  | Execute | 00:00:00 | updating               | LOCK WAIT | NULL                                                              | 0         |\n+-----+-----+-----------------+-----------+---------+---------+----------+------------------------+-----------+-------------------------------------------------------------------+-----------+</pre><p></p>\n<h3>How to Find the Running “BACKGROUND” Threads Details</h3>\n<p><span>This will give detailed information about the background threads, mostly InnoDB. You can use the flag “&#8211;background” to get these details. These details will be really helpful for debugging the performance issues.</span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads --background\n+-----+--------------------------------------+---------+-----------+------------+------------+------------+\n| tid | name                                 | nio     | ioltncy   | iominltncy | ioavgltncy | iomaxltncy |\n+-----+--------------------------------------+---------+-----------+------------+------------+------------+\n| 1   | sql/main                             | 92333   | 192.51 ms | 229.63 ns  | 96.68 us   | 1.42 ms    |\n| 3   | innodb/io_ibuf_thread                | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 4   | innodb/io_log_thread                 | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 5   | innodb/io_read_thread                | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 6   | innodb/io_read_thread                | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 7   | innodb/io_read_thread                | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 8   | innodb/io_read_thread                | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 9   | innodb/io_write_thread               | 37767   | 45.83 s   | 1.26 us    | 1.21 ms    | 17.81 ms   |\n| 10  | innodb/io_write_thread               | 36763   | 44.57 s   | 1.23 us    | 1.21 ms    | 30.11 ms   |\n| 11  | innodb/io_write_thread               | 37989   | 45.87 s   | 1.26 us    | 1.21 ms    | 24.03 ms   |\n| 12  | innodb/io_write_thread               | 37745   | 45.78 s   | 1.23 us    | 1.21 ms    | 28.93 ms   |\n| 13  | innodb/page_flush_coordinator_thread | 456128  | 2.19 min  | 5.27 us    | 419.75 us  | 29.98 ms   |\n| 14  | innodb/log_checkpointer_thread       | 818     | 479.84 ms | 2.62 us    | 710.63 us  | 9.26 ms    |\n| 15  | innodb/log_flush_notifier_thread     | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 16  | innodb/log_flusher_thread            | 1739344 | 41.71 min | 1.46 us    | 1.44 ms    | 30.22 ms   |\n| 17  | innodb/log_write_notifier_thread     | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 18  | innodb/log_writer_thread             | 5239157 | 10.23 min | 1.14 us    | 117.16 us  | 29.02 ms   |\n| 19  | innodb/srv_lock_timeout_thread       | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 20  | innodb/srv_error_monitor_thread      | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 21  | innodb/srv_monitor_thread            | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 22  | innodb/buf_resize_thread             | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 23  | innodb/srv_master_thread             | 270     | 4.02 ms   | 6.75 us    | 14.90 us   | 41.74 us   |\n| 24  | innodb/dict_stats_thread             | 3088    | 429.12 ms | 3.22 us    | 138.96 us  | 5.93 ms    |\n| 25  | innodb/fts_optimize_thread           | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 26  | mysqlx/worker                        | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 28  | mysqlx/acceptor_network              | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 32  | innodb/buf_dump_thread               | 1060    | 7.61 ms   | 2.74 us    | 7.18 us    | 647.18 us  |\n| 33  | innodb/clone_gtid_thread             | 4       | 689.86 us | 4.46 us    | 172.46 us  | 667.95 us  |\n| 34  | innodb/srv_purge_thread              | 7668    | 58.21 ms  | 3.34 us    | 336.20 us  | 1.64 ms    |\n| 35  | innodb/srv_worker_thread             | 30      | 278.22 us | 5.57 us    | 9.27 us    | 29.69 us   |\n| 36  | innodb/srv_purge_thread              | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 37  | innodb/srv_worker_thread             | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 38  | innodb/srv_worker_thread             | 24      | 886.23 us | 5.24 us    | 36.93 us   | 644.75 us  |\n| 39  | innodb/srv_worker_thread             | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 40  | innodb/srv_worker_thread             | 22      | 223.92 us | 5.84 us    | 10.18 us   | 18.34 us   |\n| 41  | innodb/srv_worker_thread             | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 43  | sql/signal_handler                   | NULL    | NULL      | NULL       | NULL       | NULL       |\n| 44  | mysqlx/acceptor_network              | NULL    | NULL      | NULL       | NULL       | NULL       |\n+-----+--------------------------------------+---------+-----------+------------+------------+------------+</pre><p></p>\n<h3>How to Find the Top Five Threads, Which are Consuming More Memory From a Particular User</h3>\n<p><span>From the below example, I am finding the top five threads, which are consuming more memory from user “root”. </span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads --foreground -o tid,user,memory,started --order-by=memory --desc --where \"user = 'root'\" --limit=5\n+-----+------+----------+---------------------+\n| tid | user | memory   | started             |\n+-----+------+----------+---------------------+\n| 247 | root | 9.47 MiB | 2021-02-23 18:30:29 |\n| 166 | root | 9.42 MiB | 2021-02-23 18:30:29 |\n| 248 | root | 9.41 MiB | 2021-02-23 18:30:29 |\n| 186 | root | 9.39 MiB | 2021-02-23 18:30:29 |\n| 171 | root | 9.38 MiB | 2021-02-23 18:30:29 |\n+-----+------+----------+---------------------+</pre><p></p>\n<h3>How to Find the Query Digest Details From Ongoing Threads</h3>\n<p><span>You can use the options “digest” and “digesttxt” to find the digest output of the running threads.</span></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads -o tid,cid,info,digest,digesttxt --where \"digesttxt like 'UPDATE%'\" --vertical\n*************************** 1. row ***************************\n      tid: 161\n      cid: 123\n     info: update herc set name='hercules' where id=3\n   digest: 7832494e46eee2b28a46dc1fdae2e1b18d1e5c00d42f56b5424e5716d069fd39\ndigesttxt: UPDATE `herc` SET NAME = ? WHERE `id` = ?</pre><p></p>\n<h3>How to Find the Top Five Threads Which Consumed Huge IO Operations</h3>\n<p></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads -o tid,cid,nio --order-by=nio --desc --limit=5\n+-----+-----+-------+\n| tid | cid | nio   |\n+-----+-----+-------+\n| 27  | 114 | 36982 |\n| 238 | 200 | 2857  |\n| 215 | 177 | 2733  |\n| 207 | 169 | 2729  |\n| 232 | 194 | 2724  |\n+-----+-----+-------+</pre><p><span>Nio → Total number of IO events for the thread.</span></p>\n<h3>How to Find the Top Five Blocked and Blocking Threads</h3>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>nblocked  &#8211; The number of other threads blocked by the thread</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>nblocking &#8211; The number of other threads blocking the thread</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span>Ntxrlckd   &#8211; The approximate number of rows locked by the current InnoDB transaction</span></li>\n</ul>\n<p><b>Blocking threads:</b></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads -o tid,cid,nblocked,nblocking,ntxrlckd,txstate --order-by=nblocking --desc --limit 5\n+-----+-----+----------+-----------+----------+-----------+\n| tid | cid | nblocked | nblocking | ntxrlckd | txstate   |\n+-----+-----+----------+-----------+----------+-----------+\n| 230 | 192 | 0        | 7         | 5        | LOCK WAIT |\n| 165 | 127 | 0        | 6         | 2        | LOCK WAIT |\n| 215 | 177 | 0        | 5         | 9        | LOCK WAIT |\n| 221 | 183 | 0        | 4         | NULL     | NULL      |\n| 233 | 195 | 1        | 4         | NULL     | NULL      |\n+-----+-----+----------+-----------+----------+-----------+</pre><p><b>Blocked threads:</b></p><pre class=\"crayon-plain-tag\">MySQL  localhost:33060+ ssl  JS &#62; \\show threads -o tid,cid,nblocked,nblocking,ntxrlckd,txstate --order-by=nblocked --desc --limit 5\n+-----+-----+----------+-----------+----------+-----------+\n| tid | cid | nblocked | nblocking | ntxrlckd | txstate   |\n+-----+-----+----------+-----------+----------+-----------+\n| 203 | 165 | 15       | 0         | 8        | LOCK WAIT |\n| 181 | 143 | 10       | 1         | 5        | LOCK WAIT |\n| 223 | 185 | 9        | 0         | 8        | LOCK WAIT |\n| 209 | 171 | 9        | 1         | 5        | LOCK WAIT |\n| 178 | 140 | 6        | 0         | 7        | LOCK WAIT |\n+-----+-----+----------+-----------+----------+-----------+</pre><p><span>Like this, you have many options to explore and you can generate the report based on your requirements. I hope this blog post is helpful to understand the “\\show” and “\\watch” commands from the MySQL shell!</span></p>\n","descriptionType":"html","publishedDate":"Thu, 25 Feb 2021 15:28:18 +0000","feedId":11,"bgimg":"","linkMd5":"8d7b08bfa2026cbb9dd9940b036d9b67","bgimgJsdelivr":"","metaImg":"","author":"Sri Sakthivel","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn23@2020_3/2021/04/03/04-49-15-929_f943f262a565a9ed.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn12@2020_4/2021/04/03/04-49-23-987_57b5e45f51dfa7cf.webp"},"publishedOrCreatedDate":1617425343851},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Top 5 Features Developers Love About MongoDB","link":"https://www.percona.com/blog/?p=74407","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Developers Love About MongoDB\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><a target=\"_blank\" href=\"https://docs.mongodb.com/\"><img loading=\"lazy\" class=\"alignright size-medium wp-image-74456\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-300x157.png\" alt=\"Developers Love About MongoDB\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />MongoDB</a> is one of the most admired and effortless NoSQL databases to set up. Developers want to spend time building the features for their application, and with MongoDB, developers can build the application quickly while utilizing well-supported infrastructure and high availability with automatic failover.</p>\n<p>In this blog post, we will discuss the top five things which MongoDB does better than anyone else.</p>\n<h2>Ease of Setup</h2>\n<p>First and foremost, MongoDB is very easy to install and deploy, and a developer can start writing code immediately for the application. As said, the installation of MongoDB is very simple whether it’s on Windows, Mac, or Linux. Even for Linux/Mac, one can download the tarball, extract it, configure the db/log path, and start it. Percona offers “<a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Percona Server for MongoDB</a>”, an enhanced, open source, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB Community Edition. For more details on the installation of “Percona Server for MongoDB (PSMDB)” on various OS, please visit the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/LATEST/index.html\">installation section</a>. One can also spin up MongoDB with Kubernetes, and Percona also has a <a target=\"_blank\" href=\"https://www.percona.com/doc/kubernetes-operator-for-psmongodb/index.html\">Kubernetes Operator for Percona Server for MongoDB</a> available.</p>\n<h2>Flexible Schema</h2>\n<p>One of the great features MongoDB has is a flexible schema. MongoDB can be a schemaless database. A developer won&#8217;t be stuck with a defined schema, i.e. we don’t need to define data-type in a collection before inserting the data or a field’s data type can be different across the documents in a collection. A document from an employee collection in MongoDB may look like:</p><pre class=\"crayon-plain-tag\">{ \"emp_name\" : \"XYZ\", \"city\" : \"NYC\" }\n\n{ \"emp_name\" : \"XYZ\", \"city\" : \"NYC\", \"country\" : \"US\"  }</pre><p>Even if you have to change the structure of a document in a collection, you only need to update the document with a new structure. Consider a document of a phone collection below:</p><pre class=\"crayon-plain-tag\">{\n\n\"_id\" : ObjectId(\"5f8d175127f5862e567f676c\"),\n\n\"model_name\" : \"iphone12\",\n\n\"features\" : {\n\n\"5G_support\" : true,\n\n\"display\" : \"OLED with Ceramic Shield\"\n\n},\n\n}</pre><p>Let&#8217;s say you want to append a new field &#8220;<em>screen_size</em>&#8221; in it. One can easily do this with an update without specifying the type of <em>screen_size</em> column [in MongoDB it’s a key].</p><pre class=\"crayon-plain-tag\">db.phone.update({ model_name: \"iphone12\" }, { $set : {   \"screen_size\" : 6.1 } } )\n\ndb.phone.find({ \"model_name\" : \"iphone12\" }).pretty()\n\n{\n\n\"_id\" : ObjectId(\"5f8d175127f5862e567f676c\"),\n\n\"model_name\" : \"iphone12\",\n\n\"features\" : {\n\n\"5G_support\" : true,\n\n\"display\" : \"OLED with Ceramic Shield\"\n\n},\n\n\"screen_size\" : 6.1\n\n}</pre><p>It also allows related documents to be embedded as a single document or a document reference:</p>\n<p><strong>Embedded single document</strong></p><pre class=\"crayon-plain-tag\">{\n\n\"_id\" : ObjectId(\"5f8d175127f5862e567f676c\"),\n\n\"model_name\" : \"iphone12\",\n\n\"features\" : {\n\n\"5G_support\" : true,\n\n\"display\" : \"OLED with Ceramic Shield\"\n\n},\n\n\"screen_size\" : 6.1\n\n}</pre><p><strong>A document with reference</strong></p><pre class=\"crayon-plain-tag\">// Customer collection’s document\n\n{\n\n_id : 1211,\n\nname : \"Apple Solomon Pond Mall\",\n\naddress : \"601 Donald Lynch Blvd, Marlborough, MA 01752, United States\"\n\n}\n\n\n\n\n// Review collection’s Document\n\n{\n\n_id : 442321\n\nreview : “iphone SE is the cheapest iphone with a similar look like iPhone 8 but better internals with A13 bionic chip. However, it’s camera is not upto mark...”\n\ncust_id : 1211\n\n}</pre><p></p>\n<p style=\"text-align: center;\">\n<h2>Fault Tolerance</h2>\n<p>MongoDB has built-in Replication features that provide High Availability and redundancy. Since it has copies of data in multiple servers, it gives a layer of fault tolerance in case of loss of a database server. Having multiple copies of data in different regions increases the availability and data locality for reads with potential stale reading. It can also improve data locality for writes with zoned shards.</p>\n<p>In the MongoDB Replica set, how many nodes can be unavailable and still have sufficient members to elect a new Primary is said to be the Fault Tolerance limit.</p>\n<p>A correct fault tolerance configuration would be a mix of business consideration and budget. To achieve replication and fault tolerance of one, we would require a minimum of three nodes. So, if one node goes down, there will still be a majority of nodes available to elect a new Primary.</p>\n<p>The below chart shows the number of required nodes to achieve fault tolerance.</p>\n<table>\n<tbody>\n<tr>\n<td><b>Number of nodes</b></td>\n<td><b>Majority Required to Elect a New Primary</b></td>\n<td><b>Fault Tolerance</b></td>\n</tr>\n<tr>\n<td><span>3</span></td>\n<td><span>2</span></td>\n<td><span>1</span></td>\n</tr>\n<tr>\n<td><span>4</span></td>\n<td><span>3</span></td>\n<td><span>1</span></td>\n</tr>\n<tr>\n<td><span>5</span></td>\n<td><span>3</span></td>\n<td><span>2</span></td>\n</tr>\n<tr>\n<td><span>6</span></td>\n<td><span>4</span></td>\n<td><span>2</span></td>\n</tr>\n</tbody>\n</table>\n<p>Replica Sets can also increase the number of queries served to the application as clients can send read requests to secondaries of the replica set, i.e a client can set the <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/core/read-preference/\">readPreference</a> to read from the secondary, &#8220;nearest&#8221;, or by a <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/tutorial/configure-replica-set-tag-sets/\">tag set</a>. However, reading from secondary nodes comes with a tradeoff as well. Clients may see stale data.</p>\n<h2>Scalability</h2>\n<p>Scalability is one of the key features of MongoDB. It is built on a scale-out architecture which enables it to sustain a high volume of data and traffic.</p>\n<p>In any database system, growth can be managed by two methods: vertical and horizontal scaling. Vertical scaling involves increasing the capacity of a single server like a more powerful CPU, increasing RAM, or extending disk space. Horizontal scaling involves dividing the dataset into multiple small machines without any code change to be made at the application level.</p>\n<p>MongoDB supports sharding through Horizontal scaling. It is cost-effective, more data can be written or read back as necessary as you’re able to distribute the load across your shards. When there is an increase in dataset growth a new shard can be added at any time and MongoDB will automatically migrate the data.</p>\n<p>In MongoDB, sharding happens at the collection level and each document is associated with a <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/core/sharding-shard-key/\">shard key</a> which decides which shard the document should live on. The application doesn’t send requests to shards directly, it sends the requests to the <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/program/mongos/#bin.mongos\">MongoS</a> [the Query router] and MongoS redirects the read/write request to the respective shards by cached metadata from the <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/core/sharded-cluster-config-servers/#sharded-cluster-config-server\">config servers</a>.</p>\n<h2>Performance</h2>\n<p>Database performance varies with many factors like “Database design”, “application queries” and “load” etc. and MongoDB has the ability to handle large volumes of unstructured data because it allows users to query in a different way which is more appropriate to their workload. It is always faster to retrieve a related single document than to join data across multiple collections.</p>\n<p>To get better performance, one needs to make sure that the <a target=\"_blank\" href=\"https://docs.mongodb.com/manual/reference/glossary/#term-working-set\">working set</a> fits in RAM as well. All data persists in hard-disk, except when using the in-memory storage engine, but during the query execution, it fetches the data from local RAM. It is also important to have the right indexes and enough RAM in place to get the advantage of MongoDB’s performance.</p>\n<p><strong>Conclusion</strong></p>\n<p>MongoDB is feature-rich, and an easy way to get started with NoSQL databases. It has a flexible data model, expressive easy to learn query syntax, automatic failover with replica sets, and is quite scalable. It also has good documentation which makes a  developer&#8217;s life a lot easier.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Percona Server for MongoDB</a> offers all of the functionality of MongoDB Enterprise edition with a non-licensed model. This means no need to worry about purchasing licenses for production or non-production environments. You can ensure consistent deployment across all environments by utilizing non-licensed, open source software, all while ensuring that the security standards required by your organization are being met and if support is what you need Percona has you covered there as well.</p>\n<p>MongoDB has both Community and Enterprise editions. While the Community edition is source-available and it is free to use the database within the confines of the <a target=\"_blank\" href=\"https://www.mongodb.com/licensing/server-side-public-license\">SSPL license</a>, Enterprise is available as a part of the MongoDB Enterprise subscription which includes MongoDB-provided support for your deployment.</p>\n<p>To know more about what <a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Percona Server for MongoDB</a> covers, please visit the blog “<a target=\"_blank\" href=\"https://www.percona.com/blog/2020/05/28/mongodb-why-pay-for-enterprise-when-open-source-has-you-covered/\">Why Pay for Enterprise When Open Source Has You Covered?</a>”.</p>\n<p>&#160;</p>\n","descriptionType":"html","publishedDate":"Mon, 15 Feb 2021 13:40:01 +0000","feedId":11,"bgimg":"","linkMd5":"d71c22ae0c04f164edfa81af13728f44","bgimgJsdelivr":"","metaImg":"","author":"Mukesh Kumar","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn75@2020_4/2021/04/03/04-49-12-398_8c4b4d496e8d4c47.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn36@2020_5/2021/04/03/04-49-15-749_e4ac3fdf92043475.webp"},"publishedOrCreatedDate":1617425343843},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Percona XtraBackup Point-In-Time Recovery for the Single Database","link":"https://www.percona.com/blog/?p=74903","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona XtraBackup Point-In-Time Recovery\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><img loading=\"lazy\" class=\"alignright size-medium wp-image-75246\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-300x157.png\" alt=\"Percona XtraBackup Point-In-Time Recovery\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Recovering to a particular time in the past is called Point-In-Time Recovery (PITR). With PITR you can rollback unwanted <code>DELETE</code> without <code>WHERE</code> clause or any other harmful command.</p>\n<p>PITR with <a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtrabackup\">Percona XtraBackup</a> is pretty straightforward and perfectly described in the <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-xtrabackup/LATEST/innobackupex/pit_recovery_ibk.html\">user manual</a>. You need to restore the data from the backup, then apply all binary logs created or updated after the backup was taken, but skip harmful event(s).</p>\n<p>However, if your data set is large you may want to recover only the affected database or table. This is possible but you need to be smart when filtering events from the binary log. In this post, I will show how to perform such a partial recovery using Percona XtraBackup, <code>mysql</code> command-line client, and <code>mysqlbinlog</code> programs only. There is an alternative approach that involves creating a fake source server, that is described in <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/10/23/mysql-point-in-time-recovery-right-way/\">MySQL Point in Time Recovery the Right Way</a>. You may consider it, especially if you need to apply changes to a <a target=\"_blank\" href=\"https://www.percona.com/blog/2018/02/26/mysql-single-table-point-in-time-recovery/\">single table</a>.</p>\n<h2>Percona XtraBackup Point-In-Time Recovery</h2>\n<p>For our example we will create data first, then run <code>DROP</code> and <code>DELETE</code> commands on two different tables. Then we will rollback these commands.</p>\n<p>First, let&#8217;s assume we have a server with two databases: <code>test</code> and <code>sbtest</code>. We are using GTIDs and row-based binary log format. We also run the server with the option <code>innodb_file_per_table=1</code> and all our InnoDB tables use individual tablespaces. Otherwise, the individual restore method would not work.</p><pre class=\"crayon-plain-tag\">mysql&#62; show tables from sbtest;\n+------------------+\n| Tables_in_sbtest |\n+------------------+\n| sbtest1          |\n| sbtest2          |\n| sbtest3          |\n| sbtest4          |\n| sbtest5          |\n| sbtest6          |\n| sbtest7          |\n| sbtest8          |\n+------------------+\n8 rows in set (0.00 sec)\n\nmysql&#62; show tables from test;\n+----------------+\n| Tables_in_test |\n+----------------+\n| bar            |\n| baz            |\n| foo            |\n+----------------+\n3 rows in set (0.00 sec)</pre><p>We will experiment with tables <code>foo</code> and <code>bar</code>. We assume that at the time of our first backup, each of the tables contained five rows. Tables in the database <code>sbtest</code> also contain data, but it does not really matter for our experiment.</p><pre class=\"crayon-plain-tag\">mysql&#62; select count(*) from foo;\n+----------+\n| count(*) |\n+----------+\n|        5 |\n+----------+\n1 row in set (0.00 sec)\n\nmysql&#62; select count(*) from bar;\n+----------+\n| count(*) |\n+----------+\n| 5        |\n+----------+\n1 row in set (0.00 sec)\n\nmysql&#62; select count(*) from baz;\n+----------+\n| count(*) |\n+----------+\n| 0        |\n+----------+\n1 row in set (0.00 sec)</pre><p>Since we want to restore individual tables, we need to make a preparation before taking a backup: store database structure. We will do it with help of the <code>mysqldump</code> command. In this example, I store structure per database to make partial PITR easier, but you are free to use the option <code>--all-databases</code>.</p><pre class=\"crayon-plain-tag\">mysqldump --no-data --set-gtid-purged=OFF --triggers --routines --events test &#62; test_structure.sql\nmysqldump --no-data --set-gtid-purged=OFF --triggers --routines --events sbtest &#62; sbtest_structure.sql</pre><p>Then we are ready to take the backup.</p><pre class=\"crayon-plain-tag\">xtrabackup --parallel=8 --target-dir=./full_backup --backup</pre><p>I am using the option <code>--parallel</code> to speed up the backup process.</p>\n<p>Now let&#8217;s do some testing. First, let&#8217;s update rows in the table foo.</p><pre class=\"crayon-plain-tag\">mysql&#62; update foo set f1=f1*2;\nQuery OK, 5 rows affected (0.01 sec)\nRows matched: 5 Changed: 5 Warnings: 0\n\nmysql&#62; select * from foo;\n+----+------+\n| id | f1   |\n+----+------+\n|  1 |    2 |\n|  2 |    4 |\n|  3 |    6 |\n|  4 |    8 |\n|  5 |   10 |\n+----+------+\n5 rows in set (0.00 sec)</pre><p>And then drop it and delete all rows from the table bar.</p><pre class=\"crayon-plain-tag\">mysql&#62; drop table foo;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql&#62; delete from bar;\nQuery OK, 5 rows affected (0.01 sec)</pre><p>Finally, let&#8217;s insert a few rows into the tables bar and baz.</p><pre class=\"crayon-plain-tag\">mysql&#62; insert into bar(f1) values(6),(7),(8),(9),(10);\nQuery OK, 5 rows affected (0.01 sec)\nRecords: 5 Duplicates: 0 Warnings: 0\n\nmysql&#62; insert into baz(f1) values(1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.01 sec)\nRecords: 5 Duplicates: 0 Warnings: 0</pre><p>Assume that the <code>DROP TABLE</code> and <code>DELETE</code> command was an accident and we want to restore the state of the tables <code>foo</code> and <code>bar</code> as they were before these unlucky statements.</p>\n<p>First, we need to prepare the backup.</p>\n<p>Since we are interested in restoring only tables in the database <code>test</code> we need to prepare the backup with a special option <code>--export</code> that exports tablespaces in a way that they could be later imported:</p><pre class=\"crayon-plain-tag\">xtrabackup --prepare --export --target-dir=./full_backup</pre><p>Now the directory for the database <code>test</code> contains not only table definition files (<code>.frm</code>, only before 8.0) and tablespace files (<code>.ibd</code>) but also configuration files (<code>.cfg</code>).</p>\n<p>Since we want all changes that happened after backup and before the problematic <code>DROP TABLE</code> and <code>DELETE</code> statements were applied, we need to identify which binary log and position were actual at the backup time. We can find it in the <code>xtrabackup_binlog_info</code> file:</p><pre class=\"crayon-plain-tag\">$ cat full_backup/xtrabackup_binlog_info\nmaster-bin.000004 1601 0ec00eed-87f3-11eb-acd9-98af65266957:1-56</pre><p>Now we are ready to perform restore.</p>\n<p>First, let&#8217;s restore the table <code>foo</code> from the backup. Restoring individual tablespaces requires the <code><a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-table-import.html\">ALTER TABLE ... IMPORT TABLESPACE</a></code> command. This command assumes that the table exists in the server. However, in our case, it was dropped and therefore we need to re-create it.</p>\n<p>We will recreate the full database test from the file <code>test_structure.sql</code></p>\n<p>Since we do not want these administrative tasks to be re-applied, I suggest disabling binary logging for the session which will recreate the database structure.</p><pre class=\"crayon-plain-tag\">mysql&#62; set sql_log_bin=0;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&#62; source test_structure.sql\nQuery OK, 0 rows affected (0.00 sec)\n\nQuery OK, 0 rows affected (0.00 sec)\n....</pre><p>Once tables are recreated discard their tablespaces. I will show an example for the table <code>foo</code>. Adjust the code for the rest of the tables.</p><pre class=\"crayon-plain-tag\">mysql&#62; alter table foo discard tablespace;\nQuery OK, 0 rows affected (0.01 sec)</pre><p>Then, in another terminal, copy the tablespace and configuration files from the backup to the database directory:</p><pre class=\"crayon-plain-tag\">cp full_backup/test/foo.{ibd,cfg} var/mysqld.1/data/test/</pre><p>And, finally, import the tablespace:</p><pre class=\"crayon-plain-tag\">mysql&#62; alter table foo import tablespace;\nQuery OK, 0 rows affected (0.05 sec)</pre><p>Repeat for the other tables in the database test.</p>\n<p>Now you can enable binary logging back.</p>\n<p>You can do the same task in a script. For example:</p><pre class=\"crayon-plain-tag\">for table in `mysql test --skip-column-names --silent -e \"show tables\"`\n&#62; do\n&#62;   mysql test -e \"set sql_log_bin=0; alter table $table discard tablespace\"\n&#62;   cp full_backup/test/$table.{ibd,cfg} var/mysqld.1/data/test/\n&#62;   mysql test -e \"set sql_log_bin=0; alter table $table import tablespace\"\n&#62; done</pre><p>Our tables are recovered but do not have the updates made after the backup.</p><pre class=\"crayon-plain-tag\">mysql&#62; select * from foo;\n+----+------+\n| id | f1   |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n|  5 |    5 |\n+----+------+\n5 rows in set (0.00 sec)\n\nmysql&#62; select * from bar;\n+----+------+\n| id | f1   |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n|  5 |    5 |\n+----+------+\n5 rows in set (0.00 sec)\n\nmysql&#62; select * from baz;\nEmpty set (0.00 sec)</pre><p>Therefore, we need to restore data from the binary logs.</p>\n<p>To do it we first need to identify the GTID of the disaster event. It can be done if we dump all binary logs updated and created after backup into a dump file and then search for the <code>DROP TABLE</code> and <code>DELETE</code> statements and skipping them.</p>\n<p>First, let&#8217;s check which binary logs do we have.</p><pre class=\"crayon-plain-tag\">mysql&#62; show binary logs;\n+-------------------+-----------+\n| Log_name          | File_size |\n+-------------------+-----------+\n| master-bin.000001 |   1527476 |\n| master-bin.000002 |      3035 |\n| master-bin.000003 |      1987 |\n| master-bin.000004 |      2466 |\n| master-bin.000005 |       784 |\n+-------------------+-----------+\n5 rows in set (0.00 sec)</pre><p>So we need to parse them, starting from the log <code>master-bin.000004</code> and position 1601:</p><pre class=\"crayon-plain-tag\">mysqlbinlog --start-position=1601 -vvv --base64-output=decode-rows --database=test master-bin.000004 master-bin.000005 &#62; binlog_test.sql</pre><p>I used options <code>-vvv</code> that prints SQL representation of row events, so we can find the one which we want to skip and <code>--base64-output=decode-rows</code> to not print row events at all. We will not use this file for the restore, only for searching the <code>DROP TABLE</code> and <code>DELETE</code> events.</p>\n<p>Here they are, at the positions 2007 and 2123, with GTID <code>0ec00eed-87f3-11eb-acd9-98af65266957:58</code> and <code>0ec00eed-87f3-11eb-acd9-98af65266957:59</code></p><pre class=\"crayon-plain-tag\"># at 2007\n#210321 13:29:58 server id 1 end_log_pos 2123 CRC32 0xd1eb9854 Query thread_id=138 exec_time=0 error_code=0\nuse `test`/*!*/;\nSET TIMESTAMP=1616322598/*!*/;\nDROP TABLE `foo` /* generated by server */\n/*!*/;\n# at 2123\n#210321 13:30:08 server id 1 end_log_pos 2188 CRC32 0xfc9b2088 GTID last_committed=7 sequence_number=8 rbr_only=yes original_committed_timestamp=0 immediate_commit_timestamp=0 transaction_length=0\n/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;\n# original_commit_timestamp=0 (1970-01-01 02:00:00.000000 EET)\n# immediate_commit_timestamp=0 (1970-01-01 02:00:00.000000 EET)\n/*!80001 SET @@session.original_commit_timestamp=0*//*!*/;\n/*!80014 SET @@session.original_server_version=0*//*!*/;\n/*!80014 SET @@session.immediate_server_version=0*//*!*/;\nSET @@SESSION.GTID_NEXT= '0ec00eed-87f3-11eb-acd9-98af65266957:59'/*!*/;\n# at 2188\n#210321 13:30:08 server id 1 end_log_pos 2260 CRC32 0x1d525b11 Query thread_id=138 exec_time=0 error_code=0\nSET TIMESTAMP=1616322608/*!*/;\nBEGIN\n/*!*/;\n# at 2260\n#210321 13:30:08 server id 1 end_log_pos 2307 CRC32 0xb57ecb73 Table_map: `test`.`bar` mapped to number 226\n# at 2307\n#210321 13:30:08 server id 1 end_log_pos 2387 CRC32 0x6770a7e2 Delete_rows: table id 226 flags: STMT_END_F\n### DELETE FROM `test`.`bar`\n### WHERE\n### @1=1 /* INT meta=0 nullable=0 is_null=0 */\n### @2=1 /* INT meta=0 nullable=1 is_null=0 */\n### DELETE FROM `test`.`bar`\n### WHERE\n...</pre><p>Note that decoded row event contains a <code>DELETE</code> command for each affected row.</p>\n<p>We may also find to which binary log this event belongs if search for the <code>\"Rotate to\"</code> event. In our case &#8220;Rotate to master-bin.000005&#8221; happened after the found positions, so we only need file <code>master-bin.000004</code> In your case, you may need to skip events from the previous log files too.</p>\n<p>So to restore the data we need to run <code>mysqlbinlog</code> one more time, this time with parameters:</p><pre class=\"crayon-plain-tag\">mysqlbinlog  --start-position=1601 --exclude-gtids=0ec00eed-87f3-11eb-acd9-98af65266957:58-59 --database=test --skip-gtids=true master-bin.000004 master-bin.000005 &#62; binlog_restore.sql</pre><p>I removed options <code>-vvv</code>because we are not going to examine this restore file and option <code>--base64-output=decode-rows</code> because we need row events to present in the resulting file. I also used option <code>--exclude-gtids=0ec00eed-87f3-11eb-acd9-98af65266957:58-59</code> to exclude GTIDs that we do not want to re-apply. We also need to use <code>--skip-gtids=true</code> because otherwise updates will be skipped since such GTIDs already exist on the server.</p>\n<p>Now <code>binlog_restore.sql</code> contains all updates to the database <code>test</code> made after the backup and before the <code>DROP</code> statement. Let&#8217;s restore it.</p><pre class=\"crayon-plain-tag\">mysql test &#60; binlog_restore.sql</pre><p>Restore went successfully. Our tables have all past updates.</p><pre class=\"crayon-plain-tag\">mysql&#62; select * from foo;\n+----+------+\n| id | f1   |\n+----+------+\n|  1 |    2 |\n|  2 |    4 |\n|  3 |    6 |\n|  4 |    8 |\n|  5 |   10 |\n+----+------+\n5 rows in set (0.01 sec)\n\nmysql&#62; select count(*) from bar;\n+----------+\n| count(*) |\n+----------+\n|       10 |\n+----------+\n1 row in set (0.00 sec)\n\nmysql&#62; select count(*) from baz;\n+----------+\n| count(*) |\n+----------+\n|        5 |\n+----------+\n1 row in set (0.00 sec)</pre><p></p>\n<h3>Conclusion</h3>\n<p>You may save the time required for PITR if use the per-database restore method. However, you need to take into account the following considerations:</p>\n<ul>\n<li><code>mysqlbinlog</code> does not support filtering per table, therefore you either need to restore the full database or use a fake server method, described in <a target=\"_blank\" href=\"https://www.percona.com/blog/2017/10/23/mysql-point-in-time-recovery-right-way/\">MySQL Point in Time Recovery the Right Way</a>.</li>\n<li>Per-database filters depend on the <code>USE</code> statement in the statement-based binary log format. Therefore option <a target=\"_blank\" href=\"https://dev.mysql.com/doc/refman/8.0/en/mysqlbinlog.html#option_mysqlbinlog_database\" target=\"_blank\" rel=\"noopener\"><code>--database</code></a> can only be considered safe with a row-based format.</li>\n<li>If you do not use GTID you still can use this method. You will need to combine options <code>--start-position</code> and <code>--stop-position</code> to skip the event.</li>\n</ul>\n<hr />\n<p style=\"text-align: center;\"><strong><a target=\"_blank\" href=\"https://www.percona.com/software/mysql-database/percona-xtrabackup?utm_source=blog\">Percona XtraBackup is a free, open source database backup solution for Percona Server for MySQL and MySQL.</a></strong></p>\n","descriptionType":"html","publishedDate":"Fri, 02 Apr 2021 16:15:42 +0000","feedId":11,"bgimg":"","linkMd5":"b4ed034325bd52a99b1d001860021fcb","bgimgJsdelivr":"","metaImg":"","author":"Sveta Smirnova","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn87@2020_3/2021/04/03/04-49-18-830_e8d33ad541551be8.webp","https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn44@2020_6/2021/04/03/04-49-17-076_ba069d05e8e022de.webp"},"publishedOrCreatedDate":1617425343760},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Percona Distribution for MongoDB 4.4.4, Bug Fix in Percona Server for MongoDB: Release Roundup March 1, 2021","link":"https://www.percona.com/blog/?p=74509","description":"<img width=\"200\" height=\"112\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-200x112.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Release Roundup March 1, 2021\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021.png 712w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><h2><img loading=\"lazy\" class=\"alignright size-medium wp-image-74683\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-300x169.png\" alt=\"Release Roundup March 1, 2021\" width=\"300\" height=\"169\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-300x169.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-200x112.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-367x206.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021.png 712w\" sizes=\"(max-width: 300px) 100vw, 300px\" />It&#8217;s release roundup time again here at Percona!</h2>\n<p>Our Release Roundups <span class=\"s1\">showcase the latest Percona software updates, tools, and features to help you manage and deploy our software. It offers</span> highlights and critical information, as well as links to the full release notes and direct links to the software or service itself to download.</p>\n<p>Today&#8217;s post includes those releases and updates that have come out since February 15, 2021, including the release of Percona Distribution for MongoDB 4.4.4.</p>\n<p>&#160;</p>\n<h2>Percona Distribution for MongoDB 4.4.4</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-distribution-for-mongodb/4.4/release-notes-v4.4.4.html\">Percona Distribution for MongoDB 4.4.4</a> was released on February 25, 2021. It is a collection of solutions to run and operate your MongoDB efficiently with the data being consistently backed up, consisting of the following components:</p>\n<ul class=\"simple\">\n<li><em>Percona Server for MongoDB</em> is a fully compatible open source, drop-in replacement for MongoDB.</li>\n<li><em>Percona Backup for MongoDB</em> is a distributed, low-impact solution for achieving consistent backups of MongoDB sharded clusters and replica sets.</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb\">Download Percona Distribution for MongoDB 4.4.4</a></p>\n<p>&#160;</p>\n<p style=\"text-align: center;\"><strong><a target=\"_blank\" class=\"ProsemirrorEditor-link\" href=\"http://percona.com/live/?utm_source=inblog\">Have open source expertise you want to share? Submit your talk for Percona Live ONLINE 2021!</a></strong></p>\n<p>&#160;</p>\n<h2>Percona Server for MongoDB 3.6.22-12.0</h2>\n<p>On February 23, 2021, <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/3.6/release_notes/3.6.22-12.0.html\">Percona Server for MongoDB 3.6.22-12.0</a> was released. An enhanced, open source, and highly-scalable database that is a fully-compatible, drop-in replacement for MongoDB 3.6.22 Community Edition, it supports MongoDB 3.6.22 protocols and drivers. In this release, bug <a target=\"_blank\" class=\"reference external\" href=\"https://jira.percona.com/browse/PSMDB-817\">PSMDB-817</a> was fixed, where LDAP ConnectionPoller always uses up CPU of one core (Thanks to user cleiton.domazak for reporting this issue).</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/software/mongodb/percona-server-for-mongodb\">Download Percona Server for MongoDB 3.6.22-12.0</a></p>\n<p>&#160;</p>\n<h2>Percona Server for MongoDB 4.4.4-6</h2>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server-for-mongodb/4.4/release_notes/4.4.4-6.html\">Percona Server for MongoDB 4.4.4-6</a> was released on February 25, 2021. It is a drop-in replacement for MongoDB 4.4.4 Community Edition. The same bug as above was fixed.</p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/downloads/percona-server-mongodb-LATEST/\">Download Percona Server for MongoDB 4.4.4-6</a></p>\n<p>&#160;</p>\n<p>That&#8217;s it for this roundup, and be sure to <a target=\"_blank\" href=\"https://twitter.com/Percona\" target=\"_blank\" rel=\"&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;&#34;noopener&#34; noopener noreferrer\">follow us on Twitter</a> to stay up-to-date on the most recent releases! Percona is a leader in providing best-of-breed enterprise-class support, consulting, managed services, training, and software for MySQL, MongoDB, PostgreSQL, MariaDB, and other open source databases in on-premises and cloud environments.</p>\n","descriptionType":"html","publishedDate":"Mon, 01 Mar 2021 13:58:05 +0000","feedId":11,"bgimg":"","linkMd5":"bf72694b5c2d4d2fcd88881c2eba6bb3","bgimgJsdelivr":"","metaImg":"","author":"David Quilty","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-200x112.png":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn71@2020_1/2021/04/03/04-49-11-357_47a07ab39626858e.webp","https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-300x169.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn65@2020_1/2021/04/03/04-49-05-251_a05a6e66ea592fc8.webp"},"publishedOrCreatedDate":1617425343781},{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","title":"Percona Monthly Bug Report: February 2021","link":"https://www.percona.com/blog/?p=74608","description":"<img width=\"200\" height=\"105\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-200x105.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Percona Bug report Feb 2021\" loading=\"lazy\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021.png 1200w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><p><span><strong><img loading=\"lazy\" class=\"alignright size-medium wp-image-74612\" src=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-300x157.png\" alt=\"Percona Bug report Feb 2021\" width=\"300\" height=\"157\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-300x157.png 300w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-1024x536.png 1024w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-200x105.png 200w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-1140x595.png 1140w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-367x192.png 367w, https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021.png 1200w\" sizes=\"(max-width: 300px) 100vw, 300px\" />Here at Percona, we operate on the premise that full-transparency makes a product better.</strong> We strive to build the best open-source database products, but also to help you manage any issues that arise in any of the databases that we support. And, in true open-source form, report back on any issues or bugs you might encounter along the way.</span></p>\n<p><span>We constantly update our </span><a target=\"_blank\" href=\"https://jira.percona.com/\"><span>bug reports</span></a><span> and monitor </span><a target=\"_blank\" href=\"https://bugs.mysql.com/\"><span>other boards</span></a><span> to ensure we have the latest information, but we wanted to make it a little easier for you to keep track of the most critical ones. This monthly post is a central place to get information on the most noteworthy open and recently resolved bugs. </span></p>\n<p><span>In this February 2021 edition of our monthly bug report, we have the following list of bugs:</span></p>\n<h2><span>Percona Server for MySQL/MySQL Bugs</span></h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-7477\">PS-7477</a> (<a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=101257\">MySQL#101257</a>) : MySQL-8 Crash. Prepared statements involving stored programs could cause MySQL to crash due to heap-use-after-free memory problems.</strong></p>\n<p><span>Affects Version/s: 8.0.22  [Tested/Reported version 8.0.22]</span></p>\n<p><span>Fixed Version/s: 8.0.23</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-7567\">PS-7567</a>: When <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/LATEST/management/enforce_engine.html\"><i>enforce_storage_engine</i></a><i> = InnoDB</i> is set and a minor version upgrade performed, you can no longer view system and status variables.</strong></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/doc/percona-server/LATEST/management/enforce_engine.html\"><i><span>enforce_storage_engine</span></i></a><span> option is only available in Percona Server, so the bug only applicable to Percona Server. SHOW VARIABLES and SHOW STATUS both affected due to engine change of Performance_schema tables.</span></p>\n<p><span>Affects Version/s: 8.0.22  [Tested/Reported version 8.0.22]</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=102586\">MySQL#102586</a>:  When doing a multiple-table DELETE that is anticipating a foreign key ON DELETE CASCADE, the statements work on the primary but it breaks row-based replication.</strong></p>\n<p><span>Affects Version/s: 8.0, 5.7  [Tested/Reported version 8.0.23, 5.7.33]</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=102175\">MySQL#102175</a>:  When the server is under heavy write operation, binary_log_position of gitid_executed shown in PS.log_status table doesn&#8217;t match with the position of that gitd shown in the binary log file. The impact of this bug is, It could break replication when using this GTID position information to start replication. </strong></p>\n<p><span>Affects Version/s: 8.0.22  [Tested/Reported version 8.0.22]</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-7498\">PS-7498</a>(<a target=\"_blank\" href=\"https://bugs.mysql.com/bug.php?id=102647\">MySQL#102647</a>): Replica sql_thread getting stuck due to MASTER_DELAY. The replication applier thread in a multi-threaded replica can randomly get stuck in the &#8220;Waiting until MASTER_DELAY seconds after master executed event&#8221; state and doesn&#8217;t apply any transaction for a long time when the replica is configured with MASTER_DELAY.</strong></p>\n<p><span>The issue happens only when parallel replication enabled (slave_parallel_workers &#62; 1) and sql_delay is enabled on the replica. Disabling the parallel replication fixes the issue and sql_thread resumes the work as expected.</span></p>\n<p><span>Affects Version/s: 5.7  [Tested/Reported version 5.7.32]</span></p>\n<p><span>In Percona Server we fixed this issue and the fix will be available in the next release.</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-6876\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69259\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PS-7542\">PS-7542</a>: SELECT query which creates temporary tables could lead to “<i>ERROR 1022 (23000): Can&#8217;t write; duplicate key in table &#8216;/path/tmp/#sqla882_21_2</i>&#8216;” error.</strong></p>\n<p><span>Workaround: Running the same SELECT query works fine after changing internal_tmp_mem_storage_engine from TempTable(default) to MEMORY.</span></p>\n<p><span>Affects Version/s: 8.0  [Tested/Reported version 8.0.17-8, 8.0.22-13]</span></p>\n<p>&#160;</p>\n<p style=\"text-align: center;\" data-pm-slice=\"1 1 []\"><strong><a target=\"_blank\" class=\"ProsemirrorEditor-link\" href=\"http://percona.com/live/?utm_source=inblog\">Have open source expertise you want to share? Submit your talk for Percona Live ONLINE 2021!</a></strong></p>\n<h2><span>Percona XtraDB Cluster</span></h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3248\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69263\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3536\">PXC-3536</a>: PXC Cluster data inconsistency after MDL conflict solved.</strong></p>\n<p><span>Affects Version/s: 8.0,5.7  [Tested/Reported version </span><span>8.0.21-12.1, 5.7.31-31.45.3</span><span>]</span></p>\n<p>&#160;</p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3248\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69263\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png\" alt=\"\" width=\"75\" height=\"75\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXC-3455\">PXC-3455</a>: When binlog disabled (skip-log-bin = 1) on the PXC node it crashes when a table with composite keys queried by SHOW INDEXES. </strong></p>\n<p><span>Affects Version/s: 8.0  [Tested/Reported version 8.0.19-10, 8.0.21-12.1]</span></p>\n<p>&#160;</p>\n<h2><span>Percona XtraBackup</span></h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2162\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69262\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2375\">PXB-2375</a>:  In some cases, XtraBackup will write the wrong binlog filename, pos, and GTID combination info in xtrabackup_binlog_info. </strong></p>\n<p><span>If we are using this backup with GTID position details in xtrabackup_binlog_info to create a new replica, then most likely replication will break due to incorrect GTID position.</span></p>\n<p><span>Looks like the GTID position is not consistent with binlog file pos, they are captured differently and later printed together in xtrabackup_binlog_info  file.</span></p>\n<p><span>Affects Version/s:  8.0 [Tested/Reported version 8.0.14]</span></p>\n<p><strong> </strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2162\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69262\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PXB-2274\">PXB-2274</a>: XtraBackup prepare fails with the wrong LSN message when there are DML statements running during a backup stage.</strong></p>\n<p><span>Affects Version/s: 8.0 [Tested/Reported version 8.0.22-15]</span></p>\n<p><span>Fixed Version/s: 8.0.23 [Next release]</span></p>\n<p>&#160;</p>\n<h2><span>Percona Toolkit</span></h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1747\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69264\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1914\">PT-1914</a>: When using pt-osc on a table that has a column with the &#8216;Generated&#8217; word in the column comment then it will remove all data in some columns.</strong></p>\n<p><span>Affects Version/s:  3.0.13, 3.2.1, 3.3.0</span></p>\n<p><strong> </strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1747\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69264\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png\" alt=\"\" width=\"75\" height=\"74\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PT-1919\">PT-1919</a>:  Running a pt-osc on a table that has trigger/s with <a target=\"_blank\" href=\"https://www.percona.com/doc/percona-toolkit/3.0/pt-online-schema-change.html#cmdoption-pt-online-schema-change-alter-foreign-keys-method\">alter-foreign-keys-method</a> drop_swap mode (or auto mode which could choose drop swap) will delete some trigger/s.</strong></p>\n<p><span>Affects Version/s:  3.2.1, 3.3.0</span></p>\n<p>&#160;</p>\n<h2><span>PMM  [Percona Monitoring and Management]</span></h2>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-5364\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" class=\"alignleft size-full wp-image-69261\" src=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png\" alt=\"\" width=\"75\" height=\"76\" srcset=\"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png 75w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-32x32.png 32w, https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug-50x50.png 50w\" sizes=\"(max-width: 75px) 100vw, 75px\" /></a></strong></p>\n<p><strong><a target=\"_blank\" href=\"https://jira.percona.com/browse/PMM-4665\">PMM-4665</a>: Frequent error messages in pmm-agent.log for components like tokudb storage engine which are not supported by upstream MySQL instance. </strong></p>\n<p><span>Affects Version/s:  2.x  </span><span>[Tested/Reported version </span><span>2.0.13</span><span>]</span></p>\n<p>&#160;</p>\n<h2><span>Summary</span></h2>\n<p><span>We welcome community input and feedback on all our products. If you find a bug or would like to suggest an improvement or a feature, learn how in our post, </span><a target=\"_blank\" href=\"https://www.percona.com/blog/2019/06/12/report-bugs-improvements-new-feature-requests-for-percona-products/\"><span>How to Report Bugs, Improvements, New Feature Requests for Percona Products</span></a><span>.</span></p>\n<p><span>For the most up-to-date information, be sure to follow us on </span><a target=\"_blank\" href=\"https://twitter.com/percona\"><span>Twitter</span></a><span>, </span><a target=\"_blank\" href=\"https://www.linkedin.com/company/percona\"><span>LinkedIn</span></a><span>, and </span><a target=\"_blank\" href=\"https://www.facebook.com/Percona?fref=ts\"><span>Facebook</span></a><span>.</span></p>\n<p><b>Quick References:</b></p>\n<p><a target=\"_blank\" href=\"https://jira.percona.com\"><span>Percona JIRA </span></a><span> </span></p>\n<p><a target=\"_blank\" href=\"https://bugs.mysql.com/\"><span>MySQL Bug Report</span></a></p>\n<p><a target=\"_blank\" href=\"https://www.percona.com/blog/2019/06/12/report-bugs-improvements-new-feature-requests-for-percona-products/\"><span>Report a Bug in a Percona Product</span></a></p>\n<p><span>___</span></p>\n<p><b>About Percona:</b></p>\n<p><span>As the only provider of distributions for all three of the most popular open source databases—PostgreSQL, MySQL, and MongoDB—Percona provides </span><a target=\"_blank\" href=\"https://www.percona.com/services/consulting\"><span>expertise</span></a><span>, </span><a target=\"_blank\" href=\"https://www.percona.com/software\"><span>software</span></a><span>, </span><a target=\"_blank\" href=\"https://www.percona.com/services/support/mysql-support\"><span>support</span></a><span>, and </span><a target=\"_blank\" href=\"https://www.percona.com/services/managed-services\"><span>services</span></a><span> no matter the technology.</span></p>\n<p><span>Whether it&#8217;s enabling developers or DBAs to realize value faster with tools, advice, and guidance, or making sure applications can scale and handle peak loads, Percona is here to help.</span></p>\n<p><span>Percona is committed to being open source and preventing vendor lock-in. Percona contributes all changes to the upstream community for possible inclusion in future product releases.</span></p>\n","descriptionType":"html","publishedDate":"Thu, 25 Feb 2021 13:31:30 +0000","feedId":11,"bgimg":"","linkMd5":"82cf99cfa352824abe981b34160ae8a2","bgimgJsdelivr":"","metaImg":"","author":"Lalit Choudhary","articleImgCdnMap":{"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-200x105.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn35@2020_2/2021/04/03/04-49-19-498_66d8e46003af2501.webp","https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-300x157.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn8@2020_1/2021/04/03/04-49-14-445_959751926e13a87c.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn51@2020_3/2021/04/03/04-49-37-940_2826482aac8c233a.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn52@2020_2/2021/04/03/04-49-09-923_8d1760662c65eda5.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn47@2020_3/2021/04/03/04-49-20-595_147c67c11b518b52.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn28@2020_5/2021/04/03/04-49-21-261_abb43840edeeeb7b.webp","https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn56@2020_1/2021/04/03/04-49-10-394_8f6b725a02096785.webp"},"publishedOrCreatedDate":1617425343831}],"record":{"createdTime":"2021-04-03 12:49:03","updatedTime":"2021-04-03 12:49:03","feedId":11,"fetchDate":"Sat, 03 Apr 2021 04:49:03 +0000","fetchMs":685,"handleMs":1730,"totalMs":50401,"newArticles":0,"totalArticles":40,"status":1,"type":0,"ip":"794c4e5e0c84feb835750305582528f2","hostName":"us-034*","requestId":"d48161e422ef4885952e1069b3474f6b_11","contentType":"application/rss+xml; charset=UTF-8","totalBytes":1432836,"bgimgsTotal":0,"bgimgsGithubTotal":0,"articlesImgsTotal":121,"articlesImgsGithubTotal":121,"successGithubMap":{"myreaderx14":3,"myreaderx8":4,"myreaderx7":4,"myreaderx15":4,"myreaderx6":4,"myreaderx16":5,"myreaderx10":4,"myreaderx32":4,"myreaderx4":3,"myreaderx33":3,"myreaderx3":5,"myreaderx11":4,"myreaderx12":4,"myreaderx2":5,"myreaderx13":4,"myreaderx1":4,"myreaderx30":4,"myreaderx31":5,"myreaderx18":5,"myreaderx19":4,"myreaderx":4,"myreaderx25":3,"myreaderx27":4,"myreaderx21":4,"myreaderx22":5,"myreaderx23":4,"myreaderx24":5,"myreaderx5oss":5,"myreaderx29":5},"failGithubMap":{}},"feed":{"createdTime":"2020-05-30 17:21:38","updatedTime":"2020-09-01 09:23:03","id":11,"name":"Percona Database Performance Blog","url":"https://www.percona.com/blog/feed/","subscriber":null,"website":null,"icon":"https://www.percona.com/blog/wp-content/uploads/2018/09/percona-32x32.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn89@2020_6/2020/09/01/01-23-01-358_b72bb3b39c378fe6.png","description":"","weekly":null,"link":null},"noPictureArticleList":[],"tmpCommonImgCdnBytes":0,"tmpBodyImgCdnBytes":1432836,"tmpBgImgCdnBytes":0,"extra4":{"start":1617425341285,"total":0,"statList":[{"spend":855,"msg":"获取xml内容"},{"spend":1730,"msg":"解释文章"},{"spend":13,"msg":"上传封面图到cdn"},{"spend":6,"msg":"修正封面图上传失败重新上传"},{"spend":47282,"msg":"正文链接上传到cdn"}]},"extra5":121,"extra6":121,"extra7ImgCdnFailResultVector":[],"extra10_invalidATagHrefValue":{"https://www.percona.com/blog/?p=74571_mailto:hoss@percona.com":"mailto:hoss@percona.com"},"extra111_proxyServerAndStatMap":{"http://us-032.herokuapp.com/":{"failCount":0,"successCount":8,"resultList":[200,200,200,200,200,200,200,200]},"http://us-037.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://europe68.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe63.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://us-028.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://us-024.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://europe70.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-020.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://europe69.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe-23.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe21.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://us-004.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://europe64.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-22.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-008.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://us-016.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://us-012.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://us-018.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-24.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-55.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://us-021.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-58.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-030.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-006.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-25.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://europe67.herokuapp.com/":{"failCount":0,"successCount":8,"resultList":[200,200,200,200,200,200,200,200]},"http://us-51.herokuapp.com/":{"failCount":0,"successCount":7,"resultList":[200,200,200,200,200,200,200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_210326.png","sourceStatusCode":200,"destWidth":1021,"destHeight":765,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn100@2020_1/2021/04/03/04-49-04-557_56c9a26c5b89573e.webp","sourceBytes":60752,"destBytes":31268,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1136,"convertSpendMs":34,"createdTime":"2021-04-03 12:49:04","host":"us-018*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"59.3 KB","destSize":"30.5 KB","compressRate":"51.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/import-dashboard.png","sourceStatusCode":200,"destWidth":985,"destHeight":369,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn69@2020_5/2021/04/03/04-49-05-157_84e7b7084f62013c.webp","sourceBytes":22982,"destBytes":11294,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1610,"convertSpendMs":12,"createdTime":"2021-04-03 12:49:04","host":"europe-24*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.4 KB","destSize":"11 KB","compressRate":"49.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/ConnectionThoughQueue.png","sourceStatusCode":200,"destWidth":646,"destHeight":81,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn44@2020_4/2021/04/03/04-49-05-486_2413c241661828dd.webp","sourceBytes":23121,"destBytes":13646,"targetWebpQuality":75,"feedId":11,"totalSpendMs":914,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:05","host":"us-032*","referer":"https://www.percona.com/blog/?p=74480","linkMd5ListStr":"16d12f2d30b182a5a838c7da9d71dec1","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.6 KB","destSize":"13.3 KB","compressRate":"59%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn8@2020_3/2021/04/03/04-49-05-152_1c4faf7fd610ade6.webp","sourceBytes":32063,"destBytes":7034,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1752,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:04","host":"europe69*","referer":"https://www.percona.com/blog/?p=75187","linkMd5ListStr":"8cbdc4fcf8dbffae590b23534dfa7ddf","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.3 KB","destSize":"6.9 KB","compressRate":"21.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/namespaces-1024x292.png","sourceStatusCode":200,"destWidth":1024,"destHeight":292,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn57@2020_2/2021/04/03/04-49-05-325_73bc49ce5122fcd1.webp","sourceBytes":149950,"destBytes":14320,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1804,"convertSpendMs":17,"createdTime":"2021-04-03 12:49:04","host":"europe68*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"146.4 KB","destSize":"14 KB","compressRate":"9.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_211845-1024x64.png","sourceStatusCode":200,"destWidth":1024,"destHeight":64,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn52@2020_4/2021/04/03/04-49-04-554_df9de04ac9ee2423.webp","sourceBytes":31545,"destBytes":7820,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2057,"convertSpendMs":10,"createdTime":"2021-04-03 12:49:04","host":"us-040*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"30.8 KB","destSize":"7.6 KB","compressRate":"24.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-200x113.png","sourceStatusCode":200,"destWidth":200,"destHeight":113,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn13@2020_3/2021/04/03/04-49-05-089_52f219c11251929e.webp","sourceBytes":13847,"destBytes":5070,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1983,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:04","host":"europe-58*","referer":"https://www.percona.com/blog/?p=75088","linkMd5ListStr":"2425d4b26612cefc91bda1b5433432f9","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.5 KB","destSize":"5 KB","compressRate":"36.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn53@2020_4/2021/04/03/04-49-05-142_da3beca23c6b32fa.webp","sourceBytes":22239,"destBytes":7750,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2089,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:04","host":"europe-25*","referer":"https://www.percona.com/blog/?p=74520","linkMd5ListStr":"9f9459a2d8847538d0d0e9f9eaf46481","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.7 KB","destSize":"7.6 KB","compressRate":"34.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn65@2020_1/2021/04/03/04-49-05-251_a05a6e66ea592fc8.webp","sourceBytes":86161,"destBytes":10584,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2260,"convertSpendMs":8,"createdTime":"2021-04-03 12:49:04","host":"europe-22*","referer":"https://www.percona.com/blog/?p=74509","linkMd5ListStr":"bf72694b5c2d4d2fcd88881c2eba6bb3","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.1 KB","destSize":"10.3 KB","compressRate":"12.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_202748-1024x193.png","sourceStatusCode":200,"destWidth":1024,"destHeight":193,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn64@2020_5/2021/04/03/04-49-05-313_f76658530ac4b36e.webp","sourceBytes":85663,"destBytes":15864,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2549,"convertSpendMs":14,"createdTime":"2021-04-03 12:49:04","host":"europe21*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"83.7 KB","destSize":"15.5 KB","compressRate":"18.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn87@2020_2/2021/04/03/04-49-06-511_fbf707727f76d771.webp","sourceBytes":48350,"destBytes":12926,"targetWebpQuality":75,"feedId":11,"totalSpendMs":887,"convertSpendMs":11,"createdTime":"2021-04-03 12:49:06","host":"us-008*","referer":"https://www.percona.com/blog/?p=74644","linkMd5ListStr":"82fb984c6056ef4f100542a596e971d9","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"47.2 KB","destSize":"12.6 KB","compressRate":"26.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/leader-winter-white-3-1024x702.jpg","sourceStatusCode":200,"destWidth":1024,"destHeight":702,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn60@2020_6/2021/04/03/04-49-05-343_4b77b64d9f82a043.webp","sourceBytes":132831,"destBytes":86518,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3114,"convertSpendMs":37,"createdTime":"2021-04-03 12:49:04","host":"europe69*","referer":"https://www.percona.com/blog/?p=74740","linkMd5ListStr":"b55980eba389b4a5afc63dd445b1a854","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"129.7 KB","destSize":"84.5 KB","compressRate":"65.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/creating-a-percona-product-release-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn80@2020_1/2021/04/03/04-49-06-456_43956f05338d33c0.webp","sourceBytes":13189,"destBytes":3836,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1473,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:06","host":"us-032*","referer":"https://www.percona.com/blog/?p=74764","linkMd5ListStr":"b7cbc67aa9f9a490a47146c51cd54179","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.9 KB","destSize":"3.7 KB","compressRate":"29.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn61@2020_3/2021/04/03/04-49-05-274_b9db5810a75a37e6.webp","sourceBytes":42445,"destBytes":5084,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3211,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:04","host":"europe70*","referer":"https://www.percona.com/blog/?p=74692","linkMd5ListStr":"31583d79676cf36b069aeb75d5f083f0","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.5 KB","destSize":"5 KB","compressRate":"12%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn92@2020_2/2021/04/03/04-49-07-353_e70c64bba01281fe.webp","sourceBytes":74948,"destBytes":9468,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1247,"convertSpendMs":8,"createdTime":"2021-04-03 12:49:06","host":"europe21*","referer":"https://www.percona.com/blog/?p=74438","linkMd5ListStr":"bdbdc777b5768814fb7bc017456c5e61","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"73.2 KB","destSize":"9.2 KB","compressRate":"12.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn16@2020_5/2021/04/03/04-49-07-821_ca7609853f9cc723.webp","sourceBytes":10053,"destBytes":3126,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1750,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:07","host":"europe63*","referer":"https://www.percona.com/blog/?p=74538","linkMd5ListStr":"acf85eccf23ec1e00967361275f02244","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"9.8 KB","destSize":"3.1 KB","compressRate":"31.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-3.png","sourceStatusCode":200,"destWidth":970,"destHeight":780,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn11@2020_1/2021/04/03/04-49-07-609_7328624c08adbb47.webp","sourceBytes":39499,"destBytes":26058,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2077,"convertSpendMs":33,"createdTime":"2021-04-03 12:49:07","host":"europe-25*","referer":"https://www.percona.com/blog/?p=75187","linkMd5ListStr":"8cbdc4fcf8dbffae590b23534dfa7ddf","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"38.6 KB","destSize":"25.4 KB","compressRate":"66%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn8@2020_2/2021/04/03/04-49-08-691_c8f34cc28b6843c5.webp","sourceBytes":43646,"destBytes":6348,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1709,"convertSpendMs":35,"createdTime":"2021-04-03 12:49:07","host":"us-012*","referer":"https://www.percona.com/blog/?p=74571","linkMd5ListStr":"835b3d62eed8d5aa41a9e425666acfe4","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"42.6 KB","destSize":"6.2 KB","compressRate":"14.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/pod_utilization-1024x299.png","sourceStatusCode":200,"destWidth":1024,"destHeight":299,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn68@2020_1/2021/04/03/04-49-08-377_e9cfb6662c36a3f2.webp","sourceBytes":83962,"destBytes":11856,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2076,"convertSpendMs":29,"createdTime":"2021-04-03 12:49:07","host":"europe-23*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"82 KB","destSize":"11.6 KB","compressRate":"14.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/blue-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":75,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn52@2020_2/2021/04/03/04-49-09-923_8d1760662c65eda5.webp","sourceBytes":5432,"destBytes":1446,"targetWebpQuality":75,"feedId":11,"totalSpendMs":745,"convertSpendMs":11,"createdTime":"2021-04-03 12:49:09","host":"us-008*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.3 KB","destSize":"1.4 KB","compressRate":"26.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn44@2020_5/2021/04/03/04-49-09-229_9b745d3cbedc0d17.webp","sourceBytes":55719,"destBytes":7572,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2018,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:09","host":"us-032*","referer":"https://www.percona.com/blog/?p=75057","linkMd5ListStr":"d4611282a8da21922c609e19f4374a12","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"54.4 KB","destSize":"7.4 KB","compressRate":"13.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_153848-1024x438.png","sourceStatusCode":200,"destWidth":1024,"destHeight":438,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn63@2020_6/2021/04/03/04-49-10-914_1ab5b4b3b71c05c4.webp","sourceBytes":276823,"destBytes":31392,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1660,"convertSpendMs":35,"createdTime":"2021-04-03 12:49:09","host":"us-016*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"270.3 KB","destSize":"30.7 KB","compressRate":"11.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-1-2021-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn71@2020_1/2021/04/03/04-49-11-357_47a07ab39626858e.webp","sourceBytes":42264,"destBytes":5096,"targetWebpQuality":75,"feedId":11,"totalSpendMs":836,"convertSpendMs":11,"createdTime":"2021-04-03 12:49:11","host":"us-012*","referer":"https://www.percona.com/blog/?p=74509","linkMd5ListStr":"bf72694b5c2d4d2fcd88881c2eba6bb3","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.3 KB","destSize":"5 KB","compressRate":"12.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/red-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":76,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn56@2020_1/2021/04/03/04-49-10-394_8f6b725a02096785.webp","sourceBytes":5436,"destBytes":1454,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2116,"convertSpendMs":4,"createdTime":"2021-04-03 12:49:09","host":"europe21*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.3 KB","destSize":"1.4 KB","compressRate":"26.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/04/Infinitely-Scalable-Storage-with-High-Compression-Feature-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn27@2020_2/2021/04/03/04-49-10-768_055594309ba93c46.webp","sourceBytes":55500,"destBytes":13218,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3108,"convertSpendMs":27,"createdTime":"2021-04-03 12:49:09","host":"us-016*","referer":"https://www.percona.com/blog/?p=75187","linkMd5ListStr":"8cbdc4fcf8dbffae590b23534dfa7ddf","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"54.2 KB","destSize":"12.9 KB","compressRate":"23.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn35@2020_5/2021/04/03/04-49-11-597_0f8a5d14ed442be6.webp","sourceBytes":34651,"destBytes":10990,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2276,"convertSpendMs":15,"createdTime":"2021-04-03 12:49:10","host":"europe67*","referer":"https://www.percona.com/blog/?p=74562","linkMd5ListStr":"05b384867001d9b6ccbb12624b6b34cd","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"33.8 KB","destSize":"10.7 KB","compressRate":"31.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn75@2020_4/2021/04/03/04-49-12-398_8c4b4d496e8d4c47.webp","sourceBytes":14775,"destBytes":4478,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1779,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:11","host":"europe-25*","referer":"https://www.percona.com/blog/?p=74407","linkMd5ListStr":"d71c22ae0c04f164edfa81af13728f44","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"14.4 KB","destSize":"4.4 KB","compressRate":"30.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Open-Source-Podcast-1024x386.png","sourceStatusCode":200,"destWidth":1024,"destHeight":386,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn56@2020_4/2021/04/03/04-49-11-964_5d5abae9dce4c934.webp","sourceBytes":403089,"destBytes":22474,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2854,"convertSpendMs":60,"createdTime":"2021-04-03 12:49:10","host":"europe67*","referer":"https://www.percona.com/blog/?p=74571","linkMd5ListStr":"835b3d62eed8d5aa41a9e425666acfe4","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"393.6 KB","destSize":"21.9 KB","compressRate":"5.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Copy-of-simplified-release-process-.jpg","sourceStatusCode":200,"destWidth":960,"destHeight":540,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn79@2020_3/2021/04/03/04-49-12-812_4ed60fcf5dba1995.webp","sourceBytes":64964,"destBytes":47070,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2169,"convertSpendMs":19,"createdTime":"2021-04-03 12:49:12","host":"europe63*","referer":"https://www.percona.com/blog/?p=74764","linkMd5ListStr":"b7cbc67aa9f9a490a47146c51cd54179","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"63.4 KB","destSize":"46 KB","compressRate":"72.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-16-1024x432.png","sourceStatusCode":200,"destWidth":1024,"destHeight":432,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn96@2020_2/2021/04/03/04-49-13-538_09c88bf99462b43d.webp","sourceBytes":163310,"destBytes":26182,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1638,"convertSpendMs":31,"createdTime":"2021-04-03 12:49:12","host":"europe-59*","referer":"https://www.percona.com/blog/?p=74946","linkMd5ListStr":"ad5af7759a03394ee27c6d95b528d5c4","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"159.5 KB","destSize":"25.6 KB","compressRate":"16%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/k8s_summary-1024x258.png","sourceStatusCode":200,"destWidth":1024,"destHeight":258,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn72@2020_4/2021/04/03/04-49-11-923_2b77e5debabace4c.webp","sourceBytes":172423,"destBytes":16056,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3233,"convertSpendMs":33,"createdTime":"2021-04-03 12:49:11","host":"europe67*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"168.4 KB","destSize":"15.7 KB","compressRate":"9.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn8@2020_1/2021/04/03/04-49-14-445_959751926e13a87c.webp","sourceBytes":48310,"destBytes":7748,"targetWebpQuality":75,"feedId":11,"totalSpendMs":412,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:14","host":"us-032*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"47.2 KB","destSize":"7.6 KB","compressRate":"16%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn92@2020_5/2021/04/03/04-49-13-435_3795a759750ccc96.webp","sourceBytes":11658,"destBytes":3470,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2012,"convertSpendMs":16,"createdTime":"2021-04-03 12:49:13","host":"us-016*","referer":"https://www.percona.com/blog/?p=74946","linkMd5ListStr":"ad5af7759a03394ee27c6d95b528d5c4","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.4 KB","destSize":"3.4 KB","compressRate":"29.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-20-1024x662.png","sourceStatusCode":200,"destWidth":1024,"destHeight":662,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn15@2020_5/2021/04/03/04-49-14-551_5ba608d243daec00.webp","sourceBytes":143897,"destBytes":15968,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1027,"convertSpendMs":40,"createdTime":"2021-04-03 12:49:14","host":"us-008*","referer":"https://www.percona.com/blog/?p=75187","linkMd5ListStr":"8cbdc4fcf8dbffae590b23534dfa7ddf","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"140.5 KB","destSize":"15.6 KB","compressRate":"11.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/sharding-remove-2.png","sourceStatusCode":200,"destWidth":963,"destHeight":668,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn59@2020_4/2021/04/03/04-49-13-696_606c7d7f493309d5.webp","sourceBytes":49361,"destBytes":25980,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2405,"convertSpendMs":32,"createdTime":"2021-04-03 12:49:13","host":"europe-59*","referer":"https://www.percona.com/blog/?p=74786","linkMd5ListStr":"927214461581e653db7f74f537604e7a","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"48.2 KB","destSize":"25.4 KB","compressRate":"52.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_201736-1024x186.png","sourceStatusCode":200,"destWidth":1024,"destHeight":186,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn99@2020_4/2021/04/03/04-49-14-597_56dfa2673511a53d.webp","sourceBytes":110921,"destBytes":12220,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1742,"convertSpendMs":17,"createdTime":"2021-04-03 12:49:13","host":"europe67*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"108.3 KB","destSize":"11.9 KB","compressRate":"11%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/add-shard.png","sourceStatusCode":200,"destWidth":879,"destHeight":639,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn4@2020_5/2021/04/03/04-49-14-431_60cb0436e9b1f552.webp","sourceBytes":49936,"destBytes":28682,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1844,"convertSpendMs":120,"createdTime":"2021-04-03 12:49:13","host":"us-006*","referer":"https://www.percona.com/blog/?p=74786","linkMd5ListStr":"927214461581e653db7f74f537604e7a","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"48.8 KB","destSize":"28 KB","compressRate":"57.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Developers-Love-About-MongoDB-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn36@2020_5/2021/04/03/04-49-15-749_e4ac3fdf92043475.webp","sourceBytes":21812,"destBytes":8064,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1421,"convertSpendMs":13,"createdTime":"2021-04-03 12:49:15","host":"us-012*","referer":"https://www.percona.com/blog/?p=74407","linkMd5ListStr":"d71c22ae0c04f164edfa81af13728f44","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.3 KB","destSize":"7.9 KB","compressRate":"37%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn24@2020_4/2021/04/03/04-49-15-893_f151b0dc68abd10d.webp","sourceBytes":12059,"destBytes":4548,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1481,"convertSpendMs":56,"createdTime":"2021-04-03 12:49:15","host":"us-028*","referer":"https://www.percona.com/blog/?p=74401","linkMd5ListStr":"f7c6d6db32b6967f9cdedeaf02051422","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"11.8 KB","destSize":"4.4 KB","compressRate":"37.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/ScaleFlux-Computational-Storage-Drive-PostgreSQL-1-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn88@2020_4/2021/04/03/04-49-15-894_9a70fe567f5a6900.webp","sourceBytes":14500,"destBytes":4018,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1683,"convertSpendMs":48,"createdTime":"2021-04-03 12:49:15","host":"us-028*","referer":"https://www.percona.com/blog/?p=74710","linkMd5ListStr":"aaf1719f47ea1c56bcbff35f0f9ebdcc","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"14.2 KB","destSize":"3.9 KB","compressRate":"27.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn23@2020_3/2021/04/03/04-49-15-929_f943f262a565a9ed.webp","sourceBytes":21974,"destBytes":5282,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1825,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:15","host":"europe-59*","referer":"https://www.percona.com/blog/?p=74605","linkMd5ListStr":"8d7b08bfa2026cbb9dd9940b036d9b67","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.5 KB","destSize":"5.2 KB","compressRate":"24%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Important-Skills-for-an-SRE-DBRE-or-DBA-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn20@2020_6/2021/04/03/04-49-15-453_e852089897d562c7.webp","sourceBytes":16065,"destBytes":4234,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2497,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:14","host":"europe21*","referer":"https://www.percona.com/blog/?p=74520","linkMd5ListStr":"9f9459a2d8847538d0d0e9f9eaf46481","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.7 KB","destSize":"4.1 KB","compressRate":"26.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Webinar-Introduction-to-pg_stat_monitor-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn39@2020_3/2021/04/03/04-49-16-492_dec5e4e3a513f0fa.webp","sourceBytes":25894,"destBytes":3972,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1559,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:15","host":"europe-25*","referer":"https://www.percona.com/blog/?p=74743","linkMd5ListStr":"fbff45194291c54a093ef301d60ae273","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.3 KB","destSize":"3.9 KB","compressRate":"15.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/storing-kubernetes-MongoDB-secrets-github-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn4@2020_4/2021/04/03/04-49-16-807_55a5ba77bf02fa12.webp","sourceBytes":22206,"destBytes":7032,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1235,"convertSpendMs":10,"createdTime":"2021-04-03 12:49:16","host":"us-55*","referer":"https://www.percona.com/blog/?p=74946","linkMd5ListStr":"ad5af7759a03394ee27c6d95b528d5c4","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.7 KB","destSize":"6.9 KB","compressRate":"31.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn39@2020_6/2021/04/03/04-49-17-421_7ad68a4f647ff723.webp","sourceBytes":21649,"destBytes":8544,"targetWebpQuality":75,"feedId":11,"totalSpendMs":450,"convertSpendMs":16,"createdTime":"2021-04-03 12:49:17","host":"us-55*","referer":"https://www.percona.com/blog/?p=74998","linkMd5ListStr":"70eede3fb1727a158133024b99497716","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.1 KB","destSize":"8.3 KB","compressRate":"39.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/blog-Page-1-1-1024x670.png","sourceStatusCode":200,"destWidth":1024,"destHeight":670,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn68@2020_1/2021/04/03/04-49-17-673_ac61de0382dbba73.webp","sourceBytes":166838,"destBytes":32104,"targetWebpQuality":75,"feedId":11,"totalSpendMs":686,"convertSpendMs":96,"createdTime":"2021-04-03 12:49:17","host":"us-55*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"162.9 KB","destSize":"31.4 KB","compressRate":"19.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn68@2020_1/2021/04/03/04-49-17-126_47d9f58641e2021e.webp","sourceBytes":27714,"destBytes":6950,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1635,"convertSpendMs":130,"createdTime":"2021-04-03 12:49:16","host":"us-024*","referer":"https://www.percona.com/blog/?p=74624","linkMd5ListStr":"4b3e9d6af32194c291344246b19ca57c","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.1 KB","destSize":"6.8 KB","compressRate":"25.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn64@2020_2/2021/04/03/04-49-17-945_dcd6bfbe09757110.webp","sourceBytes":18765,"destBytes":3892,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1075,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:17","host":"europe67*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.3 KB","destSize":"3.8 KB","compressRate":"20.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn31@2020_1/2021/04/03/04-49-17-507_5072804b0dbd6d23.webp","sourceBytes":86425,"destBytes":10672,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1988,"convertSpendMs":131,"createdTime":"2021-04-03 12:49:16","host":"us-024*","referer":"https://www.percona.com/blog/?p=74250","linkMd5ListStr":"703b15df2427397e9cc1f07b723cde7e","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.4 KB","destSize":"10.4 KB","compressRate":"12.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/future-1-145x150.jpeg","sourceStatusCode":200,"destWidth":145,"destHeight":150,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn59@2020_5/2021/04/03/04-49-16-608_aeb9c6e8a3975ab1.webp","sourceBytes":5369,"destBytes":3646,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2208,"convertSpendMs":18,"createdTime":"2021-04-03 12:49:16","host":"us-028*","referer":"https://www.percona.com/blog/?p=74571","linkMd5ListStr":"835b3d62eed8d5aa41a9e425666acfe4","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.2 KB","destSize":"3.6 KB","compressRate":"67.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn44@2020_6/2021/04/03/04-49-17-076_ba069d05e8e022de.webp","sourceBytes":59914,"destBytes":8760,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2335,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:16","host":"europe63*","referer":"https://www.percona.com/blog/?p=74903","linkMd5ListStr":"b4ed034325bd52a99b1d001860021fcb","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"58.5 KB","destSize":"8.6 KB","compressRate":"14.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn77@2020_2/2021/04/03/04-49-16-616_1e11c7148304186d.webp","sourceBytes":33433,"destBytes":5912,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2525,"convertSpendMs":9,"createdTime":"2021-04-03 12:49:16","host":"us-021*","referer":"https://www.percona.com/blog/?p=75147","linkMd5ListStr":"b107a81989fb33bdf2a7f3c0e14ce764","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.6 KB","destSize":"5.8 KB","compressRate":"17.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Validate-Configuration-Settings-in-MySQL-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn3@2020_4/2021/04/03/04-49-16-790_9ef95075066a8137.webp","sourceBytes":24762,"destBytes":9104,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2531,"convertSpendMs":69,"createdTime":"2021-04-03 12:49:16","host":"us-024*","referer":"https://www.percona.com/blog/?p=75088","linkMd5ListStr":"2425d4b26612cefc91bda1b5433432f9","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.2 KB","destSize":"8.9 KB","compressRate":"36.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_6/2021/04/03/04-49-17-414_97eee12653d25708.webp","sourceBytes":12919,"destBytes":3590,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1969,"convertSpendMs":81,"createdTime":"2021-04-03 12:49:17","host":"us-028*","referer":"https://www.percona.com/blog/?p=74736","linkMd5ListStr":"740b49217b028b16333cba4b01495341","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.6 KB","destSize":"3.5 KB","compressRate":"27.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn83@2020_5/2021/04/03/04-49-18-529_195f5079b5ddd12e.webp","sourceBytes":41434,"destBytes":8570,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1202,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:18","host":"europe21*","referer":"https://www.percona.com/blog/?p=74812","linkMd5ListStr":"b687f48d545690e3d97271e4cfa2248b","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"40.5 KB","destSize":"8.4 KB","compressRate":"20.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Bare-Systemd-Method-to-Create-an-XFS-Mount-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn80@2020_4/2021/04/03/04-49-18-008_f79500e911042718.webp","sourceBytes":18618,"destBytes":8874,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1442,"convertSpendMs":11,"createdTime":"2021-04-03 12:49:17","host":"us-008*","referer":"https://www.percona.com/blog/?p=74401","linkMd5ListStr":"f7c6d6db32b6967f9cdedeaf02051422","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.2 KB","destSize":"8.7 KB","compressRate":"47.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/pvcs-automation-1.png","sourceStatusCode":200,"destWidth":732,"destHeight":501,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn76@2020_6/2021/04/03/04-49-18-327_01e988315ffa4502.webp","sourceBytes":30371,"destBytes":16494,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1178,"convertSpendMs":18,"createdTime":"2021-04-03 12:49:18","host":"us-55*","referer":"https://www.percona.com/blog/?p=74786","linkMd5ListStr":"927214461581e653db7f74f537604e7a","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.7 KB","destSize":"16.1 KB","compressRate":"54.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Monitoring-and-Management-2.15-1-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn4@2020_2/2021/04/03/04-49-19-366_a83904df2ca33634.webp","sourceBytes":26691,"destBytes":7008,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1134,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:18","host":"europe-25*","referer":"https://www.percona.com/blog/?p=74644","linkMd5ListStr":"82fb984c6056ef4f100542a596e971d9","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.1 KB","destSize":"6.8 KB","compressRate":"26.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-2-2.png","sourceStatusCode":200,"destWidth":601,"destHeight":278,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn56@2020_1/2021/04/03/04-49-17-389_ab92be5a4a6c00ac.webp","sourceBytes":5723,"destBytes":11470,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2664,"convertSpendMs":58,"createdTime":"2021-04-03 12:49:17","host":"us-016*","referer":"https://www.percona.com/blog/?p=75187","linkMd5ListStr":"8cbdc4fcf8dbffae590b23534dfa7ddf","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.6 KB","destSize":"11.2 KB","compressRate":"200.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Direct20Connection1.png","sourceStatusCode":200,"destWidth":594,"destHeight":79,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn32@2020_3/2021/04/03/04-49-19-473_394e0c1b68562174.webp","sourceBytes":22958,"destBytes":13618,"targetWebpQuality":75,"feedId":11,"totalSpendMs":646,"convertSpendMs":8,"createdTime":"2021-04-03 12:49:19","host":"us-55*","referer":"https://www.percona.com/blog/?p=74480","linkMd5ListStr":"16d12f2d30b182a5a838c7da9d71dec1","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.4 KB","destSize":"13.3 KB","compressRate":"59.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/quick-131x150.png","sourceStatusCode":200,"destWidth":131,"destHeight":150,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn71@2020_4/2021/04/03/04-49-17-577_f395cd0b9f0b3a6e.webp","sourceBytes":10882,"destBytes":3168,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2594,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:17","host":"us-032*","referer":"https://www.percona.com/blog/?p=74571","linkMd5ListStr":"835b3d62eed8d5aa41a9e425666acfe4","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.6 KB","destSize":"3.1 KB","compressRate":"29.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn100@2020_4/2021/04/03/04-49-18-725_f632162ec682e739.webp","sourceBytes":15200,"destBytes":4188,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1546,"convertSpendMs":8,"createdTime":"2021-04-03 12:49:18","host":"us-012*","referer":"https://www.percona.com/blog/?p=74884","linkMd5ListStr":"d362d124e09e7053013c2ca0ca0310b9","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"14.8 KB","destSize":"4.1 KB","compressRate":"27.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/04/Percona-XtraBackup-Point-In-Time-Recovery-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn87@2020_3/2021/04/03/04-49-18-830_e8d33ad541551be8.webp","sourceBytes":31224,"destBytes":4366,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1999,"convertSpendMs":4,"createdTime":"2021-04-03 12:49:18","host":"europe-59*","referer":"https://www.percona.com/blog/?p=74903","linkMd5ListStr":"b4ed034325bd52a99b1d001860021fcb","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"30.5 KB","destSize":"4.3 KB","compressRate":"14%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Connection-Queuing-in-pgBouncer-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn16@2020_6/2021/04/03/04-49-19-081_ad3fad87d93973ae.webp","sourceBytes":25062,"destBytes":4632,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1379,"convertSpendMs":14,"createdTime":"2021-04-03 12:49:19","host":"us-028*","referer":"https://www.percona.com/blog/?p=74480","linkMd5ListStr":"16d12f2d30b182a5a838c7da9d71dec1","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.5 KB","destSize":"4.5 KB","compressRate":"18.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/importing-encrypted-InnoDB-Tablespace-MySQL-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn20@2020_5/2021/04/03/04-49-19-237_6fa12b0eac405511.webp","sourceBytes":13573,"destBytes":4712,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1582,"convertSpendMs":50,"createdTime":"2021-04-03 12:49:19","host":"us-016*","referer":"https://www.percona.com/blog/?p=74998","linkMd5ListStr":"70eede3fb1727a158133024b99497716","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.3 KB","destSize":"4.6 KB","compressRate":"34.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Bug-report-Feb-2021-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn35@2020_2/2021/04/03/04-49-19-498_66d8e46003af2501.webp","sourceBytes":26256,"destBytes":4260,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1266,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:19","host":"us-032*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.6 KB","destSize":"4.2 KB","compressRate":"16.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-pipe-1024x564.png","sourceStatusCode":200,"destWidth":1024,"destHeight":564,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn27@2020_1/2021/04/03/04-49-20-094_f7a6ee83c9fa90eb.webp","sourceBytes":204030,"destBytes":28910,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1445,"convertSpendMs":35,"createdTime":"2021-04-03 12:49:19","host":"europe67*","referer":"https://www.percona.com/blog/?p=74562","linkMd5ListStr":"05b384867001d9b6ccbb12624b6b34cd","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"199.2 KB","destSize":"28.2 KB","compressRate":"14.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn96@2020_6/2021/04/03/04-49-18-641_e22630c20dcca84e.webp","sourceBytes":27951,"destBytes":7640,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2297,"convertSpendMs":18,"createdTime":"2021-04-03 12:49:18","host":"us-024*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.3 KB","destSize":"7.5 KB","compressRate":"27.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/explore.png","sourceStatusCode":200,"destWidth":766,"destHeight":389,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn7@2020_5/2021/04/03/04-49-19-350_0b8c4f0341a84ecb.webp","sourceBytes":30600,"destBytes":26858,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2019,"convertSpendMs":18,"createdTime":"2021-04-03 12:49:18","host":"europe63*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.9 KB","destSize":"26.2 KB","compressRate":"87.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn80@2020_3/2021/04/03/04-49-20-796_be0583cee4ec1282.webp","sourceBytes":24124,"destBytes":4508,"targetWebpQuality":75,"feedId":11,"totalSpendMs":856,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:20","host":"us-028*","referer":"https://www.percona.com/blog/?p=75138","linkMd5ListStr":"8d29dd2848e596db260dedef0518d1b3","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23.6 KB","destSize":"4.4 KB","compressRate":"18.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn63@2020_1/2021/04/03/04-49-20-353_e1b38eb283705bf4.webp","sourceBytes":47927,"destBytes":7580,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1501,"convertSpendMs":51,"createdTime":"2021-04-03 12:49:20","host":"us-012*","referer":"https://www.percona.com/blog/?p=74824","linkMd5ListStr":"6adab452b809422f5b5eade2a7c01854","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"46.8 KB","destSize":"7.4 KB","compressRate":"15.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210330_130454.png","sourceStatusCode":200,"destWidth":236,"destHeight":141,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn71@2020_6/2021/04/03/04-49-20-942_f42771f131bfb49f.webp","sourceBytes":7213,"destBytes":4472,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1381,"convertSpendMs":5,"createdTime":"2021-04-03 12:49:20","host":"europe63*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"7 KB","destSize":"4.4 KB","compressRate":"62%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Global-Processlist-in-Percona-Monitoring-and-Management-200x113.png","sourceStatusCode":200,"destWidth":200,"destHeight":113,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn76@2020_6/2021/04/03/04-49-20-588_a60844d910f519d8.webp","sourceBytes":37610,"destBytes":4846,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1865,"convertSpendMs":121,"createdTime":"2021-04-03 12:49:19","host":"us-020*","referer":"https://www.percona.com/blog/?p=74438","linkMd5ListStr":"bdbdc777b5768814fb7bc017456c5e61","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"36.7 KB","destSize":"4.7 KB","compressRate":"12.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Automate-Dashboard-Importing-in-Percona-Monitoring-and-Management-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn43@2020_1/2021/04/03/04-49-20-046_512789a7a1874474.webp","sourceBytes":15129,"destBytes":3958,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1956,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:19","host":"us-008*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"14.8 KB","destSize":"3.9 KB","compressRate":"26.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_214233-1024x367.png","sourceStatusCode":200,"destWidth":1024,"destHeight":367,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn48@2020_1/2021/04/03/04-49-20-856_3a041108af05f7ca.webp","sourceBytes":181403,"destBytes":12952,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1936,"convertSpendMs":18,"createdTime":"2021-04-03 12:49:20","host":"europe21*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"177.2 KB","destSize":"12.6 KB","compressRate":"7.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn84@2020_2/2021/04/03/04-49-20-664_ab40f8654e4d09a4.webp","sourceBytes":16587,"destBytes":5286,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1494,"convertSpendMs":9,"createdTime":"2021-04-03 12:49:20","host":"us-020*","referer":"https://www.percona.com/blog/?p=74413","linkMd5ListStr":"7bc37091b41b2f689d3c0eb2ded9d335","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16.2 KB","destSize":"5.2 KB","compressRate":"31.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_202510-1024x588.png","sourceStatusCode":200,"destWidth":1024,"destHeight":588,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn68@2020_6/2021/04/03/04-49-21-491_ca18279fdba9c2c7.webp","sourceBytes":464547,"destBytes":19552,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1548,"convertSpendMs":45,"createdTime":"2021-04-03 12:49:20","host":"europe-25*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"453.7 KB","destSize":"19.1 KB","compressRate":"4.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Screenshot_20210228_212649-1024x215.png","sourceStatusCode":200,"destWidth":1024,"destHeight":215,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn99@2020_1/2021/04/03/04-49-21-790_62de23adf12ae55a.webp","sourceBytes":214317,"destBytes":19138,"targetWebpQuality":75,"feedId":11,"totalSpendMs":353,"convertSpendMs":17,"createdTime":"2021-04-03 12:49:21","host":"us-032*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"209.3 KB","destSize":"18.7 KB","compressRate":"8.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/resources_graph-1024x258.png","sourceStatusCode":200,"destWidth":1024,"destHeight":258,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn83@2020_1/2021/04/03/04-49-21-069_c2ae6c9e34602f11.webp","sourceBytes":189908,"destBytes":24724,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1256,"convertSpendMs":111,"createdTime":"2021-04-03 12:49:20","host":"us-016*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"185.5 KB","destSize":"24.1 KB","compressRate":"13%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/purple-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":74,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn47@2020_3/2021/04/03/04-49-20-595_147c67c11b518b52.webp","sourceBytes":5639,"destBytes":1326,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2916,"convertSpendMs":77,"createdTime":"2021-04-03 12:49:19","host":"us-020*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.5 KB","destSize":"1.3 KB","compressRate":"23.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Build-Percona-Server-for-MySQL-From-Sources-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx23/cdn95@2020_4/2021/04/03/04-49-21-702_ac96bccaa855fa76.webp","sourceBytes":22927,"destBytes":6514,"targetWebpQuality":75,"feedId":11,"totalSpendMs":633,"convertSpendMs":11,"createdTime":"2021-04-03 12:49:21","host":"us-55*","referer":"https://www.percona.com/blog/?p=74736","linkMd5ListStr":"740b49217b028b16333cba4b01495341","githubUser":"myreaderx23","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.4 KB","destSize":"6.4 KB","compressRate":"28.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/04/MyRocks-in-the-Enterprise-with-Dropbox-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn92@2020_6/2021/04/03/04-49-21-455_a9eecce7436e8816.webp","sourceBytes":25690,"destBytes":4446,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1355,"convertSpendMs":9,"createdTime":"2021-04-03 12:49:20","host":"europe67*","referer":"https://www.percona.com/blog/?p=74812","linkMd5ListStr":"b687f48d545690e3d97271e4cfa2248b","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.1 KB","destSize":"4.3 KB","compressRate":"17.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/recovery-binlog.png","sourceStatusCode":200,"destWidth":711,"destHeight":593,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn100@2020_5/2021/04/03/04-49-21-260_7fbd641cd86035b5.webp","sourceBytes":38756,"destBytes":22342,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1577,"convertSpendMs":141,"createdTime":"2021-04-03 12:49:20","host":"us-037*","referer":"https://www.percona.com/blog/?p=74562","linkMd5ListStr":"05b384867001d9b6ccbb12624b6b34cd","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"37.8 KB","destSize":"21.8 KB","compressRate":"57.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Software-SourceForge-Award-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn8@2020_5/2021/04/03/04-49-22-004_b177daffef307204.webp","sourceBytes":21104,"destBytes":5174,"targetWebpQuality":75,"feedId":11,"totalSpendMs":422,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:21","host":"us-008*","referer":"https://www.percona.com/blog/?p=74740","linkMd5ListStr":"b55980eba389b4a5afc63dd445b1a854","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.6 KB","destSize":"5.1 KB","compressRate":"24.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/upgrading-to-mysql-8-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn11@2020_1/2021/04/03/04-49-20-589_dfae59a11c8cfa04.webp","sourceBytes":44136,"destBytes":9846,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3451,"convertSpendMs":85,"createdTime":"2021-04-03 12:49:19","host":"us-020*","referer":"https://www.percona.com/blog/?p=75138","linkMd5ListStr":"8d29dd2848e596db260dedef0518d1b3","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"43.1 KB","destSize":"9.6 KB","compressRate":"22.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn91@2020_5/2021/04/03/04-49-21-259_2bca72f2115bbc0f.webp","sourceBytes":18974,"destBytes":3714,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2166,"convertSpendMs":52,"createdTime":"2021-04-03 12:49:20","host":"us-037*","referer":"https://www.percona.com/blog/?p=75071","linkMd5ListStr":"3ce9e57e09207a7fe19234725cd8466f","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.5 KB","destSize":"3.6 KB","compressRate":"19.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/pitr-gtid-1024x742.png","sourceStatusCode":200,"destWidth":1024,"destHeight":742,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn44@2020_2/2021/04/03/04-49-22-445_f5b54efed075f80c.webp","sourceBytes":182489,"destBytes":31862,"targetWebpQuality":75,"feedId":11,"totalSpendMs":593,"convertSpendMs":62,"createdTime":"2021-04-03 12:49:22","host":"us-028*","referer":"https://www.percona.com/blog/?p=74562","linkMd5ListStr":"05b384867001d9b6ccbb12624b6b34cd","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"178.2 KB","destSize":"31.1 KB","compressRate":"17.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn40@2020_3/2021/04/03/04-49-20-585_322dd71a30133830.webp","sourceBytes":28811,"destBytes":3450,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3450,"convertSpendMs":71,"createdTime":"2021-04-03 12:49:19","host":"us-020*","referer":"https://www.percona.com/blog/?p=75112","linkMd5ListStr":"79242dc8db88dc141a2475cd5600e267","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"28.1 KB","destSize":"3.4 KB","compressRate":"12%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Point-In-Time-Recovery-in-Kubernetes-Operator-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn56@2020_4/2021/04/03/04-49-21-570_cdd193bfde8826fe.webp","sourceBytes":20946,"destBytes":5672,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1706,"convertSpendMs":34,"createdTime":"2021-04-03 12:49:21","host":"us-037*","referer":"https://www.percona.com/blog/?p=74562","linkMd5ListStr":"05b384867001d9b6ccbb12624b6b34cd","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.5 KB","destSize":"5.5 KB","compressRate":"27.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/green-bug.png","sourceStatusCode":200,"destWidth":75,"destHeight":74,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn28@2020_5/2021/04/03/04-49-21-261_abb43840edeeeb7b.webp","sourceBytes":5510,"destBytes":1352,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2561,"convertSpendMs":49,"createdTime":"2021-04-03 12:49:20","host":"us-037*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.4 KB","destSize":"1.3 KB","compressRate":"24.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/currentOp-in-MongoDB-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn28@2020_4/2021/04/03/04-49-22-154_925bcb3e2e426bdd.webp","sourceBytes":56993,"destBytes":6396,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1020,"convertSpendMs":11,"createdTime":"2021-04-03 12:49:22","host":"us-012*","referer":"https://www.percona.com/blog/?p=75112","linkMd5ListStr":"79242dc8db88dc141a2475cd5600e267","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"55.7 KB","destSize":"6.2 KB","compressRate":"11.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn64@2020_3/2021/04/03/04-49-21-249_bc15442cb23942eb.webp","sourceBytes":28868,"destBytes":10152,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2823,"convertSpendMs":138,"createdTime":"2021-04-03 12:49:20","host":"us-037*","referer":"https://www.percona.com/blog/?p=74786","linkMd5ListStr":"927214461581e653db7f74f537604e7a","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"28.2 KB","destSize":"9.9 KB","compressRate":"35.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Troubleshoot-MySQL-Using-Percona-Monitoring-and-Management-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn59@2020_3/2021/04/03/04-49-20-426_7308a34cfa2af9e6.webp","sourceBytes":64947,"destBytes":11416,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3105,"convertSpendMs":28,"createdTime":"2021-04-03 12:49:20","host":"us-024*","referer":"https://www.percona.com/blog/?p=75147","linkMd5ListStr":"b107a81989fb33bdf2a7f3c0e14ce764","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"63.4 KB","destSize":"11.1 KB","compressRate":"17.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/InnoDB-Transaction-Isolation-Levels-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn19@2020_3/2021/04/03/04-49-22-074_f7b2d096a116c502.webp","sourceBytes":25046,"destBytes":11314,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1332,"convertSpendMs":8,"createdTime":"2021-04-03 12:49:22","host":"us-037*","referer":"https://www.percona.com/blog/?p=74413","linkMd5ListStr":"7bc37091b41b2f689d3c0eb2ded9d335","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.5 KB","destSize":"11 KB","compressRate":"45.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/CVE-2020-29488-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn4@2020_3/2021/04/03/04-49-22-151_c88c96cdf532cb1a.webp","sourceBytes":15541,"destBytes":5832,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1364,"convertSpendMs":42,"createdTime":"2021-04-03 12:49:21","host":"us-020*","referer":"https://www.percona.com/blog/?p=74538","linkMd5ListStr":"acf85eccf23ec1e00967361275f02244","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.2 KB","destSize":"5.7 KB","compressRate":"37.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210228_154312-1024x541.png","sourceStatusCode":200,"destWidth":1024,"destHeight":541,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn51@2020_6/2021/04/03/04-49-21-039_41ecef631efc01d3.webp","sourceBytes":370009,"destBytes":14342,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3440,"convertSpendMs":47,"createdTime":"2021-04-03 12:49:20","host":"europe-59*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"361.3 KB","destSize":"14 KB","compressRate":"3.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-19-1024x662.png","sourceStatusCode":200,"destWidth":1024,"destHeight":662,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn32@2020_2/2021/04/03/04-49-22-995_b85b8592804cd804.webp","sourceBytes":158104,"destBytes":20120,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1602,"convertSpendMs":31,"createdTime":"2021-04-03 12:49:22","host":"europe-25*","referer":"https://www.percona.com/blog/?p=75187","linkMd5ListStr":"8cbdc4fcf8dbffae590b23534dfa7ddf","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"154.4 KB","destSize":"19.6 KB","compressRate":"12.7%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn63@2020_6/2021/04/03/04-49-22-609_f5e2c9f9fe38a726.webp","sourceBytes":50433,"destBytes":10400,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1407,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:22","host":"us-032*","referer":"https://www.percona.com/blog/?p=74352","linkMd5ListStr":"008eb2d24b981e80bd3b226206dbded3","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"49.3 KB","destSize":"10.2 KB","compressRate":"20.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/MongoDB-Performance-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn60@2020_2/2021/04/03/04-49-22-533_2ca7693e4262243c.webp","sourceBytes":25967,"destBytes":7670,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1758,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:22","host":"us-55*","referer":"https://www.percona.com/blog/?p=74884","linkMd5ListStr":"d362d124e09e7053013c2ca0ca0310b9","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.4 KB","destSize":"7.5 KB","compressRate":"29.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn12@2020_1/2021/04/03/04-49-22-618_85039a715c25a591.webp","sourceBytes":40387,"destBytes":10966,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2379,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:22","host":"europe21*","referer":"https://www.percona.com/blog/?p=74553","linkMd5ListStr":"60741d14cf97d9fb42cfe52348880c5c","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"39.4 KB","destSize":"10.7 KB","compressRate":"27.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn55@2020_6/2021/04/03/04-49-23-048_a253c345db9c984f.webp","sourceBytes":42455,"destBytes":5096,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2087,"convertSpendMs":9,"createdTime":"2021-04-03 12:49:22","host":"europe67*","referer":"https://www.percona.com/blog/?p=74913","linkMd5ListStr":"c13248c7476255e2bcae20484e995e74","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.5 KB","destSize":"5 KB","compressRate":"12%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Kubernetes-Operator-for-Percona-Server-for-MongoDB-New-Features-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn47@2020_6/2021/04/03/04-49-23-991_0acd1d41d9050e75.webp","sourceBytes":18985,"destBytes":5520,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1506,"convertSpendMs":96,"createdTime":"2021-04-03 12:49:22","host":"us-51*","referer":"https://www.percona.com/blog/?p=74786","linkMd5ListStr":"927214461581e653db7f74f537604e7a","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"18.5 KB","destSize":"5.4 KB","compressRate":"29.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Monitoring-Using-the-MySQL-Shell-300x157.png","sourceStatusCode":200,"destWidth":300,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn12@2020_4/2021/04/03/04-49-23-987_57b5e45f51dfa7cf.webp","sourceBytes":38716,"destBytes":10264,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1480,"convertSpendMs":41,"createdTime":"2021-04-03 12:49:22","host":"us-51*","referer":"https://www.percona.com/blog/?p=74605","linkMd5ListStr":"8d7b08bfa2026cbb9dd9940b036d9b67","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"37.8 KB","destSize":"10 KB","compressRate":"26.5%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Webinar-MongoDB-Backups-Overview-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn24@2020_1/2021/04/03/04-49-22-152_01b196d59aaa0a80.webp","sourceBytes":25413,"destBytes":3758,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2651,"convertSpendMs":9,"createdTime":"2021-04-03 12:49:22","host":"us-024*","referer":"https://www.percona.com/blog/?p=74824","linkMd5ListStr":"6adab452b809422f5b5eade2a7c01854","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.8 KB","destSize":"3.7 KB","compressRate":"14.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Releases-March-29-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn47@2020_5/2021/04/03/04-49-22-597_f45ee932e8e6eef3.webp","sourceBytes":86514,"destBytes":10656,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2396,"convertSpendMs":40,"createdTime":"2021-04-03 12:49:22","host":"us-016*","referer":"https://www.percona.com/blog/?p=74913","linkMd5ListStr":"c13248c7476255e2bcae20484e995e74","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.5 KB","destSize":"10.4 KB","compressRate":"12.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Kubernetes-Costs-Percona-Monitoring-and-Management-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn16@2020_4/2021/04/03/04-49-22-660_9525d80903073c70.webp","sourceBytes":36412,"destBytes":7776,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2635,"convertSpendMs":6,"createdTime":"2021-04-03 12:49:22","host":"europe-59*","referer":"https://www.percona.com/blog/?p=74425","linkMd5ListStr":"9b3c8c4ae697c9b277c681189244e353","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"35.6 KB","destSize":"7.6 KB","compressRate":"21.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Percona-Release-Roundup-March-15-300x169.png","sourceStatusCode":200,"destWidth":300,"destHeight":169,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn35@2020_3/2021/04/03/04-49-22-947_a599c63ad14c9fa3.webp","sourceBytes":86464,"destBytes":10648,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2641,"convertSpendMs":12,"createdTime":"2021-04-03 12:49:22","host":"europe63*","referer":"https://www.percona.com/blog/?p=74692","linkMd5ListStr":"31583d79676cf36b069aeb75d5f083f0","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"84.4 KB","destSize":"10.4 KB","compressRate":"12.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Diagram1-1024x484.png","sourceStatusCode":200,"destWidth":1024,"destHeight":484,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn84@2020_6/2021/04/03/04-49-24-285_898fe50fcd9fa23b.webp","sourceBytes":190459,"destBytes":19602,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1058,"convertSpendMs":30,"createdTime":"2021-04-03 12:49:24","host":"us-51*","referer":"https://www.percona.com/blog/?p=74710","linkMd5ListStr":"aaf1719f47ea1c56bcbff35f0f9ebdcc","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"186 KB","destSize":"19.1 KB","compressRate":"10.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-Alternative-Storage-Engines-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn54@2020_1/2021/04/03/04-49-24-647_20e4ff73535c9981.webp","sourceBytes":32219,"destBytes":4434,"targetWebpQuality":75,"feedId":11,"totalSpendMs":1426,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:24","host":"us-51*","referer":"https://www.percona.com/blog/?p=75057","linkMd5ListStr":"d4611282a8da21922c609e19f4374a12","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.5 KB","destSize":"4.3 KB","compressRate":"13.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/database-podcast-151x150.jpeg","sourceStatusCode":200,"destWidth":151,"destHeight":150,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn48@2020_6/2021/04/03/04-49-23-575_1f2fb06054f2a601.webp","sourceBytes":5798,"destBytes":3310,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3006,"convertSpendMs":7,"createdTime":"2021-04-03 12:49:22","host":"europe64*","referer":"https://www.percona.com/blog/?p=74571","linkMd5ListStr":"835b3d62eed8d5aa41a9e425666acfe4","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.7 KB","destSize":"3.2 KB","compressRate":"57.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Screenshot_20210316_172621-1024x507.png","sourceStatusCode":200,"destWidth":1024,"destHeight":507,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn76@2020_1/2021/04/03/04-49-24-097_97bc10059d353f85.webp","sourceBytes":585093,"destBytes":60240,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3102,"convertSpendMs":89,"createdTime":"2021-04-03 12:49:22","host":"us-51*","referer":"https://www.percona.com/blog/?p=74548","linkMd5ListStr":"2598112912c21d21b807f7c4edf61769","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"571.4 KB","destSize":"58.8 KB","compressRate":"10.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/MySQL-101-super_read_only-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn19@2020_4/2021/04/03/04-49-23-990_a8eec40f221a5622.webp","sourceBytes":32958,"destBytes":6714,"targetWebpQuality":75,"feedId":11,"totalSpendMs":2898,"convertSpendMs":48,"createdTime":"2021-04-03 12:49:23","host":"us-51*","referer":"https://www.percona.com/blog/?p=75071","linkMd5ListStr":"3ce9e57e09207a7fe19234725cd8466f","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.2 KB","destSize":"6.6 KB","compressRate":"20.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Releases-Feb-15-2021-200x112.png","sourceStatusCode":200,"destWidth":200,"destHeight":112,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn39@2020_1/2021/04/03/04-49-23-994_7e7d9b4d75c68b91.webp","sourceBytes":42292,"destBytes":5126,"targetWebpQuality":75,"feedId":11,"totalSpendMs":3296,"convertSpendMs":110,"createdTime":"2021-04-03 12:49:23","host":"us-51*","referer":"https://www.percona.com/blog/?p=74250","linkMd5ListStr":"703b15df2427397e9cc1f07b723cde7e","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"41.3 KB","destSize":"5 KB","compressRate":"12.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/06/bug-small.png","sourceStatusCode":200,"destWidth":75,"destHeight":75,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn51@2020_3/2021/04/03/04-49-37-940_2826482aac8c233a.webp","sourceBytes":5479,"destBytes":1472,"targetWebpQuality":75,"feedId":11,"totalSpendMs":833,"convertSpendMs":14,"createdTime":"2021-04-03 12:49:37","host":"us-030*","referer":"https://www.percona.com/blog/?p=74608","linkMd5ListStr":"82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2,82cf99cfa352824abe981b34160ae8a2","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.4 KB","destSize":"1.4 KB","compressRate":"26.9%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Percona-Open-Source-Podcast-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn59@2020_3/2021/04/03/04-49-47-796_d9ae32db4deb617b.webp","sourceBytes":94446,"destBytes":13608,"targetWebpQuality":75,"feedId":11,"totalSpendMs":8170,"convertSpendMs":482,"createdTime":"2021-04-03 12:49:41","host":"us-004*","referer":"https://www.percona.com/blog/?p=74571","linkMd5ListStr":"835b3d62eed8d5aa41a9e425666acfe4","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"92.2 KB","destSize":"13.3 KB","compressRate":"14.4%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/Moving-Your-Database-to-the-Cloud-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn88@2020_1/2021/04/03/04-49-46-770_c06c4c7cb790423b.webp","sourceBytes":26050,"destBytes":5628,"targetWebpQuality":75,"feedId":11,"totalSpendMs":9091,"convertSpendMs":577,"createdTime":"2021-04-03 12:49:41","host":"us-004*","referer":"https://www.percona.com/blog/?p=74553","linkMd5ListStr":"60741d14cf97d9fb42cfe52348880c5c","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.4 KB","destSize":"5.5 KB","compressRate":"21.6%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2020/12/MySQL5_6-200x105.png","sourceStatusCode":200,"destWidth":200,"destHeight":105,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn23@2020_5/2021/04/03/04-49-46-186_edb4e1d7b4fb1322.webp","sourceBytes":27241,"destBytes":5758,"targetWebpQuality":75,"feedId":11,"totalSpendMs":7722,"convertSpendMs":12,"createdTime":"2021-04-03 12:49:41","host":"us-004*","referer":"https://www.percona.com/blog/?p=74352","linkMd5ListStr":"008eb2d24b981e80bd3b226206dbded3","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.6 KB","destSize":"5.6 KB","compressRate":"21.1%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-15-1024x361.png","sourceStatusCode":200,"destWidth":1024,"destHeight":361,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx14/cdn67@2020_5/2021/04/03/04-49-48-726_4b62da5caafa3708.webp","sourceBytes":169113,"destBytes":24260,"targetWebpQuality":75,"feedId":11,"totalSpendMs":9164,"convertSpendMs":722,"createdTime":"2021-04-03 12:49:42","host":"us-004*","referer":"https://www.percona.com/blog/?p=74946","linkMd5ListStr":"ad5af7759a03394ee27c6d95b528d5c4","githubUser":"myreaderx14","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"165.1 KB","destSize":"23.7 KB","compressRate":"14.3%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/blog-Page-1-3-1024x475.png","sourceStatusCode":200,"destWidth":1024,"destHeight":475,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn96@2020_2/2021/04/03/04-49-48-564_14ff1cb4844d015c.webp","sourceBytes":168666,"destBytes":23308,"targetWebpQuality":75,"feedId":11,"totalSpendMs":9481,"convertSpendMs":516,"createdTime":"2021-04-03 12:49:41","host":"us-004*","referer":"https://www.percona.com/blog/?p=74786","linkMd5ListStr":"927214461581e653db7f74f537604e7a","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"164.7 KB","destSize":"22.8 KB","compressRate":"13.8%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/02/object-storage.png","sourceStatusCode":200,"destWidth":685,"destHeight":623,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn52@2020_5/2021/04/03/04-49-48-143_8ed65cba45053ce2.webp","sourceBytes":40021,"destBytes":25292,"targetWebpQuality":75,"feedId":11,"totalSpendMs":11089,"convertSpendMs":1818,"createdTime":"2021-04-03 12:49:40","host":"us-004*","referer":"https://www.percona.com/blog/?p=74562","linkMd5ListStr":"05b384867001d9b6ccbb12624b6b34cd","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"39.1 KB","destSize":"24.7 KB","compressRate":"63.2%"},{"code":1,"isDone":false,"source":"https://www.percona.com/blog/wp-content/uploads/2021/03/Session-Analyzer-traffic-non-production-300x168.png","sourceStatusCode":200,"destWidth":300,"destHeight":168,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn32@2020_2/2021/04/03/04-49-47-647_a983fcdd589f81b3.webp","sourceBytes":49667,"destBytes":12586,"targetWebpQuality":75,"feedId":11,"totalSpendMs":10408,"convertSpendMs":1317,"createdTime":"2021-04-03 12:49:41","host":"us-004*","referer":"https://www.percona.com/blog/?p=74624","linkMd5ListStr":"4b3e9d6af32194c291344246b19ca57c","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"48.5 KB","destSize":"12.3 KB","compressRate":"25.3%"}],"successGithubMap":{"myreaderx14":3,"myreaderx8":4,"myreaderx7":4,"myreaderx15":4,"myreaderx6":4,"myreaderx16":5,"myreaderx10":4,"myreaderx32":4,"myreaderx4":3,"myreaderx33":3,"myreaderx3":5,"myreaderx11":4,"myreaderx12":4,"myreaderx2":5,"myreaderx13":4,"myreaderx1":4,"myreaderx30":4,"myreaderx31":5,"myreaderx18":5,"myreaderx19":4,"myreaderx":4,"myreaderx25":3,"myreaderx27":4,"myreaderx21":4,"myreaderx22":5,"myreaderx23":4,"myreaderx24":5,"myreaderx5oss":5,"myreaderx29":5},"failGithubMap":{}}