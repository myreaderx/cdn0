{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-10-17 01:24:33","updatedTime":"2020-10-17 01:24:33","title":"PyTorch (11) Variational Autoencoder","link":"https://aidiary.hatenablog.com/entry/20180228/1519828344","description":"<p>今回は、Variational Autoencoder (VAE) の実験をしてみよう。</p>\n\n<p>実は自分が始めてDeep Learningに興味を持ったのがこのVAEなのだ！VAEの潜在空間をいじって多様な顔画像を生成するデモ（<a href=\"https://vdumoulin.github.io/morphing_faces/\">Morphing Faces</a>）を見て、これを<strong>音声合成の声質生成</strong>に使いたいと思ったのが興味のきっかけだった。</p>\n\n<p>今回の実験は、PyTorchの公式にある<a href=\"https://github.com/pytorch/examples/blob/master/vae/main.py\">VAEのスクリプト</a> を自分なりに読み解いてまとめてみた結果になっている。</p>\n\n<p><a href=\"https://drive.google.com/open?id=1sTevZFlcQGFqeGyJnG3-6wSPpDYZioQ7\">180221-variational-autoencoder.ipynb - Google &#x30C9;&#x30E9;&#x30A4;&#x30D6;</a></p>\n\n<p>さっそく実験！いつものimport。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synPreProc\">import</span> os\n<span class=\"synPreProc\">import</span> numpy <span class=\"synStatement\">as</span> np\n<span class=\"synPreProc\">import</span> torch\n<span class=\"synPreProc\">import</span> torch.nn <span class=\"synStatement\">as</span> nn\n<span class=\"synPreProc\">import</span> torch.utils.data\n<span class=\"synPreProc\">import</span> torch.optim <span class=\"synStatement\">as</span> optim\n<span class=\"synPreProc\">from</span> torch.autograd <span class=\"synPreProc\">import</span> Variable\n<span class=\"synPreProc\">from</span> torch.nn <span class=\"synPreProc\">import</span> functional <span class=\"synStatement\">as</span> F\n<span class=\"synPreProc\">from</span> torchvision <span class=\"synPreProc\">import</span> datasets, transforms\n<span class=\"synPreProc\">from</span> torchvision.utils <span class=\"synPreProc\">import</span> save_image\n\nbatch_size = <span class=\"synConstant\">128</span>\nnum_epochs = <span class=\"synConstant\">100</span>\nseed = <span class=\"synConstant\">1</span>\nout_dir = <span class=\"synConstant\">'./vae_2'</span>\n</pre>\n\n\n<p>出力先のディレクトリを <code>vae_2</code> としている。潜在空間が2次元であるVAEの結果を意味する。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>cuda = torch.cuda.is_available()\n<span class=\"synStatement\">if</span> cuda:\n    <span class=\"synIdentifier\">print</span>(<span class=\"synConstant\">'cuda is available!'</span>)\n\n<span class=\"synStatement\">if</span> <span class=\"synStatement\">not</span> os.path.exists(out_dir):\n    os.mkdir(out_dir)\n\ntorch.manual_seed(seed)\n<span class=\"synStatement\">if</span> cuda:\n    torch.cuda.manual_seed(seed)\n</pre>\n\n\n<p>MNISTのデータをロードする。前回と同じだけど標準化は [0, 1] にしている。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>train_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(<span class=\"synConstant\">'data'</span>,\n                   train=<span class=\"synIdentifier\">True</span>,\n                   download=<span class=\"synIdentifier\">True</span>,\n                   transform=transforms.ToTensor()),\n    batch_size=batch_size,\n    shuffle=<span class=\"synIdentifier\">True</span>\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(<span class=\"synConstant\">'data'</span>,\n                   train=<span class=\"synIdentifier\">False</span>,\n                   transform=transforms.ToTensor()),\n    batch_size=batch_size,\n    shuffle=<span class=\"synIdentifier\">True</span>\n)\n</pre>\n\n\n<h2>VAEのアーキテクチャ</h2>\n\n<p>VAEは、Autoencoderと似ているが、<strong>Encoderの出力が正規分布の平均と共分散行列</strong>になり、潜在表現zがその正規分布からサンプリングされる点が異なる。潜在表現zはランダムサンプリングされるため同じ入力画像Xを入れても毎回異なるzにマッピングされる。</p>\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228212323.png\" alt=\"f:id:aidiary:20180228212323p:plain\" title=\"f:id:aidiary:20180228212323p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<p>上図のようにEncoderは正規分布の平均ベクトル（mu）と分散共分散行列の対数（logvar）を出力する。ここでは、潜在表現 z は可視化しやすいように2次元としたので、平均ベクトルのサイズは2となる。分散共分散行列は対角行列と仮定しているため対角成分のみ取ってこちらも2次元ベクトルとなる。対数を取る理由がはっきりしないけどアンダーフローを防ぐためかな？</p>\n\n<p>Encoderが出力した平均と分散を持つ正規分布から入力Xの潜在表現zをサンプリングする。</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20z%20%5Csim%20N%28%5Cmu%28X%29%2C%20%5CSigma%28X%29%29\" alt=\" z \\sim N(\\mu(X), \\Sigma(X))\"/></p>\n\n<p>ただ、これを普通にやると誤差逆伝搬ができないので <strong>Reparameterization Trick</strong> というのを使う。上の式でサンプリングするのではなく、</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cepsilon%20%5Csim%20N%280%2C%20I%29\" alt=\" \\epsilon \\sim N(0, I)\"/></p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20z%20%3D%20%5Cmu%28X%29%20%2B%20%5CSigma%28X%29%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20%5Cepsilon\" alt=\" z = \\mu(X) + \\Sigma(X)^{\\frac{1}{2}} \\epsilon\"/></p>\n\n<p>でzを計算する。このように計算すると和と積の演算だけで構成されるので計算グラフが構築でき、誤差逆伝搬ができるとのこと。PyTorchには <a href=\"http://pytorch.org/docs/master/tensors.html#torch.Tensor.normal_\"><code>normal_(mean=0, std=1)</code></a> という正規乱数を生成するTensor Operationが実装されている。</p>\n\n<p><em>ここがちょっとわからない。meanとstdを指定しても乱数生成できるみたいだけどReparameterization Trick必要なのかな？多次元正規分布になるとできないのだろうか？</em></p>\n\n<p>上のアーキテクチャをPyTorchのコードで書くと下のようになる。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synStatement\">class</span> <span class=\"synIdentifier\">VAE</span>(nn.Module):\n\n    <span class=\"synStatement\">def</span> <span class=\"synIdentifier\">__init__</span>(self):\n        <span class=\"synIdentifier\">super</span>(VAE, self).__init__()\n        \n        self.fc1 = nn.Linear(<span class=\"synConstant\">784</span>, <span class=\"synConstant\">512</span>)\n        self.fc21 = nn.Linear(<span class=\"synConstant\">512</span>, <span class=\"synConstant\">2</span>)  <span class=\"synComment\"># mu</span>\n        self.fc22 = nn.Linear(<span class=\"synConstant\">512</span>, <span class=\"synConstant\">2</span>)  <span class=\"synComment\"># logvar</span>\n\n        self.fc3 = nn.Linear(<span class=\"synConstant\">2</span>, <span class=\"synConstant\">512</span>)\n        self.fc4 = nn.Linear(<span class=\"synConstant\">512</span>, <span class=\"synConstant\">784</span>)\n        \n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n    \n    <span class=\"synStatement\">def</span> <span class=\"synIdentifier\">encode</span>(self, x):\n        h = self.relu(self.fc1(x))\n        <span class=\"synStatement\">return</span> self.fc21(h), self.fc22(h)\n\n    <span class=\"synStatement\">def</span> <span class=\"synIdentifier\">reparameterize</span>(self, mu, logvar):\n        <span class=\"synStatement\">if</span> self.training:\n            std = logvar.mul(<span class=\"synConstant\">0.5</span>).exp_()\n            eps = Variable(std.data.new(std.size()).normal_())\n            <span class=\"synStatement\">return</span> eps.mul(std).add_(mu)\n        <span class=\"synStatement\">else</span>:\n            <span class=\"synStatement\">return</span> mu\n\n    <span class=\"synStatement\">def</span> <span class=\"synIdentifier\">decode</span>(self, z):\n        h = self.relu(self.fc3(z))\n        <span class=\"synStatement\">return</span> self.sigmoid(self.fc4(h))\n    \n    <span class=\"synStatement\">def</span> <span class=\"synIdentifier\">forward</span>(self, x):\n        x = x.view(-<span class=\"synConstant\">1</span>, <span class=\"synConstant\">784</span>)\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        <span class=\"synStatement\">return</span> self.decode(z), mu, logvar\n\nmodel = VAE()\n<span class=\"synStatement\">if</span> cuda:\n    model.cuda()\noptimizer = optim.Adam(model.parameters(), lr=<span class=\"synConstant\">1e-3</span>)\n</pre>\n\n\n<p>ちょっと数式とコードの対応関係を補足すると <code>logvar</code> は <img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20%5CSigma\" alt=\" \\log \\Sigma\"/> にあたる。</p>\n\n<p><code>std = logvar.mul(0.5).exp_()</code> は、</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20std%20%3D%20%5Cexp%280.5%20%2A%20%5Clog%20%5CSigma%29%20%3D%20%5Cexp%28%5Clog%20%5CSigma%20%5E%20%5Cfrac%7B1%7D%7B2%7D%29%20%3D%20%5CSigma%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D\" alt=\" std = \\exp(0.5 * \\log \\Sigma) = \\exp(\\log \\Sigma ^ \\frac{1}{2}) = \\Sigma^{\\frac{1}{2}}\"/></p>\n\n<p>となる。よって、<code>eps.mul(std).add_(mu)</code> は、</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cepsilon%20%2A%20%5CSigma%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20%2B%20%5Cmu\" alt=\" \\epsilon * \\Sigma^{\\frac{1}{2}} + \\mu\"/></p>\n\n<p>となり、先の式とコードが一致することがわかる！<strong>数式だとεはスカラーっぽいけど実装ではベクトルになっている</strong>。潜在表現の各次元ごとに異なる乱数をかけるようだ。</p>\n\n<p><em>スカラーでもよいのかな？</em></p>\n\n<h2>VAEの損失関数</h2>\n\n<p>VAEの損失関数は既存のものではなく、独自の定義が必要。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synStatement\">def</span> <span class=\"synIdentifier\">loss_function</span>(recon_x, x, mu, logvar):\n    <span class=\"synComment\"># size_average=Falseなのでバッチ内のサンプルの合計lossを求める</span>\n    <span class=\"synComment\"># reconstruction loss 入力画像をどのくらい正確に復元できたか？</span>\n    <span class=\"synComment\"># 数式では対数尤度の最大化だが交差エントロピーlossの最小化と等価</span>\n    recon = F.binary_cross_entropy(recon_x, x.view(-<span class=\"synConstant\">1</span>, <span class=\"synConstant\">784</span>), size_average=<span class=\"synIdentifier\">False</span>)\n\n    <span class=\"synComment\"># 潜在空間zに対する正則化項</span>\n    <span class=\"synComment\"># P(z|x) が N(0, I)に近くなる（KL-distanceが小さくなる）ようにする</span>\n    kld = -<span class=\"synConstant\">0.5</span> * torch.<span class=\"synIdentifier\">sum</span>(<span class=\"synConstant\">1</span> + logvar - mu.<span class=\"synIdentifier\">pow</span>(<span class=\"synConstant\">2</span>) - logvar.exp())\n\n    <span class=\"synStatement\">return</span> recon + kld\n</pre>\n\n\n<p>このコードを理解するのがとても難しかった。数式の導出は</p>\n\n<ul>\n<li><a href=\"https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24\">Variational Autoencoder&#x5FB9;&#x5E95;&#x89E3;&#x8AAC; - Qiita</a></li>\n<li><a href=\"https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\">Variational Autoencoder: Intuition and Implementation - Agustinus Kristiadi&#39;s Blog</a></li>\n<li><a href=\"https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\">Tutorial - What is a variational autoencoder? &ndash; Jaan Altosaar</a></li>\n<li><a href=\"http://nzw0301.github.io/notes/vae.pdf\">Variational Auto Encoder</a></li>\n</ul>\n\n\n<p>を見ていただくほうがよいと思う。最終的には下の目的関数が出て来るのだがそこまでのたどり着き方にはいくつかアプローチがあるようだ。</p>\n\n<p>VAEの最終的な目的関数は、</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20P%28X%29%20-%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%3D%20E%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20-%20D_%7BKL%7D%20%5BQ%28z%7CX%29%7C%7CP%28z%29%5D%20\" alt=\" \\log P(X) - D_{KL} [ Q(z|X) || P(z|X) ] = E [\\log P(X|z) ] - D_{KL} [Q(z|X)||P(z)] \"/></p>\n\n<p>となる。左辺のKL divergenceは <img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%5Cge%200\" alt=\" D_{KL} [ Q(z|X) || P(z|X) ] \\ge 0\"/> なので</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20P%28X%29%20%5Cge%20E%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20-%20D_%7BKL%7D%20%5BQ%28z%7CX%29%7C%7CP%28z%29%5D%20\" alt=\" \\log P(X) \\ge E [\\log P(X|z) ] - D_{KL} [Q(z|X)||P(z)] \"/></p>\n\n<p>が成り立つ。たとえば、12 - 2 = 10 のとき 12 >= 10。</p>\n\n<p>左辺がデータXの対数尤度なので生成モデルにおいて最大化したい値になる。右辺は <strong>変分下限（ELBO: evidence lower bound）</strong> と呼び、対数尤度の下限となる。ここで、対数尤度を最大化する問題を<strong>変分下限を最大化する問題に置き換える</strong>のがポイント。変分下限をできるだけ大きくしてやれば、それより大きい対数尤度も大きくなるというわけ。変分下限を最大化するには、</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20E_%7BQ%28z%7CX%29%7D%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20%5Cto%20%5Cmax\" alt=\" E_{Q(z|X)} [\\log P(X|z) ] \\to \\max\"/></p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BQ%28z%7CX%29%20%7C%7C%20P%28z%29%20%5D%20%5Cto%20%5Cmin\" alt=\" D_{KL} [Q(z|X) || P(z) ] \\to \\min\"/></p>\n\n<p>とすればよい。簡単のため期待値の分布は省略してたけど最初の式をきちんと導出していくと Q(z|X) になることがわかる。</p>\n\n<h3>Reconstruction Loss</h3>\n\n<p><em>実はここの理解がちょっと怪しい。尤度最大化って交差エントロピーの最小化と等価で正しい？ときどき一部の論文でlossの式に尤度が書いてあってちょっと混乱する。</em></p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20E_%7BQ%28z%7CX%29%7D%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20%5Cto%20%5Cmax\" alt=\" E_{Q(z|X)} [\\log P(X|z) ] \\to \\max\"/></p>\n\n<p>から見ていく。確率分布で書かれているのでわかりにくいが、<strong>Q(z|X) は入力画像Xを潜在空間zにマッピングしているためEncoderとみなせる</strong>。また、<strong>P(X|z) は潜在空間zから元の画像XにマッピングしているためDecoderとみなせる</strong>。つまり、この式は入力画像Xを潜在空間zに落としてそこからXに戻したときの対数尤度を最大化しろという意味だと解釈できる。</p>\n\n<p>この対数尤度の最大化は入力画像 <img src=\"https://chart.apis.google.com/chart?cht=tx&chl=X\" alt=\"X\"/>と再構成画像 <img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%5Chat%7BX%7D\" alt=\"\\hat{X}\"/> の交差エントロピーの最小化とみなせる。つまり、数式で表すと下の部分と一致する。これをReconstruction Lossと呼ぶ。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>recon = F.binary_cross_entropy(recon_x, x.view(-<span class=\"synConstant\">1</span>, <span class=\"synConstant\">784</span>), size_average=<span class=\"synIdentifier\">False</span>)\n</pre>\n\n\n<h3>KL Divergence</h3>\n\n<p>次はこの項。</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BQ%28z%7CX%29%20%7C%7C%20P%28z%29%20%5D%20%5Cto%20%5Cmin\" alt=\" D_{KL} [Q(z|X) || P(z) ] \\to \\min\"/></p>\n\n<p>先に述べたように Q(z|X) は入力画像Xを潜在空間zにマッピングしているためEncoderとみなせる。つまり、<strong>Encoderで入力画像Xをマッピングした分布 Q(z|X) が P(z) に近くなるようにしろという制約</strong> と解釈できる。</p>\n\n<p>ここで、<strong>P(z) は簡単のため平均0、分散1の多次元正規分布 N(0, I) と仮定する</strong>。</p>\n\n<p>先に書いたようにEncoderの出力は N(μ(X), Σ(X)) の正規分布に従うようにしたため、上の式は</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BN%28%5Cmu%28X%29%2C%20%5CSigma%20%28X%29%29%20%7C%7C%20N%280%2C%20I%29%20%5D%20\" alt=\" D_{KL} [N(\\mu(X), \\Sigma (X)) || N(0, I) ] \"/></p>\n\n<p>となる。多次元正規分布間のKL Divergenceは下の簡単な式で求まる。</p>\n\n<p><img src=\"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cdisplaystyle%20D_%7BKL%7D%20%5BN%28%5Cmu%28X%29%2C%20%5CSigma%28X%29%29%20%7C%7C%20N%280%2C%20I%29%20%5D%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bk%7D%20%281%20%2B%20%5Clog%20%5CSigma%28X%29%20-%20%5Cmu%28X%29%5E2%20-%20%5CSigma%28X%29%29\" alt=\" \\displaystyle D_{KL} [N(\\mu(X), \\Sigma(X)) || N(0, I) ] = - \\frac{1}{2} \\sum_{k} (1 + \\log \\Sigma(X) - \\mu(X)^2 - \\Sigma(X))\"/></p>\n\n<p>参考: <a href=\"https://qiita.com/kenmatsu4/items/c107bd51503462fb677f\">&#x591A;&#x5909;&#x91CF;&#x6B63;&#x898F;&#x5206;&#x5E03;&#x306E;&#x5834;&#x5408;&#x306E;Kullback Leibler Divergence&#x306E;&#x5C0E;&#x51FA; - Qiita</a></p>\n\n<p>これをコードで書くと</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>kld = -<span class=\"synConstant\">0.5</span> * torch.<span class=\"synIdentifier\">sum</span>(<span class=\"synConstant\">1</span> + logvar - mu.<span class=\"synIdentifier\">pow</span>(<span class=\"synConstant\">2</span>) - logvar.exp())\n</pre>\n\n\n<p>となる。この <code>kld</code> は<strong>潜在空間zが N(0, I) にちらばるようにする正則化項とみなせる</strong>。あとで実際に潜在空間を描画してみるとこの正則化が正しく機能していることがわかる。</p>\n\n<h2>訓練ループ</h2>\n\n<p>あとはいつもの訓練ループなので比較的簡単。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synStatement\">def</span> <span class=\"synIdentifier\">train</span>(epoch):\n    model.train()\n    train_loss = <span class=\"synConstant\">0</span>\n    <span class=\"synStatement\">for</span> batch_idx, (data, _) <span class=\"synStatement\">in</span> <span class=\"synIdentifier\">enumerate</span>(train_loader):\n        <span class=\"synStatement\">if</span> cuda:\n            data = Variable(data.cuda())\n        <span class=\"synStatement\">else</span>:\n            data = Variable(data)\n        optimizer.zero_grad()\n        recon_batch, mu, logvar = model(data)\n        loss = loss_function(recon_batch, data, mu, logvar)\n        loss.backward()\n        train_loss += loss.data[<span class=\"synConstant\">0</span>]\n        optimizer.step()\n    \n    <span class=\"synComment\"># loss_function() は平均ではなく全サンプルの合計lossを返すのでサンプル数で割る</span>\n    train_loss /= <span class=\"synIdentifier\">len</span>(train_loader.dataset)\n\n    <span class=\"synStatement\">return</span> train_loss    \n    \n\n<span class=\"synStatement\">def</span> <span class=\"synIdentifier\">test</span>(epoch):\n    model.<span class=\"synIdentifier\">eval</span>()\n    test_loss = <span class=\"synConstant\">0</span>\n    <span class=\"synStatement\">for</span> batch_idx, (data, _) <span class=\"synStatement\">in</span> <span class=\"synIdentifier\">enumerate</span>(test_loader):\n        <span class=\"synStatement\">if</span> cuda:\n            data = Variable(data.cuda(), volatile=<span class=\"synIdentifier\">True</span>)\n        <span class=\"synStatement\">else</span>:\n            data = Variable(data, volatile=<span class=\"synIdentifier\">True</span>)\n        recon_batch, mu, logvar = model(data)\n        loss = loss_function(recon_batch, data, mu, logvar)\n        test_loss += loss.data[<span class=\"synConstant\">0</span>]\n        \n        <span class=\"synStatement\">if</span> epoch % <span class=\"synConstant\">10</span> == <span class=\"synConstant\">0</span>:\n            <span class=\"synComment\"># 10エポックごとに最初のminibatchの入力画像と復元画像を保存</span>\n            <span class=\"synStatement\">if</span> batch_idx == <span class=\"synConstant\">0</span>:\n                n = <span class=\"synConstant\">8</span>\n                comparison = torch.cat([data[:n],\n                                        recon_batch.view(batch_size, <span class=\"synConstant\">1</span>, <span class=\"synConstant\">28</span>, <span class=\"synConstant\">28</span>)[:n]])\n                save_image(comparison.data.cpu(),\n                           <span class=\"synConstant\">'{}/reconstruction_{}.png'</span>.<span class=\"synIdentifier\">format</span>(out_dir, epoch), nrow=n)\n\n    test_loss /= <span class=\"synIdentifier\">len</span>(test_loader.dataset)\n\n    <span class=\"synStatement\">return</span> test_loss\n\nloss_list = []\ntest_loss_list = []\n<span class=\"synStatement\">for</span> epoch <span class=\"synStatement\">in</span> <span class=\"synIdentifier\">range</span>(<span class=\"synConstant\">1</span>, num_epochs + <span class=\"synConstant\">1</span>):\n    loss = train(epoch)\n    test_loss = test(epoch)\n\n    <span class=\"synIdentifier\">print</span>(<span class=\"synConstant\">'epoch [{}/{}], loss: {:.4f} test_loss: {:.4f}'</span>.<span class=\"synIdentifier\">format</span>(\n        epoch + <span class=\"synConstant\">1</span>,\n        num_epochs,\n        loss,\n        test_loss))\n\n    <span class=\"synComment\"># logging</span>\n    loss_list.append(loss)\n    test_loss_list.append(test_loss)\n\n<span class=\"synComment\"># save the training model</span>\nnp.save(<span class=\"synConstant\">'loss_list.npy'</span>, np.array(loss_list))\nnp.save(<span class=\"synConstant\">'test_loss_list.npy'</span>, np.array(test_loss_list))\ntorch.save(model.state_dict(), <span class=\"synConstant\">'vae.pth'</span>)\n</pre>\n\n\n<h2>学習曲線</h2>\n\n<p>学習曲線を描いてみよう。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synPreProc\">import</span> matplotlib.pyplot <span class=\"synStatement\">as</span> plt\n%matplotlib inline\nloss_list = np.load(<span class=\"synConstant\">'{}/loss_list.npy'</span>.<span class=\"synIdentifier\">format</span>(out_dir))\nplt.plot(loss_list)\nplt.xlabel(<span class=\"synConstant\">'epoch'</span>)\nplt.ylabel(<span class=\"synConstant\">'loss'</span>)\nplt.grid()\n</pre>\n\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225157.png\" alt=\"f:id:aidiary:20180228225157p:plain\" title=\"f:id:aidiary:20180228225157p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>test_loss_list = np.load(<span class=\"synConstant\">'{}/test_loss_list.npy'</span>.<span class=\"synIdentifier\">format</span>(out_dir))\nplt.plot(test_loss_list)\nplt.xlabel(<span class=\"synConstant\">'epoch'</span>)\nplt.ylabel(<span class=\"synConstant\">'test loss'</span>)\nplt.grid()\n</pre>\n\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225210.png\" alt=\"f:id:aidiary:20180228225210p:plain\" title=\"f:id:aidiary:20180228225210p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<p>テストlossも減っており、学習が進んでいることが確認できる。</p>\n\n<h2>入力画像と再構成画像の比較</h2>\n\n<p>上が入力画像で下が再構成画像。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synPreProc\">from</span> IPython.display <span class=\"synPreProc\">import</span> Image\nImage(<span class=\"synConstant\">'vae_2/reconstruction_10.png'</span>)\n</pre>\n\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225258.png\" alt=\"f:id:aidiary:20180228225258p:plain\" title=\"f:id:aidiary:20180228225258p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>Image(<span class=\"synConstant\">'vae_2/reconstruction_100.png'</span>)\n</pre>\n\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225314.png\" alt=\"f:id:aidiary:20180228225314p:plain\" title=\"f:id:aidiary:20180228225314p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<p>10エポック目だとあまり再現できてないが、100エポック目だとある程度は再現できている。ただ、潜在空間を2次元とかなり絞ったのであまりくっきりと再現できていない。潜在空間を20次元にすると</p>\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225426.png\" alt=\"f:id:aidiary:20180228225426p:plain\" title=\"f:id:aidiary:20180228225426p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<p>こんな感じでほぼ再構成できることがわかる。潜在空間が2次元だとテストlossは150くらいで収束するが、20次元にするとテストlossは90台まで下がる。</p>\n\n<h2>潜在空間の可視化</h2>\n\n<p>最後にテストデータを使って潜在空間を可視化しよう。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink>model.load_state_dict(torch.load(<span class=\"synConstant\">'{}/vae.pth'</span>.<span class=\"synIdentifier\">format</span>(out_dir),\n                                 map_location=<span class=\"synStatement\">lambda</span> storage,\n                                 loc: storage))\ntest_dataset = datasets.MNIST(<span class=\"synConstant\">'./data'</span>, download=<span class=\"synIdentifier\">True</span>, train=<span class=\"synIdentifier\">False</span>, transform=transforms.ToTensor())\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=<span class=\"synConstant\">10000</span>, shuffle=<span class=\"synIdentifier\">False</span>)\nimages, labels = <span class=\"synIdentifier\">iter</span>(test_loader).<span class=\"synIdentifier\">next</span>()\nimages = images.view(<span class=\"synConstant\">10000</span>, -<span class=\"synConstant\">1</span>)\n\n<span class=\"synComment\"># 784次元ベクトルを2次元ベクトルにencode</span>\nz = model.encode(Variable(images, volatile=<span class=\"synIdentifier\">True</span>))\nmu, logvar = z\nmu, logvar = mu.data.numpy(), logvar.data.numpy()\n<span class=\"synIdentifier\">print</span>(mu.shape, logvar.shape)\n</pre>\n\n\n<p>各入力画像Xごとに正規分布のパラメータ μ(X), Σ(X) が出力されるがここでは平均 μ(X) の場所に点をプロットすることにする。ランダムサンプリングすると平均の場所にマッピングされる可能性が一番高い。</p>\n\n<pre class=\"code lang-python\" data-lang=\"python\" data-unlink><span class=\"synPreProc\">import</span> pylab\n<span class=\"synPreProc\">import</span> matplotlib.pyplot <span class=\"synStatement\">as</span> plt\nplt.figure(figsize=(<span class=\"synConstant\">10</span>, <span class=\"synConstant\">10</span>))\nplt.scatter(mu[:, <span class=\"synConstant\">0</span>], mu[:, <span class=\"synConstant\">1</span>], marker=<span class=\"synConstant\">'.'</span>, c=labels.numpy(), cmap=pylab.cm.jet)\nplt.colorbar()\nplt.xlim((-<span class=\"synConstant\">6</span>, <span class=\"synConstant\">6</span>))\nplt.ylim((-<span class=\"synConstant\">6</span>, <span class=\"synConstant\">6</span>))\nplt.grid()\n</pre>\n\n\n<p><span itemscope itemtype=\"http://schema.org/Photograph\"><img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225730.png\" alt=\"f:id:aidiary:20180228225730p:plain\" title=\"f:id:aidiary:20180228225730p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"></span></p>\n\n<p>潜在空間zは平均0で分散Iの正規分布 P(z) = N(0, I) 上にデータが散らばっており、損失関数のKL divergenceの正則化項が効いていることがわかる。</p>\n\n<p>次はConditional VAEいってみよう！</p>\n\n<h2>参考文献</h2>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1312.6114\">Kingma, D. P. and M. Welling, Auto-Encoding Variational Bayes</a></li>\n<li><a href=\"https://arxiv.org/abs/1606.05908\">C. Doersch, Tutorial on Variational Autoencoders</a></li>\n<li><a href=\"https://github.com/pytorch/examples/blob/master/vae/main.py\">examples/main.py at master &middot; pytorch/examples &middot; GitHub</a></li>\n<li><a href=\"https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24\">Variational Autoencoder&#x5FB9;&#x5E95;&#x89E3;&#x8AAC; - Qiita</a></li>\n<li><a href=\"https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\">Variational Autoencoder: Intuition and Implementation - Agustinus Kristiadi&#39;s Blog</a></li>\n<li><a href=\"https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\">Tutorial - What is a variational autoencoder? &ndash; Jaan Altosaar</a></li>\n<li><a href=\"http://nzw0301.github.io/notes/vae.pdf\">Variational Auto Encoder</a></li>\n</ul>\n\n","descriptionType":"html","publishedDate":"Wed, 28 Feb 2018 14:32:24 +0000","feedId":18951,"bgimg":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225730.png","linkMd5":"e94b1a024c209cc0b3cf836fe32d4ca5","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx/cdn74@2020_1/2020/10/16/17-24-34-481_b147a750d6c95c6c.webp","destWidth":551,"destHeight":579,"sourceBytes":120325,"destBytes":43834,"author":"aidiary","enclosureType":"image/png","enclosureUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225730.png","articleImgCdnMap":{"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228212323.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn42@2020_4/2020/10/16/17-24-37-007_d1dd20f2c43dd6f8.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20z%20%5Csim%20N%28%5Cmu%28X%29%2C%20%5CSigma%28X%29%29":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn78@2020_4/2020/10/16/17-24-35-867_1949e9361ef4af71.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cepsilon%20%5Csim%20N%280%2C%20I%29":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn11@2020_5/2020/10/16/17-24-35-762_a715695cb212dfe4.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20z%20%3D%20%5Cmu%28X%29%20%2B%20%5CSigma%28X%29%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20%5Cepsilon":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn29@2020_2/2020/10/16/17-24-38-342_4d6817419befe965.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20%5CSigma":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn54@2020_3/2020/10/16/17-24-35-677_3b092e48ccf0d84a.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20std%20%3D%20%5Cexp%280.5%20%2A%20%5Clog%20%5CSigma%29%20%3D%20%5Cexp%28%5Clog%20%5CSigma%20%5E%20%5Cfrac%7B1%7D%7B2%7D%29%20%3D%20%5CSigma%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn90@2020_1/2020/10/16/17-24-35-742_600535fa916ae921.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cepsilon%20%2A%20%5CSigma%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20%2B%20%5Cmu":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn6@2020_1/2020/10/16/17-24-36-483_cf1d26626aad2719.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20P%28X%29%20-%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%3D%20E%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20-%20D_%7BKL%7D%20%5BQ%28z%7CX%29%7C%7CP%28z%29%5D%20":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn50@2020_2/2020/10/16/17-24-35-867_599ba21d127f3bf4.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%5Cge%200":null,"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20P%28X%29%20%5Cge%20E%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20-%20D_%7BKL%7D%20%5BQ%28z%7CX%29%7C%7CP%28z%29%5D%20":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn34@2020_5/2020/10/16/17-24-35-822_456c9925b062b7a1.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20E_%7BQ%28z%7CX%29%7D%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20%5Cto%20%5Cmax":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn9@2020_4/2020/10/16/17-24-37-968_3f4029c3e7894826.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BQ%28z%7CX%29%20%7C%7C%20P%28z%29%20%5D%20%5Cto%20%5Cmin":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn21@2020_6/2020/10/16/17-24-55-609_63ad050995a21442.webp","https://chart.apis.google.com/chart?cht=tx&chl=X":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn18@2020_2/2020/10/16/17-24-35-986_b59ec51b19cf76fa.webp","https://chart.apis.google.com/chart?cht=tx&chl=%5Chat%7BX%7D":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn81@2020_6/2020/10/16/17-24-35-897_ce5851f02fa04dd9.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BN%28%5Cmu%28X%29%2C%20%5CSigma%20%28X%29%29%20%7C%7C%20N%280%2C%20I%29%20%5D%20":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn2@2020_6/2020/10/16/17-24-37-234_5e189735f1a89133.webp","https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cdisplaystyle%20D_%7BKL%7D%20%5BN%28%5Cmu%28X%29%2C%20%5CSigma%28X%29%29%20%7C%7C%20N%280%2C%20I%29%20%5D%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bk%7D%20%281%20%2B%20%5Clog%20%5CSigma%28X%29%20-%20%5Cmu%28X%29%5E2%20-%20%5CSigma%28X%29%29":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn97@2020_6/2020/10/16/17-24-36-021_92f87ca497c2640e.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225157.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn91@2020_1/2020/10/16/17-24-38-577_fe1b6f4add048e4a.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225210.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn46@2020_1/2020/10/16/17-24-36-230_e7dae92ce3375c80.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225258.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn25@2020_5/2020/10/16/17-24-35-741_53e36132020894e9.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225314.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn38@2020_6/2020/10/16/17-24-36-287_811e520df1cf3285.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225426.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn55@2020_6/2020/10/16/17-24-38-397_8076faf30151b409.webp","https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225730.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn74@2020_1/2020/10/16/17-24-34-481_b147a750d6c95c6c.webp"},"publishedOrCreatedDate":1602869073204}],"record":{"createdTime":"2020-10-17 01:24:33","updatedTime":"2020-10-17 01:24:33","feedId":18951,"fetchDate":"Fri, 16 Oct 2020 17:24:33 +0000","fetchMs":1488,"handleMs":5838,"totalMs":30959,"newArticles":0,"totalArticles":30,"status":1,"type":0,"ip":"540163a0102fe53e04316a15a93523d0","hostName":"us-021*","requestId":"f26ccc20740e49e5b2838926bca22eab_18951","contentType":"application/atom+xml; charset=utf-8","totalBytes":114964,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":22,"articlesImgsGithubTotal":21,"successGithubMap":{"myreaderx25":1,"myreaderx8":1,"myreaderx15":1,"myreaderx7":1,"myreaderx6":1,"myreaderx16":1,"myreaderx10":1,"myreaderx11":1,"myreaderx22":1,"myreaderx3":1,"myreaderx33":1,"myreaderx2":1,"myreaderx12":1,"myreaderx1":1,"myreaderx13":1,"myreaderx24":1,"myreaderx31":1,"myreaderx18":1,"myreaderx29":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{"myreaderx23":1}},"feed":{"createdTime":"2020-09-07 02:18:44","updatedTime":"2020-09-07 02:18:44","id":18951,"name":"人工知能に関する断創録","url":"http://aidiary.hatenablog.com/feed","subscriber":175,"website":null,"icon":"https://aidiary.hatenablog.com/favicon.ico","icon_jsdelivr":null,"description":"このブログでは人工知能のさまざまな分野について調査したことをまとめています（更新停止: 2019年12月31日）","weekly":null,"link":"https://aidiary.hatenablog.com"},"noPictureArticleList":[{"createdTime":"2020-10-17 01:24:56","updatedTime":"2020-10-17 01:24:56","id":null,"feedId":18951,"linkMd5":"e94b1a024c209cc0b3cf836fe32d4ca5"}],"tmpCommonImgCdnBytes":43834,"tmpBodyImgCdnBytes":71130,"tmpBgImgCdnBytes":0,"extra4":{"start":1602869065530,"total":0,"statList":[{"spend":1837,"msg":"获取xml内容"},{"spend":5838,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":20915,"msg":"正文链接上传到cdn"}]},"extra5":22,"extra6":22,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%5Cge%200","sourceStatusCode":200,"destWidth":206,"destHeight":20,"sourceBytes":3071,"destBytes":1848,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":375,"convertSpendMs":4,"createdTime":"2020-10-17 01:24:35","host":"us-028*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn84/contents/2020/10/16/17-24-35-927_747d12ed3f79f178.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Fri, 16 Oct 2020 17:24:35 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["D3E2:57B0:F0C2F2:2289C1A:5F89D74D"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1602870262"],"x-ratelimit-used":["62"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn84/contents/2020/10/16/17-24-35-927_747d12ed3f79f178.webp","historyStatusCode":[],"spendMs":56},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3 KB","destSize":"1.8 KB","compressRate":"60.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%5Cge%200","sourceStatusCode":200,"destWidth":206,"destHeight":20,"sourceBytes":3071,"destBytes":1848,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":78,"convertSpendMs":3,"createdTime":"2020-10-17 01:24:35","host":"us-028*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn84/contents/2020/10/16/17-24-36-009_747d12ed3f79f178.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Fri, 16 Oct 2020 17:24:36 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["D3E2:57B0:F0C2FA:228A0C2:5F89D753"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1602870262"],"x-ratelimit-used":["62"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn84/contents/2020/10/16/17-24-36-009_747d12ed3f79f178.webp","historyStatusCode":[],"spendMs":60},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3 KB","destSize":"1.8 KB","compressRate":"60.2%"}],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-032.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-24.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-002.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-007.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe-58.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-028.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://europe66.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-024.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe70.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-011.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-006.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-54.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe62.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-003.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-040.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://us-027.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225730.png","sourceStatusCode":200,"destWidth":551,"destHeight":579,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn74@2020_1/2020/10/16/17-24-34-481_b147a750d6c95c6c.webp","sourceBytes":120325,"destBytes":43834,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":2220,"convertSpendMs":24,"createdTime":"2020-10-17 01:24:33","host":"europe-24*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5,e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"117.5 KB","destSize":"42.8 KB","compressRate":"36.4%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225258.png","sourceStatusCode":200,"destWidth":242,"destHeight":62,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn25@2020_5/2020/10/16/17-24-35-741_53e36132020894e9.webp","sourceBytes":5690,"destBytes":2078,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":937,"convertSpendMs":3,"createdTime":"2020-10-17 01:24:35","host":"us-036*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.6 KB","destSize":"2 KB","compressRate":"36.5%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cepsilon%20%5Csim%20N%280%2C%20I%29","sourceStatusCode":200,"destWidth":78,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn11@2020_5/2020/10/16/17-24-35-762_a715695cb212dfe4.webp","sourceBytes":1576,"destBytes":726,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":965,"convertSpendMs":2,"createdTime":"2020-10-17 01:24:35","host":"us-007*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.5 KB","destSize":"726 B","compressRate":"46.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20P%28X%29%20%5Cge%20E%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20-%20D_%7BKL%7D%20%5BQ%28z%7CX%29%7C%7CP%28z%29%5D%20","sourceStatusCode":200,"destWidth":374,"destHeight":20,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn34@2020_5/2020/10/16/17-24-35-822_456c9925b062b7a1.webp","sourceBytes":6143,"destBytes":3024,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1035,"convertSpendMs":3,"createdTime":"2020-10-17 01:24:35","host":"us-011*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"6 KB","destSize":"3 KB","compressRate":"49.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20std%20%3D%20%5Cexp%280.5%20%2A%20%5Clog%20%5CSigma%29%20%3D%20%5Cexp%28%5Clog%20%5CSigma%20%5E%20%5Cfrac%7B1%7D%7B2%7D%29%20%3D%20%5CSigma%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D","sourceStatusCode":200,"destWidth":315,"destHeight":31,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn90@2020_1/2020/10/16/17-24-35-742_600535fa916ae921.webp","sourceBytes":6152,"destBytes":2522,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1092,"convertSpendMs":5,"createdTime":"2020-10-17 01:24:35","host":"us-002*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"6 KB","destSize":"2.5 KB","compressRate":"41%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%5Chat%7BX%7D","sourceStatusCode":200,"destWidth":19,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn81@2020_6/2020/10/16/17-24-35-897_ce5851f02fa04dd9.webp","sourceBytes":598,"destBytes":316,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1099,"convertSpendMs":19,"createdTime":"2020-10-17 01:24:35","host":"us-027*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"598 B","destSize":"316 B","compressRate":"52.8%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20z%20%5Csim%20N%28%5Cmu%28X%29%2C%20%5CSigma%28X%29%29","sourceStatusCode":200,"destWidth":139,"destHeight":19,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn78@2020_4/2020/10/16/17-24-35-867_1949e9361ef4af71.webp","sourceBytes":2903,"destBytes":1240,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1017,"convertSpendMs":3,"createdTime":"2020-10-17 01:24:35","host":"europe62*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.8 KB","destSize":"1.2 KB","compressRate":"42.7%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20P%28X%29%20-%20D_%7BKL%7D%20%5B%20Q%28z%7CX%29%20%7C%7C%20P%28z%7CX%29%20%5D%20%3D%20E%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20-%20D_%7BKL%7D%20%5BQ%28z%7CX%29%7C%7CP%28z%29%5D%20","sourceStatusCode":200,"destWidth":569,"destHeight":20,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn50@2020_2/2020/10/16/17-24-35-867_599ba21d127f3bf4.webp","sourceBytes":7425,"destBytes":4446,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1212,"convertSpendMs":6,"createdTime":"2020-10-17 01:24:35","host":"us-028*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"7.3 KB","destSize":"4.3 KB","compressRate":"59.9%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Clog%20%5CSigma","sourceStatusCode":200,"destWidth":39,"destHeight":18,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn54@2020_3/2020/10/16/17-24-35-677_3b092e48ccf0d84a.webp","sourceBytes":957,"destBytes":508,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1324,"convertSpendMs":4,"createdTime":"2020-10-17 01:24:35","host":"us-002*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"957 B","destSize":"508 B","compressRate":"53.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=X","sourceStatusCode":200,"destWidth":16,"destHeight":14,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn18@2020_2/2020/10/16/17-24-35-986_b59ec51b19cf76fa.webp","sourceBytes":439,"destBytes":228,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1191,"convertSpendMs":2,"createdTime":"2020-10-17 01:24:35","host":"europe70*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"439 B","destSize":"228 B","compressRate":"51.9%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cdisplaystyle%20D_%7BKL%7D%20%5BN%28%5Cmu%28X%29%2C%20%5CSigma%28X%29%29%20%7C%7C%20N%280%2C%20I%29%20%5D%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bk%7D%20%281%20%2B%20%5Clog%20%5CSigma%28X%29%20-%20%5Cmu%28X%29%5E2%20-%20%5CSigma%28X%29%29","sourceStatusCode":200,"destWidth":531,"destHeight":44,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn97@2020_6/2020/10/16/17-24-36-021_92f87ca497c2640e.webp","sourceBytes":7734,"destBytes":4448,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1192,"convertSpendMs":4,"createdTime":"2020-10-17 01:24:35","host":"europe66*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"7.6 KB","destSize":"4.3 KB","compressRate":"57.5%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225210.png","sourceStatusCode":200,"destWidth":402,"destHeight":266,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn46@2020_1/2020/10/16/17-24-36-230_e7dae92ce3375c80.webp","sourceBytes":12677,"destBytes":8480,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1419,"convertSpendMs":9,"createdTime":"2020-10-17 01:24:35","host":"us-040*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"12.4 KB","destSize":"8.3 KB","compressRate":"66.9%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225314.png","sourceStatusCode":200,"destWidth":242,"destHeight":62,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn38@2020_6/2020/10/16/17-24-36-287_811e520df1cf3285.webp","sourceBytes":5266,"destBytes":2168,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1554,"convertSpendMs":4,"createdTime":"2020-10-17 01:24:35","host":"europe-24*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.1 KB","destSize":"2.1 KB","compressRate":"41.2%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20%5Cepsilon%20%2A%20%5CSigma%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20%2B%20%5Cmu","sourceStatusCode":200,"destWidth":71,"destHeight":31,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn6@2020_1/2020/10/16/17-24-36-483_cf1d26626aad2719.webp","sourceBytes":1382,"destBytes":724,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1674,"convertSpendMs":2,"createdTime":"2020-10-17 01:24:35","host":"us-032*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.3 KB","destSize":"724 B","compressRate":"52.4%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BN%28%5Cmu%28X%29%2C%20%5CSigma%20%28X%29%29%20%7C%7C%20N%280%2C%20I%29%20%5D%20","sourceStatusCode":200,"destWidth":227,"destHeight":20,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn2@2020_6/2020/10/16/17-24-37-234_5e189735f1a89133.webp","sourceBytes":4129,"destBytes":2082,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":2450,"convertSpendMs":4,"createdTime":"2020-10-17 01:24:35","host":"us-54*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4 KB","destSize":"2 KB","compressRate":"50.4%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228212323.png","sourceStatusCode":200,"destWidth":1024,"destHeight":520,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn42@2020_4/2020/10/16/17-24-37-007_d1dd20f2c43dd6f8.webp","sourceBytes":172654,"destBytes":24758,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":2412,"convertSpendMs":62,"createdTime":"2020-10-17 01:24:35","host":"europe62*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"168.6 KB","destSize":"24.2 KB","compressRate":"14.3%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20E_%7BQ%28z%7CX%29%7D%20%5B%5Clog%20P%28X%7Cz%29%20%5D%20%5Cto%20%5Cmax","sourceStatusCode":200,"destWidth":211,"destHeight":20,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn9@2020_4/2020/10/16/17-24-37-968_3f4029c3e7894826.webp","sourceBytes":4302,"destBytes":1716,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":3165,"convertSpendMs":4,"createdTime":"2020-10-17 01:24:35","host":"us-006*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5,e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4.2 KB","destSize":"1.7 KB","compressRate":"39.9%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20z%20%3D%20%5Cmu%28X%29%20%2B%20%5CSigma%28X%29%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%20%5Cepsilon","sourceStatusCode":200,"destWidth":144,"destHeight":31,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn29@2020_2/2020/10/16/17-24-38-342_4d6817419befe965.webp","sourceBytes":2817,"destBytes":1276,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":3534,"convertSpendMs":10,"createdTime":"2020-10-17 01:24:35","host":"us-024*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.8 KB","destSize":"1.2 KB","compressRate":"45.3%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225157.png","sourceStatusCode":200,"destWidth":392,"destHeight":266,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn91@2020_1/2020/10/16/17-24-38-577_fe1b6f4add048e4a.webp","sourceBytes":8786,"destBytes":5974,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1750,"convertSpendMs":26,"createdTime":"2020-10-17 01:24:37","host":"us-003*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"8.6 KB","destSize":"5.8 KB","compressRate":"68%"},{"code":1,"isDone":false,"source":"https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20180228/20180228225426.png","sourceStatusCode":200,"destWidth":242,"destHeight":62,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn55@2020_6/2020/10/16/17-24-38-397_8076faf30151b409.webp","sourceBytes":5299,"destBytes":2654,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":1844,"convertSpendMs":13,"createdTime":"2020-10-17 01:24:37","host":"us-003*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.2 KB","destSize":"2.6 KB","compressRate":"50.1%"},{"code":1,"isDone":false,"source":"https://chart.apis.google.com/chart?cht=tx&chl=%20D_%7BKL%7D%20%5BQ%28z%7CX%29%20%7C%7C%20P%28z%29%20%5D%20%5Cto%20%5Cmin","sourceStatusCode":200,"destWidth":211,"destHeight":20,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn21@2020_6/2020/10/16/17-24-55-609_63ad050995a21442.webp","sourceBytes":3396,"destBytes":1762,"targetWebpQuality":75,"feedId":18951,"totalSpendMs":20762,"convertSpendMs":2,"createdTime":"2020-10-17 01:24:35","host":"europe-58*","referer":"https://aidiary.hatenablog.com/entry/20180228/1519828344","linkMd5ListStr":"e94b1a024c209cc0b3cf836fe32d4ca5,e94b1a024c209cc0b3cf836fe32d4ca5","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.3 KB","destSize":"1.7 KB","compressRate":"51.9%"}],"successGithubMap":{"myreaderx25":1,"myreaderx8":1,"myreaderx15":1,"myreaderx7":1,"myreaderx6":1,"myreaderx16":1,"myreaderx10":1,"myreaderx11":1,"myreaderx22":1,"myreaderx3":1,"myreaderx33":1,"myreaderx2":1,"myreaderx12":1,"myreaderx1":1,"myreaderx13":1,"myreaderx24":1,"myreaderx31":1,"myreaderx18":1,"myreaderx29":1,"myreaderx19":1,"myreaderx":1},"failGithubMap":{"myreaderx23":1}}