{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2021-09-28 21:50:54","updatedTime":"2021-09-28 21:50:54","title":"MIG or vGPU Mode for NVIDIA Ampere GPU: Which One Should I Use? (Part 1 of 3)","link":"https://blogs.vmware.com/performance/?p=4699","description":"<p><em>By&#160;Hari Sivaraman, Uday Kurkure, and Lan Vu</em>&#160;</p>    <p>NVIDIA Ampere-based GPUs [1, 2] are the latest generation of GPUs from NVIDIA. NVIDIA Ampere GPUs on VMware vSphere 7 Update 2 (or later) can be shared among VMs in one of two modes: VMware’s virtual GPU (vGPU) mode or NVIDIA’s multi-instance GPU (MIG) mode. NVIDIA vGPU software is included in the NVIDIA AI Enterprise suite, which is certified for VMware vSphere. </p>    <p>In vGPU mode, the memory on the GPU is statically partitioned, but the compute capability is time-shared among the VMs that share the GPU. In this mode, when a VM is running on the GPU, it “owns” all the compute capability of the GPU but only has access to its share of GPU memory. </p>    <p>In MIG mode, the memory and computational capability are statically partitioned. When a VM uses a GPU in MIG mode, it can only access the memory assigned to it and only use the computational cores assigned to it. So, even if the remaining computational cores (that is, the cores not assigned to this VM) in the GPU are idle, the VM cannot use those idle cores.  </p>    <p>Regardless of which mode a VM uses to execute its workload, the computational results will be the same. The only difference will be in the performance, measured using wall-clock time, achieved. Both the vGPU and MIG modes have their respective advantages and drawbacks: the vGPU mode time-shares the computational cores, whereas the MIG mode statically partitions the cores. Given this difference in how cores are shared by these two modes, it raises the question of which mode delivers the best performance (that is, the lowest run time) for a given workload. We attempt to answer this question in a series of blogs of which this is the first part.</p>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1024x377.png\" alt=\"\" class=\"wp-image-4743\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1024x377.png 1024w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-300x111.png 300w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-768x283.png 768w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1536x566.png 1536w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-600x221.png 600w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1.png 1598w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Table 1. Summary of results from running unit tests with different compute and data transfer profiles.</em></figcaption></figure>    <p>We ran unit tests (see table 1) inspired by the classic CUDA matrix multiplication example, with different ratios of computation to data transfer from host to GPU and back, to determine the criteria for what workloads would show better performance on MIG mode and which ones would do better in vGPU mode. Our test used ten matrices each of size 1000X1000. </p>    <p>The results presented in this blog show that workloads that execute heavy, large computational CUDA kernels with no interruptions for data transfers or CPU computations show better performance in MIG mode than in vGPU mode. But when the CUDA kernels are interspersed with data transfers or interruptions to execute CPU computations, vGPU mode offers better performance. So, the workload characteristics determine which GPU mode, vGPU or MIG, will deliver the best performance. In subsequent blogs, we’ll present results from real-world applications to show that the conclusions reached using unit tests apply to actual workloads.</p>    <h2>Test Environment, Code, and Results</h2>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1.png\" alt=\"\" class=\"wp-image-4724\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1.png 1024w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1-300x158.png 300w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1-768x405.png 768w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1-600x316.png 600w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Figure 1. Pseudocode for unit test that intersperses data transfers with CUDA computation. The test has ten matrices each of size 1000&#215;1000.</em></figcaption></figure>    <p>The tests were run on a Dell R740 (2 Intel Xeon Gold 6140 CPUs, 768 GB RAM, SSD storage) with 2 A100 GPUs. One GPU was configured in vGPU mode and the second was configured in MIG mode. Pseudocode for the first test is shown in figure 1 (above). The test was run with different ratios of data transfer to compute. The ratio values we tested were 0% data transfer, 10% data transfer, 20% data transfer, and so on in steps of ten to 100% data transfer. For each ratio of data transfer to compute, we varied the number of VMs running concurrently from one to the maximum allowed for that vGPU or MIG profile. For example, with MIG profile a100-1-5c (which denotes a profile with one compute slice and 5 GB GPU memory), a maximum of seven VMs can share the GPU. So, with this profile, we varied the number of VMs from one through seven.  MIG profile a100-2-10c can support a maximum of 3 VMs. So, for this profile, we varied the number of VMs from one through three. The run time for executing CUDA computations for this test with 10% data transfer to 90% compute activity is shown in figure 2 (below). From the figure, we can see that when data transfers are interspersed with computations and the ratio of data transfers is 10%, vGPU mode offers better performance for the CUDA computations.</p>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2-874x1024.png\" alt=\"\" class=\"wp-image-4710\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2-874x1024.png 874w, https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2-256x300.png 256w, https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2-768x900.png 768w, https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2-600x703.png 600w, https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2.png 883w\" sizes=\"(max-width: 874px) 100vw, 874px\" /><figcaption> <em>Table 2. Configurations we used for all three sets of tests. vGPU mode can support more than seven VMs running concurrently in the A100-4c and A100-5c profiles, but since the maximum number of VMs that can be run concurrently with MIG mode is seven, we only tested with at most seven VMs running concurrently. We also did not test with mixed MIG modes, as in one VM with MIG mode A100-2-10c and a second with A100-1-5c.  In vGPU mode, all tests used the best-effort scheduler with the default time slice.  </em></figcaption></figure>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/download-fig1-1024x512.png\" alt=\"\" class=\"wp-image-4730\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/download-fig1-1024x512.png 1024w, https://blogs.vmware.com/performance/files/2021/09/download-fig1-300x150.png 300w, https://blogs.vmware.com/performance/files/2021/09/download-fig1-768x384.png 768w, https://blogs.vmware.com/performance/files/2021/09/download-fig1-600x300.png 600w, https://blogs.vmware.com/performance/files/2021/09/download-fig1.png 1152w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Figure 2. Mean normalized run time to execute CUDA computations for the test shown in Figure 1. These results are obtained with a 10% data transfer ratio. To normalize the run time, we divided the measured run time for this dataset by the maximum time in this dataset.</em></figcaption></figure>    <p> In figure 3 (below), we show results from this test with a ratio of 50% data transfers to 50% compute. The graphs show the run time for the entire test, and for the computations only. In figures 2 and 3, we can see that vGPU outperforms MIG mode when data transfers are interspersed with computation and the ratio of data transfers is 50%. From the data at other values of the ratio of data transfers to computation (not shown here), vGPU outperforms MIG mode whenever CUDA computations are interspersed with data transfers regardless of the ratio of data transfers to CUDA computation.   </p>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/download-fig2-1024x512.png\" alt=\"\" class=\"wp-image-4731\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/download-fig2-1024x512.png 1024w, https://blogs.vmware.com/performance/files/2021/09/download-fig2-300x150.png 300w, https://blogs.vmware.com/performance/files/2021/09/download-fig2-768x384.png 768w, https://blogs.vmware.com/performance/files/2021/09/download-fig2-600x300.png 600w, https://blogs.vmware.com/performance/files/2021/09/download-fig2.png 1152w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Figure 3. Mean normalized run time to execute CUDA computations and for the full test for the test shown in figure 1. These results are obtained with a 50% data transfer ratio. To normalize the run time, we divided the measured run time for this dataset by the maximum time in this dataset.</em></figcaption></figure>    <figure class=\"wp-block-gallery columns-1 is-cropped\"><ul class=\"blocks-gallery-grid\"><li class=\"blocks-gallery-item\"><figure><img src=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4.png\" alt=\"\" data-id=\"4732\" data-full-url=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4.png\" data-link=\"https://blogs.vmware.com/performance/?attachment_id=4732\" class=\"wp-image-4732\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4.png 996w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4-300x154.png 300w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4-768x394.png 768w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4-600x308.png 600w\" sizes=\"(max-width: 996px) 100vw, 996px\" /></figure></li></ul><figcaption class=\"blocks-gallery-caption\"><em>Figure 4. Pseudocode for test that executes both data transfers and computation, but the operations are aggregated; all data transfers are completed before computations are executed (that is, the operations are <strong>NOT</strong> interspersed). The test has ten matrices each of size 1000X1000.</em></figcaption></figure>    <p>In a second set of tests, we changed the code so that all the data transfer operations were completed before we ran any CUDA computations (see the pseudocode in figure 4, above). For this type of workload, MIG mode outperforms vGPU with up to about three VMs running concurrently. With more than three VMs running concurrently, there is a crossover point, and vGPU mode delivers better performance at higher consolidation (that is, with more than three VMs). Figure 5 shows data from this test. The data is truncated at four VMs to highlight the crossover point.</p>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/download-fig3-1024x410.png\" alt=\"\" class=\"wp-image-4733\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/download-fig3-1024x410.png 1024w, https://blogs.vmware.com/performance/files/2021/09/download-fig3-300x120.png 300w, https://blogs.vmware.com/performance/files/2021/09/download-fig3-768x307.png 768w, https://blogs.vmware.com/performance/files/2021/09/download-fig3-600x240.png 600w, https://blogs.vmware.com/performance/files/2021/09/download-fig3.png 1440w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Figure 5. Mean normalized run time to execute CUDA computations and for the full test for the test shown in figure 4. To normalize the run time, we divided the measured run time for this dataset by the maximum time in this dataset. The total time includes both compute and data transfer time.</em></figcaption></figure>    <p>In a final set of tests, we changed the code so that only CUDA computations were executed. The pseudocode is shown in figure 6, below. </p>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-1024x259.png\" alt=\"\" class=\"wp-image-4734\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-1024x259.png 1024w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-300x76.png 300w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-768x195.png 768w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-1536x389.png 1536w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-600x152.png 600w, https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6.png 1891w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Figure 6. Pseudocode for the test that executes only CUDA computations with just one data transfer to load data at the start. The test has ten matrices each of size 1000X1000.</em></figcaption></figure>    <p>We ran this test with all&#160;vGPU&#160;and MIG profiles. The results shown in figure 7 (below) clearly show that MIG mode offers better performance at almost all configurations and profiles with this workload.&#160; </p>    <figure class=\"wp-block-image size-large\"><img src=\"https://blogs.vmware.com/performance/files/2021/09/download-fig4-1024x512.png\" alt=\"\" class=\"wp-image-4735\" srcset=\"https://blogs.vmware.com/performance/files/2021/09/download-fig4-1024x512.png 1024w, https://blogs.vmware.com/performance/files/2021/09/download-fig4-300x150.png 300w, https://blogs.vmware.com/performance/files/2021/09/download-fig4-768x384.png 768w, https://blogs.vmware.com/performance/files/2021/09/download-fig4-600x300.png 600w, https://blogs.vmware.com/performance/files/2021/09/download-fig4.png 1152w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption><em>Figure 7. Total run time for the test with only CUDA computations. MIG mode offers the best performance at all configurations with this workload.</em></figcaption></figure>    <h2>Conclusion</h2>    <p>NVIDIA A100 and A30 Tensor Core GPUs (A30 GPUs will be supported in an upcoming release of vSphere) on VMware vSphere supports sharing a GPU among many VMs using two modes: vGPU and MIG. In vGPU mode, memory is statically partitioned, but the CUDA computational cores are time-shared. In MIG mode, memory and the CUDA computational cores are statically partitioned. This difference in how CUDA computational cores are partitioned can cause differences in the performance achieved using vGPU mode compared to MIG mode for the exact same workload.  </p>    <p>In this blog, we presented data from unit tests to show which workloads would show the best performance in each mode. vGPU mode shows the best performance, measured using wall-clock time, to complete the task for workloads with data transfers and/or CPU computations interspersed with CUDA computations. MIG mode shows the best performance for workloads that execute heavy, large CUDA kernels with little or no interruption for data transfers or CPU computations. For workloads with aggregated data transfers and aggregated CUDA computations, MIG mode shows the best performance for two or fewer VMs running concurrently, whereas the vGPU mode shows the best performance with three or more VMs running concurrently. </p>    <h2>References</h2>    <ol><li>NVIDIA Ampere Architecture <br><a href=\"https://www.nvidia.com/en-us/data-center/ampere-architecture/\">https://www.nvidia.com/en-us/data-center/ampere-architecture/</a> </li><li>NVIDIA Ampere GA102 GPU Architecture <br><a href=\"https://www.nvidia.com/content/PDF/nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf\">https://www.nvidia.com/content/PDF/nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf</a> </li></ol><p>The post <a rel=\"nofollow\" href=\"https://blogs.vmware.com/performance/2021/09/mig-or-vgpu-part1.html\">MIG or vGPU Mode for NVIDIA Ampere GPU: Which One Should I Use? (Part 1 of 3)</a> appeared first on <a rel=\"nofollow\" href=\"https://blogs.vmware.com/performance\">VROOM! Performance Blog</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 15 Sep 2021 23:54:38 +0000","feedId":38792,"bgimg":"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1024x377.png","linkMd5":"5318926085a0288b56be01b5ae9f7b03","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn87@2020_4/2021/09/28/13-53-56-135_8f019a828b716b8f.webp","destWidth":1024,"destHeight":377,"sourceBytes":238793,"destBytes":32500,"author":"Hari Sivaraman","articleImgCdnMap":{"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1024x377.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn7@2020_5/2021/09/28/13-52-55-798_8f019a828b716b8f.webp","https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn3@2020_5/2021/09/28/13-53-55-938_4f0053462722f7e9.webp","https://blogs.vmware.com/performance/files/2021/09/mig-vs-vgpu-table2-874x1024.png":null,"https://blogs.vmware.com/performance/files/2021/09/download-fig1-1024x512.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn23@2020_3/2021/09/28/13-52-55-925_13f85c7e15195c02.webp","https://blogs.vmware.com/performance/files/2021/09/download-fig2-1024x512.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn11@2020_3/2021/09/28/13-53-57-780_0ca600e1220238b6.webp","https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn20@2020_2/2021/09/28/13-53-55-983_9df628091a249fd1.webp","https://blogs.vmware.com/performance/files/2021/09/download-fig3-1024x410.png":null,"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig6-1024x259.png":null,"https://blogs.vmware.com/performance/files/2021/09/download-fig4-1024x512.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn99@2020_4/2021/09/28/13-52-56-180_8ea0d2076b71e36e.webp"},"publishedOrCreatedDate":1632837054131}],"record":{"createdTime":"2021-09-28 21:50:54","updatedTime":"2021-09-28 21:50:54","feedId":38792,"fetchDate":"Tue, 28 Sep 2021 13:50:54 +0000","fetchMs":1405,"handleMs":17,"totalMs":245125,"newArticles":0,"totalArticles":10,"status":1,"type":0,"ip":"af0629e1ae74a27744b4cbd27b40a78e","hostName":"us-023*","requestId":"e6ecc7b980e642ad8913606049ce7faa_38792","contentType":"text/xml; charset=UTF-8","totalBytes":155800,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":9,"articlesImgsGithubTotal":6,"successGithubMap":{"myreaderx25":1,"myreaderx6":1,"myreaderx32":1,"myreaderx3":1,"myreaderx5oss":1,"myreaderx29":1,"myreaderx":1},"failGithubMap":{"myreaderx23":1}},"feed":{"createdTime":"2020-09-07 03:15:17","updatedTime":"2020-09-07 05:30:49","id":38792,"name":"VMware VROOM! Performance Blog","url":"http://blogs.vmware.com/performance/rss.xml","subscriber":83,"website":null,"icon":"https://blogs.vmware.com/performance/files/2020/08/cropped-perf-icon-32x32.png","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx63/cdn56@2020_2/2020/09/06/21-30-46-873_280fc8623629fd86.png","description":"from VMware's performance engineering team","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2021-09-28 21:54:57","updatedTime":"2021-09-28 21:54:57","id":null,"feedId":38792,"linkMd5":"5318926085a0288b56be01b5ae9f7b03"}],"tmpCommonImgCdnBytes":0,"tmpBodyImgCdnBytes":155800,"tmpBgImgCdnBytes":0,"extra4":{"start":1632837052710,"total":0,"statList":[{"spend":1407,"msg":"获取xml内容"},{"spend":17,"msg":"解释文章"},{"spend":61070,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":122148,"msg":"正文链接上传到cdn"}]},"extra5":9,"extra6":7,"extra7ImgCdnFailResultVector":[null,null,null,null,null,null,null,null,null,{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/download-fig3-1024x410.png","sourceStatusCode":200,"destWidth":1024,"destHeight":410,"sourceBytes":63622,"destBytes":14976,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":612,"convertSpendMs":30,"createdTime":"2021-09-28 21:53:57","host":"us-037*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn15/contents/2021/09/28/13-53-58-019_aaf2a583e87a6607.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Tue, 28 Sep 2021 13:53:58 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["8946:0710:493D7:864B3:61531E76"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1632837892"],"x-ratelimit-resource":["core"],"x-ratelimit-used":["60"],"x-xss-protection":["0"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn15/contents/2021/09/28/13-53-58-019_aaf2a583e87a6607.webp","historyStatusCode":[],"spendMs":244},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"62.1 KB","destSize":"14.6 KB","compressRate":"23.5%"},null,null],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-025.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-037.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe-25.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe21.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe63.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe-59.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-51.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-029.herokuapp.com/":{"failCount":1,"successCount":2,"resultList":[200,200,null]},"http://us-012.herokuapp.com/":{"failCount":1,"successCount":3,"resultList":[200,200,200,null]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1024x377.png","sourceStatusCode":200,"destWidth":1024,"destHeight":377,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn7@2020_5/2021/09/28/13-52-55-798_8f019a828b716b8f.webp","sourceBytes":238793,"destBytes":32500,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":412,"convertSpendMs":19,"createdTime":"2021-09-28 21:52:55","host":"us-012*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03,5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"233.2 KB","destSize":"31.7 KB","compressRate":"13.6%"},{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/download-fig1-1024x512.png","sourceStatusCode":200,"destWidth":1024,"destHeight":512,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn23@2020_3/2021/09/28/13-52-55-925_13f85c7e15195c02.webp","sourceBytes":45800,"destBytes":16430,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":510,"convertSpendMs":19,"createdTime":"2021-09-28 21:52:55","host":"us-029*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"44.7 KB","destSize":"16 KB","compressRate":"35.9%"},{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/download-fig4-1024x512.png","sourceStatusCode":200,"destWidth":1024,"destHeight":512,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn99@2020_4/2021/09/28/13-52-56-180_8ea0d2076b71e36e.webp","sourceBytes":44773,"destBytes":15676,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":743,"convertSpendMs":21,"createdTime":"2021-09-28 21:52:55","host":"us-037*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"43.7 KB","destSize":"15.3 KB","compressRate":"35%"},{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig1.png","sourceStatusCode":200,"destWidth":1024,"destHeight":540,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn3@2020_5/2021/09/28/13-53-55-938_4f0053462722f7e9.webp","sourceBytes":138370,"destBytes":34466,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":321,"convertSpendMs":26,"createdTime":"2021-09-28 21:53:55","host":"us-029*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"135.1 KB","destSize":"33.7 KB","compressRate":"24.9%"},{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-fig4.png","sourceStatusCode":200,"destWidth":996,"destHeight":511,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn20@2020_2/2021/09/28/13-53-55-983_9df628091a249fd1.webp","sourceBytes":96916,"destBytes":34334,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":401,"convertSpendMs":30,"createdTime":"2021-09-28 21:53:55","host":"us-012*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"94.6 KB","destSize":"33.5 KB","compressRate":"35.4%"},{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/mig-vgpu-table1-1024x377.png","sourceStatusCode":200,"destWidth":1024,"destHeight":377,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn87@2020_4/2021/09/28/13-53-56-135_8f019a828b716b8f.webp","sourceBytes":238793,"destBytes":32500,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":821,"convertSpendMs":20,"createdTime":"2021-09-28 21:53:55","host":"europe-59*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03,5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"233.2 KB","destSize":"31.7 KB","compressRate":"13.6%"},{"code":1,"isDone":false,"source":"https://blogs.vmware.com/performance/files/2021/09/download-fig2-1024x512.png","sourceStatusCode":200,"destWidth":1024,"destHeight":512,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn11@2020_3/2021/09/28/13-53-57-780_0ca600e1220238b6.webp","sourceBytes":61203,"destBytes":22394,"targetWebpQuality":75,"feedId":38792,"totalSpendMs":493,"convertSpendMs":25,"createdTime":"2021-09-28 21:53:57","host":"us-012*","referer":"https://blogs.vmware.com/performance/?p=4699","linkMd5ListStr":"5318926085a0288b56be01b5ae9f7b03","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"59.8 KB","destSize":"21.9 KB","compressRate":"36.6%"}],"successGithubMap":{"myreaderx25":1,"myreaderx6":1,"myreaderx32":1,"myreaderx3":1,"myreaderx5oss":1,"myreaderx29":1,"myreaderx":1},"failGithubMap":{"myreaderx23":1}}