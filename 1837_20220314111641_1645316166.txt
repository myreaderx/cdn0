{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2022-03-14 19:12:31","updatedTime":"2022-03-14 19:12:31","title":"7 Papers & Radios | DeepMind用AI复原古希腊铭文登Nature封面；单GPU调优GPT-3超参数","link":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","description":"<div><div><div id=\"media\" class=\"rich_media_thumb_wrp\">\n\n            <img class=\"rich_media_thumb\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hRlLEGWibvzkmJA6SFYUMbJnibCUfEgU0F5xpWpyuyPuY3Gl6RJrA8tg/0?wx_fmt=jpeg?imageView2/1/w/600\">\n        </div>\n    \n\n    \n\n    <div class=\"rich_media_content\" id=\"js_content\">\n                    \n\n                    \n                    \n                    \n                    <section data-mpa-powered-by=\"yiban.io\" data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" data-style=\"white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: \" helvetica neue sans gb yahei arial sans-serif box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__0\" style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-size-adjust: auto;font-family: \" visible><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" style=\"outline: 0px;max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section data-darkmode-bgcolor-16095509242984=\"rgb(25, 25, 25)\" data-darkmode-original-bgcolor-16095509242984=\"rgb(255, 255, 255)\" data-style=\"margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;\" class=\"js_darkmode__1\" style=\"margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;max-width: 100%;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section style=\"margin-top: -1.2em;outline: 0px;max-width: 100%;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(163, 163, 163) !important;\"><span style=\"outline: 0px;max-width: 100%;text-decoration: inherit;visibility: visible;color: rgb(255, 255, 255);letter-spacing: 0.544px;background-color: rgb(117, 117, 118);font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">机器之心 &amp; ArXiv Weekly Radiostation</span></section><section style=\"margin-top: 10px;margin-bottom: 5px;outline: 0px;max-width: 100%;min-height: 1em;text-align: center;visibility: visible;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"outline: 0px;max-width: 100%;font-size: 12px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"outline: 0px;max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">参与：杜伟</strong><strong style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">、<strong style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;box-sizing: border-box !important;overflow-wrap: break-word !important;\">楚航、罗若天</strong></strong></span></strong></span></section></section></section></section></section></section></section></section></section></section></section></section><blockquote data-type=\"2\" data-url=\"\" data-author-name=\"\" data-content-utf8-length=\"136\" data-source-title=\"\" style=\"outline: 0px;color: rgba(0, 0, 0, 0.5);max-width: 100%;font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal rgb border-box break-word><section style=\"outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><section style=\"outline: 0px;max-width: 100%;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span style=\"letter-spacing: 0.544px;\">本周论文包括 DeepMind 用 AI 复原古希腊铭文，登 Nature 封面；微软联合 OpenAI 提出超参数调优新范式，单个 GPU 上就可以调优 GPT-3 超参数。</span><br></section></section></blockquote><section style=\"outline: 0px;max-width: 100%;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><br></section><section style=\"outline: 0px;max-width: 100%;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong><span style=\"font-size: 15px;\">目录：</span></strong></section><section style=\"outline: 0px;max-width: 100%;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong><span style=\"font-size: 15px;\"><br></span></strong></section><ol class=\"list-paddingleft-1\" style=\"list-style-type: decimal;\"><li><p><span style=\"font-size: 15px;\">Restoring and attributing ancient texts using deep neural networks</span></p></li><li><p><span style=\"font-size: 15px;\">Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer </span></p></li><li><p><span style=\"font-size: 15px;\">Rediscovering orbital mechanics with machine learning </span></p></li><li><p><span style=\"font-size: 15px;\">End-to-End Referring Video Object Segmentation with Multimodal Transformers </span></p></li><li><p><span style=\"font-size: 15px;\">Do We Really Need Deep Learning Models for Time Series Forecasting? </span></p></li><li><p><span style=\"font-size: 15px;\">HCSC: Hierarchical Contrastive Selective Coding </span></p></li><li><p><span style=\"font-size: 15px;\">Exploring Endogenous Shift for Cross-domain Detection: A Large-scale Benchmark and Perturbation Suppression Network</span></p></li><li><p><span style=\"font-size: 15px;\">ArXiv Weekly Radiostation：NLP、CV、ML 更多精选论文（附音频）</span></p></li></ol><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 1：Restoring and attributing ancient texts using deep neural networks</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Yannis Assael、Thea Sommerschield 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://www.nature.com/articles/s41586-022-04448-z</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">在最新一期 Nature 封面文章中，DeepMind 联合威尼斯大学人类学系、牛津大学经典学院的研究者，探索利用机器学习来帮助历史学家更好地解释这些铭文，从而让人们更深入地了解古代历史，并释放 AI 和历史学家之间合作的潜力。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">他们提出了首个可以恢复受损铭文缺失文本、识别原始位置并帮助确定创建日期的深度神经网络 —— Ithaca，它是以荷马史诗《奥德赛》中的希腊伊萨卡岛命名，在之前的 Pythia 工具上构建并进行了扩展。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究结果表明，当单独使用时，Ithaca 在恢复受损铭文文本方面的准确率达到了 62%。相比之下，参与的历史学家的准确率为 25%，不过他们使用 Ithaca 可以将这一数字提升到 72%。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">同时，Ithaca 在识别铭文原始位置方面的准确率达到了 71%，鉴定它们的年代只与真实日期范围相差不到 30 年。历史学家已经使用 Ithaca 重新评估了希腊历史上的重要时期。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">此外，为了让广大研究人员、教育工作者、博物馆职员及其他人使用他们的研究成果，DeepMind 与谷歌云、谷歌艺术与文化合作推出了 Ithaca 的免费交互版本。并且，DeepMind 还开源了代码、预训练模型和交互 Colab 笔记本。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">模型核心为稀疏自注意力机制，用来并行计算这两个输入（单词和单个字符）。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9906976744186047\" data-s=\"300,640\" data-type=\"png\" data-w=\"860\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9N0agrUzBNpwgMTiaChPTwVlPXUdDuNDicFA3LSJObC2p3Qib6pBttzoiaA/640?wx_fmt=png\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">Ithaca 的主干由堆叠的 transformer 块组成：每个块输出一系列处理后的表示，其长度等于输入字符的数量，每个块的输出成为下一个块的输入。主干的最终输出被传递给三个不同的任务头，分别处理恢复、地理归属和时间归属。每个头都由一个浅层前馈神经网络组成，专门针对每个任务进行训练。在图 2 所示的例子中，恢复头预测了三个丢失的字符；地理归属头将铭文分为 84 个区域，并且按时间顺序的归属头将其追溯到公元前 800 年至公元 800 年之间。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5772200772200772\" data-s=\"300,640\" data-type=\"png\" data-w=\"1036\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hE5KQrLRE1EwV9j3Jux0y613vKxUVXegOe965d5QOiaBrM1vjkXoYRA/640?wx_fmt=png\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">预测过去？DeepMind 用 AI 复原古希腊铭文，登 Nature 封面。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 2：Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Greg Yang 、 Edward J. Hu、 Igor Babuschkin 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://arxiv.org/pdf/2203.03466.pdf</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">来自微软和 OpenAI 的研究者首次提出了基础研究如何调优大型神经网络（这些神经网络过于庞大而无法多次训练）。他们通过展示特定参数化保留不同模型大小的最佳超参数来实现这一点。利用 µP （Maximal Update Parametrization）将 HP （超参数）从小型模型迁移到大型模型。也就是说，该研究在大型模型上获得了接近最优的 HP。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">具体而言，该研究证明，在 µP 中，即使模型大小发生变化，许多最优的 HP 仍保持稳定。这导致一种新的 HP 调优范式：µTransfer，即在 µP 中对目标模型进行参数化，并在较小的模型上间接调优 HP，将其零样本迁移到全尺寸模型上，无需调优后者。该研究在 Transformer 和 ResNet 上验证 µTransfer，例如，1）通过从 13M 参数的模型中迁移预训练 HP，该研究优于 BERT-large (350M 参数)，总调优成本相当于一次预训练 BERT-large；2）通过从 40M 参数迁移，该研究的性能优于已公开的 6.7B GPT-3 模型，调优成本仅为总预训练成本的 7%。 </span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">与随机初始化不同，模型训练期间的行为更难进行数学分析。该研究用 µP 解决，如图 1 右侧所示，该图显示了网络激活扩展（activation scales）在模型宽度增加的最初几个训练步骤中的稳定性。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe98sqLEhCl1la13aNWvdicDpbwQrPAIywSZ3ZJ4SLrHcf1YtUiaqTKX12g/640?wx_fmt=png\"></p><section style=\"text-align: left;line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">图 1：在 PyTorch 的默认参数化中，左图，在经过一次 step 训练后，激活扩展的宽度会出现差异。但是在右图的 µP 中，无论训练 step 宽度如何，激活扩展都会发生一致的变化。</span></em></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">如图所示，µP 是唯一在宽度上保持最佳学习率的参数化，在宽度为 213 - 8192 的模型中实现了最佳性能，并且对于给定的学习率，更宽的模型性能更好——即曲线不相交。</span></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5630797773654916\" data-s=\"300,640\" data-type=\"gif\" data-w=\"1078\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9uc365d2e0IVdribEf1tAe9YX5r0PzibQKJN1lsQrb23cPqKLP6z8TJklibia2kaPohiac0TvSqeKxicLw/640?wx_fmt=gif\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">基于张量程序（Tensor Programs）的理论基础，µTransfer 自动适用于高级架构，例如 Transformer 和 ResNet。此外，它还可以同时迁移各种超参数。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">微软联合 OpenAI 提出 HP 调优新范式，单个 GPU 上就可以调优 GPT-3 超参数。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 3：Rediscovering orbital mechanics with machine learning</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Pablo Lemos 、 Niall Jeffrey 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://arxiv.org/pdf/2202.02306.pdf</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">机器学习 (ML) 推动了科学的巨大进步，从粒子物理学到结构生物学再到宇宙学，机器学习能够在大型数据集中学习特征，对不同的对象进行分类，并执行参数推断，以及更具开创性的应用，例如自回归语言模型、预测蛋白质结构，以及蛋白质功能预测。机器学习强大的学习能力，我们不禁会问，机器学习能否仅仅通过观察我们的太阳系来重新发现万有引力定律？</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">近日来自萨塞克斯大学、伦敦大学学院等机构的研究者在论文《 Rediscovering orbital mechanics with machine learning 》中对上述问题进行的解答，他们的回答是：可以。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">具体而言，该研究提出了一种采用机器学习方法，通过观察自动发现实际物理系统的控制方程和隐藏属性。研究者训练了一个图神经网络，通过 30 年的轨迹数据来模拟太阳系的太阳、行星和大型卫星的动力学。然后，他们使用符号回归来发现神经网络隐式学习的力学定律解析表达式，结果表明表达式等效于牛顿万有引力定律。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">该研究分为两个阶段：第一阶段的学习模拟器基于图网络 (GN)，图网络是一种深度神经网络，可以通过训练来逼近图上的复杂函数。在这里，太阳系的太阳、行星和卫星的（相对）位置和速度被表示为输入图的节点，而天体之间可能的物理交互（例如力）被表示为图的边。该研究将基于 GN 的模拟器与 30 年来观测到的太阳系轨迹进行了拟合。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在第二阶段，该研究分离边函数（edge function），并应用符号回归拟合边函数的解析公式，其最好的拟合是对牛顿万有引力定律的拟合。然后，该研究使用已发现的方程重新拟合未观察到的（相对）天体质量，并找到了与天体真实质量几乎完美的拟合。之后研究者可以使用发现的方程和重新学习的质量来模拟太阳系动力学，并获得与真实观察到的轨迹非常接近的对应关系。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.6144578313253012\" data-s=\"300,640\" data-type=\"gif\" data-w=\"1079\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9uc365d2e0IVdribEf1tAe9xEp49eGDZx9AP15Pwr4FgcFgS5U0KDGIBMAHzN24X6am1WDOvqcUWw/640?wx_fmt=gif\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"display: none;line-height: 0px;\">‍</span><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">给 GNN 一堆数据，它自己发现了万有引力定律。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 4：End-to-End Referring Video Object Segmentation with Multimodal Transformers</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Adam Botach、Evgenii Zheltonozhskii、Chaim Baskin</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://arxiv.org/pdf/2111.14821.pdf</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"display: none;line-height: 0px;\">‍</span><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">在被 CVPR 2022 接收的一篇论文《End-to-End Referring Video Object Segmentation with Multimodal Transformers》中，来自以色列理工学院的研究者提出了一种简单的、基于 Transformer 的端到端 RVOS 方法——Multimodal Tracking Transformer（MTTR ）。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">具体地，他们使用 MTTR 将任务建模成序列预测问题。给定一个视频和文本查询，该模型在确定文本参考的对象之前为视频中所有对象生成预测序列。并且，他们的方法不需要与文本相关的归纳偏置模块，利用简单的交叉熵损失对齐视频和文本。因此，该方法相比以往简单的多。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究者提出的 pipeline 示意图如下所示。首先使用标准的 Transformer 文本编码器从文本查询中提取语言特征，使用时空编码器从视频帧中提取视觉特征。接着将这些特征传递给多模态 Transformer 以输出几个对象预测序列。然后为了确定哪个预测序列能够最好地对应参考对象，研究者计算了每个序列的文本参考分数。为此，他们还提出了一种时序分割 voting 方案，使模型在做出决策时专注于最相关的部分。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9811912225705329\" data-s=\"300,640\" data-type=\"png\" data-w=\"957\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9zqzUMumtickt0nlMdj2z6kkK67CEGriaEHBXceWDcl8Jt8QVRibiccxlgg/640?wx_fmt=png\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">从实验结果来看，MTTR 在 A2D-Sentences 和 JHMDB-Sentences 数据集上分别实现了 + 5.7 和 + 5.0 的 mAP 增益，同时每秒能够处理 76 帧。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究者还展示了一系列不同对象之间的实际分割效果，如下穿白色 T 恤和蓝色短裤的冲浪者（淡黄色冲浪板）。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.6711956521739131\" data-s=\"300,640\" data-type=\"gif\" data-w=\"736\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9uc365d2e0IVdribEf1tAe9xXc1SkhvPsHm8pPiaYJT4Peic7nsQXcFxgMSBPpmtVkC93naibZ1PAhXQ/640?wx_fmt=gif\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">实例分割过程如图 2 所示：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><p style=\"text-align: center;\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.7712962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" style=\"max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9T7f8ePcCZQyPp1A2DoyLApDaoDx5YClqoEoOOn0E5tH8aU7aboC5ibQ/640?wx_fmt=png\"></p><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">单 GPU 每秒 76 帧，重叠对象也能完美分割，多模态 Transformer 用于视频分割效果惊艳。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 5：Do We Really Need Deep Learning Models for Time Series Forecasting?</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Shereen Elsayed 、 Daniela Thyssens 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://arxiv.org/pdf/2101.02118.pdf</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">来自德国希尔德斯海姆大学计算机科学系的研究者展示了通过精心配置的输入处理结构，GBRT 等简单但强大的集成模型在时间序列预测领域能够媲美甚至超越很多 DNN 模型。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">研究者对特征工程多输出 GBRT 模型进行了评估，并提出了以下两个研究问题：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">对于用于时间序列预测的基于窗口的学习框架来说，精心配置 GBRT 模型的输入和输出结构有什么效果？</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">一个虽简单但配置良好的 GBRT 模型与 SOTA 深度学习时间序列预测框架相比如何？</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">为了回答这两个问题，研究者选择了双重实验设置，分别解决两类预测任务，即系统化方式中的单变量和多变量预测。目的是评估 GBRT 模型以及在顶会（NeurIPS、KDD、SIGIR、ECML、ICML、CIKM、IJCAI、ICLR 等）中出现的 SOTA 深度学习方法。这项研究的整体贡献可以总结如下：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">一，研究者将一个简单的机器学习方法 GBRT 提升了竞品 DNN 时间序列预测模型的标准。首先将 GBRT 转换成一个基于窗口的回归框架，接着对它的输入和输出结构进行特征工程，如此便能从额外上下文信息中获益最多；</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">二，为了突出输入处理对时间序列预测模型的重要性，研究者通过实证证明了为什么基于窗口的 GBRT 输入设置可以在时间序列预测领域提高 ARIMA 和原版 GBRT 等精心配置的模型所产生的预测性能；</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">三，研究者比较了 GBRT 与各种 SOTA 深度学习时间序列预测模型的性能，并验证了它在单变量和双变量时间序列预测任务中的竞争力。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这种基于窗口的 GBRT 模型输入设置如图 1 所示：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.31666666666666665\" data-type=\"png\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9dmfiaxcZIh40OJZQDOibqughCJhW2Icmy8TusUFliaiaqFcXrkZeyhr18w/640?wx_fmt=png\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">为了使所选的深度学习基线和 GBRT 之间具有显著的可比性，该研究在相同的数据集上评估了所有模型，数据集如下表 1 所示：左边提供了关于用来评估模型数据集，而右边则列出了各自的实验规范：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5731481481481482\" data-type=\"png\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9UaqIIIJ6DibUpjh8iaG2qZqQw0ia5kqwomGpyHVrrEJX2WCsxKaUslG9A/640?wx_fmt=png\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">梯度提升回归树媲美甚至超越多个 DNN 模型。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 6：HCSC: Hierarchical Contrastive Selective Coding</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：Yuanfan Guo 、 Minghao Xu 、 Jiawen Li 等</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://arxiv.org/pdf/2202.00455.pdf</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">来自上海交通大学、Mila 魁北克人工智能研究所和字节跳动的研究者提出了一种基于层级语义结构的选择性对比学习框架（Hiearchical Contrastive Selective Coding，HCSC）。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">这一框架通过将图像表征进行层级聚类，构造具有层级结构的原型向量 (hierarhcical prototypes)，并通过这些原型向量选择更加符合语义结构的负样本进行对比学习, 由此将层级化的语义信息融入到图像表征中。该自监督学习框架在多个下游任务中达到卷积神经网络自监督预训练方法的 SOTA 性能。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.4264705882352941\" data-type=\"png\" data-w=\"612\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9k6KzNdqZ2JZuVGyibdWF5QwiaIHggkqVCMwrqknMff8icNPTiatCACJia7Q/640?wx_fmt=png\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">该工作的方法论框架包含两个重要的模块: 一个是层级语义结构的构建与维护, 另一个是基于层级语义结构的选择性对比学习。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在实现过程中, 该研究采用了简单有效的自底向上层级 K-means 算法, 具体算法流程如下：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.6013071895424836\" data-type=\"png\" data-w=\"612\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9iaEFSVtSxnFfb4jrk8icOPbyaIj5VnLuueqCDiczpI1ASiaIaSL3SQEBjQ/640?wx_fmt=png\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">CVPR 2022，CNN 自监督预训练新 SOTA：上交、Mila、字节联合提出具有层级结构的图像表征自学习新框架。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: left;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">论文 7：Exploring Endogenous Shift for Cross-domain Detection: A Large-scale Benchmark and Perturbation Suppression Network</span></strong></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><ul class=\"list-paddingleft-1\" style=\"list-style-type: disc;\"><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">作者：北京航空航天大学、科大讯飞研究院</span></p></li><li style=\"text-align: left;color: rgb(123, 12, 0);\"><p><span style=\"font-size: 15px;color: rgb(123, 12, 0);\">项目地址：https://github.com/DIG-Beihang/PSN</span></p></li></ul><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">摘要：</span></strong><span style=\"font-size: 15px;\">近日，计算机视觉顶级会议 CVPR 2022 接收论文结果已经正式公布，会议接收了一篇由北京航空航天大学、科大讯飞研究院共同完成的工作，论文题目为《Exploring Endogenous Shift for Cross-domain Detection: A Large-scale Benchmark and Perturbation Suppression Network》（之后公布论文链接）。这项工作以 X 光安检场景为例，首先从域间偏移产生原因入手，分析由机器硬件参数等原因造成的域间内生偏移和常见的天气等外部原因造成的域间内生偏移的异同点。此外，该工作还构建了内生偏移自适应能力评估基准，并提出了噪声抑制网络，为跨域检测带来新的思考。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在本文中，研究者们以 X 光安检场景为例，首先从域间偏移产生原因入手，结合常见的自然场景变化，分析外生和内生域间偏移的异同点。然后展示研究者们构建的内生偏移自适应能力评估基准，以及噪声抑制网络，探索目标检测模型在复杂环境下由于感知设备变化导致的脆弱性问题，寻找不同类别物体的领域无关特征的最佳表征。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">在表 1 中，研究者们从不同场景、领域数量和支持的实验组数分别把 EDS 数据集和跨域检测任务下各种类型的数据集进行了对比。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.32367149758454106\" data-type=\"png\" data-w=\"621\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe97rVqdibeDU6vicOwLpAibksVZaAF3nwHpKnfnCmRhWcMauGMiczkSpsfhw/640?wx_fmt=png\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">表 1 EDS 数据集和传统跨域检测数据集对比</span></em></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><br></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><strong><img class=\"rich_pages wxw-img\" data-ratio=\"0.4429065743944637\" data-type=\"png\" data-w=\"867\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9sibSu375m79RJhFwmzVJRyAjyso0V9EL0sQSsvAicbk62GOe4RjqIKeQ/640?wx_fmt=png\" style=\"max-width: 600px\"></strong></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">图 1 EDS 数据集中物品实物图和不同 X 光机器下的成像图</span></em></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">噪声抑制网络的框架图如图 4 所示，它包括两个重要的子模块，分别是局部原型对齐和全局对抗同化。局部原型对齐模块主要针对类别相关噪声，全局对抗同化主要针对类别无关噪声。以下分别展开叙述。</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.36944444444444446\" data-type=\"png\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png\" style=\"max-width: 600px\"></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"color: rgb(136, 136, 136);\"><em><span style=\"color: rgb(136, 136, 136);font-size: 12px;\">图 4 噪声抑制网络的结构图</span></em></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\">整个网络的训练流程如下：</span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><span style=\"font-size: 15px;\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.9358552631578947\" data-type=\"png\" data-w=\"608\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9P3bI3ZP6TaLQmVIUJMR9CIib4UjD1WrWvTs8qE5icicibmPMI1xLpHlmiaQ/640?wx_fmt=png\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;line-height: 1.75em;\"><br></section><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;\">推荐：</span></strong><span style=\"font-size: 15px;\">CVPR 2022，跨域检测新任务，北航、讯飞提出内生偏移自适应基准和噪声抑制网络。</span></section><p><br></p><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center border-box break-word><span style=\"outline: 0px;max-width: 100%;font-size: 15px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><strong style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif border-box break-word>ArXiv Weekly Radiostation</strong></span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center border-box break-word><br style=\"outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;\"></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word>机器之心联合由楚航、罗若天发起的ArXiv Weekly Radiostation，在 7 Papers 的基础上，精选本周更多重要论文，包括NLP、CV、ML领域各10篇精选，并提供音频形式的论文摘要简介，详情如下：</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word><br></span></section><section><mpvoice class=\"js_editor_audio audio_iframe js_uneditable custom_select_card\" src=\"/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;name=10%20NLP%20Papers&amp;play_length=21:22\" isaac2=\"1\" low_size=\"2420.59\" source_size=\"2457.6\" high_size=\"5011.64\" name=\"10 NLP Papers\" play_length=\"1282000\" voice_encode_fileid=\"MzA3MzI4MjgzM18yNjUwODQwMjQ3\" data-topic_id=\"\" data-topic_name=\"\" data-pluginname=\"insertaudio\" data-trans_state=\"1\" data-verify_state=\"3\"></mpvoice></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><br></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word>本周 10 篇 NLP 精选论文是：</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. Focus on the Target's Vocabulary: Masked Label Smoothing for Machine Translation.  (from Liang Chen)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. Faking Fake News for Real Fake News Detection: Propaganda-loaded Training Data Generation.  (from Kathleen McKeown)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition.  (from Tara N. Sainath)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. Input-Tuning: Adapting Unfamiliar Inputs to Frozen Pretrained Models.  (from Nanning Zheng)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. DUAL: Textless Spoken Question Answering with Speech Discrete Unit Adaptive Learning.  (from Abdelrahman Mohamed)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. Training language models to follow instructions with human feedback.  (from John Schulman)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">7. Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation.  (from Jian Liu)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">8. Look Backward and Forward: Self-Knowledge Distillation with Bidirectional Decoder for Neural Machine Translation.  (from Liang Wang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">9. SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models.  (from Liang Wang)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">10. Adaptive Discounting of Implicit Language Models in RNN-Transducers.  (from Sunita Sarawagi)</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word><br></span></section><section><mpvoice class=\"js_editor_audio audio_iframe js_uneditable custom_select_card\" src=\"/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;name=10%20CV%20Papers&amp;play_length=19:30\" isaac2=\"1\" low_size=\"2201.81\" source_size=\"2252.8\" high_size=\"4573.17\" name=\"10 CV Papers\" play_length=\"1170000\" voice_encode_fileid=\"MzA3MzI4MjgzM18yNjUwODQwMjQ4\" data-topic_id=\"\" data-topic_name=\"\" data-pluginname=\"insertaudio\" data-trans_state=\"1\" data-verify_state=\"3\"></mpvoice></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word><br></span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word>本周 10 篇 CV 精选论文是：</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers.  (from Bernhard Schölkopf)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. Towards Self-Supervised Category-Level Object Pose and Size Estimation.  (from Jian Sun)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. Membership Privacy Protection for Image Translation Models via Adversarial Knowledge Distillation.  (from Jian Pei)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. Building 3D Generative Models from Minimal Data.  (from Joshua Tenenbaum)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. Didn't see that coming: a survey on non-verbal social human behavior forecasting.  (from Isabelle Guyon)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. Fast Neural Architecture Search for Lightweight Dense Prediction Networks.  (from Jiri Matas, Janne Heikkila)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">7. Contrastive Boundary Learning for Point Cloud Segmentation.  (from Dacheng Tao)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">8. ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation.  (from Dacheng Tao)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">9. The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods.  (from Thomas G. Dietterich)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">10. SelfTune: Metrically Scaled Monocular Depth Estimation through Self-Supervised Learning.  (from Dinesh Manocha)</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word><br></span></section><section><mpvoice class=\"js_editor_audio audio_iframe js_uneditable custom_select_card\" src=\"/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;name=10%20ML%20Papers&amp;play_length=21:22\" isaac2=\"1\" low_size=\"2419.57\" source_size=\"2457.6\" high_size=\"5011.64\" name=\"10 ML Papers\" play_length=\"1282000\" voice_encode_fileid=\"MzA3MzI4MjgzM18yNjUwODQwMjQ5\" data-topic_id=\"\" data-topic_name=\"\" data-pluginname=\"insertaudio\" data-trans_state=\"1\" data-verify_state=\"3\"></mpvoice></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><br></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word>本周 10 篇 ML 精选论文是：</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left rgb border-box break-word><br></span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">1. Learn to Match with No Regret: Reinforcement Learning in Markov Matching Markets.  (from Michael I. Jordan)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">2. Score matching enables causal discovery of nonlinear additive noise models.  (from Bernhard Schölkopf)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">3. Interventions, Where and How? Experimental Design for Causal Models at Scale.  (from Bernhard Schölkopf)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">4. Zero-shot Domain Adaptation of Heterogeneous Graphs via Knowledge Transfer Networks.  (from Ruslan Salakhutdinov)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">5. DIME: Fine-grained Interpretations of Multimodal Models via Disentangled Local Explanations.  (from Ruslan Salakhutdinov, Louis-Philippe Morency)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">6. On the influence of over-parameterization in manifold based surrogates and deep neural operators.  (from George Em Karniadakis)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">7. A Neuro-vector-symbolic Architecture for Solving Raven's Progressive Matrices.  (from Luca Benini)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">8. New Insights on Reducing Abrupt Representation Change in Online Continual Learning.  (from Tinne Tuytelaars, Joelle Pineau)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">9. How to Train Unstable Looped Tensor Network.  (from Andrzej Cichocki)</span></section><section style=\"line-height: 1.75em;\"><span style=\"font-size: 15px;\">10. Matrix Completion via Non-Convex Relaxation and Adaptive Correlation Learning.  (from Xuelong Li)</span></section><section style=\"outline: 0px;max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb border-box break-word><span style=\"outline: 0px;max-width: 100%;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif left border-box break-word><br></span></section><p style=\"margin-top: 5px;outline: 0px;max-width: 100%;font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal rgb center border-box break-word><span style=\"outline: 0px;max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif border-box break-word>© THE END </span></p><p style=\"margin-top: 5px;outline: 0px;max-width: 100%;font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal rgb center border-box break-word><span style=\"outline: 0px;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;overflow-wrap: break-word !important;\">转载请联系本公众号获得授权</span></p><p style=\"margin-top: 5px;outline: 0px;max-width: 100%;font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal rgb center border-box break-word><span style=\"outline: 0px;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;overflow-wrap: break-word !important;\">投稿或寻求报道：content@jiqizhixin.com</span></p>\n                </div>\n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650840250&amp;idx=5&amp;sn=72ace7c4212468c8472316a4b9f88f8e&amp;chksm=84e558c4b392d1d24e14588bc49a6292986ed9701f51c6bbca3678115463c5654938a49f2d0a#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/5409/GJ7xjvfn4Z\"></div></div>","descriptionType":"html","publishedDate":"Sun, 13 Mar 2022 04:34:00 +0000","feedId":1837,"bgimg":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hRlLEGWibvzkmJA6SFYUMbJnibCUfEgU0F5xpWpyuyPuY3Gl6RJrA8tg/0?wx_fmt=jpeg?imageView2/1/w/600","linkMd5":"a6637d254064076b2870d87fddcf3137","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn78@2020_4/2022/03/14/11-12-32-642_8c3704309035c108.webp","destWidth":675,"destHeight":675,"sourceBytes":67157,"destBytes":60464,"author":"","articleImgCdnMap":{"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hRlLEGWibvzkmJA6SFYUMbJnibCUfEgU0F5xpWpyuyPuY3Gl6RJrA8tg/0?wx_fmt=jpeg?imageView2/1/w/600":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn78@2020_4/2022/03/14/11-12-32-642_8c3704309035c108.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9N0agrUzBNpwgMTiaChPTwVlPXUdDuNDicFA3LSJObC2p3Qib6pBttzoiaA/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn9@2020_6/2022/03/14/11-12-38-837_a15458339eab7b9e.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hE5KQrLRE1EwV9j3Jux0y613vKxUVXegOe965d5QOiaBrM1vjkXoYRA/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn95@2020_2/2022/03/14/11-13-47-888_85c60c5a47537ae5.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe98sqLEhCl1la13aNWvdicDpbwQrPAIywSZ3ZJ4SLrHcf1YtUiaqTKX12g/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn85@2020_6/2022/03/14/11-12-34-705_ddfcd6c0285a1fbd.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9uc365d2e0IVdribEf1tAe9YX5r0PzibQKJN1lsQrb23cPqKLP6z8TJklibia2kaPohiac0TvSqeKxicLw/640?wx_fmt=gif":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9uc365d2e0IVdribEf1tAe9xEp49eGDZx9AP15Pwr4FgcFgS5U0KDGIBMAHzN24X6am1WDOvqcUWw/640?wx_fmt=gif":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9zqzUMumtickt0nlMdj2z6kkK67CEGriaEHBXceWDcl8Jt8QVRibiccxlgg/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9uc365d2e0IVdribEf1tAe9xXc1SkhvPsHm8pPiaYJT4Peic7nsQXcFxgMSBPpmtVkC93naibZ1PAhXQ/640?wx_fmt=gif":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9T7f8ePcCZQyPp1A2DoyLApDaoDx5YClqoEoOOn0E5tH8aU7aboC5ibQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9dmfiaxcZIh40OJZQDOibqughCJhW2Icmy8TusUFliaiaqFcXrkZeyhr18w/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn42@2020_3/2022/03/14/11-12-36-129_dc1f74b92a882bc1.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9UaqIIIJ6DibUpjh8iaG2qZqQw0ia5kqwomGpyHVrrEJX2WCsxKaUslG9A/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn14@2020_6/2022/03/14/11-12-39-693_cdaf618c3146d04f.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9k6KzNdqZ2JZuVGyibdWF5QwiaIHggkqVCMwrqknMff8icNPTiatCACJia7Q/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn81@2020_4/2022/03/14/11-12-43-282_5754b83faa282772.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9iaEFSVtSxnFfb4jrk8icOPbyaIj5VnLuueqCDiczpI1ASiaIaSL3SQEBjQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe97rVqdibeDU6vicOwLpAibksVZaAF3nwHpKnfnCmRhWcMauGMiczkSpsfhw/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn18@2020_2/2022/03/14/11-12-34-892_c8af73955d9759e5.webp","http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9sibSu375m79RJhFwmzVJRyAjyso0V9EL0sQSsvAicbk62GOe4RjqIKeQ/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png":null,"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9P3bI3ZP6TaLQmVIUJMR9CIib4UjD1WrWvTs8qE5icicibmPMI1xLpHlmiaQ/640?wx_fmt=png":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn1@2020_4/2022/03/14/11-12-36-960_aa08aa31705963ac.webp","http://www.jintiankansha.me/rss_static/5409/GJ7xjvfn4Z":null},"publishedOrCreatedDate":1647256351556}],"record":{"createdTime":"2022-03-14 19:12:31","updatedTime":"2022-03-14 19:12:31","feedId":1837,"fetchDate":"Mon, 14 Mar 2022 11:12:31 +0000","fetchMs":323,"handleMs":52,"totalMs":250650,"newArticles":0,"totalArticles":5,"status":1,"type":0,"ip":"f306b40366a93aa712f78b685bea0f01","hostName":"us-019*","requestId":"a80a6b0bb98843da8f826bc06cb497aa_1837","contentType":"application/rss+xml","totalBytes":411476,"bgimgsTotal":1,"bgimgsGithubTotal":1,"articlesImgsTotal":18,"articlesImgsGithubTotal":9,"successGithubMap":{"myreaderx25":1,"myreaderx32":1,"myreaderx10":1,"myreaderx33":1,"myreaderx12":1,"myreaderx2":1,"myreaderx24":1,"myreaderx30":1,"myreaderx18":1},"failGithubMap":{}},"feed":{"createdTime":"2020-08-24 21:31:33","updatedTime":"2020-09-01 09:54:29","id":1837,"name":"机器之心","url":"http://feedmaker.kindle4rss.com/feeds/almosthuman2014.weixin.xml","subscriber":null,"website":null,"icon":"http://www.sogou.com/images/logo/new/favicon.ico?v=4","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx65/cdn87@2020_3/2020/09/01/01-54-30-263_d24121c9beed1de6.ico","description":"专业的人工智能媒体和产业服务平台","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2022-03-14 19:16:41","updatedTime":"2022-03-14 19:16:41","id":null,"feedId":1837,"linkMd5":"a6637d254064076b2870d87fddcf3137"}],"tmpCommonImgCdnBytes":60464,"tmpBodyImgCdnBytes":351012,"tmpBgImgCdnBytes":0,"extra4":{"start":1647256350793,"total":0,"statList":[{"spend":711,"msg":"获取xml内容"},{"spend":52,"msg":"解释文章"},{"spend":0,"msg":"上传封面图到cdn"},{"spend":1,"msg":"修正封面图上传失败重新上传"},{"spend":248447,"msg":"正文链接上传到cdn"}]},"extra5":18,"extra6":11,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5409/GJ7xjvfn4Z","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":423,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"us-030*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":974,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"europe-22*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.jintiankansha.me/rss_static/5409/GJ7xjvfn4Z","sourceStatusCode":405,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":926,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"us-035*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[405],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9N0agrUzBNpwgMTiaChPTwVlPXUdDuNDicFA3LSJObC2p3Qib6pBttzoiaA/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":1262,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"europe-60*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},null,null,null,null,null,null,null,null,{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":974,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"europe-22*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},null,null,null,null,null,null,null,{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":974,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"europe-22*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":974,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"europe-22*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe92A0TMFnfbpgdtITpJrAmfanqoI5RvP6HjuxVpicCp0NCvN1Jr0HkWjg/640?wx_fmt=png","sourceStatusCode":403,"sourceBytes":0,"destBytes":0,"feedId":1837,"totalSpendMs":974,"convertSpendMs":0,"createdTime":"2022-03-14 19:12:33","host":"europe-22*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","extra22GetBytesInfo":"2、Referer字段 ： http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","extra23historyStatusCode":[403,403],"sourceSize":"0","destSize":"0"}],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-013.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe-56.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe-24.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://europe68.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-021.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-005.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://europe-58.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://us-035.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://us-022.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-030.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[405]},"http://europe-60.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://us-009.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-52.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-024.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://us-026.herokuapp.com/":{"failCount":1,"successCount":2,"resultList":[200,200,null]},"http://us-038.herokuapp.com/":{"failCount":2,"successCount":1,"resultList":[200,null,null]},"http://us-001.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://us-017.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://us-036.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,null]},"http://europe62.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]},"http://europe64.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[null]},"http://europe-22.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[403]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hRlLEGWibvzkmJA6SFYUMbJnibCUfEgU0F5xpWpyuyPuY3Gl6RJrA8tg/0?wx_fmt=jpeg?imageView2/1/w/600","sourceStatusCode":200,"destWidth":675,"destHeight":675,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn78@2020_4/2022/03/14/11-12-32-642_8c3704309035c108.webp","sourceBytes":67157,"destBytes":60464,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":1422,"convertSpendMs":26,"createdTime":"2022-03-14 19:12:31","host":"us-017*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137,a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"65.6 KB","destSize":"59 KB","compressRate":"90%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe98sqLEhCl1la13aNWvdicDpbwQrPAIywSZ3ZJ4SLrHcf1YtUiaqTKX12g/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":540,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn85@2020_6/2022/03/14/11-12-34-705_ddfcd6c0285a1fbd.webp","sourceBytes":245863,"destBytes":31764,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":1961,"convertSpendMs":26,"createdTime":"2022-03-14 19:12:33","host":"europe68*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"240.1 KB","destSize":"31 KB","compressRate":"12.9%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe97rVqdibeDU6vicOwLpAibksVZaAF3nwHpKnfnCmRhWcMauGMiczkSpsfhw/640?wx_fmt=png","sourceStatusCode":200,"destWidth":621,"destHeight":201,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn18@2020_2/2022/03/14/11-12-34-892_c8af73955d9759e5.webp","sourceBytes":79432,"destBytes":20738,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":2134,"convertSpendMs":27,"createdTime":"2022-03-14 19:12:33","host":"us-026*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"77.6 KB","destSize":"20.3 KB","compressRate":"26.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9dmfiaxcZIh40OJZQDOibqughCJhW2Icmy8TusUFliaiaqFcXrkZeyhr18w/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":342,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn42@2020_3/2022/03/14/11-12-36-129_dc1f74b92a882bc1.webp","sourceBytes":162688,"destBytes":36998,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":3388,"convertSpendMs":40,"createdTime":"2022-03-14 19:12:33","host":"us-017*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"158.9 KB","destSize":"36.1 KB","compressRate":"22.7%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9P3bI3ZP6TaLQmVIUJMR9CIib4UjD1WrWvTs8qE5icicibmPMI1xLpHlmiaQ/640?wx_fmt=png","sourceStatusCode":200,"destWidth":608,"destHeight":569,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn1@2020_4/2022/03/14/11-12-36-960_aa08aa31705963ac.webp","sourceBytes":108614,"destBytes":56602,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":4293,"convertSpendMs":27,"createdTime":"2022-03-14 19:12:33","host":"us-009*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"106.1 KB","destSize":"55.3 KB","compressRate":"52.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9N0agrUzBNpwgMTiaChPTwVlPXUdDuNDicFA3LSJObC2p3Qib6pBttzoiaA/640?wx_fmt=png","sourceStatusCode":200,"destWidth":860,"destHeight":852,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn9@2020_6/2022/03/14/11-12-38-837_a15458339eab7b9e.webp","sourceBytes":107177,"destBytes":42318,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":4666,"convertSpendMs":54,"createdTime":"2022-03-14 19:12:34","host":"us-036*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"104.7 KB","destSize":"41.3 KB","compressRate":"39.5%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9UaqIIIJ6DibUpjh8iaG2qZqQw0ia5kqwomGpyHVrrEJX2WCsxKaUslG9A/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1080,"destHeight":619,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn14@2020_6/2022/03/14/11-12-39-693_cdaf618c3146d04f.webp","sourceBytes":427267,"destBytes":94320,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":7017,"convertSpendMs":301,"createdTime":"2022-03-14 19:12:33","host":"us-038*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"417.3 KB","destSize":"92.1 KB","compressRate":"22.1%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9k6KzNdqZ2JZuVGyibdWF5QwiaIHggkqVCMwrqknMff8icNPTiatCACJia7Q/640?wx_fmt=png","sourceStatusCode":200,"destWidth":612,"destHeight":261,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn81@2020_4/2022/03/14/11-12-43-282_5754b83faa282772.webp","sourceBytes":149689,"destBytes":27676,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":10650,"convertSpendMs":30,"createdTime":"2022-03-14 19:12:33","host":"us-005*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"146.2 KB","destSize":"27 KB","compressRate":"18.5%"},{"code":1,"isDone":false,"source":"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9uc365d2e0IVdribEf1tAe9hE5KQrLRE1EwV9j3Jux0y613vKxUVXegOe965d5QOiaBrM1vjkXoYRA/640?wx_fmt=png","sourceStatusCode":200,"destWidth":1036,"destHeight":598,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn95@2020_2/2022/03/14/11-13-47-888_85c60c5a47537ae5.webp","sourceBytes":151099,"destBytes":40596,"targetWebpQuality":75,"feedId":1837,"totalSpendMs":14981,"convertSpendMs":54,"createdTime":"2022-03-14 19:13:33","host":"us-026*","referer":"http://weixin.sogou.com/weixin?type=2&query=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83+7%20Papers%20%26%20Radios%20%7C%20DeepMind%E7%94%A8AI%E5%A4%8D%E5%8E%9F%E5%8F%A4%E5%B8%8C%E8%85%8A%E9%93%AD%E6%96%87%E7%99%BBNature%E5%B0%81%E9%9D%A2%EF%BC%9B%E5%8D%95GPU%E8%B0%83%E4%BC%98GPT-3%E8%B6%85%E5%8F%82%E6%95%B0","linkMd5ListStr":"a6637d254064076b2870d87fddcf3137","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"147.6 KB","destSize":"39.6 KB","compressRate":"26.9%"}],"successGithubMap":{"myreaderx25":1,"myreaderx32":1,"myreaderx10":1,"myreaderx33":1,"myreaderx12":1,"myreaderx2":1,"myreaderx24":1,"myreaderx30":1,"myreaderx18":1},"failGithubMap":{}}