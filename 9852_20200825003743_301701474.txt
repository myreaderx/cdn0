{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"创业与企业家精神","link":"http://www.parallellabs.com/?p=1558","description":"\n<p>最近读到的一段话，很有意思，摘录如下：</p>\n\n\n\n<blockquote class=\"wp-block-quote is-style-large\"><p>同时熊彼得也指出，企业家与只想赚钱的普通商人和投机者不同，个人致富充其量只是他的部分动机，而其最突出的动机是“个人实现”，即“企业家精神”。借用其他研究者的解读，就是“存在着一种梦想和意志，要去找到一个私人王国”、“存在有征服的意志：战斗的冲动”、“存在有创造的欢乐，把事情办成的欢乐，或者只是施展个人的能力和智谋的欢乐”。即熊彼得认为的“企业家精神”，它包括：<br /><br /><br /><strong>1、建立私人王国。</strong>企业家经常“存在有一种梦想和意志，要去找到一个私人王国，常常也是一个王朝。”对于没有其他机会获得社会名望的人来说，它的引诱力是特别强烈的。<br /><br /><br /><strong>2、对胜利的热情。</strong>企业家“存在有征服的意志；战斗的冲动，证明自己比别人优越的冲动，他求得成功不仅是为了成功的果实，而是为了成功本身。”利润和金钱是次要的考虑，而是“作为成功的指标和胜利的象征才受到重视”。<br /><br /><br /><strong>3、创造的喜悦。</strong>企业家“存在有创造的欢乐，把事情做成的欢乐，或者只是施展个人能力和智谋的欢乐。这类似于一个无所不在的动机……他们寻找困难，为改革而改革，以冒险为乐事。”企业家是典型的反享乐主义者。<br /><br /><br /><strong>4、坚强的意志。</strong>企业家“在自己熟悉的循环流转中是顺着潮流游泳，如果他想要改变这种循环流转的渠道，他就是逆潮流游泳。从前的助力现在变成了阻力，过去熟悉的数据，现在变成了未知数。”“需要有新的和另一种意志上的努力……去为设想和拟订出新的组合而搏斗，并设法使自己把它看作是一种真正的可能性，而不只是一场白日梦。”<br /><br /><br />正是这种“企业家精神”，企业家追求自我实现需要的满足，为了体现自己特殊的权力和地位、展示自己的才华、获得事业成功的欲望，使得各种创新能够不断出现和发展，促进社会的进步。</p><cite>《熊彼得创新理论与企业家精神培育》</cite></blockquote>\n","descriptionType":"html","publishedDate":"Wed, 22 Jul 2020 11:46:47 +0000","feedId":9852,"bgimg":"","linkMd5":"a6e2f1d9f51de693e5dae9f392d79590","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821746},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Shape the world to come","link":"http://www.parallellabs.com/?p=1516","description":"<p>2018年9月20日。</p>\n<p>很有意思的一天。</p>\n<p>一整天大部分时间，都在想怎么在业务上突破的事情，沉醉其中。</p>\n<p>今天最大的新闻，就是美团上市，一跃成为中国第四大互联网公司。</p>\n<p>看到朋友圈的信息流，突然很想在3000多好友的朋友圈中只保留那些最触动人心的，最Exciting的，最波澜壮阔的，最纵情向前又既往不恋的，最罗马史诗又惊心动魄的，最困难重重又有点意思的，最奋不顾身又热泪盈眶的，最触动心神又心潮澎湃的，最具挑战的，最有影响的，最大价值的，最感动的，最惊喜的，最赞叹的，最创新的，最聚人心的，最有耐心的，最有信心的，最能长跑的，最能坚持的，成长曲线最陡峭的，挑战最大又最激动人心的Feed。</p>\n<p>我突然发现，原来我与这个世界对话的最佳频率，其实就是心里与这个世界产生那一瞬共鸣的时刻。头条，快手，抖音，美团，滴滴，PingCAP，水滴，Testin，北森，小米，华米，Amazon，Google，极光，推啊，兑吧，LinkDest，Suanfati，Parallellabs，NemaLabs，都有那些“最”，都有那些共鸣的频率，那些有趣的灵魂。</p>\n<p>Think Different, Think Deep, Think Big, Stay Hungry, Stay Foolish.</p>\n<p>Let&#8217;s GO!</p>\n<p>&#160;</p>\n","descriptionType":"html","publishedDate":"Thu, 20 Sep 2018 13:11:03 +0000","feedId":9852,"bgimg":"","linkMd5":"63e272872329bf286275cffb88392c80","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"一步一步教你怎样给Apache Spark贡献代码","link":"http://www.parallellabs.com/?p=1439","description":"<h3><span style=\"color: #333333;\">本文将教大家怎样用10个步骤完成给Apache Spark贡献代码这个任务：）</span></h3>\n<ol class=\"task-list\" style=\"color: #333333;\">\n<li>到 Apache Spark 的github 页面内点击 fork 按钮</li>\n<li>你的github帐户中会出现 spark 这个项目</li>\n<li>本地电脑上， 使用</li>\n</ol>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git clone [你的 spark repository 的 github 地址]\n例如：\ngit clone git@github.com:gchen/spark.git</code></pre>\n<p style=\"color: #333333;\">本地得到一个叫 spark 的文件夹</p>\n<p style=\"color: #333333;\">4. 进入该文件夹，使用</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git remote add upstream https://github.com/apache/spark.git\n</code></pre>\n<p style=\"color: #333333;\">添加 Apache/spark 的远程地址</p>\n<p style=\"color: #333333;\">5. 使用</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git pull upstream master \n</code></pre>\n<p style=\"color: #333333;\">得到目前的 Apache/spark 的最新代码，现在我们在 你自己fork的Spark代码仓库的master 这个分支上，以后这个分支就留作跟踪 upstream 的远程代码</p>\n<p style=\"color: #333333;\">6. 好了，现在你可以开始贡献自己的代码了。</p>\n<p style=\"color: #333333;\">按照开发惯例，我们一般不在自己代码仓库的master上提交新的代码，而是需要为每一个新增的功能或者bugfix新增一个新的branch。使用：</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git checkout -b my_change\n</code></pre>\n<p style=\"color: #333333;\">创建新的分支，现在我们可以在这个分支上更改代码</p>\n<p style=\"color: #333333;\">7. 添加代码，并提交代码：</p>\n<p style=\"color: #333333;\">* git add .</p>\n<p style=\"color: #333333;\">* git commit -m &#8220;message need to be added here&#8221;</p>\n<p style=\"color: #333333;\">8. 提交Pull Request前合并冲突</p>\n<p style=\"color: #333333;\">在我们提交完我们的代码更新之后，一个常见的问题是远程的upstream（即apache/spark)已经有了新的更新，从而会导致我们提交Pull Request时会导致conflict。为此我们可以在提交自己这段代码前手动先把远程其他开发者的commit与我们的commit合并。使用：</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git checkout master\n</code></pre>\n<p style=\"color: #333333;\">切换到我们自己的主分支，使用</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git pull upstream master \n</code></pre>\n<p style=\"color: #333333;\">拉出apache spark的最新的代码。切换回 my_change 分支，使用</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git checkout my_change\ngit rebase master\n</code></pre>\n<p style=\"color: #333333;\">然后把自己在my_change分支中的代码更新到在自己github代码仓库的my_change分支中去：</p>\n<pre style=\"color: #333333;\"><code style=\"color: #555555;\">git push origin my_change \n</code></pre>\n<p style=\"color: #333333;\">将代码提交到自己的仓库。</p>\n<p style=\"color: #333333;\">9. 提交Pull Request</p>\n<p style=\"color: #333333;\">这时候可以在自己的仓库页面跳转到自己的my_change分支，然后点击 new pull request。按照Spark的风格规定，我们需要在新的Pull Request的标题最前面加上JIRA代号。所以我们需要在<a title=\"https://issues.apache.org/jira/\" href=\"https://issues.apache.org/jira/\" target=\"_blank\">https://issues.apache.org/jira/</a>上创建一个新的JIRA，例如<a title=\"https://issues.apache.org/jira/browse/SPARK-2859\" href=\"https://issues.apache.org/jira/browse/SPARK-2859\" target=\"_blank\">https://issues.apache.org/jira/browse/SPARK-2859</a>。然后把SPARK-2859这个代号加到你的Pull Request的标题里面。</p>\n<p style=\"color: #333333;\">例如：<a title=\"https://github.com/apache/spark/pull/1782\" href=\"https://github.com/apache/spark/pull/1782\" target=\"_blank\">https://github.com/apache/spark/pull/1782</a></p>\n<p style=\"color: #333333;\">Pull Rquest的描述的写法很重要。有几个要点：</p>\n<p style=\"color: #333333;\">（1）在Pull Request的描述中，一定记得加上你提交的JIRA的url，方便JIRA系统自动把Pull Request的链接加进去，例如https://issues.apache.org/jira/browse/SPARK-2859。</p>\n<p style=\"color: #333333;\">（2）PR的描述要言简意赅，讲清楚你要解决的问题是什么，你怎么解决的。大家可以多参考其他committer提交的PR。</p>\n<p style=\"color: #333333;\">10. 等待Spark committer审核你的PR。</p>\n<p style=\"color: #333333;\">如果需要进一步的代码修改，你可以继续在本地的my_change分支下commit新的代码，所有新的代码会在&#8221;git push origin my_change&#8221;之后自动被加入你之前提交的Pull Request中，方便进行问题的跟踪和讨论。</p>\n<p style=\"color: #333333;\">11.  如果一切顺利，具有apache/spark.git 写权限的commiter就会把你的代码merge到apache/spark.git的master里面去了！</p>\n<p style=\"color: #333333;\">恭喜你！相信你一定很开心吧？</p>\n<p style=\"color: #333333;\">Happy contributing to Spark!</p>\n<p style=\"color: #333333;\">ps. 你的代码被merge完之后，就可以把my_change这个分支给删掉了:)</p>\n<p style=\"color: #333333;\">注：本文写的比较仓促，是在@<strong style=\"color: #999999;\"><a class=\"author\" style=\"color: #555555;\" href=\"https://github.com/lufeihaidao\">lufeihaidao</a></strong>的基础上直接修改而成，特此感谢：<a title=\"https://github.com/19wu/19wu/issues/41\" href=\"https://github.com/19wu/19wu/issues/41\" target=\"_blank\">https://github.com/19wu/19wu/issues/41</a></p>\n<h2 style=\"color: #333333;\">参考：</h2>\n<p>How to use github pull request: <a title=\"https://help.github.com/articles/using-pull-requests\" href=\"https://help.github.com/articles/using-pull-requests\" target=\"_blank\">https://help.github.com/articles/using-pull-requests</a></p>\n<p>github的多人协作: <a title=\"https://gist.github.com/suziewong/4378619\" href=\"https://gist.github.com/suziewong/4378619\" target=\"_blank\">https://gist.github.com/suziewong/4378619</a></p>\n<p style=\"color: #333333;\">How to rebase a pull request：<a title=\"https://gist.github.com/suziewong/4378619\" href=\"https://gist.github.com/suziewong/4378619\" target=\"_blank\">https://github.com/edx/edx-platform/wiki/How-to-Rebase-a-Pull-Request</a></p>\n<p style=\"color: #333333;\">我提交的一个JIRA例子：<a title=\"https://issues.apache.org/jira/browse/SPARK-2859\" href=\"https://issues.apache.org/jira/browse/SPARK-2859\" target=\"_blank\">https://issues.apache.org/jira/browse/SPARK-2859</a></p>\n<p style=\"color: #333333;\">我提交的一个Spark PR的例子：<a title=\"https://github.com/apache/spark/pull/1782\" href=\"https://github.com/apache/spark/pull/1782\" target=\"_blank\">https://github.com/apache/spark/pull/1782</a></p>\n","descriptionType":"html","publishedDate":"Tue, 05 Aug 2014 08:48:05 +0000","feedId":9852,"bgimg":"","linkMd5":"09a334be9818d7879288091875f6c73b","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"做好失败的准备","link":"http://www.parallellabs.com/?p=1235","description":"<p>这周二晚上收到了<a href=\"http://sc12.supercomputing.org/\" target=\"_blank\">SC&#8217;12</a>大会的邮件通知,我的论文终于被接收了.在被SC&#8217;12录取之前,我这篇文章分别被IPDPS,ICS和SC据过,每一次被拒都得到了非常多有帮助的评审意见,帮助我更好的改进这篇文章.当然,被拒的滋味不好受.我认识的众多好友投顶级会议纷纷一投就中(例如<a href=\"http://www.madongfly.cn/\" target=\"_blank\">madong</a>的IJCAI, <a href=\"http://www.public.asu.edu/~jzhou29/\" target=\"_blank\">jiayu</a>的NIPS和SIGIR, <a href=\"http://www.tektalk.org/2011/03/17/asplos-11/\" target=\"_blank\">yang xi</a>的ASPLOS和OOSPLA),我被拒了那么多次咋还没中呢,心里的挫败感多多少少还是有一点.</p>\n<p>不过现在回头来看,最大的体会就是:要想做成一件公认的不太容易的事情,你必须做好失败的准备.<a href=\"http://www.ce.chalmers.se/~pers/\" target=\"_blank\">Per</a>在第一次投稿的时候跟我说,&#8221;没事,你投ICS吧,把目标设的高一点好&#8221;.现在想来,就是要给自己设定一个超出自己能力的目标,才能激发出自己的潜能:) 当然,既然你给自己设定了一个比较高的目标,你就一定要清楚的认识到,这件事情不是那么容易成功的.你必须把工作做到位,做扎实,过了那个门槛才行.而这个门槛的高度可能需要你付出非常多的努力.具体到SC&#8217;12的这篇论文上,因为是系统相关的题目,所以必须要把实验部分做的非常扎实才能让审稿人满意,像我这样的普通人,自然需要努力努力再努力才能成功.</p>\n<p>大家都在讲成功,都想要成功,殊不知成功之前大都要经历失败,尤其是在令人瞩目的成功之前，更是如此.比如说,你想成为一名优秀的程序员,可能需要<a href=\"http://norvig.com/21-days.html\" target=\"_blank\">10年的苦工</a>.比如说,你想要在ISCA发一篇有影响力的文章,可能需要做个三四年扎实的工作才行.比如说,你想创办一家成功的公司并上市,可能需要10年的时间并经历千辛万苦.当然,除了努力之外,还有另外一个非常重要的因素,那就是洞察力.如果能发现一个新的热点,自然就能站在浪潮之巅成为风云人物,不过那是另一个故事了,发现问题永远比解决问题要难嘛.</p>\n<p>把目标设的高一点,然后朝着那个目标的门槛努力,中间失败了也不要紧,因为每失败一次,离成功就近了一分.</p>\n","descriptionType":"html","publishedDate":"Sat, 14 Jul 2012 13:39:59 +0000","feedId":9852,"bgimg":"","linkMd5":"c98fae24161018ea16e4c6b63aff9f7e","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Pthreads并行编程之spin lock与mutex性能对比分析","link":"http://www.parallellabs.com/?p=233","description":"<p>POSIX threads(简称Pthreads)是在多核平台上进行并行编程的一套常用的API。线程同步(Thread Synchronization)是并行编程中非常重要的通讯手段，其中最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程之间共 享的临界区(Critical Section)进行保护(另一种常用的同步机制是barrier)。</p>\n<p>Pthreads提供了多种锁机制：<br />\n(1) Mutex（互斥量）：pthread_mutex_***<br />\n(2) Spin lock（自旋锁）：pthread_spin_***<br />\n(3) Condition Variable（条件变量）：pthread_con_***<br />\n(4) Read/Write lock（读写锁）：pthread_rwlock_***</p>\n<p>Pthreads提供的Mutex锁操作相关的API主要有：<br />\n<a href=\"https://computing.llnl.gov/tutorials/pthreads/man/pthread_mutex_lock.txt\">pthread_mutex_lock (pthread_mutex_t *mutex);</a><br />\n<a href=\"https://computing.llnl.gov/tutorials/pthreads/man/pthread_mutex_trylock.txt\"> pthread_mutex_trylock (pthread_mutex_t *mutex);</a><br />\n<a href=\"https://computing.llnl.gov/tutorials/pthreads/man/pthread_mutex_unlock.txt\"> pthread_mutex_unlock (pthread_mutex_t *mutex);</a></p>\n<p>Pthreads提供的与Spin Lock锁操作相关的API主要有：<br />\n<a href=\"https://computing.llnl.gov/tutorials/pthreads/man/pthread_spin_lock.txt\">pthread_spin_lock (pthread_spinlock_t *lock);</a><br />\n<a href=\"https://computing.llnl.gov/tutorials/pthreads/man/pthread_spin_trylock.txt\">pthread_spin_trylock (pthread_spinlock_t *lock);</a><br />\n<a href=\"https://computing.llnl.gov/tutorials/pthreads/man/pthread_spin_unlock.txt\">pthread_spin_unlock (pthread_spinlock_t *lock);</a></p>\n<p>从实现原理上来讲，Mutex属于sleep-waiting类型的锁。例如在一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core0和Core1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞(blocking)，Core0 会在此时进行上下文切换(Context Switch)将线程A置于等待队列中，此时Core0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待。而Spin lock则不然，它属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，那么线程A就会一直在 Core0上进行忙等待并不停的进行锁请求，直到得到这个锁为止。</p>\n<p>如果大家去查阅Linux glibc中对pthreads API的实现NPTL(<a id=\"d6h2\" title=\"Native POSIX Thread Library\" href=\"http://en.wikipedia.org/wiki/Native_POSIX_Thread_Library\">Native POSIX Thread Library</a>) 的源码的话(使用&#8221;getconf GNU_LIBPTHREAD_VERSION&#8221;命令可以得到我们系统中NPTL的版本号)，就会发现pthread_mutex_lock()操作如果没有锁成功的话就会调用system_wait()的系统调用（现在NPTL的实现采用了用户空间的<a href=\"http://en.wikipedia.org/wiki/Futex\">futex</a>，不需要频繁进行系统调用，性能已经大有改善），并将当前线程加入该mutex的等待队列里。而spin lock则可以理解为在一个while(1)循环中用内嵌的汇编代码实现的锁操作(印象中看过一篇论文介绍说在linux内核中spin lock操作只需要两条CPU指令，解锁操作只用一条指令就可以完成)。有兴趣的朋友可以参考另一个名为<a id=\"g7o.\" title=\"sanos\" href=\"http://www.jbox.dk/\">sanos</a>的微内核中pthreds API的实现：<a id=\"hpz5\" title=\"mutex.c\" href=\"http://www.jbox.dk/sanos/source/lib/pthread/mutex.c.html\">mutex.c</a> <a id=\"kpo_\" title=\"spinlock.c\" href=\"http://www.jbox.dk/sanos/source/lib/pthread/spinlock.c.html\">spinlock.c</a>，尽管与NPTL中的代码实现不尽相同，但是因为它的实现非常简单易懂，对我们理解spin lock和mutex的特性还是很有帮助的。</p>\n<p>那么在实际编程中mutex和spin lcok哪个的性能更好呢？我们知道spin lock在Linux内核中有非常广泛的利用，那么这是不是说明spin lock的性能更好呢？下面让我们来用实际的代码测试一下（请确保你的系统中已经安装了最近的g++）。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// Name: spinlockvsmutex1.cc\n// Source: http://www.alexonlinux.com/pthread-mutex-vs-pthread-spinlock\n// Compiler(spin lock version): g++ -o spin_version -DUSE_SPINLOCK spinlockvsmutex1.cc -lpthread\n// Compiler(mutex version): g++ -o mutex_version spinlockvsmutex1.cc -lpthread\n#include &#60;stdio.h&#62;\n#include &#60;unistd.h&#62;\n#include &#60;sys/syscall.h&#62;\n#include &#60;errno.h&#62;\n#include &#60;sys/time.h&#62;\n#include &#60;list&#62;\n#include &#60;pthread.h&#62;\n\n#define LOOPS 50000000\n\nusing namespace std;\n\nlist&#60;int&#62; the_list;\n\n#ifdef USE_SPINLOCK\npthread_spinlock_t spinlock;\n#else\npthread_mutex_t mutex;\n#endif\n\n//Get the thread id\npid_t gettid() { return syscall( __NR_gettid ); }\n\nvoid *consumer(void *ptr)\n{\n    int i;\n\n    printf(&#34;Consumer TID %lun&#34;, (unsigned long)gettid());\n\n    while (1)\n    {\n#ifdef USE_SPINLOCK\n        pthread_spin_lock(&#38;spinlock);\n#else\n        pthread_mutex_lock(&#38;mutex);\n#endif\n\n        if (the_list.empty())\n        {\n#ifdef USE_SPINLOCK\n            pthread_spin_unlock(&#38;spinlock);\n#else\n            pthread_mutex_unlock(&#38;mutex);\n#endif\n            break;\n        }\n\n        i = the_list.front();\n        the_list.pop_front();\n\n#ifdef USE_SPINLOCK\n        pthread_spin_unlock(&#38;spinlock);\n#else\n        pthread_mutex_unlock(&#38;mutex);\n#endif\n    }\n\n    return NULL;\n}\n\nint main()\n{\n    int i;\n    pthread_t thr1, thr2;\n    struct timeval tv1, tv2;\n\n#ifdef USE_SPINLOCK\n    pthread_spin_init(&#38;spinlock, 0);\n#else\n    pthread_mutex_init(&#38;mutex, NULL);\n#endif\n\n    // Creating the list content...\n    for (i = 0; i &#60; LOOPS; i++)\n        the_list.push_back(i);\n\n    // Measuring time before starting the threads...\n    gettimeofday(&#38;tv1, NULL);\n\n    pthread_create(&#38;thr1, NULL, consumer, NULL);\n    pthread_create(&#38;thr2, NULL, consumer, NULL);\n\n    pthread_join(thr1, NULL);\n    pthread_join(thr2, NULL);\n\n    // Measuring time after threads finished...\n    gettimeofday(&#38;tv2, NULL);\n\n    if (tv1.tv_usec &#62; tv2.tv_usec)\n    {\n        tv2.tv_sec--;\n        tv2.tv_usec += 1000000;\n    }\n\n    printf(&#34;Result - %ld.%ldn&#34;, tv2.tv_sec - tv1.tv_sec,\n        tv2.tv_usec - tv1.tv_usec);\n\n#ifdef USE_SPINLOCK\n    pthread_spin_destroy(&#38;spinlock);\n#else\n    pthread_mutex_destroy(&#38;mutex);\n#endif\n\n    return 0;\n}\n</pre>\n<p>该程序运行过程如下：主线程先初始化一个list结构，并根据LOOPS的值将对应数量的entry插入该list，之后创建两个新线程，它们都执行consumer()这个任务。两个被创建的新线程同时对这个list进行pop操作。主线程会计算从创建两个新线程到两个新线程结束之间所用的时间，输出为下文中的&#8221;Result &#8220;。</p>\n<p>测试机器参数：<br />\nUbuntu 9.04 X86_64<br />\nIntel(R) Core(TM)2 Duo CPU     E8400  @ 3.00GHz<br />\n4.0 GB Memory</p>\n<p>从下面是测试结果：</p>\n<pre class=\"brush: bash; title: ; notranslate\">\ngchen@gchen-desktop:~/Workspace/mutex$ g++ -o spin_version -DUSE_SPINLOCK spinvsmutex1.cc -lpthread\ngchen@gchen-desktop:~/Workspace/mutex$ g++ -o mutex_version spinvsmutex1.cc -lpthread\ngchen@gchen-desktop:~/Workspace/mutex$ time ./spin_version\nConsumer TID 5520\nConsumer TID 5521\nResult - 5.888750\n\nreal    0m10.918s\nuser    0m15.601s\nsys    0m0.804s\n\ngchen@gchen-desktop:~/Workspace/mutex$ time ./mutex_version\nConsumer TID 5691\nConsumer TID 5692\nResult - 9.116376\n\nreal    0m14.031s\nuser    0m12.245s\nsys    0m4.368s\n</pre>\n<p>可以看见spin lock的版本在该程序中表现出来的性能更好。另外值得注意的是sys时间，mutex版本花费了更多的系统调用时间，这就是因为mutex会在锁冲突时调用system wait造成的。</p>\n<p>但是，是不是说spin lock就一定更好了呢？让我们再来看一个锁冲突程度非常剧烈的实例程序：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n//Name: svm2.c\n//Source: http://www.solarisinternals.com/wiki/index.php/DTrace_Topics_Locks\n//Compile(spin lock version): gcc -o spin -DUSE_SPINLOCK svm2.c -lpthread\n//Compile(mutex version): gcc -o mutex svm2.c -lpthread\n#include &#60;stdio.h&#62;\n#include &#60;stdlib.h&#62;\n#include &#60;pthread.h&#62;\n#include &#60;sys/syscall.h&#62;\n\n#define        THREAD_NUM     2\n\npthread_t g_thread[THREAD_NUM];\n#ifdef USE_SPINLOCK\npthread_spinlock_t g_spin;\n#else\npthread_mutex_t g_mutex;\n#endif\n__uint64_t g_count;\n\npid_t gettid()\n{\n    return syscall(SYS_gettid);\n}\n\nvoid *run_amuck(void *arg)\n{\n       int i, j;\n\n       printf(&#34;Thread %lu started.n&#34;, (unsigned long)gettid());\n\n       for (i = 0; i &#60; 10000; i++) {\n#ifdef USE_SPINLOCK\n           pthread_spin_lock(&#38;g_spin);\n#else\n               pthread_mutex_lock(&#38;g_mutex);\n#endif\n               for (j = 0; j &#60; 100000; j++) {\n                       if (g_count++ == 123456789)\n                               printf(&#34;Thread %lu wins!n&#34;, (unsigned long)gettid());\n               }\n#ifdef USE_SPINLOCK\n           pthread_spin_unlock(&#38;g_spin);\n#else\n               pthread_mutex_unlock(&#38;g_mutex);\n#endif\n       }\n       \n       printf(&#34;Thread %lu finished!n&#34;, (unsigned long)gettid());\n\n       return (NULL);\n}\n\nint main(int argc, char *argv[])\n{\n       int i, threads = THREAD_NUM;\n\n       printf(&#34;Creating %d threads...n&#34;, threads);\n#ifdef USE_SPINLOCK\n       pthread_spin_init(&#38;g_spin, 0);\n#else\n       pthread_mutex_init(&#38;g_mutex, NULL);\n#endif\n       for (i = 0; i &#60; threads; i++)\n               pthread_create(&#38;g_thread[i], NULL, run_amuck, (void *) i);\n\n       for (i = 0; i &#60; threads; i++)\n               pthread_join(g_thread[i], NULL);\n\n       printf(&#34;Done.n&#34;);\n\n       return (0);\n}\n</pre>\n<p>这个程序的特征就是临界区非常大，这样两个线程的锁竞争会非常的剧烈。当然这个是一个极端情况，实际应用程序中临界区不会如此大，锁竞争也不会如此激烈。测试结果显示mutex版本性能更好：</p>\n<pre class=\"brush: bash; title: ; notranslate\">\ngchen@gchen-desktop:~/Workspace/mutex$ time ./spin\nCreating 2 threads...\nThread 31796 started.\nThread 31797 started.\nThread 31797 wins!\nThread 31797 finished!\nThread 31796 finished!\nDone.\n\nreal    0m5.748s\nuser    0m10.257s\nsys    0m0.004s\n\ngchen@gchen-desktop:~/Workspace/mutex$ time ./mutex\nCreating 2 threads...\nThread 31801 started.\nThread 31802 started.\nThread 31802 wins!\nThread 31802 finished!\nThread 31801 finished!\nDone.\n\nreal    0m4.823s\nuser    0m4.772s\nsys    0m0.032s\n</pre>\n<p>另外一个值得注意的细节是spin lock耗费了更多的user time。这就是因为两个线程分别运行在两个核上，大部分时间只有一个线程能拿到锁，所以另一个线程就一直在它运行的core上进行忙等待，CPU占用率一直是100%；而mutex则不同，当对锁的请求失败后上下文切换就会发生，这样就能空出一个核来进行别的运算任务了。（其实这种上下文切换对已经拿着锁的那个线程性能也是有影响的，因为当该线程释放该锁时它需要通知操作系统去唤醒那些被阻塞的线程，这也是额外的开销）</p>\n<p>总结<br />\n（1）Mutex适合对锁操作非常频繁的场景，并且具有更好的适应性。尽管相比spin lock它会花费更多的开销（主要是上下文切换），但是它能适合实际开发中复杂的应用场景，在保证一定性能的前提下提供更大的灵活度。</p>\n<p>（2）spin lock的lock/unlock性能更好(花费更少的cpu指令)，但是它只适应用于临界区运行时间很短的场景。而在实际软件开发中，除非程序员对自己的程序的锁操作行为非常的了解，否则使用spin lock不是一个好主意(通常一个多线程程序中对锁的操作有数以万次，如果失败的锁操作(contended lock requests)过多的话就会浪费很多的时间进行空等待)。</p>\n<p>（3）更保险的方法或许是先（保守的）使用 Mutex，然后如果对性能还有进一步的需求，可以尝试使用spin lock进行调优。毕竟我们的程序不像Linux kernel那样对性能需求那么高(Linux Kernel最常用的锁操作是spin lock和rw lock)。</p>\n<p>2010年3月3日补记：这个观点在<a href=\"http://www.oracle.com/technology/documentation/berkeley-db/db/programmer_reference/transapp_tune.html\">Oracle的文档</a>中得到了支持：</p>\n<blockquote><p>During configuration, Berkeley DB selects a mutex implementation for the architecture. Berkeley DB normally prefers blocking-mutex implementations over non-blocking ones. For example, Berkeley DB will select POSIX pthread mutex interfaces rather than assembly-code test-and-set spin mutexes because pthread mutexes are usually more efficient and less likely to waste CPU cycles spinning without getting any work accomplished. </p></blockquote>\n<p>p.s.调用syscall(SYS_gettid)和syscall( __NR_gettid )都可以得到当前线程的id:)</p>\n<p>转载请注明来自: www.parallellabs.com</p>\n","descriptionType":"html","publishedDate":"Sun, 31 Jan 2010 19:46:55 +0000","feedId":9852,"bgimg":"","linkMd5":"b6eef64732fa1eb9ef5d8c477d07bcbe","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"09年感悟","link":"http://www.parallellabs.com/?p=156","description":"<p>上半年顺风顺水，有付出也有收获，良好的状态持续到暑假实习结束。下半年压力陡增，主要包括就业压力和毕设压力。一个是因为国内就业竞争的激烈，另一个是因为十分具有挑战性的毕设课题。</p>\n<p><strong>压力。</strong>有压力是好事，在恰当的时候它能转换为我的动力，督促我的行为，间接促进我的进步。但是对待压力也要心态平和，不要过于焦虑、消沉，否则会陷入非常被动的局面。看过一句话，压力大就是因为自信心不足。自信心是建立在刻苦的努力之上的。所以最好的状态还是Take it easy，找准最需要下功夫的地方，多勤奋一点，多努力一点，付出的比别人多自然就有丰厚的回报，而且随着一点一滴的积累，自信心自然也就来了。</p>\n<p><strong>定位。</strong>首先是找到并持续的激发自己的兴趣点，从事自己真正发自内心喜欢并且觉得有意义的事情，这往往是成功的第一步。不要被所谓的“热潮”牵着鼻子走，分散了自己的注意力不说，这些不是自己最感兴趣的事情往往也不太适合自己。最好的学习和工作状态是每天早晨睁开眼就很兴奋很期待今天要做的事情，不管是它能给他人带来很积极的影响，或是能提升自己的专业技能，都能给自己带来满足感、成就感。最怕的就是对事情只有三分钟热情，当几天过去热情不在，或是碰到困难后就放弃，这样往往最后就是竹篮打水一场空。其次就是对症下药，先找自己最薄弱的环节并积极去弥补它。不要左一下右一下，结果等到面对问题的时候那些最需要的技能还没准备好那就完了。这里引出了另一个话题，专注。</p>\n<p><strong>专注。</strong>提高学习效率最有效的办法就是专注。首先从生活习惯上改善，每天划出几大块完整的学习时间段有助于保持专注。把学习的精力集中在能提升自己核心竞争力的技能上，而不是“花拳绣腿”，看上去新鲜实际上没啥用处。其次，注意任务切换（Context Switch）是要花费时间和精力的。这体现在学习的过程中，例如你学着学着突然想上下网，结果这一上就是十几二十分钟，等你再切回学习这个进程，你得先花十几分钟找回刚刚学习的感觉，才能继续开始，这样宝贵的三十分钟就没了。解决办法就是尽量减少Context Switch的次数。</p>\n<p><strong>计划。</strong>短期来看，给事情安排好优先级，给每天的工作都制定好计划；长期来看，给职业生涯做好规划。这样能有效的减少学习时的无所事事的（idle）时间（参考<a href=\"http://mindhacks.cn/2009/12/20/dark-time/\">暗时间</a>一文），有效的提升productivity。以前我不相信我可以同时做好两三件大事，但是2010年我想挑战一下自己，从每天的时间安排做起，争取高效率快节奏的同时把两到三件事情给同时做好，因为我<a href=\"http://www.ce.chalmers.se/~pers/\">导师</a>就是这么干的。我问过我导师你这么忙胆识还能把事情安排的井井有条（又是搞研究开会又是开公司）是不是因为你已经成功的把自己并行化了，他笑说他希望他有One million cores，这样他就能把所有的事情都处理的来。当然了，其实我发现一个重要原因是因为他有严格的时间管理方法，以小时为单位来详细安排自己每天的行程。</p>\n<p><strong>思考。</strong>如果每天只是忙忙碌碌但是不进行足够深入的思考并总结自己得到的经验教训，所能得到的进步就会不够多。每天起床吃饭学习然后睡觉，但是不思考，就会停滞在一个思维水平上，往往不能得到大突破。<a href=\"http://mindhacks.cn/\">刘未鹏</a>的博客有很多关于“思考”的好文，今年我的目标就是多思考，多总结，从而多进步。</p>\n<p><strong>宠辱不惊。</strong>心智的成熟体现在“不以物喜，不以己悲”，抗压能力，调整能力等等上。我现在这个阶段，开始从校园走向社会，各方面的压力会迎面而来。这个时候更需要自己有良好的心态，积极的调整自己，善于化解压力，善于自我激励，时刻把握住自己的目标，不迷失自己的方向。</p>\n<p><strong>眼光。</strong>眼光放长远些，明年的目标只是第一步，五年乃至十年的目标才是更值得关注的。当然，第一步的起点如果够高会很有帮助。</p>\n<h3>09年大事记：</h3>\n<p>09 Jan &#8211; 09 Mar</p>\n<p>TDA297 Distributed Systems II, EDA281 Parallel Computer Organization and Design</p>\n<p>09 Mar &#8211; 09 May</p>\n<p>TIN092 Algorithm, EDA203 Unix Internal, Internship Applications &#38; Interviews</p>\n<p>09 Jun &#8211; 09 Jul</p>\n<p>Summer Intern at Nema Labs</p>\n<p>09 Aug</p>\n<p>Summer vacation in China</p>\n<p>09 Sep &#8211; 09 Oct</p>\n<p>TDA381 Concurrent Programming (pending), DAT145 Advanced topic in NDS</p>\n<p>09 Oct &#8211; 09 Dec</p>\n<p>DAT105 Computer Architecture, Master Thesis</p>\n<h3>10年计划：</h3>\n<p>09 Jan &#8211; 09 Mar</p>\n<p>TDA231 &#8211; Algorithms for machine learning and inference</p>\n<p>09 Jan &#8211; 09 Sep</p>\n<p>Master Thesis</p>\n<p>09 Jun &#8211; 09 Aug</p>\n<p>Summer Internship</p>\n<p>09 Fall</p>\n<p>To be continued.</p>\n","descriptionType":"html","publishedDate":"Thu, 31 Dec 2009 02:01:56 +0000","feedId":9852,"bgimg":"","linkMd5":"1371192ede09005dea2ea524d6db996f","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"An interesting algorithm problem: the longest plateau","link":"http://www.parallellabs.com/?p=59","description":"<p>Recently I met an interesting algorithm problem:</p>\n<h4>Problem:</h4>\n<p>Given an array, try to develop an efficient algorithm which can compute the length of <em>the longest plateau</em>. A plateau is a consecutive segment of an array with equal contents. For example, if x[] = {1, 2, 3, 4, 4, 4, 5, 5, 6}, then we have six plateaus which are 1, 2, 3, 4-4-4, 5-5 and 6. And obviously the length of the longest plateaus is 3.</p>\n<h4>Analysis:</h4>\n<p>Well, a straightforward idea is try to firstly compute all the length of different plateaus from left to right and then select the longest length. The pseudo-code is like this:</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nfor each element in the array a[]\n     if a[i] is equal to a[i-1]\n          add 1 to the length for the current plateau\n          check whether the current length is the longest one so far\n     else\n          reset length to 1 // plateau length is at least 1\n</pre>\n<p>Whether we need line 5&#38;6 depends on whether we need to store the length of every plateau. If we just want to calculate the longest length then we can keep the code and use the &#8220;length&#8221; as a temp variable which is only used inside the loop. On the other hand, if we need to keep track of the length of all plateaus, we need to use an array of &#8220;length[]&#8221; to store the needed information.</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n/*\n * input: an array a[], the length of the array n\n * output: the length of the longest plateau\n */\nint longestPlateau (int a[], int n)\n{\n\tif (n == 0)\n \t\treturn 0;\n\n\tint length = 1;\n\tint longestLength = 1;\n\n\tfor (int i = 1; i&#60;n; i++)\n \t{\n\t\tif (a[i] == a[i-1])\n \t\t{\n \t\t\tlength++;\n\t\t\tlongestLength = max(longestLength, length);\n \t\t}\n \t\telse\n \t\t\tlength = 1;\n\t}\n\treturn longestLength;\n}\n</pre>\n<h4>Some more:</h4>\n<p>What if the given array is <em>sorted</em> (in the increasing order) already?</p>\n<p>Actually if the array is sorted, the algorithm can be much simpler:</p>\n<p>assume the longest length now is L, then we just need to compare a[i] and a[i-L], if they are equal then all the elements between them are also equal (since this is a sorted array!), and we can add 1 to the current longest length. The code looks like this:</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n/*\n * input: an sorted array a[] (increasing order), the length of the array n\n * output: the length of the longest plateau\n */\nint longestPlateau (int a[], int n)\n{\n\tif (n == 0)\n \t\treturn 0;\n\n\tint length = 1;\n\tfor (int i = 1; i&#60;n; i++)\n \t{\n\t\tif (a[i] == a[i-length])\n \t\t\tlength++;\n\t}\n\treturn length;\n}\n</pre>\n","descriptionType":"html","publishedDate":"Thu, 12 Nov 2009 22:30:15 +0000","feedId":9852,"bgimg":"","linkMd5":"387bffdaf73c252d06c4dd1201dcbbf0","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"2018新年目标","link":"http://www.parallellabs.com/?p=1512","description":"<p>2018年，3个目标：</p>\n<ul>\n<li>夯实基础，继续打造细分领域业界第一的产品和服务</li>\n<li>带家人去旅行</li>\n<li>减重20斤</li>\n</ul>\n<p>2018年，3个不变：</p>\n<ul>\n<li>保持持续学习的习惯：实践、读书、求教</li>\n<li>保持对世界的好奇心和饥渴感：拥抱新事物，新观点，新变化</li>\n<li>保持乐观的心态：痛苦，就是走上坡路的感受！</li>\n</ul>\n","descriptionType":"html","publishedDate":"Tue, 20 Feb 2018 03:53:59 +0000","feedId":9852,"bgimg":"","linkMd5":"68b6044bc02c3b7f4bfd81344f5ae4ab","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"实施并行编程的五大障碍","link":"http://www.parallellabs.com/?p=433","description":"<p>近期看见一篇来自Intel的很有意思的<a id=\"p6t8\" style=\"color: #551a8b;\" title=\"分析文章\" href=\"http://software.intel.com/en-us/blogs/2010/03/15/what-parallel-programmers-really-really-want/\">分析文章</a>，作者提到在他向45名与会的各公司程序员/开发经理/战略师提问“什么是实施并行编程的最大障碍”时，下面五个因素被提及的次数最多：遗留代码(legacy code)、教育(education)、工具(tools)、对众核趋势的恐惧(fear of many cores)以及可维护性(maintainability)。文章虽然是一篇Intel Parallel Studio的软文，但是其中提及的这五大障碍却非常值得讨论，下面是我对这五大障碍的一些粗浅看法，希望能起到一个抛砖引玉的作用，欢迎大家给出你们的看法。</p>\n<p><strong>1. 遗留代码</strong></p>\n<p>众所周知，怎样把公司的那些遗留代码给并行化是一件非常困难的事情。100K~1000K的代码量都非常正常，而并行编程本身又是非常容易出错的，一大堆诸如data race, dependency, non-deterministic, memory consistency, dead lock, serialization bottleneck, thread safe等的问题随便哪一个拉出来都让人头大，更别说要高效可靠的并行化这些庞大的遗留代码了。更困难的是很多遗留代码还有编写者已经离职，文档注释不全等问题，这无疑是雪上加霜。从成本上来讲，如果能通过一些优秀的编译器(例如Intel的ICC)自动并行化一些遗留代码无疑是最省钱的，但是这种方法最大的缺陷就在于像Intel ICC这种自动型编译器能自动并行化的代码非常少，从而导致它能提供的性能优化非常有限，而且就算是真正能获得speedup的代码也有很多约束条件(例如loop的循环之间没有dependence，并且该loop应该是一个程序热点)。所以目前的现状就是大量的遗留代码并不能有效的被并行化，从商业的角度上来讲，如果能有一种解决方案能在短时间内快速可靠的通过实施并行化让遗留代码在多核平台上获得10%~30%的性能提升，那么它就已经能为公司节省大量成本了。</p>\n<p><strong>2. 教育</strong></p>\n<p>第二大的障碍可能就是程序员缺乏并行编程方面的教育了。其实并行编程已经有二三十年的历史，不过在多核CPU出现之前那些并行编程都是“专家”们的玩具。那时候的并行编程大都是跑在集群、大型机或者服务器上，通过MPI(message passing interface)或者SMP(对称多处理器，即一个主板上有多个单核CPU，属于shared memory model)来完成并行计算。Pthread标准是1995年建立的，之后出来了Windows版的Win32 thread，后来又出来了“编译指导”、面向data parallel模型的OpenMP(OpenMP 3.0加入了task parallel支持)，task parallel的鼻祖Cilk，Intel的Intel Thread Building Block(task parallel)，Java 1.5开始对多线程提供较好的支持(加入了Java Memory Model)，近几年随着GPU的发展，Nvidia又开始搞CUDA(data-parallel)，Apple一看不对，并行编程以后是主流啊，我得插一手，于是自己撑旗弄了个针对CPU和GPU混合编程的OpenCL，微软一看也坐不住了也要随着Visual Studio2010开始搞C#的并行库，马上C++0x也要加入多线程支持，甚至连老古董Erlang也因为天生支持并行被重新热炒，总之随着摩尔定律在串行世界的失效，整个业界都开始<em>被迫</em>往并行编程方向发展。</p>\n<p>可是对程序员来说呢是什么情况呢？我们现在所接受的教育大都还是串行世界的那些算法和数据结构，高德纳在一篇<a id=\"y-:i\" style=\"color: #551a8b;\" title=\"访谈\" href=\"http://blog.csdn.net/programmer_editor/archive/2008/07/10/2631316.aspx\">访谈</a>里说“在我看来，这种现象或多或少是由于硬件设计者已经无计可施了导致的，他们将Moore定律失效的责任推脱给软件开发者，而他们给我们的机器只是在某些指标上运行得更快了而已。如果多线程的想法被证明是失败的，我一点都不会感到惊讶&#8230;&#8230;你听说过有多少程序员对这种未来一片光明的机器抱有强烈的兴趣？我几乎没有听说过，除了他们的诉苦。尽管我们学院那些搞硬件的家伙一直想让我相信我是错的”，可见硬件发展被迫向多核转移直接导致程序员们<a id=\"gnai\" style=\"color: #551a8b;\" title=\"免费的午餐已经结束\" href=\"http://www.gotw.ca/publications/concurrency-ddj.htm\">免费的午餐已经结束</a>了。那么程序员现在受到良好的并行编程教育了吗？很显然，现在随便问一个普通的程序员：“你觉得并行编程容易么？”，十有八九会说“我觉得很难”。前一阵有人讨论服务器编程用多线程好还是多进程好？其实根本原因就在于哪怕多线程有性能优势，可是isolation的多进程模式能在programming productivity和performance之间找到比较好的折衷，所以国内很有服务器开发者都选择了多进程(例如<a id=\"b.12\" style=\"color: #551a8b;\" title=\"云风\" href=\"http://blog.codingnow.com/2006/10/multi_process_design.html\">云风</a>)。从大趋势上来讲，不管是研究体系机构的，还是写OS/Compiler的，还是定义编程语言的，现在都在积极努力的为广大的程序员提供一个更容易使用的并行编程模型，Intel这几年不也在搞多核培训么，这都是好现象，但是，离真正的全民并行编程时代还有相当长的路要走。近几年的IT技术热门书单里面很少有并行编程的书籍就是个很好的写照。</p>\n<p><strong>3. 工具</strong></p>\n<p>工欲善其事，必先利其器。那么现阶段我们能用的，并且好用的并行编程工具有多少呢（欢迎大家补充）？</p>\n<p>(1) IDE: Intel Parallel Studio，微软马上出来的VS2010算一个，Sun的Sun Studio(不知道它的未来如何，但是它本来就很小众)，Nvidia的CUDA平台什么的就先不算了<br />\n(2) Compiler: Intel的ICC(能自动并行化一些代码)，<a id=\"byuh\" style=\"color: #551a8b;\" title=\"Nema Labs\" href=\"http://www.nemalabs.com/\">Nema Labs</a>的FASThread(一套可以快速可靠的指导程序员实施并行化的解决方案，特别适合将遗留代码并行化)<br />\n(3) Performance Tuning: Intel Vtune Analyzer(综合性能分析)，Thread profiler，<a id=\"r5i1\" style=\"color: #551a8b;\" title=\"Acumem\" href=\"http://www.acumem.com/\">Acumem</a>的Thread Spotter(针对多核Cache的性能分析和优化)<br />\n(4) Debugging: Petra的<a id=\"ox8:\" style=\"color: #551a8b;\" title=\"Jinx\" href=\"http://petravm.com/\">Jinx</a></p>\n<p>总体上我个人觉得它们对程序员来说确实有用，但是前提条件是你要会用。这其实又跟第二点“教育”有很大关系了。</p>\n<p><strong>4. 对众核的恐惧</strong></p>\n<p>现在我们看到4核已经非常普遍了，等过几年那可就是8核，16核，32核了。怎样确保你的代码在核数倍增的趋势下仍能有很好的性能，很好的可伸缩性？这真的是个问题。我现在所做的研究就是多线程程序中锁竞争的性能分析，目的就是为了帮助程序员更好的解决由锁竞争造成的性能瓶颈。实际上，为了得到很好的可伸缩性，程序员需要往往需要使用并行友好的数据结构(例如concurrent hash map)，使用细粒度的锁甚至无锁编程，设计data parallel的算法，性能调优(例如典型的false sharing问题)等等等等，这其中每一项都是不小的挑战。我曾经翻译过的一篇文章对设计多线程程序提供了一些<a id=\"t8n7\" style=\"color: #551a8b;\" title=\"有用的建议\" href=\"http://www.parallellabs.com/2010/02/18/8-simple-rules-for-designing-multithreaded-applications/\">有用的建议</a>。</p>\n<p><strong>5. 可维护性</strong></p>\n<p>毫无疑问，我们希望并行代码能够与现存的runtime系统、build系统以及其他现有代码一起正确的工作，我们更希望这些并行代码易于理解、便于维护并且有较长的生命周期。可是现阶段真正掌握并行编程的程序员少之又少，而且并行编程又是这么困难，哪怕你对这些并行代码只是做一些小小的改动都很有可能导致新的bug，新的性能瓶颈，那真的是一件非常痛苦的事情。</p>\n","descriptionType":"html","publishedDate":"Sun, 21 Mar 2010 16:28:57 +0000","feedId":9852,"bgimg":"","linkMd5":"beab00818c640349829164728e33f2c9","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Git快速学习指南","link":"http://www.parallellabs.com/?p=1357","description":"<h2>写在前面的话</h2>\n<p>学习是一个永无止境的过程，举个例子，学习“学习的方法”是一个不断迭代的过程：随着个人经历、周围环境的变化，我们的学习方法也需要作相应的改变。在学生时代，如果想要学习新知识，最常做的很可能是买一本这个领域的经典著作，然后啃下去。这种方法优点是学的扎实，对概念的来龙去脉能理解的比较深刻，缺点嘛也很明显，费时费力，需要很多一大段的、不被打扰的时间，学生时代最适合这种方法。</p>\n<p>工作之后，因为惯性使然，我还经常继续使用这种方法，结果因为很难抽出大块时间深入学习某项知识，所以收效甚微。这样一个痛点，作为爱折腾点新东西的人，当然是要想办法从“方法论”上做改进。痛定思痛，仔细思考后，我决定拿Git的学习过程做一个实验，来摸索一个适合（已上班的）程序员的学习方法的最佳实践。</p>\n<p>对Git这样的工具，最终目的一定是用到实际项目中去。所以大致原则是：不要太深入理论（知道Git是个分布式版本控制系统就OK），然后找一个能直接上手的教程，learn by doing。</p>\n<h2>具体步骤</h2>\n<p>1）先在Code shool上了一节<a title=\"try.github.io\" href=\"http://try.github.io\" target=\"_blank\">Try Git</a>，交互式的网页教程，直接边看文字教材边在网页terminal里面敲命令，基本学完之后堆Git最基本的几个命令比较熟了。<br />\n2）<a title=\"gitimmersion.googol.im\" href=\"http://gitimmersion.googol.im\" target=\"_blank\">gitimmersion.googol.im</a>的教程，目前正在学习中，内容比Try Git全面，作为进一步提高用，一步一步跟着做就行。<br />\n3）优才网的Git视频教程，目前还没开始练。</p>\n<p><em><strong>To be continued.</strong></em></p>\n","descriptionType":"html","publishedDate":"Mon, 22 Jul 2013 01:39:23 +0000","feedId":9852,"bgimg":"","linkMd5":"d1ad228d3904cbdf0a500480cd412e81","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Facebook的Realtime Hadoop及其应用","link":"http://www.parallellabs.com/?p=1076","description":"<p>在今年的SIGMOD‘11上，Facebook又发了一篇新paper（<a href=\"http://borthakur.com/ftp/RealtimeHadoopSigmod2011.pdf\">点此下载</a>），讲述了它们在提高Hadoop实时性上的工作及其应用。简单来讲，他们的项目需求主要有：</p>\n<p>1. Elasticity（伸缩性）<br />\n2. High write throughput（高写吞吐量）<br />\n3. Efficient and low-latency strong consistency semantics within a data center（单个data center内高性能、低延迟的强一致性）<br />\n4. Efficient random reads from disk（disk的高性能随机读）<br />\n5. High Availability and Disaster Recovery（高可靠性、灾后恢复能力）<br />\n6. Fault Isolation（错误隔离）<br />\n7. Atomic read-modify-write primitives（read-modify-write原子操作）<br />\n8. Range Scans（范围扫描）</p>\n<p>最终他们选择了Hadoop和HBase作为解决方案的基石，因为HBase已经满足了上述需求中的大部分。与此同时，他们还做了如下三点改进以满足实时性需求：<br />\n1. File Appends<br />\n2. Name Node的高可靠性优化 (<a href=\"http://hadoopblog.blogspot.com/2010/02/hadoop-namenode-high-availability.html\">AvatarNode</a>)<br />\n3. HBase的读性能的优化</p>\n<p>文章还列举了三个基于此方案的应用：Facebook Message，Facebook Insight，Facebook Metric Systems，大家可以着重看看这三个应用的特点及需求是怎样被这个方案满足的。</p>\n<p>在现在这个时代，只有大公司才有如此大的数据来做新东西，难怪Facebook，Google的paper被大量追捧了。</p>\n<p>参考资料：<br />\n[1] <a href=\"http://highscalability.com/blog/2011/3/22/facebooks-new-realtime-analytics-system-hbase-to-process-20.html\">Facebook&#8217;s New Realtime Analytics System: HBase To Process 20 Billion Events Per Day</a><br />\n[2] <a href=\"http://natishalom.typepad.com/nati_shaloms_blog/2011/07/real-time-analytics-for-big-data-an-alternative-approach-to-facebooks-new-realtime-analytics-system.html\">Real Time Analytics for Big Data: An Alternative Approach</a></p>\n<p>下面是这篇文章的slides：</p>\n<div style=\"width:425px\" id=\"__ss_8616309\"> <strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/parallellabs/sigmod-realtime-hadooppresentation\" title=\"Realtime Apache Hadoop at Facebook\" target=\"_blank\">Realtime Apache Hadoop at Facebook</a></strong> <iframe src=\"http://www.slideshare.net/slideshow/embed_code/8616309\" width=\"425\" height=\"355\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe> </p>\n<div style=\"padding:5px 0 12px\"> View more <a href=\"http://www.slideshare.net/\" target=\"_blank\">presentations</a> from <a href=\"http://www.slideshare.net/parallellabs\" target=\"_blank\">parallellabs</a> </div>\n</p></div>\n","descriptionType":"html","publishedDate":"Sun, 17 Jul 2011 07:38:27 +0000","feedId":9852,"bgimg":"","linkMd5":"3be9f1023c9f607fd5d8d05a8728472c","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"My Way","link":"http://www.parallellabs.com/?p=1397","description":"<p>这一年经历了很多低谷，很多困惑。思索了许多类似于“人从哪里来，要到哪里去”这类的问题。</p>\n<p>最近终于有一点点感悟：</p>\n<p>（1）世界是多元化的，接受这种多元化，有贫富，有善恶，有悲喜；</p>\n<p>（2）不要先去想自己想要什么，先想想自己能做什么，然后一步一步向你想要的方向走，哪怕慢点，每个人路线和速度都不可能一样；</p>\n<p>（3）哪有什么天才，都是靠努力一步步积累来的，十年，二十年，一辈子的专注，你做好准备了吗？《寿司之神》里做了一辈子寿司的次郎，米其林三星厨师，你感受到他的职人精神了吗？</p>\n<p>（4）找到自己的路。想起若干年前电影《燕尾蝶》中固力果唱的那首“My Way”，真是再次触动我心里最深处。希望自己鼓起勇气，坚定意志，不再想成为另一个“谁”，而是坚定的，做唯一的一个”自己“，不管前路多艰苦，不管经历多少失败，不管外界声音如何，不管是别人眼中的“捷径”亦或是“漫漫长征”，我都希望走自己选择的路，因为我希望回首往事时，我能无悔地说“I did it my way”.</p>\n<pre style=\"padding-left: 30px;\"><em>And now, the end is near;</em>\n<em>And so I face the final curtain.</em>\n<em>My friend, I'll say it clear,</em>\n<em>I'll state my case, of which I'm certain.</em>\n<em>I've lived a life that's full.</em>\n<em>I've traveled each and ev'ry highway;</em>\n<em>And more, much more than this,</em>\n<em>I did it my way.</em>\n<em>Regrets, I've had a few;</em>\n<em>But then again, too few to mention.</em>\n<em>I did what I had to do</em>\n<em>And saw it through without exemption.</em>\n<em>I planned each charted course;</em>\n<em>Each careful step along the byway,</em>\n<em>But more, much more than this,</em>\n<em>I did it my way.</em>\n<em>Yes, there were times, I'm sure you knew</em>\n<em>When I bit off more than I could chew.</em>\n<em>But through it all, when there was doubt,</em>\n<em>I ate it up and spit it out.</em>\n<em>I faced it all and I stood tall;</em>\n<em>And did it my way.</em>\n<em>I've loved, I've laughed and cried.</em>\n<em>I've had my fill; my share of losing.</em>\n<em>And now, as tears subside,</em>\n<em>I find it all so amusing.</em>\n<em>To think I did all that;</em>\n<em>And may I say - not in a shy way,</em>\n<em>\"Oh no, oh no not me,</em>\n<em>I did it my way\".</em>\n<em>For what is a man, what has he got?</em>\n<em>If not himself, then he has naught.</em>\n<em>To say the things he truly feels;</em>\n<em>And not the words of one who kneels.</em>\n<em>The record shows I took the blows -</em>\n<em>And did it my way!</em>\n<em> </em>\n<em>Yes, it was my way.</em></pre>\n","descriptionType":"html","publishedDate":"Sun, 22 Sep 2013 04:48:46 +0000","feedId":9852,"bgimg":"","linkMd5":"58623889184d922370a49fc1f09c7bf7","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Impala：新一代开源大数据分析引擎","link":"http://www.parallellabs.com/?p=1392","description":"<p>原文发表在《程序员》杂志2013年第8期，略有删改。</p>\n<p align=\"left\"><b>文</b><b> / </b><b>耿益锋</b><b> </b><b>陈冠诚</b><b></b></p>\n<p align=\"left\"><b> </b>大数据处理是云计算中非常重要的问题，自Google公司提出MapReduce分布式处理框架以来，以Hadoop为代表的开源软件受到越来越多公司的重视和青睐。以Hadoop为基础，之后的HBase，Hive，Pig等系统如雨后春笋般的加入了Hadoop的生态系统中。今天我们就来谈谈Hadoop系统中的一个新成员 &#8211; Impala。</p>\n<h3>Impala架构分析</h3>\n<p align=\"left\">Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能够查询存储在Hadoop的HDFS和HBase中的PB级大数据。已有的Hive系统虽然也提供了SQL语义，但是由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性；相比之下，Impala的最大特点也是最大卖点就是它的快速。那么Impala如何实现大数据的快速查询呢？在回答这个问题之前，我们需要先介绍Google的Dremel系统[1]，因为Impala最开始就是参照Dremel系统进行设计的。</p>\n<p align=\"left\"> Dremel是Google的交互式数据分析系统，它构建于Google的GFS（Google File System）等系统之上，支撑了Google的数据分析服务BigQuery等诸多服务。Dremel的技术亮点主要有两个：一个是实现了嵌套型数据的列存储；二是使用了多层查询树，使得任务可以在数千个节点上的并行执行和聚合结果。列存储在关系型数据库中并不陌生，它可以减少查询时处理的数据量，有效的提升查询效率。Dremel的列存储的不同之处在于它针对的并不是传统的关系数据，而是针对嵌套结构的数据。Dremel可以将一条条的嵌套结构的记录转换成列存储形式，查询时根据查询条件读取需要的列，然后进行条件过滤，输出时再将列组装成嵌套结构的记录输出，记录的正向和反向转换都通过高效的状态机实现。另一方面，Dremel的多层查询树则借鉴了分布式搜索引擎的设计，查询树的根节点负责接收查询，并将查询分发到下一层节点，底层节点负责具体的数据读取和查询执行，然后将结果返回上层节点。关于Dremel技术实现上的更多信息，读者可以参阅[9]。</p>\n<p align=\"left\"> Impala其实就是Hadoop的Dremel，Impala使用的列存储格式是Parquet。Parquet实现了Dremel中的列存储，未来还将支持Hive并添加字典编码，游程编码等功能。Impala的系统架构如图一所示。Impala使用了Hive 的SQL接口（包括SELECT，INSERT，Join等操作），但目前只实现了Hive的SQL语义的子集（例如尚未对UDF提供支持），表的元数据信息存储在Hive的Metastore中。StateStore是Impala的一个子服务，用来监控集群中各个节点的健康状况，提供节点注册，错误检测等功能。Impala在每个节点运行了一个后台服务impalad，impalad用来响应外部请求，并完成实际的查询处理。Impalad主要包含Query Planner，Query Coordinator和Query Exec Engine三个模块。QueryPalnner接收来自SQL APP和 ODBC的查询，然后将查询转换为许多子查询，Query Coordinator将这些子查询分发到各个节点上，由各个节点上的Query Exec Engine负责子查询的执行，最后返回子查询的结果，这些中间结果经过聚集之后最终返回给用户。</p>\n<p align=\"left\"> <a href=\"http://www.parallellabs.com/wp-content/uploads/2013/08/图1.png\"><img class=\"size-full wp-image-1393 aligncenter\" src=\"http://www.parallellabs.com/wp-content/uploads/2013/08/图1.png\" alt=\"图1\" width=\"500\" height=\"281\" srcset=\"http://www.parallellabs.com/wp-content/uploads/2013/08/图1.png 500w, http://www.parallellabs.com/wp-content/uploads/2013/08/图1-300x168.png 300w\" sizes=\"(max-width: 500px) 85vw, 500px\" /></a></p>\n<p align=\"center\">图1. Impala的系统架构图 [2]</p>\n<p align=\"left\">在Cloudera的测试中，Impala的查询效率相比Hive，有数量级的提升。从技术角度上来看，Impala之所以能有好的性能，主要有如下几方面的原因：</p>\n<p align=\"left\"> 1） Impala不需要把中间结果写入磁盘，省掉了大量的I/O开销。</p>\n<p align=\"left\">2） 省掉了MapReduce作业启动的开销。MapReduce启动task的速度是很慢的（默认每个心跳间隔是3秒钟），Impala直接通过相应的服务进程来进行作业调度，速度快了很多。</p>\n<p align=\"left\">3） Impala完全抛弃了MapReduce这个不太适合做SQL查询的范式，而是像Dremel一样借鉴了MPP并行数据库的思想，从新另起炉灶，因此可以做更多的查询优化，从而能省掉不必要的shuffle，sort等开销；</p>\n<p align=\"left\">4） 通过使用LLVM来统一编译运行时代码，避免了为支持通用编译而带来的不必要开销；</p>\n<p align=\"left\">5） 用C++实现，做了很多有针对性的硬件优化，例如使用SSE指令；</p>\n<p align=\"left\">6） 使用了支持Data locality的I/O调度机制，尽可能的将数据和计算分配在同一台机器上进行，减少了网络开销；</p>\n<p align=\"left\">虽然Impala是参照Dremel来实现，但是Impala也有一些自己的特色，例如Impala不仅仅支持Parquet格式，同时也可以直接处理文本，SequenceFile等Hadoop中常用的文件格式。另外一个更关键的地方在于，Impala是开源的，再加上Cloudera在Hadoop领域的领导地位，其生态圈有很大可能会在将来快速成长。可以预见在不久的未来，Impala很可能像之前的Hadoop和Hive一样在大数据处理领域大展拳脚。Cloudera自己也说期待未来Impala能完全取代Hive。当然，用户从Hive上迁移到Impala上来是需要时间的，而且Impala也只是刚刚发布1.0版，虽然号称已经可以稳定的在生产环境上运行，但相信仍然有很多可改进的空间[7]。需要说明的是，Impala并不是用来取代已有的MapReduce系统，而是作为MapReduce的一个强力补充，总的来说Impala适合用来处理输出数据适中或比较小的查询，而对于大数据量的批处理任务，MapReduce依然是更好的选择。另外一个花边消息是，Cloudera里负责Impala的架构师Marcel Komacker就曾在Google负责过F1系统的查询引擎开发，可见Google确实为大数据的流行出钱出力J</p>\n<h2>Impala与Shark，Drill等的比较</h2>\n<p align=\"left\">开源组织Apache也发起了名为Drill的项目来实现Hadoop上的Dremel，目前该项目正在开发当中，相关的文档和代码还不多，可以说暂时还未对Impala构成足够的威胁[10]。从Quora上的问答来看，Cloudera有7-8名工程师全职在Impala项目上，而相比之下Drill目前的动作稍显迟钝。具体来说，截止到2012年10月底，Drill的代码库里实现了query parser, plan parser，及能对JSON格式的数据进行扫描的plan evaluator；而Impala同期已经有了一个比较完毕的分布式query execution引擎，并对HDFS和HBase上的数据读入，错误检测，INSERT的数据修改，LLVM动态翻译等都提供了支持。当然，Drill作为Apache的项目，从一开始就避免了某个vendor的一家独大，而且对所有Hadoop流行的发行版都会做相应的支持，不像Impala只支持Cloudera自己的发行版CDH。从长远来看，谁会占据上风还真不一定[10]。</p>\n<p align=\"left\">除此之外，加州伯克利大学AMPLab也开发了名为Shark的大数据分析系统。在今天6月份的《程序员》上有一篇专门分析与Shark相关的Spark系统的文章，感兴趣的读者朋友可以参考。从长远目标来看，Shark想成为一个既支持大数据SQL查询，又能支持高级数据分析任务的一体化数据处理系统。从技术实现的角度上来看，Shark基于Scala语言的算子推导实现了良好的容错机制，因此对失败了的长任务和短任务都能从上一个“快照点”进行快速恢复。相比之下，Impala由于缺失足够强大的容错机制，其上运行的任务一旦失败就必须“从头来过”，这样的设计必然会在性能上有所缺失。而且Shark是把内存当作第一类的存储介质来做的系统设计，所以在处理速度上也会有一些优势[11]。实际上，AMPLab最近对Hive，Impala，Shark及Amazon采用的商业MPP数据库Redshift进行了一次对比试验，在Scan Query，Aggregation Query和Join Query三种类型的任务中对它们进行了比较。图2就是AMPLab报告中Aggregation Query的性能对比。在图中我们可以看到，商业版本的Redshift的性能是最好的， Impala和Shark则各有胜负，且两者都比Hive的性能高出了一大截。更多相关的实验结果读者朋友可以参考[12]。</p>\n<p align=\"left\"><a href=\"http://www.parallellabs.com/wp-content/uploads/2013/08/图2.png\"><img class=\"wp-image-1394 aligncenter\" src=\"http://www.parallellabs.com/wp-content/uploads/2013/08/图2.png\" alt=\"图2\" width=\"806\" height=\"328\" srcset=\"http://www.parallellabs.com/wp-content/uploads/2013/08/图2.png 1344w, http://www.parallellabs.com/wp-content/uploads/2013/08/图2-300x121.png 300w, http://www.parallellabs.com/wp-content/uploads/2013/08/图2-1024x416.png 1024w, http://www.parallellabs.com/wp-content/uploads/2013/08/图2-690x280.png 690w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px\" /></a></p>\n<p align=\"center\">图2. Redshift，Impala，Shark与Hive的Aggregation Query性能对比 [12]</p>\n<p align=\"left\">以笔者愚见，其实对大数据分析的项目来说，技术往往不是最关键的。例如Hadoop中的MapReduce和HDFS都是源于Google，原创性较少。事实上，开源项目的生态圈，社区，发展速度等，往往在很大程度上会影响Impala和Shark等开源大数据分析系统的发展。就像Cloudera一开始就决定会把Impala开源，以期望利用开源社区的力量来推广这个产品；Shark也是一开始就开源了出来，更不用说Apache的Drill更是如此。说到底还是谁的生态系统更强的问题。技术上一时的领先并不足以保证项目的最终成功。虽然最后那一款产品会成为事实上的标准还很难说，但是，我们唯一可以确定并坚信的一点是，大数据分析将随着新技术的不断推陈出新而不断普及开来，这对用户永远都是一件幸事。举个例子，如果读者注意过下一代Hadoop（YARN）的发展的话就会发现，其实YARN已经支持MapReduce之外的计算范式（例如Shark，Impala等），因此将来Hadoop将可能作为一个兼容并包的大平台存在，在其上提供各种各样的数据处理技术，有应对秒量级查询的，有应对大数据批处理的，各种功能应有尽有，满足用户各方面的需求。</p>\n<h2>未来展望</h2>\n<p>其实除了Impala，Shark，Drill这样的开源方案外，像Oracle，EMC等传统厂商也没在坐以待毙等着自己的市场被开源软件侵吞。像EMC就推出了HAWQ系统，并号称其性能比之Impala快上十几倍，而前面提到的Amazon的Redshift也提供了比Impala更好的性能。虽然说开源软件因为其强大的成本优势而拥有极其强大的力量，但是传统数据库厂商仍会尝试推出性能、稳定性、维护服务等指标上更加强大的产品与之进行差异化竞争，并同时参与开源社区、借力开源软件来丰富自己的产品线、提升自己的竞争力，并通过更多的高附加值服务来满足某些消费者需求。毕竟，这些厂商往往已在并行数据库等传统领域积累了大量的技术和经验，这些底蕴还是非常深厚的。甚至现在还有像NuoDB（一个创业公司）这样号称即支持ACID，又有Scalability的NewSQL系统出来。总的来看，未来的大数据分析技术将会变得越来越成熟、越来越便宜、越来越易用；相应的，用户将会更容易更方便地从自己的大数据中挖掘出有价值的商业信息。</p>\n<h2>参考资料</h2>\n<p align=\"left\">[1]<a href=\"http://research.google.com/pubs/pub36632.html\">http://research.google.com/pubs/pub36632.html</a></p>\n<p align=\"left\">[2]<a href=\"http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/\">http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/</a></p>\n<p>[3]<a href=\"http://www.slideshare.net/cloudera/data-science-on-hadoop\">http://www.slideshare.net/cloudera/data-science-on-hadoop</a></p>\n<p>[4] Impala重点问题列表：<a href=\"http://yuntai.1kapp.com/?p=1089\">http://yuntai.1kapp.com/?p=1089</a></p>\n<p>[5] Hive原理与不足：<a href=\"http://www.ccplat.com/?p=1035\">http://www.ccplat.com/?p=1035</a></p>\n<p>[6] Impala/Hive现状分析与前景展望：<a href=\"http://yanbohappy.sinaapp.com/?p=220\">http://yanbohappy.sinaapp.com/?p=220</a></p>\n<p>[7] What’s next for Cloudera Impala: <a href=\"http://blog.cloudera.com/blog/2012/12/whats-next-for-cloudera-impala/\">http://blog.cloudera.com/blog/2012/12/whats-next-for-cloudera-impala/</a></p>\n<p>[8] MapReduce：一个巨大的倒退：<a href=\"http://t.cn/zQLFnWs\">http://t.cn/zQLFnWs</a></p>\n<p>[9] Google Dremel 原理 &#8212; 如何能3秒分析1PB：<a href=\"http://www.yankay.com/google-dremel-rationale/\">http://www.yankay.com/google-dremel-rationale/</a></p>\n<p>[10] Isn&#8217;t Cloudera Impala doing the same job as Apache Drill incubator project? <a href=\"http://www.quora.com/Cloudera-Impala/Isnt-Cloudera-Impala-doing-the-same-job-as-Apache-Drill-incubator-project\">http://www.quora.com/Cloudera-Impala/Isnt-Cloudera-Impala-doing-the-same-job-as-Apache-Drill-incubator-project</a></p>\n<p>[11] Shark：<a href=\"https://github.com/amplab/shark/wiki\">https://github.com/amplab/shark/wiki</a></p>\n<p>[12] Big Data Benchmark: <a href=\"https://amplab.cs.berkeley.edu/benchmark/\">https://amplab.cs.berkeley.edu/benchmark/</a></p>\n<p>[13] Impala wiki：<a href=\"http://dirlt.com/impala.html\">http://dirlt.com/impala.html</a></p>\n<p>[14]How does Impala compare to Shark: <a href=\"http://www.quora.com/Apache-Hadoop/How-does-Impala-compare-to-Shark\">http://www.quora.com/Apache-Hadoop/How-does-Impala-compare-to-Shark</a></p>\n<p>[15] EMC讲解Hawq SQL性能：左手Hive右手Impala: <a href=\"http://stor-age.zdnet.com.cn/stor-age/2013/0308/2147607.shtml\">http://stor-age.zdnet.com.cn/stor-age/2013/0308/2147607.shtml</a></p>\n<h2></h2>\n<h2>作者简介</h2>\n<p>耿益锋，清华大学计算机系博士研究生，主要研究方向包括大数据处理和云计算中新应用和新场景下分布式系统的设计和优化。</p>\n<p>陈冠诚，IBM中国研究院研究员，主要技术方向为大规模分布式系统中的软硬件协同设计。个人博客为并行实验室（www.parallellabs.com），新浪微博<a href=\"http://weibo.com/parallellabs\" target=\"_blank\">@冠诚</a>。</p>\n","descriptionType":"html","publishedDate":"Sat, 24 Aug 2013 17:40:59 +0000","feedId":9852,"bgimg":"http://www.parallellabs.com/wp-content/uploads/2013/08/图1.png","linkMd5":"4dd2aedad5700145e91cfdeec190b152","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn11@2020_3/2020/08/25/00-37-02-323_840631c0545f3da5.webp","destWidth":500,"destHeight":281,"sourceBytes":84214,"destBytes":17586,"author":"Guancheng (G.C.)","articleImgCdnMap":{"http://www.parallellabs.com/wp-content/uploads/2013/08/图1.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn11@2020_3/2020/08/25/00-37-02-323_840631c0545f3da5.webp","http://www.parallellabs.com/wp-content/uploads/2013/08/图2.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn36@2020_5/2020/08/25/00-37-10-835_2541e2de67466b74.webp"},"publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Intel Nehalem微处理器架构 by Glenn Hinton (Intel Fellow)","link":"http://www.parallellabs.com/?p=1196","description":"<p>Intel的Nehalem是一个空前成功的设计。<strong>做架构最重要的本事就是学会做折衷（Tradeoff）。</strong> Nehalem的Lead Architect Glenn Hinton在Stanford ee380这门课上详细讲解了Nehalem设计时的几个关键选择，特此分享给大家。</p>\n<p>Intel’s Nehalem family of CPUs span from large multi-socket 32 core/64 thread systems to ultra small form factor laptops. What were some of the key tradeoffs in architecting and developing the Nehalem family of CPUs? What pipeline should it use? Should it optimize for servers? For desktops? For Laptops? There are lots of tradeoffs here. This talk will discuss some of the tradeoffs and results.</p>\n<div style=\"width:595px\" id=\"__ss_12723569\"> <strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/parallellabs/10intelnehalemdesignslides\" title=\"Intel&#39;s Nehalem Microarchitecture by Glenn Hinton\" target=\"_blank\">Intel&#39;s Nehalem Microarchitecture by Glenn Hinton</a></strong> <iframe src=\"http://www.slideshare.net/slideshow/embed_code/12723569\" width=\"595\" height=\"497\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe> </p>\n<div style=\"padding:5px 0 12px\"> View more <a href=\"http://www.slideshare.net/\" target=\"_blank\">presentations</a> from <a href=\"http://www.slideshare.net/parallellabs\" target=\"_blank\">parallellabs</a> </div>\n</p></div>\n<p>课程视频地址：<a href=\"http://ee380.stanford.edu/cgi-bin/videologger.php?target=100217-ee380-300.asx\" title=\"http://ee380.stanford.edu/cgi-bin/videologger.php?target=100217-ee380-300.asx\" target=\"_blank\">http://ee380.stanford.edu/cgi-bin/videologger.php?target=100217-ee380-300.asx</a></p>\n<p>Stanford ee380往年课程汇总：<a href=\"http://www.stanford.edu/class/ee380/\" title=\"http://www.stanford.edu/class/ee380/\" target=\"_blank\">http://www.stanford.edu/class/ee380/</a></p>\n","descriptionType":"html","publishedDate":"Sat, 28 Apr 2012 03:58:12 +0000","feedId":9852,"bgimg":"","linkMd5":"fff20a0ff167fc6452b0010aa358fd89","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多核与异步并行","link":"http://www.parallellabs.com/?p=1280","description":"<p align=\"left\"><span style=\"color: #0000ff;\"><em>原文发表于《程序员》杂志2012年第9期，文字略有修改。</em></span></p>\n<p align=\"left\">我们在设计多线程程序时往往有很多性能指标，例如低延迟（latency），高吞吐量（throughput），高响应度（responsiveness）等。随着多核处理器上CPU核数的日益增加，如何高效地利用这些计算资源以满足这些设计目标变得越来越重要。这次向大家介绍的异步并行就是一种帮助实现低延迟、高吞吐量和高响应度的并行编程技术。</p>\n<p align=\"left\">让我们先来看这样一个例子。在下面的程序中，我们有一个do_something()的API，这个函数实现了将一个文件写入磁盘的功能，所以改函数比较耗时。在调用这个函数时，最简单的用法是对该函数进行同步调用，即下面程序中caller1()所采用的方式。这种写法带来的问题是，caller1需要阻塞等待do_something()的完成，期间CPU不能做任何其他的计算，从而导致CPU资源的空闲。与此相反，程序中的caller2就采用了异步调用do_something()的方式。这样，caller2在将异步调用do_something的命令发送给worker线程之后，就可以立刻返回并开始执行other_work()，不仅能将other_work()提前完成，更提高了CPU利用率。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nint do_something(doc)\n{\n    return write_document(doc); // 耗时的I/O写操作\n}\n\nvoid caller1(doc) {\n   result = do_something(doc); //同步调用do_something()\n   other_work(); //这个操作需要等待do_something()的完成\n   more_other_work();\n}\nvoid caller2() {\n   worker.send(do_something_msg());//异步调用do_something()\n   other_work(); //这个操作不需要等待do_something()的完成，因此提高了CPU的利用率\n   more_other_work();\n}\n</pre>\n<p align=\"left\">在现代计算机体系结构中，I/O设备的速度远远比不上CPU，我们在做计算时一个基本的设计原则就是在CPU等待I/O请求的同时，用足够多的计算任务将CPU跑满，从而掩盖掉I/O请求造成的延迟。在单核时代，我们使用Multiplexing的方式将I/O任务与计算任务重叠在一起进而提高程序性能，即一个进程如果进入I/O等待，操作系统会将该进程放入等待队列，并调度执行另一个进程的计算任务；多核时代来临之后，CPU上的计算资源变得越来越多，通过使用异步并行技术充分利用CPU的计算资源，提升应用程序的延迟性、吞吐量、响应度也变得越来越普遍。下面让我们通过几个典型应用来对异步并行做更多的介绍。</p>\n<h2 align=\"left\">GUI线程的异步并行设计</h2>\n<p align=\"left\">GUI线程是采用异步并行设计来提高响应度的一个经典例子。一个GUI程序的典型结构是使用一个循环来处理诸如用户点击了某个按钮、系统产生了一个中断等事件。许多GUI系统还提供了诸如优先级队列等数据结构以保证优先级高的事件能得到及时的相应。下例是一个典型的GUI系统伪代码：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nwhile( message = queue.receive() ) {\n  if( it is a &#34;保存文件&#34; request ) {\n    save_document(); // 这是一个会产生阻塞的同步调用\n  }\n  else if( it's a &#34;打印文档&#34; request ) {\n    print_document(); // 这是一个会产生阻塞的同步调用\n  }\nelse\n  ...\n}\n</pre>\n<p align=\"left\">这个程序有一个非常常见的性能bug：它对save_document()和print_document()这两个非常耗时的操作采用了同步调用的方式，这与GUI线程应该具备及时响应的设计初衷产生了直接矛盾。GUI线程的设计目标不仅仅是对相应的事件作出正确的响应，更重要的是这些响应必须非常及时。按照上面这个程序的逻辑，很可能会出现如下情况：用户在点击“保存文件”按钮之后，程序需要花费几秒钟才能完成save_document()调用，因此该程序在这几秒钟时间内都不能再对其他任何事件作出响应；而这时如果用户还想要调整窗口大小，这个操作在几秒钟之内都得不到响应，从而破坏用户体验。</p>\n<p align=\"left\">一般来说，需要拥有高响应度的线程不应该直接执行可能带来延迟或阻塞的操作。可能带来延迟或阻塞的操作不仅仅包括保存文件、打印文件，还包括请求互斥锁、等待其他线程某个操作的完成等。</p>\n<p align=\"left\">我们有三种方式来将耗时的操作从需要保持高响应度的线程中转移出去。下面让我们继续用GUI系统的例子来对这三种方法一一进行介绍，以分析它们各自适用的场景。</p>\n<p align=\"left\"><b>方式一：一个专用的工作线程</b></p>\n<p align=\"left\">第一种将耗时操作从GUI线程中转移出去的方式是，使用一个专门的工作线程来异步地处理GUI线程发送的耗时操作请求。如下图所示，GUI线程依次将打印文档（PrintDocument）和保存文档（SaveDocument）两个异步请求发送给工作线程之后就立刻返回，从而继续对用户的其他请求做出及时的相应（例如调整窗口大小、编辑文档等）；与此同时，工作线程依次对打印文档和保持文档进行顺序处理，并在并在该异步请求完成到某一进度时（或者该异步请求完成时）向GUI线程发送相应的通知信号。</p>\n<p><figure style=\"width: 442px\" class=\"wp-caption aligncenter\"><img title=\"图1. 使用专门的工作线程来处理GUI线程的异步请求\" alt=\"图1. 使用专门的工作线程来处理GUI线程的异步请求\" src=\"http://farm9.staticflickr.com/8356/8401870744_7201e14920.jpg\" width=\"442\" height=\"410\" /><figcaption class=\"wp-caption-text\">图1. 使用专门的工作线程来处理GUI线程的异步请求</figcaption></figure></p>\n<p align=\"left\">让我们来看看这种处理方式的代码会长成什么样子：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 第一种方式：使用一个专门的工作线程来处理GUI线程的异步请求\n// GUI线程：\nwhile( message = queue.receive() ) {\n   if( it's a &#34;保存文档&#34; request ) {\n      worker.send( new save_msg() ); // 发送异步请求\n   }\n   else if( it's a &#34;保存文档&#34; completion notification ) {\n     display(“保存文档成功！”); // 接到异步请求的进度通知\n   }\n   else if( it's a &#34;打印文档&#34; request ) {\n      worker.send( new print_msg() ); //发送异步请求\n   }\n   else if( it's a &#34;打印文档&#34; progress notification ) {\n      if( percent &#60; 100 ) // 接到异步请求的进度通知\n         display_print_progress( percent );\n      else\n         display(“打印完毕！”);\n   }\n   else\n   ...\n}\n\n// 工作线程：处理来自GUI线程的异步请求\nwhile( message = workqueue.receive() ) {\n   if( it's a &#34;保存文档&#34; request )\n      save_document(); // 保存文档并在结束后向GUI线程发送通知\n   else if( it's a &#34;打印文档 &#34; request )\n      print_document(); // 打印文档并向GUI线程发送进度通知\n   else\n   ...\n}\n</pre>\n<p align=\"left\"><b>方式二：每一个异步请求分配一个工作线程</b></p>\n<p align=\"left\">在第一种方法的基础之上，我们可以做一些相应的扩展：对每一个GUi线程的异步请求都分配一个专门的工作线程，而不是只用一个工作线程去处理所有异步请求。这个方式的好处很明显，异步请求被多个线程分别并行处理，因此提升了处理速度。值得注意的是，我们需要及时对这些工作线程进行垃圾回收操作，否则大量线程会造成内存资源的紧张。</p>\n<p><figure style=\"width: 442px\" class=\"wp-caption aligncenter\"><img alt=\"图2. 为每个GUI线程的异步请求分配一个工作线程\" src=\"http://farm9.staticflickr.com/8047/8401870784_9c2717ca33.jpg\" width=\"442\" height=\"275\" /><figcaption class=\"wp-caption-text\">图2. 为每个GUI线程的异步请求分配一个工作线程</figcaption></figure></p>\n<p align=\"left\">\n<p align=\"left\">这种模式的代码如下所示。因为对每个异步请求我们都启动一个新的线程，我们可以充分地利用多核的计算资源，更快地完成相应的任务。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 方式二：每一个异步请求分配一个线程\nwhile( message = queue.receive() ) {\n   if( it's a &#34;保存文档&#34; request ) {\n      ...  new Thread( [] { save_dcument(); } ); // 启动新线程对异步请求进行处理\n   }\n   else if( it's a &#34;打印文档&#34; request ) {\n      … new Thread( [] { print_document(); } );/ // 启动新线程对异步请求进行处理\n   }\n   else if( it's a &#34;保存文档&#34; notification ) { ... }\n                                      // 同方式一\n   else if( it's a &#34;打印文档&#34; progress notification ) { ... }\n                                      // 同方式一\n   else\n      ...\n}\n</pre>\n<p align=\"left\"><b>方式三：使用线程池来处理异步请求</b></p>\n<p align=\"left\">第三种方式更进了一步：我们可以根据多核硬件资源的多少来启动一个专门的线程池，用线程池来完成GUI线程的异步请求。这种方式的好处在于，我们可以在充分利用多核的硬件资源，以及并行地对异步请求进行高效处理间取得一个很好的平衡。该方式的工作示意图如下所示：</p>\n<p><figure style=\"width: 374px\" class=\"wp-caption aligncenter\"><img alt=\"图3. 使用线程池来处理GUI线程的异步请求\" src=\"http://farm9.staticflickr.com/8365/8400781281_b526307057.jpg\" width=\"374\" height=\"313\" /><figcaption class=\"wp-caption-text\">图3. 使用线程池来处理GUI线程的异步请求</figcaption></figure></p>\n<p align=\"left\">让我们来看一下这种方式的伪代码。需要注意的是，线程池的具体实现每个语言各有不同，因此下面的代码只供大家参考之用。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 方式三：使用线程池来处理异步请求\nwhile( message = queue.receive() ) {\nif( it's a &#34;保存文档&#34; request ) {\npool.run( [] { save_document(); } ); // 线程池的异步调用\n}\nelse if( it's a &#34;打印文档&#34; request ) {\npool.run( [] { print_document(); } ); //线程池的异步调用\n}\nelse if( it's a &#34;保存文档&#34; notification ) { ... }\n// 同前\nelse if( it's a &#34;打印文档&#34; progress notification ) {  ... }\n// 同前\nelse\n...\n}\n</pre>\n<h2 align=\"left\">Grand Central Dispatch的异步并行</h2>\n<p align=\"left\">Grand Central Dispatch（GCD）是苹果于Mac OS X 10.6和iOS4中发布的一项并行编程技术。对使用GCD的程序员来说，只需要将需要被处理的任务块丢到一个全局的任务队列中去就可以了，这个任务队列中的任务会由操作系统自动地分配和调度多个线程来进行并行处理。将需要被处理的任务块插入到任务队列中去有两种方式：同步插入和异步插入。</p>\n<p align=\"left\">让我们来看看一个使用GCD异步并行的实例。在下面的程序中，analyzeDocument函数需要完成的功能是对这个文档的字数和段落数进行相关统计。在分析一个很小的文档时，这个函数可能非常快就能执行完毕，因此在主线程中同步调用这个函数也不会有很大的性能问题。但是，如果这个文件非常的大，这个函数可能变得非常耗时，而如果仍然在主线程中同步调用该方法，就可能带来很大的性能延迟，从而影响用户体验。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 不使用GCD的版本\n- (IBAction)analyzeDocument:(NSButton *)sender {\n    NSDictionary *stats = [myDoc analyze];\n    [myModel setDict:stats];\n    [myStatsView setNeedsDisplay:YES];\n    [stats release];\n}\n</pre>\n<p align=\"left\">使用GCD的异步并行机制来优化这个函数非常简单。如下所示，我们只需要在原来的代码基础上，先通过dispatch_get_global_queue来获取全局队列的引用，然后再将任务块通过dispatch_async方法插入该队列即可。任务块的执行会交由操作系统去处理，并在该任务块完成时通知主线程。一般来讲，异步插入的方式拥有更高的性能，因为在插入任务之后dispatch_async可以直接返回，不需要进行额外等待。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n//使用GCD异步并行的版本\n- (IBAction)analyzeDocument:(NSButton *)sender\n{\ndispatch_queue_t queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0ul);\ndispatch_async(queue, ^{\n         NSDictionary *stats = [myDoc analyze];\n         [myModel setDict:stats];\n         [myStatsView setNeedsDisplay:YES];\n         [stats release];\n     });\n}\n</pre>\n<h2>总结</h2>\n<p align=\"left\">本文对多核编程时常用的异步并行技术做了相关介绍。通过使用异步并行技术，我们可以将比较耗时的操作交给其他线程去处理，主线程因此可以去处理其他有意义的计算任务（例如相应用户的其他请求，完成其他计算任务等），从而有效提高系统的延迟性、吞吐率和响应性。</p>\n","descriptionType":"html","publishedDate":"Mon, 21 Jan 2013 10:20:47 +0000","feedId":9852,"bgimg":"http://farm9.staticflickr.com/8356/8401870744_7201e14920.jpg","linkMd5":"e2a00eb700b0d750629e26805b914fbc","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn7@2020_3/2020/08/25/00-37-01-881_5583f544257d9a52.webp","destWidth":442,"destHeight":410,"sourceBytes":36213,"destBytes":17392,"author":"Guancheng (G.C.)","articleImgCdnMap":{"http://farm9.staticflickr.com/8356/8401870744_7201e14920.jpg":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn7@2020_3/2020/08/25/00-37-01-881_5583f544257d9a52.webp","http://farm9.staticflickr.com/8047/8401870784_9c2717ca33.jpg":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn26@2020_2/2020/08/25/00-37-10-777_ac938c55f07789b9.webp","http://farm9.staticflickr.com/8365/8400781281_b526307057.jpg":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn30@2020_2/2020/08/25/00-37-10-436_7421c1c4ebeafe82.webp"},"publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多核的未来","link":"http://www.parallellabs.com/?p=635","description":"<p>UT Austin的<a href=\"https://hostdb.ece.utexas.edu/~patt/\">Yale Patt</a>教授上个月来Chalmers交流，做了题为《Future Microprocessors: Multi-core, Mega-nonsense, and What We Must Do Differently Moving Forward》的讲座。Yale Patt是计算机体系结构学术圈的巨擘，他最有名的研究成果是和Branch Predictor和HPS microarchitecture，他的学生们也巨牛无比，学术界有名的有UIUC的Wen-Mei Hwu，CMU的Onur Mutlu等等，工业界Intel不少核心工程师也出自他的门下。这个讲座主要谈了他对未来的多核处理器的发展的看法，有趣的是他二十年前也预测过现在的处理器，我还专门问了他当时的预测是否靠谱，他说“那我得回去查查看才行”,人非常的Nice。</p>\n<p>简单介绍一下关键的几点：</p>\n<p>1. 为什么要多核？<br />\nIt is easier than designing a much better uni-core<br />\nIt is cheaper than designing a much better uni-core<br />\nIt was embarrassing to continue making L2 bigger<br />\nIt was the next obvious step</p>\n<p>2. Asymmetric Chip Multiprocessor才是未来<br />\n一个chip上既有Large Core，又有Small Core，前者专门用来加速那些诸如Critical Section之类的串行代码。</p>\n<p>3. ILP未死<br />\n其实还有ILP的性能很多可挖掘的空间，只是多核设计上更经济更简单，所以大家都慢慢转到多核上来了</p>\n<p>4. Parallel Programming is NOT Hard<br />\n如果从新生就开始进行并行编程的教育，从一开始就thinking in parallel，并行编程就不难，关键是打破Abstraction。</p>\n<p>UIUC的<a href=\"http://www.parallel.illinois.edu/dls_archive.html\">Distinguished Lecture Series</a>也有他今年4月在UIUC的讲座，甚至还有video。</p>\n<p>Enjoy!</p>\n<div style=\"width:425px\" id=\"__ss_5342231\"><strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/parallellabs/chalmers-microprocessor-sept-2010\" title=\"Chalmers microprocessor sept 2010\">Chalmers microprocessor sept 2010</a></strong><object id=\"__sse5342231\" width=\"425\" height=\"355\"><param name=\"movie\" value=\"http://static.slidesharecdn.com/swf/ssplayer2.swf?doc=chalmersmicroprocessorsept2010-101002163458-phpapp01&#038;stripped_title=chalmers-microprocessor-sept-2010&#038;userName=parallellabs\" /><param name=\"allowFullScreen\" value=\"true\"/><param name=\"allowScriptAccess\" value=\"always\"/><embed name=\"__sse5342231\" src=\"http://static.slidesharecdn.com/swf/ssplayer2.swf?doc=chalmersmicroprocessorsept2010-101002163458-phpapp01&#038;stripped_title=chalmers-microprocessor-sept-2010&#038;userName=parallellabs\" type=\"application/x-shockwave-flash\" allowscriptaccess=\"always\" allowfullscreen=\"true\" width=\"425\" height=\"355\"></embed></object></p>\n<div style=\"padding:5px 0 12px\">View more <a href=\"http://www.slideshare.net/\">presentations</a> from <a href=\"http://www.slideshare.net/parallellabs\">parallellabs</a>.</div>\n</div>\n","descriptionType":"html","publishedDate":"Sat, 02 Oct 2010 16:13:43 +0000","feedId":9852,"bgimg":"","linkMd5":"908b29cb864d1a5ac3ffb70f24662b5b","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"聊一聊瑞典的程序员","link":"http://www.parallellabs.com/?p=558","description":"<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.8em; margin-left: 0px; padding: 0px;\">在瑞典这个发达国家，IT企业的基本工资都相差不大。认识的一位Ericsson的员工（入职刚一年）工资是税前29K SEK/M（~30%的税率），资格老一点的员工能有40K~50K SEK/M。不过工资高的人交的税也会相应的增加（40%~50%），所以有一个流行的说法就是大学教授和码头工人的税后工资差不多。小公司的薪资也很不错，而且还有不同程度的股份。</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.8em; margin-left: 0px; padding: 0px;\">瑞典的大学都是免学费的（明年开始向外国学生收费），由政府承担教育经费。瑞典的教育、医疗大都是免费的，它们需要的大量资金都由政府的税收收入来支持，取之于民用之于民。大学生的生活费大都是向政府申请的贷款（生活费大约7K SEK/M，父母大都不支持他们的生活费），所以很多我身边的瑞典朋友早早就开始在企业兼职来补贴生活费，这样在他们研究生毕业的时候很多人都已经有了几年的兼职经验。</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.8em; margin-left: 0px; padding: 0px;\">像瑞典这样的欧美发达国家，很多计算机专业的大学生很早就开始学习编程了，而且还非常普遍。他们在高中的时候就会开设编程相关的课程，更早一点的十二、三岁就开始学习编程了。我的一个瑞典朋友在高中的最后一年用汇编写了一个40K行的操作系统！另一个我认识的前辈在高中毕业之后就去了瑞典的一家游戏公司做开发，工作了七八年之后又回学校读本科，但是没读完又加入了另一家创业公司。</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.8em; margin-left: 0px; padding: 0px;\">瑞典的实习工资也很不错。Volvo的实习生能给到25K SEK/M，而其他公司的实习生大都能给到17K~20K SEK/M。另一种实习的方式是去做毕业设计。Ericsson的Master Thesis为期6个月，Offer的基本工资是35K，奖金根据最后的表现最多给15K，所以税前最多能拿50K，扣掉30%的税后能拿到30K左右。</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.8em; margin-left: 0px; padding: 0px;\">高工资，高税收，高福利，大家收入都差不多，所以人们都很“安居乐业”。总而言之，我相信瑞典人真的不富（贫富差距不大），但是也没啥压力。这样的环境很容易出两种人，一种是真正爱搞研究搞创新的人，他们能弄出一些Great Idea开创一片天地；另一种就是在公司养老的人，能完成工作，但也就仅限于此。</p>\n","descriptionType":"html","publishedDate":"Tue, 04 May 2010 08:00:40 +0000","feedId":9852,"bgimg":"","linkMd5":"4a434b9e57d92d824cbcac7d4ed5fce9","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Facebook技术分享: Social Networking at Scale","link":"http://www.parallellabs.com/?p=1228","description":"<p>在HPCA&#8217;12大会上,来自Facebook的Sanjeev Kumar做了题为“Social Networking at Scale”的技术演讲，主要对Facebook在可扩展的软/硬件架构上的挑战做了分析，特地分享给大家。</p>\n<div style=\"width:595px\" id=\"__ss_13130437\"> <strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/parallellabs/hpca2012-facebook-keynote\" title=\"Hpca2012 facebook keynote\" target=\"_blank\">Hpca2012 facebook keynote</a></strong> <iframe src=\"http://www.slideshare.net/slideshow/embed_code/13130437\" width=\"595\" height=\"497\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" allowfullscreen></iframe> </p>\n<div style=\"padding:5px 0 12px\"> View more <a href=\"http://www.slideshare.net/\" target=\"_blank\">presentations</a> from <a href=\"http://www.slideshare.net/parallellabs\" target=\"_blank\">parallellabs</a> </div>\n</p></div>\n","descriptionType":"html","publishedDate":"Wed, 30 May 2012 08:49:19 +0000","feedId":9852,"bgimg":"","linkMd5":"8a89eb23688d81e5cb800816137c14dd","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"仰望星空 脚踏实地","link":"http://www.parallellabs.com/?p=1301","description":"<p>最近连续跟IBM的一位VP和一位Fellow有过交流，对“仰望星空，脚踏实地”有了一些新的体会，特在此分享。</p>\n<h2>仰望星空</h2>\n<p>讲的是你做事情的vision，或者是说你的动机。作为一名研究员来讲，最兴奋最幸福的事情莫过于对社会产生巨大的影响。IBM Fellow Chieko Asakawa（浅川智惠子）是无障碍设计领域的杰出研究人员，她领导了IBM于1997年专为盲人设计的语音浏览器<a href=\"http://en.wikipedia.org/wiki/File:Home_Page_Reader_Splash.png\" target=\"_blank\">Homepage Reader</a>等一系列产品，而浅川院士本身就是一位盲人。在1997年互联网还没有很普及的时候，根据自己的需求研发了这样一款产品，不得不佩服她敏锐的技术触觉。但是最关键的是她长期以来对技术的vision。她的目标很简单：利用计算技术帮助盲人（及其他残障人士）更好地接触数字信息和社会环境，她说这是她的dream。跟那位VP的聊天中谈到技术项目的评估第一步往往要看它的vision是什么。其实不管是研究还是开发，第一步往往是要讲清楚你要做的这件事情的vision是什么，通过你要做的事情你改变了什么？你解决了什么问题？这件事情能不能使听众一听就觉得很买账？可以说vision好不好直接决定两件事情：<span style=\"text-decoration: underline;\"><strong>你自己是不是很兴奋的要去做这件事情</strong></span>，<span style=\"text-decoration: underline;\"><strong>以及你能从你的听众那里得到多少支持（可以是你的老板，你的投资人）</strong></span>。IBM CRL领导过两个IBM Research全球的研究项目：<a href=\"http://dl.acm.org/citation.cfm?id=1850700\" target=\"_blank\">Wireless Network Cloud</a>（无线网络云）和Internet of Things（物联网），一个是用软件来实现传统硬件基站的功能，一个是将物理世界和数字世界连接起来。Facebook，Google，Apple，Cloud Computing，Software Defined Network，Mobile，Big Data，Social，Virtualization这些名词背后你都能找到一个很鼓舞人的vision。想vision的时候一个重要原则就是<span style=\"text-decoration: underline;\"><strong>make a difference</strong></span>。这件事情为什么只有在IBM能干成？为什么别人干不了？你有啥资源和优势是别人不可能达到的？你的技术背景是否足够强大？关系人脉如何？<strong>你干的这事情是“锦上添花”还是“雪中送炭”？锦上添花的事情意义就很小了，没啥做的必要。雪中送炭就是一个从无到有的过程，干成了得到的满足感肯定是无以伦比的，而且影响力也会很大。</strong>一句俗话就是：“心有多大，舞台就有多大”。郭去疾受World is flat的启发去做兰亭集市就是一个例子。Coursera正在改变教育的普及度，改变就放生在你身边。要敢于Think Big。除此之外，另一个原则就是<span style=\"text-decoration: underline;\"><strong>understanding how the world works</strong></span>。这个话题可以讲的很深，但关键一点就是说你如果想预测未来什么是重要的，你可以从历史中学习那些重要的事情到底是怎么变得那么重要的？</p>\n<h2>脚踏实地</h2>\n<p>讲的是执行。要做好一件事情，一定要<span style=\"text-decoration: underline;\"><strong>坚持</strong></span>。你必须一步一步，从小事做起，积跬步以至千里，而走完这个千里可能需要十年甚至三十年时间。在中国，很普遍的一件事情是你的目标很容易动摇，很容易被社会的现实因素所动摇，例如房子，例如钱。不得不说取得巨大成功的人还是很有些理想主义的dreamer，例如马云，例如扎克伯格。浅川在IBM工作了28年评上IBM Fellow，我导师Per Stenstrom 20年才评上ACM/IEEE Fellow，高德纳写Tex断断续续用了10年，VMware在成长为今天这个规模之前蛰伏了好几年，DARPA资助的众多研究项目周期长达十年，成为了一个领域的专家需要10000个小时的训练，等等。小步快跑，快速修正，不断迭代，错了就改，失败了就再来，反复锤炼。顶级会议的论文要花大量工作，反复修改才会被录取（CRL最近中的一篇ISCA是六个人近一年的工作）；顶级研究项目会遇到众多困难 和挑战。让人惊叹的成就大都是一路风雨走过来的。深入深入在深入，多想想你做这件事情怎样才能make a difference？你要做的很平庸，那你不就是个随便都可以被替代的人了么，干嘛非得让你来做？你创造了什么别人创造不了的价值？多想想这些问题，耐得住寂寞，好好干。国人在执行层面一般都很强大，但是vision比外国人确实弱不少。</p>\n<p>最后分享下我的一点心得：</p>\n<blockquote><p>想到一个问题： 不应该在意结果，而应该注重过程，因为正是在过程中你才得到了快乐，得到了体验。与过程相比，结果是好是坏其实远不那么重要。太关注结果，很容易失去活着的意义，因为等你历经艰辛得到那个结果的时候，你却什么都没得到。结果导向很容易让自己生活的不快乐，也不能让身边的人快乐。结果只是一些点，得到了也就过去了，而过程才是真正需要我们仔细享受的，因为它才是用我们的生命中最宝贵的时间换来的。想起一个终极问题：人活着为了什么？现在我的答案是：“为了尽情的体会生命的美好”</p></blockquote>\n","descriptionType":"html","publishedDate":"Thu, 21 Mar 2013 15:01:31 +0000","feedId":9852,"bgimg":"","linkMd5":"5e7da3cf825e012bbd3f3fa2f140e2bf","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"八条设计多线程程序的简单规则","link":"http://www.parallellabs.com/?p=343","description":"<p>更新：<br />\n[2010.3.6] Scalability翻译从”可扩展性“改成”可伸缩性“.</p>\n<p>前言：最近在看该作者的《The Art of Concurrency》，里面第四章就是上面这篇文章，觉得很实用而且很有共鸣。作者基于在并行编程领域的20多年工作经验总结成下面八条简单的原则，一下子帮我把之前并行编程时的一些认识给理清了，量化了，实在是“居家旅行，并行编程，必备良药”。花了几天时间把它翻译了一下，不知道各位在看了之后是否有些共鸣呢？</p>\n<p><strong><br />\n作者：Clay Breshears<br />\n译者：并行实验室 Parallel Labs</strong></p>\n<p>在Intel，并行化技术主要有四个步骤：分析，设计与实现，调试以及性能调优。这些步骤用来对一段串行代码进行并行化。尽管这四个步骤中的第一、三、四步都已经有了很多相关文档，但是关于怎样进行设计与实现的却不多。</p>\n<p>并行编程更像是一门艺术，而不是一门科学。这里将会给出八条设计多线程程序的简单规则，你可以把他们一一放进你的多线程程序设计百宝箱中。通过参考这些规则，你能写出高质量、高效率的多线程程序。我努力试着将这些规则按照(半)时间顺序组织起来，但是它们之间并没有硬性的先后顺序。就像“别在泳池边奔跑”和“别在浅水区跳水”一样，两个都是好主意，但是后者也能放在前者的前面，反之亦然。</p>\n<p><strong>规则一：找到真正不相关的计算任务</strong><br />\n如果你将要执行的运算任务相互之间不独立的话，你是不可能将它们并行化的。我可以很容易的举出一些真实世界中相互独立的任务如何为了达成同一个目的而工作的例子。比如说一个DVD出租店，它先把收到的求租电影的订单分给员工们，员工再从存放电影DVD的地方根据订单找到影片拷贝。当一个员工取出一张古典音乐喜剧的拷贝时，他并不影响另一个寻找最近科幻电影大作的员工，也不影响另一个寻找某热门犯罪连续剧第二季花絮的员工（我假设所有不能被满足的订单在递交给DVD出租店之前就已经被处理过了）。同样的，每个订单的打包和邮递工作也不会影响其他订单的查找、运送和处理工作。</p>\n<p>你也可能会遇到某些不能被并行化的而只能串行执行的计算任务，它们大多数是因为循环之间或者计算步骤之间有依赖关系从而导致它们只能按照特定的顺序串行执行。一个很好的例子是驯鹿怀孕的过程。通常驯鹿需要八个月来生小驯鹿，你不可能为了早点生个小驯鹿就让八个驯鹿来一起来生，想一个月就生出一个来。但是，如果圣诞老人希望尽快的扩充雪橇队伍，他可以让八只驯鹿一起生，这样八个月后就能有八只小驯鹿了（注：可以理解为尽管单个任务的执行时间没缩短，但是吞吐量却大了）。</p>\n<p><strong>规则二：尽可能地在最高层进行并行化</strong><br />\n在对一段串行代码进行并行化时我们有两种方法可以选择，一个是自底向上，另一个是自顶向下。在对我们的代码进行分析的过程中，我们先找到花费了最多执行时间的程序热点(hotspots)。对这些代码段进行并行化是使我们获得最大的性能提升的最好办法。</p>\n<p>在自底向上的方法中，你可以考虑先直接对那些程序热点进行并行化。如果这不太可能实现的话，我们可以顺着它的调用栈(call stack)向上查找，看看能不能找到其他的可以并行化的程序热点。假如你的程序热点在一个嵌套循环的最里层，我们可以从内向外的逐一检查每一层循环，看看某一层是否能被并行执行。即使我们能一开始就很顺利的把程序热点并行化了，我们仍然应该去检查一下是否可能在调用栈中更高的某一层上实现并行化。这样做能提高每个线程所执行的任务的粒度。（注：每个线程所执行的任务的粒度可以理解为成功并行化了的部分在整个程序中所占的比例，根据Amdahl定律，并行化的部分越多，程序的整体性能越高）</p>\n<p>为了更清楚的描述这条规则，让我们举一个对视频编码程序进行并行化的例子。如果你的程序热点是针对每个像素的计算，你可以先找到对一帧视频中的每个像素进行计算的循环，并考虑对它进行并行化。以此为基础向“上”找，你可能会发现对每一帧进行处理的循环也是可以被并行化的，这意味着每个线程都可以以帧为单位对一组数据进行独立的处理。如果这个视频编码程序同时要对好几个视频进行处理，那么让每个线程单独处理一个视频流将会是最高层的并行化。</p>\n<p>在另一种自顶向下的并行化方法中，我们可以先对整个程序以及计算的流程（为了完成计算任务而依序组合起来的各个程序模块）进行分析。如果并行化的机会不是很明显，我们可以挑出那些包含了程序热点的模块并对他们进行分析，如果不行就再分析更小的程序热点模块，直到能找到独立的计算任务为止。</p>\n<p>对视频编码程序的例子来说，如果你的程序热点是针对单个像素的计算，采用自顶向下的方法时就可以首先考虑该程序对多个不同的视频流进行编码的情况（每个编码任务都包含了像素计算的任务）。如果你能在这一层成功进行并行化，那么你已经得到了最高层的并行。如果没能成功，那我们可以向“下”找，看看每个视频流的不同帧的计算是否能被并行处理，最后看看每个帧的不同像素的计算是否能被并行处理。</p>\n<p>并行任务的粒度可以理解成在进行同步之前所需要完成的计算量。同步之间运行的时间越长，粒度越大。细粒度的并行存在的隐患就是给每个线程分配的任务可能不够多，以至于都不够弥补使用多线程所带来的开销。此时，在计算量不变的情况下使用更多的线程只会让情况变得更加糟糕。粗粒度的并行化拥有相对来说更少的线程开销，并且更可能在线程增多的情况下仍然有很好的可扩展性。尽可能的在最高层对程序热点实现并行化是实现对多线程的粗粒度任务划分的主要方法之一。</p>\n<p><strong>规则三：尽早针对众核趋势做好可伸缩性的规划</strong><br />\n当我写这本书的时候，四核处理器已经成为了主流。未来处理器的核心数量只会越来越多。所以你应该在你的软件中为这个发展趋势做好规划。可伸缩性（scalability）被用来用来衡量一个程序应对变化的能力，典型的变化有系统资源（例如核心数量，内存大小，总线速度）或数据集大小的增加等。在面对越来越多的可用核心时，你必须写出能灵活高效的利用不同数量的核心的代码。</p>\n<p>C. Northcote Parkinson说过，“数据的增长是为了适应处理能力的增加”。这意味着随着计算能力的增长加（核心数量的增加），很有可能我们会有更多的数据需要处理。我们永远会有更多的计算任务需要完成。不管是增加科学模拟中的建模精度，还是处理更清晰的高清视频，又或者搜索许多更大的数据库，如果你拥有了更多的计算资源，总会有人想要处理更多的数据。</p>\n<p>用数据分解(data decomposition)的方法来设计和实现并行化能给你提供更多的高可扩展性的解决方案。任务分解(task decomposition)的方法可能会面临程序中可独立运行的函数或者代码段数量有限或者数量固定的问题。等到每一个独立的任务已经在单独的线程和核心上运行的时候，再想通过增加线程的数量来利用空闲的多余核心的方法就提高不了程序的性能了。因为在一个程序中数据的大小比独立的计算任务的数量更有可能增加，所以基于数据分解的设计将更有可能获得很好的可伸缩性。</p>\n<p>即使有的程序已经基于任务分解的模式给每个线程分配了不同的计算任务，我们仍然可以在需要处理的数据增加的时候利用更多的线程来完成工作。例如我们需要修建一个杂货店，这项工程由一些不同的任务组成。如果开发商又买了一块相邻的地皮，并且商店要盖的楼层数翻倍了，我们可以雇佣更多的工人去完成这些的任务，比如说更多的油漆工，更多的盖顶工，更多的电工。因此，我们应该注意是否能对增加了的数据进行数据分解，以便利用空闲核心上的可用线程来完成这个工作，哪怕是在我们已经采用了任务分解的方式的程序中。</p>\n<p><strong>规则四：尽可能利用已有的线程安全库</strong><br />\n如果你的程序热点的计算任务能通过库函数调用来完成，强烈建议你考虑使用同等功能的库函数，而不是调用自己手写的代码。即使是串行程序，“重新造轮子”来完成已经被高度优化的库函数实现了的功能仍不是一个好主意。许多的库，例如Intel Math Kernel Library（Intel MKL）和Intel Integrated Performance Primitives (Intel IPP)，提供了能更好的利用多核处理器的并行版本的函数。</p>\n<p>比使用并行版本的函数库更重要的一点是：我们需要确保所有的库函数调用都是线程安全的（thread-safe）。如果你已经把你串行代码中的程序热点替换成了一个库函数调用，你仍有可能在调用树(call tree)的更高层上发现能把程序分解成独立的计算任务的代码段。当你有好几个并行的计算任务，并且它们都同时调用了库函数（特别是第三方函数库），那么函数库中引用并更新共享变量的函数可能会造成数据竞争(data race)。记得好好检查你在并行编程中所调用的函数库的文档中关于线程安全性的描述。当你在设计和编写自己的用于并行执行的函数库时，请务必确保函数是可重入(reentrant)的。如果不能确保的话，你应该给共享的资源加上同步机制。</p>\n<p><strong>规则五：使用合适的多线程模型</strong><br />\n如果并行版的函数库不足以完成程序的并行化，而你又想使用可以自己控制的线程，在隐式的多线程模型能满足你的功能需求的前提下请尽量使用该模型（例如OpenMP或者Intel Thread Building Block）而不是显式的多线程模型（例如Pthread）。显式的多线程模型确实能提供对线程的更精确的控制。但是，如果你仅仅是想把你的计算密集型循环给并行化，或者你不需要显式多线程模型提供的诸多特性，那么我们最好还是能满足需要就好。实现的复杂度越高，犯错误的几率就越大，以后代码的维护难度也会越大。</p>\n<p>OpenMP采用的是数据分解的方法，它尤其适合并行化那些需要处理大量数据的循环。尽管这种类型的并行化可能是唯一一种你能引入的并行模式，但是可能还会有其他的要求（例如由你的雇主或者管理层所决定的工程方案）让你不能使用OpenMP。如果是那样的话，我建议你先使用OpenMP来快速开发出并行化后的模型，估算一下可能的性能提升、可扩展性以及大概需要多少时间才能把这些串行代码用显式多线程库给并行化。</p>\n<p><strong>规则六：永远不要假设具体的执行顺序</strong><br />\n在串行程序中我们可以非常容易地预测某个程序的当前状态结束之后它会变成什么状态。然而，多个线程的执行顺序却是不确定的，它是由操作系统的调度器(scheduler)决定的。这意味着我们不可能准确的预测两个执行状态之间多个线程的执行顺序，甚至连预测哪个线程会在下一步被调度执行也不能。这样的机制主要是为了隐藏程序运行时的延迟，特别是当运行的线程的数量多于核心的数量时。例如，如果一个线程因为要访问不在cache中的地址，或者需要处理一个I/O请求而被阻塞了(blocked)，那么操作系统的调度器就会把该线程调度到等待队列里，同时把另一个等待执行的线程调度进来并执行它。</p>\n<p>数据竞争(data race)就是由这种调度的不确定性造成的。如果你假设一个线程对共享变量的写操作会在另一个线程对该共享变量的读操作之前完成，你的预测可能会一直正确，有可能有些时候会正确，也有可能从来都不会正确。如果你足够幸运的话，有时候在一个特定平台上每次你运行这个程序时线程的执行顺序都不会改变。但是系统间的每个不同（例如数据在磁盘上存储的位置，内存的速度或者插座中的交流电源）都有可能影响线程的调度。对一段需要特定的线程执行顺序的代码来说，如果仅仅依靠乐观的估计而不采取任何实质性的措施的话，很有可能会受到数据竞争，死锁等问题的困扰。</p>\n<p>从性能的角度来讲，最好的情形当然是让所有的线程尽可能没有约束的运行，就像比赛中的赛马或猎犬的一样。除非必要的话，尽可能不要规定一个特定的执行顺序。你需要找到那些确实需要规定执行顺序的地方，并且实现一些必要的同步方法来调整线程间的执行顺序。</p>\n<p>拿接力赛跑来说，第一棒的选手会竭尽全力的奔跑。但是为了成功的完成接力赛，第二个，第三个和最后一棒都需要先等到拿到接力棒之后才能开始跑他们的赛段。接力棒的交接就是他们的同步机制，这样就确保了接力过程中的“执行”顺序。</p>\n<p><strong>规则七：尽可能使用线程本地存储或者对特定的数据加锁</strong><br />\n同步（Synchronization）本身并不属于计算任务，它只是为了确保程序的并行执行能得到正确的结果所产生的额外开销。虽然它产生了额外的开销但是又不可或缺。因此我们还是要尽可能的把同步所产生的开销降低到最低。你可以使用线程私有的存储空间或者独占的内存地址（例如一个用线程ID来进行索引的数组）来达到这个目的。</p>\n<p>那些很少需要在线程间共享的临时变量可以被每个线程单独地在本地进行声明或分配。那些存储着每个线程的部分结果（partial result）的变量也应该是线程私有的。但是在把每个线程的部分结果保存到一个共享的变量的时候就需要采取一些适当的同步措施了。如果我们能确保这样的共享更新操作能尽可能少的进行，我们就可以把同步的额外开销降到最低了。如果我们使用显式的线程编程模型的话，我们可以使用那些线程本地存储（Thread Local Storage）的API来保证线程私有变量在多个并行区域的执行过程中，或者在一个并行函数的多次调用的过程中的一致性。</p>\n<p>如果线程本地存储不可行，而且你必须用同步的对象（例如锁）来协调对共享资源的访问的话，请确保对数据进行了适当的锁操作。最简单的方法就是对锁和数据对象采取一一对应的分配策略。如果对变量的内存地址的访问都是在同一个临界区进行的话，我们就可以使用一把锁来对多个数据进行保护。</p>\n<p>如果你有大量的数据需要保护，例如由一万个数据的数组，我们该怎么办呢？如果我们对整个数组只用一个锁来进行保护的话，很可能会造成严重的锁竞争从而导致性能瓶颈。那么我们是不是可以给每个数组元素创建一个锁呢？然而即使是有32个或者64个线程在同时访问这个数组，这样做看起来也浪费了很多的内存空间来保护那些只有百分之一不到的发生概率的访问冲突。不过有一种折中的解决方案，叫做“取模锁”（modulo lock）。取模锁是用来保护数据集合中的所有的第N个元素，其中N是锁的数量。例如，有两个锁，一个保护所有的奇数个的元素，另一个保护所有的偶数个元素。当需要访问一个被保护的变量时，线程需要先对要访问的地址进行取模操作，然后再去获得对应的取模锁。使用的锁的数量应该是基于线程的数量以及两个线程同时访问相同元素的可能性来决定。</p>\n<p>但是，当你决定用锁来对数据进行保护时，请一定不要用多于一个的锁来给一个单独的元素进行加锁。西格尔定律告诉我们“一个人看着一个表能知道现在几点了，但是他要是有两个表那么他就确定不了时间了”。如果两个不同的锁都对同一个变量进行了保护，那么可能出现代码中的某一部分通过第一个锁来进行访问的同时，代码中的另一部分通过第二个锁也进行了访问。正在执行这两个代码段的多个线程就可能发生数据竞争，因为它们都以为它们对这个被保护的变量有独占的访问权限。</p>\n<p><strong>规则八：敢于更换更易并行化的算法</strong><br />\n当比较串行或者并行程序的性能的时候，运行时间就是衡量的首要标准。程序员会根据算法的时间复杂度来进行选择。时间复杂度和一个程序的性能是息息相关的。它的含义就是，当其他的一切条件都一样时，完成同样功能的时间复杂度为O(NlogN)的算法（例如快速排序）要比O（n^2）的算法（例如选择排序）要快。</p>\n<p>在并行程序中，拥有更好的时间复杂度的算法也会更快一些。然而，有些时候时间复杂度更好的算法却不是很容易被并行化。如果算法的热点不太容易被并行化的话（而且在调用栈的更高层中你又找不到能很容易被并行化的热点），那么你可以尝试换一个稍微慢一点但是却更容易被并行化的算法。当然，还有可能一些其他的改动措施也能让你比较轻松的把某一段代码给并行化了。</p>\n<p>这里我们可以给出一个线性代数中两个矩阵相乘的例子。Strassen的算法拥有最好的时间复杂度：O(n^2.81)。这当然比传统的三重循环的O(n^3)的算法要好。Strassen的算法把每个分成四部分，然后进行七次递归调用来对n/2 x n/2的子矩阵进行乘运算。如果想把这七次递归调用并行化的话，我们可以在每次的递归调用的时候创建一个新线程来进行运算，直到子矩阵到达一个预设的大小为止。这样的话线程的数量就会指数级的成倍增长。随着子矩阵越来越小，给新创建的线程分配的计算任务就会越来越少。还有另一种方法，就是先创建一个有七个线程的线程池。七次子矩阵相乘的运算任务可以分别分配给这七个线程以完成并行化。这样的话线程池就会跟串行版本的程序一样递归调用Strassen算法来对子矩阵进行乘运算。然而，这种方法的缺点就在于对一个拥有大于八个核的系统来说，永远只有七个核在工作，其他的资源都被浪费了。</p>\n<p>另一个更容易被并行化的矩阵乘法就是三重循环的算法了。我们可以有很多方法来对矩阵进行数据分解（按行分解，按列分解或者按块分解）然后再把它们分配给不同的线程。通过用OpenMP在某一层循环中加上编译指示，或者用显式线程模型实现矩阵分割，我们很容易的就能完成并行化。只需要更少的代码改动就可以对这个简单的串行算法完成并行化，并且代码的整体结构改动也会比Strassen算法要少很多。</p>\n<p><strong>总结</strong><br />\n我们已经列出了八条简单的规则，在把串行程序并行化的过程中你应该时刻记住它们。通过遵循这些规则以及一些实际的编程规则，你应该可以更容易的创造更健壮的并行化解决方案，同时能包含更少的并行化时的问题，以及在更短的时间里得到最好的性能。</p>\n<p><strong>原文链接：<a href=\"http://software.intel.com/en-us/articles/8-simple-rules-for-designing-threaded-applications/\">8 Simple Rules for Designing Threaded Applications</a></strong></p>\n","descriptionType":"html","publishedDate":"Thu, 18 Feb 2010 11:59:01 +0000","feedId":9852,"bgimg":"","linkMd5":"138ec05214996e1cfd3653d7ee7a24db","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"并行编程中的“锁”难题","link":"http://www.parallellabs.com/?p=1102","description":"<p><em>注：本文发表于《程序员》2011年第8期并行编程专栏，略有删改。</em></p>\n<p>在并行程序中，锁的使用会主要会引发两类难题：一类是诸如死锁、活锁等引起的多线程Bug；另一类是由锁竞争引起的性能瓶颈。本文将介绍并行编程中因为锁引发的这两类难题及其解决方案。</p>\n<h2>1. 用锁来防止数据竞跑</h2>\n<p>在进行并行编程时，我们常常需要使用锁来保护共享变量，以防止多个线程同时对该变量进行更新时产生数据竞跑（Data Race）。所谓数据竞跑，是指当两个（或多个）线程同时对某个共享变量进行操作，且这些操作中至少有一个是写操作时所造成的程序错误。例1中的两个线程可能同时执行“counter++”从而产生数据竞跑，造成counter最终值为1（而不是正确值2）。<br />\n例1：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n#include &#60;pthread.h&#62;\nint counter = 0;\nvoid *func(void *params)\n{\n    counter++; //数据竞跑\n}\nvoid main()\n{\n    pthread_t thread1, thread2;\n    pthread_create(&#38;thread1, 0, func, 0);\n    pthread_create(&#38;thread2, 0, func, 0);\n    pthread_join(thread1, 0 );\n    pthread_join(thread2, 0 );\n}\n</pre>\n<p>这是因为counter++本身是由三条汇编指令构成的（从主存中将counter的值读到寄存器中；对寄存器进行加1操作；将寄存器中的新值写回主存），所以例1中的两个线程可能按如下交错顺序执行，导致counter的最终值为1：<br />\n例2：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nload [%counter], rax; // 线程1从counter读取0到寄存器rax\nadd rax, 1; // 线程1对寄存器rax进行加1\nload [%counter], rbx; // 线程2从counter读取0到寄存器rbx\nstore rax [%counter]; // 线程1把1写入counter的主存地址\nadd rbx, 1; // 线程2对寄存器rbx进行加1\nstore rbx, [%counter]; // 线程2把1写入counter的主存地址\n</pre>\n<p>为了防止例1中的数据竞跑现象，我们可以使用锁来保证每个线程对counter++操作的独占访问（即保证该操作是原子的）。在例3的程序中，我们使用mutex锁将counter++操作放入临界区中，这样同一时刻只有获取锁的线程能访问该临界区，保证了counter++的原子性：即只有在线程1执行完counter++的三条指令之后线程2才能执行counter++操作，保证了counter的最终值必定为2。<br />\n例3：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n#include &#60;pthread.h&#62;\nint counter = 0;\npthread_mutex_t mutex;\nvoid *func(void *params)\n{\n    pthread_mutex_lock(&#38;mutex);\n    counter++; //处于临界区，不会产生数据竞跑\n    pthread_mutex_unlock(&#38;mutex);\n}\nvoid main()\n{\n    pthread_t thread1, thread2;\n    pthread_mutex_init(&#38;mutex);\n    pthread_create(&#38;thread1, 0, func, 0);\n    pthread_create(&#38;thread2, 0, func, 0);\n    pthread_join(thread1, 0 );\n    pthread_join(thread2, 0 );\n    pthread_mutex_destroy(&#38;mutex);\n}\n</pre>\n<h2>2. 死锁和活锁</h2>\n<p>然而，锁的使用非常容易导致多线程Bug，最常见的莫过于死锁和活锁。从原理上讲，死锁的产生是由于两个（或多个）线程在试图获取正被其他线程占有的资源时造成的线程停滞。在下例中，假设线程1在获取mutex_a锁之后正在尝试获取mutex_b锁，而线程2此时已经获取了mutex_b锁并正在尝试获取mutex_a锁，两个线程就会因为获取不到自己想要的资源、且自己正占有着对方想要的资源而停滞，从而产生死锁。<br />\n例4：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 线程 1 \t\t\t\t\t\nvoid func1() \t\t\t\t\t\n{ \t\t\t\t\t\t\n    LOCK(&#38;mutex_a); \t    \t \t\t \n    LOCK(&#38;mutex_b);//线程1停滞在此 \t\t \n    counter++; \t\t\t\t    \t \n    UNLOCK(&#38;mutex_b); \t    \t \t\t  \n    UNLOCK(&#38;mutex_a); \t    \t \t\t \n} \t\t\t\t\t\t\n\n// 线程 2\nvoid func2()\n{\n    LOCK(&#38;mutex_b);\n    LOCK(&#38;mutex_a);//线程2停滞在此\n    counter++;\n    UNLOCK(&#38;mutex_a);\n    UNLOCK(&#38;mutex_b);\n}\n</pre>\n<p>例4中的死锁其实是最简单的情形，在实际的程序中，死锁往往发生在复杂的函数调用过程中。在下面这个例子中，线程1在func1()中获取了mutex_a锁，之后调用func_call1()并在其函数体中尝试获取mutex_b锁；与此同时线程2在func2()中获取了mutex_b锁之后再在func_call2()中尝试获取mutex_a锁从而造成死锁。可以想象，随着程序复杂度的增加，想要正确的检测出死锁会变得越来越困难。<br />\n例5：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 线程 1 \t\t\t\t\t\nvoid func1() \t\t\t\t\t\n{ \t\t\t\t\t\t\nLOCK(&#38;mutex_a); \t    \t \t\t \n...\t\t\t\t\t\t\nfunc_call1();\t\t\t \t \nUNLOCK(&#38;mutex_a); \t \t\t   \t \n}\t\t\t\t\t\t\n\nfunc_call1()\t\t\t\t\t\n{\t\t\t\t\t\t\n   LOCK(&#38;mutex_b);\t\t \t\t \n   ...\t\t\t\t\t\t \n   UNLOCK(&#38;mutex_b);\t\t\t\t \n   ...\t\t\t\t\t\t \n}\t\t\t\t\t\t\n\n// 线程 2\nvoid func2()\n{\n    LOCK(&#38;mutex_b);\n    ...\n    func_call2()\n    UNLOCK(&#38;mutex_b);\n}\n\nfunc_call2()\n{\n    LOCK(&#38;mutex_a);\n    ...\n    UNLOCK(&#38;mutex_b);\n    ...\n}\n</pre>\n<p>其实避免死锁的方法非常简单，其基本原则就是保证各个线程加锁操作的执行顺序是全局一致的。例如，如果上例中的线程1和线程2都是先对mutex_a加锁再对mutex_b进行加锁就不会产生死锁了。在实际的软件开发中，除了严格遵守相同加锁顺序的原则防止死锁之外，我们还可以使用RAII（Resource Acquisition Is Initialization，即“资源获取即初始化”）的手段来封装加锁解锁操作，从而帮助减少死锁的发生[1]。</p>\n<p>除死锁外，多个线程的加锁、解锁操作还可能造成活锁。在下例中，程序员为了防止死锁的产生而做了如下处理：当线程1在获取了mutex_a锁之后再尝试获取mutex_b时，线程1通过调用一个非阻塞的加锁操作（类似pthread_mutex_trylock）来尝试进行获得mutex_b：如果线程1成功获得mutex_b，则trylock()加锁成功并返回true，如果失败则返回false。线程2也使用了类似的方法来保证不会出现死锁。不幸的是，这种方法虽然防止了死锁的产生，却可能造成活锁。例如，在线程1获得mutex_a锁之后尝试获取mutex_b失败，则线程1会释放mutex_a并进入下一次while循环；如果此时线程2在线程1进行TRYLOCK(&#038;mutex_b)的同时执行TRYLOCK(&#038;mutex_a)，那么线程2也会获取mutex_a失败，并接着释放mutex_b及进入下一次while循环；如此反复，两个线程都可能在较长时间内不停的进行“获得一把锁、尝试获取另一把锁失败、再解锁之前已获得的锁“的循环，从而产生活锁现象。当然，在实际情况中，因为多个线程之间调度的不确定性，最终必定会有一个线程能同时获得两个锁，从而结束活锁。尽管如此，活锁现象确实会产生不必要的性能延迟，所以需要大家格外注意。<br />\n例6：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n// 线程 1 \t\t\t\t\t\nvoid func1() \t\t\t\t\t\n{ \t\t\t\t\t\t\n    int done = 0;\t\t\t\t\t\n    while(!done) {\t\t\t\t \n        LOCK(&#38;mutex_a); \t    \t   \t\t \n        if (TRYLOCK(&#38;mutex_b)) {\t\t \t   \n            counter++; \t\t\t\t     \n            UNLOCK(&#38;mutex_b); \t    \t     \t     \n            UNLOCK(&#38;mutex_a); \t    \t     \t     \n            done = 1;\t\t\t\t\t     \n        }\t\t\t\t\t\t   \n        else {\t\t\t\t\t   \n            UNLOCK(&#38;mutex_a);\t\t     \t    \n        }\t\t\t\t\t\t   \n    }\t\t\t\t\t\t \n} \t\t\t\t\t\t\n\n// 线程 2\nvoid func2()\n{\n    int done = 0;\n    while(!done) {\n        LOCK(&#38;mutex_b);\n        if (TRYLOCK(&#38;mutex_a)) {\n            counter++;\n            UNLOCK(&#38;mutex_a);\n            UNLOCK(&#38;mutex_b);\n            done = 1; \n        }\n        else {\n            UNLOCK(&#38;mutex_b);\n        }\n    }\n}\n</pre>\n<h2>3. 锁竞争性能瓶颈</h2>\n<p>在多线程程序中锁竞争是最主要的性能瓶颈之一。在前面我们也提到过，通过使用锁来保护共享变量能防止数据竞跑，保证同一时刻只能有一个线程访问该临界区。但是我们也注意到，正是因为锁造成的对临界区的串行执行导致了并行程序的性能瓶颈。</p>\n<h3>3.1阿姆达尔法则（Amdahl’s Law）</h3>\n<p>在介绍锁竞争引起的性能瓶颈之前，让我们先来了解一下阿姆达尔法则。我们知道，一个并行程序是由两部分组成的：串行执行的部分和可以并行执行的部分。假设串行部分的执行时间为S，可并行执行部分的执行时间为P，则整个并行程序使用单线程（单核）串行执行的时间为S+P。阿姆达尔法则规定，可并行执行部分的执行时间与线程数目成反比：即如果有N个线程（N核CPU）并行执行这个可并行的部分，则该部分的执行时间为P/N。由此我们可以得到并行程序总体执行时间的公式：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n总体执行时间T = S + P/N\n</pre>\n<p>根据这个公式，我们可以得到一些非常有意思的结论。例如，如果一个程序全部代码都可以被并行执行，那么它的加速比会非常好，即随着线程数（CPU核数）的增多该程序的加速比会线性递增。换句话说，如果单线程执行该程序需要16秒钟，用16个线程执行该程序就只需要1秒钟。<br />\n然而，如果这个程序只有80%的代码可以被并行执行，它的加速比却会急剧下降。根据阿姆达尔法则，如果用16个线程并行执行次程序可并行的部分，该程序的总体执行时间T = S + P/N = (16*0.2) + (16*0.8)/16 = 4秒，这比完全并行化的情况（只需1秒）足足慢了4倍！实际上，如果该程序只有50%的代码可以被并行执行，在使用16个线程时该程序的执行时间仍然需要8.5秒！<br />\n从阿姆达尔法则我们可以看到，并行程序的性能很大程度上被只能串行执行的部分给限制住了，而由锁竞争引起的串行执行正是造成串行性能瓶颈的主要原因之一。</p>\n<h3>3.2锁竞争的常用解决办法</h3>\n<h4>3.2.1 避免使用锁</h4>\n<p>为了提高程序的并行性，最好的办法自然是不使用锁。从设计角度上来讲，锁的使用无非是为了保护共享资源。如果我们可以避免使用共享资源的话那自然就避免了锁竞争造成的性能损失。幸运的是，在很多情况下我们都可以通过资源复制的方法让每个线程都拥有一份该资源的副本，从而避免资源的共享。如果有需要的话，我们也可以让每个线程先访问自己的资源副本，只在程序的后讲各个线程的资源副本合并成一个共享资源。例如，如果我们需要在多线程程序中使用计数器，那么我们可以让每个线程先维护一个自己的计数器，只在程序的最后将各个计数器两两归并（类比二叉树），从而最大程度提高并行度，减少锁竞争。</p>\n<h4>3.2.2 使用读写锁</h4>\n<p>如果对共享资源的访问多数为读操作，少数为写操作，而且写操作的时间非常短，我们就可以考虑使用读写锁来减少锁竞争。读写锁的基本原则是同一时刻多个读线程可以同时拥有读者锁并进行读操作；另一方面，同一时刻只有一个写进程可以拥有写者锁并进行写操作。读者锁和写者锁各自维护一份等待队列。当拥有写者锁的写进程释放写者锁时，所有正处于读者锁等待队列里的读线程全部被唤醒并被授予读者锁以进行读操作；当这些读线程完成读操作并释放读者锁时，写者锁中的第一个写进程被唤醒并被授予写者锁以进行写操作，如此反复。换句话说，多个读线程和一个写线程将交替拥有读写锁以完成相应操作。这里需要额外补充的一点是锁的公平调度问题。例如，如果在写者锁等待队列中有一个或多个写线程正在等待获得写者锁时，新加入的读线程会被放入读者锁的等待队列。这是因为，尽管这个新加入的读线程能与正在进行读操作的那些读线程并发读取共享资源，但是也不能赋予他们读权限，这样就防止了写线程被新到来的读线程无休止的阻塞。<br />\n需要注意的是，并不是所有的场合读写锁都具备更好的性能，大家应该根据Profling的测试结果来判断使用读写锁是否能真的提高性能，特别是要注意写操作虽然很少但很耗时的情况。</p>\n<h4>3.2.3 保护数据而不是操作</h4>\n<p>在实际程序中，有不少程序员在使用锁时图方便而把一些不必要的操作放在临界区中。例如，如果需要对一个共享数据结构进行删除和销毁操作，我们只需要把删除操作放在临界区中即可，资源销毁操作完全可以在临界区之外单独进行，以此增加并行度。<br />\n正是因为临界区的执行时间大大影响了并行程序的整体性能，我们必须尽量少在临界区中做耗时的操作，例如函数调用，数据查询，I/O操作等。简而言之，我们需要保护的只是那些共享资源，而不是对这些共享资源的操作，尽可能的把对共享资源的操作放到临界区之外执行有助于减少锁竞争带来的性能损失。</p>\n<h4>3.2.4 尽量使用轻量级的原子操作</h4>\n<p>在例3中，我们使用了mutex锁来保护counter++操作。实际上，counter++操作完全可以使用更轻量级的原子操作来实现，根本不需要使用mutex锁这样相对较昂贵的机制来实现。在今年程序员第四期的《volatile与多线程的那些事儿》中我们就有对Java和C/C++中的原子操作做过相应的介绍。</p>\n<h4>3.2.5 粗粒度锁与细粒度锁</h4>\n<p>为了减少串行部分的执行时间，我们可以通过把单个锁拆成多个锁的办法来较小临界区的执行时间，从而降低锁竞争的性能损耗，即把“粗粒度锁”转换成“细粒度锁”。但是，细粒度锁并不一定更好。这是因为粗粒度锁编程简单，不易出现死锁等Bug，而细粒度锁编程复杂，容易出错；而且锁的使用是有开销的（例如一个加锁操作一般需要100个CPU时钟周期），使用多个细粒度的锁无疑会增加加锁解锁操作的开销。在实际编程中，我们往往需要从编程复杂度、性能等多个方面来权衡自己的设计方案。事实上，在计算机系统设计领域，没有哪种设计是没有缺点的，只有仔细权衡不同方案的利弊才能得到最适合自己当前需求的解决办法。例如，Linux内核在初期使用了Big Kernel Lock（粗粒度锁）来实现并行化。从性能上来讲，使用一个大锁把所有操作都保护起来无疑带来了很大的性能损失，但是它却极大的简化了并行整个内核的难度。当然，随着Linux内核的发展，Big Kernel Lock已经逐渐消失并被细粒度锁而取代，以取得更好的性能。</p>\n<h4>3.2.6 使用无锁算法、数据结构</h4>\n<p>首先要强调的是，笔者并不推荐大家自己去实现无锁算法。为什么别去造无锁算法的轮子呢？因为高性能无锁算法的正确实现实在是太难了。有多难呢？Doug Lea提到java.util.concurrent库中一个Non Blocking的算法的实现大概需要1个人年，总共约500行代码。事实上，我推荐大家直接去使用一些并行库中已经实现好了的无锁算法、无锁数据结构，以提高并行程序的性能。典型的无锁算法的库有java.util.concurrent，Intel TBB等，它们都提供了诸如Non-blocking concurrent queue之类的数据结构以供使用。</p>\n<h3>参考</h3>\n<p>[1] 陈硕.<a href=\"http://blog.csdn.net/solstice/article/details/5307710\">多线程服务器的常用编程模型. </a><br />\n[2]  Darryl Gove.<a href=\"http://book.douban.com/subject/5366276/\"> Multicore Application Programming</a><br />\n[3]  并行实验室. <a href=\"http://www.parallellabs.com/2010/10/25/practical-concurrent-queue-algorithm/\">多线程队列的算法优化. </a></p>\n","descriptionType":"html","publishedDate":"Sun, 02 Oct 2011 02:11:14 +0000","feedId":9852,"bgimg":"","linkMd5":"75565f51e6e9ff8075432ea905a36d3e","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Proposal for the “Search and sort” competition of Findwise","link":"http://www.parallellabs.com/?p=146","description":"<p>In this April I took part in a competition hold by <a href=\"http://www.findwise.se\" target=\"_blank\">Findwise</a> and <a href=\"http://www.mriday.com\" target=\"_blank\">Mriday</a> which is about search technology.</p>\n<blockquote><p>Search and Sort | Findwise</p>\n<p>Current, Search and Sort | Findwise April 25th, 2009</p>\n<p>We are constantly acquiring innovative ideas and solutions in the field of search technology. Therefore we have created the following contest to discover people who are interested in joining Findwise and build next generation’s search technology.</p>\n<p>Project overview</p>\n<p>The name of this contest is called Search and Sort. We can start by looking at an example which everybody is familiar with, Google. The Google search engine is the most used search engine on the Web. The search results generated from it includes webpages, PDF, Word documents, Excel spreadsheets, Flash, videos etc. For any query, up to the first 1000 results can be shown with a maximum of 100 displayed per page.</p>\n<p>Despite all this power, it is still sometimes time consuming to find the exact piece of information you are looking for. This is because although the different results are ranked, they are not well organized. For the average user, wouldn’t it be neat if different types of search results are categorized and displayed in different<br />\ngroups?</p>\n<p>Submission</p>\n<p>Your submission for this contest should contain two parts</p>\n<p>Think of a search engine based on the concept of Search and Sort. Come up with a user interface design including two pages. One welcome page with the search box (and whatever else you think is suitable), and one page with the different types of results categorized, sorted, and presented in a userfriendly fashion. There is no strict requirements on exactly how the results will be categorized. It is entirely up to you to decide the types of categories. In fact, this will be a key deciding factor when your contest submission is being reviewed.</p>\n<p>The second part of the contest is to discuss the framework behind your graphical user interface. What programming language and platform do you suggest for building the system? How would you extract information from different types of results and use that information to categorize them? Describe the plan to develop and implement it. The key for this part is to show a good understanding of the basics of a search engine, and a passion to innovate new ideas.</p>\n<p>Searching has become the standard way for Internet users to find information. This contest gives you the chance to take Searching to the next level. If you are interested in search technology and would like to join the leading vendor independent company within this segment in Sweden, then send us your ideas. We will carefully review your submission and provide feedback. Your submission should be in PDF or DOC format.</p>\n<p>The deadline for submission is 2009-04-30</p>\n<p>Reward</p>\n<p>The top 5 submissions will be invited to Findwise and receive a learning session about the company and the future of search technology. The most outstanding submission will receive a monetary reward of 10 000 SEK. Job offers will be presented to qualified individuals if requirements are met.</p></blockquote>\n<p>I spent a whole Sunday to write down a proposal for this topic. That&#8217;s the first time for me to write down something on &#8220;search technology&#8221; which is a very interesting and hot area nowdays. Even though this paper looks a lit bit naive now, I still like it since I enjoy the feeling of writing down something interesting very much.</p>\n<p>You can find and download my proposal from the link below:</p>\n<p><a href=\"http://docs.google.com/fileview?id=0B3e2Z4tVgRpsN2E3ZGZmNDQtNmFiYS00YjI0LWFiYzgtMWUzMDNkMjM1MWJi&#38;hl=en\" target=\"_blank\"><em><strong>Search and sort.pdf</strong></em></a></p>\n","descriptionType":"html","publishedDate":"Wed, 30 Dec 2009 01:26:54 +0000","feedId":9852,"bgimg":"","linkMd5":"7cd2b9ad46fe7413ff2d817d2d6bf6ae","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"智能优化&AB测试-实验驱动用户增长@QCon10 PPT分享","link":"http://www.parallellabs.com/?p=1545","description":"\n<p>这次在“用户增长”Session做了一个分享，标题是“智能优化 &#38; A/B 测试 &#8211; 实验驱动用户增长的理论与技术实践”，对过去几年AB测试、用户增长的工作做了一次系统分享，希望对大家有用：）</p>\n\n\n\n<p>PPT下载链接: <a href=\"https://pan.baidu.com/s/1be1xThcjkSz8tHMMwVnVPQ\">https://pan.baidu.com/s/1be1xThcjkSz8tHMMwVnVPQ</a> 提取码: 5fyu </p>\n\n\n\n<h1>演讲：智能优化 &#38; A/B 测试 &#8211; 实验驱动用户增长的理论与技术实践</h1>\n\n\n\n<p>在流量红利日渐消逝的今天，如何用科学的实验方法来有效地实现用户增长，正受到越来越多的关注。A/B 测试在头条、抖音、快手等现象级应用的增长过程中发挥了极其重要的作用，增长黑客之父 Sean Ellis 更是对 Test Driven Growth（实验驱动增长）推崇备至。本次分享将介绍如何搭建 A/B 测试驱动用户增长的科学运营体系，A/B 测试在亿级 App 产品中的实战增长案例，以及亿级智能优化 &#38; A/B 测试系统的机器学习和大数据技术实践。</p>\n\n\n\n<h3>听众收益</h3>\n\n\n\n<ol><li>A/B 测试如何助力用户增长？</li><li>如何在团队中有效推进A/B测试？</li><li>A/B 测试实际案例分享；</li><li>基于强化学习和 Druid 的智能优化 &#38; A/B 测试系统技术实践。</li></ol>\n\n\n\n<h1><strong>专题演讲嘉宾：</strong>陈冠诚</h1>\n\n\n\n<h6>Testin 云测CTO</h6>\n\n\n\n<p>陈冠诚，Testin 云测 CTO，原 IBM 研究院高级科学家。师从欧洲科学院院士 Per Stenstrom 教授，在 Supercomputing，IEEE BigData 等顶级会议上发表过 6 篇大数据机器学习相关论文，拥有 8 项国际专利。10 年大数据产品技术经验。曾为众多企业搭建了智能优化 &#38; A/B 测试驱动产品优化的数据体系。国内最大的 Druid 开源大数据技术社区发起人。在 Testin 云测负责与应用相关的测试、安全、推广、产品优化，流量变现及 AI 大数据解决方案产品技术研发，服务了全球超百万的开发者和企业。</p>\n\n\n\n<p>PS. 今年是QCon 10周年，mark下。</p>\n","descriptionType":"html","publishedDate":"Sun, 26 May 2019 10:03:17 +0000","feedId":9852,"bgimg":"","linkMd5":"f0564184ed4036e85fd1ca796f0d2fc0","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"人工智能芯片公司招聘工程师/行政/出纳","link":"http://www.parallellabs.com/?p=1501","description":"<p>我的好朋友陈云霁、陈天石是中科院计算所的研究员，他们课题组研发的寒武纪深度学习处理器斩获了国际顶级会议ASPLOS‘14，Micro’14的最佳论文奖，MIT Technical Review 2015年35位35岁以下的全球创新者等荣誉，并在计算机体系机构的旗舰会议ISCA‘16中荣获评分第一名，现在Stanford，MIT，Intel，三星等著名高校和公司都在跟随他们的脚步做深度学习处理器方面的研发工作。现在他们已经正式成立了中科寒武纪科技公司，开始了深度学习处理器的产业化进程。在深度学习处理器方面他们已经积累了上百项全球专利，是该领域毫无疑问的领导者。现在他们正在招聘Linux驱动开发工程师，逻辑设计工程师，Android应用、驱动开发工程师，编译器工程师，芯片验证工程师、物理设计工程师，行政、出纳等，如果你感兴趣加入一家想通过人工智能和芯片改变世界的公司，欢迎将你的简历发给我：chenguancheng@gmail.com。</p>\n<p>&#8212;&#8211; 下面是他们的详细招聘信息 &#8212;&#8212;-</p>\n<p>寒武纪科技是全球智能芯片领域的领导者，宗旨是打造各类智能终端、机器学习云服务器以及智能机器人上的“大脑芯片”。团队曾研制了国际上首个深度学习处理器，相关成果入选了国际计算机学会评选的研究热点，并两次获得计算机硬件顶级国际会议最佳论文（亚洲仅有的两次）。目前公司与智能产业上下游企业建立了良好的合作关系和生态链，受到业界广泛看好，得到了集成电路产业领导性VC以及国内主板上市智能产业公司的投资。<br />\n未来10年是人工智能大爆炸的十年，寒武纪科技必将是这次大爆炸的弄潮儿，我们的芯片将会成为所有智能服务器、智能终端设备的不二选择，从我们开始，硬件将进入真正的智能化时代。万事俱备，热切欢迎有理想、有追求、有干劲的有志之士加盟。虽然是初创，公司依然会为每位员工提供具有行业竞争力的待遇。具体的需求岗位如下：</p>\n<p>[招聘岗位] Linux驱动开发工程师（1人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、进行智能芯片在Linux系统下的驱动设计、开发、测试和维护；<br />\n2、配合应用开发工程师，完成必要的API接口开发；<br />\n3、进行模块设计，包括软硬件接口、协议接口设计等；<br />\n4、进行模块开发、调试和系统联调等。<br />\n任职条件：<br />\n1、理解Linux Kernel和Driver结构和开发流程；<br />\n2、两年以上Linux驱动开发经验，具有独立开发设备驱动的经验；<br />\n3、熟练掌握C/C++，有扎实的编程基础、良好的编程风格和工作习惯；<br />\n4、具有独立解决问题的能力，良好的团队合作意识和沟通能力；<br />\n5、重点院校计算机相关专业本科及以上学历。</p>\n<p>[招聘岗位]：逻辑设计工程师（2人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、与深度学习算法工程师合作，设计开发RTL功能模块。<br />\n任职条件：<br />\n1、电子工程或计算机相关专业，大学本科及以上学历；<br />\n2、有3~5年以上数字电路前端工作经验，有实际芯片流片和量产经验；<br />\n3、精通Verilog设计及验证；<br />\n4、熟悉FPGA设计开发经验；<br />\n5、熟悉集成电路前端/后端的设计和调试工具。</p>\n<p>[招聘岗位] Android驱动开发工程师（1人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、负责Android平台智能芯片驱动开发及维护；<br />\n2、进行模块开发、调试和系统联调等；<br />\n3、编写、整理设计开发等相关技术文档。<br />\n任职条件：<br />\n1、熟悉Linux和Android架构，熟悉操作系统，具备硬件基础知识；<br />\n2、两年以上Android驱动开发经验，具有独立进行硬件底层驱动、HAL接口编程等技术开发能力；<br />\n3、熟练掌握C/C++，有扎实的编程基础、良好的编程风格和工作习惯；<br />\n4、具有独立解决问题的能力，良好的团队合作意识和沟通能力；<br />\n5、重点院校计算机相关专业本科及以上学历。</p>\n<p>[招聘岗位] 移动平台应用开发工程师（1人）<br />\n工作地点：北京/上海<br />\n岗位职责<br />\n1、负责智能芯片在Android平台上应用软件的开发及维护；<br />\n2、负责智能芯片SDK的封装、调用示例代码编写、开发和帮助文档的撰写及SDK相关技术支持；<br />\n3、负责或协助进行需求分析，进行应用软件的定义和程序设计；<br />\n4、编写、整理设计开发等相关技术文档 。<br />\n任职条件<br />\n1、两年以上Android平台软件开发经验；<br />\n2、熟悉Andriod系统架构，精通Android平台的应用开发；<br />\n3、擅长UI设计及编程，熟悉Android界面开发及其相关技术；<br />\n4、具有独立解决问题的能力，良好的团队合作意识和沟通能力；<br />\n5、重点院校计算机相关专业本科及以上学历。</p>\n<p>[招聘岗位] 编译器开发与性能优化工程师（1人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、编译工具链的开发和维护；<br />\n2、智能芯片指令相关工具的开发和维护；<br />\n3、对编译器优化算法改进，提升编译器优化性能；<br />\n4、分析智能芯片性能，进行性能测试、分析和优化。<br />\n任职条件：<br />\n1、熟悉C/C++语言、操作系统和计算机系统结构；<br />\n2、熟悉编译原理、熟悉编译、链接流程，有GCC、LLVM和Open64等开源编译器相关开发经验为佳；<br />\n3、熟悉oprofile、perf等性能分析工具；<br />\n4、具有独立解决问题的能力，良好的团队合作意识和沟通能力；<br />\n5、重点院校计算机相关专业本科及以上学历。</p>\n<p>[招聘岗位]：验证工程师（2人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、负责进行深度学习处理器的功能验证与FPGA验证。<br />\n任职条件：<br />\n1、电子工程或计算机相关专业，大学本科及以上学历；<br />\n2、有3~5年以上数字电路前端工作经验，有实际芯片流片和量产经验；<br />\n3、精通Verilog验证，熟悉任何一种验证方法学；<br />\n4、熟悉FPGA设计开发经验；<br />\n5、熟悉集成电路前端的仿真和调试工具。</p>\n<p>[招聘岗位]：物理设计工程师（2人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、负责在深亚微米低工艺条件下的复杂处理器芯片物理设计工作，包括模块或芯片极的逻辑综合、布局布线、芯片集成、静态时序分析和sign-off等。<br />\n任职条件：<br />\n1、电子工程或微电子相关专业，大学本科及以上学历；<br />\n2、集成电路物理设计领域的2-3年以上的工作经验；<br />\n3、具有模块和芯片级的静态时序分析和时序收敛的经验；<br />\n4、具有28纳米产品芯片成功tape-out经验者优先；<br />\n5、具有DFT– ATPG，JTAG，BIST经验者优先。</p>\n<p>【招聘岗位】：人事/行政助理（2人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1. 人事: 负责员工招聘，薪酬福利，员工关系等主要模块的工作；<br />\n2. 行政：负责办公室资产管理，办公用品管理、购买和发放；负责来访人员接待，及其他日常管理工作。<br />\n任职条件：<br />\n1、 认真负责，细心周到；<br />\n2、 性格开朗热情，沟通顺畅；<br />\n3、 团队合作精神；<br />\n4、 工作勤奋踏实，守时；<br />\n5、 有很好的服务意识。</p>\n<p>【招聘岗位】：出纳（1人）<br />\n工作地点：北京/上海<br />\n岗位职责：<br />\n1、负责现金、支票的收入保管、签发支付工作。<br />\n2、严格按照公司的财务制度报销结算公司各项费用并编制相关凭证。<br />\n3、及时准确编制记账凭证并逐笔登记总账及明细账，定期上缴各种完整的原始凭证。<br />\n4、及时与银行定期对账。<br />\n任职条件：<br />\n1、会计、财务或相关专业本，并取得会计从业资格证。<br />\n2、1年以上财务工作经验，熟悉出纳工作流程。<br />\n3、了解国家财经政策和会计、税务法规，熟悉银行结算业务。<br />\n4、熟悉会计报表的处理，熟练使用财务软件。<br />\n5、工作认真细致、善于沟通、富有责任心。<br />\n6、具有良好的职业道德，敬业精神和团队协作能力。</p>\n<p>有意者请将中文或英文简历寄至：jiajingkai@ict.ac.cn<br />\n公司地址：北京市海淀区科学院南路6号<br />\n邮编:100190</p>\n","descriptionType":"html","publishedDate":"Mon, 04 Apr 2016 12:51:13 +0000","feedId":9852,"bgimg":"","linkMd5":"3e1be97b843fd10dec675c4c3a3f9e3c","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"给Vim配置Scala语法高亮显示","link":"http://www.parallellabs.com/?p=1468","description":"<p>第一步，执行下面这个脚本：</p>\n<p style=\"padding-left: 30px;\">mkdir -p ~/.vim/{ftdetect,indent,syntax} &#38;&#38; for d in ftdetect indent syntax ; do curl -o ~/.vim/$d/scala.vim https://raw.githubusercontent.com/gchen/scala.vim/master/scala.vim; done</p>\n<p>第二步，在~/.vimrc中添加：</p>\n<p style=\"padding-left: 30px;\">syntax on</p>\n","descriptionType":"html","publishedDate":"Sat, 11 Apr 2015 14:54:06 +0000","feedId":9852,"bgimg":"","linkMd5":"0f48da75afb8e62da5c86f5894f963a5","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"与Google拼音的工程师聊聊中文滑行输入","link":"http://www.parallellabs.com/?p=1347","description":"<p>前一阵子Google拼音输入法加入了中文滑行输入功能，我因为去年和同事一起发过一个输入法的专利，对输入法的创新比较感兴趣，所以第一时间体验了一番。于是就有了与Google负责拼音输入法的@秃秃哥 同学的一番对话。</p>\n<p><a href=\"http://www.weibo.com/2149547674/zBlOmd9kJ#_rnd1372946523209\" title=\"http://www.weibo.com/2149547674/zBlOmd9kJ#_rnd1372946523209\" target=\"_blank\">http://www.weibo.com/2149547674/zBlOmd9kJ#_rnd1372946523209</a></p>\n<p>@冠诚：装了，但感觉輸中文还是没有九宫格好用 输入法的极致是实现盲打 我觉得目前的实现离这个目标还是差很多的 倒是flskey这个盲打输入法比较有意思 谷歌工程师可以参考下 合格的工程师一定会看到我这条评论的 呵呵 加油 争取变改进型创新为革命型 毕竟改变用户长久的九宫格习惯需要更大的力量</p>\n<p><strong>果然@秃秃哥 同学开始回复我这个微博，我俩就此开始交互：<br />\n</strong></p>\n<p>@秃秃哥：谷歌全键盘的智能纠错已经可以支持一定程度的盲打了，你不妨试试。</p>\n<p>@冠诚：回复@秃秃哥九宫格也可以盲打啊，跟九宫格比，滑行盲打的准确度能提升一倍吗？如果不能的话，凭什么去吸引那么多的用户去改变输入习惯？滑行之所以能在英文输入上火起来，是因为老外不幸的没有九宫格。[嘻嘻] </p>\n<p>@冠诚：回复@秃秃哥九宫格的键比滑行要大很多，所以它实现盲打很容易。如果稍微观察下现在的年轻人，他们九宫格打字应该很快的。尤其是在手机上。平板上滑行的发展空间会更大些。但是你去搜下各种论坛，很多人还在求平板上的九宫格。说白了，还是要先找用户的痛点，再去考虑算法技术实现等。</p>\n<p>秃秃哥：回复@冠诚:谷歌拼音在平板上的九宫格你有没有试过啊？给点建议呗。</p>\n<p>冠诚：回复@秃秃哥:你说的是平板上的滑行输入吧？ 手上只有ipad sorry 啊。其实，我觉得吧，要有一个能在中文盲打效率上比九宫格好两倍以上才能让用户改变输入习惯，而且这个改变还要很长时间，例如从年轻的刚入网的用户开始培养比较容易。那么这个问题就变成，九宫格在平板上有多弱？能被提升两倍吗？</p>\n<p>秃秃哥：回复@冠诚:不是滑行啊。我是说谷歌拼音在平板上的九宫格键盘是特殊设计的布局。</p>\n<p>秃秃哥：回复@冠诚:我们并不是要改变用户的使用习惯啊。九宫格用户还应该继续使用九宫格。滑行输入是给全键盘用户准备的。全键盘用户比九宫格用户还是多的。另外，我们的九宫格键盘也是优化了的。</p>\n<p>冠诚：回复@秃秃哥:那就要做市场调研，看看不用九宫格做中文输入法的用户有多少，然后在看看滑行中文比非九宫格的中文输入快到两倍没？如果有市场，有提升，那就有机会。先把这帮人转到滑行上来，再去跟九宫格死磕。</p>\n<p>秃秃哥：回复@冠诚:哎呀，哪儿那么麻烦呀。九宫格和全键盘两个用户群其实重叠很小的，他们之间是很难转换的。我们的目标就是让他们都可以快速舒服的输入。</p>\n<p>冠诚：回复@秃秃哥:恩，我是想从创造新business角度来考虑输入法创新的，可能跟你不太一样。所以我才那么关注效率的成倍提升和用户习惯。就像当年的搜狗拼音一样的质变。这样影响力才大。只是量产的话可能竞争壁垒比较低一点，影响力也小一些。可能输入法确实坑小一些，用户的使用习惯也千差万别。</p>\n<p>此时@xcv58_ 同学也开始加入：</p>\n<p>@xcv58_：回复@冠诚:想创造新的Business 就应该思考如何让人们离开输入法也能交流。</p>\n<p>冠诚：回复@xcv58_:是的，所以新business是语音输入，甚至智能助手，贴心小秘书，能直接自动理解你的意图，google now啥的路数。未来就是直接”一个眼神，我就懂了你”。更极客点那就直接读懂脑电波。 </p>\n<p>秃秃哥：回复@冠诚:输入法领域用户习惯是非常难以改变的。你看看qwerty那么低效的键盘，还不是活了快一个世纪了。那么多创新的高效的键盘设计，没一个能取代的了的。我们的创新就是要在不对用户习惯做彻底变革的前提下一小步一小步的提升输入效率，降低学习难度。全键盘拼音滑行输入就是一个有益的尝试。</p>\n<p>冠诚：回复@秃秃哥:完全同意，而且确实帮到了全键盘用户。[呵呵]</p>\n<p>然后，@触宝 同学也来凑了这条微博的热闹：</p>\n<p>触宝：亲也可以试试触宝输入法哇，不仅支持中文的简全拼和整句滑行输入外，同时支持英文滑行输入哇~\t</p>\n<p><strong>&#8211; 分割线 &#8211;</strong></p>\n<p>总结：微博果然是了解用户需求，与用户交流并收集反馈的好工具。</p>\n","descriptionType":"html","publishedDate":"Thu, 04 Jul 2013 14:14:28 +0000","feedId":9852,"bgimg":"","linkMd5":"917a008fd3bb3e4f7394154b9239da5e","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多核编程的难题（二）","link":"http://www.parallellabs.com/?p=620","description":"<p>刚刚过去的一个月一直都在忙着赶实验赶论文，直到前几天完成一篇短论文的写作才得以抽身来补上这一篇关于多核的曙光的文章。我将分几个方面来阐述一下我对多核上并行编程持乐观态度的原因。</p>\n<h3>1. 较易并行化的应用</h3>\n<p>如果一个应用的子任务之间依赖关系比较小，相互独立性强，那么它就具有很好的可并行性。很容易我们就会想到服务端的应用。服务端应用的特征就是为多用户提供相似的服务，因为它本身具有内在的并行性，所以相比那些子任务之间依赖性很强的应用来说，它们是比较适合多核的。这些应用常见的例子有大型数据库、飞机票预订系统、银行交易系统、网络搜索、游戏服务器以及云计算所提供的软件即服务（SaaS）等等。</p>\n<p>另一种大量采用并行化的成功案例就是图像处理了。举个简单的例子，渲染一幅图像这个任务就充满了大量的数据级并行（data-level parallelism）：一幅图像是由许许多多的像素组成的，而现在的GPU都有成百个核心，我们可以比较容易的做到让每个GPU核心分别负责渲染图像的一部分，从而快速的完成整个计算任务。虽然现在来讲GPU上面的编程很难，但是它所能提供的性能提升确实非常可观。</p>\n<p>还有很火的GPGPU应用（General-purpost computing on GPU），它们在Scientific Computing领域也有不少成功案例，虽然John Carmack就在Twitter上对GPGPU编程的困难性这样评价过：“Hundreds of GPGPU research papers valiantly struggling with graphic API limitations are painfully obsolete with CUDA / OpenCL available.”其实Scientific Computing可以算是多核上的杀手级应用了，典型的例如天气预测、气候模拟等运用，为了得到更精确的结果肯定就需要处理更多的数据，而且是必须在短时间内出结果，要不然你预测后天的天气但是一个礼拜才给你出结果怎么行？这些大数据量的计算任务对性能的需求永远都是非常大的。而且这些应用本身有很多数据级的并行性，再加上这个领域一般都是行业专家和软件工程师的组合，大规模的应用并行计算是很自然的事情。</p>\n<h3>2. 我们有持乐观态度的理由</h3>\n<p>为什么我们可以对多核发展持乐观态度？因为第一点，现在整个工业界、学术界都在研究多核，研究怎样简化并行编程、怎样降低功耗、怎样持续提升性能。Intel和Microsoft资助UIUC和UC Berkeley建立了两个重点实验室，其他顶级研究机构对多核的研究也如火如荼，大量最顶尖的人才都在帮助普及并行计算。第二点，Motivation，即“动机”。免费午餐都结束了，想继续提升性能？你只能进行并行编程。不管是客户端应用也好服务器端应用也好，用户对性能的需求肯定是不会停止的。当并行编程成为持续提升性能的唯一选择时，再困难你也得去做对不对？不过大家不用特别担心，对广大的程序员来讲，一项新技术的普及本身就是需要时间的，现在来讲大量帮助程序员进行并行编程的软硬件工具都在处在发展阶段，我们有理由相信并行编程会更容易更大众。</p>\n<h3>3. 多核的发展趋势</h3>\n<p>9月初我去参加斯德哥尔摩举办的<a href=\"http://www.sics.se/multicore2010/presentations\" target=\"_blank\">Multicore Day</a>时听了一位在Intel负责Nehalem的首席工程师的演讲，里面有几点我记忆深刻：<br />\n（1）单核的性能仍在提升<br />\n虽然整个工业界主题是往多核发展，但是处理器的单线程性能仍然在持续提升，这是由需求决定的。例如Nehalem架构的i7的单线程性能是奔4的5倍，这一需求也在Google在Micro 2010的论文”<a href=\"http://www.google.com/research/pubs/archive/36448.pdf\">Brawny cores still beat wimpy cores, most of the time</a>“中得到印证。这篇文章的核心观点就是性能较弱但是功耗较低的”小号“处理器只有在它们的单核性能接近中档的”大号“处理器时才具有足够的竞争力，否则它们羸弱的单核性能会成为Google现有应用中的性能瓶颈。虽然当初整个业界因为单核性能提升太困难而被迫转向更易实施的多核<br />\n（2）CPU和GPU的融合趋势<br />\n现在业界已经认同GPU比CPU更适合做数据级并行，而且这类应用需求量很大，这种需求就催生了Intel的Larrabee项目。虽然Larrabee流产了，但是它的技术还在，以后迟早会出现在Intel的产品线上。为了追求更高的性能，GPU和CPU结合的方案会是最好的选择，当然，怎样在这样的硬件上编程又是一个很大的难题。<br />\n（3）性能与功耗都重要<br />\nIntel的工程师一直在努力确保处理器的性能提升的同时它的功耗也一直在稳步下降。为什么说功耗很重要？我们可以举个很简单的例子，笔记本电脑上运行PowerPoint的速度已经很快了，让PowerPoint运行速度快个一两倍其实并不那么重要，但是如果在保证它运行速度的同时还能让笔记本的续航时间提升一些，这就很有意义了。服务器端更不用说了，现在哪个数据中心不把功耗当做头等大事来考虑？</p>\n<h3>4. 并行编程的普及教育</h3>\n<p>虽然说传统的应用一直都以串行计算为背景，所以现在来讲大家普遍觉得并行编程很困难。但是我们换个思路看看：如果从大一开始我们就教新生《并行算法》《并行编程导论》呢？如果程序员一开始就接受的是并行编程的教育，并行编程还是困难的吗？其实我们整个世界本身就充满了并行，人可以同时听课和做笔记，同时吃饭和交流，而计算机硬件更是可以并行工作，为什么软件就不可以？算法导论最新的第三版专门添加了一章<a href=\"http://blog.csdn.net/hoping/archive/2010/02/25/5326354.aspx\" target=\"_blank\">《多线程算法》</a>，（该书其中一位作者Prof. Charles Leiserson创办的并行编程的公司Cilk Art也已被Intel收购）让我大胆想象一下，整本算法导论通篇都是“并行”的时代还会远吗？</p>\n","descriptionType":"html","publishedDate":"Mon, 20 Sep 2010 04:11:06 +0000","feedId":9852,"bgimg":"","linkMd5":"cdddaaa436c93565bc44e83174fdefcb","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"大数据的价值密度","link":"http://www.parallellabs.com/?p=1423","description":"<p>文 / 陈冠诚</p>\n<p><span style=\"color: #0000ff;\"><em>注：原文刊载于《程序员》2014年第5期，略有删改。</em></span></p>\n<p>在大数据和云计算如火如荼的今天，怎样将数据的商业价值变现成为各位老板和技术男们最关心的问题。马云经常讲，我不懂技术，所以我才要发力做云计算，做大数据。相信马总一定因为看到了云计算和大数据的潜在商业价值才做出上述决定的。在各位大佬争相跑马圈地的年代，各大公司都开始占领数据源头，从构建自己线上应用的生态圈入手，将用户的数据牢牢掌握在自己手中，以期望将来能从这些数据中挖掘出“潜在”的商业价值，例如在2014年风生水起的互联网金融行业就是其中典型。请注意，笔者这里专门对大数据的商业价值加上了“潜在”这两字。为什么需要这么关注这个字？其实这跟你的投资回报率非常有关系。</p>\n<p>例如，大家都知道如果你能把新浪微博上的数据都扒拉下来，必然对很多生意都非常有帮助，例如各大电商网站，各大招聘网站等等。但是，你必须考虑清楚构建一个能存储和分析新浪微博数据的大数据平台的成本有多高，而你基于这些数据构建的解决方案能给你创造多大的商业价值。举例来说，电商网站可以通过微博数据进行社交推荐，也可以根据用户正在谈论的关键热词进行针对性的商品需求趋势预测并作针对性的营销。这些用法都很好，都能看到商业价值，可是，最关键的问题在于，如果你知道花五百万搭建整个大数据团队和平台，一年后只能为你的生意带来四百万的增长，你还愿意干这件事情吗？</p>\n<p>这里面牵涉到一个很关键的因素：大数据的价值密度问题。要知道，存储和计算PB级的数据是需要非常高的成本的，大数据虽然看起来很美，但是价值密度却远远低于传统关系型数据库中已经有的那些数据。有一句话笔者很认同：“如果用石油行业来类比大数据分析，那么在互联网金融领域甚至整个互联网行业中，最重要的并不是如何炼油（分析数据），而是如何获得优质原油（优质元数据）”。以股市为例，真正有价值的数据都只会在很小范围内（例如庄家之间）传播，极少可能会流落到互联网上来，所以你如果想去只靠分析微博上网民对股票涨跌的评论来做行情预测的话，真的是要小心了。</p>\n<p>阿里之所以牛气，就因为他掌握了全国上亿网民实名制的历史交易记录，这会成为将来阿里金融帝国最重要的资产。而像“挖财”这样的理财软件，则选择了围魏救赵的策略，用“免费”的噱头积累大量用户的理财数据，以便他日能转换成商业价值。而像雪球，知乎这样的高质量UGC社区，最大的资本也就是在于这些高价值密度的内容所拥有的巨大可能性。当年友盟被高价收购的时候，他们最大的资产也就是来自于他们所掌握的移动互联网领域的高价值数据。笔者愚见，当大家为各种层出不穷的大数据新技术而热血沸腾的同时，一定不要忘记了兄弟们用大数据的初衷，只是为了挖掘更大的商业价值而已。</p>\n<p>回到刚刚提到的阿里巴巴金融数据，微博上的大数据怎么被更高效利用的问题，阿里和微博正在做的就是所谓Big-Data-As-a-Service的服务，所以你不需要自建一个专门用来存放淘宝和新浪微博海量数据的平台，产生不必要的成本浪费，而只需要根据自己的需求，直接通过阿里和微博提供的大数据服务的付费和免费接口，去对那些真正能对你产生价值的淘宝、微博数据进行分析，按需付费，实现双赢，甚至多赢。也许到那一天，我们才能真正在大数据的成本和收益之间取得一个很好的平衡，以创造更多的社会价值。</p>\n<p><span style=\"color: #ff0000;\">简而言之，玩大数据的时候，请一定要考虑清楚你所面对的数据的价值密度有多高，归根结底，商业的本质只是希望通过大数据挖掘更多的商业价值，仅此而已。</span></p>\n","descriptionType":"html","publishedDate":"Sat, 03 May 2014 08:47:40 +0000","feedId":9852,"bgimg":"","linkMd5":"bab1d409311cfb88fc20299f8ed75522","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"为什么NoSQL和Hadoop该一起使用？","link":"http://www.parallellabs.com/?p=1220","description":"<p>Cloudera和CouchBase最近以“为什么NoSQL和Hadoop该一起使用？”为题做了个主题分享，其中对传统IT架构和Big Data架构做了很好的对比，很值得一看。</p>\n<div style=\"width:595px\" id=\"__ss_12947682\"> <strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/cloudera/why-every-no-sql-deployment-should-be-paired-with-hadoop-webinar\" title=\"Why Every NoSQL Deployment Should Be Paired with Hadoop Webinar\" target=\"_blank\">Why Every NoSQL Deployment Should Be Paired with Hadoop Webinar</a></strong> <iframe src=\"http://www.slideshare.net/slideshow/embed_code/12947682\" width=\"595\" height=\"497\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe> </p>\n<div style=\"padding:5px 0 12px\"> View more <a href=\"http://www.slideshare.net/\" target=\"_blank\">presentations</a> from <a href=\"http://www.slideshare.net/cloudera\" target=\"_blank\">Cloudera, Inc.</a> </div>\n</p></div>\n","descriptionType":"html","publishedDate":"Thu, 17 May 2012 02:54:22 +0000","feedId":9852,"bgimg":"","linkMd5":"4928f21448c48e6de1620a3b0e28c855","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Druid 6th Meetup资料下载","link":"http://www.parallellabs.com/?p=1540","description":"<p>Druid 6th Meetup资料下载：链接: https://pan.baidu.com/s/1gfvgtHEFb09_b4J2ef7BXg 提取码: x4av</p>\n","descriptionType":"html","publishedDate":"Mon, 18 Mar 2019 09:40:29 +0000","feedId":9852,"bgimg":"","linkMd5":"eb63ae70e9c711cb1b5ff2b72e89fe12","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Impala与Stinger对比","link":"http://www.parallellabs.com/?p=1386","description":"<p>Tez和Impala现在竞争非常激烈，前者走的是基于DAG的精细化管理，后者是基于MPP的技术架构重头开始造了一个C++版本的SQL引擎。截止到2013年7月，Hortonworks的Stinger（Hive 0.11 + Tez）还是比Impala慢不少，毕竟Impala的动作更早一些。Hortonworks跟Cloudera这场硬仗干的真是激烈啊。</p>\n<p>与大家分享三个演讲（墙外），一个是Impala与Stinger的对比，一个是Stinger的核心-Tez的介绍，一个是Impala跟微策略合作的情况。</p>\n<p><iframe src=\"http://www.slideshare.net/slideshow/embed_code/24391774?rel=0\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe> </p>\n<div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/cloudera/impala-v1update130709222849phpapp01\" title=\"Cloudera Impala Overview (via Scott Leberknight)\" target=\"_blank\">Cloudera Impala Overview (via Scott Leberknight)</a> </strong> from <strong><a href=\"http://www.slideshare.net/cloudera\" target=\"_blank\">Cloudera, Inc.</a></strong> </div>\n<p><iframe src=\"http://www.slideshare.net/slideshow/embed_code/24065492\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe> </p>\n<div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/Hadoop_Summit/murhty-saha-june26255pmroom212\" title=\"Apache Tez: Accelerating Hadoop Query Processing \" target=\"_blank\">Apache Tez: Accelerating Hadoop Query Processing </a> </strong> from <strong><a href=\"http://www.slideshare.net/Hadoop_Summit\" target=\"_blank\">Hadoop_Summit</a></strong> </div>\n<p><iframe src=\"http://www.slideshare.net/slideshow/embed_code/21793932?rel=0\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe> </p>\n<div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/cloudera/2013-0523-impala-and-mstr-webinar-1\" title=\"Impala Unlocks Interactive BI on Hadoop\" target=\"_blank\">Impala Unlocks Interactive BI on Hadoop</a> </strong> from <strong><a href=\"http://www.slideshare.net/cloudera\" target=\"_blank\">Cloudera, Inc.</a></strong> </div>\n","descriptionType":"html","publishedDate":"Thu, 01 Aug 2013 00:31:27 +0000","feedId":9852,"bgimg":"","linkMd5":"03b7ff07773a614d23bb67e7040dce0c","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"你好，2011！","link":"http://www.parallellabs.com/?p=1024","description":"<h2>2010年总结</h2>\n<p><strong>爱人。</strong>在08年8月24日踏上去瑞典的飞机时我曾跟我的女友说：“宝贝，你放心，等我回来”。今年我最大的成就之一就是实现了两年前的诺言。</p>\n<p><strong>家人。</strong>在暑假时我抽时间跟家人完成了一次欧洲游。“活在当下”是《追逐日光》作者的一句感慨，不要等到已经失去与你所爱的人相处的机会时再去后悔。</p>\n<p><strong>研究。</strong>10年大部分时间都用来做研究了。我非常庆幸能有机会与我的导师Per Stenström一起共事，从他身上我学到了非常非常多的东西，是他帮助我找到了自己的兴趣和方向，他给我的<a href=\"http://www.parallellabs.com/2010/10/27/steve-jobs-talked-in-stanford-2005/\">那句寄语</a>更是让我终生受益。临别之际我跟他说，“现在我因你而骄傲，将来我一定努力使你因我而自豪。”</p>\n<p>2010年最有感触的一句话：&#8221;仰望星空与脚踏实地&#8221;。前者提醒我想成为的是一个对社会有用的人；后者提醒我在特定的环境下该如何把事情做好。</p>\n<h2>2011年计划</h2>\n<p><strong>自修。</strong>希望能全方面提升自己的修养。</p>\n<p><strong>研究。</strong>希望能发一篇顶级Paper。现在正在冲刺ICS。</p>\n<p><strong>工作。</strong>希望能在北京找到一份让我感到Exciting的工作，牛同事越多越好。</p>\n<p><strong>编程。</strong>希望今年至少能写三万行代码。</p>\n<p><strong>交际。</strong>希望能参加更多的线下聚会，认识更多的朋友。</p>\n<p><strong>读书。</strong>希望能读完12本书，至少3本非技术的。</p>\n<p><strong>博客。</strong>希望能写24篇博客。其实我觉得我写Wiki的形式更好，因为我的博客都很长。</p>\n<p><strong>锻炼。</strong>希望每周能锻炼一次。</p>\n<p><strong>效率。</strong>希望能全方面提升自己的个人效率。</p>\n<p><strong>感情，亲情。</strong>放在心中。</p>\n<p>2011年的箴言：&#8221;Stay Hungry，Stay Foolish&#8221;。<br />\n郭去疾先生对这句话的解读我非常喜欢，特此与大家分享：</p>\n<p>“乔布斯说stay hungry，我以为饥渴有三个层次：贪婪、成就动机、好奇心。三者分别关注：瞬间的结果，持续的过程，和远大的未知。三者也恰好对应了三种人：卑劣的投机者，艰辛的攀登者，与幸福的探索者。</p>\n<p>乔布斯说的stay foolish，放在语言环境中（斯坦福毕业典礼），我觉得很有针对性的，是特别说给这些所谓名校毕业生听的，因为他们比较容易持才放旷，不可一世，或者投机取巧，追求捷径。翻译成中文，就是：切不要聪明反被聪明误。”</p>\n<p>祝大家新年里幸福，平安，健康，开心！</p>\n","descriptionType":"html","publishedDate":"Sat, 01 Jan 2011 06:47:28 +0000","feedId":9852,"bgimg":"","linkMd5":"ecceabcab99545db7a5d58ebc8f4781c","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"《程序员的自我修养》中关于加锁不能保证线程安全的一个错误","link":"http://www.parallellabs.com/?p=1062","description":"<p>在《程序员的自我修养 &#8212; 链接装载与库》一书第28页“过度优化”这一节中，作者提到了编译器优化可能造成多线程bug的情况（我手中的是09年6月第二次印刷那版）。原文如下：</p>\n<blockquote><p>线程安全是一个非常烫手的山芋，因为即使合理的使用了锁，也不一定能保证线程安全，这是源于落后的编译器技术已经无法满足日益增长的并发需求。很多看似无错的代码在优化和并发前又产生了麻烦。最简单的例子，让我们看看如下代码：</p>\n<p>x = 0;<br />\nThread 1        Thread 2<br />\nlock();           lock();<br />\nx++;             x++;<br />\nunlock();        unlock();</p>\n<p>由于有lock和unlock的保护，x++的行为不会被并发所破坏，那么x的值似乎必然是2了。然后，如果编译器为了提高x的访问速度，把x放到了某个寄存器里，那么我们知道不同线程的寄存器是各自独立的，因此如果Thread 1先获得锁，则程序的执行可能会呈现如下的执行情况：</p>\n<p>*1 Thread 1：读取x的值到某个寄存器R[1] （R[1]=0）<br />\n*2 Thread 1：R[1]++<br />\n*3 Thread 2：读取x的值到某个寄存器R[2] （R[2]=0）<br />\n*4 Thread 2：R[2]++<br />\n*5 Thread 2：将R[2]写回至x（x=1）<br />\n*6 Thread 1：（很久以后）将R[1]写回至x（x=1）</p>\n<p>可见在这样的情况下即使正确的加锁，也不能保证多线程安全。</p></blockquote>\n<p>这个“加锁后仍不能保证线程安全”的结论其实是错误的。在对一段代码进行加锁操作之后，被锁保护起来的代码就形成了一个临界区，在任何时刻最多只能有一个线程运行这个临界区中的代码，而其他的线程必须等待（例如<a href=\"http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/\" target=\"“_blank”\">pthread_mutex_lock是阻塞型等待，pthread_spin_lock是忙等待</a>）。给临界区加锁之后相当于给临界区内的代码添加了原子性的语义。</p>\n<p>既然加锁之后临界区内的代码是原子操作的，那么就不可能出现《程》中描述的那种执行顺序，因为Thread 2必须要等到Thread 1执行完x++和unlock()之后才能获得锁并随即进行x++操作。即如下所述的执行顺序：</p>\n<p>*1 Thread 1：lock()<br />\n*2 Thread 1：读取x的值到某个寄存器R[1] （R[1]=0）<br />\n*3 Thread 1：R[1]++<br />\n*4 Thread 1：将R[1]写回至x（x=1）<br />\n*5 Thread 1：unlock()<br />\n*6 Thread 2：lock() //得到锁<br />\n*7 Thread 2：读取x的值到某个寄存器R[2] （R[2]=1）<br />\n*8 Thread 2：R[2]++<br />\n*9 Thread 2：将R[2]写回至x（x=2）<br />\n*10 Thread 2：unlock()</p>\n<p>其实，这里更值得讨论的一个问题是memory visibility（内存可见性）。例如，在Thread 1将R[1]的值写回至x的这一步中，如果Thread 1只是将值放到了这个CPU核的write buffer（write buffer是多核CPU中为于优化写性能的一种硬件）里，而未将最新值直接更新至内存，那么处在另一个CPU核上的Thread 2真的有可能在第7步时读到的是x的旧值0，这下该怎么办？这个问题其实就是共享变量的值何时能被其他线程可见的问题。</p>\n<p>好在正是因为内存可见性在共享内存的并行编程中如此的重要，所以以pthread为代表的线程库早就规定好了自己的内存模型，其中就包括了memory visibility的定义：</p>\n<p>Memory Visibility<br />\n&#8211; When will changes of shared data be visible to other threads?<br />\n&#8211; Pthreads standard guarantees basic memory visibility rules<br />\n» thread creation<br />\n• memory state before calling pthread_create(&#8230;) is visible to created thread<br />\n» mutex unlocking (also combined with condition variables)<br />\n• memory state before unlocking a mutex is visible to thread which locks same mutex<br />\n» thread termination (i.e. entering state “terminated”)<br />\n• memory state before termination is visible to thread which joins with terminated thread<br />\n» condition variables<br />\n• memory state before notifying waiting threads is visible to woke up threads</p>\n<p>说简单点，Pthreads线程库帮程序员保证了pthread mutex（spin lock也一样）所保护的临界区内共享变量的可见性：即Thread 1一执行完unlock()，x的最新值1一定能被Thread 2看见。（为了实现这一点，Pthreads线程库在实现的时候都会根据相应的硬件平台调用相应的memory barrier来保证内存可见性，感兴趣的同学可以看看nptl的实现）</p>\n<p>所以，只要正确的用锁保护好你的共享变量，你的程序就会是线程安全的。《程》中所给出的上述例子其实是错误的。</p>\n<p>PS.《程》确实是本好书，作者作为我的同龄人功力还是令人钦佩的。但是这个例子也反映了一个现实：写书最怕的就是出现重大的原则性错误，而博客作为互联网上的公开资源，能更容易的吸收大家的修改意见，保证文章的正确性。</p>\n<p>参考文献：<br />\n<a href=\"http://book.douban.com/subject/1941123/\" target=\"_blank\">[1] Programming with POSIX Threads</a><br />\n<a href=\"http://www.domaigne.com/blog/computing/mutex-and-memory-visibility/\" target=\"_blank\">[2] Mutex and Memory Visibility</a></p>\n","descriptionType":"html","publishedDate":"Sat, 09 Apr 2011 00:49:16 +0000","feedId":9852,"bgimg":"","linkMd5":"c3f0f00a72a336ee135cc04433b7da72","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多线程程序常见Bug剖析（下）","link":"http://www.parallellabs.com/?p=829","description":"<p><a href=\"http://www.parallellabs.com/2010/11/13/concurrency-bugs-1/\" target=\"_blank\">上一篇文章</a>我们专门针对违反原子性（Atomicity Violation）的多线程程序Bug做了剖析，现在我们再来看看另一种常见的多线程程序Bug：违反执行顺序（Ordering Violation）。</p>\n<p>简单来说，多线程程序各个线程之间交错执行的顺序的不确定性（Non-deterministic）是造成违反执行顺序Bug的根源[注1]。正是因为这个原因，程序员在编写多线程程序时就不能假设程序会按照你设想的某个顺序去执行，而是应该充分考虑到各种可能的顺序组合，从而采取正确的同步措施。</p>\n<h3>1. 违反执行顺序（Ordering Violation）</h3>\n<p>举例来说，下面这个来自Mozilla的多线程Bug产生的原因就是程序员错误地假设S1一定会在S2之前执行完毕，即在S2访问mThread之前S1一定已经完成了对mThread的初始化（因为线程2是由线程1创建的）。事实上线程2完全有可能执行的很快，而且S1这个初始化操作又不是原子的（因为需要几个时钟周期才能结束），从而在线程1完成初始化（即S1）之前就已经运行到S2从而导致Bug。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n例1：\n    Thread 1                                 Thread 2\nvoid init(...)                           void mMain(...)\n{ ...                                    { ...\n S1: mThread=                              ...\n      PR_CreateThread(mMain, ...);         S2: mState = mThread-&#62;State;\n  ...                                      ...\n}                                        }\n</pre>\n<p>上面这个例子是一个线程读一个线程写的情况，除此之外还有违反写-写顺序以及违反一组读写顺序的情况。例如下面这个程序，程序员错误的以为S2（写操作）一定会在S4（也是写操作）之前执行。但是实际上这个程序完全有可能先执行S4后执行S2，从而导致线程1一直hang在S3处：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n例2：\n    Thread 1                                 Thread 2\nint ReadWriteProc(...)                   void DoneWaiting(...)\n{                                        {\n  ...                                     /*callback func of PBReadAsync*/\n S1: PBReadAsync(&#38;p);\n S2: io_pending = TRUE;                   ...\n  ...                                     S4: io_pending = FALSE;\n S3: while (io_pending) {...}             ...\n  ...                                    }\n}\n</pre>\n<p>下面这个是违反一组读写操作顺序的例子：程序员假设S2一定会在S1之前执行，但是事实上可能S1在S2之前执行，从而导致程序crash。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n例3：\n    Thread 1                                 Thread 2\nvoid js_DestroyContext(...){             void js_DestroyContext(...){\n  /* last one entering this func */      /* non-last one entering this func */\n  S1: js_UnpinPinnedAtom(&#38;atoms);          S2: js_MarkAtom(&#38;atoms,...);\n}                                        }\n</pre>\n<p>调试违反执行顺序这种类型的Bug最困难的地方就在只有某几种执行顺序才会引发Bug，这大大降低了Bug重现的几率。最简单的调试手段自然是使用printf了，但是类似printf这样的函数会干扰程序的执行顺序，所以有可能违反执行顺序的Bug更难产生了。我所知道的目前最领先的商业多线程Debugger是Corensic的<a href=\"http://www.corensic.com\" target=\"_blank\">Jinx</a>，他们的技术核心是用Hypervisor来控制线程的执行顺序以找出可能产生Bug的那些特定的执行顺序（学生、开源项目可以申请免费使用，Windows/Linux版均有）。八卦一下，这个公司是从U of Washington发展出来的，他们现在做的Deterministic Parallelism是最热门的方向之一。</p>\n<h3>2. Ordering Violation的解决方案</h3>\n<p>常见的解决方案主要有四种：<br />\n（1）加锁进行同步<br />\n加锁的目的就在于保证被锁住的操作的原子性，从而这些被锁住的操作就不会被别的线程的操作打断，在一定程度上保证了所需要的执行顺序。例如上面第二个例子可以给{S1,S2}一起加上锁，这样就不会出现S4打断S1,S2的情况了（即S1->S4->S2），因为S4是由S1引发的异步调用，S4肯定会在{S1,S2}这个原子操作执行完之后才能被运行。</p>\n<p>（2）进行条件检查<br />\n进行条件检查是另一种常见的解决方案，关键就在于通过额外的条件语句来迫使该程序会按照你所想的方式执行。例如下面这个例子就会对n的值进行检查：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n例4：\nretry:\n  n = block-&#62;n;\n  ...\n  ...\n  if (n!=block-&#62;n)\n  {\n    goto retry;\n  }\n  ...\n</pre>\n<p>（3）调整代码执行顺序<br />\n这个也是很可行的方案，例如上面的例2不需要给{S1,S2}加锁，而是直接调换S2与S1的顺序，这样S2就一定会在S4之前执行了！</p>\n<p>（4）重新设计算法/数据结构<br />\n还有一些执行顺序的问题可以通过重新设计算法/数据结构来解决。这个就得具体情况具体分析了。例如MySQL的bug #7209中，一个共享变量HASH::current_record的访问有顺序上的冲突，但是实际上这个变量不需要共享，所以最后的解决办法就是线程私有化这个变量。</p>\n<h3>3. 总结</h3>\n<p>多线程Bug确实是个非常让人头痛的问题。写多线程程序不难，难的在于写正确的多线程程序。多线程的debug现在仍然可以作为CS Top10学校的博士论文题目。在看过这两篇分析多线程常见Bug的文章之后，不知道各位同学有没有什么关于多线程Bug的经历与大家分享呢？欢迎大家留言:)</p>\n<p>需要注意的是，违反执行顺序和违反原子性这两种Bug虽然是相互独立的，但是两者又有着潜在的联系。例如，上一篇文章中我所讲到的第一个违反原子性的例子其实是因为执行顺序的不确定性造成的，而本文的第二个例子就可以通过把{S1,S2}加锁保证原子性来保证想要的执行顺序。</p>\n<h3>参考</h3>\n<p>[1] <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.1203\" target=\"_blank\">Learning from Mistakes – A Comprehensive Study on Real World Concurrency Bug Characteristics</a><br />\n[2] <a href=\"https://www.ideals.illinois.edu/handle/2142/10865\" target=\"_blank\">Understanding, Detecting and Exposing Concurrency Bugs</a><br />\n[3] <a href=\"http://ppcp.codeplex.com/\" target=\"_blank\">Practical Parallel and Concurrent Programming</a><br />\n[4] <a href=\"http://www.ibm.com/developerworks/java/library/j-concurrencybugpatterns/index.html\">Java concurrency bug patterns for multicore systems</a></p>\n<p>注1：严格来讲，多线程交错执行顺序的不确定性只是违反执行顺序Bug的原因之一。另一个可能造成违反执行顺序Bug的原因是编译器/CPU对代码做出的违反多线程程序语义的乱序优化，这种“错误的优化”直接引出了编程语言的内存模型（memory model）这个关键概念。后面我会专门分析下C++与Java的内存模型，敬请期待。</p>\n","descriptionType":"html","publishedDate":"Tue, 23 Nov 2010 00:27:31 +0000","feedId":9852,"bgimg":"","linkMd5":"226376dfa29a6b3edd08c3edef24385f","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多线程程序中操作的原子性","link":"http://www.parallellabs.com/?p=469","description":"<h3><span style=\"color: #000000;\">0. 背景</span></h3>\n<p><a id=\"mpkc\" style=\"color: #551a8b;\" title=\"原子操作\" href=\"http://en.wikipedia.org/wiki/Atomic_operation\">原子操作</a>就是不可再分的操作。在多线程程序中原子操作是一个非常重要的概念，它常常用来实现一些同步机制，同时也是一些常见的多线程Bug的源头。本文主要讨论了三个问题：1. 多线程程序中对变量的读写操作是否是原子的？2. 多线程程序中对Bit field（位域）的读写操作是否是线程安全的？3. 程序员该如何使用原子操作？</p>\n<h3><span style=\"color: #000000;\">1. 多线程环境下对变量的读写操作是否是原子的？</span></h3>\n<p>我们先从一道很热门的百度笔试题讲起。很多人讲不清楚其背后的原理，下面我们就来对它进行一下剖析（其实这个题目有点歧义，后面我们会讲到）：</p>\n<blockquote><p>以下多线程对int型变量x的操作，哪几个需要进行同步：（ ）<br />\nA. x=y; B. x++; C. ++x; D. x=1;</p></blockquote>\n<p>要彻底理解这个问题，我们首先需要从硬件讲起。以常见的X86 CPU来说，根据Intel的<a id=\"pvf3\" style=\"color: #551a8b;\" title=\"参考手册\" href=\"http://download.intel.com/design/processor/manuals/253668.pdf\">参考手册</a>，它基于以下三种机制保证了多核中加锁的原子操作（8.1节）：<br />\n（1）Guaranteed atomic operations （注：8.1.1节有详细介绍）<br />\n（2）Bus locking, using the LOCK# signal and the LOCK instruction prefix<br />\n（3）Cache coherency protocols that ensure that atomic operations can be carried out on cached data structures (cache lock); this mechanism is present in the Pentium 4, Intel Xeon, and P6 family processors</p>\n<p>这三个机制相互独立，相辅相承。简单的理解起来就是<br />\n（1）一些基本的内存读写操作是本身已经被硬件提供了原子性保证（例如读写单个字节的操作）；<br />\n（2）一些需要保证原子性但是没有被第（1）条机制提供支持的操作（例如read-modify-write）可以通过使用&#8221;LOCK#&#8221;来锁定总线，从而保证操作的原子性<br />\n（3）因为很多内存数据是已经存放在L1/L2 cache中了，对这些数据的原子操作只需要与本地的cache打交道，而不需要与总线打交道，所以CPU就提供了cache coherency机制来保证其它的那些也cache了这些数据的processor能读到最新的值（关于cache coherency可以参加我的<a id=\"prz.\" style=\"color: #551a8b;\" title=\"一篇博文\" href=\"http://www.parallellabs.com/2010/03/06/why-should-programmer-care-about-sequential-consistency-rather-than-cache-coherence/\">一篇博文</a>）。</p>\n<p>那么CPU对哪些（1）中的基本的操作提供了原子性支持呢？根据Intel手册8.1.1节的介绍：</p>\n<p>从Intel486 processor开始，以下的基本内存操作是原子的：<br />\n• Reading or writing a byte（一个字节的读写）<br />\n• Reading or writing a word aligned on a 16-bit boundary（对齐到16位边界的字的读写）<br />\n• Reading or writing a doubleword aligned on a 32-bit boundary（对齐到32位边界的双字的读写）</p>\n<p>从Pentium processor开始，除了之前支持的原子操作外又新增了以下原子操作：<br />\n• Reading or writing a quadword aligned on a 64-bit boundary（对齐到64位边界的四字的读写）<br />\n• 16-bit accesses to uncached memory locations that fit within a 32-bit data bus（未缓存且在32位数据总线范围之内的内存地址的访问）</p>\n<p>从P6 family processors开始，除了之前支持的原子操作又新增了以下原子操作：<br />\n• Unaligned 16-, 32-, and 64-bit accesses to cached memory that fit within a cache line（对单个cache line中缓存地址的未对齐的16/32/64位访问）</p>\n<p>那么哪些操作是非原子的呢？<br />\nAccesses to cacheable memory that are split across bus widths, cache lines, and<br />\npage boundaries are not guaranteed to be atomic by the Intel Core 2 Duo, Intel®<br />\nAtom<img src=\"https://s.w.org/images/core/emoji/11.2.0/72x72/2122.png\" alt=\"™\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" />, Intel Core Duo, Pentium M, Pentium 4, Intel Xeon, P6 family, Pentium, and<br />\nIntel486 processors.（说点简单点，那些被总线带宽、cache line以及page大小给分隔开了的内存地址的访问不是原子的，你如果想保证这些操作是原子的，你就得求助于机制（2），对总线发出相应的控制信号才行）。</p>\n<p>需要注意的是尽管从P6 family开始对一些非对齐的读写操作已经提供了原子性保障，但是非对齐访问是非常影响性能的，需要尽量避免。当然了，对于一般的程序员来说不需要太担心这个，因为大部分编译器会自动帮你完成内存对齐。</p>\n<p>回到最开始那个笔试题。我们先反汇编一下看看它们到底执行了什么操作：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nx = y;\nmov eax,dword ptr [y]\nmov dword ptr [x],eax\n\nx++;\nmov eax,dword ptr [x]\nadd eax,1\nmov dword ptr [x],eax\n\n++x;\nmov eax,dword ptr [x]\nadd eax,1\nmov dword ptr [x],eax\n\nx = 1;\nmov dword ptr [x],1\n</pre>\n<p>（1）很显然，x=1是原子操作。<br />\n因为x是int类型，32位CPU上int占32位，在X86上由硬件直接提供了原子性支持。实际上不管有多少个线程同时执行类似x=1这样的赋值语句，x的值最终还是被赋的值（而不会出现例如某个线程只更新了x的低16位然后被阻塞，另一个线程紧接着又更新了x的低24位然后又被阻塞，从而出现x的值被损坏了的情况）。</p>\n<p>（2）再来看x++和++x。<br />\n其实类似x++, x+=2, ++x这样的操作在多线程环境下是需要同步的。因为X86会按三条指令的形式来处理这种语句：从内存中读x的值到寄存器中，对寄存器加1，再把新值写回x所处的内存地址（见上面的反汇编代码）。</p>\n<p>例如有两个线程，它们按照如下顺序执行（注意读x和写回x是原子操作，两个线程不能同时执行）：</p>\n<p>time    Thread 1         Thread 2<br />\n0      load eax, x<br />\n1                            load eax, x<br />\n2      add eax, 1        add eax, 1<br />\n3      store x, eax<br />\n4                            store x, eax</p>\n<p>我们会发现最终x的值会是1而不是2，因为Thread 1的结果被覆盖掉了。这种情况下我们就需要对x++这样的操作加锁（例如Pthread中的mutex）以保证同步，或者使用一些提供了atomic operations的库（例如Windows API中的<a id=\"w3tu\" style=\"color: #551a8b;\" title=\"atomic库\" href=\"http://msdn.microsoft.com/en-us/library/ms686360(VS.85).aspx\">atomic库</a>，Linux内核中的<a id=\"jbi8\" style=\"color: #551a8b;\" title=\"atomic.h\" href=\"http://lxr.linux.no/linux+v2.6.26.5/include/asm-x86/atomic_32.h\">atomic.h</a>，Java concurrent库中的Atomic Integer，C++0x中即将支持的atomic_int等等，这些库会利用CPU提供的硬件机制做一层封装，提供一些保证了原子性的API）。</p>\n<p>（3）最后来看看x=y。<br />\n在X86上它包含两个操作：读取y至寄存器，再把该值写入x。读y的值这个操作本身是原子的，把值写入x也是原子的，但是两者合起来是不是原子操作呢？我个人认为x=y不是原子操作，因为它不是不可再分的操作。但是它需要不需要同步呢？其实问题的关键在于程序的上下文。</p>\n<p>例如有两个线程，线程1要执行{y = 1; x = y;}，线程2要执行{y = 2; y = 3;}，假设它们按如下时间顺序执行：</p>\n<p>time    Thread 1        Thread 2<br />\n0        store y, 1<br />\n1                            store y, 2<br />\n2        load eax, y<br />\n3                            store y, 3<br />\n4        store x, eax</p>\n<p>那么最终线程1中x的值为2，而不是它原本想要的1。我们需要加上相应的同步语句确保y = 2不会在线程1的两条语句之间发生。y = 3那条语句尽管在load y和store x之间执行，但是却不影响x=y这条语句本身的语义。所以你可以说x=y需要同步，也可以说x=y不需要同步，看你怎么理解题意了。x=1是否需要同步也是一样的道理，虽然它本身是原子操作，但是如果有另一个线程要读x=1之后的值，那肯定也需要同步，否则另一个线程读到的就是x的旧值而不是1了。</p>\n<h3><span style=\"color: #000000;\">2. 对Bit field（位域）的读写操作是否是线程安全的？</span></h3>\n<p><a id=\"spoi\" style=\"color: #551a8b;\" title=\"Bit field\" href=\"http://learn.akae.cn/media/ch19s04.html\">Bit field</a>常用来高效的存储有限位数的变量，多用于内核/底层开发中。一般来说，对同一个结构体内的不同bit成员的多线程访问是无法保证线程安全的。</p>\n<p>例如<a id=\"s:v.\" style=\"color: #551a8b;\" title=\"WikiPedia\" href=\"http://en.wikipedia.org/wiki/Bit_field\">Wikipedia</a>中的如下例子：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nstruct foo {\n    int flag : 1;\n    int counter : 15;\n};\n\nstruct foo my_foo;\n\n/* ... */\n\n/* in thread 1 */\n\npthread_mutex_lock(&#38;my_mutex_for_flag);\nmy_foo.flag = !my_foo.flag;\npthread_mutex_unlock(&#38;my_mutex_for_flag);\n\n/* in thread 2 */\n\npthread_mutex_lock(&#38;my_mutex_for_counter);\n++my_foo.counter;\npthread_mutex_unlock(&#38;my_mutex_for_counter);\n</pre>\n<p>两个线程分别对my_foo.flag和my_foo.counter进行读写操作，但是即使有上面的加锁方式仍然不能保证它是线程安全的。原因在于不同的成员在内存中的具体排列方式“跟Byte Order、Bit Order、对齐等问题都有关，不同的平台和编译器可能会排列得很不一样，要编写可移植的代码就不能假定Bit-field是按某一种固定方式排列的”[3]。而且一般来讲CPU对内存操作的最小单位是<a id=\"mmki\" style=\"color: #551a8b;\" title=\"word\" href=\"http://en.wikipedia.org/wiki/Word_length\">word</a>（X86的word是16bits），而不是1bit。这就是说，如果my_foo.flag和my_foo.counter存储在同一个word里，CPU在读写任何一个bit member的时候会同时把两个值一起读进寄存器，从而造成读写冲突。这个例子正确的处理方式是用一个mutex同时保护my_foo.flag和my_foo.counter，这样才能确保读写是线程安全的。</p>\n<p>在<a id=\"k.sc\" style=\"color: #551a8b;\" title=\"C++0x草案\" href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3092.pdf\">C++0x草案</a>中对bit field是这样定义的：<br />\n连续的多个非0bit的bit fields是属于同一个memory location的；长度为0bit的bit field会把占单独的一个memory location。对同一个memory location的读写不是线程安全的；对不同memory location的读写是线程安全的。<br />\n例如在下图的例子中bf1和bf2是同一个memory location，bf3是一个单独的memory location，bf4是一个单独的memory location：<br />\n<img class=\"size-full wp-image-508 alignnone\" title=\"bit field\" src=\"http://www.parallellabs.com/wp-content/uploads/2010/04/bitfield.JPG\" alt=\"bit field\" width=\"525\" height=\"388\" /></p>\n<p>这里有一个因为Bit field不是线程安全所导致的一个Linux内核中的<a id=\"bq8v\" style=\"color: #551a8b;\" title=\"bug\" href=\"http://lkml.indiana.edu/hypermail/linux/kernel/0810.1/0828.html\">Bug</a>。</p>\n<p>引用一下Pongba的<a id=\"m40.\" style=\"color: #551a8b;\" title=\"总结\" href=\"http://www.newsmth.net/bbscon.php?bid=335&#38;id=186723\">总结</a>：</p>\n<blockquote><p>所以，如果你的多个bitfields是连续的，同时又想要无冲突的读取它们，有两种做法，一是在中间用0大小bitfield隔开，但这种做法实际上就消除了bitfield的节省内存的初衷，因为为了使它们不冲突，至少被隔开的两个bitfield肯定不可能共享byte了。另一种做法当然就是用锁了。</p></blockquote>\n<h3><span style=\"color: #000000;\">3. 程序员该怎么用Atomic操作？</span></h3>\n<p>一般情况下程序员不需要跟CPU提供的原子操作直接打交道，所以只需要选择语言或者平台提供的atomic API即可。而且使用封装好了的API还有一个好处是它们常常还提供了诸如compare_and_swap，fetch_and_add这样既有读又有写的较复杂操作的封装。</p>\n<p>常见的API如下：</p>\n<p>Windows上<a id=\"fuwa\" style=\"color: #551a8b;\" title=\"InterlockedXXXX\" href=\"http://msdn.microsoft.com/en-us/library/ms686360(VS.85).aspx\">InterlockedXXXX</a>的API<br />\nGNU/Linux上linux kernel中<a id=\"k6en\" style=\"color: #551a8b;\" title=\"atomic_32.h\" href=\"http://lxr.linux.no/linux+v2.6.26.5/include/asm-x86/atomic_32.h\">atomic_32.h</a><br />\nGCC中的<a style=\"color: #551a8b;\" href=\"http://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Atomic-Builtins.html\">Atomic Builtins</a> (__sync_fetch_and_add()等)<br />\nJava中的java.util.concurrent.atomic<br />\nC++0x中的<a style=\"color: #551a8b;\" href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3092.pdf\">atomic operation</a><br />\nIntel TBB中的<a style=\"color: #551a8b;\" href=\"http://software.intel.com/en-us/blogs/2007/09/12/threading-building-blocks-atomic-operations-introduction/\">atomic operation</a></p>\n<h3><span style=\"color: #000000;\">4. 参考文献：</span></h3>\n<p>[1] <a style=\"color: #551a8b;\" title=\"关于变量操作的原子性(atomicity)FAQ\" href=\"http://www.newsmth.net/bbstcon.php?board=CPlusPlus&#38;gid=236548\">关于变量操作的原子性(atomicity)FAQ</a><br />\n[2] <a style=\"color: #551a8b;\" href=\"http://en.wikipedia.org/wiki/Atomic_operation\">http://en.wikipedia.org/wiki/Atomic_operation</a><br />\n[3] <a style=\"color: #551a8b;\" title=\"关于内存对齐、bit field等\" href=\"http://learn.akae.cn/media/ch19s04.html\">关于内存对齐、bit field等 &#8211;《Linux C编程一站式学习》</a><br />\n[4] <a style=\"color: #551a8b;\" href=\"http://www.alexonlinux.com/do-you-need-mutex-to-protect-int\">Do you need mutex to protect an &#8216;int&#8217;?</a><br />\n[5] <a style=\"color: #551a8b;\" href=\"http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770/ref=sr_1_1?ie=UTF8&#38;s=books&#38;qid=1272232877&#38;sr=8-1\">C++ Concurrency in Action</a><br />\n[6] <a style=\"color: #551a8b;\" href=\"http://www.alexonlinux.com/multithreaded-simple-data-type-access-and-atomic-variables\">Multithreaded simple data type access and atomic variables</a><br />\n<span style=\"color: #ffffff;\">[6] http://www.newsmth.net/bbscon.php?bid=335&#38;id=236629</span><span style=\"color: #ffffff;\"><br />\n[7] </span><span style=\"color: #ffffff;\">http://www.newsmth.net/bbscon.php?bid=335&#38;id=209239</span><span style=\"color: #ffffff;\"><br />\n[8] </span><span style=\"color: #ffffff;\">http://www.newsmth.net/bbscon.php?bid=335&#38;id=186723</span><br />\n<span style=\"color: #ffffff;\">转载请注明来自</span><a href=\"http://www.parallellabs.com\" target=\"_blank\"><span style=\"color: #ffffff;\">parallellabs.com</span></a></p>\n","descriptionType":"html","publishedDate":"Thu, 15 Apr 2010 15:49:10 +0000","feedId":9852,"bgimg":"https://s.w.org/images/core/emoji/11.2.0/72x72/2122.png","linkMd5":"71f657713d66e35cb0482207a5f8c78b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn3@2020_5/2020/08/25/00-37-02-029_2b6f91e88d5f6d66.webp","destWidth":72,"destHeight":72,"sourceBytes":613,"destBytes":1242,"author":"Guancheng (G.C.)","articleImgCdnMap":{"https://s.w.org/images/core/emoji/11.2.0/72x72/2122.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn3@2020_5/2020/08/25/00-37-02-029_2b6f91e88d5f6d66.webp","http://www.parallellabs.com/wp-content/uploads/2010/04/bitfield.JPG":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn51@2020_4/2020/08/25/00-37-10-777_040a5e3b979ba680.webp"},"publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Jeff Dean关于Google系统架构的讲座","link":"http://www.parallellabs.com/?p=900","description":"<p>上个月Jeff Dean在Standford的<a href=\"http://www.stanford.edu/class/ee380/\" target=\"_blank\">Computer Systems Colloquium (EE380)</a>这门讨论课上详细讲了讲Google的系统架构发展过程，因为这是份很新的资料，所以特意把它的Slide下下来与大家分享一下。这门课是Standford的讲座课程，每一节课都由不同的顶级工程师/科学家/投资人前来讲授IT行业的最新动向，非常非常有料，绝对值得深挖。这门课的每节课都是带视频的，Jeff Dean的这个讲座的录像在<a href=\"http://ee380.stanford.edu/cgi-bin/videologger.php?target=101110-ee380-300.asx\">这里</a>。想要下载该视频的同学可以去<a href=\"http://www.youtube.com/user/VortexTech#p/u/0/eidc-A4ElmQ\">这里</a>（要会功夫，你懂的）。</p>\n<p>这个讲座的主要内容包括：<br />\n• Evolution of various systems at Google<br />\n– computing hardware<br />\n– core search systems<br />\n– infrastructure software</p>\n<p>• Techniques for building large-scale systems<br />\n– decomposition into services<br />\n– design patterns for performance &#038; reliability</p>\n<p>个人的一点小感想：Jeff Dean在Google的这几年能面临这么多有意思的挑战，编程模型，可靠性，伸缩性，运行时环境等等等等，真是羡煞旁人。随着Google业务的扩展，整个系统的设计也面临各种各样新的挑战。只有有了<a href=\"http://www.parallellabs.com/2010/11/29/erlang-user-conference-2010-and-some-thoughts-on-career-of-programmers/\">扎实的基本功</a>，在面对没有现成解决方案的新问题时才能游刃有余，做工程是如此，做研究更是如此。</p>\n<p>可能有些同学会因为这是个英语的讲座而头疼。我觉得大家可以坚持看，哪个单词看不懂的就查字典，刚开始可能痛苦点，但是只要坚持下去，积少成多，你就会发现自己的英语慢慢就上来了，至少看这些英文slides是没问题了。</p>\n<div style=\"width:538px\" id=\"__ss_5982202\"><strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/parallellabs/building-software-systems-at-google-and-lessons-learned\" title=\"Building Software Systems at Google and Lessons Learned\">Building Software Systems at Google and Lessons Learned</a></strong><object id=\"__sse5982202\" width=\"538\" height=\"450\"><param name=\"movie\" value=\"http://static.slidesharecdn.com/swf/ssplayer2.swf?doc=101110-slides-101130101117-phpapp01&#038;rel=0&#038;stripped_title=building-software-systems-at-google-and-lessons-learned&#038;userName=parallellabs\" /><param name=\"allowFullScreen\" value=\"true\"/><param name=\"allowScriptAccess\" value=\"always\"/><embed name=\"__sse5982202\" src=\"http://static.slidesharecdn.com/swf/ssplayer2.swf?doc=101110-slides-101130101117-phpapp01&#038;rel=0&#038;stripped_title=building-software-systems-at-google-and-lessons-learned&#038;userName=parallellabs\" type=\"application/x-shockwave-flash\" allowscriptaccess=\"always\" allowfullscreen=\"true\" width=\"538\" height=\"450\"></embed></object></p>\n<p>另外还有几个关于Jeff Dean的Google架构的博文：<br />\n<a href=\"http://tiny4.org/prog/diary/2009/03/jeff-dean-wsdm-2009-keynote.html\" target=\"_blank\">Jeff Dean 在WSDM 2009上面的演讲 Keynote 和视频终于出来了</a><br />\n<a href=\"http://peopleyun.com/?p=794\" target=\"_blank\">来自Jeff Dean的分布式系统设计模式（更新版）</a><br />\n<a href=\"http://coolshell.cn/articles/3301.html\" target=\"_blank\">Jeff Dean的Stanford演讲</a></p>\n<p>我还发现了Jeff另外一个在09年做的类似主题的讲座，内容稍有重复，但是可以算是一个补充，例如这个里面包括了BigTable等内容。</p>\n<p>Enjoy！</p>\n<div style=\"width:538px\" id=\"__ss_6010344\"><strong style=\"display:block;margin:12px 0 4px\"><a href=\"http://www.slideshare.net/parallellabs/dean-keynoteladis2009jeffdean\" title=\"Dean keynote-ladis2009-jeff-dean\">Dean keynote-ladis2009-jeff-dean</a></strong><object id=\"__sse6010344\" width=\"538\" height=\"450\"><param name=\"movie\" value=\"http://static.slidesharecdn.com/swf/ssplayer2.swf?doc=dean-keynote-ladis2009-101202152049-phpapp01&#038;rel=0&#038;stripped_title=dean-keynoteladis2009jeffdean&#038;userName=parallellabs\" /><param name=\"allowFullScreen\" value=\"true\"/><param name=\"allowScriptAccess\" value=\"always\"/><embed name=\"__sse6010344\" src=\"http://static.slidesharecdn.com/swf/ssplayer2.swf?doc=dean-keynote-ladis2009-101202152049-phpapp01&#038;rel=0&#038;stripped_title=dean-keynoteladis2009jeffdean&#038;userName=parallellabs\" type=\"application/x-shockwave-flash\" allowscriptaccess=\"always\" allowfullscreen=\"true\" width=\"538\" height=\"450\"></embed></object>\n</div>\n</div>\n","descriptionType":"html","publishedDate":"Thu, 02 Dec 2010 22:00:28 +0000","feedId":9852,"bgimg":"","linkMd5":"a614e2ab3869dd198b10f443294143d7","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","enclosureType":"video/x-ms-asf","enclosureUrl":"http://ee380.stanford.edu/cgi-bin/videologger.php?target=101110-ee380-300.asx","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Erlang User Conference 2010见闻（兼谈程序员职业生涯）","link":"http://www.parallellabs.com/?p=867","description":"<h2>1. Erlang User Confernece 2010</h2>\n<p>这是我第一次参加关于Erlang的技术大会，总来的说收获非常大，不管是技术上的还是非技术上的都是如此。首先不得不说的是会议举行的地点。我从别人那得知之前的会议一直都是在Ericsson的总部大楼举行的，但是因为参会人数越来越多，好像是从去年开始就转移到市中心一个很有历史的电影院ASTORIA举行了。由于这个举办地是电影院的缘故，从去年开始EUC就开始有电影海报了！去年海报是由哈利波特改的，今年的是星球大战。去年那张如下，有意思吧？</p>\n<p><img src=\"http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie-208x300.jpg\" alt=\"Erlang-the-Movie\" title=\"Erlang-the-Movie\" width=\"208\" height=\"300\" class=\"aligncenter size-medium wp-image-868\" srcset=\"http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie-208x300.jpg 208w, http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie-710x1024.jpg 710w, http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie.jpg 1541w\" sizes=\"(max-width: 208px) 85vw, 208px\" /></p>\n<p>海报上面的四个人是Erlang最早的设计者们：Joe Armstrong, Mike Williams, Robert Virding还有当时的团队经理Bjarne Däcker。有了海报没有电影怎么能行？点这里观看<a href=\"http://v.youku.com/v_show/id_XMTE2OTcxNzE2.html\" target=\"_blank\">Erlang – The Movie</a>。</p>\n<p>因为我赶早乘火车去的斯德，所以我到的时候已经快9点了，大会即将开始。在去之前我就很期待能见到Joe Armstrong本人，结果意外的是在签到处我就见到Joe本人了！不知道为什么，他出现在我面前时的形象与我之前想象的一模一样，后来我想明白了，根本原因在于他穿的就是他那件非常眼熟的紫黑线衫！哈哈！Joe爷爷人非常开朗，时不时从他坐的地方传出爽朗的笑声，此为后话。因为会议即将开始所以我就赶紧进去找座位坐下，正好赶上Bjarne Däcker在致开幕辞，这是每年的传统了。仔细看了下我的签到卡，这已经是第16届Erlang大会了！</p>\n<p><a href=\"http://klarna.se/en/personal\" target=\"_blank\">Klarna</a>无疑是这届大会最吸引眼球的公司。开幕第一个Talk就是关于他们怎么使用Erlang相关的工具来解决他们的CodeManagement，Translation，Testing等问题的。Klarna有两个中国程序员，我见到其中之一的<a href=\"http://www.erlang-factory.com/conference/ErlangUserConference2010/speakers/JiaWong\" target=\"_blank\">Wang Jia</a>。Klarna是由三位瑞典银行家在05年创立的公司，提供第三方电子支付解决方案。他们最早的开发者就是从当时提供Erlang咨询的公司（其实也是Ericsson前员工）跳出来的。传闻说当时创始人提出业务需求后，他们说这个太简单了，用Erlang几天就开发出来了，虽然最后花了大概一个礼拜，但是可见Erlang开发效率之高。现在他们应该是Erlang程序员最多的公司，而且随着业务的增长他们的开发团队也在快速扩张。一年前他们只有20个左右，现在已经解决60人了，听说还要继续招人。Good for them！ 我还见到另一个在Mobile Art做Erlang开发的中国人<a href=\"http://zhang.nu/\" target=\"_blank\">张浩</a>，他已经用Erlang做开发3年多了。我们聊了很多关于职业发展的问题，非常有收获。</p>\n<p>此次大会的slides和talk都可以在<a href=\"http://www.erlang-factory.com/conference/ErlangUserConference2010/talks\" target=\"_blank\">这里下载</a>。</p>\n<h2>2. 关于职业生涯</h2>\n<p>除技术之外我最大的感触就是看见一群爷爷级的人物仍然热衷于参加这样的技术盛会，让我很有编程编到老的冲动。Joe Armstrong老爷子是1950年生的，早年在英国念物理PhD，后来自己钱花光了，就跑去了爱丁堡做人工智能了。他的导师Donald Michie在二战时跟图灵一起工作过，所以收藏有图灵所有的论文。Joe就在满是图灵的论文的办公室里工作了整整一年多，难怪如此之牛。做研究讲究家谱，大师之所以成为大师还是需要一些机缘在里面的（当然，独力开创一片新天地的神牛除外）。关于Joe的更多趣闻可以看<a href=\"http://book.douban.com/subject/3673223/\" target=\"_blank\">《Coders at Works》</a>，中文版应该快出版了，但是如果有条件的话还是推荐大家读英文版，边学大师的经验边学英语，一举两得，岂不快哉？如果大家好奇Joe是怎么修炼到大师级的，他自己一句话很有代表性：“So I would characterize that period, which took 20 years, as learning how to program”。这句话的上下文我就不详述了，简单地说你可以理解成他花了20年学会了如何编程（注意，这个“如何编程”可不是指精通C++之类的）。这说明要想成为大师，没有十几二十年的功力肯定是不行的。<a href=\"http://daiyuwen.freeshell.org/gb/misc/21-days-cn.html\" target=\"_blank\">十年学会编程</a>不是空谈，而是实实在在的。说到程序员的基本功，我必须要站出来批评一下《Coders at Works》此书在豆瓣的一个<a href=\"http://book.douban.com/review/3733680/\" target=\"_blank\">不负责任的书评</a>，这位同学说“去他的算法内功基础，对于程序员实用主义才是王道”，这完全是误人子弟，而且可悲的是这个观点竟然有很多人支持。表面上这句话好像抓住了“实用主义”的大旗，但是这位同学却借此抨击算法基本功的重要性，实在是荒谬。（Update：该同学已经把标题改掉了）就拿Google Fellow Jeff Dean来说，他绝对算得上是实用主义的大师了吧？可是如果你去看看他关于Google整个系统架构演变过程的讲座，你就会发现把Google的那些诸如MapReduce、GFS之类的看家法宝化繁为简之后都可以还原成最基本的算法、数据结构之类的问题。Google整个架构的发展是根据需求的变化而发展而来的，MapReduce之类的不就是在遇到需要解决大规模并行编程这个问题时产生的实用的解决方案吗？可是，<strong>如果没有扎实的基本功它能被设计出来么？哪一个大师不是编程十几二十年以上？他们的基本功可能差么？</strong>想真正成为杰出的程序员，没有扎实的基本功是绝对不可能的，因为你会发现当你需要面对一个没有现成的解决方案的问题时，你的基本功就是最可信赖的法宝。</p>\n<p>我在国内念书时确实也不知道天有多高，国内IT界有多浮躁，到了瑞典之后我有机会在<a href=\"http://www.nemalabs.com\" target=\"_blank\">Nema Labs</a>（创业公司），<a href=\"http://www.ericsson.com\" target=\"_blank\">Ericsson</a>（大公司）实习，跟我的导师<a href=\"http://129.16.20.23/~pers/\" target=\"_blank\">Per Stenström</a>学习，与<a href=\"http://www.cse.chalmers.se/~rjmh/\" target=\"_blank\">John Hughes</a>这样的大师交流，眼界真的开阔了很多。浮躁在中国是很普遍的社会性现象，就拿程序员职业生涯发展来说，中国现在很难找到有十几二十年经验的超级程序员，为什么？因为他们都转到管理方向去了，当CEO，CTO去了。<strong>我觉得这是由中国“官本位”的社会思想导致的。大家都觉得管人的比被管的等级高，要拿更高的工资，这实在是大错特错。</strong>实际上在外国公司里终身从事技术工作的超级工程师大有人在，而且这些超级工程师的工资往往比他们的Manager高得多。在瑞典，做基站的超级工程师时薪4K多克朗的都有（克朗跟人民币几乎等值，绝对真实），50W年薪的比比皆是，这样的待遇还会让你觉得当一辈子工程师没前（钱）途吗？我觉得走管理路线本身没有错，前提是你确实喜欢管理，善于交流，适合你的性格，而不是为了职业发展“被迫”往管理方向转。<strong>在现代企业中，管理者与被管理者本身没有高低贵贱之分，只是职能不同罢了。</strong>最顶级的程序员不仅受人尊重，更可以拿高薪。可惜国内社会风气普遍浮躁，这样的状况想要改变还需要很长时间。<strong>从供需的角度来讲，超级程序员的身价是由市场需求决定的。</strong>就拿华为来说，我上次跟他们在瑞典这边的一位技术负责人聊天时了解到他们在Kista最喜欢有十几年以上经验的超级工程师，因为这样的人才国内根本招不到。为什么他们需要招这样的人？因为华为的竞争对手也是世界级的企业（例如Ericsson），这个时候科技创新就是企业最重要的核心竞争力，自然就需要最顶级的工程师才能在竞争中胜出。我们看到的Google花250W美金挽留一位女工程师的例子（未经证实，<a href=\"http://thunk.org/tytso/blog/2010/11/29/google-has-a-problem-retaining-great-engineers-bullcrap/\">可能是Facebook负责招聘的人炒作</a>）不也刚刚发生么？国内不也出现了年薪200W的工程师牛新庄么？我觉得随着中国IT行业的发展，科技创新将会变得越来越重要，而超级程序员也会越来越成为香饽饽，如果各位同学确实热爱编程，愿意一辈子编程，我希望你坚持下去，因为只要你成为超级程序员肯定会有赏识你的公司。现在的盛大创新院好像做的不错，他们给高级研究员年薪能有30W+，可以算是一个招聘高端人才的例子。而一个反例就是不依靠科技创新的公司（例如团购网站），它们确实是不怎么需要高端人才的，这样的公司不怎么靠技术取胜。</p>\n<p>当然，技术不是最重要的，哪怕对Google，对Facebook也是一样。再高端的技术也必须找到市场，满足消费者的需求才能创造财富。我现在相信的是市场>管理>技术。是走管理路线还是走技术路线最好是按照你自己的性格特点来，喜欢干哪个就做哪个，而不是跟风去做管理。只要你努力，做什么都会有回报。</p>\n<h2>3. 关于英语</h2>\n<p>关于程序员个人发展，我不得不提及英语能力。我个人感觉，英语是阻碍中国程序员提升眼界的一道非常重要的关卡。关于英语于程序员之重要性，Joe在此书里面说了一句“If you are not good at English you&#8217;ll never be a very good programmer.”在欧美IT企业引领科技潮流的今天我们不去学习他们的技术怎么可能追上甚至超越他们？<strong>我建议所有有追求的程序员一定要把英语当做最基本的一门编程语言来学习！</strong>我自己的亲身经历是：英语帮我打开了另一个更广阔的世界的大门，从此直接阅读原版书酣畅淋漓的学习新知识，从此随意阅读最新的论文了解新动态，从此直接与最厉害的程序员毫无障碍的交流！</p>\n<h2>4. 创新+创业</h2>\n<p>我在最近一次Ericsson Research Day上有幸与John Hughes在Demo Session成为邻居，所以才出现了我在推上征求推友关于Erlang问题的一幕。John是从Basic开始学习编程的，在牛津念博士时就做的就是函数式编程的研究，他也是Haskell的创始人之一，95年他来到Chalmers任教至今。他学术上最有影响力的论文之一“QuickCheck: A lightweight Tool for Random Testing of Haskell Programs”成为了他后来创办的<a href=\"http://quviq.com/\" target=\"_blank\">Quviq</a>的技术核心。这个公司目前只有四名员工，当然四个人各个都是教授（我知道另一个专做编译器前端的传奇公司<a href=\"http://www.lingcc.com/2010/09/16/11217/\" target=\"_blank\">EDG</a>也只有5个人）。John为人非常亲切，我跟他聊的非常开心。他追求的编程之美（好吧，我本也不想再用XX之美，但是实在没更合适的词了）是<em>make programming easier &#8212; I like my programs to be short, beautiful, and elegant, and I hate drudgery</em>。我还问他你编程是不是有快40年了？他老人家（其实他跟Joe都是精气神特好，非常年轻的那种）想了半天说还真有四十年了。我最羡慕他一点是，他跟我导师Per Stenström一样横跨学术界与工业界，创新与创业双管齐下，互利互惠，既是学识渊博的教授，又是能给社会创造价值的企业家，人生如此，夫复何求？我跟他说真羡慕你真能享受双倍乐趣啊，他说是啊，真是太有趣了！其实中国教授也有在工业界与学术界都取得成功的例子，例如普林斯顿的<a href=\"http://www.cs.princeton.edu/~li/\">Li Kai</a>教授和UCSD的<a href=\"http://cseweb.ucsd.edu/~yyzhou/\">Zhou Yuanyuan</a>教授，所以说主要还是环境问题导致的。我个人是<a href=\"http://www.loongson.cn/\" target=\"_blank\">龙芯</a>的坚决拥护者，很多人说怎么用MIPS的授权，怎么浪费国家的钱什么什么的，我觉得这些都是扯淡。从我知道的情况来看，龙芯他们组最近把Micro, HPCA, ISCA, ISSCC这些最顶级的会议全发了一个遍，学术水平毫无疑问！胡伟武老师用毛泽东思想来带领团队是有效的（不管是否有失偏薄），而且也有<a href=\"http://sites.google.com/site/yunji83ict/\">Chen Yunji</a>这样的青年才俊，我相信至少龙芯团队培养出来的这批人才已经足以对社会做出贡献。现在龙芯商业化还处在初期阶段，任重而道远，我祝福他们，看好他们！</p>\n<p>中国的发展需要创新！需要最高端的科技人才！需要最顶尖的程序员！</p>\n","descriptionType":"html","publishedDate":"Sun, 28 Nov 2010 16:07:09 +0000","feedId":9852,"bgimg":"http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie-208x300.jpg","linkMd5":"82f930fc186ae7e4dbc3b6ff3f8bf88b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn87@2020_2/2020/08/25/00-37-02-242_45deeb231a86f971.webp","destWidth":208,"destHeight":300,"sourceBytes":22356,"destBytes":12728,"author":"Guancheng (G.C.)","articleImgCdnMap":{"http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie-208x300.jpg":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn87@2020_2/2020/08/25/00-37-02-242_45deeb231a86f971.webp"},"publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"How to do performance analysis on your parallelized program efficiently?","link":"http://www.parallellabs.com/?p=176","description":"<p><em>Be a scientist: Gather data. Analyze it. Especially when it comes to parallelism and scalability, there&#8217;s just no substitute for the advice to measure, measure, measure, and understand what the results mean. Putting together test harnesses and generating and analyzing numbers is work, but the work will reward you with a priceless understanding of how your code actually runs, especially on parallel hardware—an understanding you will never gain from just reading the code or in any other way. And then, at the end, you will ship high-quality parallel code not because you think it&#8217;s fast enough, but because you know under what circumstances it is and isn&#8217;t (there will always be an &#8220;isn&#8217;t&#8221;), and why.</em></p>\n<p>&#8212;<em>Herb Sutter</em></p>\n<p><span style=\"color: #ffffff;\">doubanclaim5959b1bcd330f270</span></p>\n","descriptionType":"html","publishedDate":"Sun, 31 Jan 2010 13:45:42 +0000","feedId":9852,"bgimg":"","linkMd5":"0eaac84685253196054c40fa8954b368","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"在瑞典打甲流疫苗","link":"http://www.parallellabs.com/?p=132","description":"<p>如果在哥德堡想打甲流H1N1疫苗的话可以参考<a href=\"http://primarvardengoteborg.vgregion.se/sv/Primar--och-tandvardsforvaltningen/Vara-omraden/Primarvarden-Goteborg/Vardcentraler/\" target=\"_blank\">这里</a>：</p>\n<p>在页面左侧栏列出了哥德堡不同的地区的Vårdcentraler，离Chalmers最近的Vårdcentraler是属于<a href=\"http://primarvardengoteborg.vgregion.se/sv/Primar--och-tandvardsforvaltningen/Vara-omraden/Primarvarden-Goteborg/Vardcentraler/Centrum/\" target=\"_blank\">Centrum</a>地区。我去的是<a href=\"http://primarvardengoteborg.vgregion.se/sv/Primar--och-tandvardsforvaltningen/Vara-omraden/Primarvarden-Goteborg/Vardcentraler/Centrum/Gibraltargatan1/\" target=\"_blank\">Vårdcentralen Gibraltargatan</a>，就在图书馆旁边。打开Vårdcentralen Gibraltargatan的页面后有专门的接种时间等信息：</p>\n<h2 style=\"margin-top: 0.6em; margin-right: 0px; margin-bottom: 0.2em; margin-left: 0px; font-family: Arial, Verdana, Helvetica, sans-serif; font-weight: bold; color: #005dab; font-size: 1.4em; padding: 0px;\"><span style=\"color: #000000; font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif; font-weight: normal; font-size: 13px;\"><a style=\"font-family: Arial, Verdana, Helvetica, sans-serif; font-size: 1em; color: #005195; text-decoration: none;\" href=\"http://hittavard.vgregion.se/hriv/HRIV.Search.searchunit-flow.flow?unitName=v%C3%A5rdcentralen+gibraltargatan&#38;healthcareType=18&#38;municipality=1480&#38;resultType=1&#38;noHeader=&#38;sortOrder=UNIT_NAME\" target=\"_top\">Våra vaccinationstider</a></span></h2>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; line-height: 1.5em; padding: 0px;\"><a style=\"font-family: Arial, Verdana, Helvetica, sans-serif; font-size: 1em; color: #005195; text-decoration: none;\" href=\"http://vard.vgregion.se/sv/\" target=\"_blank\">För information om influensan och vaccineringen</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; line-height: 1.5em; padding: 0px;\">一般他们都是8点开门，但是疫苗现在还是比较抢手，昨天11点到的时候已经没有了，所以今天我是早上8点到的，排到了24号，等了半个多小时轮到了我。等待时填了个人信息表，然后进去打针，打完后医生会给你写好一个小卡片让你留底。但是个人信息表是瑞典语的，以下是粗略翻译（仅供参考）：</p>\n<blockquote><p>underlag för pandemivaccination (pandemrix)</p>\n<p>för patienten</p>\n<p>inför vaccinationen mot den pandemiska influensan ber vi dig svara på följande frågor</p>\n<p>1. har du tidigare fatt nagon allvarlig reaktion (som yrsel, svimning, andnod eller utslag)</p>\n<p>ja/nej/vet ej</p>\n<p>2. ar du allergisk mot agg</p>\n<p>3. medicinerar du med nagon blodfortunnande medicin, t.ex. waran eller fragmin? (galler ej trombyl)</p>\n<p>4. har du nagon sjukdom eller medicin som påverkar ditt immunforsvar</p>\n<p>5. har du nyligen (inom 1 manad) fatt nagot annat vaccin</p>\n<p>6. tillhor du nagon medicinsk riskgrupp for den pandemiska flu</p>\n<p>&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;</p>\n<p>basis for pandemic vaccination (Pandemrix)<br />\nthe patient</p>\n<p>for vaccination against pandemic influenza, please answer the following questions<br />\n1. have you ever had any severe reaction (such as dizziness, fainting, shortness of breath or a rash)<br />\nyes/no/do not know<br />\n2nd Are you allergic to eggs<br />\n3rd medication you with any blood-thinning medicine, such as warfarin or Fragmin? (Not Trombyl)<br />\n4th you have an illness or medication that affects your immune system<br />\n5th have you recently (within 1 month) received any other vaccine<br />\n6th you belong to any medical risk groups for pandemic flu</p></blockquote>\n","descriptionType":"html","publishedDate":"Wed, 09 Dec 2009 09:49:00 +0000","feedId":9852,"bgimg":"","linkMd5":"9a5b19a09d0897bf2f3a0ae52dcfc02b","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"增长二三事","link":"http://www.parallellabs.com/?p=1532","description":"\n<p>最近对增长有了一些新的思考，正好又听了Hola Group Growth负责人Daisy的一次分享，把一些心得体会汇总记录一下。</p>\n\n\n\n<ol><li>获客成本越低越好？不尽然。只要想获得更多客户，CAC一定越来越高。画一个图：X轴是拉新量级，Y轴单个客户CAC，这个曲线一定是45度往上走。</li><li>产品的用户是分圈层的，最核心的圈层是铁杆粉丝，CAC最低，需求最强，次核心圈层是中需求群体，CAC次低，以此类推。</li><li>增长公式：MAX[(LTV &#8211; CAC) * N]，N是客户数。对于不同圈层用户，LTV，CAC还有N都是不相同的，而产品本身的PMF也可能在发生变化。例如抖音经历过从垂类泛化的过程，它的“算法+商业化+增长/内容运营”组成的增长飞轮，使得他清楚对每类用户的PMF，以及算清楚每类圈层每个客户的LTV、CAC还有N，只要ROI他们能接受，就可以开始全渠道买量。商业化做得好真是任性。</li><li>客户越多，CAC越高，那么努力还有没有用？有用。像压弹簧一样，努力到位了，能最大限度降低各个圈层用户的CAC，例如裂变做得好，CAC在同一圈层里就是更低。广告转化率优化的好，CAC就是更低。不努力，CAC肯定越来越高。</li><li>流量有季节性影响：节日，周末，季节性，双11，春节等等都是影响因子。</li><li>都说留存最重要，而留存不好，可能不仅仅是产品不好，还可能是某渠道来的用户与产品不匹配，也可能是做了某些活动造成短期留存高但是长期留存没变化。抖音极强的一点是把Musica.ly在国内用户中曾经碰到的长留存低问题解决了，且跨越用户圈层之后留存能继续保持，也就是成功从垂类产品扩展到全民产品。千人千面的极致就是所有圈层的人都有高留存。</li><li>流量有红利属性且载体在不断变化。例如App、微博、微信、公众号、FB、朋友圈、小程序、信息流、快手、抖音，还有线下的共享充电宝，共享单车，实体物品的二维码，免费体重秤等一波波红利。而且现在流量渠道的变化越来越快，要能敏锐的捕捉到流量红利，提前布局。这就需要对新的流量媒体敏感，对人性敏感。</li><li>应用流量的价值，有两个维度：X轴是用户的交互程度，也就是停留时间，Y轴是支付金额。光看停留时间是不够的。</li><li>PMF + MAX[(LTV-CAC)*N] 是王道。话说很多产品PMF做得好的，很多都是做游戏出身，对“上瘾”，人性更了解，当然也被很多人“诟病”，例如拼多多。抖音本质上也是一个游戏，一个“舞台”类游戏。</li><li>有一个很有名的App分类图，X轴是App 90天留存，Y轴是用户每周使用频率。第一象限的就是通信社交App，高频高留存。第四象限是天气App，留存高但是频率低。要清楚自己在哪个象限。</li></ol>\n","descriptionType":"html","publishedDate":"Mon, 11 Mar 2019 11:21:39 +0000","feedId":9852,"bgimg":"","linkMd5":"9847d407efb0081f1db6e59614ddbd90","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"云计算时代的多核开发","link":"http://www.parallellabs.com/?p=1179","description":"<p><em>注：原文发表于《程序员》杂志2011年第12期，略有删改。<br />\n</em></p>\n<p>云计算和多核这两大趋势正对软件开发者产生重大影响。近几年，多核逐渐成为主流：随着提升CPU核心频率越来越难，处理器厂商选择了更加容易实现的多核方案来继续提升硬件的性能。进入后PC时代，移动处理器也同样面临着性能的提升与功耗的控制这两大挑战，为了满足提升性能与控制功耗的需求，多核也正成为其以后发展的方向。另一方面，云计算也渐渐成为软件开发的大势。在云计算的生态系统中最主要的设备是“端”和“云”。所谓端包括移动设备（智能手机，Pad等）和传统的PC，尤其是前者；而云指的就是由高性能服务器组成的大规模集群，它们向端设备提供各种服务支持。在云计算时代进行多核开发会是一幅什么样的场景？这两大趋势彼此会有什么样的影响？我们不妨先回顾一下在大型机和PC机时代软件开发的历史。</p>\n<h2><span style=\"color: #3366ff;\">多核上开发将更加容易</span></h2>\n<p align=\"left\">在大型机时代，计算机非常昂贵，用户需要分时共享同一台大型机。计算资源的稀缺使得那时候的软件开发者必须高效地利用每一个处理器时钟周期，因此他们大都使用汇编、C等非常底层的语言来进行软件开发，而算法的效率是他们最关心的问题。在之后的几十年中，计算机硬件变得越来越廉价，软件开发者越来越不需要关心软件的性能。以主流的互联网应用为例，现在的开发大量使用成熟的框架来帮助自动生成大量的代码。就拿Django这个流行的Web开发框架来说，它的设计原则是“focuses on automating as much as possible and adhering to the DRY principle: Don’t Repeat Yourself.”开发者最核心的目标已经变成了如何用最少的代码，最快的速度将自己的点子转为成可用的软件产品并推向市场。<em>“市场投放时间”已经取代“处理器时钟周期”成为软件开发的关键指标。</em>在过去的几十年里，正是因为硬件一直在按照摩尔定律稳步地发展，所以开发者不再需要时刻关注软件的性能，而是将其注意力转移到更为重要的开发效率上，这点在近十年来Java、Python、Ruby等高级语言的兴起上就可见一斑。多核的出现，将硬件的细节再一次暴露在程序员的面前。如果想利用好多核，程序员必须手动的处理同步、死锁、数据竞跑等疑难问题，这极大的降低了软件开发的效率。现有的生产工具（多核开发框架、开发工具）远不能满足生产力（软件开发效率）的发展需要，还有很大的发展空间。可以预见，<strong><em>不久的将来更简单易用的多核开发框架将不断涌现，在多核上进行并行编程将变得越来越容易。</em></strong></p>\n<p align=\"left\">那放在云计算的大背景下，多核开发又会有怎么的发展呢？让我们先来看一看在“云”和“端”上的多核发展趋势。</p>\n<h2><span style=\"color: #3366ff;\">“云”和“端”的多核趋势</span></h2>\n<p>据IDC预测，以智能手机和Pad为代表的移动设备在2013年将达到3.9亿台的出货量；相对的，传统PC机、笔记本和服务器加起来的出货量预计为4.4亿[1]。移动设备的日益流行将让更多的开发者转向移动平台。与此同时，云将为端设备提供更多的服务支撑。那么云和端上的多核将如何发展呢？</p>\n<p><a href=\"http://farm8.staticflickr.com/7001/6820998747_b2e8d526fc.jpg\"><img class=\"alignnone size-full wp-image-1180\" title=\"multicore\" src=\"http://www.parallellabs.com/wp-content/uploads/2012/01/multicore.bmp\" alt=\"\" width=\"708\" height=\"87\" /></a></p>\n<p>如上图所示，从2012年开始双核的手机/平板将成为主流。因为受到功耗的限制，移动设备上的处理器核数并不会迅速增长。实际上，移动设备将会越来越多地依赖专用硬件加速器来提供高性能、低功耗的解决方案。GPU（图形处理器）就是一个很好的例子。在手机和平板上观看高清电影、玩高分辨游戏时会我们可以依靠专用的图形处理器来进行图像渲染、高清解码等操作，这种解决方案相比于使用更多的通用处理器核数来说能提供更高的性能功耗比。从开发者的角度来讲，产品设计、用户体验才是现阶段移动开发者最关注的问题，而如何利用并行编程的方式提升移动应用的性能在短期内还不会是最主要的关注点。不可否认的是，越来越多的移动应用将通过并行化的方式提供更绚丽的3D渲染，更流畅的用户体验以及更丰富的特效（尤其是游戏类应用）。</p>\n<p>与此同时，云端服务器的处理器核数将继续以每18个月翻一番的速度增长。在多核出现之前，软件开发者无需担心软件的性能，他们唯一需要做的就是“等”：等到下一代处理器出现时，软件对性能的需要就能得到满足。这个免费的午餐在多核到来之后不复存在：单纯靠增加处理器的核数并不能提升单线程程序的性能。换言之，我们必须通过并行的方式来提升“串行”应用的性能。但是如果我们所关心的问题不再是如何提升单线程的性能，而是如何利用更多的核来处理已经并行化的应用（例如MapReduce），那么核数的增加不就能继续“免费”地提升此类应用的性能吗？从这个角度来看，云端的应用与多核有点天生一对的意味。举例来说，以Hadoop为基础的大规模数据处理通过并行执行Map和Reduce来有效的对海量数据进行有效的处理。这种数据并行（data parallel）的模式关心的不再是单个Mapper或者Reducer的性能，而是所有Mapper、Reducer的吞吐量。如果需要处理的数据增加了，那么我们一般只需要增加更多的机器（即更多的处理器核数）就能达到所需的性能。</p>\n<p>当谈到并行计算时，我们必须区分好两种完全不同的应用：并行（Parallel）与并发（Concurrency）。所谓并行是指两个或多个task同时执行用以完成同一个计算任务，例如使用两个线程来并行地完成矩阵乘运算。所谓并发是指两个或多个task同时执行，但是彼此相互独立、分别在完成不同的计算（这里的task不仅仅局限于线程，它也可以代表纤程、进程等）。而对云计算来说，云端所需要处理的请求大都是并发任务，因为不同的终端请求彼此大都是相互独立的。想象一下数千用户同时使用Google Docs编辑文件，此时服务器端所需要处理的就是数千个并发请求，这些独立的请求能非常自然地把服务器上的多核利用好。由此可见，在云计算的大背景下，大量存在的并发应用能天然的利用好云端的多核，通过并行的方式来利用好多核并不是那么的重要。</p>\n<h2><span style=\"color: #3366ff;\">人人都是并行程序员？</span></h2>\n<p>在多核出现之初，许多业界人士都惊呼狼来了，人人都需要掌握并行编程。殊不知并行编程这项技术早在二三十年前就已经存在了，只不过当时大都是由搞高性能计算的一小群人会并行编程，而随着多核的普及并行编程的神秘面纱也逐渐向大众展开。幸运的是，在云计算的大图下，多核的应用场景以及与高性能计算领域大不相同。高性能领域关心的主要问题是如何用更多的处理器核心来更快的完成同一个任务，例如天气预测，地震模拟等。而在云计算领域，我们面临的主要难题是如何满足众多端设备的并发请求，这些请求彼此大都独立，因此处于云端之上的开发者已经不太需要担心如何用并行编程来解决他们所面临的问题。</p>\n<p><a href=\"http://farm8.staticflickr.com/7153/6821001131_6d35611db9.jpg\"><img class=\"alignnone size-full wp-image-1181\" title=\"google trend multicore\" src=\"http://www.parallellabs.com/wp-content/uploads/2012/01/google-trend-multicore.bmp\" alt=\"\" width=\"601\" height=\"337\" /></a></p>\n<p>如上图所示，在Google趋势中“云计算（cloud computing）”这个关键词的热度一直都处在上升趋势中，而“多核（multicore）”的热度一直都比较平稳。随着移动互联网的兴起，Android和iOS开发的热度也已经超过了多核。<strong><em>并不是所有的程序员都需要关心如何进行并行编程。在云计算的大背景下，并发应用能与多核很容易地结合在一起，将云端的多核利用好。</em></strong></p>\n","descriptionType":"html","publishedDate":"Sat, 21 Jan 2012 17:24:54 +0000","feedId":9852,"bgimg":"http://www.parallellabs.com/wp-content/uploads/2012/01/multicore.bmp","linkMd5":"518a402e4b446b4c88c478e1adca05e8","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn100@2020_1/2020/08/25/00-37-02-920_41e42614f8a17ea1.jpg","destWidth":0,"destHeight":0,"sourceBytes":184842,"destBytes":184842,"author":"Guancheng (G.C.)","articleImgCdnMap":{"http://www.parallellabs.com/wp-content/uploads/2012/01/multicore.bmp":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn100@2020_1/2020/08/25/00-37-02-920_41e42614f8a17ea1.jpg","http://www.parallellabs.com/wp-content/uploads/2012/01/google-trend-multicore.bmp":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn48@2020_5/2020/08/25/00-37-11-313_f350aed50ecf4776.jpg"},"publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多线程程序常见Bug剖析（上）","link":"http://www.parallellabs.com/?p=773","description":"<p><strong>编写多线程程序的第一准则是先保证正确性，再考虑优化性能。</strong>本文重点分析多线程编程中除死锁之外的另两种常见Bug：违反原子性（Atomicity Violation）和违反执行顺序（Ordering Violation）。现在已经有很多检测多线程Bug的工具，但是这两种Bug还没有工具能完美地帮你检测出来，所以到目前为止最好的办法还是程序员自己有意识的避免这两种Bug。本文的目的就是帮助程序员了解这两种Bug的常见形式和常见解决办法。</p>\n<h4>1. 多线程程序执行模型</h4>\n<p>在剖析Bug之前，我们先来简单回顾一下多线程程序是怎么执行的。从程序员的角度来看，一个多线程程序的执行可以看成是每个子线程的指令交错在一起共同执行的，即<a href=\"http://www.parallellabs.com/2010/03/06/why-should-programmer-care-about-sequential-consistency-rather-than-cache-coherence/\">Sequential Consistency</a>模型。它有两个属性：每个线程内部的指令是按照代码指定的顺序执行的（Program Order），但是线程之间的交错顺序是任意的、不确定的（Non deterministic）。</p>\n<p>我原来举过一个形象的例子。伸出你的双手，掌心面向你，两个手分别代表两个线程，从食指到小拇指的四根手指头分别代表每个线程要依次执行的四条指令。<br />\n（1）对每个手来说，它的四条指令的执行顺序必须是从食指执行到小拇指<br />\n（2）你两个手的八条指令（八个手指头）可以在满足（1）的条件下任意交错执行（例如可以是左1，左2，右1，右2，右3，左3，左4，右4，也可以是左1，左2，左3，左4，右1，右2，右3，右4，也可以是右1，右2，右3，左1，左2，右4，左3，左4等等等等）</p>\n<p>好了，现在让我们来看看程序员在写多线程程序时是怎么犯错的。</p>\n<h4>2. 违反原子性（Atomicity Violation）</h4>\n<p>何谓原子性？简单的说就是不可被其他线程分割的操作。大部分程序员在编写多线程程序员时仍然是按照串行思维来思考，他们习惯性的认为一些简单的代码肯定是原子的。</p>\n<p>例如：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n\tThread 1\t\t\t\t\t\tThread 2\nS1: if (thd-&#62;proc_info)\t\t\t\t...\n{\t\t\t\t\t\t\tS3: thd-&#62;proc_info=NULL;\n  S2: fputs(thd-&#62;proc_info,...)\n}\n</pre>\n<p>这个来自MySQL的Bug的根源就在于程序员误认为，线程1在执行S1时如果从thd->proc_info读到的是一个非空的值的话，在执行S2时thd->proc_info的值肯定也还是非空的，所以可以调用fputs()进行操作。事实上，{S1,S2}<strong>组合到一起之后</strong>并不是原子操作，所以它们可能被线程2的S3打断，即按S1->S3->S2的顺序执行，从而导致线程1运行到S2时出错（注意，虽然这个Bug是因为多线程程序执行顺序的不确定性造成的，可是它违反的是程序员对这段代码是原子的期望，所以这个Bug不属于违反顺序性的Bug）。</p>\n<p>这个例子的对象是两条语句，所以很容易看出来它们的组合不是原子的。事实上，有些看起来像是原子操作的代码其实也不是原子的。最著名的莫过于多个线程执行类似<a href=\"http://www.parallellabs.com/2010/04/15/atomic-operation-in-multithreaded-application/\">&#8220;x++&#8221;这样的操作</a>了。这条语句本身不是原子的，因为它在大部分硬件平台上其实是由三条语句实现的：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nmov eax,dword ptr [x]\nadd eax,1\nmov dword ptr [x],eax\n</pre>\n<p>同样，下面这个“r.Location = p”也不是原子的，因为事实上它是两个操作：“r.Location.X = p.X”和“r.Location.Y = p.Y”组成的。</p>\n<pre class=\"brush: csharp; title: ; notranslate\">\nstruct RoomPoint {\n   public int X;\n   public int Y;\n}\n\nRoomPoint p = new RoomPoint(2,3);\nr.Location = p;\n</pre>\n<p>从根源上来讲，如果你想让这段代码真正按照你的心意来执行，你就得在脑子里仔细考虑是否会出现违反你本意的执行顺序，特别是涉及的变量（例如thd->proc_info）在其他线程中有可能被修改的情况，也就是数据竞争（Data Race）[注1]。如果有两个线程同时对同一个内存地址进行操作，而且它们之中至少有一个是写操作，数据竞争就发生了。</p>\n<p>有时候数据竞争可是隐藏的很深的，例如下面的Parallel.For看似很正常：</p>\n<pre class=\"brush: csharp; title: ; notranslate\">\nParallel.For(0, 10000, \n    i =&#62; {a[i] = new Foo();})\n</pre>\n<p>实际上，如果我们去看看Foo的实现：</p>\n<pre class=\"brush: csharp; title: ; notranslate\">\nclass Foo {\n\tprivate static int counter;\n\tprivate int unique_id;\n\tpublic Foo()\n       {\n\t\tunique_id = counter++;\n       }\n}\n</pre>\n<p>同志们，看出来哪里有数据竞争了么？是的，counter是静态变量，Foo()这个构造函数里面的counter++产生数据竞争了！想避免Atomicity Violation，其实根本上就是要保证没有数据竞争（Data Race Free）。</p>\n<h4>3. Atomicity Violation的解决方案</h4>\n<p>解决方案大致有三（可结合使用）：<br />\n（1）把变量隔离起来：只有一个线程可以访问它（isolation）<br />\n（2）把变量的属性定义为immutable的：这样它就是只读的了（immutability）<br />\n（3）同步对这个变量的读写：比如用锁把它锁起来（synchronization）</p>\n<p>例如下面这个例子里面x是immutable的；而a[]则通过index i隔离起来了，即不同线程处理a[]中不同的元素；</p>\n<pre class=\"brush: csharp; title: ; notranslate\">\nParallel.For(1,1000, \ni =&#62; {\n    a[i] = x;\n});\n</pre>\n<p>例如下面这个例子在构造函数中给x和y赋值（此时别的线程不能访问它们），保证了isolation；一旦构造完毕x和y就是只读的了，保证了immutability。</p>\n<pre class=\"brush: csharp; title: ; notranslate\">\npublic class Coordinate\n{\n   private double x, y;\n\n   public Coordinate(double a,\n                     double b)\n   {\n      x = a;\n      y = b;\n   }\n   public void GetX() {\n      return x; \n   }\n   public void GetY() {\n      return y; \n   }\n}\n</pre>\n<p>而我最开始提到的关于thd->proc_info的Bug可以通过把S1和S2两条语句用锁包起来解决（同志们，千万别忘了给S3加同一把锁，要不然还是有Bug！）。被锁保护起来的临界区在别的线程看来就是“原子”的，不可以被打断的。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n\tThread 1\t\t\t\t\t\tThread 2\nLOCK(&#38;lock)\nS1: if (thd-&#62;proc_info)\t\t\t\tLOCK(&#38;lock);\n{\t\t\t\t\t\t\tS3: thd-&#62;proc_info=NULL;\n  S2: fputs(thd-&#62;proc_info,...)\t\tUNLOCK(&#38;lock);\n}\nUNLOCK(&#38;lock)\n</pre>\n<p>还有另一个用锁来同步的<a href=\"http://blog.csdn.net/shell_picker/archive/2010/04/28/5540619.aspx\">例子</a>，即通过使用锁（Java中的synchronized关键字）来保证没有数据竞争：</p>\n<p>&#8220;Java 5 中提供了 ConcurrentLinkedQueue 来简化并发操作。但是有一个问题：使用了这个类之后是否意味着我们不需要自己进行任何同步或加锁操作了呢？<br />\n也就是说，如果直接使用它提供的函数，比如：queue.add(obj); 或者 queue.poll(obj);，这样我们自己不需要做任何同步。&#8221;但是，两个原子操作合起来可就不一定是原子操作了（Atomic + Atomic != Atomic），例如：</p>\n<pre class=\"brush: java; title: ; notranslate\">\nif(!queue.isEmpty()) {  \n   queue.poll(obj);  \n}  \n</pre>\n<p>事实情况就是在调用isEmpty()之后，poll()之前，这个queue没有被其他线程修改是不确定的，所以对于这种情况，我们还是需要自己同步，用加锁的方式来保证原子性（虽然这样很损害性能）：</p>\n<pre class=\"brush: java; title: ; notranslate\">\nsynchronized(queue) {  \n    if(!queue.isEmpty()) {  \n       queue.poll(obj);  \n    }  \n}  \n</pre>\n<p>但是注意了，使用锁也会造成一堆Bug，死锁就先不说了，先看看初学者容易犯的一个错误（是的，我曾经也犯过这个错误），x在两个不同的临界区中被修改，加了锁跟没加一样，因为还是有数据竞争：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nint x = 0;\npthread_mutex_t lock1;\npthread_mutex_t lock2;\n\npthread_mutex_lock(&#38;lock1);\nx++;\npthread_mutex_unlock(&#38;lock1);\n...\n...\npthread_mutex_lock(&#38;lock2);\nx++;\npthread_mutex_unlock(&#38;lock2);\n</pre>\n<p>事实上，类似x++这样的操作最好的解决办法就是使用类似java.util.concurrent.atomic，Intel TBB中的atomic operation之类的方法完成，具体的例子可以参考<a href=\"http://www.parallellabs.com/2010/04/15/atomic-operation-in-multithreaded-application/\">这篇文章</a>。</p>\n<p>总结一下，不管是多条语句之间的原子性也好，单个语句（例如x++）的原子性也好都需要大家格外小心，有这种意识之后很多跟Atomicity Violation相关的Bug就可以被避免了。其实归根结底，我们最终是想让多线程程序按照你的意愿正确的执行，所以在清楚什么样的情形可能让你的多线程程序不能按你所想的那样执行之后我们就能有意识的避免它们了（或者更加容易的修复它们）。<a href=\"http://www.parallellabs.com/2010/11/23/concurrency-bugs-2/\" target=\"_blank\">下一篇文章</a>我们再来仔细分析下Ordering Violation。</p>\n<p>[注1] 严格意义上来讲，Data Race只是Atomicity Violation的一个特例，Data Race Free不能保证一定不会出现Atomicity Violation。例如文中Java实现的那个Concurrent Queue的例子，严格意义上来讲它并没有data race，因为isEmpty()和poll()都是线程安全的调用，只不过它们<strong>组合起来</strong>之后会出现违反程序员本意的Atomicity Violation，所以要用锁保护起来。</p>\n<p>P.S. 参考文献中的前两篇是<a href=\"http://cseweb.ucsd.edu/~yyzhou/\" target=\"_blank\">YuanYuan Zhou</a>教授的得意门生<a href=\"http://pages.cs.wisc.edu/~shanlu/\" target=\"_blank\">Dr. Shan Lu</a>的论文，后者现在已经是Wisconsin–Madison的教授了。</p>\n","descriptionType":"html","publishedDate":"Sat, 13 Nov 2010 14:59:40 +0000","feedId":9852,"bgimg":"","linkMd5":"1613f11f153e6ca9ea5a47269a389e62","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"IBM研究院（CRL）诚聘 Bigdata/Clould 方向正式员工","link":"http://www.parallellabs.com/?p=1412","description":"<p>工作地点：北京<br />\n工作职位：正式员工</p>\n<p>IBM中国研究院是IBM技术力量最强的部门，在新技术研发，前沿学术研究，高价值专利等领域都具备一流水平，我们的员工大都来自清华北大中科院等中国一流学府，我们能给您提供一流的技术研发环境与最具挑战的技术研发项目，期待您的加入！</p>\n<p>1. 大数据、Cloud方向的硕士或博士生（应届/社招均可）。<br />\n2. 具有深入以下方面的学习工作背景 （多个条件为或的关系）<br />\na）大数据平台（例如hadoop/yarn/spark）的部署、代码分析、工作机制理解<br />\nb）大数据应用（例如推荐系统，数据挖掘，机器学习等上层应用）<br />\nc）大数据平台、应用性能分析，性能调优<br />\nd）大规模机群上面的平台和应用的开发、测试</p>\n<p>3. 有良好的表达能力，与人沟通能力，与人合作能力<br />\n4. 较强的学习，接受新知识的能力。<br />\n5. 较强的编程能力，如c/java/python/shell<br />\n6. 对计算机体系结构、并行计算有工作研究经验者优先<br />\n7. 较强的英文读写能力。</p>\n<p>如果您对此职位感兴趣，请发送您的简历至chengc@cn “dot” ibm “dot” com。<br />\n请以“应聘CRL职位”作为邮件标题，以免邮件被过滤。多谢关注！</p>\n","descriptionType":"html","publishedDate":"Tue, 11 Mar 2014 02:57:52 +0000","feedId":9852,"bgimg":"","linkMd5":"ee70afb90dbf8598b8277db07da0016c","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Druid中国用户组第一次线下技术交流资料分享","link":"http://www.parallellabs.com/?p=1495","description":"<p>Druid（<a href=\"http://www.druid.io\" target=\"_blank\">http://www.druid.io</a>）作为一个开源的大数据OLAP分析引擎，得到了越来越多的关注。在Druid co-founder Fangjin Yang的支持下，阿里，OneAPM，Hulu，小米，蚂蜂窝，滴滴，携程等公司的同学共同成立了Druid China User Group的微信群，并决定与2016年2月20日下午举办第一次线下技术交流，欢迎对大数据分析，Druid，OLAP引擎等话题感兴趣的同学参加。</p>\n<p>PPT下载链接：<a href=\"http://pan.baidu.com/s/1jHFspRg\" target=\"_blank\">http://pan.baidu.com/s/1jHFspRg</a></p>\n<p>技术交流议题：<br />\n<strong>1. Druid在Hulu的应用</strong><br />\n演讲人：张汉生，Hulu北京AdIntelligence组软件研发工程师。主要参与Hulu广告定位和广告预测等相关工作，同时负责维护Druid集群。</p>\n<p><object width=\"630\" height=\"500\" align=\"middle\" id=\"reader\" codebase=\"http://fpdownload.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,0,0\" classid=\"clsid:d27cdb6e-ae6d-11cf-96b8-444553540000\"><param value=\"window\" name=\"wmode\"/><param value=\"true\" name=\"allowfullscreen\"/><param name=\"allowscriptaccess\" value=\"always\"/><param value=\"http://wenku.baidu.com/static/flash/apireader.swf?docurl=http://wenku.baidu.com/play&#38;docid=059807208bd63186bdebbc47&#38;title=Druid%20Meetup%20-%20Druid-in-Hulu-2016-02-20&#38;doctype=pdf&#38;fpn=5&#38;npn=5&#38;readertype=external&#038;catal=0&#38;cdnurl=http://txt.wenku.baidu.com/play\" name=\"movie\"/><embed width=\"630\" align=\"middle\" height=\"500\" pluginspage=\"http://www.macromedia.com/go/getflashplayer\" type=\"application/x-shockwave-flash\" name=\"reader\" src=\"http://wenku.baidu.com/static/flash/apireader.swf?docurl=http://wenku.baidu.com/play&#38;docid=059807208bd63186bdebbc47&#38;title=Druid%20Meetup%20-%20Druid-in-Hulu-2016-02-20&#38;doctype=pdf&#38;fpn=5&#38;npn=5&#38;readertype=external&#038;catal=0&#38;cdnurl=http://txt.wenku.baidu.com/play\" wmode=\"window\" allowscriptaccess=\"always\" bgcolor=\"#FFFFFF\" ver=\"9.0.0\" allowfullscreen=\"true\"/></object></p>\n<p><strong>2. Real-time Architecture for Online Travel</strong><br />\n演讲人：Jin Yu，蚂蜂窝技术VP兼首席架构师。蚂蜂窝是中国最大的在线旅游社区，拥有超过1亿用户。在加入蚂蜂窝之前，Jin Yu是OpenX的技术VP和首席架构师，负责公司的数据战略，移动产品线和整体架构，其中就包括由5个全球数据中心的6000多台服务器组成的数据业务。Jin Yu还是连续创业者，他联合创办过2个创业公司：移动社交大数据领域的Portaura和电商搜索引擎领域的Martsoft。</p>\n<p><strong>3. OneAPM的Druid分析实践</strong><br />\n演讲人：刘麒赟，OneAPM大数据高级架构师，主要负责OneAPM大数据架构的设计和开发工作。加入OneAPM之前是IBM BigInsights的大数据架构师，是多个Apache开源大数据项目的Contributor。<br />\n<object width=\"630\" height=\"500\" align=\"middle\" id=\"reader\" codebase=\"http://fpdownload.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,0,0\" classid=\"clsid:d27cdb6e-ae6d-11cf-96b8-444553540000\"><param value=\"window\" name=\"wmode\"/><param value=\"true\" name=\"allowfullscreen\"/><param name=\"allowscriptaccess\" value=\"always\"/><param value=\"http://wenku.baidu.com/static/flash/apireader.swf?docurl=http://wenku.baidu.com/play&#38;docid=a807ffbcad02de80d5d8403c&#38;title=Druid%20Meetup%20-%20OneAPM%E7%9A%84Druid%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5&#38;doctype=pdf&#38;fpn=5&#38;npn=5&#38;readertype=external&#038;catal=0&#38;cdnurl=http://txt.wenku.baidu.com/play\" name=\"movie\"/><embed width=\"630\" align=\"middle\" height=\"500\" pluginspage=\"http://www.macromedia.com/go/getflashplayer\" type=\"application/x-shockwave-flash\" name=\"reader\" src=\"http://wenku.baidu.com/static/flash/apireader.swf?docurl=http://wenku.baidu.com/play&#38;docid=a807ffbcad02de80d5d8403c&#38;title=Druid%20Meetup%20-%20OneAPM%E7%9A%84Druid%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5&#38;doctype=pdf&#38;fpn=5&#38;npn=5&#38;readertype=external&#038;catal=0&#38;cdnurl=http://txt.wenku.baidu.com/play\" wmode=\"window\" allowscriptaccess=\"always\" bgcolor=\"#FFFFFF\" ver=\"9.0.0\" allowfullscreen=\"true\"/></object></p>\n<p>&#160;</p>\n","descriptionType":"html","publishedDate":"Tue, 29 Mar 2016 08:29:45 +0000","feedId":9852,"bgimg":"","linkMd5":"9e68fc2ae9e4260dfad5340ed36e5cee","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"[已经招到了，谢谢大家！]IBM中国研究院招聘Hadoop实习生","link":"http://www.parallellabs.com/?p=1098","description":"<p>我们组最近有一个实习生的名额，做Hadoop性能优化相关的研究工作，如果大家感兴趣的话请给我发邮件:)</p>\n<p>IBM Research China is looking for graduate computer science/engineering students who are interested in Hadoop performance optimizations works.</p>\n<p>Location: Beijing<br />\nJob Tile: Research Intern<br />\nJob Openings: 1<br />\nExpected Duration: at least 3 months (full-time preferred)</p>\n<p>Job responsibilities:<br />\n&#8211; Write MapReduce program and analyze Hadoop performance model.<br />\n&#8211; Tune and optimize the performance of Hadoop workloads.<br />\n&#8211; Publish high quality research papers to report your work.</p>\n<p>Requirements:<br />\n&#8211; Creative and Self-motivated<br />\n&#8211; Knowledge of Parallel Computing and Distributed Systems.<br />\n&#8211; Knowledge of Java.<br />\n&#8211; Familiarity with Linux as development and testing environments.<br />\n&#8211; Knowledge of Apache Hadoop is a plus.<br />\n&#8211; Past research experience is a plus.</p>\n<p><strong>If you&#8217;re interested, please feel free to send your Chinese or English resume with the mail title of &#8220;Intern_Your Name_University_Major_Grade&#8221; (e.g. Intern_Zhang San_XXU_CS_Master) to chengc_at_cn.ibm.com.</strong></p>\n","descriptionType":"html","publishedDate":"Thu, 22 Sep 2011 03:07:09 +0000","feedId":9852,"bgimg":"","linkMd5":"4658f904a232ac819df4fb5edf6d1522","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"X-RIME: 基于Hadoop的开源大规模社交网络分析工具","link":"http://www.parallellabs.com/?p=1133","description":"<p><strong>文 / 陈冠诚，史巨伟，杨博（IBM中国研究院)，杨寅（人民搜索）<br />\n</strong></p>\n<p>随着互联网的快速发展，涌现出了一大批以Facebook，Twitter，人人，微博等为代表的新型社交网站。这些网站用户数量的迅速增长使得海量的用户数据不断被产生出来，而如何有效地对这些海量的用户数据进行社交网络分析（Social Network Analysis）正成为一个越来越热门的问题。本文向大家介绍由IBM中国研究院和北京邮电大学合作开发的X-RIME开源库（<a href=\"http://xrime.sourceforge.net/\" target=\"_blank\">http://xrime.sourceforge.net/</a>），一个基于Hadoop的开源社交网络分析工具。</p>\n<p>其实早在90年代初就已经有许多企业和研究机构对社交网络进行过相关研究。然而随着互联网用户的急速的增长，今日的社交网站所需处理的数据已经不是传统的解决方案所能够应对的了。例如，传统的社会网络分析算法和工具往往都是单机形式的，在面对大规模数据集的时候往往会出现存储和处理能力不足等方面问题，再加上原始输入数据和社会网络的内部表示大都属于无结构或者半结构化数据，传统关系数据库并不擅长处理此类数据，使得利用传统的社会网络分析算法和工具对大规模数据集进行处理变得更加困难。另一方面，随着Hadoop的日益流行，许多中小互联网企业可以通过搭建Hadoop集群来方便地进行大规模数据处理。然而，Hadoop并不直接提供社交网络分析的算法库，因此实施海量社交网络分析仍存在较高门槛。基于这些需求，我们设计并实现了X-RIME。</p>\n<p>X-RIME是一个基于Hadoop的开源社会网络分析工具。依赖于Hadoop提供的大规模数据并行处理能力，X-RIME实现了对十几中网络分析算法的并行化，提供了一整套用于对大规模社会网络进行分析处理的解决方案。通过使用X-RIME，用户可以方便快捷地对海量社会网络数据进行分析，从这些海量社会网络数据中获取更深层次的有用信息，从而进一步挖掘商业价值，支持商业决策以及发现新的业务增长点。</p>\n<h1>1. X-RIME架构介绍</h1>\n<p>&#160;</p>\n<p>&#160;</p>\n<p>图一描述了X-RIME的整体架构，它主要由四层组成：HDFS，X-RIME数据模型，X-RIME算法库以及基于社交网络分析的商业智能分析应用。</p>\n<div class=\"mceTemp\" style=\"text-align: center;\">\n<dl id=\"attachment_1135\" class=\"wp-caption alignnone\" style=\"width: 561px;\">\n<dt class=\"wp-caption-dt\"><a href=\"http://farm8.staticflickr.com/7003/6821005195_30c8776c93.jpg\"><img class=\"size-full wp-image-1135   \" title=\"X-RIME整体架构\" src=\"http://www.parallellabs.com/wp-content/uploads/2011/12/xrime.bmp\" alt=\"X-RIME整体架构\" width=\"551\" height=\"470\" /></a></dt>\n<dd class=\"wp-caption-dd\">图1. X-RIME整体架构</dd>\n</dl>\n</div>\n<p style=\"text-align: left;\">\n<p style=\"text-align: left;\">X-RIME算法库是X-RIME的核心组成部分，他基于Map/Reduce实现了十余种分布式社交网络处理算法。</p>\n<p style=\"text-align: left;\">X-RIME最底层采用了HDFS来存储海量数据。像很多其他基于Hadoop的数据分析解决方案一样，X-RIME也采用了HDFS来构建底层的海量数据存储设施。整个X-RIME算法库的所有的输入文件、中间结果和最终结果都会存储在HDFS上。</p>\n<p>处于倒数第二层的X-RIME数据模型层实现了社交网络数据的“数据结构”。我们知道，社交网络的基础模型是图论中的图模型。在这个模型中，社会网络的个体被视为图中的节点，个体之间的关联被视为图中的边。 X-RIME数据模型层包括了近20 种数据结构，主要包括基于Hadoop 的对社会网络中的点、边等抽象概念的具体数据结构表示。在后面一节我们会详细介绍该数据模型的设计原则。</p>\n<p>在X-RIME数据模型层之上的是X-RIME核心算法库（它运行在Hadoop的MapReduce框架之上）。在算法库中，我们通过map()/reduce()函数对的形式实现了十余种常见的社交网络分析算法。这些算法通过将多个Hadoop Job按算法工作流程组合在一起来共同完成相应的任务。这些算法都被相同的接口封装起来，这些接口一般包括四种参数：（1）输入文件在HDFS中的路径，它保存了与X-RIME数据模型相兼容的输入文件；（2）输出文件在HDFS中的路径，它用以保存最终的分析结果；（3）MAP/REDUCE的相关参数，例如Mapper数或者Reducer数等；（4）社交网络分析算法相关参数，例如迭代次数等。</p>\n<p>图一中最顶层是基于社交网络分析的商业智能分析应用。它通过调用X-RIME核心算法库来实现对社交网络的数据分析。如果需要的话，用户还能将它与已有的数据仓库解决方案集成（例如JAQL，Mahout等），从而提供一个更加完整、高效的综合商业智能分析解决方案。</p>\n<h1>2. X-RIME 数据模型的设计原则</h1>\n<p>&#160;</p>\n<p>&#160;</p>\n<p>X-RIME 的设计目标是用来专门做大规模数据集社会网络分析的工具，因此我们对X-RIME 数据模型进行设计时必须考虑以下两点原则：X-RIME 需要处理大规模数据集；X-RIME 分析的对象是社会网络。X-RIME 处理大规模数据集的能力主要依赖于Hadoop的大规模并行处理能力，因此只要X-RIME 中所有的数据结构都是基于HADOOP 的海量数据集接口即可。这里我们重点分析X-RIME分析的对象即社会网络的特点。之前的分析中已经提到社会网络的基础模型是图论中的图模型，在这个模型里，社会网络中的个体被视为图里的结点v ，结点的集合为V ；个体之间的关联被视为图里面的边e，边的集合是E = {e (u, v) | u∈V, v∈V}，因此整个模型就可以看作是G = (V, E)。基于此我们对X-RIME 的数据模型做了如下考量：</p>\n<h2>2.1 采用邻接矩阵还是邻接表</h2>\n<div class=\"mceTemp mceIEcenter\" style=\"text-align: center;\">\n<dl id=\"attachment_1137\" class=\"wp-caption aligncenter\" style=\"width: 516px;\">\n<dt class=\"wp-caption-dt\"><a href=\"http://farm8.staticflickr.com/7015/6821009975_db90b7b53f.jpg\"><img class=\"size-full wp-image-1137  \" title=\"稀疏图和稠密图的邻接表与邻接矩阵形式\" src=\"http://www.parallellabs.com/wp-content/uploads/2011/12/稀疏图和稠密图的邻接表与邻接矩阵形式.bmp\" alt=\"稀疏图和稠密图的邻接表与邻接矩阵形式\" width=\"506\" height=\"428\" /></a></dt>\n<dd class=\"wp-caption-dd\">图2. 稀疏图和稠密图的邻接表与邻接矩阵形式</dd>\n</dl>\n</div>\n<p style=\"text-align: left;\">\n<p style=\"text-align: left;\">如图 2 所示，要表示一个图G = (V, E)，有两种标准的方法，即邻接矩阵和邻接表。一般认为当|E|远小于|V|2的图属于稀疏图，反之则认为是稠密图。使用邻接矩阵表示法的优点在于可以很快判断两个给定结点是否存在连接边，缺点在于当要表示的图是稠密图的时候有大量的空间会被浪费。邻接表表示方式的优点在于节省空间，缺点在于判断两个给定结点是否存在连接表需要遍历其中某个结点的邻接表，效率较低。基于以下两点考虑，我们采用了邻接表的方式表示X-RIME 中的图结构：</p>\n<p>（1）社交网络一般属于稀疏图结构，因此使用邻接表表示可以节省大量空间，提高空间利用率。<br />\n（2）X-RIME 中大部分算法不需要快速判断两个给定结点是否存在连接边。</p>\n<h2>2.2 边的表现形式</h2>\n<p>在邻接表中，结点之间的关系需要使用边来承载，边的形式可以有多种，如有向边，无向边，自环边（自己指向自己）等。考虑到在社会网络中，上述几种边都有可能存在，在不同的应用场景中有不同需求，因此我们需要有灵活的数据结构来支持上述各种不同形式的边。此外还有一种情况需要考虑，当有向边用{from, to}来表示时，传统的邻接表表示法只是将这条边信息记录在from 端，但是在社会网络分析中，我们可能存在某种场景需要同时将这条边信息记录在to 端，X-RIME 的设计中考虑了这种应用场景。</p>\n<h2>2.3 额外的承载信息</h2>\n<div class=\"mceTemp mceIEcenter\" style=\"text-align: center;\">\n<dl id=\"attachment_1160\" class=\"wp-caption aligncenter\" style=\"width: 595px;\">\n<dt class=\"wp-caption-dt\"><a href=\"http://farm8.staticflickr.com/7164/6821011811_510c82b7a9.jpg\"><img class=\"size-full wp-image-1160  \" title=\"社会网络中结点和边需要存储额外信息\" src=\"http://www.parallellabs.com/wp-content/uploads/2012/01/社会网络中结点和边需要存储额外信息.bmp\" alt=\"社会网络中结点和边需要存储额外信息\" width=\"585\" height=\"266\" /></a></dt>\n<dd class=\"wp-caption-dd\">图3. 社会网络中结点和边需要存储额外信息</dd>\n</dl>\n</div>\n<p style=\"text-align: left;\">\n<p style=\"text-align: left;\">X-RIME 需要处理的社会网络图与传统的简单图不一样，它是个体以及个体之间复杂关系的一种抽象。如图3 所示，在社会网络中，结点自身往往需要存储一些额外的信息，例如当图中的结点表示人的时候，可能需要额外记录这个人的性别、年龄、家庭地址等信息；结点之间的关系（边）往往也需要存储一些额外的信息，例如当图中的边表示两个人是好朋友的时候，可能需要额外记录这条边的强度（好友关系的强烈程度）、边的类型（关系类型，如家人、朋友、同学等）、好友间的物理距离等。基于上述考虑，X-RIME 的设计中必须考虑为结点和边提供额外的信息存储功能。</p>\n<h2 style=\"text-align: left;\">2.4 比较器</h2>\n<p>在社会网络中，个体和边需要进行某种程度的对比。例如在好友关系网中，人们可能希望比较得出哪些人是自己最好的朋友，人们同样可能希望比较得出自己在好友心目中的重要程度等。映射到X-RIME 中，大量的运算的确需要对结点以及边进行比较。这种比较可以是简单的数值比较（例如边的权值比较）也可以是复杂的逻辑比较（例如综合边的关系类型，边的强度，结点之间的物理距离等进行比较）。X-RIME 的设计中必须考虑数据类型之间的比较，需要设计各种比较器。</p>\n<h2>2.5 效率问题</h2>\n<p>X-RIME 需要处理的是大规模海量数据，如果我们对输入数据的读写处理只是简单地根据原始的文本文件格式进行读写，势必影响效率，因为这样多了一个中间转换过程，需要读入内存再根据特定的数据结构格式进行转换。Hadoop 提供的序列化IO 接口为我们提供了一个有效的方法来提高读写效率。在读取输入数据之前，我们需要预先对原始文本进行转换，通过Hadoop 序列化IO 接口的序列化功能将其转换成二进制镜像文件形式，这样每次X-RIME 读取被序列化产生的二进制文件的时候可以直接通过Hadoop 序列化IO 接口的反序列化功能将镜像文件装载到内存里，输出的时候直接通过Hadoop IO 的序列化功能进行输出，效率大大提高。两种读写方式的示意图如图4 所示。</p>\n<p><figure id=\"attachment_1167\" aria-describedby=\"caption-attachment-1167\" style=\"width: 414px\" class=\"wp-caption aligncenter\"><a href=\"http://farm8.staticflickr.com/7149/6821014255_ecaa8f1d4d.jpg\"><img class=\"size-full wp-image-1167 \" title=\"两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）\" src=\"http://www.parallellabs.com/wp-content/uploads/2012/01/两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）.bmp\" alt=\"两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）\" width=\"414\" height=\"345\" /></a><figcaption id=\"caption-attachment-1167\" class=\"wp-caption-text\">图4. 两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）</figcaption></figure></p>\n<h1>3. X-RIME使用介绍</h1>\n<p>&#160;</p>\n<p>&#160;</p>\n<p>使用X-RIME大致可以分为四步。第一步：获取原始数据，例如使用爬虫获取原始网站数据。第二步：对数据进行预处理以转化成X-RIME数据模型所支持的格式。这个步骤与用户提供的具体数据格式相关，因而通常由X-RIME用户自己实现。第三步：调用X-RIME算法库对这些数据进行社交网络分析。第四步：对X-RIME的输出结果进行整合，生成易于理解的文档。</p>\n<p>下面我们来介绍下使用X-RIME对某BBS中一个分论坛进行弱连通分支（Weakly Connected Components，后面简称WCC）算法分析的结果。在BBS中，每一个帖子的发起者A是一个节点，而如果另一个用户B回复了这个帖子，我们说这两个用户间形成了一个关系，即B指向了A。</p>\n<div class=\"mceTemp mceIEcenter\" style=\"text-align: center;\">\n<dl id=\"attachment_1169\" class=\"wp-caption aligncenter\" style=\"width: 512px;\">\n<dt class=\"wp-caption-dt\"><a href=\"http://farm8.staticflickr.com/7171/6821016923_78c7a4859a.jpg\"><img class=\"size-full wp-image-1169 \" title=\"弱连通分布\" src=\"http://www.parallellabs.com/wp-content/uploads/2012/01/弱连通分布.bmp\" alt=\"弱连通分布\" width=\"502\" height=\"381\" /></a></dt>\n<dd class=\"wp-caption-dd\">图5. 弱连通分布</dd>\n</dl>\n</div>\n<p>图5中的蓝红紫三条线分别代表该BBS中MilitaryView版， Circuit版和Career_POST版的WCC分布情况。从图中我们可以看到，MilitaryView版和Circuit版中大部分的用户的WCC值都很高。这说明这两个版块中的大部分用户彼此都直接或者间接的联系在一起。相反的，Career_POST版中大部分的用户彼此间的联系都非常松散。其实这个结果非常易于理解，因为MilitaryView和Circuit版是专门的版块，在这个版块的用户大都是基于相同的兴趣而产生的发帖、回帖行为，因此彼此间的互动更频繁、联系更紧密；相对的，Career_POST版主要被用于发布和浏览招聘信息，因此用户的回帖行为不多，用户间的关联性不强。</p>\n<h1>4. 总结</h1>\n<p>&#160;</p>\n<p>&#160;</p>\n<p>X-RIME作为基于Hadoop的开源工具，为大家提供了一种方便快捷地进行大规模社交网络分析的新选择。如果您对X-RIME有什么新的需求或者建议，欢迎您直接与我们联系：chengc@cn.ibm.com。</p>\n<h1>参考文献</h1>\n<p>&#160;</p>\n<p>&#160;</p>\n<p>[1] X-RIME Homepage: http://xrime.sourceforge.net/</p>\n<p>[2] Wei Xue, JuWei Shi, Bo Yang. X-RIME: Cloud-Based Large Scale Social Network Analysis. Proceedings of 2010 IEEE International Conference on Services Computing.</p>\n<p>[3] Kai Shuang, Yin Yang, Bin Cai, Zhe Xiang. X-RIME: HADOOP-BASED LARGE-SCALE SOCIAL NETWORK ANALYSIS. Proceedings of IC-BNMT2010.</p>\n<p>[4] 杨寅.大规模社会网络分析数据模型的设计与实现. 中国科技论文在线.</p>\n","descriptionType":"html","publishedDate":"Mon, 09 Jan 2012 01:44:57 +0000","feedId":9852,"bgimg":"http://www.parallellabs.com/wp-content/uploads/2011/12/xrime.bmp","linkMd5":"e8beedf13674409a00b5af7231bc8e9a","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"author":"Guancheng (G.C.)","articleImgCdnMap":{"http://www.parallellabs.com/wp-content/uploads/2011/12/xrime.bmp":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","http://www.parallellabs.com/wp-content/uploads/2011/12/稀疏图和稠密图的邻接表与邻接矩阵形式.bmp":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","http://www.parallellabs.com/wp-content/uploads/2012/01/社会网络中结点和边需要存储额外信息.bmp":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","http://www.parallellabs.com/wp-content/uploads/2012/01/两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）.bmp":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","http://www.parallellabs.com/wp-content/uploads/2012/01/弱连通分布.bmp":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg"},"publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"下一代大数据分析技术","link":"http://www.parallellabs.com/?p=1293","description":"<p><em><strong>原文发表于《程序员》杂志2013年第2期.</strong></em></p>\n<p>文 / 陈冠诚</p>\n<p>随着以Hadoop为代表的大数据分析技术的普及，大数据的商业价值得到深入挖掘，并开始在互联网、零售、医疗、物联网等多个行业里成为商业变革的主导力量。Facebook最近就发布了名为Graph Search的新型社交搜索产品，基于海量的社交关系网络及“Likes”行为数据，为用户提供个性化的社交搜索服务，该产品被认为将是Google搜索业务的重要竞争对手。在电子商务领域，淘宝的数据魔方就是一个基于大数据分析的典型产品。数据魔方基于淘宝所掌握的大量消费数据提供各种各样的分析服务，例如展示消费者的购物习惯，地域分布，年龄分布，热销排名等，为淘宝卖家提供了非常有价值的分析数据。然而，这些现有的大数据分析技术处理的主要对象仍集中于文本数据，例如社交图谱，搜索关键字，商品数目，店铺、商品浏览记录，成交、收藏、评价记录等等，却没有涵盖一类非常重要的数据：多媒体。</p>\n<p>实际上，多媒体数据的数据不仅规模远远超过文本数据，其商业价值也毫不逊色。以全球流量最大的网站Youtube为例，它在07年一年所消耗的网络带宽就等同于整个互联网在2000年的全部流量。另一方面，多媒体数据的来源也是异常丰富。仅以手机为例，手机的摄像头、麦克风可以产生丰富的图像、视频、语音数据。除此之外，社会中的各种监控摄像设备、医疗图像设备、物联网传感设备、卫星图像等都能产生大量的图像、视频数据。而多媒体相对于文本数据更有其得天独厚的优势：丰富的多媒体数据对人的感官刺激远胜过纯文本数据。以新浪微博为例，微博中被大量关注和转发的微博大都含有图片、视频等链接；相反，纯文字的微博受关注的程度还是会差不少。同样，微信以语音作为主要的信息载体，一举与纯文本的短信形成差异化竞争优势，再加上产品的社交因素而一炮走红，现在大家经常能在街上看见与手机上的微信好友对话的用户。在零售行业，基于图像的大数据分析也将打开一片新的市场。例如在一个大型的购物中心，我们可以对人流的视频数据进行分析，从而对消费者的购物习惯、逛街顺序等信息进行充分挖掘，从而有针对性地设计相应的促销方案、货架摆放规律等等。在安防行业，基于对视频数据的实时分析，我们可以监控潜在的安全隐患（例如检测出消防通道被占用需要及时清理），大大提升安全措施的响应时间。可以预见，基于多媒体数据的大数据分析将对互联网、零售、安防、生物医药等在内的众多领域发挥重要的作用。</p>\n<p>在笔者看来，基于多媒体数据的大数据分析主要的技术难点就在于数据量和算法复杂度大大增加。Google在2012年有一项曾引起广泛关注的研究成果：他们使用了一千台电脑的一点六万颗处理器核组建了一个机器学习神经网络，花了三天时间用来自Youtube中截取的1000万幅图像来训练该神经网络，从而使得该网络可以自主学习并形成了“猫”这个概念，最终成功地识别出猫的图像。从这个例子中我们可以看到，要对海量图像、视频进行分析所需要的机器规模确实对计算资源和软件算法提出了极大挑战。好在视频、图像、语音处理并不是一个什么崭新的领域，这些方向都有很多的技术积累。笔者认为，真正的挑战可能在于如何将现有的多媒体处理技术扩展到大规模数据上去，毕竟对小规模数据有效的算法可能在处理超大规模的数据时会遇到从未有过的挑战。但是笔者也相信，基于多媒体数据的分析技术也一定会在未来得到蓬勃发展，并为用户创造新的价值。</p>\n","descriptionType":"html","publishedDate":"Fri, 08 Mar 2013 02:59:46 +0000","feedId":9852,"bgimg":"","linkMd5":"b10bd8d10d6727ec634149854a2f0367","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"IBM中国研究院招聘大规模数据分析实习生","link":"http://www.parallellabs.com/?p=1094","description":"<p>帮同事发文，招聘实习生：</p>\n<p>IBM Research China is looking for undergraduate and graduate computer science/engineering students who are interested in Big Data Analytics development and performance optimizations works. </p>\n<p>Location: Beijing<br />\nJob Tile: Research Intern<br />\nJob Openings: 1-2<br />\nExpected Duration: at least 3 months (full time)</p>\n<p>Job responsibilities:<br />\n&#8211; Develop text mining solutions such as Topic Detection and Tracking (TDT).<br />\n&#8211; Write Apache MapReduce user function code to implement Social Network Analysis (SNA), Machine Learning and Text Mining algorithms.<br />\n&#8211; Tune and optimize the performance of Apache MapReduce/HDFS based analytics workload on POWER7.<br />\n&#8211; Publish high quality research papers to report your work. </p>\n<p>Required skills:<br />\n&#8211; Knowledge of 1) Parallel Computing and Distributed Systems or 2) Machine Learning and Data Mining<br />\n&#8211; Knowledge of Java<br />\n&#8211; Familiarity with Linux as development and testing environments.<br />\n&#8211; Experience of Apache Hadoop will be a plus. </p>\n<p>We also encourage exceptional students to generate and implement their own ideas about Big Data Analytics related works over the course of internship. </p>\n<p>If you&#8217;re interested, please feel free to drop us an email to jwshi_at_cn.ibm.com with your resume. </p>\n","descriptionType":"html","publishedDate":"Thu, 01 Sep 2011 16:22:04 +0000","feedId":9852,"bgimg":"","linkMd5":"1579cea380fd22b90fa8bf3ddb80c9a1","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多核编程的难题（一）","link":"http://www.parallellabs.com/?p=611","description":"<p>最近David Patterson老爷子（就是计算机体系结构&#8211;量化方法的作者之一）发表了一篇文章《<a href=\"http://spectrum.ieee.org/computing/software/the-trouble-with-multicore\" target=\"_blank\">The trouble with multicore</a>》，文章高屋建瓴的分析了一下多核发展的当前形势，文章开篇就说了一句话“造芯片的家伙们正忙着生产那些大多数程序员不知道如何编程的多核CPU”。这不由的让我想起我跟我导师Per Stenstrom的一次对话，我问他说“现在多核出来了，有一大堆新的难题等着我们去解决，作为研究人员您是否觉得很兴奋呢？”结果他说“其实我还是有点沮丧的，因为我们是被迫转到多核上来的。”</p>\n<p>其实这就道出了多核发展中的一个关键：造硬件的没办法在单核上继续像以前那样容易地提升性能了（有兴趣的朋友可以查下“Power Wall”），为了利用更多的晶体管提高性能，只好走多核这条路，但是在他们选择走这条路的时候，所有人都不知道该如何在多核平台上有效的进行编程，David Patterson管这个叫“Hail Mary”，简单翻译过来就是“让我们多核吧，但是该咋进行多核编程就祈祷奇迹的发生吧！”</p>\n<p>好吧，为什么多核编程很困难？一个形象的例子就是把编程比作写书，理论上10个作者同时写一本书应该会比一个人写快10倍。但是他们首先要把任务均匀的分成10份，否则任务最多的那个作者会拖后腿肯定就快不了10倍了。但是呢光这个还不够，如果这个故事中的某一部分必须要在其他部分写完之后才能写，这种顺序上的依赖关系也会拖慢速度；而且10个作者的故事情节还得一致，那么他们肯定少不了沟通啊，这又慢了一点。这就是三个多核编程的最大挑战：“load balancing（负载均衡）”、“sequential dependency（顺序依赖关系）”和“synchronization（同步）”。</p>\n<p>难道就没有人尝试着解决这个问题吗？有啊！从60年代开始，一堆一堆的天才们尝试着创造新的编程语言好让并行编程更加美好：APL，Id，Linda，Occam，SISAL等等，他们中有的确实让并行编程更加容易了，但是没有一个人能成功的让他们向传统的串行编程语言一样兼具性能、效率和灵活性，更没有像C/C++、Java这样主要为串行编程设计的语言一样流行。我记得有人问过“Java的并发包挺好用的啊，是不是足够解决多核编程的问题了呢？”，我觉得不然。在语言上进行并行编程的扩展确实是有效的办法，但是它却不能从根本上解决并行编程困难的问题。最根本的原因是这些语言并不是天生为并发而设计的，这就决定了所有的库都只能给你提供并行编程最原始的工具，但是对程序员来说并行编程却并没有因为有了这些库就变得更容易了，你还是得面临死锁dead lock、数据竞跑data race、伪共享false sharing、锁竞争lock contention等种种问题。</p>\n<p>讲到这我就想起Erlang了，它就是一种天生为并发设计的语言。它的并发模型核心是基于消息传递机制的轻量级进程，进程之间不共享内存。这样的模型好处就在于每个进程是相互独立的，要通信就发消息好了，最大程度上减少了进程间的依赖关系，从而能提高整体性能，而且核越多跑的越快。但是我们要考虑到Erlang最初是Ericsson为电信系统设计的语言，由它编写的程序的目标就是为了提高系统的throughput以便为更多的用户提供服务，这也是大部分服务器端程序的目标。它们的共同特征是每个用户的请求大部分情况下都是彼此独立的，所以多核对这样的高并发应用来讲其实是有点天生一对的感觉。但是对于传统的客户端程序来讲，latency才是它们的首要目标。例如大型的商业软件，它所希望的是完成一个任务的速度能够更快，或者单位时间内能处理更多的数据。</p>\n<p>另一个解决并行编程难的思路就是设计更易进行并行编程的硬件，现在最火的Transactional Memory（事务性内存）就是其中的典范。但是现在它们还只处于研究阶段，里面有一大堆的问题尚待解决，最主要的就是性能还不足以到商用阶段。</p>\n<p>还有的人尝试过用编译器自动并行化，但是多年的研究表明纯粹让编译器来给你进行自动并行化是完全走不通了。它能在一定程度上提升程序的性能，但是非常有限，而且随着核数的增加它对性能的提升会更加有限。</p>\n<p>那么多核时代的曙光在哪里呢？请看我<a href=\"http://www.parallellabs.com/2010/09/20/the-trouble-with-multicore-2/\">下一篇文章</a>。</p>\n","descriptionType":"html","publishedDate":"Tue, 17 Aug 2010 04:49:14 +0000","feedId":9852,"bgimg":"","linkMd5":"e3bf44951d91073c5b3c4a3f7fe038bf","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Google创始人的求职目标","link":"http://www.parallellabs.com/?p=656","description":"<p>想知道Google创始人之一的谢尔盖·布林学生时代的求职目标么？</p>\n<p>在他Stanford的resume页面上的一段被注释掉了的html代码透露了他的秘密：</p>\n<pre class=\"brush: xml; title: ; notranslate\">&#60;!--&#60;H4&#62;Objective:&#60;/H4&#62;\nA large office, good pay, and very little work.\nFrequent expense-account trips to exotic lands would be a plus.--&#62; </pre>\n<p><a href=\"http://infolab.stanford.edu/~sergey/resume.html\">瞻仰遗址</a>。</p>\n<p>此八卦来自威武的<a href=\"http://www.unclexia.net/?p=761\" target=\"_blank\">虾叔</a>。</p>\n","descriptionType":"html","publishedDate":"Wed, 13 Oct 2010 00:08:53 +0000","feedId":9852,"bgimg":"","linkMd5":"234add5ad23da973a1a25044b70b68f9","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"史蒂夫乔布斯(Steve Jobs)在Stanford2005年毕业典礼上的演讲","link":"http://www.parallellabs.com/?p=736","description":"<p><embed src=\"http://player.youku.com/player.php/sid/XMTM3OTM5OTA0/v.swf\" quality=\"high\" width=\"480\" height=\"400\" align=\"middle\" allowScriptAccess=\"sameDomain\" type=\"application/x-shockwave-flash\"></embed></p>\n<p>我觉得这是我看过的最好的演讲之一。三个故事每一个都让我深受触动。</p>\n<p>这句话让我忍不住留下眼泪：<br />\n“And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.”<br />\n“还有最重要的是, 你要有勇气去听从你直觉和心灵的指示——它们在某种程度上知道你想要成为什么样子，所有其他的事情都是次要的。 ”</p>\n<p>今天我老板<a href=\"http://129.16.20.23/~pers/\">Prof. Per Stenström</a>也跟我说：<br />\n“Keep the focus on what you believe in and keep delivering what you promised yourself to deliver. Your contributions will not only be rewarding for yourself;  it will likely make a significant contribution to our society.”</p>\n<p>博士与工业界之间我选择了后者，在即将毕业之时，我热切期待着下一个让我成长的机会，每个人都应该寻找并追寻自己内心最深切的渴望，Stay hungry, Stay foolish!</p>\n","descriptionType":"html","publishedDate":"Tue, 26 Oct 2010 18:13:22 +0000","feedId":9852,"bgimg":"","linkMd5":"ef8bb78359445fa39e6e4b238f052662","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"多线程队列的算法优化","link":"http://www.parallellabs.com/?p=680","description":"<p>多线程队列（Concurrent Queue）的使用场合非常多，高性能服务器中的消息队列，并行算法中的Work Stealing等都离不开它。对于一个队列来说有两个最主要的动作：添加（enqueue）和删除（dequeue）节点。在一个（或多个）线程在对一个队列进行enqueue操作的同时可能会有一个（或多个）线程对这个队列进行dequeue操作。因为enqueue和dequeue都是对同一个队列里的节点进行操作，为了保证线程安全，一般在实现中都会在队列的结构体中加入一个队列锁（典型的如pthread_mutex_t q_lock），在进行enqueue和dequeue时都会先锁住这个锁以锁住整个队列然后再进行相关的操作。这样的设计如果实现的好的话一般性能就会很不错了。以链表实现的队列的结构体一般是这样的：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nstruct queue_t {\n    node_t *head;\n    node_t *tail;\n    pthread_mutex_t q_lock;\n};\n</pre>\n<p>但是，这其中其实有一个潜在的性能瓶颈：enqueue和dequeue操作都要锁住整个队列，这在线程少的时候可能没什么问题，但是只要线程数一多，这个锁竞争所产生的性能瓶颈就会越来越严重。那么我们可不可以想办法优化一下这个算法呢？当然可以！如果我们仔细想一想enqueue和dequeue的具体操作就会发现他们的操作其实不一定是冲突的。例如：如果所有的enqueue操作都是往队列的尾部插入新节点，而所有的dequeue操作都是从队列的头部删除节点，那么enqueue和dequeue大部分时候都是相互独立的，我们大部分时候根本不需要锁住整个队列，白白损失性能！那么一个很自然就能想到的算法优化方案就呼之欲出了：我们可以把那个队列锁拆成两个：一个队列头部锁（head lock)和一个队列尾部锁(tail lock)。这样这样的设计思路是对了，但是如果再仔细思考一下它的实现的话我们会发现其实不太容易，因为有两个特殊情况非常的tricky（难搞）：第一种就是往空队列里插入第一个节点的时候，第二种就是从只剩最后一个节点的队列中删除那个“最后的果实”的时候。</p>\n<p>为什么难搞呢？当我们向空队列中插入第一个节点的时候，我们需要同时修改队列的head和tail指针，使他们同时指向这个新插入的节点，换句话说，我们此时即需要拿到head lock又需要拿到tail lock。而另一种情况是对只剩一个节点的队列进行dequeue的时候，我们也是需要同时修改head和tail指针使他们指向NULL，亦即我们需要同时获得head和tail lock。有经验的同学会立刻发现我们进入危险区了！是什么危险呢？死锁！多线程编程中最臭名昭著的一种bug就是死锁了。例如，如果线程A在锁住了资源1后还想要获取资源2，而线程B在锁住了资源2后还想要获取资源1，这时两个线程谁都不能获得自己想要的那个资源，两个线程就死锁了。所以我们要小心奕奕的设计这个算法以避免死锁，例如保证enqueue和dequeue对head lock和tail lock的请求顺序（lock ordering）是一致的等等。但是这样设计出来的算法很容易就会包含多次的加锁/解锁操作，这些都会造成不必要的开销，尤其是在线程数很多的情况下反而可能导致性能的下降。我的亲身经历就是在32线程时这个思路设计出来的算法性能反而下降了10%左右，原因就是加锁/解锁的开销增加了。</p>\n<p>好在有聪明人早在96年就想到了一个更妙的算法。这个算法也是用了head和tail两个锁，但是它有一个关键的地方是它在队列初始化的时候head和tail指针不为空，而是指向一个空节点。在enqueue的时候只要向队列尾部添加新节点就好了。而dequeue的情况稍微复杂点，它要返回的不是头节点，而是head->next，即头节点的下一个节点。先来看伪代码：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\ntypedef struct node_t {\n    TYPE value; \n    node_t *next\n} NODE;\n\ntypedef struct queue_t {\n    NODE *head; \n    NODE *tail;\n    LOCK q_h_lock;\n    LOCK q_t_lock;\n} Q;\n\ninitialize(Q *q) {\n   node = new_node()   // Allocate a free node\n   node-&#62;next = NULL   // Make it the only node in the linked list\n   q-&#62;head = q-&#62;tail = node\t// Both head and tail point to it\n   q-&#62;q_h_lock = q-&#62;q_t_lock = FREE   // Locks are initially free\n}\n\nenqueue(Q *q, TYPE value) {\n   node = new_node()       // Allocate a new node from the free list\n   node-&#62;value = value\t  // Copy enqueued value into node\n   node-&#62;next = NULL       // Set next pointer of node to NULL\n   lock(&#38;q-&#62;q_t_lock)\t  // Acquire t_lock in order to access Tail\n      q-&#62;tail-&#62;next = node // Link node at the end of the queue\n      q-&#62;tail = node       // Swing Tail to node\n   unlock(&#38;q-&#62;q_t_lock)    // Release t_lock\n｝\n\ndequeue(Q *q, TYPE *pvalue) {\n   lock(&#38;q-&#62;q_h_lock)   // Acquire h_lock in order to access Head\n      node = q-&#62;head    // Read Head\n      new_head = node-&#62;next\t     // Read next pointer\n      if new_head == NULL         // Is queue empty?\n         unlock(&#38;q-&#62;q_h_lock)     // Release h_lock before return\n         return FALSE             // Queue was empty\n      endif\n      *pvalue = new_head-&#62;value   // Queue not empty, read value\n      q-&#62;head = new_head  // Swing Head to next node\n   unlock(&#38;q-&#62;q_h_lock)   // Release h_lock\n   free(node)\t\t\t  // Free node\n   return TRUE\t\t\t  // Queue was not empty, dequeue succeeded\n}\n</pre>\n<p>发现玄机了么？是的，这个算法中队列总会包含至少一个节点。dequeue每次返回的不是头节点，而是头节点的下一个节点中的数据：如果head->next不为空的话就把这个节点的数据取出来作为返回值，同时再把head指针指向这个节点，此时旧的头节点就可以被free掉了。这个在队列初始化时插入空节点的技巧使得enqueue和dequeue彻底相互独立了。但是，还有一个小地方在实现的时候需要注意：对第一个空节点的next指针的读写。想象一下，当一个线程对一个空队列进行第一次enqueue操作时刚刚运行完第25行的代码（对该空节点的next指针进行写操作）；而此时另一个线程对这个队列进行第一次dequeue操作时恰好运行到第33行（对该空节点的next指针进行读操作），它们其实还是有冲突！不过，好在一般来讲next指针是32位数据，而现代的CPU已经能保证多线程程序中内存对齐了的32位数据<a href=\"http://www.parallellabs.com/2010/04/15/atomic-operation-in-multithreaded-application/\">读写操作的原子性</a>，而一般来讲编译器会自动帮你对齐32位数据，所以这个不是问题。唯一需要注意的是我们要确保enqueue线程是先让要添加的新节点包含好数据再把新节点插入链表（也就是不能先插入空节点，再往节点中填入数据），那么dequeue线程就不会拿到空的节点。其实我们也可以把q_t_lock理解成生产者的锁，q_h_lock理解成消费者的锁，这样生产者（们）和消费者（们）的操作就相互独立了，只有在多个生产者对同一队列进行添加操作时，以及多个消费者对同一队列进行删除操作时才需要加锁以使访问互斥。</p>\n<p>通过使用这个算法，我成功的把一个32线程程序的性能提升了11%！可见多线程中的锁竞争对性能影响之大！此算法出自一篇著名的论文：M. Michael and M. Scott. <a href=\"http://www.cs.rochester.edu/research/synchronization/pseudocode/queues.html\" target=\"_blank\">Simple, Fast, and Practical Non-Blocking and Blocking Concurren Queue Algorithms</a>. 如果还想做更多优化的话可以参考这篇论文实现相应的Non Blocking版本的算法，性能还能有更多提升。当然了，这个算法早已被集成到java.util.concurrent里了（即LinkedBlockingQueue），其他的并行库例如Intel的TBB多半也有类似的算法，如果大家能用上现成的库的话就不要再重复造轮子了。为什么别造并行算法的轮子呢？因为高性能的并行算法实在太难正确地实现了，尤其是Non Blocking，Lock Free之类的“火箭工程”。有多难呢？Doug Lea提到java.util.concurrent中一个Non Blocking的算法的实现大概需要1年的时间，总共约500行代码。所以，对最广大的程序员来说，别去写Non Blocking, Lock Free的代码，只管用就行了，我看见网上很多的Non Blocking阿，无锁编程的算法实现啊什么的都非常地害怕，谁敢去用他们贴出来的这些代码啊？我之所以推荐这个two lock的算法是因为它的实现相对Non Blocking之类的来说容易多了，非常具备实用价值。虽然这篇论文出现的很早，但是我在看了几个开源软件中多线程队列的实现之后发现他们很多还是用的本文最开始提到的那种一个锁的算法。如果你想要实现更高性能的多线程队列的话，试试这个算法吧！</p>\n<p>Update: 多线程队列算法有很多种，大家应根据不同的应用场合选取最优算法（例如是CPU密集型还是IO密集型）。本文所列的算法应用在这样一个多线程程序中：每个线程都拥有一个队列，每个队列可能被本线程进行dequeue操作，也可以被其他线程进行dequeue（即work stealing），线程数不超过CPU核心数，是一个典型的CPU/MEM密集型客户端单写者多读者场景。</p>\n","descriptionType":"html","publishedDate":"Sun, 24 Oct 2010 16:52:57 +0000","feedId":9852,"bgimg":"","linkMd5":"6d38572b8e04cf0934c732d3fb9a0551","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"采访Hadoop创始人Doug Cutting纪要","link":"http://www.parallellabs.com/?p=1128","description":"<p>2020年6月9日，无意在Wordpress草稿箱发现了11年跟@董世晓一起对Doug Cutting的采访纪要。感谢世晓和CSDN给我这个机会。9年之后回顾这个采访内容，还觉得很有意思。一个影响行业的技术大牛，都是在一个技术领域深耕多年的。而最早开源的原因，竟然是Doug想复用他写的代码：）</p>\n<p>最后修改 2011-12-05</p>\n<dl>\n<dd>有关Doug Cutting这次采访的更详细内容，请关注最新一期<a href=\"http://weibo.com/n/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%9D%82%E5%BF%97\">@程序员杂志</a></p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:24\" href=\"http://weibo.com/1730295057/xAzm3brEk\">2分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>最后，感谢CSDN<a href=\"http://weibo.com/n/CSDN%E8%91%A3%E4%B8%96%E6%99%93\">@CSDN董世晓</a> <a href=\"http://weibo.com/n/%E5%88%98%E6%B1%9FCE\">@刘江CE</a> <a href=\"http://weibo.com/n/%E8%92%8B%E6%B6%9BCSDN\">@蒋涛CSDN</a> 给我这个机会一起采访Doug，收获很大！</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:22\" href=\"http://weibo.com/1730295057/xAzlt8mBr\">3分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>19）Doug最近刚换了一个Dell的30‘显示器，竖着放，写代码方便:)</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:21\" href=\"http://weibo.com/1730295057/xAzl0snbc\">4分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>16）Doug觉得他的成功有两点很关键：一是对这份工作很有热情，二是不要比目标定的太高，一步一个脚印比较实际，而且容易做到。17）Doug一周工作5天（非常非常努力的工作），然后周末休息:) 18）他用微软的nature键盘，因为右手有严重的关节炎，所以10年前就换用左手的轨迹球（好像是？）了。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:21\" href=\"http://weibo.com/1730295057/xAzkNsJql\">5分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>15）Doug早在大学就开始做infrastructure类的程序并乐在其中，他觉得他非常喜欢自己的程序被千万人使用的感觉。对了，当年他用Lisp给Emacs贡献过代码:)</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:18\" href=\"http://weibo.com/1730295057/xAzjQFpTd\">7分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>14）Cloudera的客户大都是传统行业，他们通过使用Hadoop来处理之前只能被直接抛弃的大规模数据。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:16\" href=\"http://weibo.com/1730295057/xAzj3ACuQ\">9分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>12）当时面试了Yahoo, IBM等，Doug的重点是想在hadoop上花更多功夫并改进它，因为IBM当时只关心Lucene，Yahoo却能提供资源开发hadoop，于是加入Yahoo！IBM的遗憾啊！13）之后加入Cloudera，目标以Hadoop这个Big Data Kernel发展成Cloud领域中的RedHat。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:15\" href=\"http://weibo.com/1730295057/xAzixFItk\">10分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>10）于是开始在家做Lucene，先放在SourFought上，用GPL，后来转到LGPL，但是公司不怎么喜欢这个license，于是转到Apache上。11）基于Lucene开了一家consulting公司，但是开公司啥杂事都要自己管，还得每天催账单，于是想加入一个大公司专心写code。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:12\" href=\"http://weibo.com/1730295057/xAzhlfv2y\">13分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>8）之后加入InfraSearch，但是它之后被Sun收购，Doug不想给Sun干活，觉得那个项目没意思，于是拍屁股走人。9）在搜索领域工作了这么多年，换了这么多公司，他很想复用原来的一些代码，于是想到做一个开源搜索引擎，这样以后再换公司也可以用这个代码。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:09\" href=\"http://weibo.com/1730295057/xAzg3rK92\">16分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>7）当时的Excite跟其他大部分公司都用最传统的排序方式来展示搜索结果，他们并不觉得这是个问题，而且搜索业务已经开始有广告收入，所以那时候他们的重心是做在线日历，邮箱，个人主页等。温水煮青蛙，结果他们的市场被Google干掉，多么像今天的Nokia。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:04\" href=\"http://weibo.com/1730295057/xAzear7ip\">21分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>6）Doug觉得Google成功有两大关键：一、反向排序之后再存储对搜索引擎的改进非常大，这个技术比pagerank更重要；二、他们对自己的技术非常有信心，觉得他们解决了一个被当时的巨头（Excite，Infoseek等）认为完全不重要的问题。再次印证一个道理，game changer永远不会等消费者来告诉你他们需要什么。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 08:01\" href=\"http://weibo.com/1730295057/xAzcVAGOs\">24分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>4）离开苹果的原因是他参与的OS被cancel了，其后苹果把乔布斯的Next给买回来做了新的MacOS. 5）之后加入Excite做网页搜索，期间Googler两个创始人去Excite兜售他们的技术，但是因为当时这两人的demo检索的网页量只有几百万，觉得他们太小儿科了，于是两哥们被鄙视，于是自己创业，于是有了Google。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 07:58\" href=\"http://weibo.com/1730295057/xAzbGuOYD\">27分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>2）毕业后去苏格兰工作一年半之后回到Xerox，期间做了4年多研究，发论文发专利并开始学习信息检索，正式开始深入学习搜索技术。3）研究对工业界的影响不够直接，因此继续去苹果转作做搜索技术的开发，他现在的代码应该还跑在MacOS的finder中。不过他现在用Linux <img src=\"https://s.w.org/images/core/emoji/11.2.0/72x72/1f642.png\" alt=\"🙂\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /></p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 07:54\" href=\"http://weibo.com/1730295057/xAza42OnF\">31分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n<dd></dd>\n</dl>\n<dl>\n<dd>昨天与<a href=\"http://weibo.com/n/CSDN%E8%91%A3%E4%B8%96%E6%99%93\">@CSDN董世晓</a> 一起采访了Doug Cutting，有几个段子印象很深刻，与大家分享一下：1）Doug最早在Xerox实习期间给GUI OS写屏保程序，其他同事可以给这个程序添加不同的主题，这算是他最早的“平台”作品，并乐在其中。</p>\n<p><a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">转发</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">收藏</a><em>|</em> <a href=\"http://weibo.com/parallellabs/profile?topnav=1&#38;wvr=3.6\">评论</a><a title=\"2011-12-05 07:52\" href=\"http://weibo.com/1730295057/xAz91zLNY\">34分钟前</a> 来自<a href=\"http://weibo.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">新浪微博</a></dd>\n</dl>\n","descriptionType":"html","publishedDate":"Tue, 09 Jun 2020 00:31:40 +0000","feedId":9852,"bgimg":"https://s.w.org/images/core/emoji/11.2.0/72x72/1f642.png","linkMd5":"c4f3d185b21523dd1128c610849f4b28","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn95@2020_1/2020/08/25/00-37-01-864_6d4495c4489cf88c.webp","destWidth":72,"destHeight":72,"sourceBytes":620,"destBytes":1362,"author":"Guancheng (G.C.)","articleImgCdnMap":{"https://s.w.org/images/core/emoji/11.2.0/72x72/1f642.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn95@2020_1/2020/08/25/00-37-01-864_6d4495c4489cf88c.webp"},"publishedOrCreatedDate":1598315821746},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Understanding System and Architecture for Big Data","link":"http://www.parallellabs.com/?p=1208","description":"<p>简介：IBM Research最近在Big Data领域有很多工作，例如我们组在4月份在10台采用POWER7处理器的P730服务器上成功地用14分钟跑完了1TB数据的排序(7月份又在10台Power7R2上用8分44秒跑完了1TB排序)，这项工作已经发表为一篇IBM Research Report，欢迎大家围观，并提出宝贵意见，谢谢。</p> \n<p><span style=\"color: #000000;\">The use of&nbsp;Big&nbsp;Data&nbsp;underpins critical activities in all sectors of our society. Achieving the full transformative potential of&nbsp;Big&nbsp;Data&nbsp;in this increasingly digital world requires both new&nbsp;data&nbsp;analysis algorithms and a new class of systems to handle the dramatic&nbsp;data&nbsp;growth, the demand to integrate structured and unstructured&nbsp;data&nbsp;analytics, and the increasing computing needs of massive-scale analytics. In this paper, we discuss several&nbsp;Big&nbsp;Data&nbsp;research activities at IBM Research: (1)&nbsp;Big&nbsp;Data&nbsp;benchmarking and methodology; (2) workload optimized systems for&nbsp;Big&nbsp;Data; (3) case study of&nbsp;Big&nbsp;Data&nbsp;workloads on IBM Power systems. In (3), we show that preliminary infrastructure tuning results in sorting 1TB&nbsp;data&nbsp;in 14 minutes on 10 Power 730 machines running IBM InfoSphere&nbsp;BigInsights. Further improvement is expected, among other factors, on the new IBM PowerLinuxTM 7R2 systems.</span></p> \n<p>By:<em>&nbsp;Anne E. Gattiker, Fadi H. Gebara, Ahmed Gheith, H. Peter Hofstee, Damir A. Jamsek, Jian Li, Evan Speight, Ju Wei Shi, Guan Cheng Chen, Peter W. Wong</em></p> \n<p>Published in: RC25281 in 2012</p> \n<p><strong>LIMITED DISTRIBUTION NOTICE:</strong></p> \n<p><strong>This Research Report is available. This report has been submitted for publication outside of IBM and will probably be copyrighted if accepted for publication. It has been issued as a Research Report for early dissemination of its contents. In view of the transfer of copyright to the outside publisher, its distribution outside of IBM prior to publication should be limited to peer communications and specific requests. After outside publication, requests should be filled only by reprints or legally obtained copies of the article (e.g., payment of royalties). I have read and understand this notice and am a member of the scientific community outside or inside of IBM seeking a single copy only.</strong></p> \n<p><span style=\"color: #0000ff;\"><strong>Download link:&nbsp;<a href=\"http://domino.research.ibm.com/library/cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/f085753cf57c8c35852579e90050598f!OpenDocument&amp;Highlight=0,big,data\" target=\"_blank\">http://domino.research.ibm.com/library/cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/f085753cf57c8c35852579e90050598f!OpenDocument&amp;Highlight=0,big,data</a></strong></span></p> \n<p>Questions about this service can be mailed to&nbsp;<a href=\"mailto:reports@us.ibm.com\">reports@us.ibm.com</a>&nbsp;.</p>","descriptionType":"html","publishedDate":"Wed, 09 May 2012 13:18:49 +0000","feedId":9852,"bgimg":"","linkMd5":"852662c3b3f2e53f596149e4e4e68d2a","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"C++ AMP异构并行编程解析","link":"http://www.parallellabs.com/?p=1202","description":"<p><strong>原文发表于《程序员》杂志2012年第4期，略有改动。</strong></p>\n<p><strong>文</strong><strong> / </strong><strong>陈冠诚</strong></p>\n<p align=\"left\">微软在今年2月份的GoingNative大会上正式对外发布了C++ AMP（Accelerated Massive Parallelism）开放规范。C++ AMP是微软于11年6月推出的一个异构并行编程框架，从Visual Studio 11开发者预览版起，微软正式提供了C++AMP的支持。C++ AMP的目标是降低在由CPU和GPU共同组成的异构硬件平台上进行数据并行编程（data parallel）的门槛。通过C++ AMP，开发者将获得一个类似C++ STL的库，这个库将作为微软concurrency namespace的一部分，开发者既不需要学习新的C++语法，也不需要更换编译器就能够方便地进行异构并行编程。本文主要介绍C++ AMP的设计原则和语法规则，并将其与CUDA和OpenCL这两个已有的异构并行编程框架进行了对比，希望对大家了解异构并行编程有所帮助。</p>\n<h2>C++ AMP设计原则</h2>\n<p align=\"left\">随着CPU由单核向多核转移，多核计算成为了近几年的热点。另一方面，GPU编程也经历着一场变革。传统意义上，GPU一直是作为图形图像专用处理器而存在。然后，因为GPU拥有比CPU还要强大的浮点并行运算能力，我们是不是能让GPU来完成一些通用的计算任务呢？答案是肯定的，例如科学计算中就需要大量的用到浮点计算。在这样的背景下，我们可以将并行计算从单纯的在多核CPU上做，扩展到在多核CPU与GPU共同组成的异构硬件平台上来。除了多核与GPU通用计算的快速发展职位，云计算更成为软件开发的一个重要趋势。实际上，云端的每一台服务器都可以是由多核CPU和GPU共同组成的异构硬件平台。微软的Herb Sutter介绍说：“我们认为多核编程、GPU编程和云计算根本不是三个独立的趋势。实际上，他们只是同一种趋势的不同方面，我们把这个趋势叫做异构并行编程”。进行异构并行编程需要一个统一的编程模型，这就是微软推出C++ AMP的原因。</p>\n<p align=\"left\">微软决定另起炉灶，推出C++ AMP这样一个全新的异构并行编程模型的原因很简单，他们认为这个编程模型必须同时具备下面这六个特征，而目前已有的CUDA和OpenCL并不同时满足这些需求。</p>\n<ul>\n<li><strong>C++</strong><strong>而不是</strong><strong>C</strong>：这种编程模型应该利用好C++丰富的语言特性（例如抽象，模板，例外处理等），并且不会牺牲性能，因此我们不能像OpenCL一样只是C语言的一种方言；</li>\n<li><strong>主流</strong><strong>:</strong> 这个编程框架应该能被成千上万的开发者所使用，而不是只被少数人所接受。一个立见分晓的检验办法是：用该编程框架实现GPU上的hello world是只需要几行代码，还是需要几十行才行？</li>\n<li><strong>最小的改动</strong><strong>:</strong> 这个编程模型应该只需要在C++上进行最小的改动就能够实现应有的功能。通过一个非常小的、具有良好设计的语言扩展，我们就可以把绝大部分复杂的实现交由运行时系统/库去完成。</li>\n<li><strong>可移植的。</strong>这种编程模型应该让用户只需要一个二进制可执行文件就可以在任何厂商的GPU硬件上面运行。目前我们使用Direct Compute来实现Windows上所有支持DX11的 GPU上的C++ AMP编程模型，但是未来我们会根据用户的需求在其他异构硬件平台上做相应的实现。</li>\n<li><strong>通用且不会过时</strong>。C++ AMP目前针对的是GPU并行计算。但是我们希望，将来C++ AMP的程序可以无缝的扩展到其他形式的计算单元上去，例如FPGA，云端的CPU/GPU处理器等等。</li>\n<li><strong>开放</strong>。微软将吧C++ AMP做成一个开放标准，我们鼓励第三方在任何硬件和操作系统上实现C++ AMP编译器和运行时系统。目前AMD和Nvidia都已经声明将会支持C++ AMP。</li>\n</ul>\n<h2>C++ AMP介绍</h2>\n<p>下面让我们通过一个简单的程序来了解一下C++ AMP的一些语法规则。首先我们需要引用amp.h这个头文件。C++ AMP中的模板都在concurrency这个命名空间内，所以也需要引用。在C++ AMP中主要有array和array_view这两种数据容器。这两者主要的区别在于array类型的数据在创建时会在GPU显存上拥有一个备份，在GPU对该数据进行完运算之后，开发者必须手动将数据拷贝回CPU。与之相比，array_view其实是一个数据结构的封装，只有在它指向的数据被GPU调用时才会被拷贝到GPU上进行相应的计算。从下例中我们看到，声明array_view数据时需要提供两个模板参数：array_view元素的类型和数据结构的纬度。因为aCPP，bCPP和sumCPP都是一维数组，因此我们在声明时传入int和1两个参数。</p>\n<p>接下来就是最重要的计算部分了。parallel_for_each这个方法就是执行在GPU部分的代码的入口。可以看到，parallel_for_each有两个参数，第一个名为sum.extent的参数是用于描述并行计算拓扑结构的对象。通过这个变量，我们指定有多少个GPU线程来并行执行该计算任务，以及这些线程的排列方式。Sum.extend可以理解为按照sum的数据纬度来分配相应数目的GPU线程。Parallel_for_each的第二个参数是一个名为“[=] (index&#60;1&#62; idx) restrict(amp)”的lambda表达式。方括号里的“=”代表了表示lambda表达式的捕获列表。具体来说，“[=]”表示lambda里捕捉的变量按照传值的方式来引用。该for循环的主要参数就是index&#60;1&#62; idx了，它其实代表的是GPU线程的编号。因为之前我们已经通过sum.extent定义好了GPU线程的数量和拓扑结构，因此这个index参数代表的就是一维的数组，即从0到4共5个数。最后一个参数restrict(amp)用来表示parallel_for_each的函数体运行在默认GPU设备上。当然我们也可以定义出amp之外的其他的语法约束，具体的内容请大家参考[1]中的内容。在这之后就是循环体了。这个例子的循环体非常简单，就是让GPU用5个线程并行地把数组a和b中的元素依次相加并存到sum数组中去。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n#include &#60;amp.h&#62;\n#include &#60;iostream&#62;\nusing namespace concurrency;\n\nvoid CampMethod() {\n    int aCPP[] = {1, 2, 3, 4, 5};\n    int bCPP[] = {6, 7, 8, 9, 10};\n    int sumCPP[5] = {0, 0, 0, 0, 0};\n\n    // Create C++ AMP objects.\n    array_view&#60;int, 1&#62; a(5, aCPP);\n    array_view&#60;int, 1&#62; b(5, bCPP);\n    array_view&#60;int, 1&#62; sum(5, sumCPP);\n\n    parallel_for_each(\n        // Define the compute domain, which is the set of threads that are created.\n        sum.extent,\n        // Define the code to run on each thread on the accelerator.\n        [=](index&#60;1&#62; idx) restrict(amp)\n        {\n            sum[idx] = a[idx] + b[idx];\n        }\n    );\n\n    // Print the results. The expected output is &#34;7, 9, 11, 13, 15&#34;.\n    for (int i = 0; i &#60; 5; i++) {\n        std::cout &#60;&#60; sum[i] &#60;&#60; &#34;\\n&#34;;\n    }\n}\n</pre>\n<p>从这个例子我们可以看到，使用C++ AMP进行异构多线程编程确实是很容易的。开发者如果熟悉C++的话，一般只需要很短的时间就可以上手实现相应的功能。</p>\n<h2>CUDA、OpenCL与C++ AMP</h2>\n<p align=\"left\">其实在C++ AMP之前已经有了两个异构编程框架：CUDA与OpenCL。CUDA（Compute Unified Device Architecture）是显卡厂商Nvidia于2007年推出的业界第一款异构并行编程框架。在Nvidia的大力支持下，CUDA拥有良好的开发环境，丰富的函数库，优秀的性能。但是CUDA只能被用于在Nvidia的显卡上进行异构编程，有先天的局限性。OpenCL (Open Computing Language) 是业界第一个跨平台的异构编程框架。它是Apple领衔并联合Nvidia，AMD，IBM，Intel等众多厂商于2008年共同推出的一个开放标准，由单独成立的非营利性组织Khronos Group管理。与C++ AMP类似，OpenCL作为一个开放的标准，并不局限于某个特定的GPU厂商，从这点上来看，Nvidia自己独家的CUDA显得很封闭。我们可以把OpenCL在异构编程上的地位与OpenGL和OpenAL类比，这两个标准分别用于三维图形和计算机音频。</p>\n<p align=\"left\">因为CUDA与OpenCL比C++AMP更接近硬件底层，所以前两者的性能更好，然而与C++ AMP的易编程性却要优于CUDA和OpenCL。与C++ AMP基于C++语言特性直接进行扩展不同，OpenCL是基于C99编程语言进行的相关修改和扩展，因此C++ AMP比OpenCL拥有更高层次的抽象，编程更加简单。在CUDA和OpenCL中，kernels（运行在GPU上的代码）必须被封装成特定函数，而在C++ AMP中，代码看起来整洁的多：我们只需要使用for循环中内嵌的lambda函数就能完成异构并行计算，而且它的内存模型也在一定程度上被大大简化了。</p>\n<div>\n<p>那么在OpenCL、CUDA 与C++ AMP之间，开发者该如何选择呢？</p>\n<p>1）  如果你只需要在Windows平台上进行异构编程，并且看重易编程性的话，C++ AMP无疑是最好的选择。依托于Visual Studio这个强有力的开发工具，再加上基于C++这一更高层抽象带来的先天优势，C++ AMP将为Windows开发者进行异构编程提供良好的支持。</p>\n<p>2）  如果你只需要在Nvidia的GPU卡上进行异构编程，并且非常看重性能的话，CUDA应该是第一选择：在Nvidia的强力支持下，CUDA在Nvidia硬件上的性能一直保持领先，许多学术研究表明OpenCL与CUDA的性能相差不大，在一部分应用中CUDA的性能稍微好于OpenCL。同时CUDA的开发环境也非常成熟，拥有众多扩展函数库支持。</p>\n<p>3）  如果你更注重不同平台间的可移植性，OpenCL可能是目前最好的选择。作为第一个异构计算的开放标准，OpenCL已经得到了包括Intel，AMD，Nvidia，IBM，Oracle，ARM，Apple，Redhat等众多软硬件厂商的大力支持。当然，C++ AMP本身也是一个开放的标准，只是目前只有微软自己做了实现，将来C++ AMP的跨平台支持能做到什么程度还是一个未知数。</p>\n<p>其实从编程语言的发展来看，易编程性往往比性能更加重要。从Java和.Net的流行，到脚本语言的崛起，编程效率无疑是最重要的指标。更不用说开发者往往可以通过更换下一代GPU硬件来获得更好的性能。从这点来看，C++ AMP通过降低异构编程的编程难度，实际上也是推进了异构编程的普及。下面我们需要看的就是C++ AMP是否能成为真正的业界标准，而不仅仅局限于微软自己的平台，微软这次开放C++ AMP标准的行为也正是为了推广C++ AMP在业界的普及。</p>\n</div>\n<h2>总结</h2>\n<p align=\"left\">目前整个业界的异构硬件体系结构仍然处于快速演变之中。可以看到，许多厂商的处理器正在尝试融合CPU和GPU（例如AMD的Fusion，Intel的Larrabee和Nvidia的Tegra3都融合了CPU和GPU）。如果将来的处理器上集成了CPU和GPU，并通过同一条总线使它们与内存直接相连的话，我们就不需要向今天这样把数据在CPU和GPU之间搬来搬去了。随着异构硬件的发展，与之相对应的异构编程框架在需要随着演变。可以预见，今天我们看到的CUDA，OpenCL和C++ AMP都只处于一个初期形态，将来它们还会有很多新的变化。但是有一点我们可以肯定：将来的异构编程一定会比现在更加容易。</p>\n<h2>参考文献</h2>\n<p>[1] Overview of C++ Accelerated Massive Parallelism. <span style=\"text-decoration: underline;\"><a href=\"http://msdn.microsoft.com/en-us/library/hh265136(v=vs.110).aspx\">http://msdn.microsoft.com/en-us/library/hh265136(v=vs.110).aspx</a></span></p>\n<p>[2] C++ AMP实战：绘制曼德勃罗特集图像. <span style=\"text-decoration: underline;\"><a href=\"http://www.cnblogs.com/Ninputer/archive/2012/01/03/2310945.html\">http://www.cnblogs.com/Ninputer/archive/2012/01/03/2310945.html</a></span></p>\n","descriptionType":"html","publishedDate":"Wed, 09 May 2012 13:05:52 +0000","feedId":9852,"bgimg":"","linkMd5":"0784ddb87dea862404d7b4d9525e98d3","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Hello world!","link":"http://www.parallellabs.com/?p=1","description":"<p>Hello world!</p>\n<p><strong><em>“This is Parallel Labs speaking!”</em></strong></p>\n","descriptionType":"html","publishedDate":"Fri, 25 Sep 2009 15:15:38 +0000","feedId":9852,"bgimg":"","linkMd5":"105d83fc688d2e7e25329066e8f89d5f","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"二进制的二三事","link":"http://www.parallellabs.com/?p=564","description":"<p>二进制是计算机的自然语言，逻辑门中神奇的0/1组合犹如那起起伏伏的“滴答”之声构成了曼妙的电子世界。不仅如此，二进制中的0和1往往也是我们解决实际问题的利器。</p>\n<h3>Task1：求一个固定长度集合所有子集</h3>\n<p>最直观的方法就是穷举：对集合中的每个元素来说它要么在当前子集中，要么不在当前子集中，以此依次类推穷举出所有可能的值。如果我们用0表示该元素在当前子集中，用1表示该元素不在当前子集中，我们就可以用一串0/1序列来表示当前的子集。</p>\n<p>例如集合{a, b, c, d, e}中的子集{a, b, c}可以用“11100”来表示，子集{c, d, e}可以用“00111”来表示，空子集{}可以用“00000”来表示。</p>\n<p>那么对任意固定长度的集合a[n]，我们可以从a[0]开始穷举a[0]在子集中和a[0]不在子集中两种情况，再依次类推从a[1]开始一直穷举到a[n-1]为止。于是我们可以得到一个很直观的递归程序：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nvoid sub_sets_recu(int index, int length, char *array, char *bits)\n{\n\tint j = 0;\n\n\tif (index &#62;= length) {\n\t\tfor (j = 0; j &#60; length; j++) {\n\t\t\tif (bits[j] == '1') {\n\t\t\t\tprintf(&#34;%c&#34;, array[j]);\n\t\t\t}\n\t\t}\n\t\tprintf(&#34;\\n&#34;);\n\t}\n\telse {\n\t\tbits[index] = '1';\n\t\tsub_sets_recu(index+1, length, array, bits);\n\t\tbits[index] = '0';\n\t\tsub_sets_recu(index+1, length, array, bits);\n\t}\n}\n</pre>\n<p>但是递归版本的缺点就是需要一个额外的数组bits来存储0/1序列，那么有没有办法改进呢？我们可以先试试把递归改成迭代的方式会不会有效果。</p>\n<p>迭代的关键就在于明白你究竟要做哪些计算步骤，为此我们可以先画出递归函数的Execution Tree来看看：</p>\n<p>&#8212;                       ○<br />\n|                     0/  \\1<br />\n|                     ○    ○<br />\n|                  0/  \\1   .<br />\n|                  ○    ○      .<br />\nn层             .       .       .<br />\n|                .         .<br />\n|               .           .<br />\n|             /  \\        /  \\<br />\n|           ○     ○     ○    ○<br />\n&#8212;</p>\n<p>上图中，第i层的值为1的边来表示a[i]在子集中，值为0的边表示a[i]不在子集中，那么从根节点到所有叶子节点所经过的边的组合就是所有可能的子集组合，例如从根节点到最左叶子节点的组合为“00000”，即空子集。根据完全二叉树的性质，第n层有2^n个节点，所以共有2^n个不同的子集。既然所有的解都已经存储在这颗二叉树中，那么我们自然就可以依此构建一个遍历所有路径的迭代算法。</p>\n<p>思路是有了，但是实际编码中我们需要用到一个跟二进制编码相关的trick了。我们知道任意一个十进制的数是可以用二进制来表示的，反过来我们也可以用十进制来表示二进制啊，“用二进制来思考”其实就是这个trick的关键。既然我们的解是“00000”~“11111”，那么它们自然可以用十进制的0~31来表示。很自然的我们就可以想到如果我们依次遍历0~31这些数，根据它们二进制值中每一位的值是0还是1即可确定当前元素是否在子集中。关于二进制的位操作等相关知识Matrix67的blog[1]有一个系列写的很不错，在此就不再赘述。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nvoid sub_sets_iter(int length, char *array)\n{\n\tint i = 0;\n\tint j = 0;\n\tfor (i = 0; i &#60; (1&#60;&#60;length); i++) {\n\t\tfor (j = 0; j &#60; length; j++) {\n\t\t\tif ((i &#38; (1&#60;&#60;j)) != 0) {\n\t\t\t\tprintf(&#34;%c&#34;, array[j]);\n\t\t\t}\n\t\t}\n\t\tprintf(&#34;\\n&#34;);\n\t}\n}\n</pre>\n<p>再加上测试用的main函数：</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\nint main()\n{\n\tchar a[5] = {'a','b','c','d','e'};\n\tchar b[5];\n\tint i;\n\n#ifdef USE_RECU\n\tfor (i = 0; i &#60; 10000000; i++) {\n\t\tsub_sets_recu(0, 5, a, b);\n\t}\n#else\n\tfor (i = 0; i &#60; 10000000; i++) {\n\t\tsub_sets_iter(5, a);\n\t}\n#endif\n\treturn 0;\n}\n</pre>\n<p>好，代码全写完了，当然应该比试比试两个算法孰优孰劣。测试平台是：cygwin + gcc 3.4.4 + Core2 Duo T7300@2.0GHz</p>\n<p>在测试时已经把两个算法中的printf给注释掉了，只比拼速度。先把gcc的优化设成-O0看看：</p>\n<pre class=\"brush: bash; title: ; notranslate\">\n$ time ./recu.exe\n\nreal    0m8.847s\nuser    0m8.811s\nsys     0m0.046s\n\n$ time ./iter.exe\n\nreal    0m5.093s\nuser    0m4.999s\nsys     0m0.046s\n</pre>\n<p>再看看gcc -O3的结果：</p>\n<pre class=\"brush: bash; title: ; notranslate\">\n$ time ./recu_o3.exe\n\nreal    0m8.285s\nuser    0m8.234s\nsys     0m0.031s\n\n$ time ./iter_o3.exe\n\nreal    0m1.887s\nuser    0m1.796s\nsys     0m0.031s\n</pre>\n<p>结果显示迭代算法优于递归算法。感兴趣的朋友可以反汇编一下编译器优化后的代码，看看为什么迭代算法优化后能快那么多。关于递归与迭代已经有很多分析了，简单说来递归更加直观易懂，但是栈的开销比较大；迭代的算法不容易一开始就想出来，但是一般来说效率更高。从编译器的角度来讲，部分的编译器能把相对简单的递归算法转化成迭代算法，因为递归的算法对编译器来说是更友好的算法，更易于在此基础上做更多的优化。从体系结构的角度来讲，递归算法更易于发挥CPU流水线的特点让多步运算同时执行，而某些特定的架构，例如GPU就没有对递归提供有效的硬件支持，因为栈空间是一个大问题。</p>\n<h3>Task2：小白鼠试毒药问题</h3>\n<p>实验室里有1000个一模一样的瓶子，但是其中的一瓶有毒。可以用实验室的小白鼠来测试哪一瓶是毒药。如果小白鼠喝掉毒药的话，会在一个星期的时候死去，其他瓶子里的药水没有任何副作用。请问最少用多少只小白鼠可以在一个星期以内查出哪瓶是毒药？</p>\n<p>这个问题关键是跳出思维，并不是说瓶子和小白鼠必须一一对应，然后我们用1000只小白鼠，每只各试一瓶药水，等一个礼拜然后出结果。其实我们仔细想想，小白鼠试毒只有两种结果，非“死”即“生”，又是一个0/1状态。很显然我们可以再次构建一个0/1组成的二叉树，由此即可表示不同的试毒结果。假设我们需要n个小白鼠，那么2^n-1应大于等于1000（因为有1000种可能的结果，减一是指要除去小白鼠全部不死的情况 &#8212; 多谢danqi指正），那么最小的n就是10了。</p>\n<h3>总结</h3>\n<p>解决此类问题的关键在于找到能用0/1表示的状态，然后想办法用0/1组成的二进制数来表示不同的结果，从而达到节省存储空间，提高解题效率的目的。</p>\n<p>二进制真是神奇，文章的最后附一张0和1构成的Fibonacci数列（来自[2]）：</p>\n<p><img src=\"http://www.matrix67.com/blogimage/200601111.gif\" alt=\"\" /></p>\n<h3>相关文献</h3>\n<p>[1] <a href=\"http://www.matrix67.com/blog/archives/122\" target=\"_blank\">位运算讲解系列文章</a><br />\n[2] <a href=\"http://www.matrix67.com/blog/archives/60\" target=\"_blank\">Fibonacci数列转二进制图形的惊异发现</a></p>\n<p><span style=\"color: #ffffff;\">转载请注明来自</span><a href=\"http://www.parallellabs.com\" target=\"_blank\"><span style=\"color: #ffffff;\">www.parallellabs.com</span></a></p>\n","descriptionType":"html","publishedDate":"Sat, 15 May 2010 10:14:52 +0000","feedId":9852,"bgimg":"http://www.matrix67.com/blogimage/200601111.gif","linkMd5":"fccb7c7d22e7975787fa7365845c0781","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn15@2020_4/2020/08/25/00-37-01-963_028e7770b40f1ed4.webp","destWidth":523,"destHeight":362,"sourceBytes":14010,"destBytes":11782,"author":"Guancheng (G.C.)","articleImgCdnMap":{"http://www.matrix67.com/blogimage/200601111.gif":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn15@2020_4/2020/08/25/00-37-01-963_028e7770b40f1ed4.webp"},"publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"两个平行世界","link":"http://www.parallellabs.com/?p=1523","description":"\n<p>一个是虚拟世界，一个是物理世界。</p>\n\n\n\n<p>PC时代，两个世界间的通道，大部分是PC机。</p>\n\n\n\n<p>移动互联网时代，两个世界间的通道，大部分是手机。</p>\n\n\n\n<p>IOT时代，两个世界间的通道，IOT的比例会越来越高，手机和PC的占比会越来越低。想象一下，衣食住行，各个能接触的设备，都是IOT。</p>\n\n\n\n<p>通道越来越多，意味着两个平行世界之间的联系越来越紧密。</p>\n\n\n\n<p>2G，3G，4G，5G，新的技术不停促进通道变得更多、连接变得更快。</p>\n\n\n\n<p>不同类型通道的通道载体一直在变化，而变化，就是新机会的源泉。</p>\n\n\n\n<p>ps. 现在互联网人喜欢去做智能制造了：造车，造卫星，造火箭，造鞋，造船。本质上，是把IT驱动的运营能力嵌入到制造业中去，用更高效率满足消费者的需求。</p>\n","descriptionType":"html","publishedDate":"Sun, 24 Feb 2019 03:05:46 +0000","feedId":9852,"bgimg":"","linkMd5":"b10a98ab8b4f28227ac4a76f76c79fe5","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"为什么程序员需要关心顺序一致性（Sequential Consistency）而不是Cache一致性（Cache Coherence？）","link":"http://www.parallellabs.com/?p=367","description":"<p><em><span style=\"color: #0000ff;\">最后一次修改：2010年11月11日</span></em></p>\n<p>本文所讨论的计算机模型是Shared Memory Multiprocessor，即我们现在常见的共享内存的多核CPU。本文适合的对象是想用C++或者Java进行多线程编程的程序员。本文主要包括对Sequential Consistency和Cache Coherence的概念性介绍并给出了一些相关例子，目的是帮助程序员明白为什么需要在并行编程时关注Sequential Consistency。</p>\n<p>Sequential Consistency（下文简称SC）是Java内存模型和即将到来的C++0x内存模型的一个关键概念，它是一个最直观最易理解的多线程程序执行顺序的模型。Cache Coherence（下文简称CC）是多核CPU在硬件中已经实现的一种机制，简单的说，它确保了对在多核CPU的Cache中一个地址的读操作一定会返回那个地址最新的（被写入）的值。</p>\n<p>那么为什么程序员需要关心SC呢？因为现在的硬件和编译器出于性能的考虑会对程序作出违反SC的优化，而这种优化会影响多线程程序的正确性，也就是说你用C++编写的多线程程序可能会得到的不是你想要的错误的运行结果。Java从JDK1.5开始加入SC支持，所以Java程序员在进行多线程编程时需要注意使用Java提供的相关机制来确保你程序的SC。程序员之所以不需要关心CC的细节是因为现在它已经被硬件给自动帮你保证了（不是说程序员完全不需要关心CC，实际上对程序员来说理解CC的大致工作原理也是很有帮助的，典型的如避免多线程程序的<a href=\"http://blog.yufeng.info/archives/783\">伪共享问题</a>，即<a href=\"http://en.wikipedia.org/wiki/False_sharing\">False Sharing</a>）。</p>\n<p>那么什么是SC，什么是CC呢？</p>\n<h3>1. Sequential Consistency (顺序一致性）</h3>\n<p>SC的作者Lamport给的严格定义是：<br />\n<em>&#8220;&#8230; the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.&#8221;</em></p>\n<p>这个概念初次理解起来拗口，不过不要紧，下面我会给出个很直观的例子帮助理解。</p>\n<p>假设我们有两个线程（线程1和线程2）分别运行在两个CPU上，有两个初始值为0的全局共享变量x和y，两个线程分别执行下面两条指令：</p>\n<p>初始条件： x = y = 0;</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><em>线程 1</em></td>\n<td style=\"text-align: center;\" width=\"50%\"><em>线程 2</em></td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\">x = 1;</td>\n<td style=\"text-align: center;\" width=\"50%\">y=1;</td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\">r1 = y;</td>\n<td style=\"text-align: center;\" width=\"50%\">r2 = x;</td>\n</tr>\n</tbody>\n</table>\n<p>因为多线程程序是交错执行的，所以程序可能有如下几种执行顺序：</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody></tbody>\n</table>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"33.333333333333336%\">Execution 1</td>\n<td style=\"text-align: center;\" width=\"33.333333333333336%\">Execution 2</td>\n<td style=\"text-align: center;\" width=\"33.333333333333336%\">Execution 3</td>\n</tr>\n<tr style=\"text-align: left;\">\n<td width=\"33.333333333333336%\">\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">x = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r1 = y;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">y = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r2 = x;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">结果:r1==0 and r2 == 1</div>\n</td>\n<td width=\"33.333333333333336%\">\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">y = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r2 = x;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">x = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r1 = y;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">结果: r1 == 1 and r2 == 0</div>\n</td>\n<td width=\"33.333333333333336%\">\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">x = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">y = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r1 = y;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r2 = x;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">结果: r1 == 1 and r2 == 1</div>\n</td>\n</tr>\n</tbody>\n</table>\n<p>当然上面三种情况并没包括所有可能的执行顺序，但是它们已经包括所有可能出现的结果了，所以我们只举上面三个例子。我们注意到这个程序只可能出现上面三种结果，但是不可能出现r1==0 and r2==0的情况。</p>\n<p>SC其实就是规定了两件事情：<br />\n（1）每个线程内部的指令都是按照程序规定的顺序（program order）执行的（单个线程的视角）<br />\n（2）线程执行的交错顺序可以是任意的，但是所有线程所看见的整个程序的总体执行顺序都是一样的（整个程序的视角）</p>\n<p>第一点很容易理解，就是说线程1里面的两条语句一定在该线程中一定是x=1先执行，r1=y后执行。第二点就是说线程1和线程2所看见的整个程序的执行顺序都是一样的，举例子就是假设线程1看见整个程序的执行顺序是我们上面例子中的Execution 1，那么线程2看见的整个程序的执行顺序也是Execution 1，不能是Execution 2或者Execution 3。</p>\n<p>有一个更形象点的例子。伸出你的双手，掌心面向你，两个手分别代表两个线程，从食指到小拇指的四根手指头分别代表每个线程要依次执行的四条指令。SC的意思就是说：<br />\n（1）对每个手来说，它的四条指令的执行顺序必须是从食指执行到小拇指<br />\n（2）你两个手的八条指令（八根手指头）可以在满足（1）的条件下任意交错执行（例如可以是左1，左2，右1，右2，右3，左3，左4，右4，也可以是左1，左2，左3，左4，右1，右2，右3，右4，也可以是右1，右2，右3，左1，左2，右4，左3，左4等等等等）</p>\n<p>其实说简单点，SC就是我们最容易理解的那个多线程程序执行顺序的模型。</p>\n<h3>2. Cache Conherence （缓存一致性）</h3>\n<p>那么CC是干什么用的呢？这个要详细说的话就复杂了，写一本书绰绰有余。简单来说，我们知道现在的多核CPU的Cache是多层结构，一般每个CPU核心都会有一个私有的L1级和L2级Cache，然后多个CPU核心共享一个L3级缓存，这样的设计是出于提高内存访问性能的考虑。但是这样就有一个问题了，每个CPU核心之间的私有L1，L2级缓存之间需要同步啊。比如说，CPU核心1上的线程A对一个共享变量global_counter进行了加1操作，这个被写入的新值存到CPU核心1的L1缓存里了；此时另一个CPU核心2上的线程B要读global_counter了，但是CPU核心2的L1缓存里的global_counter的值还是旧值，最新被写入的值现在还在CPU核心1上呢！怎么把？这个任务就交给CC来完成了！</p>\n<p>CC是Cache之间的一种同步协议，它其实保证的就是对某一个地址的读操作返回的值一定是那个地址的最新值，而这个最新值可能是该线程所处的CPU核心刚刚写进去的那个最新值，也可能是另一个CPU核心上的线程刚刚写进去的最新值。举例来说，上例的Execution 3中，r1 = y是对y进行读操作，该读操作一定会返回在它之前已经执行的那条指令y=1对y写入的最新值。可能程序员会说这个不是显而意见的么？r1肯定是1啊，因为y=1已经执行了。其实这个看似简单的”显而易见“在多核processor的硬件实现上是有很多文章的，因为y=1是在另一个CPU上发生的事情，你怎么确保你这个读操作能立刻读到别的CPU核心刚刚写入的值？不过对程序员来讲你不需要关心CC，因为CPU已经帮你搞定这些事情了，不用担心多核CPU上不同Cache之间的同步的问题了（感兴趣的朋友可以看看体系结构的相关书籍，现在的多核CPU一般是以MESI protocol为原型来实现CC）。<strong>总结一下，CC和SC其实是相辅相承的，前者保证对单个地址的读写正确性，后者保证整个程序对多个地址读写的正确性，两者共同保证多线程程序执行的正确性。</strong></p>\n<h3>3. 为什么要关心SC？</h3>\n<p>好，回到SC的话题。为什么说程序员需要关心SC？因为现在的CPU和编译器会对代码做各种各样的优化，有时候它们可能会为了优化性能而把程序员在写程序时规定的代码执行顺序(program order)打乱，导致程序执行结果是错误的。</p>\n<p>例如编译器可能会做如下优化，即把线程1的两条语序调换执行顺序：<br />\n初始条件： x=y=0;</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><em><span style=\"font-size: x-small;\">线程 1</span></em></td>\n<td style=\"text-align: center;\" width=\"50%\"><em><span style=\"font-size: x-small;\">线程 2</span></em></td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">r1 = y;</span></td>\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">y=1;</span></td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">x = 1;</span></td>\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">r2 = x;</span></td>\n</tr>\n</tbody>\n</table>\n<p>那么这个时候程序如果按如下顺序执行就可能就会出现r1==r2==0这样程序员认为”不正确“的结果：</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"100%\">Execution 4</td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"100%\">r1 = y;<br />\ny = 1;<br />\nr2 = x;<br />\nx = 1;</td>\n</tr>\n</tbody>\n</table>\n<p>为什么编译器会做这样的优化呢？因为读一个在内存中而不是在cache中的共享变量需要很多周期，所以编译器就”自作聪明“的让读操作先执行，从而隐藏掉一些指令执行的latency，提高程序的性能。实际上这种类似的技术是在单核时代非常普遍的优化方法，但是在进入多核时代后编译器没跟上发展，导致了对多线程程序进行了违反SC的错误优化。为什么编译器很难保证SC？因为对编译器来讲它很难知道多个线程在执行时会按照什么样的交错顺序执行，因为这需要一个整个程序运行时的视角，而只对一份静态的代码做优化的编译器是很难得到这种运行时的上下文的。那么为什么硬件也保证不了呢？因为CPU硬件中的写缓冲区（store buffer）会把要写入memory的值缓存起来，然后当前线程继续往下执行，而这个被缓存的值可能要很晚才会被其他线程“看见”，从而导致多线程程序逻辑出错。其实硬件也提供了一些例如Memory Barrier等解决方案，但是开销是一个比较大的问题，而且很多需要程序员手动添加memory barrier，现在还不能指望CPU或者编译器<strong>自动</strong>帮你搞定这个问题。（感兴趣的朋友可以在本文的参考文献中发现很多硬件优化造成SC被违反的例子以及Memory Barrier等解决方案）</p>\n<p>好了，我们发现为了保证多线程的正确性，我们希望程序能按照SC模型执行；但是SC的对性能的损失太大了，CPU硬件和编译器为了提高性能就必须要做优化啊！为了既保证正确性又保证性能，在经过十几年的研究后一个新的新的模型出炉了：sequential consistency for data race free programs。简单地说这个模型的原理就是对没有data race的程序可以保证它是遵循SC的，这个模型在多线程程序的正确性和性能间找到了一个平衡点。对广大程序员来说，我们依赖高级语言内建的内存模型来帮我们保证多线程程序的正确性。例如，从JDK1.5开始引入的Java内存模型中已经支持data race free的SC了（例如使用volatile关键字，atomic变量等），但是C++程序员就需要等待C++0x中新的内存模型的atomic类型等来帮助保证SC了(因为atomic类型的值具有acquire和release语义，它隐式地调用了memory barrier指令)。什么意思呢？说简单点，就是由程序员用同步原语（例如锁或者atomic的同步变量）来保证你程序是没有data race的，这样CPU和编译器就会保证你程序是按你所想的那样执行的（即SC），是正确的。换句话说，程序员只需要恰当地使用具有acquire和release语义的同步原语标记那些真正需要同步的变量和操作，就等于告诉CPU和编译器你们不要对这些标记出来的操作和变量做违反SC的优化，而其它未被标记的地方你们可以随便优化，这样既保证了正确性又保证了CPU和编译器可以做尽可能多的性能优化。<del datetime=\"2010-10-26T10:19:54+00:00\">来告诉编译器和CPU这里这里你不能做违反SC的优化，那里那里你不能做违反SC的优化，然后你写的程序就会得到正确的执行结果了。</del></p>\n<p>从根源上来讲，在串行时代，编译器和CPU对代码所进行的乱序执行的优化对程序员都是封装好了的，无痛的，所以程序员不需要关心这些代码在执行时被乱序成什么样子，因为这些都被编译器和CPU封装起来了，你不用担心内部细节，它最终表现出来的行为就是按你想要的那种方式执行的。但是进入多核时代，程序员、编译器、CPU三者之间未能达成一致（例如诸如C/C++之类的编程语言没有引入多线程），所以CPU、编译器就会时不时地给你捣蛋，故作聪明的做一些优化，让你的程序不会按照你想要的方式执行，是错误的。Java作为引入多线程的先驱从1.5开始支持内存模型，等于是帮助程序员达成了与编译器、CPU（以及JVM）之间的契约，程序员只要正确的使用同步原语就可以保证程序最终表现出来的行为跟你所想的一样（即我们最容易理解的SC模型），是正确的。</p>\n<p>本文并未详细介绍所有针对SC问题的解决方案（例如X86对SC的支持，Java对它的支持，C++对它的支持等等），如果想了解更多，可以参考本文所指出的参考文献。下一次我会写一篇关于data race free model, weak ordering, x86 memory model等相关概念的文章，敬请期待。</p>\n<h3>题外话：</h3>\n<p>并行编程是非常困难的，在多核时代的程序员不能指望硬件和编译器来帮你搞定所有的事情，努力学习多核多线程编程的一些基础知识是很有必要的，至少你应该知道你的程序到底会以什么样的方式被执行。</p>\n<p>参考文献：<br />\n<a href=\"http://www.hpl.hp.com/personal/Hans_Boehm/c++mm/threadsintro.html\">[1] Hans Boehm: C++ Memory Model</a><br />\n<a href=\"http://www.cs.umd.edu/~pugh/java/memoryModel/\">[2] Bill Pugh: The Java Memory Model</a><br />\n<a href=\"http://en.wikipedia.org/wiki/Cache_coherence\">[3] Wiki: Cache Coherence</a><br />\n<a href=\"http://en.wikipedia.org/wiki/Sequential_consistency\">[4] Wiki: Sequential Consistency</a><br />\n<a href=\"http://ivanwangcn.spaces.live.com/blog/cns!F291BBD27380D1CA!153.entry\">[5] The Memory Model of X86 (中文，从硬件角度讲SC问题)</a><br />\n<a href=\"http://blog.csdn.net/pongba/archive/2007/06/20/1659952.aspx\">[6] 《C++0x漫谈》系列之：多线程内存模型</a></p>\n","descriptionType":"html","publishedDate":"Sat, 06 Mar 2010 13:01:48 +0000","feedId":9852,"bgimg":"","linkMd5":"ce6a931f98e939073c5c07de5916832e","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"瑞典Ericsson总部Master Thesis面试回忆录","link":"http://www.parallellabs.com/?p=323","description":"<p>前言：去年4月份我申请过一些6月份开始的毕业设计和暑假实习，最终拿到了Ericsson的master thesis offer和另一个哥德堡小公司的summer intern，Volvo在我拿到summer intern后也给了interview。现在应该已经有不少一年级的同学要开始找暑假实习了，我觉得你们可以考虑申请6月份开始的毕设(等毕设结束后再回学校把剩下的课程修完)。下面是我去位于Kista的Ericsson总部面试的经历，希望对大家有用。Summer Intern总体上来讲难度比thesis大很多，因为很多瑞典人也要竞争这种职位，而且那些提供summer intern的小公司也不太喜欢招foreigner。</p>\n<p>2009 May 5th:</p>\n<p>晚上刚从超市回来就发现Gtalk弹出新邮件的消息，第一眼就看见标题中Interview的字眼，立刻欣喜若狂，急急忙忙打开仔细一看，竟然是我最早申请的职位的Interview！我是April 24th投的这个职位(Master Thesis)，另外还投了若干Summer Job（其中就包括我当天刚刚投完的Nema Labs的Summer job，后面会详叙），Volvo的Master Thesis以及其他几个Ericsson的Thesis Position。</p>\n<p>因为这个是我投出去的第一份申请，当时完全没有任何经验，而且Cover Letter和CV都不是最好，现在回想之所以能够拿到这个Interview，主要因为以下几点原因：</p>\n<p>1. 专业对口，GPA够。职位是做Sensor Network的，我的专业是Networks and Distributed Systems，正好对口，而且我在刚刚结束的课程Project中正好做过Sensor Network的一个项目，可谓牛头对上了马嘴，不亦乐乎。另外GPA也是Ericsson非常看重的，很多职位写明必须4.0（满分5.0）以上，个人觉得4.3以上比较保险。</p>\n<p>2. 简历虽然有些小纰漏，但是因为当时也有针对职位的要求进行修改，所以还是能给人第一眼的好印象的。</p>\n<p>3. Cover Letter写得也还凑合。除了常规介绍外还重点说了说自己对那个Thesis的看法，扯了扯自己的本科毕设。</p>\n<p>发信人是后来面试我的Dr. V.，我一查竟然是UCxx的出身，心想又是UCxx啊！不禁由衷的仰慕，立刻对之后的Interview十分的向往。事后证明Dr. V.人真的非常的nice，虽然有些许龅牙，但是至少英语听起来比较舒服啊！</p>\n<p>之后的信件往来就是确定面试时间之类，定下下下周五之后立刻跟身在Kista的yoan师兄联系商量借住事宜（在此对师兄的热情相助表示深深感谢！是你让我在Kista感受到家的温暖啊！还顺带连累你熬了个通宵 囧），然后就是买往返的火车票之类。一切定好后剩下的两个礼拜就开始拼命准备，囫囵吞枣扫了些论文，再跟着看了些英文面试的资料，甚至还去了Career Office做了一次咨询。</p>\n<p>这其中发生了一件比较逗的事情。因为哥德堡到斯德的来回火车票加起来600多SEK，我心想这一趟下去怎么的也得1000块了，要不问问看他们能不能给报销？再加上外国公司以往报销路费的事听了不少，我就借着发信问问题的机会顺带来了句：“I am wondering whether you will undertake my travel fee for this interview?” 猜猜人家怎么回的？</p>\n<p>“it&#8217;s not possible to 报销路费， so我们只能电话Interview了”，我心想，大哥我这菜鸟要电话面试不就相当于直接管你要据信么，再说我票都定了大不了当去旅游好了，于是连忙给他发信解释说没关系云云。</p>\n<p>2009 May 14th</p>\n<p>早上6点的火车去Stockholm，4点半起的，等5点的第一班tram去Central Station。顺利等到4路电车，心想时间肯定来得及，耽误不了。但是不幸恰恰在心情放松麻痹大意的情况下发生了。我在离火车站还有两站路的时候突发奇想拿出口语书开始模拟英语面试，自己边模拟面试官边想着怎么回答，简直就是左右互搏，天人合一，不亦乐乎，十分忘我。练了5，6分钟后我发现不对了：怎么窗外还能看见火车啊？我仔细一看，我靠！还真是Central Station的火车，其中就有我要坐的x2000！我心中大叫不好，刚刚停的那站就是火车站，我给错过了！！我赶紧收拾东西站在门口准备在下站下车赶紧再坐回去，结果老天真给我开了个大玩笑：过了上一站之后Tram就进入郊区了，开了至少5分钟才到下一站！那5分钟简直就是我人生最漫长的一段时间之一，脑子100%运转，不停看表计算时间，同时储备体力随时准备狂奔。</p>\n<p>5分钟后终于到达下一站了，赶紧下车，到对面站台看反方向的车几点到：5分钟以后！这意味着我到火车站后离发车只剩10分钟不到！！！而且我还从来没去过火车站都不知道火车在哪！天无绝人之路，我发现旁边竟然还有一个车站！赶紧对了下时间，Tram7马上就到，又多出了5分钟！老天保佑，我心急如焚的等着不紧不慢的7路小电车，来了！上车！走！到！门开的一霎那，我真是卯足了劲往站台冲啊！事后回想我大概只用了1分钟不到就找到了X2000的站台。这还多亏瑞典的火车站不像国内的那么大，还要进候车厅再排队检票上下楼梯什么的，站台离车站正门也就2-3分钟的路，而且上车后再检票。我悬着的心终于放下来了，事后回想就算当天没赶上我也可以再买下一班的，大不了先上车后补票，还好是我之前订的就是周四走周五面试。虽然我这不叫大难不死，但也算是必有后福啊！</p>\n<p>顺利到达Stockholm。斯京的火车站和地铁站是连在一起的，下火车后直接就去地铁售票处买了张24h的通票（100SEK），直奔Kista。话说这个Kista号称瑞典最大的科技园区，里面不仅有Ericsson全球总部，华为瑞典分舵等众多IT公司，KTH也有一个分校区在那边。出了Kista地铁站直接就是一个大型Shopping Mall，在把正补觉的师兄吵醒之后顺利放下行李。中午吃了师兄做的红烧肉拌面，话说那个红烧肉确实很够味，真是赞！</p>\n<p>下午就出去Kista园区去寻我明天面试的地点去了。来了Kista我最大的感受就是，整个Kista到处都是Ericsson的人。不管是在Shopping Mall里的Restaurant还是在工业园区的大街上，到处都是挂着蓝色Ericsson牌子的人，简直就是Ericsson大山寨。后来听到一个说法，Ericsson这样的国民企业其实更应该被看做一个Community，在Kista的shopping mall里面甚至有专门的Ericsson员工价，由此可见一般。顺便说一句，上次回国刚下飞机在机场大巴上，坐我旁边的竟然是个瑞典小哥，仔细一聊竟然也是学CS的，从Stockholm来中国找他中国女朋友，于是我就问“你是不是给Ericsson工作”，结果竟然猜对了。由此可见爱立信有多庞大。</p>\n<p>事实也确实如此。一开始我找到的最显眼的是一栋白色的大型Ericsson办公楼，整个楼占了一个广场的大小，气势直逼瑞典皇宫了（当然更现代点），真不愧是世界级大公司的全球总部啊。于是我就去reception问我的面试官是不是在这栋楼办公，结果人家告诉我：“不好意思，你找的人在对面那栋楼办公，出门后直走就到了”。等我出去仔细一看，原来Ericsson Research是另一栋大红楼。我猜可能那栋大白楼里面应该都是Ericsson负责工业产品的部门吧。踩点完毕后就回家继续做准备去了。Tips：对面试要提前踩点，特别是去不熟悉的地方更要多做准备，因为瑞典人很忌讳迟到（瑞典交通发达，地铁非常准时，也没什么堵车，所以没有迟到的理由）。</p>\n<p>虽然最后我拿到了这个Offer，但是说实话在面试之前我还是非常紧张的。这可是我第一次英文面试，两个面试官都是顶尖大学的PHD，还顶着Ericsson总部的光环。我做的主要准备如下：</p>\n<p>1）根据Position Description看了几篇该领域的综述型Paper，以到达快速入门的目的；</p>\n<p>2）仔细研究该Position的Requirement，结合自己的CV自己进行了若干次模拟面试</p>\n<p>3）准备了自己本科毕设的资料（一页A4插图，直观明了）和，因为这个跟该Thesis有点相关</p>\n<p>4）给面试专门准备了一份CV，突出了自己项目经验跟该position的相关性</p>\n<p>面试的流程大致如下：</p>\n<p>跟两份面试官打过招呼后直接把CV和Transcript递上（省了人家自己打印的功夫，而且给你第一印象就是你准备的很充分。“我把简历都给你带过来了，上面的都是你们需要的”）。Dr.V.人非常好的先给我介绍了一下该Thesis的大致背景，很好的帮助我消除了紧张情绪并帮助我快速进入状态。在了解到项目的大致框架后我适时的接过话题（适时把握话题的主动性，不是被人牵着鼻子走。“我对这个很熟，请听听我的想法”），抛出了我对这个项目的具体实现的想法（虽然有些当时我的想法有些许错误，但是很好的表现出自己对这个项目的兴趣，就像是说：“你看，我自己脑子里已经有一个实现了，我很有可能能把这个项目完成的很好”）。</p>\n<p>再聊了一些项目的话题后面试官就开始问我的简历上的项目经验了。我就一个一个跟他们解释（“我做过的东西跟这个Thesis都很相关，我很有竞争力”），其中有几个他们比较熟悉的项目他们就会问你一些技术问题或者算法问题。不过只要自己对项目的背景知识和本身的实现比较熟悉基本没什么问题，而且就算真的不会直接说不会也没关系。我其中就有2个问题直接说了不会，很可能他们因为看重我其他的背景和我的学习能力所以没影响我拿offer。</p>\n<p>我感觉我整个面试过程中最出彩的地方在介绍我的本科毕设部分。回想当年在白混了3年之后，心想最后一个毕设怎么的也得拿个A做出点像样的东西来，要不大学白过了，于是狠命搞了半年终于如愿以偿。正好毕设跟这个Thesis很相关，当我拿出我做的prototype的照片并向他们介绍它的功能的时候，我分明的感觉到两位Ericsson Researcher都被我打动了（“给我Offer吧！本科毕设我都拿A了，你们这个Thesis我肯定不会让你们失望的！”）。</p>\n<p>最后Dr. V.非常Nice的送我下楼，我在电梯里又跟他聊起不能报销差旅费的事情，最后我对他说了我生平最有打动人的效果的一句英语：“I just want to let you know my serious and positive attitude for this position.”结果Dr.V.非常配合的笑着对我说：“Yes！You have！”</p>\n<p>The End：May 19th下午正准备跟妞妞mixi，突然接到一个010开头的电话，我还奇怪难道是北京打来的？后来才知道在瑞典Stockholm的区号也是010。也许大家都猜到了，其实就是另一位面试官打来的Offer电话。</p>\n<p>P.S. 虽然因为种种原因没去Ericsson，但是我仍然深深的被Ericsson HQ的魅力所吸引，它向我展现了一个世界电信巨头的风采。而Stockholm，它的美丽更是让我留恋。希望下一次妞妞能跟我再一次同游斯德。</p>\n<p>P.S.S. 猜猜Kista最大的中国人群体里在哪？不错，就是华为！华为真是牛逼，我问过好几个瑞典人了，华为真的是一个爱立信强有力对手的存在，直接把分舵开到Ericsson老家，有点新东方把分舵开始ETS总部的意思。在此祝华为越来越牛逼！早日出台Kista华为员工价！</p>\n","descriptionType":"html","publishedDate":"Thu, 04 Feb 2010 19:53:50 +0000","feedId":9852,"bgimg":"","linkMd5":"b31d32c4a3f36e4e1aaff8d376bf7f63","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Thank you from G.C. Guancheng Chen","link":"http://www.parallellabs.com/?p=1489","description":"<p>Dear friends, colleagues and mentors,</p>\n<p>Tomorrow (Jun 30th, 2015) will be my last working day at IBM Research &#8211; China. When I decided to join CRL in April 2011, I considered this adventure as a world-leading industry PhD program in the most interesting market &#8211; China. Instead of continuing my academic career as a regular PhD with my advisor Prof. Per Stenstrom, I was more interested in making real impact in real business world. Four years later, I would say I was so lucky to have enjoyed a fantastic journey with you who not only helped me, inspired me, encouraged me, mentored me, but also become life long friend with me.</p>\n<p>Last week I visited IBM Reserach &#8211; Almaden, and I saw a saying on the lobby wall: &#8220;Science and data to extend human capability&#8221;. IBM Research was no doubt a remarkable organization for disruptive innovation in the human history. I am so proud that I could get the chance to work with you on being essential to our society. After my graduation from IBM Research, I will start a new adventure of building cool big data technology in OneAPM, a startup that has many common interest with me. Hope what I learned from CRL could help me become a person that can shape the world to come in some degree.</p>\n<p>Please allow me to take the opportunity to thank you all for all your kind support during the years. Life is a long long journey, we will definitely have chance to meet each other again:)</p>\n<p>Please find my contact below and wish you all the best in the future!</p>\n<p>My wechat is <strong>threadingnow</strong>, my weibo is <a href=\"http://weibo.com/parallellabs\" target=\"_blank\">weibo.com/parallellabs</a><br />\nLinkedin: <a href=\"http://linkedin.com/in/guanchengchen\" target=\"_blank\">http://linkedin.com/in/guanchengchen</a><br />\nPersonal Blog: <a href=\"http://www.parallellabs.com/\" target=\"_blank\">http://www.parallellabs.com/</a><br />\nEmail: chenguancheng # at # gmail.com</p>\n","descriptionType":"html","publishedDate":"Mon, 29 Jun 2015 07:50:14 +0000","feedId":9852,"bgimg":"","linkMd5":"d5372ddfbc77e98ede2fef960408c406","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"怎样做颠覆式创新?","link":"http://www.parallellabs.com/?p=1484","description":"<p>关于怎样做颠覆式创新，普林斯顿的李凯教授给出了四个要素：</p>\n<p>（1）找到最好的合伙人</p>\n<p>（2）理解市场需求（例如你是卖维生素还是抗生素？）</p>\n<p>（3）紧跟技术发展趋势（例如多核时代来临时，你的软件一定要充分利用多核并行）</p>\n<p>（4）产生一个新的产品类别（比老产品好10倍甚至20倍，才能颠覆已有方案）。</p>\n<p>何为颠覆式创新？你的产品需要能取代高中低端的所有已有产品，这就是颠覆式创新。例如用3个2U服务器的重复数据删除解决方案取代27个机柜的传统方案。这意味着你的产品比已有产品好10倍到20倍。</p>\n<p>关于颠覆式创新，彼得·蒂尔也说过：“我判断一个项目一般有三个标准：人、技术、商业模式，必须三样同时具备。</p>\n<p>首先对人来说，我觉得我们不够重视团队的结合。可能一个团队的成员背景、履历都很厉害，但这些人在一起工作时是怎样的却是另一个问题，他们也许都很有才华，认为自己比别人聪明，而风险在于有一个“很大的自我”的人也许很难在一起工作，有时你能看到几个很优秀的人组成了一个很糟糕的团队。所以我会问这些人怎么相遇的，在一起多久了，之前的关系等等。</p>\n<p>技术方面，如果只是比别人好10%或20%是不行的，要好上10倍、20倍。</p>\n<p>还有一个标准是商业战略。对硅谷的投资者来说有太多的牛人、太好的技术，但在商业战略上是比较缺乏的。在我的理念中，要成功，首先你要能够实现垄断，你要有一个专属于你自己的类别，不是说你很快就有一个非常大的市场，而是可以从一个较小的市场做起，在早期就有一个较高的使用频度，人们很喜欢你的产品、推荐给朋友。”</p>\n<p>&#160;</p>\n","descriptionType":"html","publishedDate":"Wed, 03 Jun 2015 11:45:56 +0000","feedId":9852,"bgimg":"","linkMd5":"ee3a008e010e08e8de5a0eb92365f724","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821747},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"移动设备进入多核时代！","link":"http://www.parallellabs.com/?p=1000","description":"<p>Nvidia最近发布了代号为Tegra 2的新一代双核移动处理器，移动设备即将进入多核时代。该款处理器由两个基于ARM Cortex A9的核心及其它视频音频图形专用核心（可看成Accelerator）组成，是一个典型的异构（Heterogeneous）平台。这个平台的关键特征有两个：低功耗（比高频单核的处理器耗电小），高性能（异构平台的性能优势）。</p>\n<p>我之前也讲过为什么我们要迁移到<a href=\"http://www.parallellabs.com/2010/08/17/the-trouble-with-multicore/\" target=\"_blank\">多核平台</a>，简单来说，继续提升核心频率及电压的办法会让处理器的功耗呈指数级增加，此时的功耗会难以让人接受；而在晶体管数目持续增加的前提下，工业界自然就（被迫）选择了<a href=\"http://www.parallellabs.com/2010/10/03/future-multiprocessors/\"  target=\"_blank\">更加容易实现的多核方案</a>来继续提升硬件的性能。这个趋势也即将体现在移动处理器上。</p>\n<p>Nvidia的白皮书<a href=\"http://www.nvidia.com/content/PDF/tegra_white_papers/Benefits-of-Multi-core-CPUs-in-Mobile-Devices_Ver1.2.pdf\"  target=\"_blank\">《The Benefits of Multiple CPU Cores in Mobile Devices》</a>中提到了几个多核对移动应用带来的好处：</p>\n<h4>1. 更快的网页加载速度</h4>\n<p>现在的网页内容越来越丰富，也越来越复杂。HTML5，Flash，Javascript，视频等内容的呈现都需要强大的处理能力。Nvidia提供的测试数据表明Tegra 2的Javascript性能提升了1.5~2倍，网页平均加载速度提升了46%。事实上Firefox，Chrome等桌面浏览器都已经采用了多线程，而Android浏览器，Safari等采用的Webkit内核也已经实现了多线程。在浏览器已经并行化的前提下，多核移动处理器自然能提供更快更丰富的网页渲染体验。</p>\n<h4>2. 更低的功耗及更高的性能瓦特比</h4>\n<p>对多核来讲，任务调度及电源管理算法是提升性能瓦特比的关键。Tegra 2能通过如下几点降低功耗：<br />\n1）把任务平均分配到两个核心上，这样每个核心都不必跑在最高频率/电压上，而只需要以较低的频率/电压就能完成任务，从而节省功耗<br />\n2）如果要执行的任务是高度并行化的，Tegra 2就能更快的完成这个任务，从而更快的进入超低功耗待机模式，节省更多电量<br />\n3）如果任务只需要一个核心的话，其他计算单元可以被关闭从而节省电量</p>\n<p>续航能力一直是手机、Tablet等移动设备的关键问题之一，在电池技术没有突破性进展的今天，我们只能寄希望于硬件/软件上的优化手段来降低功耗了。</p>\n<h4>3. 提升游戏体验</h4>\n<p>Tegra 2的图形处理单元叫做Ultra Low Power (ULP) GeForce GPU，性能应该很不错。现在的一些主流游戏引擎早已经完成了并行化（多线程分别用来完成渲染，音频，网络，解码，碰撞检测，透明等任务）。白皮书中提供的测试数据表明虚幻3引擎在Tegra 2双核心上快了将近70%。一个值得注意的地方时很多游戏引擎是通过task parallelism的方式以适应不同的处理器核心数目，这说明基于这些引擎的游戏可以在几乎不修改程序的情况下在以后的4核乃至8核移动平台上取得更好的游戏体验。游戏在最受欢迎的移动应用中还是占了大头的，所以多核对移动游戏应用的影响会非常大。</p>\n<p>下面是一些主流游戏引擎使用的线程数：<br />\nGame/Engine（Number of Threads）<br />\nUnreal Engine 3（4+）<br />\nId Tech 5（6+）<br />\nFrostbite（14）<br />\nCivilization 5（12）<br />\nMafia 2（4）<br />\nCrysis（8）<br />\nUncharted 2（8）<br />\nKillzone 2（8+）</p>\n<h4>4. 更平滑的用户体验及更快的多任务处理能力</h4>\n<p>多任务处理在手机/Tablet上都非常常见。当你一边听着歌，一边下载电影，一边上网冲浪时，多核处理器就能帮你把这些任务分配到不同的核心上进行处理，从而给你提供更好的更平滑的用户体验。我记得iPad上的一些电子杂志的界面响应速度是个很大的问题，因为渲染速度太慢了，性能更高的多核平台就能提供更快的处理速度，提升用户体验，当然，这个前提是该程序能充分利用好多核。</p>\n<p>想到这我还要插一句题外话。iOS一开始不支持对第三方程序的多任务处理功能其实主要是因为iPhone/iPad上内存有限（256MB）且没有硬盘（即没有swap），具体可参考Robert Love（该大牛现在在做Android）这篇<a href=\"http://blog.rlove.org/2010/04/why-ipad-and-iphone-dont-support.html\"  target=\"_blank\">《Why the iPad and iPhone don&#8217;t Support Multitasking》</a>；至于Android怎么解决多任务处理的可以参考<a href=\"http://android-developers.blogspot.com/2010/04/multitasking-android-way.html\"  target=\"_blank\">这篇《Multitasking Android Way》</a>（想看这两篇都要会功夫，你懂的）</p>\n<p>移动设备的多核时代已经到来，移动开发者们，你们准备好了么？</p>\n","descriptionType":"html","publishedDate":"Tue, 28 Dec 2010 04:04:10 +0000","feedId":9852,"bgimg":"","linkMd5":"7e981e1b6339f3c4ffa271775e990fff","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"Launched my master thesis finally","link":"http://www.parallellabs.com/?p=42","description":"<p>Today I talked with my supervisor again and finally and officially launched my Master Thesis!</p>\n<p>The next coming 12 months I will focus on developing a methodology on analyzing the performance bottleneck of large-scale multi-threaded software. I am really excited in the challenging problem about how to find the performance bottleneck when we are moving to many-core systems with hundreds of threads running concurrently. There will be a lot of fun and I believe I can learn a lot from it.</p>\n<p>Another fun thing is, in the project plan written by my supervisor, the total budget is written as &#8220;81 000 KSEK&#8221; incorrectly, I hope Ericsson will not notice that mistake and if so, they have to pay a lot of  money to us since they have approved this project:)</p>\n","descriptionType":"html","publishedDate":"Wed, 04 Nov 2009 18:33:38 +0000","feedId":9852,"bgimg":"","linkMd5":"65d6a7d814abccb7fe38dfa14c7cb405","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"基于OpenStack, Docker和Spark打造SuperVessel大数据公有云","link":"http://www.parallellabs.com/?p=1480","description":"<p>今年4月的Spark技术峰会上我做了《SuperVessel：基于OpenStack, Docker和Spark打造大数据公有云》的技术分享:</p>\n<p><a href=\"http://www.parallellabs.com/wp-content/uploads/2015/05/Spark-China-Summit-2015-Guancheng-Chen.pdf\" target=\"_blank\">基于OpenStack和Docker打造Spark大数据服务</a></p>\n<p><a href=\"http://vdisk.weibo.com/s/vpnf2gt0rJKJ/1431438153\" target=\"_blank\">新浪微盘下载链接</a></p>\n<p><strong>1.首先请介绍下您自己,以及您在 Spark 技术方面所做的工作。</strong></p>\n<p>我是IBM中国研究院的高级研究员，大数据云方向的技术负责人，我的微博是@冠诚。我们围绕Spark主要做两方面的事情：</p>\n<p>（1） 在IBM研究院的SuperVessel公有云（<a href=\"http://www.ptopenlab.com\" target=\"_blank\">http://www.ptopenlab.com</a>）上开发和运维Spark as a Service大数据服务。<br />\n（2） 在OpenPOWER架构的服务器上做Spark的性能分析与优化。</p>\n<p><strong>2.您所在的企业是如何使用 Spark 技术的?带来了哪些好处?</strong></p>\n<p>Spark作为新一代的大数据处理引擎主要带来了两方面的好处：<br />\n（1）相比于MapReduce在性能上得到了很大提升；<br />\n（2）在一个统一的平台上将批处理，SQL，流计算，图计算，机器学习算法等多种范式集中在一起，使得混合计算变得更加的容易。</p>\n<p><strong>3.您认为 Spark 技术最适用于哪些应用场景?</strong></p>\n<p>大规模机器学习，图计算，SQL等类型数据分析业务是非常适合使用Spark的。当然，在企业的技术选型过程中，并不是说因为Spark很火就一定要使用它。例如还有很多公司在用Impala做数据分析，一些公司在用Storm和Samaza做流计算，具体的技术选型应该根据自己的业务场景，人员技能等多方面因素来做综合考量。</p>\n<p><strong>4.企业在应用 Spark 技术时,需要做哪些改变吗?企业如果想快速应用 Spark 应该如何去做?</strong></p>\n<p>企业想要拥抱Spark技术，首先需要技术人员改变。是否有给力的Spark人才会是企业能否成功应用Spark最重要的因素。多参与Spark社区的讨论，参加Spark Meetup，给upstream贡献代码都是很好的切入方式。如果个人开发者想快速上手Spark，可以考虑使用SuperVessel免费的Spark公有云服务，它能快速创建一个Spark集群供大家使用。</p>\n<p><strong>5.您所在的企业在应用 Spark 技术时遇到了哪些问题?是如何解决的?</strong></p>\n<p>我们在对Spark进行性能调优时遇到很多问题。例如JVM GC的性能瓶颈，序列化反序列化的开销，多进程好还是多线程好等等。在遇到这些问题的时候，最好的方法是做好Profiling，准确的将性能瓶颈找到，再去调整相关的参数去优化这些性能瓶颈。<br />\n另一方面，我们发现如果将Spark部署在云环境里（例如OpenStack管理的Docker Container）时，它的性能特征和在物理机上部署又会有很大的不同，目前我们还在继续这方面的工作，希望以后能有机会跟大家继续分享。</p>\n<p><strong>6.作为当前流行的大数据处理技术,您认为 Spark 还有哪些方面需要改进?</strong></p>\n<p>在与OpenStack这样的云操作系统的集成上Spark还是有很多工作可以做的。例如与Docker Container更好的集成，对Swift对象存储的性能优化等等。</p>\n<p><strong>7.您在本次演讲中将分享哪些话题?</strong></p>\n<p>我将分享的话题是“基于OpenStack, Docker和Spark打造SuperVessel大数据公有云”：</p>\n<p>随着Spark在2014年的蓬勃发展，Spark as a Service大数据服务正成为OpenStack生态系统中的新热点。另一方面，Docker Container因为在提升云的资源利用率和生产效率方面的优势而备受瞩目。在IBM中国研究院为高校和技术爱好者打造的SuperVessel公有云（www.ptopenlab.com）中，我们使用OpenStack, Docker和Spark三项开源技术，在OpenPOWER服务器上打造了一个大数据公有云服务。本次演讲我们会向大家介绍如何一步一步使用Spark, Docker和OpenStack打造一个大数据公有云，并分享我们在开发过程中遇到的问题和经验教训。</p>\n<p><strong>8.哪些听众最应该了解这些话题?您所分享的主题可以帮助听众解决哪些问题?</strong></p>\n<p>对如何构造一个大数据云感兴趣的同学应该会对这个话题感兴趣。对于开发SuperVessel的Spark as a Service服务过程中我们做的技术选型，架构设计，以及解决的问题应该能对大家有所帮助。</p>\n<p><strong>9. 您有什么需要对读者补充的吗?</strong></p>\n<p>Spark与云的结合将会是未来一个非常热的方向，希望有更多关注这个方向的同学与我交流，谢谢大家。</p>\n","descriptionType":"html","publishedDate":"Tue, 12 May 2015 13:48:30 +0000","feedId":9852,"bgimg":"","linkMd5":"65622b58e1ac7ff65b42cb20f6156ce7","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"浅析C++多线程内存模型","link":"http://www.parallellabs.com/?p=1085","description":"<p><em>注：本文发表于《程序员》2011年第6期并行编程专栏，略有删改。</em></p>\n<p>在即将到来的C++1x标准中，一个重大的更新就是引入了C++多线程内存模型。本文的主要目的在于介绍C++多线程内存模型涉及到的一些原理和概念，以帮助大家理解C++多线程内存模型的作用和意义。</p>\n<h4>1. 顺序一致性模型（Sequential Consistency）</h4>\n<p>在介绍C++多线程模型之前，让我们先介绍一下最基本的顺序一致性模型。对多线程程序来说，最直观，最容易被理解的执行方式就是顺序一致性模型。顺序一致性的提出者Lamport给出的定义是：<br />\n“… the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.”<br />\n从这个定义中我们可以看出，顺序一致性主要约定了两件事情：<br />\n（1）从单个线程的角度来看，每个线程内部的指令都是按照程序规定的顺序（program order）来执行的；<br />\n（2）从整个多线程程序的角度来看，整个多线程程序的执行顺序是按照某种交错顺序来执行的，且是全局一致的；</p>\n<p>下面我们通过一个例子来理解顺序一致性。假设我们有两个线程（线程1和线程2），它们分别运行在两个CPU核上，有两个初始值为0的全局共享变量x和y，两个线程分别执行下面两条指令：<br />\n初始条件： x = y = 0;</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><em>线程 1</em></td>\n<td style=\"text-align: center;\" width=\"50%\"><em>线程 2</em></td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\">x = 1;</td>\n<td style=\"text-align: center;\" width=\"50%\">y=1;</td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\">r1 = y;</td>\n<td style=\"text-align: center;\" width=\"50%\">r2 = x;</td>\n</tr>\n</tbody>\n</table>\n<p>因为多线程程序交错执行的顺序是不确定的，所以该程序可能有如下几种执行顺序：</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody></tbody>\n</table>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"33.333333333333336%\">顺序 1</td>\n<td style=\"text-align: center;\" width=\"33.333333333333336%\">顺序 2</td>\n<td style=\"text-align: center;\" width=\"33.333333333333336%\">顺序 3</td>\n</tr>\n<tr style=\"text-align: left;\">\n<td width=\"33.333333333333336%\">\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">x = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r1 = y;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">y = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r2 = x;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">结果:r1==0 and r2 == 1</div>\n</td>\n<td width=\"33.333333333333336%\">\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">y = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r2 = x;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">x = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r1 = y;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">结果: r1 == 1 and r2 == 0</div>\n</td>\n<td width=\"33.333333333333336%\">\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">x = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">y = 1;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r1 = y;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">r2 = x;</div>\n<div style=\"margin-top: 0px; margin-bottom: 0px;\">结果: r1 == 1 and r2 == 1</div>\n</td>\n</tr>\n</tbody>\n</table>\n<p>顺序一致性模型的第一个约定要求每个线程内部的语句都是按照程序规定的顺序执行，例如，线程1里面的两条语句在该线程中一定是x=1先执行，r1=y后执行。顺序一致性的第二个约定要求多线程程序按照某种顺序执行，且所有线程看见的整体执行顺序必须一致，即该多线程程序可以按照顺序1、顺序2或者顺序3（以及其他可能的执行顺序）执行，且线程1和线程2所观察到的整个程序的执行顺序是一致的（例如，如果线程1“看见”整个程序的执行顺序是顺序 1，那么线程2“看见”的整个程序的执行顺序也必须是顺序1，而不能是顺序2或者顺序3）。依照顺序一致性模型，虽然这个程序还可能按其他的交错顺序执行，但是r1和r2的值却只可能出现上面三种结果，而不可能出现r1和r2同时为0的情况。</p>\n<p>然而，尽管顺序一致性模型非常易于理解，但是它却对CPU和编译器的性能优化做出了很大的限制，所以常见的多核CPU和编译器大都没有实现顺序一致性模型。例如，编译器可能会为了隐藏一部分读操作的延迟而做如下优化，把线程1中对y的读操作（即r1=y）调换到x=1之前执行：</p>\n<p>初始条件：x=y=0;</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><em><span style=\"font-size: x-small;\">线程 1</span></em></td>\n<td style=\"text-align: center;\" width=\"50%\"><em><span style=\"font-size: x-small;\">线程 2</span></em></td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">r1 = y;</span></td>\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">y=1;</span></td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">x = 1;</span></td>\n<td style=\"text-align: center;\" width=\"50%\"><span style=\"font-size: x-small;\">r2 = x;</span></td>\n</tr>\n</tbody>\n</table>\n<p>在这种情况下，该程序如果按下面的顺序执行就可能就会出现r1和r2都为0这样的违反顺序一致性的结果：</p>\n<table style=\"font-size: 1em; line-height: inherit; border-collapse: collapse;\" border=\"1\" cellspacing=\"0\" cellpadding=\"3\" width=\"100%\" bordercolor=\"#000000\">\n<tbody>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"100%\">顺序 4</td>\n</tr>\n<tr style=\"text-align: left;\">\n<td style=\"text-align: center;\" width=\"100%\">r1 = y;<br />\ny = 1;<br />\nr2 = x;<br />\nx = 1;</td>\n</tr>\n</tbody>\n</table>\n<p>那么为什么编译器会做这样的乱序优化呢？因为读一个在内存中而不是在cache中的共享变量需要较长的时钟周期，所以编译器就“自作聪明”的让读操作先执行，从而隐藏掉一些指令执行的延迟，从而提高程序的性能。实际上，这种优化是串行时代非常普遍的，因为它对单线程程序的语义是没有影响的。但是在进入多核时代后，编译器缺少语言级的内存模型的约束，导致其可能做出违法顺序一致性规定的多线程语义的错误优化。同样的，多核CPU中的写缓冲区（store buffer）也可能实施乱序优化：它会把要写入内存的值先在缓冲区中缓存起来，以便让该写操作之后的指令先执行，进而出现违反顺序一致性的执行顺序。</p>\n<p>因为现有的多核CPU和编译器都没有遵守顺序一致模型，而且C/C++的现有标准中都没有把多线程考虑在内，所以给编写多线程程序带来了一些问题。例如，为了正确地用C++实现Double-Checked Locking，我们需要使用非常底层的内存栅栏（Memory Barrier）指令来显式地规定代码的内存顺序性（memory ordering）[5]。然而，这种方案依赖于具体的硬件，因此可移植性很差；而且它过于底层，不方便使用。</p>\n<h4>2. C++多线程内存模型</h4>\n<p>为了更容易的进行多线程编程，程序员希望程序能按照顺序一致性模型执行；但是顺序一致性对性能的损失太大了，CPU和编译器为了提高性能就必须要做优化。为了在易编程性和性能间取得一个平衡，一个新的模型出炉了：sequential consistency for data race free programs，它就是即将到来的C++1x标准中多线程内存模型的基础。对C++程序员来说，随着C++1x标准的到来，我们终于可以依赖高级语言内建的多线程内存模型来编写正确的、高性能的多线程程序。</p>\n<p>C++内存模型可以被看作是C++程序和计算机系统（包括编译器，多核CPU等可能对程序进行乱序优化的软硬件）之间的契约，它规定了多个线程访问同一个内存地址时的语义，以及某个线程对内存地址的更新何时能被其它线程看见。这个模型约定：没有数据竞跑的程序是遵循顺序一致性的。该模型的核心思想就是由程序员用同步原语（例如锁或者C++1x中新引入的atomic类型的共享变量）来保证你程序是没有数据竞跑的，这样CPU和编译器就会保证程序是按程序员所想的那样执行的（即顺序一致性）。换句话说，程序员只需要恰当地使用具有同步语义的指令来标记那些真正需要同步的变量和操作，就相当于告诉CPU和编译器不要对这些标记好的同步操作和变量做违反顺序一致性的优化，而其它未被标记的地方可以做原有的优化。编译器和CPU的大部分优化手段都可以继续实施，只是在同步原语处需要对优化做出相应的限制；而且程序员只需要保证正确地使用同步原语即可，因为它们最终表现出来的执行效果与顺序一致性模型一致。由此，C++多线程内存模型帮助我们在易编程性和性能之间取得了一个平衡。</p>\n<p>在C++1x标准之前，C++是在建立在单线程语义上的。为了进行多线程编程，C++程序员通过使用诸如Pthreads，Windows Thread等C++语言标准之外的线程库来完成代码设计。以Pthreads为例，它提供了类似pthread_mutex_lock这样的函数来保证对共享变量的互斥访问，以防止数据竞跑。人们不禁会问，Pthreads这样的线程库我用的好好的，干嘛需要C++引入的多线程，这不是多此一举么？其实，以线程库的形式进行多线程编程在绝大多数应用场景下都是没有问题的。然而，线程库的解决方案也有其先天缺陷。第一，如果没有在编程语言中定义内存模型的话，我们就不能清楚的定义到底什么样的编译器/CPU优化是合法的，而程序员也不能确定程序到底会怎么样被优化执行。例如，Pthreads标准中并未对什么是数据竞跑（Data Race）做出精确定义，因此C++编译器可能会进行一些错误优化从而导致数据竞跑[3]。第二，绝大多数情况下线程库能正确的完成任务，而在极少数对性能有更高要求的情况下（尤其是需要利用底层的硬件特性来实现高性能Lock Free算法时）需要更精确的内存模型以规定好程序的行为。简而言之，把内存模型集成到编程语言中去是比线程库更好的选择。</p>\n<h4>3. C++1x中引入的atomic类型</h4>\n<p>C++作为一种高性能的系统语言，其设计目标之一就在于提供足够底层的操作，以满足对高性能的需求。在这个前提之下，C++1x除了提供传统的锁、条件变量等同步机制之外，还引入了新的atomic类型。相对于传统的mutex锁来说，atomic类型更底层，具备更好的性能，因此能用于实现诸如Lock Free等高性能并行算法。有了atomic类型，C++程序员就不需要像原来一样使用汇编代码来实现高性能的多线程程序了。而且，把atomic类型集成到C++语言中之后，程序员就可以更容易地实现可移植的多线程程序，而不用再依赖那些平台相关的汇编语句或者线程库。</p>\n<p>对常见的数据类型，C++1x都提供了与之相对应的atomic类型。以bool类型举例，与之相对应的atomic_bool类型具备两个新属性：原子性与顺序性。顾名思义，原子性的意思是说atomic_bool的操作都是不可分割的，原子的；而顺序性则指定了对该变量的操作何时对其他线程可见。在C++1x中，为了满足对性能的追求，atomic类型提供了三种顺序属性：sequential consistency ordering（即顺序一致性），acquire release ordering以及relaxed ordering。因为sequential consistency是最易理解的模型，所以默认情况下所有atomic类型的操作都会使sequential consistency顺序。当然，顺序一致性的性能相对来说比较差，所以程序员还可以使用对顺序性要求稍弱一些的acquire release ordering与最弱的relaxed ordering。</p>\n<p>在下面这个例子中，atomic_bool类型的变量data_ready就被用来实现两个线程间的同步操作。需要注意的是，对data_ready的写操作仍然可以通过直接使用赋值操作符（即“=”）来进行，但是对其的读操作就必须调用load()函数来进行。在默认的情况下，所有atomic类型变量的顺序性都是顺序一致性（即sequential consistency）。在这个例子中，因为data_ready的顺序性被规定为顺序一致性，所以线程1中对data_ready的写操作会与线程2中对data_ready的读操作构建起synchronize-with的同步关系，即#2->#3。又因为writer_thread()中的代码顺序规定了#1在#2之前发生，即#1->#2；而且reader_thread中的代码顺序规定了#3->#4，所以就有了#1->#2->#3->#4这样的顺序关系，从而可以保证在#4中读取data的值时，#1已经执行完毕，即#4一定能读到#1写入的值（10）。</p>\n<pre class=\"brush: cpp; title: ; notranslate\">\n#include &#60;atomic&#62;\n#include &#60;vector&#62;\n#include &#60;iostream&#62;\n\nstd::vector&#60;int&#62; data;\nstd::atomic_bool data_ready(false);\n\n// 线程1\nvoid writer_thread()\n{\ndata.push_back(10); // #1：对data的写操作\ndata_ready = true; // #2：对data_ready的写操作\n}\n\n// 线程2\nvoid reader_thread()\n{\nwhile(!data_ready.load()) // #3：对data_ready的读操作\n{\nstd::this_thread::sleep(std::milliseconds(10));\n}\nstd::cout &#60;&#60; ”data is ” &#60;&#60; data[0] &#60;&#60; ”\\n”; // #4：对data的读操作\n}\n</pre>\n<p>相信很多朋友会纳闷，这样的执行顺序不是显然的么？其实不然。如果我们把data_ready的顺序性制定为relaxed ordering的话，编译器和CPU就可以自由地做违反顺序一致性的乱序优化，从而导致#1不一定在#2之前被执行，最终导致#4中读到的data的值不为10。</p>\n<p>简单的来说，在atomic类型提供的三种顺序属性中，acquire release ordering对顺序性的约束程度介于sequential consistency（顺序一致性）和relaxed ordering之间，因为它不要求全局一致性，但是具有synchronized with的关系。Relaxed ordering最弱，因为它对顺序性不做任何要求。由此可见，除非非常必要，我们一般不建议使用relaxed ordering，因为这不能保证任何顺序性。关于这三种属性更详细的信息大家可以参考[1]。</p>\n<p>通过上面的例子我们可以看到，C++1x中的多线程内存模型为了通过atomic类型提供足够的灵活性和性能，最大限度地将底层细节（三种不同的顺序属性）暴露给了程序员。这样的设计原则一方面给程序员提供了实现高性能多线程算法的可能，但却也大大增加了使用上的难度。我个人的建议是，如果常规的mutex锁、条件变量、future信号能满足您的设计需求，那么您完全不需要使用atomic变量。如果您决定使用atomic变量，请尽量使用默认的顺序一致性属性。</p>\n<h4>4. 总结</h4>\n<p>本文对C++1x标准中新引入的多线程内存模型进行了简要介绍。C++1x多线程内存模型的引入使得广大C++程序员可以享受语言原生支持的多线程机制，并为实现高性能多线程算法提供了足够丰富的工具（例如atomic类型）。但是，多线程内存模型本身的复杂性，以及一些底层机制（例如不同的顺序性属性）的引入也给使用C++进行多线程编程带来了不小的复杂度。如何高效、可靠的利用好这些新引入的多线程机制将会成为一个新的挑战。</p>\n<h4>参考资料</h4>\n<p>[1] C++ Concurrency in Action<br />\n[2] C++1x standard draft<br />\n[3] Threads cannot be implemented as a library<br />\n[4] Memory Models: A Case for Rethinking Parallel Languages and Hardware<br />\n[5] The &#8220;Double-Checked Locking is Broken&#8221; Declaration</p>\n","descriptionType":"html","publishedDate":"Sat, 27 Aug 2011 03:39:47 +0000","feedId":9852,"bgimg":"","linkMd5":"cd1db7f0b1bbf6de52d7d4ffe229e228","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821749},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"记一次诡异的Debug经历","link":"http://www.parallellabs.com/?p=1291","description":"<p>Debug需要有刨根问底和百折不挠的精神。曙光往往在你被折磨的体无完肤之时出现，顿时你觉得整个世界都是光明的。</p>\n<p>最近有两次难忘的Debug经历。一次是由于系统重装了OS，某些系统配置变化了，导致Hadoop上的Terasort跑不通。问题的表面现象表现为，该节点/home所挂载的磁盘在Terasort运行时出现大量I/O操作，而不是hadoop真正写data的分区/data，从而极大影响性能。本来如果正常的话，该节点的/home分区是不会出现I/O的。用iotop等工具只能看到Hadoop的JVM对/home分区造成了巨大的I/O操作，但是究竟为何这些JVM会对/home而不是/data做大量操作？这到底是哪个配置的错误造成的？牵涉到这种reasoning的debug，好像还没有很好的工具能帮上忙。最后解决这个bug是通过不断调整Terasort的参数，不断试错发现的：在一次关闭JVM Huge Page后的测试时Terasort就能正常运行，从而锁定HugePage的相关设定，最后发现是因为重装系统后该用户名的group id变了，所以被allocate的HugePage并不能被该用户的JVM所使用，从而导致内存不足进而产生大量swap，才会出现/home目录大量I/O的情形。</p>\n<p>第二次是在集群上测试是发现一台节点CPU会有很异常的WAIT时间。用sysbench进行file I/O测试能复现这个bug。既然CPU有wait，那么很可能是disk有问题。用nmon分析了该机器的磁盘组的lvm数据后发现/dev/sdb设备有故障，会出现只有这个设备I/O busy而其它LVM里面的磁盘却空闲的情形。之后把该磁盘从LVM中删除，重做RAID 0，搞定了这个bug。</p>\n","descriptionType":"html","publishedDate":"Thu, 21 Mar 2013 13:51:46 +0000","feedId":9852,"bgimg":"","linkMd5":"6543b56280469ed049a9263b68c06672","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821748},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"第三次软件危机","link":"http://www.parallellabs.com/?p=449","description":"<blockquote><p>The major cause of the software crisis is that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming has become an equally gigantic problem.</p>\n<p>造成软件危机的主要原因是因为计算机的计算能力正在呈指数级地增长！说的简单些：在没有计算机的时候，编程根本就不是一个问题；当一些计算能力较弱的计算机出现时，编程成了一个中等难度的问题，而现在，我们拥有了计算能力超绝的计算机，编程就变为了一个同样复杂的问题。</p>\n<p>– Edsger Dijkstra, 1972年图灵奖获奖感言</p></blockquote>\n<p><strong>第一次软件危机 （60年代~70年代）</strong></p>\n<p>这个时期主要的软件开发方式是使用机器语言或者汇编语言在特定的机器上进行软件的设计与编写。此时的软件规模较小，也不需要使用系统化的软件开发方法，基本上是个人设计编码、个人操作使用的模式。这个时代的程序一个典型特征就是依赖特定的机器，程序员必须根据所使用的计算机的硬件特性编写特定的程序。</p>\n<p>然而从60年代中期开始，大容量、高速度计算机问世，程序设计的复杂度也随之增长。1968 年北大西洋公约组织的计算机科学家在联邦德国召开国际会议，第一次讨论软件危机问题，并正式提出“软件工程”一词，从此一门新兴的工程学科——软件工程学——为研究和克服软件危机应运而生，“软件危机”的概念也是在那次会议上由F. L. Bauer提出的。</p>\n<p>当时业界最迫切的需求是需要在不损失性能的前提下获得更好的“抽象性”和“可移植性”。此时，比汇编和机器语言更高级的语言相聚诞生，典型的代表莫过于C语言（1972年）。C语言让程序员能让程序员编写的代码在没有或只有较少机器相关性的同时又有不输于汇编语言的性能，而且丰富的语言特性也使得编程难度大大降低，成功的解决了“抽象性”和“可移植性”的问题。</p>\n<p><strong>第二次软件危机（80年代~90年代）</strong></p>\n<p>这次危机可以归因于软件复杂性的进一步增长。这个时候的大规模软件常常由数百万行代码组成，有数以百计的程序员参与其中，怎样高效、可靠的构造和维护这样规模的软件成为了一个新的难题。著名的《人月神话》中提及，IBM公司开发的OS/360系统共有4000多个模块，约100万条指令，投入5000人年，耗资数亿美元，结果还是延期交付。在交付使用后的系统中仍发现大量（2000个以上）的错误。</p>\n<p>这时候人们典型需求的是更好的“可组合性”(Composability)、“可延展性”(Malleability)以及“可维护性”(Maintainability)。程序的性能已经不是一个大问题了，因为摩尔定律能帮你搞定它（70年代编写的C程序仍然能在现在的计算机上运行，而且它还更快！）。为了解决这次危机，面向对象的编程语言（C++、C#、Java等）诞生了，更好的软件工程方法（设计模式、重构、测试、需求分析等等）诞生了，而程序员们也越来越不需要知道硬件是怎么工作的了。软件和硬件的界限越来越牢固，Java编写的代码能在任何JVM支持的平台上运行，程序员也非常乐于享受这样的便利。</p>\n<p><strong>第三次软件危机（2005年至今）</strong></p>\n<p>兄弟们，“<a href=\"http://blog.csdn.net/hsutter/archive/2006/08/29/1136281.aspx\" target=\"_blank\">免费的午餐已经结束了</a>”。<br />\n摩尔定律在串行机器上宣告失效，多核时代正式来临！</p>\n<p>这个时候怎样在多核平台上仍然能保持性能的持续增长就成为了这一次软件危机的核心。并行编程给我们带来了许许多多新的技术难题，现阶段想要高效的利用这些多核平台以获得更好的性能，就必须对计算机的硬件有较深入的理解，而广大程序员却更喜欢能有一些更加便利的编程模型（也许是一门新的语言、也许是新的编程模型）来简单高效地进行并行编程。我们正处在这次危机的开端，前路满是荆棘。但是只要有问题，就会有机会。多核时代，你们的机会在哪里呢？</p>\n","descriptionType":"html","publishedDate":"Thu, 01 Apr 2010 04:54:40 +0000","feedId":9852,"bgimg":"","linkMd5":"e6dde523b3996a9e7ed3c7cccd4d9ffe","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750},{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","title":"剖析为什么在多核多线程程序中要慎用volatile关键字？","link":"http://www.parallellabs.com/?p=924","description":"<p>这篇文章详细剖析了为什么在多核时代进行多线程编程时需要慎用volatile关键字。</p>\n<p>主要内容有：<br />\n1. C/C++中的volatile关键字<br />\n2. Visual Studio对C/C++中volatile关键字的扩展<br />\n3. Java/.NET中的volatile关键字<br />\n4. Memory Model（内存模型）<br />\n5. Volatile使用建议</p>\n<h2>1. C/C++中的volatile关键字</h2>\n<h3>1.1 传统用途</h3>\n<p>C/C++作为系统级语言，它们与硬件的联系是很紧密的。volatile的意思是“易变的”，这个关键字最早就是为了针对那些“异常”的内存操作而准备的。它的效果是让编译器不要对这个变量的读写操作做任何优化，每次读的时候都直接去该变量的内存地址中去读，每次写的时候都直接写到该变量的内存地址中去，即不做任何缓存优化。它经常用在需要处理中断的嵌入式系统中，其典型的应用有下面几种：</p>\n<p>a. 避免用通用寄存器对内存读写的优化。编译器常做的一种优化就是：把常用变量的频繁读写弄到通用寄存器中，最后不用的时候再存回内存中。但是如果某个内存地址中的值是由片外决定的（例如另一个线程或是另一个设备可能更改它），那就需要volatile关键字了。（感谢<a href=\"http://csbabel.wordpress.com/\">Kenny老师</a>指正）<br />\nb. 硬件寄存器可能被其他设备改变的情况。例如一个嵌入式板子上的某个寄存器直接与一个测试仪器连在一起，这样在这个寄存器的值随时可能被那个测试仪器更改。在这种情况下如果把该值设为volatile属性的，那么编译器就会每次都直接从内存中去取这个值的最新值，而不是自作聪明的把这个值保留在缓存中而导致读不到最新的那个被其他设备写入的新值。<br />\nc. 同一个物理内存地址M有两个不同的内存地址的情况。例如两个程序同时对同一个物理地址进行读写，那么编译器就不能假设这个地址只会有一个程序访问而做缓存优化，所以程序员在这种情况下也需要把它定义为volatile的。</p>\n<h3>1.2 多线程程序中的错误用法</h3>\n<p>看到这里，很多朋友自然会想到：恩，那么如果是两个线程需要同时访问一个共享变量，为了让其中两个线程每次都能读到这个变量的最新值，我们就把它定义为volatile的就好了嘛！我想这个就是多线程程序中volatile之所以引起那么多争议的最大原因。可惜的是，这个想法是错误的。</p>\n<p>举例来说，想用volatile变量来做同步（例如一个flag）？错！为什么？很简单，虽然volatile意味着每次读和写都是直接去内存地址中去操作，<strong>但是volatile在C/C++现有标准中即不能保证<a href=\"http://www.parallellabs.com/2010/11/13/concurrency-bugs-1/\">原子性（Atomicity）</a>也不能保证<a href=\"http://www.parallellabs.com/2010/11/23/concurrency-bugs-2/\">顺序性（Ordering）</a>，所以几乎所有试图用volatile来进行多线程同步的方案都是错的</strong>。我之前一篇文章介绍了<a href=\"http://www.parallellabs.com/2010/03/06/why-should-programmer-care-about-sequential-consistency-rather-than-cache-coherence/\">Sequential Consistency模型</a>（后面简称SC），它其实就是我们印象中多线程程序应该有的执行顺序。但是，SC最大的问题是性能太低了，因为CPU/编译器完全没有必要严格按代码规定的顺序（program order）来执行每一条指令。学过体系结构的同学应该知道不管是编译器也好CPU也好，他们最擅长做的事情就是帮你做乱序优化。在串行时代这些乱序优化对程序员来说都是透明的，封装好了的，你不用关心它们到底给你乱序成啥样了，因为它们会保证优化后的程序的运行结果跟你写程序时预期的结果是一模一样的。但是进入多核时代之后，CPU和编译器还会继续做那些串行时代的优化，更重要的是这些优化还会打破你多线程程序的SC模型语义，从而使得多线程程序的实际运行结果与我们所期待的运行结果不一致！</p>\n<p>拿X86来说，它的多核内存模型没有严格执行SC，即属于weak ordering（或者叫relax ordering？）。它唯一允许的乱序优化是可以把对不同地址的load操作提到store之前去（即把store x->load y乱序优化成load y -> store x）。而store x -> store y、load x -> load y，以及load y -> store x不允许交换执行顺序。在X86这样的内存模型下，volatile关键字根本就不能保证对不同volatile变量x和y的store x -> load y的操作不会被CPU乱序优化成load y -> store x。</p>\n<p>而对多线程读写操作的原子性来说，诸如volatile x=1这样的写操作的<a href=\"http://www.parallellabs.com/2010/04/15/atomic-operation-in-multithreaded-application/\">原子性其实是由X86硬件保证的</a>，跟volatile没有任何关系。事实上，volatile根本不能保证对没有内存对齐的变量（或者超出机器字长的变量）的读写操作的原子性。</p>\n<p>为了有个更直观的理解，我们来看看CPU的乱序优化是如何让volatile在多线程程序中显得如此无力的。下面这个著名的Dekker算法是想用flag1/2和turn来实现两个线程情况下的临界区互斥访问。这个算法关键就在于对flag1/2和turn的读操作（load）是在其写操作（store）之后的，因此这个多线程算法能保证dekker1和dekker2中对gSharedCounter++的操作是互斥的，即等于是把gSharedCounter++放到临界区里去了。但是，多核X86可能会对这个store->load操作做乱序优化，例如dekker1中对flag2的读操作可能会被提到对flag1和turn的写操作之前，这样就会最终导致临界区的互斥访问失效，而gSharedCounter++也会因此产生data race从而出现错误的计算结果。那么为什么多核CPU会对多线程程序做这样的乱序优化呢？因为从单线程的视角来看flag2和flag1、turn是没有依赖关系的，所以CPU当然可以对他们进行乱序优化以便充分利用好CPU里面的流水线（想了解更多细节请参考计算机体系结构相关书籍）。这样的优化虽然从单线程角度来讲没有错，但是它却违反了我们设计这个多线程算法时所期望的那个多线程语义。（想要解决这个bug就需要自己手动添加memory barrier，或者干脆别去实现这样的算法，而是使用类似pthread_mutex_lock这样的库函数，后面我会再讲到这点）</p>\n<p>当然，对不同的CPU来说他们的内存模型是不同的。比如说，如果这个程序是在单核上以多线程的方式执行那么它肯定不会出错，因为单核CPU的内存模型是符合SC的。而在例如PowerPC，ARM之类的架构上运行结果到底如何就得去翻它们的硬件手册中内存模型是怎么定义的了。</p>\n<pre class=\"brush: cpp; collapse: true; light: false; title: ; toolbar: true; notranslate\">\n/*\n * Dekker's algorithm, implemented on pthreads\n *\n * To use as a test to see if/when we can make\n * memory consistency play games with us in \n * practice. \n *\n * Compile: gcc -O2 -o dekker dekker.c -lpthread\n * Source: http://jakob.engbloms.se/archives/65\n */ \n\n#include &#60;assert.h&#62;\n#include &#60;pthread.h&#62;\n#include &#60;stdio.h&#62;\n#include &#60;stdlib.h&#62;\n\n#undef PRINT_PROGRESS \n\nstatic volatile int flag1 = 0;\nstatic volatile int flag2 = 0;\nstatic volatile int turn  = 1;\nstatic volatile int gSharedCounter = 0;\nint gLoopCount;\nint gOnePercent;\n\nvoid dekker1( ) {\n        flag1 = 1;\n        turn  = 2;\n        while((flag2 ==  1) &#38;&#38; (turn == 2)) ;\n        // Critical section\n        gSharedCounter++;\n        // Let the other task run\n        flag1 = 0;\n}\n\nvoid dekker2(void) {\n        flag2 = 1;\n        turn = 1;\n        while((flag1 ==  1) &#38;&#38; (turn == 1)) ;\n        // critical section\n        gSharedCounter++;        \n        // leave critical section\n        flag2 = 0;\n}\n\n//\n// Tasks, as a level of indirection\n//\nvoid *task1(void *arg) {\n        int i,j;\n        printf(&#34;Starting task1\\n&#34;);\n        // Do the dekker very many times\n#ifdef PRINT_PROGRESS\n\tfor(i=0;i&#60;100;i++) {\n\t  printf(&#34;[One] at %d%%\\n&#34;,i);\n\t  for(j=gOnePercent;j&#62;0;j--) {\n\t    dekker1();\n\t  }\n\t}\n#else\n\t// Simple basic loop\n        for(i=gLoopCount;i&#62;0;i--) {\n                dekker1();\n        }\n#endif\n\n}\n\nvoid *task2(void *arg) {\n        int i,j;\n        printf(&#34;Starting task2\\n&#34;);\n#ifdef PRINT_PROGRESS\n\tfor(i=0;i&#60;100;i++) {\n\t  printf(&#34;[Two] at %d%%\\n&#34;,i);\n\t  for(j=gOnePercent;j&#62;0;j--) {\n\t    dekker2();\n\t  }\n\t}\n#else\n        for(i=gLoopCount;i&#62;0;i--) {\n                dekker2();\n        }\n#endif\n}\n\nint\nmain(int argc, char ** argv)\n{\n        int            loopCount = 0;\n        pthread_t      dekker_thread_1;\n        pthread_t      dekker_thread_2;\n        void           * returnCode;\n        int            result;\n        int            expected_sum;\n\n        /* Check arguments to program*/\n        if(argc != 2) \n        {\n                fprintf(stderr, &#34;USAGE: %s &#60;loopcount&#62;\\n&#34;, argv[0]);\n                exit(1);\n        }\n\n        /* Parse argument */\n        loopCount   = atoi(argv[1]);\t/* Don't bother with format checking */\n        gLoopCount  = loopCount;\n\tgOnePercent = loopCount/100;\n        expected_sum = 2*loopCount;\n        \n        /* Start the threads */\n        result = pthread_create(&#38;dekker_thread_1, NULL, task1, NULL);\n        result = pthread_create(&#38;dekker_thread_2, NULL, task2, NULL);\n\n        /* Wait for the threads to end */\n        result = pthread_join(dekker_thread_1,&#38;returnCode);\n        result = pthread_join(dekker_thread_2,&#38;returnCode);\n        printf(&#34;Both threads terminated\\n&#34;);\n\n        /* Check result */\n        if( gSharedCounter != expected_sum ) {\n                printf(&#34;[-] Dekker did not work, sum %d rather than %d.\\n&#34;, gSharedCounter, expected_sum);\n                printf(&#34;    %d missed updates due to memory consistency races.\\n&#34;, (expected_sum-gSharedCounter));\n                return 1;\n        } else {\n                printf(&#34;[+] Dekker worked.\\n&#34;);\n                return 0;\n        }\n}\n\n</pre>\n<h2>2. Visual Studio对C/C++中volatile关键字的扩展</h2>\n<p>虽然C/C++中的volatile关键字没有对ordering做任何保证，但是微软从Visual Studio 2005开始就对volatile关键字添加了同步语义（保证ordering），即：对volatile变量的读操作具有acquire语义，对volatile变量的写操作具有release语义。Acquire和Release语义是来自data-race-free模型的概念。为了理解这个acquire语义和release语义有什么作用，我们来看看<a href=\"http://msdn.microsoft.com/en-us/library/12a04hfd(VS.80).aspx\">MSDN中的一个例子</a>。</p>\n<pre class=\"brush: cpp; collapse: true; light: false; title: ; toolbar: true; notranslate\">\n// volatile.cpp\n// compile with: /EHsc /O2\n// Output: Critical Data = 1 Success\n#include &#60;iostream&#62;\n#include &#60;windows.h&#62;\nusing namespace std;\n\nvolatile bool Sentinel = true;\nint CriticalData = 0;\n\nunsigned ThreadFunc1( void* pArguments ) {\n   while (Sentinel)\n      Sleep(0);   // volatile spin lock\n\n   // CriticalData load guaranteed after every load of Sentinel\n   cout &#60;&#60; &#34;Critical Data = &#34; &#60;&#60; CriticalData &#60;&#60; endl;\n   return 0;\n} \n\nunsigned  ThreadFunc2( void* pArguments ) {\n   Sleep(2000);\n   CriticalData++;   // guaranteed to occur before write to Sentinel\n   Sentinel = false; // exit critical section\n   return 0;\n}\n\nint main() {\n   HANDLE hThread1, hThread2; \n   DWORD retCode;\n\n   hThread1 = CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)&#38;ThreadFunc1,\n      NULL, 0, NULL);\n   hThread2 = CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)&#38;ThreadFunc2,\n      NULL, 0, NULL);\n\n   if (hThread1 == NULL || hThread2 == NULL)       {\n      cout &#60;&#60; &#34;CreateThread failed.&#34; &#60;&#60; endl; \n      return 1;\n   }\n\n   retCode = WaitForSingleObject(hThread1,3000);\n\n   CloseHandle(hThread1);\n   CloseHandle(hThread2);\n\n   if (retCode == WAIT_OBJECT_0 &#38;&#38; CriticalData == 1 )\n      cout &#60;&#60; &#34;Success&#34; &#60;&#60; endl;\n   else\n      cout &#60;&#60; &#34;Failure&#34; &#60;&#60; endl;\n}\n</pre>\n<p>例子中的 while (Sentinel) Sleep(0); // volatile spin lock 是对volatile变量的读操作，它具有acquire语义，acquire语义的隐义是当前线程在对sentinel的这个读操作之后的所有的对全局变量的访问都必须在该操作之后执行；同理，例子中的Sentinel = false; // exit critical section 是对volatile变量的写操作，它具有release语义，release语义的隐义是当前线程在对sentinel这个写操作之前的所有对全局变量的访问都必须在该操作之前执行完毕。所以ThreadFunc1（）读CriticalData时必定已经在ThreadFunc2（）执行完CriticalData++之后，即CriticalData最后输出的值必定为1。建议大家用纸画一下acquire/release来加深理解。<strong>一个比较形象的解释就是把acquire当成lock，把release当成unlock，它俩组成了一个临界区，所有临界区外面的操作都只能往这个里面移，但是临界区里面的操作都不能往外移，简单吧？</strong></p>\n<p>其实这个程序就相当于用volatile变量的acquire和release语义实现了一个临界区，在临界区内部的代码就是 Sleep(2000); CriticalData++; 或者更贴切点也可以看成是一对pthread_cond_wait和pthread_cond_signal。</p>\n<p>这个volatile的acquire和release语义是VS自己的扩展，C/C++标准里是没有的，所以同样的代码用gcc编译执行结果就可能是错的，因为编译器/CPU可能做违反正确性的乱序优化。Acquire和release语义本质上就是为了保证程序执行时memory order的正确性。<strong>但是，虽然这个VS扩展使得volatile变量能保证ordering，它还是不能保证对volatile变量读写的原子性。</strong>事实上，如果我们的程序是跑在X86上面的话，内存对齐了的变量的读写的原子性是由硬件保证的，跟volatile没有任何关系。而像volatile g_nCnt++这样的语句本身就不是原子操作，想要保证这个操作是原子的，就必须使用带LOCK语义的++操作，具体请看我<a href=\"http://www.parallellabs.com/2010/04/15/atomic-operation-in-multithreaded-application/\">这篇文章</a>。</p>\n<p>另外，VS生成的volatile变量的汇编代码是否真的调用了memory barrier也得看具体的硬件平台，例如x86上就不需要使用memory barrier也能保证acquire和release语义，因为X86硬件本身就有比较强的memory模型了，但是Itanium上面VS就会生成带memory barrier的汇编代码。具体可以参考<a href=\"http://blogs.msdn.com/b/kangsu/archive/2007/07/16/volatile-acquire-release-memory-fences-and-vc2005.aspx\">这篇</a>。</p>\n<p><strong>但是，虽然VS对volatile关键字加入了acquire/release语义，有一种情况还是会出错，即我们之前看到的dekker算法的例子。</strong>这个其实蛮好理解的，因为读操作的acquire语义不允许在其之后的操作往前移，但是允许在其之前的操作往后移；同理，写操作的release语义允许在其之后的操作往前移，但是不允许在其之前的操作往后移；这样的话对一个volatile变量的读操作（acquire）当然可以放到对另一个volatile变量的写操作（release）之前了！Bug就是这样产生的！下面这个程序大家拿Visual Studio跑一下就会发现bug了（我试了VS2008和VS2010，都有这个bug）。多线程编程复杂吧？希望大家还没被弄晕，要是晕了的话也很正常，仔仔细细重新再看一遍吧:)</p>\n<p>想解决这个Bug也很简单，直接在dekker1和dekker2中对flag1/flag2/turn赋值操作之后都分别加入full memory barrier就可以了，即保证load一定是在store之后执行即可。具体的我就不详述了。</p>\n<pre class=\"brush: cpp; collapse: true; light: false; title: ; toolbar: true; notranslate\">\n#include &#60;iostream&#62;\n#include &#60;windows.h&#62;\nusing namespace std;\n\nstatic volatile int flag1 = 0;\nstatic volatile int flag2 = 0;\nstatic volatile int turn = 1; // must have &#34;turn&#34;, otherwise the two threads might introduce deadlock at line 13&#38;23 of &#34;while...&#34;\nstatic int gCount = 0;\n\nvoid dekker1() {\n\tflag1 = 1;\n\tturn = 2;\n\twhile ((flag2 == 1) &#38;&#38; (turn == 2));\n\t// critical section\n\tgCount++;\n\tflag1 = 0; \t// leave critical section\n}\n\nvoid dekker2() {\n\tflag2 = 1;\n\tturn = 1;\n\twhile ((flag1 == 1) &#38;&#38; (turn == 1));\n\t// critical setion\n\tgCount++;\n\tflag2 = 0; \t// leave critical section\n}\n\nunsigned ThreadFunc1( void* pArguments ) {\n\tint i;\n\t//cout &#60;&#60; &#34;Starting Thread 1&#34; &#60;&#60; endl;\n\tfor (i=0;i&#60;1000000;i++) {\n\t\tdekker1();\n\t}\n\treturn 0;\n} \n\nunsigned  ThreadFunc2( void* pArguments ) {\n\tint i;\n\t//cout &#60;&#60; &#34;Starting Thread 2&#34; &#60;&#60; endl;\n\tfor (i=0;i&#60;1000000;i++) {\n\t\tdekker2();\n\t}\n\treturn 0;\n}\n\nint main() {\n\tHANDLE hThread1, hThread2;\n\t//DWORD retCode;\n\n\thThread1 = CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)&#38;ThreadFunc1,\n\t\tNULL, 0, NULL);\n\thThread2 = CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)&#38;ThreadFunc2,\n\t\tNULL, 0, NULL);\n\n\tif (hThread1 == NULL || hThread2 == NULL) {\n\t\tcout &#60;&#60; &#34;CreateThread failed.&#34; &#60;&#60; endl;\n\t\treturn 1;\n\t}\n\n\tWaitForSingleObject(hThread1,INFINITE);\n\tWaitForSingleObject(hThread2,INFINITE);\n\tcout &#60;&#60; gCount &#60;&#60; endl;\n\n\tif (gCount == 2000000)\n\t\tcout &#60;&#60; &#34;Success&#34; &#60;&#60; endl;\n\telse\n\t\tcout &#60;&#60; &#34;Fail&#34; &#60;&#60; endl;\n}\n</pre>\n<h2>3. Java/.NET中的volatile关键字</h2>\n<h3>3.1 多线程语义</h3>\n<p>Java和.NET分别有JVM和CLR这样的虚拟机，保证多线程的语义就容易多了。<strong>说简单点，Java和.NET中的volatile关键字也是限制虚拟机做优化，都具有acquire和release语义，<del datetime=\"2011-06-08T07:55:52+00:00\">而且由虚拟机直接保证了对volatile变量读写操作的原子性。</del> （volatile只保证可见性，不保证原子性。java中，对volatile修饰的long和double的读写就不是原子的 (http://java.sun.com/docs/books/jvms/second_edition/html /Threads.doc.html#22244)，除此之外的基本类型和引用类型都是原子的。&#8211; 多谢liuchangit指正） </strong>这里需要注意的一点是，Java和.NET里面的volatile没有对应于我们最开始提到的C/C++中对“异常操作”用volatile修饰的传统用法。原因很简单，Java和.NET的虚拟机对安全性的要求比C/C++高多了，它们才不允许不安全的“异常”访问存在呢。</p>\n<p>而且像JVM/.NET这样的程序可移植性都非常好。虽然现在C++1x正在把多线程模型添加到标准中去，但是因为C++本身的性质导致它的硬件平台依赖性很高，可移植性不是特别好，所以在移植C/C++多线程程序时理解硬件平台的内存模型是非常重要的一件事情，它直接决定你这个程序是否会正确执行。</p>\n<p>至于Java和.NET中是否也存在类似VS 2005那样的bug我没时间去测试，道理其实是相同的，真有需要的同学自己应该能测出来。好像这篇<a href=\"http://www.infoq.com/articles/memory_barriers_jvm_concurrency\">InfoQ的文章</a>中显示Java运行这个dekker算法没有问题，因为JVM给它添加了mfence。另一个臭名昭著的例子就应该是<a href=\"http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\">Double-Checked Locking</a>了。</p>\n<h3>3.2 volatile int与AtomicInteger区别</h3>\n<p>Java和.NET中这两者还是有些区别的，主要就是后者提供了类似incrementAndGet()这样的方法可以直接调用（保证了原子性），而如果是volatile x进行++操作则不是原子的。increaseAndGet()的实现调用了类似CAS这样的原子指令，所以能保证原子性，同时又不会像使用synchronized关键字一样损失很多性能，用来做全局计数器非常合适。</p>\n<h2>4. Memory Model（内存模型）</h2>\n<p>说了这么多，还是顺带介绍一下Memory Model吧。就像前面说的，CPU硬件有它自己的内存模型，不同的编程语言也有它自己的内存模型。如果用一句话来介绍什么是内存模型，我会说它就是程序员，编程语言和硬件之间的一个契约，它保证了共享的内存地址里的值在需要的时候是可见的。下次我会专门详细写一篇关于它的内容。它最大的作用是取得可编程性与性能优化之间的一个平衡。</p>\n<h2>5. volatile使用建议</h2>\n<p>总的来说，volatile关键字有两种用途：一个是ISO C/C++中用来处理“异常”内存行为（此用途只保证不让编译器做任何优化，对多核CPU是否会进行乱序优化没有任何约束力），另一种是在Java/.NET（包括Visual Studio添加的扩展）中用来实现高性能并行算法（此种用途通过使用memory barrier保证了CPU/编译器的ordering，以及通过JVM或者CLR保证了对该volatile变量读写操作的原子性）。</p>\n<p>一句话，volatile对多线程编程是非常危险的，使用的时候千万要小心你的代码在多核上到底是不是按你所想的方式执行的，特别是对现在暂时还没有引入内存模型的C/C++程序更是如此。安全起见，大家还是用Pthreads，Java.util.concurrent，TBB等并行库提供的lock/spinlock，conditional variable, barrier, Atomic Variable之类的同步方法来干活的好，因为它们的内部实现都调用了相应的memory barrier来保证memory ordering，你只要保证你的多线程程序没有data race，那么它们就能帮你保证你的程序是正确的（是的，Pthreads库也是有它自己的内存模型的，只不过它的内存模型还些缺点，所以把多线程内存模型直接集成到C/C++中是更好的办法，也是将来的趋势，但是C++1x中将不会像Java/.NET一样给volatile关键字添加acquire和release语义，而是转而提供另一种具有同步语义的atomic variables，此为后话）。<strong>如果你想实现更高性能的lock free算法，或是使用volatile来进行同步，那么你就需要先把CPU和编程语言的memory model搞清楚，然后再时刻注意Atomicity和Ordering是否被保证了。</strong>（注意，用没有acquire/release语义的volatile变量来进行同步是错误的，但是你仍然可以在C/C++中用volatile来修饰一个不是用来做同步（例如一个event flag）而只是被不同线程读写的共享变量，只不过它的新值什么时候能被另一个线程读到是没有保证的，需要你自己做相应的处理）</p>\n<p>Herb Sutter 在他的那篇<a href=\"http://www.drdobbs.com/high-performance-computing/212701484;jsessionid=YH24PBXWP5CJ3QE1GHPCKHWATMY32JVN?pgno=1\" target=\"_blank\">volatile vs. volatile</a>中对这两种用法做了很仔细的区分，我把其中两张表格链接贴过来供大家参考：</p>\n<p><a href=\"http://i.cmpnet.com/ddj/images/article/2009/0901/090108sutter_f1.gif\" target=\"_blank\">volatile的两种用途</a><br />\n<a href=\"http://i.cmpnet.com/ddj/images/article/2009/0901/090108sutter_t1.gif\" target=\"_blank\">volatile两种用途的异同</a></p>\n<p>最后附上《Java Concurrency in Practice》3.1.4节中对Java语言的volatile关键字的使用建议（不要被英语吓到，这些内容确实对你有用，而且还能顺便帮练练英语，哈哈）：</p>\n<p>So from a memory visibility perspective, writing a volatile variable is like exiting a synchronized block and reading a volatile variable is like entering a synchronized block. However, we do not recommend relying too heavily on volatile variables for visibility; code that relies on volatile variables for visibility of arbitrary state is more fragile and harder to understand than code that uses locking.</p>\n<p>Use volatile variables only when they simplify implementing and verifying your synchronization policy; avoid using volatile variables when veryfing correctness would require subtle reasoning about visibility. Good uses of volatile variables include ensuring the visibility of their own state, that of the object they refer to, or indicating that an important lifecycle event (such as initialization or shutdown) has occurred.</p>\n<p>Locking can guarantee both visibility and atomicity; volatile variables can only guarantee visibility.</p>\n<p>You can use volatile variables only when all the following criteria are met:<br />\n(1) Writes to the variable do not depend on its current value, or you can ensure that only a single thread ever updates the value;<br />\n(2) The variable does not participate in invariants with other state variables; and<br />\n(3) Locking is not required for any other reason while the variable is being accessed.</p>\n<h2>参考资料</h2>\n<p>1. <a href=\"http://book.douban.com/subject/1888733/\">《Java Concurrency in Practice》</a>3.1.4节<br />\n2. <a href=\"http://www.drdobbs.com/high-performance-computing/212701484;jsessionid=P2PXZYKEQVDFDQE1GHPCKHWATMY32JVN?pgno=1\">volatile vs. volatile（Herb Sutter对volatile的阐述，必看）</a><br />\n3. <a href=\"http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\">The &#8220;Double-Checked Locking is Broken&#8221; Declaration</a><br />\n4. <a href=\"http://www.albahari.com/threading/part4.aspx#_The_volatile_keyword\">Threading in C#</a><br />\n5. <a href=\"http://software.intel.com/en-us/blogs/2007/11/30/volatile-almost-useless-for-multi-threaded-programming/\">Volatile: Almost Useless for Multi-Threaded Programming</a><br />\n6. <a href=\"http://www.linuxjournal.com/article/8212\">Memory Ordering in Modern Microprocessors</a><br />\n7. <a href=\"http://en.wikipedia.org/wiki/Memory_ordering\">Memory Ordering @ Wikipedia</a><br />\n8. <a href=\"http://www.spongeliu.com/clanguage/memorybarrier/\">内存屏障什么的</a><br />\n9. <a href=\"http://ivanwangcn.spaces.live.com/blog/cns!F291BBD27380D1CA!153.entry?wa=wsignin1.0&#038;sa=540891277\">The memory model of x86</a><br />\n10. <a href=\"http://codingdao.com/wp/post/vc-volatile-variable-memory-barrier-concurrent-lock/\">VC 下 volatile 变量能否建立 Memory Barrier 或并发锁</a><br />\n11. <a href=\"http://www.bluebytesoftware.com/blog/PermaLink,guid,a0484627-c752-45f6-a2ac-414130cb3d2f.aspx\">Sayonara volatile（Concurrent Programming on Windows作者的文章 跟我观点几乎一致）</a><br />\n12. <a href=\"http://www.ibm.com/developerworks/cn/java/j-jtp06197.html\">Java 理论与实践: 正确使用 Volatile 变量</a><br />\n13. <a href=\"http://blog.xiping.me/2010/12/java-volatile-is-not-so-evil.html\">Java中的Volatile关键字</a></p>\n","descriptionType":"html","publishedDate":"Sat, 04 Dec 2010 08:46:26 +0000","feedId":9852,"bgimg":"","linkMd5":"db62d84815864557c7128b7d769c0149","bgimgJsdelivr":"","metaImg":"","author":"Guancheng (G.C.)","publishedOrCreatedDate":1598315821750}],"record":{"createdTime":"2020-08-25 08:37:01","updatedTime":"2020-08-25 08:37:01","feedId":9852,"fetchDate":"Tue, 25 Aug 2020 00:37:01 +0000","fetchMs":3055,"handleMs":5543,"totalMs":50328,"newArticles":0,"totalArticles":69,"status":1,"type":0,"ip":"54.210.239.185","hostName":"us-008.herokuapp.com","requestId":"1a730b8c97d647908670447a066d7418_9852","contentType":"application/rss+xml; charset=UTF-8","totalBytes":938510,"bgimgsTotal":8,"bgimgsGithubTotal":8,"articlesImgsTotal":17,"articlesImgsGithubTotal":13,"successGithubMap":{"myreaderx25":1,"myreaderx21":1,"myreaderx32":1,"myreaderx10":1,"myreaderx3":1,"myreaderx33":1,"myreaderx22":1,"myreaderx2":1,"myreaderx1":1,"myreaderx31":1,"myreaderx18":1,"myreaderx29":1},"failGithubMap":{}},"feed":{"createdTime":"2020-08-25 04:35:27","updatedTime":"2020-08-25 04:35:27","id":9852,"name":"Parallel Labs ","url":"http://www.parallellabs.com/feed/","subscriber":null,"website":null,"icon":"http://www.parallellabs.com/favicon.ico","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx61/cdn72@2020_4/2020/08/25/00-37-00-825_f29f5555a29d04d6.png","description":"Be a lifelong learner with a natural curiosity to figure out how the world works, and passion to shape the world to come by crafting the next big thing. Don't worry dude, just hacking!","weekly":null,"link":"http://www.parallellabs.com"},"noPictureArticleList":[],"tmpCommonImgCdnBytes":246934,"tmpBodyImgCdnBytes":691576,"tmpBgImgCdnBytes":0,"extra4":{"start":1598315812765,"total":0,"statList":[{"spend":3443,"msg":"获取xml内容"},{"spend":5543,"msg":"解释文章"},{"spend":1,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":32775,"msg":"正文链接上传到cdn"}]},"extra5":17,"extra6":17,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2011/12/xrime.bmp","sourceStatusCode":404,"sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":4180,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:01","host":"us-021*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a,e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2011/12/xrime.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":4161,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:06","host":"europe-59*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a,e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）.bmp","sourceStatusCode":404,"sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":13464,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:10","host":"us-033*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/弱连通分布.bmp","sourceStatusCode":404,"sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":14857,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:10","host":"us-004*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/社会网络中结点和边需要存储额外信息.bmp","sourceStatusCode":404,"sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":15279,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:10","host":"europe67*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2011/12/稀疏图和稠密图的邻接表与邻接矩阵形式.bmp","sourceStatusCode":404,"sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":15553,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:10","host":"us-001*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":18073,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:23","host":"europe64*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/弱连通分布.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":17283,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:25","host":"us-52*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2011/12/稀疏图和稠密图的邻接表与邻接矩阵形式.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":17178,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:25","host":"us-55*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/社会网络中结点和边需要存储额外信息.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":17314,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:25","host":"us-017*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"}],"extra10_invalidATagHrefValue":{"http://www.parallellabs.com/?p=1208_mailto:reports@us.ibm.com":"mailto:reports@us.ibm.com"},"extra111_proxyServerAndStatMap":{"http://us-001.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[404]},"http://us-017.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,404]},"http://us-55.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,404]},"http://us-033.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[404]},"http://us-004.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[404]},"http://us-034.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]},"http://europe64.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,404]},"http://europe67.herokuapp.com/":{"failCount":1,"successCount":0,"resultList":[404]},"http://us-52.herokuapp.com/":{"failCount":1,"successCount":1,"resultList":[200,404]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://s.w.org/images/core/emoji/11.2.0/72x72/1f642.png","sourceStatusCode":200,"destWidth":72,"destHeight":72,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn95@2020_1/2020/08/25/00-37-01-864_6d4495c4489cf88c.webp","sourceBytes":620,"destBytes":1362,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":848,"convertSpendMs":10,"createdTime":"2020-08-25 08:37:01","host":"us-009*","referer":"http://www.parallellabs.com/?p=1128","linkMd5ListStr":"c4f3d185b21523dd1128c610849f4b28,c4f3d185b21523dd1128c610849f4b28","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"620 B","destSize":"1.3 KB","compressRate":"219.7%"},{"code":1,"isDone":false,"source":"http://www.matrix67.com/blogimage/200601111.gif","sourceStatusCode":200,"destWidth":523,"destHeight":362,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn15@2020_4/2020/08/25/00-37-01-963_028e7770b40f1ed4.webp","sourceBytes":14010,"destBytes":11782,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":970,"convertSpendMs":35,"createdTime":"2020-08-25 08:37:01","host":"us-013*","referer":"http://www.parallellabs.com/?p=564","linkMd5ListStr":"fccb7c7d22e7975787fa7365845c0781,fccb7c7d22e7975787fa7365845c0781","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.7 KB","destSize":"11.5 KB","compressRate":"84.1%"},{"code":1,"isDone":false,"source":"http://farm9.staticflickr.com/8356/8401870744_7201e14920.jpg","sourceStatusCode":200,"destWidth":442,"destHeight":410,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn7@2020_3/2020/08/25/00-37-01-881_5583f544257d9a52.webp","sourceBytes":36213,"destBytes":17392,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1006,"convertSpendMs":19,"createdTime":"2020-08-25 08:37:01","host":"us-037*","referer":"http://www.parallellabs.com/?p=1280","linkMd5ListStr":"e2a00eb700b0d750629e26805b914fbc,e2a00eb700b0d750629e26805b914fbc","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"35.4 KB","destSize":"17 KB","compressRate":"48%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2010/11/Erlang-the-Movie-208x300.jpg","sourceStatusCode":200,"destWidth":208,"destHeight":300,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn87@2020_2/2020/08/25/00-37-02-242_45deeb231a86f971.webp","sourceBytes":22356,"destBytes":12728,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1240,"convertSpendMs":6,"createdTime":"2020-08-25 08:37:01","host":"us-033*","referer":"http://www.parallellabs.com/?p=867","linkMd5ListStr":"82f930fc186ae7e4dbc3b6ff3f8bf88b,82f930fc186ae7e4dbc3b6ff3f8bf88b","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.8 KB","destSize":"12.4 KB","compressRate":"56.9%"},{"code":1,"isDone":false,"source":"https://s.w.org/images/core/emoji/11.2.0/72x72/2122.png","sourceStatusCode":200,"destWidth":72,"destHeight":72,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn3@2020_5/2020/08/25/00-37-02-029_2b6f91e88d5f6d66.webp","sourceBytes":613,"destBytes":1242,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1090,"convertSpendMs":4,"createdTime":"2020-08-25 08:37:01","host":"europe-59*","referer":"http://www.parallellabs.com/?p=469","linkMd5ListStr":"71f657713d66e35cb0482207a5f8c78b,71f657713d66e35cb0482207a5f8c78b","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"613 B","destSize":"1.2 KB","compressRate":"202.6%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2013/08/图1.png","sourceStatusCode":200,"destWidth":500,"destHeight":281,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn11@2020_3/2020/08/25/00-37-02-323_840631c0545f3da5.webp","sourceBytes":84214,"destBytes":17586,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1361,"convertSpendMs":10,"createdTime":"2020-08-25 08:37:01","host":"us-025*","referer":"http://www.parallellabs.com/?p=1392","linkMd5ListStr":"4dd2aedad5700145e91cfdeec190b152,4dd2aedad5700145e91cfdeec190b152","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"82.2 KB","destSize":"17.2 KB","compressRate":"20.9%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/multicore.bmp","sourceStatusCode":200,"destWidth":0,"destHeight":0,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn100@2020_1/2020/08/25/00-37-02-920_41e42614f8a17ea1.jpg","sourceBytes":184842,"destBytes":184842,"feedId":9852,"totalSpendMs":2813,"convertSpendMs":2,"createdTime":"2020-08-25 08:37:01","host":"europe21*","referer":"http://www.parallellabs.com/?p=1179","linkMd5ListStr":"518a402e4b446b4c88c478e1adca05e8,518a402e4b446b4c88c478e1adca05e8","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"180.5 KB","destSize":"180.5 KB","compressRate":"100%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2011/12/xrime.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":4161,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:06","host":"europe-59*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a,e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://farm9.staticflickr.com/8365/8400781281_b526307057.jpg","sourceStatusCode":200,"destWidth":374,"destHeight":313,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn30@2020_2/2020/08/25/00-37-10-436_7421c1c4ebeafe82.webp","sourceBytes":33627,"destBytes":16674,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":908,"convertSpendMs":35,"createdTime":"2020-08-25 08:37:10","host":"us-52*","referer":"http://www.parallellabs.com/?p=1280","linkMd5ListStr":"e2a00eb700b0d750629e26805b914fbc","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"32.8 KB","destSize":"16.3 KB","compressRate":"49.6%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2010/04/bitfield.JPG","sourceStatusCode":200,"destWidth":525,"destHeight":388,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn51@2020_4/2020/08/25/00-37-10-777_040a5e3b979ba680.webp","sourceBytes":24067,"destBytes":11472,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1210,"convertSpendMs":8,"createdTime":"2020-08-25 08:37:10","host":"us-034*","referer":"http://www.parallellabs.com/?p=469","linkMd5ListStr":"71f657713d66e35cb0482207a5f8c78b","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23.5 KB","destSize":"11.2 KB","compressRate":"47.7%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2013/08/图2.png","sourceStatusCode":200,"destWidth":1344,"destHeight":546,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn36@2020_5/2020/08/25/00-37-10-835_2541e2de67466b74.webp","sourceBytes":36823,"destBytes":44694,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1398,"convertSpendMs":33,"createdTime":"2020-08-25 08:37:10","host":"us-017*","referer":"http://www.parallellabs.com/?p=1392","linkMd5ListStr":"4dd2aedad5700145e91cfdeec190b152","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"36 KB","destSize":"43.6 KB","compressRate":"121.4%"},{"code":1,"isDone":false,"source":"http://farm9.staticflickr.com/8047/8401870784_9c2717ca33.jpg","sourceStatusCode":200,"destWidth":442,"destHeight":275,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn26@2020_2/2020/08/25/00-37-10-777_ac938c55f07789b9.webp","sourceBytes":21506,"destBytes":10734,"targetWebpQuality":75,"feedId":9852,"totalSpendMs":1335,"convertSpendMs":8,"createdTime":"2020-08-25 08:37:10","host":"europe64*","referer":"http://www.parallellabs.com/?p=1280","linkMd5ListStr":"e2a00eb700b0d750629e26805b914fbc","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21 KB","destSize":"10.5 KB","compressRate":"49.9%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/google-trend-multicore.bmp","sourceStatusCode":200,"destWidth":0,"destHeight":0,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn48@2020_5/2020/08/25/00-37-11-313_f350aed50ecf4776.jpg","sourceBytes":608002,"destBytes":608002,"feedId":9852,"totalSpendMs":2091,"convertSpendMs":3,"createdTime":"2020-08-25 08:37:10","host":"us-55*","referer":"http://www.parallellabs.com/?p=1179","linkMd5ListStr":"518a402e4b446b4c88c478e1adca05e8","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"593.8 KB","destSize":"593.8 KB","compressRate":"100%"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/两种输入输出方式（左：较为低效的传统方式，右：高效的序列化方式）.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":18073,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:23","host":"europe64*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/弱连通分布.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":17283,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:25","host":"us-52*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2011/12/稀疏图和稠密图的邻接表与邻接矩阵形式.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":17178,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:25","host":"us-55*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"},{"code":1,"isDone":false,"source":"http://www.parallellabs.com/wp-content/uploads/2012/01/社会网络中结点和边需要存储额外信息.bmp","sourceStatusCode":404,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn0@2020_1/404.jpg","sourceBytes":0,"destBytes":0,"feedId":9852,"totalSpendMs":17314,"convertSpendMs":0,"createdTime":"2020-08-25 08:37:25","host":"us-017*","referer":"http://www.parallellabs.com/?p=1133","linkMd5ListStr":"e8beedf13674409a00b5af7231bc8e9a","extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[404],"sourceSize":"0","destSize":"0"}],"successGithubMap":{"myreaderx25":1,"myreaderx21":1,"myreaderx32":1,"myreaderx10":1,"myreaderx3":1,"myreaderx33":1,"myreaderx22":1,"myreaderx2":1,"myreaderx1":1,"myreaderx31":1,"myreaderx18":1,"myreaderx29":1},"failGithubMap":{}}