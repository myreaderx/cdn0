{"code":1,"isDone":false,"toInsertArticleList":[{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment installer Elasticsearch, Logstash et Kibana (Elastic Stack) sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-fr","description":"<h3 id=\"introduction\">Introduction</h3>\n\n<p>Elastic Stack - anciennement connue sous le nom de <em>ELK Stack</em> - est une collection de logiciels open-source produite par <a href=\"https://www.elastic.co/\">Elastic</a> qui vous permet de rechercher, d'analyser et de visualiser des journaux générés à partir de n'importe quelle source dans n'importe quel format, une pratique connue sous le nom de <em>journalisation centralisée</em>. La journalisation centralisée peut être utile lorsque vous tentez d'identifier des problèmes avec vos serveurs ou vos applications, car elle vous permet de consulter tous vos journaux en un seul endroit. Elle est également utile car elle vous permet d'identifier les problèmes qui concernent plusieurs serveurs, en corrélant leurs journaux pendant une période spécifique.</p>\n\n<p>La Elastic Stack comporte quatre composants principaux :</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/elasticsearch\"><strong>Elasticsearch</strong></a> : un moteur de recherche <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\"><em>RESTful</em></a> distribué qui stocke toutes les données recueillies.</li>\n<li><a href=\"https://www.elastic.co/products/logstash\"><strong>Logstash</strong></a> : le composant traitement des données de Elastic Stack, qui envoie les données entrantes à Elasticsearch.</li>\n<li><a href=\"https://www.elastic.co/products/kibana\"><strong>Kibana</strong></a> : une interface web pour la recherche et la visualisation des journaux.</li>\n<li><a href=\"https://www.elastic.co/products/beats\"><strong>Beats</strong></a> : des expéditeurs de données légers et à usage unique qui peuvent envoyer des données provenant de centaines ou de milliers de machines à Logstash ou à Elasticsearch.</li>\n</ul>\n\n<p>Au cours de ce tutoriel, vous allez installer l&rsquo;<a href=\"https://www.elastic.co/elk-stack\">Elastic Stack</a> sur un serveur Ubuntu 20.04. Vous apprendrez comment installer tous les composants de l'Elastic Stack - y compris <a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>, un Beat utilisé pour transmettre et centraliser les journaux et les fichiers - et les configurer pour rassembler et visualiser les journaux du système. En outre, comme Kibana n'est normalement disponible que sur le <code>localhost</code>, nous utiliserons <a href=\"https://www.nginx.com/\">Nginx</a> comme proxy afin qu'il soit accessible via un navigateur web. Nous installerons tous ces composants sur un seul serveur, que nous appellerons notre <em>serveur Elastic Stack</em>.</p>\n\n<p><span class='note'><strong>Note</strong> : lorsque vous installez l'ElasticStack, vous devez utiliser la même version sur l'ensemble de la pile. Dans ce tutoriel, nous allons installer les dernières versions de la pile entière qui sont, au moment de la rédaction de ce document, Elasticsearch 7.7.1, Kibana 7.7.1, Logstash 7.7.1 et Filebeat 7.7.1.<br></span></p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour terminer ce tutoriel, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li><p>Un serveur Ubuntu 20.04 avec 4 Go de RAM et 2 CPU installé avec un utilisateur sudo non root. Vous pouvez y parvenir en suivant la <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">configuration initiale du serveur avec Ubuntu 20.04</a>. Pour ce tutoriel, nous travaillerons avec la quantité minimale de CPU et de RAM requise pour exécuter Elasticsearch. Notez que la quantité de CPU, de RAM et de stockage dont votre serveur Elasticsearch aura besoin dépend du volume de journaux que vous prévoyez.</p></li>\n<li><p>OpenJDK 11 installé. Voir la section <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04#installing-the-default-jrejdk\">Installation du JRE/JDK par défaut</a> dans notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04\">Comment installer Java avec Apt sur Ubuntu 20.04</a> pour configurer cela.</p></li>\n<li><p>Nginx installé sur votre serveur, que nous configurerons plus loin dans ce guide comme un proxy inverse pour Kibana. Suivez notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">Comment installer Nginx sur Ubuntu 20.04</a> pour le configurer.</p></li>\n</ul>\n\n<p>En outre, comme l'Elastic Stack est utilisé pour accéder à des informations précieuses sur votre serveur auxquelles vous ne voudriez pas que des utilisateurs non autorisés accèdent, il est important que vous mainteniez votre serveur sécurisé en installant un certificat TLS/SSL. Cette action est facultative mais <strong>fortement encouragée</strong>.</p>\n\n<p>Cependant, comme vous allez finalement apporter des modifications à votre bloc serveur Nginx au cours de ce guide, il serait sans doute plus logique que vous exécutiez les étapes du guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Let&rsquo;s Encrypt sur Ubuntu 20.04</a> à la fin de la deuxième étape de ce tutoriel. Dans cette optique, si vous prévoyez de configurer Let&rsquo;s Encrypt sur votre serveur, vous devrez au préalable mettre en place les éléments suivants :</p>\n\n<ul>\n<li>Un nom de domaine entièrement qualifié (FQDN). Ce tutoriel utilisera <code><span class=\"highlight\">your_domain</span></code>. Vous pouvez acheter un nom de domaine sur <a href=\"https://namecheap.com\">Namecheap</a>, en obtenir un gratuitement sur <a href=\"http://www.freenom.com/en/index.html\">Freenom</a>, ou utiliser le bureau d'enregistrement de domaine de votre choix.</li>\n<li><p>Les deux enregistrements DNS suivants ont été configurés pour votre serveur. Vous pouvez suivre <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">cette introduction à DigitalOcean DNS</a> pour savoir comment les ajouter.</p>\n\n<ul>\n<li>Un enregistrement A avec <code><span class=\"highlight\">your_domain</span></code> pointant sur l'adresse IP publique de votre serveur.</li>\n<li>Un enregistrement A avec <code>www.<span class=\"highlight\">your_domain</span></code>​​​​​​ pointant à l'adresse IP publique de votre serveur.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"Étape-1-—-installation-et-configuration-d-39-elasticsearch\">Étape 1 — Installation et configuration d'Elasticsearch</h2>\n\n<p>Les composants Elasticsearch ne sont pas disponibles dans les dépôts de paquets par défaut d'Ubuntu. Ils peuvent cependant être installés avec APT après avoir ajouté la liste des sources des paquets d'Elastic.</p>\n\n<p>Tous les paquets sont signés avec la clé de signature Elasticsearch afin de protéger votre système contre l'usurpation de paquets. Les paquets qui ont été authentifiés à l'aide de la clé seront considérés comme fiables par votre gestionnaire de paquets. Dans cette étape, vous allez importer la clé GPG publique d'Elasticsearch et ajouter la liste des sources du paquet Elastic afin d'installer Elasticsearch.</p>\n\n<p>Pour commencer, utilisez cURL, l'outil de ligne de commande pour le transfert de données avec URL pour importer la clé GPG publique d'Elasticsearch dans APT. Notez que nous utilisons les arguments -fsSL pour faire taire toute progression et toute erreur éventuelle (sauf en cas de panne de serveur) et pour permettre à cURL d'effectuer une requête sur un nouvel emplacement s'il est redirigé. Transmettez la sortie de la commande cURL au programme apt-key qui ajoute la clé GPG publique à l'APT.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n</li></ul></code></pre>\n<p>Ensuite, ajoutez la liste des sources Elastic au répertoire <code>sources.list.d</code> où APT cherchera de nouvelles sources :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n</li></ul></code></pre>\n<p>Ensuite, mettez à jour vos listes de paquets afin qu'APT puisse lire la nouvelle source Elastic :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Installez ensuite Elasticsearch avec cette commande :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install elasticsearch\n</li></ul></code></pre>\n<p>Elasticsearch est maintenant installé et prêt à être configuré. Utilisez votre éditeur de texte préféré pour modifier le fichier de configuration principal d'Elasticsearch, <code>elasticsearch.yml</code>. Ici, nous utiliserons <code>nano</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/elasticsearch/elasticsearch.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Note :</strong> Le fichier de configuration d'Elasticsearch est au format YAML, ce qui signifie que nous devons conserver le format d'indentation. Veillez à ne pas ajouter d'espaces supplémentaires lorsque vous modifiez ce fichier.<br></span></p>\n\n<p>Le site <code>elasticsearch.yml</code> fournit des options de configuration pour votre/vos cluster, nœud, chemins, mémoire, réseau, découverte et passerelle.  La plupart de ces options sont préconfigurées dans le fichier, mais vous pouvez les modifier en fonction de vos besoins. Pour les besoins de notre démonstration d'une configuration à serveur unique, nous n'ajusterons les paramètres que pour l'hôte du réseau.</p>\n\n<p>Elasticsearch écoute le trafic de partout sur le port <code>9200</code>. Vous voudrez limiter l'accès extérieur à votre instance Elasticsearch pour empêcher les personnes extérieures de lire vos données ou de fermer votre cluster Elasticsearch par le biais de son <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">API REST</a>.  Pour restreindre l'accès et donc accroître la sécurité, trouvez la ligne qui précise <code>network.host</code>, décommentez-la et remplacez sa valeur par<code>localhost</code>comme ceci :</p>\n<div class=\"code-label \" title=\"/etc/elasticsearch/elasticsearch.yml\">/etc/elasticsearch/elasticsearch.yml</div><pre class=\"code-pre \"><code>. . .\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: <span class=\"highlight\">localhost</span>\n. . .\n</code></pre>\n<p>Nous avons spécifié <code>localhost</code> de sorte qu'Elasticsearch écoute sur toutes les interfaces et les IP liés.  Si vous souhaitez qu'il n'écoute que sur une interface spécifique, vous pouvez spécifier son IP au lieu de <code>localhost</code>.  Sauvegardez et fermez <code>elasticsearch.yml</code>. Si vous utilisez <code>nano</code>vous pouvez le faire en appuyant sur <code>CTRL+X</code>, suivi de <code>Y</code> et ensuite <code>ENTRÉE</code>. </p>\n\n<p>Ce sont les paramètres minimums avec lesquels vous pouvez commencer pour utiliser Elasticsearch. Vous pouvez maintenant lancer Elasticsearch pour la première fois.</p>\n\n<p>Démarrez le service Elasticsearch avec <code>systemctl</code>. Donnez à Elasticsearch quelques instants pour démarrer. Dans le cas contraire, vous risquez d'obtenir des erreurs en ne pouvant pas vous connecter.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start elasticsearch\n</li></ul></code></pre>\n<p>Ensuite, exécutez la commande suivante pour permettre à Elasticsearch de démarrer à chaque fois que votre serveur démarre :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable elasticsearch\n</li></ul></code></pre>\n<p>Vous pouvez tester si votre service Elasticsearch fonctionne en envoyant une requête HTTP :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -X GET \"localhost:9200\"\n</li></ul></code></pre>\n<p>Vous verrez une réponse montrant quelques informations de base sur votre nœud local, similaire à celle-ci :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\n  \"name\" : \"Elasticsearch\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"qqhFHPigQ9e2lk-a7AvLNQ\",\n  \"version\" : {\n    \"number\" : \"7.7.1\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"deb\",\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\",\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.5.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n\n</code></pre>\n<p>Maintenant qu'Elasticsearch est opérationnel, installons Kibana, le prochain composant de l'Elastic Stack.</p>\n\n<h2 id=\"Étape-2-—-installation-et-configuration-du-tableau-de-bord-kibana\">Étape 2 — Installation et configuration du tableau de bord Kibana</h2>\n\n<p>Selon la <a href=\"https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html\">documentation officielle</a>, vous ne devez installer Kibana qu'après avoir installé Elasticsearch. L'installation dans cet ordre garantit que les composants dont dépend chaque produit sont correctement en place.</p>\n\n<p>Comme vous avez déjà ajouté le paquet source Elastic dans l'étape précédente, vous pouvez simplement installer les composants restants de l'Elastic Stack en utilisant <code>apt</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install kibana\n</li></ul></code></pre>\n<p>Ensuite, activez et démarrez le service Kibana :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable kibana\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl start kibana\n</li></ul></code></pre>\n<p>Étant donné que Kibana est configuré pour n'écouter que sur <code>localhost</code>, nous devons mettre en place un <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">proxy inverse</a> pour permettre un accès externe à celui-ci. Nous utiliserons pour cela Nginx, qui devrait déjà être installé sur votre serveur.</p>\n\n<p>Tout d'abord, utilisez la commande <code>openssl</code> pour créer un utilisateur administratif Kibana que vous utiliserez pour accéder à l'interface web de Kibana. À titre d'exemple, nous nommerons ce compte <code><span class=\"highlight\">kibanaadmin</span></code>, mais pour assurer une plus grande sécurité, nous vous recommandons de choisir un nom non standard pour votre utilisateur, un nom difficile à deviner.</p>\n\n<p>La commande suivante créera l'utilisateur et le mot de passe administratifs de Kibana, et les stockera dans le fichier <code>htpasswd.users</code>. Vous allez configurer Nginx pour qu'il vous demande ce nom d'utilisateur et ce mot de passe, puis lire ce fichier momentanément :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"<span class=\"highlight\">kibanaadmin</span>:`openssl passwd -apr1`\" | sudo tee -a /etc/nginx/htpasswd.users\n</li></ul></code></pre>\n<p>Entrez et confirmez un mot de passe à l'invite. Rappelez-vous ou prenez note de ce login, car vous en aurez besoin pour accéder à l'interface web de Kibana.</p>\n\n<p>Ensuite, nous allons créer un fichier de bloc serveur Nginx. À titre d'exemple, nous appellerons ce fichier <code><span class=\"highlight\">your_domain</span></code>, bien que vous puissiez trouver utile de donner au vôtre un nom plus descriptif. Par exemple, si vous avez un FQDN et des enregistrements DNS configurés pour ce serveur, vous pourriez nommer ce fichier en fonction de votre FQDN.</p>\n\n<p>En utilisant nano ou votre éditeur de texte préféré, créez le fichier de bloc serveur Nginx :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Ajoutez le bloc de code suivant dans le fichier, en veillant à mettre à jour <code><span class=\"highlight\">your_domain</span></code> pour qu'il corresponde au FQDN ou à l'adresse IP publique de votre serveur. Ce code configure Nginx pour diriger le trafic HTTP de votre serveur vers l'application Kibana, qui est à l'écoute sur <code>localhost:5601</code>. De plus, il configure Nginx pour qu'il lise le fichier <code>htpasswd.users</code> et exige une authentification de base.</p>\n\n<p>Notez que si vous avez suivi le <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">tutoriel Nginx</a> jusqu'à la fin, vous avez peut-être déjà créé ce fichier et y avez peut-être ajouté du contenu. Dans ce cas, supprimez tout le contenu existant dans le fichier avant d'ajouter ce qui suit :</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/your_domain\">/etc/nginx/sites-available/your_domain</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n\n    server_name <span class=\"highlight\">your_domain</span>;\n\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/htpasswd.users;\n\n    location / {\n        proxy_pass http://localhost:5601;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n</code></pre>\n<p>Lorsque vous avez terminé, sauvegardez et fermez le fichier.</p>\n\n<p>Ensuite, activez la nouvelle configuration en créant un lien symbolique vers le répertoire <code>sites-enabled</code>. Si vous avez déjà créé un fichier de bloc de serveur avec le même nom dans les pré-requis Nginx, vous n'avez pas besoin d'exécuter cette commande :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Ensuite, vérifiez que la configuration ne contient pas d'erreurs de syntaxe :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Si des erreurs sont signalées dans votre sortie, revenez en arrière et vérifiez que le contenu que vous avez placé dans votre fichier de configuration a été ajouté correctement. Une fois que vous voyez <code>syntax is ok</code> dans la sortie, continuez et redémarrez le service Nginx :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Si vous avez suivi le guide de configuration initiale du serveur, vous devriez disposer d'un pare-feu UFW activé. Pour permettre les connexions à Nginx, nous pouvons ajuster les règles en tapant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 'Nginx Full'\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Note :</strong> si vous avez suivi le tutoriel Nginx, vous avez peut-être créé une règle UFW permettant au profil <code>HTTP de Nginx</code> de passer à travers le pare-feu. Comme le profil <code>Nginx Full</code> autorise le trafic HTTP et HTTPS à travers le pare-feu, vous pouvez supprimer en toute sécurité la règle que vous avez créée dans le tutoriel des prérequis. Faites-le avec la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw delete allow 'Nginx HTTP'\n</li></ul></code></pre>\n<p></p></span>\n\n<p>Kibana est désormais accessible via votre FQDN ou l'adresse IP publique de votre serveur Elastic Stack. Vous pouvez consulter la page d'état du serveur Kibana en vous rendant à l'adresse suivante et en saisissant vos identifiants de connexion lorsque vous y êtes invité :</p>\n<pre class=\"code-pre \"><code>http://<span class=\"highlight\">your_domain</span>/status\n</code></pre>\n<p>Cette page d'état affiche des informations sur l'utilisation des ressources du serveur et énumère les plugins installés.</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png\" alt=\"Page d'état |Kibana\"></p>\n\n<p><span class='note'><strong>Note</strong> : comme mentionné dans la section « Conditions préalables », il est recommandé d'activer SSL/TLS sur votre serveur. Vous pouvez suivre <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">le guide Let&rsquo;s Encrypt</a> dès maintenant pour obtenir un certificat SSL gratuit pour Nginx sur Ubuntu 20.04. Après avoir obtenu vos certificats SSL/TLS, vous pouvez revenir et compléter ce tutoriel.<br></span></p>\n\n<p>Maintenant que le tableau de bord de Kibana est configuré, installons le composant suivant : Logstash.</p>\n\n<h2 id=\"Étape-3-—-installation-et-configuration-de-logstash\">Étape 3 — Installation et configuration de Logstash</h2>\n\n<p>Bien qu'il soit possible pour Beats d'envoyer des données directement à la base de données Elasticsearch, il est courant d'utiliser Logstash pour traiter les données. Cela vous donnera plus de flexibilité pour collecter des données provenant de différentes sources, les transformer en un format commun et les exporter vers une autre base de données.</p>\n\n<p>Installez Logstash avec cette commande :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install logstash\n</li></ul></code></pre>\n<p>Après avoir installé Logstash, vous pouvez passer à la configuration. Les fichiers de configuration de Logstash se trouvent dans le répertoire <code>/etc/logstash/conf.d</code>. Pour plus d'informations sur la syntaxe de configuration, vous pouvez consulter la <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\">référence de configuration</a> fournie par Elastic. Lorsque vous configurez le fichier, il est utile de considérer Logstash comme un pipeline qui prend les données à une extrémité, les traite d'une manière ou d'une autre et les envoie à leur destination (dans ce cas, la destination est Elasticsearch). Un pipeline Logstash comporte deux éléments obligatoires, <code>input</code> (l'entrée) et <code>output</code> (la sortie), et un élément optionnel, <code>filter</code> (le filtre). Les plugins d'entrée consomment les données d'une source, les plugins de filtrage traitent les données, et les plugins de sortie écrivent les données vers une destination.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png\" alt=\"pipeline Logstash\"></p>\n\n<p>Créez un fichier de configuration appelé <code>02-beats-input.conf</code> où vous configurerez votre entrée Filebeat :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/02-beats-input.conf\n</li></ul></code></pre>\n<p>Insérez la configuration <code>input</code> suivante. Elle spécifie une entrée de <code>beats</code> qui écoutera sur le port TCP <code>5044</code>.</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/02-beats-input.conf\">/etc/logstash/conf.d/02-beats-input.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">input {\n  beats {\n    port =&gt; 5044\n  }\n}\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>Ensuite, créez un fichier de configuration appelé <code>30-elasticsearch-output.conf</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf\n</li></ul></code></pre>\n<p>Insérez la configuration <code>output</code> suivante. Globalement, cette sortie configure Logstash pour stocker les données des Beats dans Elasticsearch, qui tourne sur <code>localhost:9200</code>, dans un index nommé en fonction du Beat utilisé. Le Beat utilisé dans ce tutoriel est Filebeat :</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/30-elasticsearch-output.conf\">/etc/logstash/conf.d/30-elasticsearch-output.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">output {\n  if [@metadata][pipeline] {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    pipeline =&gt; \"%{[@metadata][pipeline]}\"\n    }\n  } else {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n\n\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>Testez votre configuration Logstash avec cette commande :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t\n</li></ul></code></pre>\n<p>S'il n'y a pas d'erreurs de syntaxe, votre sortie affichera <code>Config Validation Result: OK. Exiting Logstash</code> après quelques secondes. Si cela n'apparaît pas dans votre sortie, vérifiez les erreurs constatées dans votre sortie et mettez à jour votre configuration pour les corriger. Notez que vous recevrez des avertissements de la part d'OpenJDK, mais ils ne devraient pas causer de problèmes et peuvent être ignorés.</p>\n\n<p>Si votre test de configuration est réussi, démarrez et activez Logstash pour implémenter les changements de configuration :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start logstash\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable logstash\n</li></ul></code></pre>\n<p>Maintenant que Logstash fonctionne correctement et est entièrement configuré, installons Filebeat.</p>\n\n<h2 id=\"Étape-4-—-installation-et-configuration-de-filebeat\">Étape 4 — Installation et configuration de Filebeat</h2>\n\n<p>L'Elastic Stack utilise plusieurs expéditeurs de données légers appelés Beats pour collecter des données de diverses sources et les transporter vers Logstash ou Elasticsearch. Voici les Beats qui sont actuellement disponibles chez Elastic :</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>  : recueille et expédie les fichiers journaux.</li>\n<li><a href=\"https://www.elastic.co/products/beats/metricbeat\">Metricbeat</a> : collecte les métriques de vos systèmes et services.</li>\n<li><a href=\"https://www.elastic.co/products/beats/packetbeat\">Packetbeat</a> : recueille et analyse les données du réseau.</li>\n<li><a href=\"https://www.elastic.co/products/beats/winlogbeat\">Winlogbeat</a> : collecte les journaux des événements Windows.</li>\n<li><a href=\"https://www.elastic.co/products/beats/auditbeat\">Auditbeat</a> : collecte les données du framework de vérification Linux et surveille l'intégrité des fichiers.</li>\n<li><a href=\"https://www.elastic.co/products/beats/heartbeat\">Heartbeat</a> : surveille activement la disponibilité des services.</li>\n</ul>\n\n<p>Dans ce tutoriel, nous utiliserons Filebeat pour transmettre les journaux locaux à notre Elastic Stack.</p>\n\n<p>Installez Filebeat en utilisant <code>apt</code>  :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install filebeat\n</li></ul></code></pre>\n<p>Ensuite, configurez Filebeat pour vous connecter à Logstash. Ici, nous allons modifier l'exemple de fichier de configuration fourni avec Filebeat.</p>\n\n<p>Ouvrez le fichier de configuration Filebeat :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/filebeat/filebeat.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Note :</strong> comme celui d'Elasticsearch, le fichier de configuration de Filebeat est au format YAML. Cela signifie qu'une indentation correcte est cruciale, aussi veillez à utiliser le même nombre d'espaces que ceux qui sont indiqués dans ces instructions.<br></span></p>\n\n<p>Filebeat prend en charge de nombreuses sorties, mais vous n'enverrez généralement les événements que directement à Elasticsearch ou à Logstash pour un traitement supplémentaire. Dans ce tutoriel, nous utiliserons Logstash pour effectuer des traitements supplémentaires sur les données collectées par Filebeat. Filebeat n'aura pas besoin d'envoyer de données directement à Elasticsearch. Désactivons donc cette sortie. Pour ce faire, trouvez la section <code>output.elasticsearch</code> et commentez les lignes suivantes en les faisant précéder d'un <code>#</code> :</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>...\n<span class=\"highlight\">#</span>output.elasticsearch:\n  # Array of hosts to connect to.\n  <span class=\"highlight\">#</span>hosts: [\"localhost:9200\"]\n...\n</code></pre>\n<p>Ensuite, configurez la section <code>output.logstash</code>. Décommentez les lignes <code>output.logstash:</code> et <code>hosts: [\"localhost:5044\"]</code> en supprimant le <code>#</code>. Cela permettra de configurer Filebeat pour qu'il se connecte à Logstash sur votre serveur Elastic Stack au port <code>5044</code>, le port pour lequel nous avons spécifié une entrée Logstash plus tôt :</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>output.logstash:\n  # The Logstash hosts\n  hosts: [\"localhost:5044\"]\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>La fonctionnalité de Filebeat peut être étendue avec <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-modules.html\">des modules Filebeat</a>. Dans ce tutoriel, nous utiliserons le module <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-module-system.html\">system</a>, qui collecte et analyse les journaux créés par le service de journalisation du système des distributions Linux courantes.</p>\n\n<p>Activons-le :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules enable system\n</li></ul></code></pre>\n<p>Vous pouvez consulter la liste des modules activés et désactivés en exécutant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules list\n</li></ul></code></pre>\n<p>Vous verrez une liste semblable à celle qui suit :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enabled:\nsystem\n\nDisabled:\napache2\nauditd\nelasticsearch\nicinga\niis\nkafka\nkibana\nlogstash\nmongodb\nmysql\nnginx\nosquery\npostgresql\nredis\ntraefik\n...\n</code></pre>\n<p>Par défaut, Filebeat est configuré pour utiliser les itinéraires par défaut pour le syslog et les journaux d'autorisation. Dans le cas de ce tutoriel, vous n'avez pas besoin de modifier quoi que ce soit dans la configuration. Vous pouvez voir les paramètres du module dans le fichier de configuration <code>/etc/filebeat/modules.d/system.yml</code>.</p>\n\n<p>Ensuite, nous devons mettre en place les pipelines d'ingestion de Filebeat, qui analysent les données du journal avant de les envoyer à Elasticsearc via Logstash. Pour charger le pipeline d'ingestion pour le module system, entrez la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --pipelines --modules system\n</li></ul></code></pre>\n<p>Ensuite, chargez le modèle d'index dans Elasticsearch. Un <a href=\"https://www.elastic.co/blog/what-is-an-elasticsearch-index\"><em>index Elasticsearch</em></a> est une collection de documents qui présentent des caractéristiques similaires. Les index sont identifiés par un nom, qui est utilisé pour se référer à l'index lors de l'exécution de diverses opérations en son sein. Le modèle d'index sera automatiquement appliqué lors de la création d'un nouvel index.</p>\n\n<p>Pour charger le modèle, utilisez la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=[\"localhost:9200\"]'\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Index setup finished.\n</code></pre>\n<p>Filebeat contient des exemples de tableaux de bord Kibana qui vous permettent de visualiser les données Filebeat dans Kibana. Avant de pouvoir utiliser les tableaux de bord, vous devez créer le modèle d'index et charger les tableaux de bord dans Kibana.</p>\n\n<p>Lors du chargement des tableaux de bord, Filebeat se connecte à Elasticsearch pour vérifier les informations de version. Pour charger des tableaux de bord lorsque Logstash est activé, vous devez désactiver la sortie Logstash et activer la sortie Elasticsearch :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601\n</li></ul></code></pre>\n<p>Vous devriez recevoir un résultat qui ressemble à ça :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Overwriting ILM policy is disabled. Set `setup.ilm.overwrite:true` for enabling.\n\nIndex setup finished.\nLoading dashboards (Kibana must be running and reachable)\nLoaded dashboards\nSetting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.\nSee more: https://www.elastic.co/guide/en/elastic-stack-overview/current/xpack-ml.html\nLoaded machine learning job configurations\nLoaded Ingest pipelines\n</code></pre>\n<p>Vous pouvez maintenant démarrer et activer Filebeat :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start filebeat\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable filebeat\n</li></ul></code></pre>\n<p>Si vous avez correctement configuré votre Elastic Stack, Filebeat commencera à envoyer votre syslog et vos journaux d'autorisation à Logstash, qui chargera ensuite ces données dans Elasticsearch.</p>\n\n<p>Pour vérifier que Elasticsearch reçoit bel et bien ces données, interrogez l'index Filebeat avec cette commande :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'\n</li></ul></code></pre>\n<p>Vous devriez recevoir un résultat qui ressemble à ça :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\n{\n{\n  \"took\" : 4,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 2,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 4040,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"filebeat-7.7.1-2020.06.04\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"FiZLgXIB75I8Lxc9ewIH\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"cloud\" : {\n            \"provider\" : \"digitalocean\",\n            \"instance\" : {\n              \"id\" : \"194878454\"\n            },\n            \"region\" : \"nyc1\"\n          },\n          \"@timestamp\" : \"2020-06-04T21:45:03.995Z\",\n          \"agent\" : {\n            \"version\" : \"7.7.1\",\n            \"type\" : \"filebeat\",\n            \"ephemeral_id\" : \"cbcefb9a-8d15-4ce4-bad4-962a80371ec0\",\n            \"hostname\" : \"june-ubuntu-20-04-elasticstack\",\n            \"id\" : \"fbd5956f-12ab-4227-9782-f8f1a19b7f32\"\n          },\n\n\n...\n</code></pre>\n<p>Si votre sortie affiche 0 résultat total, cela signifie qu'Elasticsearch ne charge aucun journal sous l'index que vous avez recherché, et vous devrez revoir votre configuration pour détecter les erreurs. Si vous avez obtenu la sortie attendue, passez à l'étape suivante, dans laquelle nous verrons comment naviguer dans certains des tableaux de bord de Kibana.</p>\n\n<h2 id=\"Étape-5-—-exploration-des-tableaux-de-bord-kibana\">Étape 5 — Exploration des tableaux de bord Kibana</h2>\n\n<p>Revenons à l'interface web Kibana que nous avons installée précédemment.</p>\n\n<p>Dans un navigateur web, rendez-vous à la FQDN ou à l'adresse IP publique de votre serveur Elastic Stack. Si votre session a été interrompue, vous devrez y rentrer en entrant les identifiants que vous avez définis lors de l'étape 2. Une fois connecté, vous devriez voir la page d'accueil de Kibana :</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg\" alt=\"Page d'accueil de Kibana\"></p>\n\n<p>Cliquez sur le lien <strong>Discover</strong> (Découvrir) dans la barre de navigation de gauche (vous devrez peut-être cliquer sur l'icône <strong>Expand</strong> (Développer) tout en bas à gauche pour voir les éléments du menu de navigation). Sur la page <strong>Discover</strong> (Découvrir), sélectionnez le modèle d'index <strong>filebeat-</strong>* prédéfini pour voir les données Filebeat. Par défaut, cela vous montrera toutes les données du journal au cours des 15 dernières minutes. Vous verrez un histogramme avec les événements du journal, et quelques messages du journal ci-dessous :</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg\" alt=\"page Discover\"></p>\n\n<p>Ici, vous pouvez rechercher des journaux et les parcourir, et également personnaliser votre tableau de bord. A ce stade, cependant, il n'y aura pas grand chose dedans, parce que vous ne recueillez que les syslogs de votre serveur Elastic Stack.</p>\n\n<p>Utilisez le panneau de gauche pour naviguer jusqu'à la page <strong>Dashboard</strong> (Tableau de bord) et rechercher les tableaux de bord <strong>Filebeat System</strong>. Une fois sur la page, vous pouvez sélectionner les exemples de tableaux de bord fournis avec le module <code>system</code> de Filebeat.</p>\n\n<p>Par exemple, vous pouvez consulter des statistiques détaillées en fonction de vos messages syslog :</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg\" alt=\"Tableau de bord Syslog\"></p>\n\n<p>Vous pouvez également voir quels utilisateurs ont utilisé la commande <code>sudo</code> et à quel moment :</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg\" alt=\"Tableau de bord Sudo\"></p>\n\n<p>Kibana offre de nombreuses autres fonctionnalités, telles que le graphisme et le filtrage : n'hésitez pas à les explorer.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans ce tutoriel, vous avez appris comment installer et configurer l'Elastic Stack pour collecter et analyser les journaux du système. N'oubliez pas que vous pouvez envoyer à peu près n'importe quel type de journal ou de données indexées à Logstash en utilisant <a href=\"https://www.elastic.co/products/beats\">Beats</a>, mais que les données deviennent encore plus utiles si elles sont analysées et structurées avec un filtre Logstash, car cela les transforme en un format cohérent qui peut être lu facilement par Elasticsearch.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:51 +0000","feedId":8037,"bgimg":"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png","linkMd5":"14350bffdb7155c0aadbf754426bd819","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","destWidth":1833,"destHeight":948,"sourceBytes":40417,"destBytes":48810,"author":"Erin Glass","articleImgCdnMap":{"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn82@2020_2/2020/08/31/07-48-31-557_41a6f5cccef041e1.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn1@2020_3/2020/08/31/07-48-32-396_0638f11900b9faf4.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn37@2020_3/2020/08/31/07-48-33-221_1dfbe5e28e76fefb.webp","http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn10@2020_4/2020/08/31/07-48-32-522_c0c2011e332e864d.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn5@2020_6/2020/08/31/07-48-32-458_2cfaecfed9ac513b.webp"},"publishedOrCreatedDate":1598860106977},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"How To Use Traefik as a Reverse Proxy for Docker Containers on Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-use-traefik-as-a-reverse-proxy-for-docker-containers-on-ubuntu-20-04","description":"<p><em>The author selected <a href=\"https://www.brightfunds.org/organizations/girls-who-code\">Girls Who Code</a> to receive a donation as part of the <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> program.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://www.docker.com\">Docker</a> can be an efficient way to run web applications in production, but you may want to run multiple applications on the same Docker host. In this situation, you&rsquo;ll need to set up a reverse proxy since you only want to expose ports <code>80</code> and <code>443</code> to the rest of the world.</p>\n\n<p><a href=\"https://traefik.io\">Traefik</a> is a Docker-aware reverse proxy that includes its own monitoring dashboard. In this tutorial, you&rsquo;ll use Traefik to route requests to two different web application containers: a <a href=\"http://wordpress.org\">Wordpress</a> container and an <a href=\"https://www.adminer.org/\">Adminer</a> container, each talking to a <a href=\"https://www.mysql.com/\">MySQL</a> database. You&rsquo;ll configure Traefik to serve everything over HTTPS using <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>.</p>\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\n<p>To follow this tutorial, you will need the following:</p>\n\n<ul>\n<li>One Ubuntu 20.04 server set up by following <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">the Ubuntu 20.04 initial server setup guide</a>, including a sudo non-root user and a firewall.</li>\n<li>Docker installed on your server, which you can do by following <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-20-04\">How to Install and Use Docker on Ubuntu 20.04</a>.</li>\n<li>Docker Compose installed with the instructions from <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-ubuntu-20-04\">How to Install Docker Compose on Ubuntu 20.04</a>.</li>\n<li>A domain and three A records,  <code>db-admin.<span class=\"highlight\">your_domain</span></code>, <code>blog.<span class=\"highlight\">your_domain</span></code> and <code>monitor.<span class=\"highlight\">your_domain</span></code>. Each should point to the IP address of your server.  You can <a href=\"https://www.digitalocean.com/docs/networking/dns/\">learn how to point domains to DigitalOcean Droplets by reading through DigitalOcean&rsquo;s Domains and DNS documentation</a>. Throughout this tutorial, substitute your domain for <code><span class=\"highlight\">your_domain</span></code> in the configuration files and examples.</li>\n</ul>\n\n<h2 id=\"step-1-—-configuring-and-running-traefik\">Step 1 — Configuring and Running Traefik</h2>\n\n<p>The Traefik project has an <a href=\"https://hub.docker.com/_/traefik\">official Docker image</a>, so we will use that to run Traefik in a Docker container.</p>\n\n<p>But before we get our Traefik container up and running, we need to create a configuration file and set up an encrypted password so we can access the monitoring dashboard.</p>\n\n<p>We&rsquo;ll use the <code>htpasswd</code> utility to create this encrypted password. First, install the utility, which is included in the <code>apache2-utils</code> package:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt-get install apache2-utils\n</li></ul></code></pre>\n<p>Then generate the password with <code>htpasswd</code>. Substitute <code><span class=\"highlight\">secure_password</span></code> with the password you&rsquo;d like to use for the Traefik admin user:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">htpasswd -nb admin <span class=\"highlight\">secure_password</span>\n</li></ul></code></pre>\n<p>The output from the program will look like this:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>admin:<span class=\"highlight\">$apr1$ruca84Hq$mbjdMZBAG.KWn7vfN/SNK/</span>\n</code></pre>\n<p>You&rsquo;ll use your unique output in the Traefik configuration file to set up HTTP Basic Authentication for the Traefik health check and monitoring dashboard. Copy your entire output line so you can paste it later. Do not use the example output.</p>\n\n<p>To configure the Traefik server, we&rsquo;ll create a new configuration file called <code>traefik.toml</code> using the TOML format. <a href=\"https://github.com/toml-lang/toml\">TOML</a> is a configuration language similar to INI files, but standardized. <a href=\"https://docs.traefik.io/providers/overview/\">This file lets us configure the Traefik server and various integrations</a>, or <code>providers</code>, that we want to use. In this tutorial, we will use three of Traefik&rsquo;s available providers: <code>api</code>, <code>docker</code>, and <code>acme</code>. The last of these, <code>acme</code> supports TLS certificates using Let&rsquo;s Encrypt.</p>\n\n<p>Open up your new file in <code>nano</code> or your favorite text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano traefik.toml\n</li></ul></code></pre>\n<p>First, add two named entry points, <code>http</code> and <code>https</code>, which all backends will have access to by default:</p>\n<div class=\"code-label \" title=\"traefik.toml\">traefik.toml</div><pre class=\"code-pre \"><code class=\"code-highlight language-toml\">defaultEntryPoints = [\"http\", \"https\"]\n</code></pre>\n<p>We&rsquo;ll configure the <code>http</code> and <code>https</code> entry points later in this file.</p>\n\n<p>Next, configure the <code>api</code> provider, which gives you access to a dashboard interface. This is where you&rsquo;ll paste the output from the <code>htpasswd</code> command:</p>\n<div class=\"code-label \" title=\"traefik.toml\">traefik.toml</div><pre class=\"code-pre \"><code class=\"code-highlight language-toml\">...\n[entryPoints]\n  [entryPoints.dashboard]\n    address = \":8080\"\n    [entryPoints.dashboard.auth]\n      [entryPoints.dashboard.auth.basic]\n        users = [\"<span class=\"highlight\">admin:your_encrypted_password</span>\"]\n\n[api]\nentrypoint=\"dashboard\"\n</code></pre>\n<p>The dashboard is a separate web application that will run within the Traefik container.  We set the dashboard to run on port <code>8080</code>.</p>\n\n<p>The <code>entrypoints.dashboard</code> section configures how we&rsquo;ll be connecting with the <code>api</code> provider, and the <code>entrypoints.dashboard.auth.basic</code> section configures HTTP Basic Authentication for the dashboard. Use the output from the <code>htpasswd</code> command you just ran for the value of the <code>users</code> entry. You could specify additional logins by separating them with commas.</p>\n\n<p>We&rsquo;ve defined our first <code>entryPoint</code>, but we&rsquo;ll need to define others for standard HTTP and HTTPS communication that isn&rsquo;t directed towards the <code>api</code> provider. The <code>entryPoints</code> section configures the addresses that Traefik and the proxied containers can listen on. Add these lines to the file underneath the <code>entryPoints</code> heading:</p>\n<div class=\"code-label \" title=\"traefik.toml\">traefik.toml</div><pre class=\"code-pre \"><code class=\"code-highlight language-toml\">...\n  [entryPoints.http]\n    address = \":80\"\n      [entryPoints.http.redirect]\n        entryPoint = \"https\"\n  [entryPoints.https]\n    address = \":443\"\n      [entryPoints.https.tls]\n...\n</code></pre>\n<p>The <code>http</code> entry point handles port <code>80</code>, while the  <code>https</code> entry point uses port <code>443</code> for TLS/SSL. We automatically redirect all of the traffic on port <code>80</code> to the <code>https</code> entry point to force secure connections for all requests.</p>\n\n<p>Next, add this section to configure Let&rsquo;s Encrypt certificate support for Traefik:</p>\n<div class=\"code-label \" title=\"traefik.toml\">traefik.toml</div><pre class=\"code-pre \"><code class=\"code-highlight language-toml\">...\n[acme]\nemail = \"<span class=\"highlight\">your_email@your_domain</span>\"\nstorage = \"acme.json\"\nentryPoint = \"https\"\nonHostRule = true\n  [acme.httpChallenge]\n  entryPoint = \"http\"\n</code></pre>\n<p>This section is called <code>acme</code> because <a href=\"https://github.com/ietf-wg-acme/acme/\">ACME</a> is the name of the protocol used to communicate with Let&rsquo;s Encrypt to manage certificates. The Let&rsquo;s Encrypt service requires registration with a valid email address, so in order to have Traefik generate certificates for our hosts, set the <code>email</code> key to your email address. We then specify that we will store the information that we will receive from Let&rsquo;s Encrypt in a JSON file called <code>acme.json</code>. The <code>entryPoint</code> key needs to point to the entry point handling port <code>443</code>, which in our case is the <code>https</code> entry point.</p>\n\n<p>The key <code>onHostRule</code> dictates how Traefik should go about generating certificates. We want to fetch our certificates as soon as our containers with specified hostnames are created, and that&rsquo;s what the <code>onHostRule</code> setting will do.</p>\n\n<p>The <code>acme.httpChallenge</code> section allows us to specify how Let&rsquo;s Encrypt can verify that the certificate should be generated. We&rsquo;re configuring it to serve a file as part of the challenge through the <code>http</code> entrypoint.</p>\n\n<p>Finally, let&rsquo;s configure the <code>docker</code> provider by adding these lines to the file:</p>\n<div class=\"code-label \" title=\"traefik.toml\">traefik.toml</div><pre class=\"code-pre \"><code class=\"code-highlight language-toml\">...\n[docker]\ndomain = \"<span class=\"highlight\">your_domain</span>\"\nwatch = true\nnetwork = \"web\"\n</code></pre>\n<p>The <code>docker</code> provider enables Traefik to act as a proxy in front of Docker containers. We&rsquo;ve configured the provider to <code>watch</code> for new containers on the <code>web</code> network, which we&rsquo;ll create soon, and expose them as subdomains of <code><span class=\"highlight\">your_domain</span></code>.</p>\n\n<p>At this point, <code>traefik.toml</code> should have the following contents:</p>\n<div class=\"code-label \" title=\"traefik.toml\">traefik.toml</div><pre class=\"code-pre \"><code class=\"code-highlight language-toml\">defaultEntryPoints = [\"http\", \"https\"]\n\n[entryPoints]\n  [entryPoints.dashboard]\n    address = \":8080\"\n    [entryPoints.dashboard.auth]\n      [entryPoints.dashboard.auth.basic]\n        users = [\"<span class=\"highlight\">admin:your_encrypted_password</span>\"]\n  [entryPoints.http]\n    address = \":80\"\n      [entryPoints.http.redirect]\n        entryPoint = \"https\"\n  [entryPoints.https]\n    address = \":443\"\n      [entryPoints.https.tls]\n\n[api]\nentrypoint=\"dashboard\"\n\n[acme]\nemail = \"<span class=\"highlight\">your_email@your_domain</span>\"\nstorage = \"acme.json\"\nentryPoint = \"https\"\nonHostRule = true\n  [acme.httpChallenge]\n  entryPoint = \"http\"\n\n[docker]\ndomain = \"<span class=\"highlight\">your_domain</span>\"\nwatch = true\nnetwork = \"web\"\n</code></pre>\n<p>Save the file and exit the editor.  With these configurations in place, we can initialize Traefik.</p>\n\n<h2 id=\"step-2-mdash-running-the-traefik-container\">Step 2 — Running the Traefik Container</h2>\n\n<p>Next, create a Docker network for the proxy to share with containers. The Docker network is necessary so that we can use it with applications that are run using Docker Compose. Let&rsquo;s call this network <code>web</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker network create <span class=\"highlight\">web</span>\n</li></ul></code></pre>\n<p>When the Traefik container starts, we will add it to this network. Then we can add additional containers to this network later for Traefik to proxy to.</p>\n\n<p>Next, create an empty file that will hold our Let&rsquo;s Encrypt information. We&rsquo;ll share this into the container so Traefik can use it:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">touch acme.json\n</li></ul></code></pre>\n<p>Traefik will only be able to use this file if the root user inside of the container has unique read and write access to it. To do this, lock down the permissions on <code>acme.json</code> so that only the owner of the file has read and write permission:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod 600 acme.json\n</li></ul></code></pre>\n<p>Once the file gets passed to Docker, the owner will automatically change to the <strong>root</strong> user inside the container.</p>\n\n<p>Finally,  create the Traefik container with this command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker run -d \\\n</li><li class=\"line\" data-prefix=\"$\">  -v /var/run/docker.sock:/var/run/docker.sock \\\n</li><li class=\"line\" data-prefix=\"$\">  -v $PWD/traefik.toml:/traefik.toml \\\n</li><li class=\"line\" data-prefix=\"$\">  -v $PWD/acme.json:/acme.json \\\n</li><li class=\"line\" data-prefix=\"$\">  -p 80:80 \\\n</li><li class=\"line\" data-prefix=\"$\">  -p 443:443 \\\n</li><li class=\"line\" data-prefix=\"$\">  -l traefik.frontend.rule=Host:monitor.<span class=\"highlight\">your_domain</span> \\\n</li><li class=\"line\" data-prefix=\"$\">  -l traefik.port=8080 \\\n</li><li class=\"line\" data-prefix=\"$\">  --network web \\\n</li><li class=\"line\" data-prefix=\"$\">  --name traefik \\\n</li><li class=\"line\" data-prefix=\"$\">  traefik:1.7-alpine\n</li></ul></code></pre>\n<p>The command is a little long so let&rsquo;s break it down.</p>\n\n<p>We use the <code>-d</code> flag to run the container in the background as a daemon. We then share our <code>docker.sock</code> file into the container so that the Traefik process can listen for changes to containers. We also share the <code>traefik.toml</code> configuration file and the <code>acme.json</code> file we created into the container.</p>\n\n<p>Next, we map ports <code>:80</code> and <code>:443</code> of our Docker host to the same ports in the Traefik container so Traefik receives all HTTP and HTTPS traffic to the server.</p>\n\n<p>Then we set up two Docker labels that tell Traefik to direct traffic to the hostname <code>monitor.<span class=\"highlight\">your_domain</span></code> to port <code>:8080</code> within the Traefik container, which will expose the monitoring dashboard.</p>\n\n<p>We set the network of the container to <code>web</code>, and we name the container <code>traefik</code>.</p>\n\n<p>Finally, we use the <code>traefik:1.7-alpine</code> image for this container, because it&rsquo;s small.</p>\n\n<p><a href=\"https://docs.docker.com/engine/reference/builder/#entrypoint\">A Docker image&rsquo;s <code>ENTRYPOINT</code> is a command that always runs when a container is created from the image</a>.  In this case, the command is the <code>traefik</code> binary within the container. You can pass additional arguments to that command when you launch the container, but we&rsquo;ve configured all of our settings in the <code>traefik.toml</code> file.</p>\n\n<p>With the container started, you now have a dashboard you can access to see the health of your containers. You can also use this dashboard to visualize the frontends and backends that Traefik has registered. Access the monitoring dashboard by pointing your browser to <code>https://monitor.<span class=\"highlight\">your_domain</span></code>. You will be prompted for your username and password, which are <strong>admin</strong> and the password you configured in Step 1.</p>\n\n<p>Once logged in, you&rsquo;ll see an interface similar to this:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/63957_Traefik/Empty_Traefik_dashboard.png\" alt=\"Empty Traefik dashboard\"></p>\n\n<p>There isn&rsquo;t much to see just yet, but leave this window open, and you will see the contents change as you add containers for Traefik to manage.</p>\n\n<p>We now have our Traefik proxy running, configured to work with Docker, and ready to monitor other Docker containers. Let&rsquo;s add some containers for Traefik to proxy.</p>\n\n<h2 id=\"step-3-—-registering-containers-with-traefik\">Step 3 — Registering Containers with Traefik</h2>\n\n<p>With the Traefik container running, you&rsquo;re ready to run applications behind it. Let&rsquo;s launch the following containers behind Traefik:</p>\n\n<ol>\n<li>A blog using the <a href=\"https://hub.docker.com/_/wordpress/\">official WordPress image</a>.</li>\n<li>A database management server using the <a href=\"https://hub.docker.com/_/adminer/\">official Adminer image</a>.</li>\n</ol>\n\n<p>We&rsquo;ll manage both of these applications with Docker Compose using a <code>docker-compose.yml</code> file. </p>\n\n<p>Create and open the <code>docker-compose.yml</code> file in your editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano docker-compose.yml\n</li></ul></code></pre>\n<p>Add the following lines to the file to specify the version and the networks we&rsquo;ll use:</p>\n<div class=\"code-label \" title=\"docker-compose.yml\">docker-compose.yml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">version: \"3\"\n\nnetworks:\n  web:\n    external: true\n  internal:\n    external: false\n</code></pre>\n<p>We use Docker Compose version <code>3</code> because it&rsquo;s the newest major version of the Compose file format.</p>\n\n<p>For Traefik to recognize our applications, they must be part of the same network, and since we created the network manually, we pull it in by specifying the network name of <code>web</code> and setting <code>external</code> to <code>true</code>. Then we define another network so that we can connect our exposed containers to a database container that we won&rsquo;t expose through Traefik. We&rsquo;ll call this network <code>internal</code>.</p>\n\n<p>Next, we&rsquo;ll define each of our <code>services</code>, one at a time.  Let&rsquo;s start with the <code>blog</code> container, which we&rsquo;ll base on the official WordPress image.  Add this configuration to the bottom of your file:</p>\n<div class=\"code-label \" title=\"docker-compose.yml\">docker-compose.yml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n\nservices:\n  blog:\n    image: wordpress:4.9.8-apache\n    environment:\n      WORDPRESS_DB_PASSWORD:\n    labels:\n      - traefik.backend=blog\n      - traefik.frontend.rule=Host:blog.<span class=\"highlight\">your_domain</span>\n      - traefik.docker.network=web\n      - traefik.port=80\n    networks:\n      - internal\n      - web\n    depends_on:\n      - mysql\n</code></pre>\n<p>The <code>environment</code> key lets you specify environment variables that will be set inside of the container. By  not setting a value for <code>WORDPRESS_DB_PASSWORD</code>, we&rsquo;re telling Docker Compose to get the value from our shell and pass it through when we create the container. We will define this environment variable in our shell before starting the containers. This way we don&rsquo;t hard-code passwords into the configuration file.</p>\n\n<p>The <code>labels</code> section is where you specify configuration values for Traefik. Docker labels don&rsquo;t do anything by themselves, but Traefik reads these so it knows how to treat containers. Here&rsquo;s what each of these labels does:</p>\n\n<ul>\n<li><code>traefik.backend</code> specifies the name of the backend service in Traefik (which points to the actual <code>blog</code> container).</li>\n<li><code>traefik.frontend.rule=Host:blog.<span class=\"highlight\">your_domain</span></code> tells Traefik to examine the host requested and if it matches the pattern of <code>blog.<span class=\"highlight\">your_domain</span></code> it should route the traffic to the <code>blog</code> container.</li>\n<li><code>traefik.docker.network=web</code> specifies which network to look under for Traefik to find the internal IP for this container. Since our Traefik container has access to all of the Docker info, it would potentially take the IP for the <code>internal</code> network if we didn&rsquo;t specify this.</li>\n<li><code>traefik.port</code> specifies the exposed port that Traefik should use to route traffic to this container.</li>\n</ul>\n\n<p>With this configuration, all traffic sent to our Docker host&rsquo;s port <code>80</code> will be routed to the <code>blog</code> container.</p>\n\n<p>We assign this container to two different networks so that Traefik can find it via the <code>web</code> network and it can communicate with the database container through the <code>internal</code> network.</p>\n\n<p>Lastly, the <code>depends_on</code> key tells Docker Compose that this container needs to start <em>after</em> its dependencies are running. Since WordPress needs a database to run, we must run our <code>mysql</code> container before starting our <code>blog</code> container.</p>\n\n<p>Next, configure the MySQL service by adding this configuration to the bottom of your file:</p>\n<div class=\"code-label \" title=\"docker-compose.yml\">docker-compose.yml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n  mysql:\n    image: mysql:5.7\n    environment:\n      MYSQL_ROOT_PASSWORD:\n    networks:\n      - internal\n    labels:\n      - traefik.enable=false\n</code></pre>\n<p>We&rsquo;re using the official MySQL 5.7 image for this container.  You&rsquo;ll notice that we&rsquo;re once again using an <code>environment</code> item without a value. The <code>MYSQL_ROOT_PASSWORD</code> and <code>WORDPRESS_DB_PASSWORD</code> variables will need to be set to the same value to make sure that our WordPress container can communicate with the MySQL. We don&rsquo;t want to expose the <code>mysql</code> container to Traefik or the outside world, so we&rsquo;re only assigning this container to the <code>internal</code> network. Since Traefik has access to the Docker socket, the process will still expose a frontend for the <code>mysql</code> container by default, so we&rsquo;ll add the label <code>traefik.enable=false</code> to specify that Traefik should not expose this container.</p>\n\n<p>Finally, add this configuration to the bottom of your file to define the Adminer container:</p>\n<div class=\"code-label \" title=\"docker-compose.yml\">docker-compose.yml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n  adminer:\n    image: adminer:4.6.3-standalone\n    labels:\n      - traefik.backend=adminer\n      - traefik.frontend.rule=Host:db-admin.<span class=\"highlight\">your_domain</span>\n      - traefik.docker.network=web\n      - traefik.port=8080\n    networks:\n      - internal\n      - web\n    depends_on:\n      - mysql\n</code></pre>\n<p>This container is based on the official Adminer image. The <code>network</code> and <code>depends_on</code> configuration for this container exactly match what we&rsquo;re using for the <code>blog</code> container.</p>\n\n<p>However, since we&rsquo;re directing all of the traffic to port <code>80</code> on our Docker host directly to the <code>blog</code> container, we need to configure this container differently in order for traffic to make it to our <code>adminer</code> container.  The line <code>traefik.frontend.rule=Host:db-admin.<span class=\"highlight\">your_domain</span></code> tells Traefik to examine the host requested. If it matches the pattern of <code>db-admin.<span class=\"highlight\">your_domain</span></code>, Traefik will route the traffic to the <code>adminer</code> container.</p>\n\n<p>At this point, <code>docker-compose.yml</code> should have the following contents:</p>\n<div class=\"code-label \" title=\"docker-compose.yml\">docker-compose.yml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">version: \"3\"\n\nnetworks:\n  web:\n    external: true\n  internal:\n    external: false\n\nservices:\n  blog:\n    image: wordpress:4.9.8-apache\n    environment:\n      WORDPRESS_DB_PASSWORD:\n    labels:\n      - traefik.backend=blog\n      - traefik.frontend.rule=Host:blog.<span class=\"highlight\">your_domain</span>\n      - traefik.docker.network=web\n      - traefik.port=80\n    networks:\n      - internal\n      - web\n    depends_on:\n      - mysql\n  mysql:\n    image: mysql:5.7\n    environment:\n      MYSQL_ROOT_PASSWORD:\n    networks:\n      - internal\n    labels:\n      - traefik.enable=false\n  adminer:\n    image: adminer:4.6.3-standalone\n    labels:\n      - traefik.backend=adminer\n      - traefik.frontend.rule=Host:db-admin.<span class=\"highlight\">your_domain</span>\n      - traefik.docker.network=web\n      - traefik.port=8080\n    networks:\n      - internal\n      - web\n    depends_on:\n      - mysql\n</code></pre>\n<p>Save the file and exit the text editor.</p>\n\n<p>Next, set values in your shell for the <code>WORDPRESS_DB_PASSWORD</code> and <code>MYSQL_ROOT_PASSWORD</code> variables before you start your containers:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">export WORDPRESS_DB_PASSWORD=<span class=\"highlight\">secure_database_password</span>\n</li><li class=\"line\" data-prefix=\"$\">export MYSQL_ROOT_PASSWORD=<span class=\"highlight\">secure_database_password</span>\n</li></ul></code></pre>\n<p>Substitute <code><span class=\"highlight\">secure_database_password</span></code> with your desired database password. Remember to use the same password for both <code>WORDPRESS_DB_PASSWORD</code> and <code>MYSQL_ROOT_PASSWORD</code>.</p>\n\n<p>With these variables set, run the containers using <code>docker-compose</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker-compose up -d\n</li></ul></code></pre>\n<p>Now take another look at the Traefik admin dashboard. You&rsquo;ll see that there is now a <code>backend</code> and a <code>frontend</code> for the two exposed servers:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/63957_Traefik/Populated_Traefik_dashboard.png\" alt=\"Populated Traefik dashboard\"></p>\n\n<p>Navigate to <code>blog.<span class=\"highlight\">your_domain</span></code>. You&rsquo;ll be redirected to a TLS connection and can now complete the WordPress setup:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/63957_Traefik/WordPress_setup_screen.png\" alt=\"WordPress setup screen\"></p>\n\n<p>Now access Adminer by visiting <code>db-admin.<span class=\"highlight\">your_domain</span></code> in your browser, again substituting <code>your_domain</code> with your domain. The <code>mysql</code> container isn&rsquo;t exposed to the outside world, but the <code>adminer</code> container has access to it through the <code>internal</code> Docker network that they share using the <code>mysql</code> container name as a hostname.</p>\n\n<p>On the Adminer login screen, set the <strong>System</strong> dropdown menu to <strong>MySQL</strong>. Now enter <code>mysql</code> for the <strong>Server</strong>, enter <code>root</code> for the <strong>username</strong>, and enter the value you set for <code>MYSQL_ROOT_PASSWORD</code> for <strong>Password</strong>. Leave <strong>Database</strong> empty. Now press <strong>Login</strong>.</p>\n\n<p>Once logged in, you&rsquo;ll see the Adminer user interface:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67478/Adminer_MySQL_database.png\" alt=\"Adminer connected to the MySQL database\"></p>\n\n<p>Both sites are now working, and you can use the dashboard at <code>monitor.<span class=\"highlight\">your_domain</span></code> to keep an eye on your applications.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>In this tutorial, you configured Traefik to proxy requests to other applications in Docker containers.</p>\n\n<p>Traefik&rsquo;s declarative configuration at the application container level makes it easy to configure more services, and there&rsquo;s no need to restart the <code>traefik</code> container when you add new applications to proxy traffic because Traefik notices the changes immediately through the Docker socket file that it&rsquo;s monitoring.</p>\n\n<p>To learn more about what you can do with Traefik, <a href=\"https://docs.traefik.io/basics/\">head over to the official Traefik documentation</a>.</p>\n","descriptionType":"html","publishedDate":"Fri, 28 Aug 2020 19:11:56 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/63957_Traefik/Empty_Traefik_dashboard.png","linkMd5":"93379a64582b399474d7baec9251891d","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn77@2020_5/2020/08/31/07-48-28-644_6e7305f4eb849e2d.webp","destWidth":3364,"destHeight":1912,"sourceBytes":129856,"destBytes":237258,"author":"Keith Thompson","articleImgCdnMap":{"https://assets.digitalocean.com/articles/63957_Traefik/Empty_Traefik_dashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn77@2020_5/2020/08/31/07-48-28-644_6e7305f4eb849e2d.webp","https://assets.digitalocean.com/articles/63957_Traefik/Populated_Traefik_dashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn62@2020_5/2020/08/31/07-48-33-057_a8f1662e5dd0f9d7.webp","https://assets.digitalocean.com/articles/63957_Traefik/WordPress_setup_screen.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn82@2020_5/2020/08/31/07-48-33-644_42ec687edf1fc2c1.webp","https://assets.digitalocean.com/articles/67478/Adminer_MySQL_database.png":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn50@2020_5/2020/08/31/07-48-31-357_2f4a7140be0210fe.webp"},"publishedOrCreatedDate":1598860106976},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo instalar TensorFlow en Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-tensorflow-on-ubuntu-20-04-es","description":"<h3 id=\"introducción\">Introducción</h3>\n\n<p><a href=\"https://www.tensorflow.org/\">TensorFlow</a>, una biblioteca de software de aprendizaje automático de código abierto, se utiliza para entrenar redes neurales. Cada nodo, expresado en forma de <a href=\"https://www.tensorflow.org/programmers_guide/graphs\">gráficos de flujo de datos con estado</a>, representa las operaciones realizadas por redes neurales en matrices multidimensionales. Estas matrices multidimensionales se denominan comúnmente “tensores”, de ahí el nombre de TensorFlow.</p>\n\n<p>En este tutorial, instalará TensorFlow en un entorno virtual Python con <code>virtualenv</code>. Este enfoque aísla la instalación de TensorFlow y pone las cosas en funcionamiento rápidamente. Una vez que complete la instalación, la validará importando TensorFlow para garantizar que no tenga errores.</p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Antes de empezar este tutorial, necesitará lo siguiente:</p>\n\n<ul>\n<li><p>Un servidor de Ubuntu 20.04 con al menos <strong>4 GB de RAM</strong> y configurado mediante <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">la guía de configuración inicial para servidores de Ubuntu 20.04</a>, con un usuario sudo no root y un firewall.</p></li>\n<li><p>Python 3.8 o superior y <code>virtualenv</code> instalados. Siga <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-programming-environment-on-an-ubuntu-20-04-server\">la guía Cómo instalar Python 3 en Ubuntu 20.04</a> para configurar Python y <code>virtualenv</code>.</p></li>\n</ul>\n\n<h2 id=\"paso-1-crear-un-entorno-de-programación\">Paso 1: Crear un entorno de programación</h2>\n\n<p>En este paso, crearemos un entorno virtual en el que instalar TensorFlow sin comprometer nuestros otros proyectos de programación. Si ya tiene un entorno de programación limpio, puede omitir este paso.</p>\n\n<p>Primero, cree un directorio de proyecto. Lo llamaremos <code>tf-demo</code> a efectos de demostración, pero elija un nombre de directorio que le resulte significativo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Diríjase a su directorio <code>tf-demo</code> que creó recientemente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>A continuación, cree un entorno virtual nuevo llamado <code>tensorflow-dev</code>, por ejemplo. Ejecute el siguiente comando para crear el entorno:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python3 -m venv <span class=\"highlight\">tensorflow-dev</span>\n</li></ul></code></pre>\n<p>Esto crea un directorio nuevo <code>tensorflow-dev</code> que contendrá todos los paquetes que instale mientras esté activado este entorno. También incluye <code>pip</code> y una versión independiente de Python.</p>\n\n<p>Ahora active su entorno virtual:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">source <span class=\"highlight\">tensorflow-dev</span>/bin/activate\n</li></ul></code></pre>\n<p>Una vez activado, su mensaje de terminal reflejará que está en el entorno virtual:</p>\n<pre class=\"code-pre \"><code>(<span class=\"highlight\">tensorflow-dev</span>)username@hostname:~/tf-demo $\n</code></pre>\n<p>En este punto, puede instalar TensorFlow en su entorno virtual.</p>\n\n<h2 id=\"paso-2-instalar-tensorflow\">Paso 2: Instalar TensorFlow</h2>\n\n<p>Al instalar TensorFlow, queremos asegurarnos de que estamos instalando y actualizando la versión más reciente disponible en <a href=\"https://pypi.python.org/pypi\">PyPi</a>.</p>\n\n<p>Por tanto, utilizaremos la siguiente sintaxis de comandos con pip:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">pip install --upgrade tensorflow\n</li></ul></code></pre>\n<p>Cuando presione <code>ENTER</code>, se instalará TensorFlow, y debería recibir un resultado que indica que la instalación junto con cualquier paquete dependiente tuvo éxito.</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nSuccessfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 numpy-1.16.2 pbr-5.1.3 protobuf-3.7.0 setuptools-40.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.0 wheel-0.33.1\n...\n\nSuccessfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 markdown-2.6.9 numpy-1.13.3 protobuf-3.5.0.post1 setuptools-38.2.3 six-1.11.0 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0rc3 werkzeug-0.12.2 wheel-0.30.0\n</code></pre>\n<span class='note'><p>\nPuede desactivar su entorno virtual en cualquier momento utilizando el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">deactivate\n</li></ul></code></pre>\n<p>Para reactivar el entorno más adelante, diríjase a su directorio de proyecto y ejecute <code>source <span class=\"highlight\">tensorflow-dev</span>/bin/activate</code>.<br></p></span>\n\n<p>Ahora que ha instalado TensorFlow, vamos a asegurarnos que la instalación funciona.</p>\n\n<h2 id=\"paso-3-validar-la-instalación\">Paso 3: Validar la instalación</h2>\n\n<p>Para validar la instalación de TensorFlow, nos aseguraremos de que podamos importar el paquete TensorFlow.</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">python\n</li></ul></code></pre>\n<p>El siguiente mensaje aparecerá en su terminal:</p>\n<pre class=\"code-pre \"><code>&gt;&gt;&gt;\n</code></pre>\n<p>Este es el mensaje para el intérprete de Python e indica que está listo para comenzar a introducir algunas instrucciones de Python.</p>\n\n<p>Primero, escriba esta línea para importar el paquete TensorFlow y vuélvala disponible como la variable local <code>tf</code>. Pulse <code>ENTER</code> después de escribir la línea de código:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;&gt;&gt;\">import tensorflow as tf\n</li></ul></code></pre>\n<p>Mientras no haya recibido errores, ha instalado TensorFlow correctamente. Si ha recibido un error, debería asegurarse de que su servidor es lo suficientemente potente para manejar TensorFlow. Es posible que necesite cambiar el tamaño de su servidor y asegurarse de tener al menos 4 GB de memoria.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>En este tutorial, ha instalado TensorFlow en un entorno virtual Python y ha validado que TensorFlow funciona al importarlo.</p>\n\n<p>La <a href=\"https://www.tensorflow.org/programmers_guide/\">guía de programadores</a> de TensorFlow proporciona un recurso y una referencia útiles para el desarrollo de TensorFlow. También puede explorar <a href=\"https://www.kaggle.com/\">Kaggle</a>, un entorno competitivo para la aplicación práctica de conceptos de aprendizaje automático que le enfrentan a otros entusiastas del aprendizaje automático, la ciencia de datos y las estadísticas.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:16 +0000","feedId":8037,"bgimg":"","linkMd5":"387414d56707158b7ced5c7e9e2448f7","bgimgJsdelivr":"","metaImg":"","author":"Lisa Tagliaferri","publishedOrCreatedDate":1598860106975},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Установка Elasticsearch, Logstash и Kibana (комплект Elastic) в Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-ru","description":"<h3 id=\"Введение\">Введение</h3>\n\n<p>Комплекс Elastic Stack (прежнее название — <em>комплекс ELK</em>) представляет собой набор программного обеспечения <a href=\"https://www.elastic.co/\">Elastic</a> с открытым исходным кодом, обеспечивающий возможности поиска, анализа и визуализации журналов, сгенерированных любым источником в любом формате (<em>централизованное ведение журнала</em>). Централизованное ведение журнала очень полезно для выявления проблем с серверами или приложениями, поскольку обеспечивает возможности поиска всех журнальных записей в одном месте. Также данная возможность позволяет выявлять проблемы, распространяющиеся на несколько серверов, посредством сопоставления их журналов за определенный период времени.</p>\n\n<p>Комплекс Elastic Stack имеет четыре основных компонента:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/elasticsearch\"><strong>Elasticsearch</strong></a>: распределенная поисковая система <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\"><em>RESTful</em></a>, которая сохраняет все собранные данные.</li>\n<li><a href=\"https://www.elastic.co/products/logstash\"><strong>Logstash</strong></a>: элемент обработки данных комплекса Elastic, отправляющий входящие данные в Elasticsearch.</li>\n<li><a href=\"https://www.elastic.co/products/kibana\"><strong>Kibana</strong></a>: веб-интерфейс для поиска и визуализации журналов.</li>\n<li><a href=\"https://www.elastic.co/products/beats\"><strong>Beats</strong></a>: компактные элементы переноса данных одиночного назначения, которые могут отправлять данные с сотен или тысяч компютеров в Logstash или Elasticsearch.</li>\n</ul>\n\n<p>В этом обучающем модуле вы научитесь устанавливать <a href=\"https://www.elastic.co/elk-stack\">комплект Elastic на</a> сервере Ubuntu 20.04. Вы научитесь устанавливать все компоненты Elastic Stack, в том числе <a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>, инструмент для перенаправления и централизации журналов и файлов, а также настраивать эти компоненты для сбора и визуализации системных журналов. Кроме того, поскольку компонент Kibana обычно доступен только через <code>localhost</code>, мы будем использовать <a href=\"https://www.nginx.com/\">Nginx</a> в качестве прокси для обеспечения доступа через браузер. Мы установим все эти компоненты на одном сервере, который будем называть нашим <em>сервером Elastic Stack</em>.</p>\n\n<p><span class='note'><strong>Примечание.</strong> При установке Elastic Stack необходимо использовать одну и ту же версию для всего комплекса. В этом обучающем модуле мы установим последние версии компонентов комплекта. На момент написания это Elasticsearch 7.7.1, Kibana 7.7.1, Logstash 7.7.1 и Filebeat 7.7.1.<br></span></p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для этого обучающего модуля вам потребуется следующее:</p>\n\n<ul>\n<li><p>Сервер Ubuntu 20.04 с 4 ГБ оперативной памяти и 2 процессорами, а также настроенный пользователь без прав root с привилегиями sudo. Вы можете это сделать, воспользовавшись <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">указаниями руководства Начальная настройка сервера Ubuntu 18.04</a>. В этом обучающем руководстве мы будем использовать минимальное количество процессоров и оперативной памяти, необходимое для работы с Elasticsearch. Обратите внимание, что требования сервера Elasticsearch к количеству процессоров, оперативной памяти и хранению данных зависят от ожидаемого объема журналов.</p></li>\n<li><p>Установленный пакет OpenJDK 11. Для настройки воспользуйтесь рекомендациями раздела <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04#installing-the-default-jrejdk\">«Установка комплекта JRE/JDK по умолчанию»</a> in our guide в документе <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04\">«Установка Java с помощью Apt в Ubuntu 20.04»</a>.</p></li>\n<li><p>На сервере должен быть установлен Nginx, который мы позднее настроим как обратный прокси для Kibana. Для настройки следуйте указаниям нашего обучающего модуля <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">«Установка Nginx в Ubuntu 20.04»</a>.</p></li>\n</ul>\n\n<p>Кроме того, поскольку комплекс Elastic используется для доступа ценной информации о вашем сервере, которую вам нужно защищать, очень важно обеспечить защиту сервера сертификатом TLS/SSL. Это необязательно, но <strong>настоятельно рекомендуется</strong>.</p>\n\n<p>Однако поскольку вы будете вносить изменения в серверный блок Nginx в ходе выполнения этого обучающего модуля, разумнее всего будет пройти обучающий модуль <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">«Let&rsquo;s Encrypt в Ubuntu 18.04»</a> после прохождения второго шага настоящего обучающего модуля. Если вы планируете настроить на сервере Let&rsquo;s Encrypt, вам потребуется следующее:</p>\n\n<ul>\n<li>Полностью квалифицированное доменное имя (FQDN). В этом обучающем руководстве мы будем использовать <code><span class=\"highlight\">your_domain</span></code>. Вы можете купить доменное имя на <a href=\"https://namecheap.com\">Namecheap</a>, получить его бесплатно на <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> или воспользоваться услугами любого предпочитаемого регистратора доменных имен.</li>\n<li><p>На вашем сервере должны быть настроены обе нижеследующие записи DNS. В руководстве <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">Введение в DigitalOcean DNS</a> содержится подробная информация по их добавлению.</p>\n\n<ul>\n<li>Запись A, где <code><span class=\"highlight\">your_domain</span></code> указывает на публичный IP-адрес вашего сервера.</li>\n<li>Запись A, где <code>www.<span class=\"highlight\">your_domain</span></code> указывает на публичный IP-адрес вашего сервера.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"Шаг-1-—-Установка-и-настройка-elasticsearch\">Шаг 1 — Установка и настройка Elasticsearch</h2>\n\n<p>Компоненты Elasticsearch отсутствуют в репозиториях пакетов Ubuntu по умолчанию. Однако их можно установить с помощью APT после добавления списка источников пакетов Elastic.</p>\n\n<p>Все пакеты подписаны ключом подписи Elasticsearch для защиты вашей системы от поддельных пакетов. Ваш диспетчер пакетов будет считать надежными пакеты, для которых проведена аутентификация с помощью ключа. На этом шаге вы импортируете открытый ключ Elasticsearch GPG и добавить список источников пакетов Elastic для установки Elasticsearch.</p>\n\n<p>Для начала используйте cURL, инструмент командной строки для передачи данных с помощью URL, для импорта открытого ключа Elasticsearch GPG в APT. Обратите внимание, что мы используем аргументы -fsSL для подавления всех текущих и возможных ошибок (кроме сбоя сервера), а также чтобы разрешить cURL подать запрос на другой локации при переадресации. Выведите результаты команды cURL в программу apt-key, которая добавит открытый ключ GPG в APT.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n</li></ul></code></pre>\n<p>Затем добавьте список источников Elastic в директорию <code>sources.list.d</code>, где APT будет искать новые источники:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n</li></ul></code></pre>\n<p>Затем обновите списки пакетов, чтобы APT мог прочитать новый источник Elastic:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Установите Elasticsearch с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install elasticsearch\n</li></ul></code></pre>\n<p>Теперь система Elasticsearch установлена и готова к настройке. Используйте предпочитаемый текстовый редактор для изменения файла конфигурации Elasticsearch, <code>elasticsearch.yml</code>. Мы будем использовать <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/elasticsearch/elasticsearch.yml\n</li></ul></code></pre>\n<p><span class='​​​note'><strong>Примечание.</strong> Файл конфигурации Elasticsearch представлен в формате YAM. Это означает, что нам нужно сохранить формат отступов. Не добавляйте никакие дополнительные пробелы при редактировании этого файла.<br></span></p>\n\n<p>Файл <code>elasticsearch.yml</code> предоставляет варианты конфигурации для вашего кластера, узла, пути, памяти, сети, обнаружения и шлюза. Большинство из этих вариантов уже настроены в файле, но вы можете изменить их в соответствии с вашими потребностями. В нашем случае для демонстрации односерверной конфигурации мы будем регулировать настройки только для хоста сети.</p>\n\n<p>Elasticsearch прослушивает весь трафик порта <code>9200</code>. По желанию вы можете ограничить внешний доступ к вашему экземпляру Elasticsearch, чтобы посторонние не смогли прочесть ваши данные или отключить ваш кластер Elasticsearch через <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">REST API</a>. Для ограничения доступа и повышения безопасности найдите строку с указанием <code>network.host</code>, разкомментируйте ее и замените значение на <code>localhost</code>, чтобы она выглядела следующим образом:</p>\n<div class=\"code-label \" title=\"/etc/elasticsearch/elasticsearch.yml\">/etc/elasticsearch/elasticsearch.yml</div><pre class=\"code-pre \"><code>. . .\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: <span class=\"highlight\">localhost</span>\n. . .\n</code></pre>\n<p>Мы указали <code>localhost</code>, и теперь Elasticsearch прослушивает все интерфейсы и связанные IP-адреса. Если вы хотите, чтобы прослушивался только конкретный интерфейс, вы можете указать его IP-адрес вместо <code>localhost</code>. Сохраните и закройте <code>elasticsearch.yml</code>. Если вы используете <code>nano</code>, вы можете сделать это, нажав <code>CTRL+X</code>, затем <code>Y</code>, а затем <code>ENTER</code>.</p>\n\n<p>Это минимальные настройки, с которыми вы можете начинать использовать Elasticsearch. Теперь вы можете запустить Elasticsearch в первый раз.</p>\n\n<p>Запустите службу Elasticsearch с помощью <code>systemctl</code>. Запуск Elasticsearch может занять некоторое время. В другом случае вы можете увидеть сообщение об ошибке подключения.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start elasticsearch\n</li></ul></code></pre>\n<p>Затем запустите следующую команду, чтобы активировать Elasticsearch при каждой загрузке сервера:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable elasticsearch\n</li></ul></code></pre>\n<p>Вы можете протестировать работу службы Elasticsearch, отправив запрос HTTP:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -X GET \"localhost:9200\"\n</li></ul></code></pre>\n<p>Вы получите ответ, содержащий базовую информацию о локальном узле:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\n  \"name\" : \"Elasticsearch\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"qqhFHPigQ9e2lk-a7AvLNQ\",\n  \"version\" : {\n    \"number\" : \"7.7.1\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"deb\",\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\",\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.5.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n\n</code></pre>\n<p>Мы настроили и запустили Elasticsearch, и теперь можем перейти к установке Kibana, следующего компонента комплекса Elastic.</p>\n\n<h2 id=\"Шаг-2-—-Установка-и-настройка-информационной-панели-kibana\">Шаг 2 — Установка и настройка информационной панели Kibana</h2>\n\n<p>Согласно <a href=\"https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html\">официальной документации</a>, Kibana следует устанавливать только после установки Elasticsearch. Установка в этом порядке обеспечивает правильность установки зависимостей компонентов.</p>\n\n<p>Поскольку вы уже добавили источник пакетов Elastic на предыдущем шаге, вы можете просто установить все остальные компоненты комплекса Elastic с помощью <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install kibana\n</li></ul></code></pre>\n<p>Затем активируйте и запустите службу Kibana:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable kibana\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl start kibana\n</li></ul></code></pre>\n<p>Поскольку согласно настройкам Kibana прослушивает только <code>localhost</code>, мы должны задать <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">обратный прокси</a>, чтобы разрешить внешний доступ. Для этого мы используем Nginx, который должен быть уже установлен на вашем сервере.</p>\n\n<p>Вначале нужно использовать команду <code>openssl</code> для создания административного пользователя Kibana, которого вы будете использовать для доступа к веб-интерфейсу Kibana. Для примера мы назовем эту учетную запись <code><span class=\"highlight\">kibanaadmin</span></code>, однако для большей безопасности мы рекомендуем выбрать нестандартное имя пользователя, которое будет сложно угадать.</p>\n\n<p>Следующая команда создаст административного пользователя Kibana и пароль и сохранит их в файле <code>htpasswd.users</code>. Вы настроите Nginx для использования этого имени пользователя и пароля и моментально прочитаете этот файл:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"<span class=\"highlight\">kibanaadmin</span>:`openssl passwd -apr1`\" | sudo tee -a /etc/nginx/htpasswd.users\n</li></ul></code></pre>\n<p>Введите и подтвердить пароль в диалоговом окне. Запомните или запишите эти учетные данные, поскольку они вам потребуются для доступа к веб-интерфейсу Kibana.</p>\n\n<p>Теперь мы создадим файл серверного блока Nginx. В качестве примера мы присвоим этому файлу имя <code><span class=\"highlight\">your_domain</span></code>, хотя вы можете дать ему более описательное имя. Например, если вы настроили записи FQDN и DNS для этого сервера, вы можете присвоить этому файлу имя своего FQDN:</p>\n\n<p>Создайте файл серверного блока Nginx, используя nano или предпочитаемый текстовый редактор:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Добавьте в файл следующий блок кода и обязательно замените <code><span class=\"highlight\">your_domain</span></code> на FQDN или публичный IP-адрес вашего сервера. Этот код настраивает Nginx для перенаправления трафика HTTP вашего сервера в приложение Kibana, которое прослушивает порт <code>localhost:5601</code>. Также он настраивает Nginx для чтения файла <code>htpasswd.users</code> и требует использования базовой аутентификации.</p>\n\n<p>Если вы выполнили <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">предварительный обучающий модуль по Nginx</a> до конца, возможно вы уже создали этот файл и заполнили его. В этом случае удалите из файла все содержание и добавьте следующее:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/your_domain\">/etc/nginx/sites-available/your_domain</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n\n    server_name <span class=\"highlight\">your_domain</span>;\n\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/htpasswd.users;\n\n    location / {\n        proxy_pass http://localhost:5601;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n</code></pre>\n<p>Завершив редактирование, сохраните и закройте файл.</p>\n\n<p>Затем активируйте новую конфигурацию, создав символическую ссылку на каталог <code>sites-enabled</code>. Если вы уже создали файл серверного блока с тем же именем, что и в обучающем модуле по Nginx, вам не нужно выполнять эту команду:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Затем проверьте конфигурацию на синтаксические ошибки:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Если в результатах будут показаны какие-либо ошибки, вернитесь и еще раз проверьте правильность изменений в файле конфигурации. Когда вы увидите на экране результатов сообщение <code>syntax is ok</code>, перезапустите службу Nginx:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Если вы следовали указаниям модуля по начальной настройке сервера, у вас должен быть включен брандмауэр UFW. Чтобы разрешить соединения с Nginx, мы можем изменить правила с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 'Nginx Full'\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Примечание.</strong> Если вы выполнили предварительный обучающий модуль Nginx, вы могли уже создать правило UFW, разрешающее профилю <code>Nginx HTTP</code> доступ через брандмауэр. Поскольку профиль <code>Nginx Full</code> разрешает трафик HTTP и HTTPS на брандмауэре, вы можете безопасно удалить ранее созданное правило. Для этого нужно использовать следующую команду:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw delete allow 'Nginx HTTP'\n</li></ul></code></pre>\n<p></p></span>\n\n<p>Теперь приложение Kibana доступно через FQDN или публичный IP-адрес вашего сервера комплекса Elastic. Вы можете посмотреть страницу состояния сервера Kibana, открыв следующий адрес и введя свои учетные данные в диалоге:</p>\n<pre class=\"code-pre \"><code>http://<span class=\"highlight\">your_domain</span>/status\n</code></pre>\n<p>На этой странице состояния отображается информация об использовании ресурсов сервера, а также выводится список установленных плагинов.</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png\" alt=\"|Страница состояния Kibana\"></p>\n\n<p><span class='note'><strong>Примечание.</strong> Как указывалось в разделе предварительных требований, рекомендуется включить на сервере SSL/TLS. Теперь вы можете следовать указаниями обучающего модуля по <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Let’s Encrypt</a> для получения бесплатного сертификата SSL для Nginx в Ubuntu 20.04. После получения сертификата SSL/TLS вы можете вернуться и завершить прохождение этого обучающего модуля.<br></span></p>\n\n<p>Теперь информационная панель Kibana настроена и мы перейдем к установке следующего компонента: Logstash.</p>\n\n<h2 id=\"Шаг-3-—-Установка-и-настройка-logstash\">Шаг 3 — Установка и настройка Logstash</h2>\n\n<p>Хотя Beats может отправлять данные напрямую в базу данных Elasticsearch, мы рекомендуем использовать для обработки данных Logstash. Это даст вам гибкую возможность собирать данные из разных источников, преобразовывать их в общий формат и экспортировать в другую базу данных.</p>\n\n<p>Установите Logstash с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install logstash\n</li></ul></code></pre>\n<p>После установки Logstash вы можете перейти к настройке. Файлы конфигурации Logstash находятся в каталоге <code>/etc/logstash/conf.d</code>. Дополнительную информацию о синтаксисе конфигурации можно найти в <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\">справочнике по конфигурации</a>, предоставляемом Elastic. Во время настройки конфигурации в файле полезно рассматривать Logstash как конвейер, принимающий данные на одном конце, обрабатывающий и отправляющий их в пункт назначения (в нашем случае пунктом назначения является Elasticsearch). Конвейер Logstash имеет два обязательных элемента, <code>input</code> и <code>output</code>, а также необязательный элемент <code>filter</code>. Плагины ввода потребляют данные источника, плагины фильтра обрабатывают данные, а плагины вывода записывают данные в пункт назначения.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png\" alt=\"Конвейер Logstash\"></p>\n\n<p>Создайте файл конфигурации с именем <code>02-beats-input.conf</code>, где вы настроите ввод данных Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/02-beats-input.conf\n</li></ul></code></pre>\n<p>Вставьте следующую конфигурацию <code>ввода</code>. В ней задается ввод <code>beats</code>, который прослушивает порт TCP <code>5044</code>.</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/02-beats-input.conf\">/etc/logstash/conf.d/02-beats-input.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">input {\n  beats {\n    port =&gt; 5044\n  }\n}\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Создайте файл конфигурации с именем <code>30-elasticsearch-output.conf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf\n</li></ul></code></pre>\n<p>Вставьте следующую конфигурацию <code>вывода</code>. Этот вывод настраивает Logstash для хранения данных Beats в Elasticsearch, запущенном на порту <code>localhost:9200</code>, в индексе с названием используемого компонента Beat. В этом обучающем модуле используется компонент Beat под названием Filebeat:</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/30-elasticsearch-output.conf\">/etc/logstash/conf.d/30-elasticsearch-output.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">output {\n  if [@metadata][pipeline] {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    pipeline =&gt; \"%{[@metadata][pipeline]}\"\n    }\n  } else {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n\n\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Протестируйте свою конфигурацию Logstash с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t\n</li></ul></code></pre>\n<p>Если ошибок синтаксиса не будет, в выводе появится сообщение <code>Config Validation Result: OK. Exiting Logstash</code> через несколько секунд после запуска. Если вы не увидите этого сообщения, проверьте ошибки вывода и обновите конфигурацию для их исправления. Обратите внимание, что вы получите предупреждения от OpenJDK, но они не должны вызывать проблем, и их можно игнорировать.</p>\n\n<p>Если тестирование конфигурации выполнено успешно, запустите и активируйте Logstash, чтобы изменения конфигурации вступили в силу:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start logstash\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable logstash\n</li></ul></code></pre>\n<p>Теперь Logstash работает нормально и полностью настроен, и мы можем перейти к установке Filebeat.</p>\n\n<h2 id=\"Шаг-4-—-Установка-и-настройка-filebeat\">Шаг 4 — Установка и настройка Filebeat</h2>\n\n<p>Комплекс Elastic использует несколько компактных элементов транспортировки данных (Beats) для сбора данных из различных источников и их транспортировки в Logstash или Elasticsearch. Ниже перечислены компоненты Beats, доступные в Elastic:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>: собирает и отправляет файлы журнала.</li>\n<li><a href=\"https://www.elastic.co/products/beats/metricbeat\">Metricbeat</a>: собирает метрические показатели использования систем и служб.</li>\n<li><a href=\"https://www.elastic.co/products/beats/packetbeat\">Packetbeat</a>: собирает и анализирует данные сети.</li>\n<li><a href=\"https://www.elastic.co/products/beats/winlogbeat\">Winlogbeat</a>: собирает данные журналов событий Windows.</li>\n<li><a href=\"https://www.elastic.co/products/beats/auditbeat\">Auditbeat</a>: собирает данные аудита Linux и отслеживает целостность файлов.</li>\n<li><a href=\"https://www.elastic.co/products/beats/heartbeat\">Heartbeat</a>: отслеживает доступность услуг посредством активного зондирования.</li>\n</ul>\n\n<p>В этом обучающем модуле мы используем Filebeat для перенаправления локальных журналов в комплекс Elastic.</p>\n\n<p>Установите Filebeat с помощью <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install filebeat\n</li></ul></code></pre>\n<p>Затем настройте Filebeat для подключения к Logstash. Здесь мы изменим образец файла конфигурации, входящий в комплектацию Filebeat.</p>\n\n<p>Откройте файл конфигурации Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/filebeat/filebeat.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Примечание.</strong> Как и в Elasticsearch, файл конфигурации Filebeat имеет формат YAML. Это означает, что в файле учитываются отступы, и вы должны использовать точно такое количество пробелов, как указано в этих инструкциях.<br></span></p>\n\n<p>Filebeat поддерживает разнообразные выводы, но обычно события отправляются только напрямую в Elasticsearch или в Logstash для дополнительной обработки. В этом обучающем модуле мы будем использовать Logstash для дополнительной обработки данных, собранных Filebeat. Filebeat не потребуется отправлять данные в Elasticsearch напрямую, поэтому мы отключим этот вывод. Для этого мы найдем раздел <code>output.elasticsearch</code> и поставим перед следующими строками значок комментария <code>#</code>:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>...\n<span class=\"highlight\">#</span>output.elasticsearch:\n  # Array of hosts to connect to.\n  <span class=\"highlight\">#</span>hosts: [\"localhost:9200\"]\n...\n</code></pre>\n<p>Затем настроим раздел <code>output.logstash</code>. Уберите режим комментариев для строк <code>output.logstash:</code> и <code>hosts: [\"localhost:5044\"]</code>, удалив значки <code>#</code>. Так мы настроим Filebeat для подключения к Logstash на сервере комплекса Elastic Stack через порт <code>5044</code>, который мы ранее задали для ввода Logstash:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>output.logstash:\n  # The Logstash hosts\n  hosts: [\"localhost:5044\"]\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Функции Filebeat можно расширить с помощью <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-modules.html\">модулей Filebeat</a>. В этом обучающем модуле мы будем использовать модуль <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-module-system.html\">system</a>, который собирает и проверяет данные журналов, созданных службой регистрации систем в распространенных дистрибутивах Linux.</p>\n\n<p>Давайте активируем его:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules enable system\n</li></ul></code></pre>\n<p>Вы увидите список включенных и отключенных модулей с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules list\n</li></ul></code></pre>\n<p>Вы увидите примерно следующий список:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enabled:\nsystem\n\nDisabled:\napache2\nauditd\nelasticsearch\nicinga\niis\nkafka\nkibana\nlogstash\nmongodb\nmysql\nnginx\nosquery\npostgresql\nredis\ntraefik\n...\n</code></pre>\n<p>Filebeat по умолчанию настроен для использования путей по умолчанию для системных журналов и журналов авторизации. Для целей данного обучающего модуля вам не нужно ничего изменять в конфигурации. Вы можете посмотреть параметры модуля в файле конфигурации <code>/etc/filebeat/modules.d/system.yml</code>.</p>\n\n<p>Затем нам нужно настроить конвейеры обработки Filebeat, выполняющие синтаксический анализ данных журнала перед их отправкой через logstash в Elasticsearch. Чтобы загрузить конвейер обработки для системного модуля, введите следующую команду:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --pipelines --modules system\n</li></ul></code></pre>\n<p>Затем загрузите в Elasticsearch шаблон индекса. <a href=\"https://www.elastic.co/blog/what-is-an-elasticsearch-index\"><em>Индекс Elasticsearch</em></a> — это коллекция документов со сходными характеристиками. Индексы идентифицируются по имени, которое используется для ссылки на индекс при выполнении различных операций внутри него. Шаблон индекса применяется автоматически при создании нового индекса.</p>\n\n<p>Используйте следующую команду для загрузки шаблона:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=[\"localhost:9200\"]'\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Index setup finished.\n</code></pre>\n<p>В комплект Filebeat входят образцы информационных панелей Kibana, позволяющие визуализировать данные Filebeat в Kibana. Прежде чем вы сможете использовать информационные панели, вам нужно создать шаблон индекса и загрузить информационные панели в Kibana.</p>\n\n<p>При загрузке информационных панелей Filebeat подключается к Elasticsearch для проверки информации о версиях. Для загрузки информационных панелей при включенном Logstash необходимо отключить вывод Logstash и активировать вывод Elasticsearch:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601\n</li></ul></code></pre>\n<p>Результат должен выглядеть примерно следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Overwriting ILM policy is disabled. Set `setup.ilm.overwrite:true` for enabling.\n\nIndex setup finished.\nLoading dashboards (Kibana must be running and reachable)\nLoaded dashboards\nSetting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.\nSee more: https://www.elastic.co/guide/en/elastic-stack-overview/current/xpack-ml.html\nLoaded machine learning job configurations\nLoaded Ingest pipelines\n</code></pre>\n<p>Теперь вы можете запустить и активировать Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start filebeat\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable filebeat\n</li></ul></code></pre>\n<p>Если вы правильно настроили комплекс Elastic, Filebeat начнет отправлять системный журнал и журналы авторизации в Logstash, откуда эти данные будут загружаться в Elasticsearch.</p>\n\n<p>Чтобы подтвердить получение этих данных в Elasticsearch необходимот отправить в индекс Filebeat запрос с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'\n</li></ul></code></pre>\n<p>Результат должен выглядеть примерно следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\n{\n{\n  \"took\" : 4,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 2,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 4040,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"filebeat-7.7.1-2020.06.04\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"FiZLgXIB75I8Lxc9ewIH\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"cloud\" : {\n            \"provider\" : \"digitalocean\",\n            \"instance\" : {\n              \"id\" : \"194878454\"\n            },\n            \"region\" : \"nyc1\"\n          },\n          \"@timestamp\" : \"2020-06-04T21:45:03.995Z\",\n          \"agent\" : {\n            \"version\" : \"7.7.1\",\n            \"type\" : \"filebeat\",\n            \"ephemeral_id\" : \"cbcefb9a-8d15-4ce4-bad4-962a80371ec0\",\n            \"hostname\" : \"june-ubuntu-20-04-elasticstack\",\n            \"id\" : \"fbd5956f-12ab-4227-9782-f8f1a19b7f32\"\n          },\n\n\n...\n</code></pre>\n<p>Если в результатах показано 0 совпадений, Elasticsearch не выполняет загрузку журналов в индекс, который вы искали, и вам нужно проверить настройки на ошибки. Если вы получили ожидаемые результаты, перейдите к следующему шагу, где мы увидим, как выполняется навигация по информационным панелям Kibana.</p>\n\n<h2 id=\"Шаг-5-—-Изучение-информационных-панелей-kibana\">Шаг 5 — Изучение информационных панелей Kibana</h2>\n\n<p>Вернемся в веб-интерфейс Kibana, который мы установили ранее.</p>\n\n<p>Откройте в браузере FQDN или публичный IP-адрес вашего сервера с комплексом Elastic. Если сессия была прервана, вам нужно будет повторно ввести учетные данные, которые вы определили на шаге 2. После входа в систему вы получите домашнюю страницу Kibana:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg\" alt=\"Главная страница Kibana\"></p>\n\n<p>Нажмите ссылку <strong>Discover</strong> (Изучение) в левой панели навигации (возможно вам нужно будет нажать значок <strong>раскрытия</strong> в нижнем левом углу, чтобы увидеть все элементы меню навигации). Выберите на странице <strong>Discover</strong> (Изучение) заранее настроенный индекс <strong>filebeat-</strong>* для просмотра данных Filebeat. По умолчанию при этом будут выведены все данные журналов за последние 15 минут. Ниже вы увидите гистограмму с событиями журнала и некоторыми сообщениями журнала:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg\" alt=\"Страница Discover\"></p>\n\n<p>Здесь вы можете искать и просматривать журналы, а также настраивать информационные панели. Сейчас на этой странице будет немного данных, потому что вы собираете системные журналы только со своего сервера Elastic Stack.</p>\n\n<p>Используйте левую панель навигации для перехода на страницу <strong>Dashboard</strong> и выполните на этой странице поиск информационных панелей <strong>Filebeat System</strong>. После этого вы можете выбрать образцы панелей управления, входящие в комплект модуля Filebeat <code>system</code>.</p>\n\n<p>Например, вы можете просматривать подробную статистику по сообщениям системного журнала:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg\" alt=\"Информационная панель Syslog\"></p>\n\n<p>Также вы сможете видеть, какие пользователи использовали команду <code>sudo</code> и когда:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg\" alt=\"Информационная панель Sudo\"></p>\n\n<p>В Kibana имеется множество других функций, в том числе функции фильтрации и составления диаграмм, так что вы можете свободно их исследовать.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>В этом обучающем модуле вы научились устанавливать и настраивать комплекс Elastic Stack для сбора и анализа данных системных журналов. Помните, что вы можете отправлять в Logstash практически любые типы данных журнала и индексированных данных с помощью <a href=\"https://www.elastic.co/products/beats\">Beats</a>, однако данные будут более полезны, если они будут проанализированы и структурированы с помощью фильтра Logstash, который преобразует данные в единый формат, легко читаемый Elasticsearch.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:01 +0000","feedId":8037,"bgimg":"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png","linkMd5":"f08085fc11977cbc11eeebd61646b9af","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","destWidth":1833,"destHeight":948,"sourceBytes":40417,"destBytes":48810,"author":"Erin Glass","articleImgCdnMap":{"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn82@2020_2/2020/08/31/07-48-31-557_41a6f5cccef041e1.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn1@2020_3/2020/08/31/07-48-32-396_0638f11900b9faf4.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn37@2020_3/2020/08/31/07-48-33-221_1dfbe5e28e76fefb.webp","http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn10@2020_4/2020/08/31/07-48-32-522_c0c2011e332e864d.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn5@2020_6/2020/08/31/07-48-32-458_2cfaecfed9ac513b.webp"},"publishedOrCreatedDate":1598860106978},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo instalar una pila ERPNext en Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-es","description":"<p><em>El autor seleccionó a <a href=\"https://www.brightfunds.org/organizations/software-in-the-public-interest-inc\">Software in the Public Interest</a> para recibir una donación como parte del programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introducción\">Introducción</h3>\n\n<p><a href=\"https://erpnext.com//\">ERPNext</a> es un conjunto de programas de Planeación de recursos empresariales (ERP) que aprovecha la potencia y la flexibilidad de las tecnologías de código abierto. Se destaca en la gestión de los principales procesos empresariales, como finanzas, ventas, recursos humanos, fabricación, compras, servicios, necesidades de soporte técnico y más. Estos son algunos de los beneficios de implementar un sistema como ERPNext:</p>\n\n<ul>\n<li>Mejor productividad mediante la automatización de procesos comerciales repetitivos</li>\n<li>Mejora de la eficacia de TI al permitir que todos los departamentos de la empresa compartan una misma base de datos</li>\n<li>Mejora la toma de decisiones al proporcionar una visión integral de cómo se relacionan las unidades de negocio entre sí</li>\n</ul>\n\n<p>ERPNext está basado en <a href=\"https://frappe.io/frappe\">Frappe</a>, un marco de aplicaciones web de pila completa escrito en <a href=\"https://www.python.org/\">Python</a> que aprovecha al máximo el <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">entorno de ejecución de Node/JavaScript</a> y utiliza <a href=\"https://mariadb.org/\">MariaDB</a> como su backend de base de datos. Una de las muchas ventajas de las aplicaciones basadas en Frappe, como ERPNext, es la utilidad de línea de comandos <a href=\"https://github.com/frappe/bench\">bench</a>. La CLI bench les ahorra tiempo a los administradores mediante la automatización de tareas como la instalación, la actualización, la configuración y la administración de varios sitios de Frappe/ERPNext.</p>\n\n<p>En este tutorial, instalará y configurará una pila ERPNext en un servidor con Ubuntu 18.04. Esto le permitirá configurar su pila para diversos entornos de desarrollo o producción de acuerdo con sus necesidades y lo preparará para crear una arquitectura más compleja y tolerante a errores.</p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<ul>\n<li>Un servidor Ubuntu 18.04 con un mínimo de 4 GB de RAM y un usuario <code>sudo</code> no root. Puede configurar su servidor y su usuario siguiendo nuestra <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Guía de configuración inicial de servidores para Ubuntu 18.04</a>.</li>\n</ul>\n\n<p><span class='note'><strong>Nota:</strong> Al seleccionar las especificaciones de su servidor, tenga en cuenta que los sistemas ERP realizan un uso intensivo de recursos. Esta guía indica que se requiere un servidor con 4 GB de RAM, que es suficiente para casos de uso básico, pero los requisitos de hardware específicos pueden variar dependiendo de la cantidad de usuarios y el tamaño de su empresa.<br></span></p>\n\n<ul>\n<li>Un nombre de dominio registrado por completo con un registro A apuntado a su servidor. Si utiliza un Droplet de DigitalOcean, puede seguir <a href=\"https://www.digitalocean.com/community/tutorials/how-to-point-to-digitalocean-nameservers-from-common-domain-registrars\">esta guía</a> para configurar correctamente su DNS. Para este tutorial, se utilizará <code><span class=\"highlight\">your_domain</span></code> en todo momento.</li>\n</ul>\n\n<h2 id=\"paso-1-configurar-el-firewall\">Paso 1: Configurar el firewall</h2>\n\n<p>Si bien la configuración del firewall para entornos de desarrollo es opcional, es una práctica de seguridad obligatoria para los entornos de producción.</p>\n\n<p>Deberá abrir los siguientes puertos en su servidor ERPNext:</p>\n\n<ul>\n<li><code>80/tcp</code> y <code>443/tcp</code> para HTTP y HTTPS respectivamente</li>\n<li><code>3306/tcp</code> para la conexión con MariaDB (se recomienda solo si necesita acceso remoto a la base de datos)</li>\n<li><code>143/tcp</code> y <code>25/tcp</code> para IMAP y STMP respectivamente</li>\n<li><code>22/tcp</code> para SSH (si aún no ha habilitado <code>OpenSSH</code>)</li>\n<li><code>8000/tcp</code> para probar el desarrollo antes de implementar su sitio</li>\n</ul>\n\n<p>Para abrir varios puertos a la vez, puede usar el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 22,25,143,80,443,3306,8000/tcp\n</li></ul></code></pre>\n<p>De forma alternativa, puede permitir conexiones de direcciones IP específicas en puertos determinados utilizando este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow from <span class=\"highlight\">server_IP</span> to any port <span class=\"highlight\">port_number</span>\n</li></ul></code></pre>\n<p>Después de abrir todos los puertos necesarios, habilite el firewall:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Después de habilitar el firewall, confirme el estado de sus puertos abiertos:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>Para obtener más información sobre la configuración del firewall , consulte nuestra guía <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-18-04\">Cómo configurar un firewall con UFW en Ubuntu 18.04</a>.</p>\n\n<p>La configuración de un firewall adecuado es el primero de dos pasos preliminares. Ahora, configurará la asignación de teclado y la codificación de caracteres en su servidor.</p>\n\n<h2 id=\"paso-2-establecer-las-configuraciones-regionales\">Paso 2: Establecer las configuraciones regionales</h2>\n\n<p>Es sumamente recomendable configurar la asignación de teclado para la consola, así como el idioma y la codificación de caracteres de su host. Esto es necesario para evitar posibles problemas durante el proceso de instalación de ERPNext 12. Tenga en cuenta que estos ajustes afectan únicamente la configuración regional del sistema y no están relacionados con el idioma de la IU de su plataforma de ERPNext.</p>\n\n<p>Primero, actualice su servidor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Ahora, configure la asignación de teclado, el idioma y la codificación de caracteres:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo localectl set-keymap us &amp;&amp; sudo localectl set-locale LANG=en_US.utf8\n</li></ul></code></pre>\n<p>Ubuntu 18.04 y otras distribuciones Linux usan la utilidad <code>localectl</code> para controlar y modificar los ajustes de configuración regional y distribución del teclado de todo el sistema antes de que el usuario inicie sesión, que es exactamente lo que requiere ERPNext 12.</p>\n\n<p>También deberá agregar las siguientes líneas a su archivo <code>/etc/environment</code>. Utilice <code>nano</code> o su editor de texto preferido para abrir el archivo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/environment\n</li></ul></code></pre>\n<p>Ahora, agregue el siguiente contenido:</p>\n<div class=\"code-label \" title=\"/etc/environment\">/etc/environment</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">LC_ALL=en_US.UTF-8\nLC_CTYPE=en_US.UTF-8\nLANG=en_US.UTF-8\n</code></pre>\n<p>Guarde y cierre el archivo.</p>\n\n<p>Reinicie su servidor para aplicar todos los cambios:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo reboot\n</li></ul></code></pre>\n<p>Dé a su servidor unos minutos para reiniciarse y, luego, volver a <code>ssh</code>. Ya está listo para instalar su base de datos.</p>\n\n<h2 id=\"paso-3-instalar-mariadb-10-4\">Paso 3: Instalar MariaDB 10.4</h2>\n\n<p>Ahora, añadirá MariaDB a su pila de servidores. ERPNext 12 requiere MariaDB 10.2+, pero la versión incluida en el repositorio oficial de Ubuntu 18.04 es 10.1, lo que significa que deberá instalar una versión superior. A los efectos de esta guía, utilizará la versión estable más reciente de MariaDB, que, en el momento de escribir este artículo, es la versión 10.4.</p>\n\n<p>Para instalar MariaDB 10.4 en Ubuntu 18.04, deberá agregar la clave de firma y el repositorio apropiados. Puede encontrar esta información en el <a href=\"https://downloads.mariadb.org/mariadb/repositories/#mirror=klaus\">asistente del repositorio de MariaDB Foundation</a>. Vaya a esta URL en su navegador web. Ahora, debajo de <strong>1. Elija un Distro</strong>, haga clic en <strong>Ubuntu</strong>. Aparecerá una segunda columna titulada <strong>2. Seleccione una versión</strong>. Debajo de este título, haga clic en <strong>18.04 LTS &ldquo;bionic&rdquo;</strong>. A continuación, aparecerá una tercera columna titulada <strong>3.Elija una versión</strong>. Debajo, haga clic en <strong>10.4 stable</strong>. A continuación, aparecerá una tercera columna titulada <strong>4.Elija un espejo</strong>. Elija un espejo basado en su ubicación y, luego, MariaDB mostrará los comandos apropiados para su instalación personalizada.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_0.png\" alt=\"Asistente del repositorio de MariaDB\"></p>\n\n<p>Ejecute los tres comandos rellenados, que agregarán correctamente el repositorio MariaDB y la clave. Sus comandos tendrán un aspecto similar a estos:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt-get install software-properties-common &amp;&amp; sudo apt-key adv --fetch-keys <span class=\"highlight\">'https://mariadb.org/mariadb_release_signing_key.asc'</span> &amp;&amp; sudo add-apt-repository 'deb [arch=amd64,arm64,ppc64el] <span class=\"highlight\">http://mirror.klaus-uwe.me/mariadb/repo/10.4/ubuntu</span> bionic main'\n</li></ul></code></pre>\n<p>Una vez que haya terminado de agregar el repositorio, instale MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install mariadb-server\n</li></ul></code></pre>\n<p>Después de instalar <code>mariadb-server</code>, instale los siguientes paquetes:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install libmysqlclient-dev python3-mysqldb\n</li></ul></code></pre>\n<p>ERPNext 12 es una aplicación Python y, por lo tanto, requiere la biblioteca <code>python3-mysqldb</code> para la gestión de la base de datos. En relación con <code>libmysqlclient-dev</code>, <code>mariadb-client</code> y <code>libmariadbclient18</code>: esos paquetes permiten a los usuarios comunicarse con el servicio MariaDB. <code>ntpdate</code> y <code>libdate-manip-perl</code> se utilizan para la sincronización de tiempo del servidor.</p>\n\n<p>A continuación, añada una capa de seguridad básica al servidor de MariaDB ejecutando la secuencia de comandos <code>mysql_secure_installation</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql_secure_installation\n</li></ul></code></pre>\n<p>La secuencia de comandos <code>mysql_secure_installation</code> le hará varias preguntas:</p>\n\n<ul>\n<li>Primero, le solicitará la contraseña <strong>root</strong>, pero como todavía no hay ninguna contraseña configurada, presione <code>ENTER</code>.</li>\n<li>A continuación, deberá decidir si usa la autenticación Unix o no. Conteste <code>Y</code> para aceptar este método de autenticación.</li>\n<li>A continuación, cuando se le pregunte si desea cambiar la contraseña <strong>root</strong> de MariaDB, responda <code>N</code>. Se recomienda usar la contraseña predeterminada junto con la autenticación de Unix en los sistemas basados en Ubuntu, dado que la cuenta <strong>root</strong> está estrechamente relacionada con tareas automatizadas de mantenimiento del sistema.</li>\n<li>Las preguntas restantes están relacionadas con la eliminación de usuarios anónimos de la base de datos, la restricción de inicio de sesión remoto de la cuenta <strong>root</strong> en el host local, la eliminación de la base de datos de prueba y la recarga de las tablas de privilegios. Puede responder <code>Y</code> a todas estas preguntas.</li>\n</ul>\n\n<p>Después de completar la secuencia de comandos <code>mysql_secure_installation</code>, MariaDB comenzará a ejecutarse utilizando su configuración predeterminada. En la instalación estándar de ERPNext, se utiliza el usuario <strong>root</strong> de MariaDB para todas las operaciones de la base de datos. Si bien este enfoque puede ser conveniente en las configuraciones de servidores individuales, no se considera una buena práctica de seguridad. Por tanto, en la siguiente sección, aprenderá a evitar este problema al crear un nuevo usuario con privilegios especiales.</p>\n\n<h3 id=\"crear-un-usuario-superadministrador-de-mariadb\">Crear un usuario superadministrador de MariaDB</h3>\n\n<p>ERPNext espera utilizar el usuario <strong>root</strong> de MariaDB para administrar las conexiones con la base de datos, pero esto no siempre es ideal. Para solucionar esta limitación y permitir que un usuario no root administre MariaDB, tendrá que crear una base de datos con el nombre del usuario de forma manual. Luego, podrá asignarle privilegios especiales al usuario nuevo para que pueda realizar operaciones en la base de datos de ERPNext.</p>\n\n<p>Abra la línea de comandos de MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql\n</li></ul></code></pre>\n<p>Ahora, cree una nueva base de datos nueva con el nombre del usuario al que desea asignar las conexiones de MariaDB. Este tutorial utilizará <code><span class=\"highlight\">sammy</span></code>, pero puede elegir su propio nombre:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">CREATE DATABASE <span class=\"highlight\">sammy</span>;\n</li></ul></code></pre>\n<p>Confirme que la base de datos se haya creado utilizando esta instrucción SQL:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SHOW DATABASES;\n</li></ul></code></pre>\n<p>Verá un resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| <span class=\"highlight\">sammy</span>             |\n+--------------------+\n</code></pre>\n<p>Ahora, cree el usuario de MariaDB, <code><span class=\"highlight\">sammy</span></code>, con privilegios similares como <strong>root</strong> y asígnele al usuario la contraseña segura que desee. Conserve la contraseña en un lugar seguro; la necesitará más adelante:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">GRANT ALL PRIVILEGES ON *.* TO '<span class=\"highlight\">sammy</span>'@'%' IDENTIFIED BY '<span class=\"highlight\">mariadb_password</span>' WITH GRANT OPTION;\n</li></ul></code></pre>\n<p>Ahora, confirme tanto la creación del usuario como los privilegios del usuario nuevo:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SELECT host, user, Super_priv FROM mysql.user;\n</li></ul></code></pre>\n<p>Verá un resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+-----------+-------+------------+\n| Host      | User  | Super_priv |\n+-----------+-------+------------+\n| localhost | root  | Y          |\n| localhost | mysql | Y          |\n| %         | <span class=\"highlight\">sammy</span> | <span class=\"highlight\">Y</span>          |\n+-----------+-------+------------+\n3 rows in set (0.001 sec)\n</code></pre>\n<p>A continuación, utilice flush privileges para aplicar todos los cambios:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">FLUSH PRIVILEGES;\n</li></ul></code></pre>\n<p>Cuando termine, salga de la sesión:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">exit\n</li></ul></code></pre>\n<p>Ahora que ha creado un usuario de la base de datos, solo deberá ajustar MariaDB para garantizar el funcionamiento correcto de ERPNext 12. Afortunadamente, el equipo de ERPNext proporciona una excelente plantilla de configuración que utilizará como punto de partida para su implementación. En la siguiente sección, aprenderá a configurar correctamente la base de datos de MariaDB utilizando esa plantilla.</p>\n\n<h2 id=\"paso-4-configurar-mariadb-para-erpnext\">Paso 4: Configurar MariaDB para ERPNext</h2>\n\n<p>Ahora que instaló y aseguró MariaDB, es momento de configurarlo para las conexiones con ERPNext.</p>\n\n<p>Primero, detenga <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop mariadb\n</li></ul></code></pre>\n<p>Ahora, utilice <code>nano</code> o el editor de texto que prefiera para crear un archivo de configuración de MariaDB, denominado <code>settings.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/conf.d/settings.cnf\n</li></ul></code></pre>\n<p>Ahora, añada la plantilla de configuración de ERPNext:</p>\n<div class=\"code-label \" title=\"/etc/mysql/conf.d/settings.cnf\">/etc/mysql/conf.d/settings.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\n\n# GENERAL #\nuser                           = mysql\ndefault-storage-engine         = InnoDB\nsocket                         = /var/lib/mysql/mysql.sock\npid-file                       = /var/lib/mysql/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n# SAFETY #\nmax-allowed-packet             = 256M\nmax-connect-errors             = 1000000\ninnodb                         = FORCE\n\n# DATA STORAGE #\ndatadir                        = /var/lib/mysql/\n\n# BINARY LOGGING #\nlog-bin                        = /var/lib/mysql/mysql-bin\nexpire-logs-days               = 14\nsync-binlog                    = 1\n\n# REPLICATION #\nserver-id                      = 1\n\n# CACHES AND LIMITS #\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\nquery-cache-type               = 0\nquery-cache-size               = 0\nmax-connections                = 500\nthread-cache-size              = 50\nopen-files-limit               = 65535\ntable-definition-cache         = 4096\ntable-open-cache               = 10240\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\ninnodb-log-file-size           = 512M\ninnodb-flush-log-at-trx-commit = 1\ninnodb-file-per-table          = 1\ninnodb-buffer-pool-size        = 5462M\ninnodb-file-format             = barracuda\ninnodb-large-prefix            = 1\ncollation-server               = utf8mb4_unicode_ci\ncharacter-set-server           = utf8mb4\ncharacter-set-client-handshake = FALSE\nmax_allowed_packet             = 256M\n\n# LOGGING #\nlog-error                      = /var/lib/mysql/mysql-error.log\nlog-queries-not-using-indexes  = 0\nslow-query-log                 = 1\nslow-query-log-file            = /var/lib/mysql/mysql-slow.log\n\n[mysql]\ndefault-character-set = utf8mb4\n\n[mysqldump]\nmax_allowed_packet=256M\n\n!includedir /etc/mysql/mariadb.conf.d/\n</code></pre>\n<p>Guarde y cierre el archivo. Para obtener información más detallada sobre estas configuraciones, <a href=\"https://github.com/frappe/erpnext/wiki/MySQL-configuration-file\">consulte este archivo de plantilla en el repositorio de Github de ERPNext</a>. Es un punto de partida útil para explorar estas opciones.</p>\n\n<p>A continuación, cree otro archivo llamado <code>erpnext.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/mariadb.conf.d/erpnext.cnf\n</li></ul></code></pre>\n<p>Añada el siguiente contenido al archivo:</p>\n<div class=\"code-label \" title=\"/etc/mysql/mariadb.conf.d/erpnext.cnf\">/etc/mysql/mariadb.conf.d/erpnext.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nbind-address    = 0.0.0.0\n</code></pre>\n<p>El primer archivo de configuración, <code>/etc/mysql/conf.d/settings.cnf</code>, complementa y también anula algunos de los valores incluidos en la configuración predeterminada de MariaDB, ubicada en <code>/etc/mysql/my.cnf</code>. Este archivo le proporciona una plantilla específica que mejora en gran medida el rendimiento de la base de datos de ERPNext. Sin embargo, tenga en cuenta que, si bien esta plantilla es un excelente punto de partida, puede mejorar aún más el rendimiento de MariaDB al ajustar estos parámetros para adaptarlos a sus necesidades.</p>\n\n<p>El segundo archivo, <code>/etc/mysql/mariadb.conf.d/erpnext.cnf</code>, también anula algunos valores al introducir información específica sobre su conexión con la base de datos.</p>\n\n<h3 id=\"prueba-de-la-conexión-con-mariadb\">Prueba de la conexión con MariaDB</h3>\n\n<p>Como ERPNext utiliza la conexión con la base de datos para casi todas sus operaciones internas, es conveniente probar la conexión antes de continuar.</p>\n\n<p>Inicie <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mariadb\n</li></ul></code></pre>\n<p>Para probar la conexión, puede usar el siguiente comando. Recuerde sustituir <code><span class=\"highlight\">sammy</span></code> y <code><span class=\"highlight\">mariadb_password</span></code> por sus credenciales:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mysql --user <span class=\"highlight\">sammy</span> --password <span class=\"highlight\">mariadb_password</span> --host=localhost --protocol=tcp --port=3306 test\n</li></ul></code></pre>\n<p>Verá un resultado que muestra el contenido de ayuda básico de MariaDB y varios parámetros. Esto significa que su conexión se estableció correctamente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>mysql  Ver 15.1 Distrib 10.4.13-MariaDB, for debian-linux-gnu (x86_64) using readline 5.2\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nUsage: mysql [OPTIONS] [database]\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\n\n...\n\n  --ssl-verify-server-cert\n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n\n...\n\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\nbinary-mode                       FALSE\nconnect-expired-password          FALSE\n</code></pre>\n<p>Si necesita modificar los ajustes de MariaDB o corregir errores, recuerde volver a cargar el servicio utilizando el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mariadb\n</li></ul></code></pre>\n<p>Cuando haya terminado, habilite MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mariadb\n</li></ul></code></pre>\n<p>Ahora que probó la conexión con la base de datos, puede proceder con la instalación de su aplicación ERPNext.</p>\n\n<h2 id=\"paso-5-configurar-erpnext-12\">Paso 5: Configurar ERPNext 12</h2>\n\n<p>Ahora que el backend de su base de datos está listo, puede seguir configurando su aplicación web ERPNext. En esta sección, aprenderá a instalar y configurar todos los componentes que requiere ERPNext 12 e instalará la aplicación.</p>\n\n<p>Comience por preparar el servidor con todos los paquetes del sistema que requiere ERPNext 12. Instale las dependencias de todo el sistema utilizando el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo DEBIAN_FRONTEND=noninteractive apt install -y curl build-essential mariadb-client python3-setuptools python3-dev libffi-dev python3-pip libcurl4 dnsmasq fontconfig git htop libcrypto++-dev libfreetype6-dev liblcms2-dev libwebp-dev libxext6 libxrender1 libxslt1-dev libxslt1.1 libffi-dev ntpdate postfix python3-dev python-tk screen vim xfonts-75dpi xfonts-base zlib1g-dev apt-transport-https libsasl2-dev libldap2-dev libcups2-dev pv libjpeg8-dev libtiff5-dev tcl8.6-dev tk8.6-dev libssl1.0-dev python3-mysqldb libdate-manip-perl logwatch\n</li></ul></code></pre>\n<p>La variable <code>DEBIAN_FRONTEND=noninteractive</code> se ha trasladado al comando de instalación para evitar los mensajes de Postfix. Para obtener información detallada sobre la configuración de Postfix, consulte nuestra guía <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-postfix-on-ubuntu-18-04\">Cómo instalar y configurar Postfix en Ubuntu 18.04</a>.</p>\n\n<p>A continuación, actualice <code>pip3</code> e instale las últimas versiones de tres módulos de Python adicionales que requiere ERPNext:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo -H python3 -m pip install --upgrade setuptools cryptography psutil\n</li></ul></code></pre>\n<p>Ahora que ha instalado todas las dependencias globales necesarias, instalará todos los servicios y las bibliotecas que requiere ERPNext 12.</p>\n\n<h3 id=\"configuración-de-node-js-y-yarn\">Configuración de Node.js y Yarn</h3>\n\n<p>ERPNext 12 funciona con la versión 8, o una más reciente, del entorno de servidor de Node.js. De hecho, a la fecha de redacción de este artículo, la secuencia de comandos oficial de ERPNext <code>easy_install</code> utiliza Node 8. Sin embargo, desde una perspectiva de seguridad, es conveniente instalar una versión más reciente, dado que Node 8 llegó al final de su vida útil (EOL) en 2020 y, por lo tanto, no se lanzarán más parches de seguridad. A efectos de esta guía, se instalará Node.js versión 12 LTS junto con los administradores de paquetes correspondientes <code>npm</code> y <code>yarn</code>. Tenga en cuenta que el marco de trabajo de Frappe utiliza <code>yarn</code> para la instalación de dependencias. Si decide utilizar un método de instalación alternativo, asegúrese de que la versión 1.12+ de <code>yarn</code> quede instalada en su sistema.</p>\n\n<p>Añada el repositorio de NodeSource a su sistema:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -sL https://deb.nodesource.com/setup_12.x -o nodesource_setup.sh\n</li></ul></code></pre>\n<p>Ahora, puede revisar el contenido de la secuencia de comandos descargada:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano nodesurce_setup.sh\n</li></ul></code></pre>\n<p>Una vez que esté satisfecho, puede ejecutar la secuencia de comandos:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bash nodesource_setup.sh\n</li></ul></code></pre>\n<p>Esta secuencia de comandos actualizará automáticamente la lista <code>apt</code>. Ahora, puede instalar <code>nodejs</code> en su servidor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install nodejs\n</li></ul></code></pre>\n<p>A continuación, instale <code>yarn</code> de modo general usando el paquete <code>npm</code> incluido:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo npm install -g yarn\n</li></ul></code></pre>\n<p>Ahora que tiene Node instalado, puede proceder con la configuración de <code>wkhtmltopdf</code> para su plataforma.</p>\n\n<p>ERPNext utiliza la herramienta de código abierto <code>wkhtmltopdf</code> para convertir contenido de HTML a PDF utilizando el motor de representación Qt WebKit. Esta característica se utiliza principalmente para imprimir facturas, cotizaciones y otros informes. ERPNext 12 requiere una versión específica de <code>wkhtmltopdf</code>: <code>0.12.5</code> con Qt corregido.</p>\n\n<p>Para instalar <code>wkhtmltopdf</code>, comience por cambiar a un directorio adecuado para descargar el paquete, en este caso <code>/tmp</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /tmp\n</li></ul></code></pre>\n<p>Descargue la versión adecuada de <code>wkhtmltopdf</code> y el paquete correspondiente para Ubuntu 18.04 de la página del proyecto:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.5/wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Ahora, instale el paquete utilizando la herramienta <code>dpkg</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo dpkg -i wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>A continuación, copie todos los ejecutables pertinentes a su directorio <code>/usr/bin/</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /usr/local/bin/wkhtmlto* /usr/bin/\n</li></ul></code></pre>\n<p>Cuando los archivos estén en su lugar, cambie sus permisos para que se puedan ejecutar:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod a+x /usr/bin/wk*\n</li></ul></code></pre>\n<p>Ahora que <code>wkhtmltopdf</code> está instalado correctamente, añada Redis a la pila de su base de datos.</p>\n\n<h3 id=\"instalar-redis\">Instalar Redis</h3>\n\n<p>ERPNext 12 utiliza Redis para mejorar el rendimiento de MariaDB. Concretamente, <a href=\"https://discuss.erpnext.com/t/why-erpnext-need-redis/6194\">ayuda con el caché</a>.</p>\n\n<p>Primero, instale Redis desde el repositorio oficial de Ubuntu 18.04:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install redis-server\n</li></ul></code></pre>\n<p>A continuación, habilite Redis en el inicio:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable redis-server\n</li></ul></code></pre>\n<p>Ahora que ha añadido Redis a su pila, vamos a tomarnos un momento para resumir lo que ha logrado hasta ahora. Hasta este punto, ha instalado todos los componentes principales que necesita ERPNext 12, que incluyen:</p>\n\n<ul>\n<li>Un backend de base de datos de MariaDB</li>\n<li>El entorno de servidor Node.js de JavaScript</li>\n<li>El administrador de paquetes Yarn</li>\n<li>Una caché de base de datos Redis</li>\n<li>El generador de documentos PDF <code>wkhtmltopdf</code></li>\n</ul>\n\n<p>Ya sea que esté instalando el sistema ERP para un entorno de desarrollo o de producción, está listo para continuar con el siguiente paso: instalar el marco de pila completa de Frappe y la aplicación web ERPNext 12.</p>\n\n<h2 id=\"paso-6-instalar-la-cli-bench-de-frappe\">Paso 6: Instalar la CLI bench de Frappe</h2>\n\n<p>Ahora que instaló todos los requisitos de pila de ERPNext, puede aprovechar la flexibilidad de la utilidad de línea de comandos <code>bench</code> de Frappe. La CLI <code>bench</code> se diseñó con el objetivo de ayudar a los usuarios en el proceso de instalación, configuración y administración de aplicaciones basadas en el marco de trabajo Frappe, como ERPNext. En las siguientes secciones, instalará la CLI <code>bench</code> y, luego, la utilizará para completar el proceso de configuración de ERPNext 12.</p>\n\n<p>Asegúrese de que el usuario de Frappe (en este caso, <code><span class=\"highlight\">sammy</span></code>) tenga los derechos apropiados en su directorio <code>home</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chown <span class=\"highlight\">sammy</span> -R /home/<span class=\"highlight\">sammy</span>\n</li></ul></code></pre>\n<p>Ahora, clone el repositorio <code>frappe/bench</code> y colóquelo su directorio de inicio. Recuerde sustituir <code><span class=\"highlight\">sammy</span></code> con su nombre de usuario del sistema:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone https://github.com/frappe/bench /home/<span class=\"highlight\">sammy</span>/.bench --depth 1 --branch master\n</li></ul></code></pre>\n<p>Instale la CLI <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo pip3 install -e /home/<span class=\"highlight\">sammy</span>/.bench\n</li></ul></code></pre>\n<p>En esta guía, se asume que está instalando ERPNext 12 para escenarios de prueba o producción y, por lo tanto, está utilizando la rama <code>master</code>. Pero si tiene la intención de desarrollar aplicaciones o módulos de ERPNext personalizados, la rama <code>develop</code> podría ser una mejor opción. En cualquier caso, está listo para instalar el marco de trabajo Frappe. Este será su último paso antes de instalar ERPNext.</p>\n\n<h3 id=\"configurar-el-entorno-del-marco-de-trabajo-frappe\">Configurar el entorno del marco de trabajo Frappe</h3>\n\n<p>En esta sección, creará un <a href=\"https://frappe.io/docs/user/en/architecture\">entorno de Frappe</a> utilizando la CLI <code>bench</code>.</p>\n\n<p>Durante la instalación de Frappe, puede exceder el límite del monitor de archivos de Ubuntu, que está establecido en 8192 por defecto. Para evitar este problema, establezca un límite superior utilizando el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p\n</li></ul></code></pre>\n<p>A continuación, inicie Frappe Framework 12. Sustituya a Sammy por su nombre de usuario del sistema:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench init /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> --frappe-path https://github.com/frappe/frappe --frappe-branch version-12 --python python3\n</li></ul></code></pre>\n<p>Durante la ejecución, puede ver un error sobre su ruta y varias advertencias. Deje que el proceso continúe hasta el final. Cuando haya terminado, verá un resultado similar al siguiente, lo que indica que su entorno se creó correctamente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nDone in 82.23s.\nINFO:bench.utils:setting up backups\nno crontab for <span class=\"highlight\">sammy</span>\nSUCCESS: Bench /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> initialized\n</code></pre>\n<p><span class='note'><strong>Nota:</strong> el proceso <code>bench init</code> puede detenerse si se encuentra un error <code>spawn ENOMEM</code>. Este error se provoca cuando su sistema se queda sin memoria. Para continuar, debe solucionarlo instalando más memoria física o asignando espacio SWAP.<br></span></p>\n\n<p>Analicemos con mayor detalle el comando utilizado para crear el entorno:</p>\n\n<ul>\n<li><code>/home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span></code> es la ruta donde se instalarán Frappe Framework, los sitios web y las aplicaciones relacionadas. En este ejemplo, se creará un nuevo directorio, denominado <code><span class=\"highlight\">frappe-bench</span></code>, para alojar todos los archivos necesarios.</li>\n<li><code>-frappe-path</code> apunta al repositorio de Frappe, que, en este caso, es el repositorio oficial de Github.</li>\n<li><code>--frappe-branch</code> es la versión de Frappe que se instalará. Como desea instalar ERPNext 12, la versión seleccionada es Frappe 12.</li>\n<li><code>--python</code> es la versión de Python que se utilizará. ERPNext 12 requiere Python 3.6 o superior. Sin embargo, las versiones anteriores siguen utilizando Python 2.7.</li>\n</ul>\n\n<p>Para obtener más información sobre los comandos de la CLI <code>bench</code>, consulte la <a href=\"https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html\">Hoja de trucos de comandos de Bench</a>.</p>\n\n<p>La flexibilidad que ofrece el marco de trabajo de Frappe va mucho más allá del uso de entornos aislados. También puede crear distintos sitios web e instalar aplicaciones en ellos.</p>\n\n<h2 id=\"paso-7-instalar-la-aplicación-web-erpnext-12\">Paso 7: Instalar la aplicación web ERPNext 12</h2>\n\n<p>En esta sección, configurará un sitio basado en Frappe e instalará la aplicación ERPNext 12 en él.</p>\n\n<p>Posiciónese en el directorio donde se inició Frappe.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Descargue ERPNext 12 desde su repositorio utilizando la CLI <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench get-app erpnext https://github.com/frappe/erpnext --branch version-12\n</li></ul></code></pre>\n<p>A continuación, cree el sitio nuevo, sustituyendo <code><span class=\"highlight\">your_domain</span></code> por el dominio que haya asociado con la IP de este servidor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench new-site <span class=\"highlight\">your_domain</span> --admin-password '<span class=\"highlight\">erpnext_admin_password</span>' --mariadb-root-username <span class=\"highlight\">sammy</span> --mariadb-root-password '<span class=\"highlight\">mariadb_password</span>'\n</li></ul></code></pre>\n<p>Tomémonos un momento para revisar las opciones utilizadas en el comando anterior:</p>\n\n<ul>\n<li><code>bench new-site</code> crea un sitio nuevo basado en Frappe Framework.</li>\n<li><code><span class=\"highlight\">your_domain</span></code> es el nombre del sitio nuevo. Asegúrese de que el DNS de su dominio tenga un registro A apuntado a la IP de su servidor.</li>\n<li><code>&amp;lt;^&amp;gt;erpnext_admin_password&amp;lt;^&amp;gt;** es la contraseña deseada para el usuario **administrador</code> de ERPNext. Conserve esta contraseña en un lugar seguro; la necesitará en breve.</li>\n<li><code><span class=\"highlight\">mariadb_password</span></code> es la contraseña que creó al principio de la guía para el usuario de MariaDB <code><span class=\"highlight\">sammy</span></code>.</li>\n</ul>\n\n<p>A continuación, instale la aplicación ERPNext en el sitio:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench --site <span class=\"highlight\">your_domain</span> install-app erpnext\n</li></ul></code></pre>\n<p>Cuando la instalación se haya completado, tendrá una aplicación ERPNext 12 en funcionamiento. Ahora, vamos a probarla utilizando un comando <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench start\n</li></ul></code></pre>\n<p>El comando anterior iniciará una consola de monitoreo en tiempo real que le mostrará varios mensajes relacionados con el servidor web y otros servicios. Abra un navegador web y diríjase a <code>localhost:8000</code> (para instalaciones locales) o <code><span class=\"highlight\">your_domain</span>:8000</code> (si está utilizando un servidor remoto). Verá la pantalla de inicio de sesión de ERPNext (procederemos con el inicio de sesión y la configuración en un paso posterior, una vez que el sitio esté listo para producción).</p>\n\n<p>Después de consultar su implementación de prueba, regrese a su terminal y presione <code>CTRL+C</code>. De esta manera, detendrá ERPNext y saldrá de la consola de monitoreo.</p>\n\n<p>Si su objetivo principal es crear módulos o modificar ERPNext 12, puede detenerse en este punto. No se requieren más componentes para fines de desarrollo. Sin embargo, si necesita un sistema listo para producción que no requiera inicialización manual, deberá instalar y configurar algunos componentes adicionales. Este será su siguiente paso.</p>\n\n<h2 id=\"paso-8-configurar-erpnext-12-para-producción\">Paso 8: Configurar ERPNext 12 para producción</h2>\n\n<p>Aunque la aplicación ERPNext 12 está lista, el sistema en su conjunto aún no está completamente preparado para la producción. Para garantizar la fiabilidad y la seguridad de ERPNext, deberá habilitar algunos servicios adicionales:</p>\n\n<ul>\n<li><strong>Fail2ban</strong> proporciona una capa de protección adicional contra los intentos de fuerza bruta de usuarios y bots maliciosos.</li>\n<li><strong>Nginx</strong> funciona principalmente como proxy web, redireccionando todo el tráfico del puerto <code>8000</code> al puerto <code>80</code> (HTTP) o <code>443</code> (HTTPS)</li>\n<li><strong>Supervisor</strong> garantiza que los procesos clave de ERPNext se ejecuten constantemente y los reinicia según sea necesario.</li>\n</ul>\n\n<p>Hasta este punto, ha instalado y configurado ERPNext 12 de forma manual, lo que le ha permitido personalizar el proceso para adaptarlo cualquier caso de uso en particular. Sin embargo, durante el resto de la configuración de producción, puede aprovechar la conveniencia de la CLI <code>bench</code> y dejar que automatice la instalación y la configuración de estos servicios restantes.</p>\n\n<p>Asegúrese de estar posicionado en el directorio de trabajo de Frappe:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Ahora, utilice el siguiente comando para finalizar la configuración de ERPNext 12 para producción:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bench setup production <span class=\"highlight\">sammy</span> --yes\n</li></ul></code></pre>\n<p>El comando anterior instala y configura Nginx, Supervisor y Fail2Ban y establece a <code><span class=\"highlight\">sammy</span></code> como propietario del entorno de producción.</p>\n\n<p>Estos son los archivos de configuración que crea el comando <code>bench</code>:</p>\n\n<ul>\n<li>Dos archivos de configuración de Nginx ubicados en <code>/etc/nginx/nginx.conf</code> y <code>/etc/nginx/conf.d/<span class=\"highlight\">frappe-bench</span>.conf</code></li>\n<li>Una proxy jail de Fail2Ban ubicada en <code>/etc/fail2ban/jail.d/nginx-proxy.conf</code> y un filtro situado en <code>/etc/fail2ban/filter.d/nginx-proxy.conf</code></li>\n</ul>\n\n<p>Estas configuraciones predeterminadas bastarán para este tutorial, pero puede explorar y ajustar estos archivos para adaptarlos a sus requisitos. Puede detener todos los servicios con el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl stop all\n</li></ul></code></pre>\n<p>Y, luego, cuando esté listo, puede reiniciar sus servicios:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl start all\n</li></ul></code></pre>\n<p>Ahora, está listo para probar su instalación.</p>\n\n<h3 id=\"probar-la-instalación-de-erpnext-12\">Probar la instalación de ERPNext 12</h3>\n\n<p>Primero, verifique que los servicios de producción clave se ejecutan utilizando el siguiente comando <code>systemctl</code> y, luego, lo conducen a <code>grep</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">systemctl list-unit-files | grep 'fail2ban\\|nginx\\|supervisor'\n</li></ul></code></pre>\n<p>Verá un resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>fail2ban.service                       enabled\nnginx.service                          enabled\nsupervisor.service                     enabled\n</code></pre>\n<p>Una vez que haya confirmado que todo funciona adecuadamente, puede probar ERPNext 12 en su servidor activo. Abra el navegador que prefiera y vaya al dominio en el que esté alojada su aplicación ERPNext 12.</p>\n\n<p>Después de unos segundos, debería ver la pantalla de inicio de sesión de ERPNext 12. Utilice el nombre de usuario <strong>Administrator</strong> y la contraseña <code><span class=\"highlight\">erpnext_admin_password</span></code> que creó anteriormente.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_1.png\" alt=\"Pantalla de inicio de sesión de ERPNext\"></p>\n\n<p>En la siguiente pantalla, verá un menú desplegable en el que puede seleccionar el idioma de la IU para la aplicación:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_2.png\" alt=\"Selección de idioma\"></p>\n\n<p>Tras la selección de idiomas, ERPNext le solicitará que indique su país, zona horaria y moneda:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_3.png\" alt=\"Seleccione su región\"></p>\n\n<p>Una vez que haya completado la información de su región, podrá crear su primer usuario de ERPNext. La información que proporcione se utilizará en las credenciales de inicio de sesión del usuario.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_4.png\" alt=\"Primer usuario de ERPNext\"></p>\n\n<p>En la siguiente pantalla, se le preguntará sobre lo que ERPNext denomina <strong>Dominios</strong>. Si no está seguro de cuál es su dominio, seleccione <strong>Distribución</strong> y haga clic en el botón <strong>Siguiente</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_5.png\" alt=\"Seleccione sus dominios\"></p>\n\n<p>A continuación, deberá proporcionar el nombre de la empresa y una abreviatura.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_6.png\" alt=\"Nombre de la empresa\"></p>\n\n<p>En la última pantalla, ERPNext le pedirá que indique la actividad de su empresa, el nombre de su banco, el tipo de plan de cuentas y el período del año fiscal. Podrá ingresar otros bancos más adelante. Por ahora, complete todos los campos que desee y, luego, haga clic en el botón <strong>Completar la configuración</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_7.png\" alt=\"Información financiera\"></p>\n\n<p>A continuación, verá una barra de progreso.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_8.png\" alt=\"Configurar ERPNext\"></p>\n\n<p>Una vez que terminado el proceso de configuración, verá el panel de control principal de ERPNext 12.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_9.png\" alt=\"Panel de control de ERPNext 12\"></p>\n\n<p>Ha instalado y configurado por completo una aplicación ERPNext 12.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>Ahora que ha instalado correctamente su aplicación ERPNext 12, es posible que desee comenzar a implementar el sistema para las necesidades de su empresa. Una buena manera de comenzar a hacerlo es hacer clic en el botón <strong>Primeros pasos</strong> del panel de control de ERPNext. ERPNext lo ayudará a configurar la plataforma para todas sus necesidades empresariales y de comercio electrónico.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_10.png\" alt=\"Primeros pasos\"></p>\n\n<p>Es posible que también desee aumentar la velocidad de ERPNext. Si es así, puede consultar <a href=\"https://github.com/frappe/erpnext/wiki/ERPNext-Performance-Tuning\">información sobre los ajustes de rendimiento de ERPNext</a>, que lo orientará sobre las mejores prácticas y cómo depurar problemas relacionados con el rendimiento.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:23 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67031/erpnext_0.png","linkMd5":"03d61cd2414a172d150bf26064b36b07","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","destWidth":3584,"destHeight":2022,"sourceBytes":966173,"destBytes":375664,"author":"Damaso Sanoja","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67031/erpnext_0.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","https://assets.digitalocean.com/articles/67031/erpnext_1.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_3/2020/08/31/07-48-32-714_e6b982f1d7fe90cd.webp","https://assets.digitalocean.com/articles/67031/erpnext_2.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn94@2020_6/2020/08/31/07-48-32-235_5dfe5b1d282ec7f1.webp","https://assets.digitalocean.com/articles/67031/erpnext_3.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_3/2020/08/31/07-48-31-862_07721efc54737d85.webp","https://assets.digitalocean.com/articles/67031/erpnext_4.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn45@2020_1/2020/08/31/07-48-32-664_c2f620996c337847.webp","https://assets.digitalocean.com/articles/67031/erpnext_5.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn13@2020_2/2020/08/31/07-48-33-137_5b1867188f4eb783.webp","https://assets.digitalocean.com/articles/67031/erpnext_6.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn25@2020_3/2020/08/31/07-48-31-288_1f4bd367e3868d6d.webp","https://assets.digitalocean.com/articles/67031/erpnext_7.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn14@2020_2/2020/08/31/07-48-31-596_2e4f2cf158e027fc.webp","https://assets.digitalocean.com/articles/67031/erpnext_8.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn65@2020_2/2020/08/31/07-48-31-323_2f22aaf79a58e762.webp","https://assets.digitalocean.com/articles/67031/erpnext_9.png":null,"https://assets.digitalocean.com/articles/67031/erpnext_10.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn97@2020_3/2020/08/31/07-48-32-254_dccc24f52c8f5d64.webp"},"publishedOrCreatedDate":1598860106981},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"How To Set Up a JupyterLab Environment on Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-jupyterlab-environment-on-ubuntu-18-04","description":"<p><em>The author selected <a href=\"https://www.brightfunds.org/organizations/united-nations-foundation-inc\">the United Nations Foundation</a> to receive a donation as part of the <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> program.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://jupyterlab.readthedocs.io\">JupyterLab</a> is a highly feature-rich UI that makes it easy for users, particularly in the fields of Data Science and AI, to perform their tasks. The JupyterLab environments provide a productivity-focused redesign of <a href=\"https://jupyter-notebook.readthedocs.io/en/stable/index.html\">Jupyter Notebook</a>. It introduces tools such as a built-in HTML viewer and CSV viewer along with features that unify several discrete features of Jupyter Notebooks onto the same screen.</p>\n\n<p>In this tutorial, you’ll install and set up JupyterLab on your Ubuntu 18.04 server. You&rsquo;ll also be configuring your server to be able to connect to the JupyterLab instance remotely from any web browser, securely, using a domain name.</p>\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\n<p>In order to complete this tutorial, you’ll need:</p>\n\n<ul>\n<li>An Ubuntu 18.04 server with a non-root user account with <code>sudo</code> privileges using this <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Initial Server Setup Guide</a>.</li>\n<li>An installation of the Python Anaconda Distribution on your server. You can use the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-the-anaconda-python-distribution-on-ubuntu-18-04\">How To Install the Anaconda Python Distribution on Ubuntu 18.04</a> tutorial.</li>\n<li>A registered domain name or sub-domain where you&rsquo;ve access to edit DNS records. This tutorial will use <code><span class=\"highlight\">your_domain</span></code> throughout. You can purchase domains on <a href=\"https://www.namecheap.com/domains/\">Namecheap</a>, get a free domain at <a href=\"http://www.freenom.com/en/index.html\">Freenom</a>, or register a new domain with any registrar of your choice.</li>\n<li>The following DNS records set up for your domain:\n\n<ul>\n<li>An A record with <code><span class=\"highlight\">your_domain</span></code> pointing to your server&rsquo;s public IP address.</li>\n<li>An A record with <code>www.<span class=\"highlight\">your_domain</span></code> pointing to your server&rsquo;s public IP address.\nThis <a href=\"https://www.digitalocean.com/docs/networking/dns/how-to/manage-records/\">How to Create, Edit, and Delete DNS Records</a> documentation can help you in setting up these records.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"step-1-—-setting-up-your-password\">Step 1 — Setting Up Your Password</h2>\n\n<p>In this step you&rsquo;ll set up a password on your JupyterLab installation. It is important to have a password in place since your instance will be publicly accessible.</p>\n\n<p>First, make sure your Anaconda environment is activated. As per the prerequisite tutorial the environment is called <code><span class=\"highlight\">base</span></code>.</p>\n\n<p>To activate the environment, use the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">conda activate <span class=\"highlight\">base</span>\n</li></ul></code></pre>\n<p>Your prompt will change in the terminal to reflect the default Anaconda environment <code><span class=\"highlight\">base</span></code>:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(base)\"><span class=\"highlight\">sammy</span>@<span class=\"highlight\">your_server</span>:~$\n</li></ul></code></pre>\n<p>All future commands in this tutorial will be run within the <code><span class=\"highlight\">base</span></code> environment.</p>\n\n<p>With your Anaconda environment activated, you&rsquo;re ready to set up a password for JupyterLab on your server.</p>\n\n<p>First, let&rsquo;s generate a configuration file for Jupyter:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">jupyter notebook --generate-config\n</li></ul></code></pre>\n<p>You&rsquo;ll receive the following output:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Writing default config to: /home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.py\n</code></pre>\n<p>Both JupyterLab and Jupyter Notebook share the same configuration file.</p>\n\n<p>Now, use the following command to set a password for accessing your JupyterLab instance remotely:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">jupyter notebook password\n</li></ul></code></pre>\n<p>Jupyter will prompt you to provide a password of your choice:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enter password:\nVerify password:\n[NotebookPasswordApp] Wrote hashed password to /home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.json\n</code></pre>\n<p>Jupyter stores the password in a hashed format at <code>/home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.json</code>. You&rsquo;ll need this hashed value in the future.</p>\n\n<p>Finally, use the <code>cat</code> command on the file generated by the previous command to view the hashed password:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cat /home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.json\n</li></ul></code></pre>\n<p>You&rsquo;ll receive an output similar to the following:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.json\">/home/sammy/.jupyter/jupyter_notebook_config.json</div><pre class=\"code-pre \"><code>{\n  \"NotebookApp\": {\n    \"password\": \"<span class=\"highlight\">sha1:your_hashed_password</span>\"\n  }\n}\n</code></pre>\n<p>Copy the value in the <code>password</code> key of the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-work-with-json-in-javascript\">JSON</a> and store it temporarily.</p>\n\n<p>You&rsquo;ve set up a password for your JupyterLab instance. In the next step you&rsquo;ll create a Let&rsquo;s Encrypt certificate for your server.</p>\n\n<h2 id=\"step-2-—-configuring-let-39-s-encrypt\">Step 2 — Configuring Let&rsquo;s Encrypt</h2>\n\n<p>In this step, you&rsquo;ll create a Let&rsquo;s Encrypt certificate for your domain. This will secure your data when you access your JupyterLab environment from your browser.</p>\n\n<p>First, you&rsquo;ll install Certbot to your server. Begin by adding its repository to the apt sources:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo add-apt-repository ppa:certbot/certbot\n</li></ul></code></pre>\n<p>On executing the command, you&rsquo;ll be asked to press <code>ENTER</code> to complete adding the PPA:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>This is the PPA for packages prepared by Debian Let's Encrypt Team and backported for Ubuntu.\n\nNote: Packages are only provided for currently supported Ubuntu releases.\n More info: https://launchpad.net/~certbot/+archive/ubuntu/certbot\nPress [ENTER] to continue or Ctrl-c to cancel adding it.\n</code></pre>\n<p>Press <code>ENTER</code> to continue adding the PPA.</p>\n\n<p>Once the command has finished executing, refresh the apt sources using the <code>apt update</code> command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Next, you&rsquo;ll install Certbot:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install certbot\n</li></ul></code></pre>\n<p>Before you can start running Certbot to generate certificates for your instance, you&rsquo;ll allow access on port <code>:80</code> and port <code>:443</code> of your server, so that Certbot can use these ports to verify your domain name. Port <code>:80</code> is checked for <code>http</code> requests to the server while port <code>:443</code> is used for <code>https</code> requests. Certbot shall be making an <code>http</code> request first and then after obtaining the certficates for your server, it will make an <code>https</code> request, which will be proxied through port <code>:443</code> to the process listening at <code>:80</code> port. This will verify the success of your certificate installation.</p>\n\n<p>First, allow access to port <code>:80</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 80\n</li></ul></code></pre>\n<p>You will receive the following output:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Rule added\nRule added (v6)\n</code></pre>\n<p>Next, allow access to port <code>:443</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 443\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Rule added\nRule added (v6)\n</code></pre>\n<p>Finally, run Certbot to generate certificates for your instance using the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot certonly --standalone\n</li></ul></code></pre>\n<p>The <code>standalone</code> flag directs <code>certbot</code> to run a temporary server for the duration of the verfication process.</p>\n\n<p>It will prompt you for your email:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Saving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator standalone, Installer None\nEnter email address (used for urgent renewal and security notices) (Enter 'c' to\ncancel): <span class=\"highlight\">your_email</span>\n</code></pre>\n<p>Enter a working email and press <code>ENTER</code>.</p>\n\n<p>Next, it will ask you to review and agree to the Terms of Service for Certbot and Let&rsquo;s Encrypt. Review the terms, type <code>A</code> if you accept, and press <code>ENTER</code>:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nPlease read the Terms of Service at\nhttps://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must\nagree in order to register with the ACME server at\nhttps://acme-v02.api.letsencrypt.org/directory\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n(A)gree/(C)ancel: A\n</code></pre>\n<p>It will now prompt you to share your email with the Electronic Frontier Foundation. Type your answer and press <code>ENTER</code>:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nWould you be willing to share your email address with the Electronic Frontier\nFoundation, a founding partner of the Let's Encrypt project and the non-profit\norganization that develops Certbot? We'd like to send you email about our work\nencrypting the web, EFF news, campaigns, and ways to support digital freedom.\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n(Y)es/(N)o: Y/N\n</code></pre>\n<p>Finally, you&rsquo;ll be asked to enter your domain name. Type in your domain name without any protocol specification:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Please enter in your domain name(s) (comma and/or space separated)  (Enter 'c'\nto cancel): <span class=\"highlight\">your_domain</span>\nObtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for <span class=\"highlight\">your_domain</span>\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/privkey.pem\n   Your cert will expire on 2020-09-28. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - Your account credentials have been saved in your Certbot\n   configuration directory at /etc/letsencrypt. You should make a\n   secure backup of this folder now. This configuration directory will\n   also contain certificates and private keys obtained by Certbot so\n   making regular backups of this folder is ideal.\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n</code></pre>\n<p>Certbot will perform domain verification and generate certificates and keys for your domain and store them at <code>/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span></code>.</p>\n\n<p>Now that you have set up your Let&rsquo;s Encrypt certificate, you&rsquo;ll update your JupyterLab configuration file.</p>\n\n<h2 id=\"step-3-—-configuring-jupyterlab\">Step 3 — Configuring JupyterLab</h2>\n\n<p>In this step, you will edit the JupyterLab configuration to make sure it uses the Let&rsquo;s Encrypt certificate you generated in Step 2. You will also make it accessible using the password you set up in Step 1.</p>\n\n<p>First, you need to edit the JupyterLab configuration file at <code>/home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.py</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano /home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.py\n</li></ul></code></pre>\n<p>Now, navigate to the line defining the value for <code>c.NotebookApp.certfile</code> and update it as follows:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.py\">/home/sammy/.jupyter/jupyter_notebook_config.py</div><pre class=\"code-pre \"><code>...\n## The full path to an SSL/TLS certificate file.\nc.NotebookApp.certfile = '/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/fullchain.pem'\n...\n</code></pre>\n<p>Next, find the <code>c.NotebookApp.keyfile</code> variable and set it as shown:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.py\">/home/sammy/.jupyter/jupyter_notebook_config.py</div><pre class=\"code-pre \"><code>...\n## The full path to a private key file for usage with SSL/TLS.\nc.NotebookApp.keyfile = '/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/privkey.pem'\n...\n</code></pre>\n<p><code>c.NotebookApp.certfile</code> and <code>c.NotebookApp.keyfile</code> refer to the SSL Certificate, which will be served when you try to access your server remotely using the <code>https</code> protocol.</p>\n\n<p>Next, navigate to the line defining the <code>c.NotebookApp.ip</code> variable and update as follows:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.py\">/home/sammy/.jupyter/jupyter_notebook_config.py</div><pre class=\"code-pre \"><code>...\n## The IP address the notebook server will listen on.\nc.NotebookApp.ip = '*'\n...\n</code></pre>\n<p><code>c.NotebookApp.ip</code> defines the IPs that can access JupyterLab running your server. You set it to the <code>*</code> wildcard to allow access from any computer you need to access JupyterLab on.</p>\n\n<p>Next, find the <code>c.NotebookApp.open_browser</code> configuration and update it as follows:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.py\">/home/sammy/.jupyter/jupyter_notebook_config.py</div><pre class=\"code-pre \"><code>...\n## Whether to open in a browser after starting. The specific browser used is\n#  platform dependent and determined by the python standard library `webbrowser`\n#  module, unless it is overridden using the --browser (NotebookApp.browser)\n#  configuration option.\nc.NotebookApp.open_browser = False\n...\n</code></pre>\n<p>By default, JupyterLab attempts to automatically initiate a browser session when it starts running. Since we do not have a browser on the remote server, it is necessary to turn this off to avoid errors.</p>\n\n<p>Next, navigate down to the <code>c.NotebookApp.password</code> variable and change to the following:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.py\">/home/sammy/.jupyter/jupyter_notebook_config.py</div><pre class=\"code-pre \"><code>...\n## Hashed password to use for web authentication.\n#\n#  To generate, type in a python/IPython shell:\n#\n#    from notebook.auth import passwd; passwd()\n#\n#  The string should be of the form type:salt:hashed-password.\nc.NotebookApp.password = '<span class=\"highlight\">your_hashed_password</span>'\n...\n</code></pre>\n<p>JupyterLab will use this hashed password configuration to check the password you enter for access in your browser.</p>\n\n<p>Finally, navigate further through the file and update the entry of the <code>c.NotebookApp.port</code>:</p>\n<div class=\"code-label \" title=\"/home/sammy/.jupyter/jupyter_notebook_config.py\">/home/sammy/.jupyter/jupyter_notebook_config.py</div><pre class=\"code-pre \"><code>...\n## The port the notebook server will listen on.\nc.NotebookApp.port = 9000\n...\n</code></pre>\n<p><code>c.NotebookApp.port</code> sets a fixed port for accessing your JupyterLab runtime. This way, you can allow access for only one port from the <code>ufw</code> firewall.</p>\n\n<p>Once you&rsquo;re done, save and exit the file.</p>\n\n<p>Finally, allow traffic on the <code>9000</code> port:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 9000\n</li></ul></code></pre>\n<p>You&rsquo;ll receive the following output:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Rule added\nRule added (v6)\n</code></pre>\n<p>Now that you&rsquo;ve set all your configuration, you&rsquo;ll run JupyterLab.</p>\n\n<h2 id=\"step-4-—-running-jupyterlab\">Step 4 — Running JupyterLab</h2>\n\n<p>In this step, you&rsquo;ll perform a test run of the JupyterLab instance.</p>\n\n<p>First, change your current working directory to the user&rsquo;s home directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd ~\n</li></ul></code></pre>\n<p>Now, modify the access permissions of the certificate files to allow JupyterLab to access them. Change the permissions of the <code>/etc/letsencrypt</code> folder to the following:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 750 -R /etc/letsencrypt\n</li><li class=\"line\" data-prefix=\"$\">sudo chown <span class=\"highlight\">sammy</span>:<span class=\"highlight\">sammy</span> -R /etc/letsencrypt\n</li></ul></code></pre>\n<p>Then, invoke your JupyterLab instance to start using the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">jupyter lab\n</li></ul></code></pre>\n<p>This command accepts several configuration parameters. However, since we have already made these changes in the configuration file, we do not need to provide them here explicitly. You can provide them as arguments to this command to override the values in the configuration file.</p>\n\n<p>You can now navigate to <code>https://<span class=\"highlight\">your_domain</span>:9000</code> to check you receive JupyterLab&rsquo;s login screen.</p>\n\n<p>If you log in with the password you set up for JupyterLab in Step 2, you&rsquo;ll be presented with the JupyterLab interface.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/jupyterlab_1804/step5.png\" alt=\"JupyterLab interface after login\"></p>\n\n<p>Finally, press <code>CTRL+C</code> twice to stop the JupyterLab server.</p>\n\n<p>In the next step, you&rsquo;ll set up a system service so that the JupyterLab server can be run in the background continuously.</p>\n\n<h2 id=\"step-6-—-setting-up-a-systemd-service\">Step 6 — Setting Up a systemd Service</h2>\n\n<p>In this step, you will create a <code>systemd</code> service that allows JupyterLab to keep running even when the terminal window is exited. You can read more about <code>systemd</code> services and units in <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\">this guide on systemd essentials</a>.</p>\n\n<p>First, you&rsquo;ll have to create a <code>.service</code> file, using the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/system/jupyterlab.service\n</li></ul></code></pre>\n<p>Add the following content to the <code>/etc/systemd/system/jupyterlab.service</code> file:</p>\n<div class=\"code-label \" title=\"/etc/systemd/system/jupyterlab.service\">/etc/systemd/system/jupyterlab.service</div><pre class=\"code-pre \"><code>[Unit]\nDescription=Jupyter Lab Server\n\n[Service]\nUser=<span class=\"highlight\">sammy</span>\nGroup=<span class=\"highlight\">sammy</span>\nType=simple\nWorkingDirectory=/home/<span class=\"highlight\">sammy</span>/\nExecStart=/home/<span class=\"highlight\">sammy</span>/anaconda3/bin/jupyter-lab --config=/home/<span class=\"highlight\">sammy</span>/.jupyter/jupyter_notebook_config.py\nStandardOutput=null\nRestart=always\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>Save and exit the editor once you&rsquo;re done.</p>\n\n<p>The service file automatically registers itself in the system as a daemon. However, it is not running by default.</p>\n\n<p>Use the <code>systemctl</code> command to start the service:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start jupyterlab\n</li></ul></code></pre>\n<p>This starts the JupyterLab server in the background. You can check if the server has started by using the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl status jupyterlab\n</li></ul></code></pre>\n<p>You&rsquo;ll receive the following output:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>● jupyterlab.service - Jupyter Lab Server\n   Loaded: loaded (/etc/systemd/system/jupyterlab.service; disabled; vendor preset: enabled)\n   Active: active (running) since Sun 2020-04-26 20:58:29 UTC; 5s ago\n Main PID: 5654 (jupyter-lab)\n    Tasks: 1 (limit: 1152)\n   CGroup: /system.slice/jupyterlab.service\n           └─5654 /home/<span class=\"highlight\">sammy</span>/anaconda3/bin/python3.7 /home/<span class=\"highlight\">sammy</span>/anaconda3/bin/jupyter-lab --config=/home/\n</code></pre>\n<p>Press <code>Q</code> to exit the service status output.</p>\n\n<p>You can now head to <code>https://<span class=\"highlight\">your_domain</span>:9000</code> in any browser of your choice, provide the password you set up in Step 2, and access the JupyterLab environment running on your server.</p>\n\n<h2 id=\"step-7-—-configuring-renewal-of-your-let-39-s-encrypt-certificate\">Step 7 — Configuring Renewal of Your Let&rsquo;s Encrypt Certificate</h2>\n\n<p>In this final step, you will configure your SSL certificates provided by Let&rsquo;s Encrypt to automatically renew when they expire every 90 days and then restart the server to load the new certificates.</p>\n\n<p>While Certbot takes care to renew the certificates for your installation, it does not automatically restart the server. To configure the server to restart with new certificates, you will have to provide a <code>renew_hook</code> to the Certbot configuration for your server.</p>\n\n<p>You&rsquo;ll need to edit the <code>/etc/letsencrypt/renewal/<span class=\"highlight\">your_domain</span>.conf</code> file and add a <code>renew_hook</code> to the end of the configuration file.</p>\n\n<p>First, use the following command to open the <code>/etc/letsencrypt/renewal/<span class=\"highlight\">your_domain</span>.conf</code> file in an editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/letsencrypt/renewal/<span class=\"highlight\">your_domain</span>.conf\n</li></ul></code></pre>\n<p>Then, at the bottom of this file, add the following line:</p>\n<div class=\"code-label \" title=\"/etc/letsencrypt/renewal/your_domain.conf\">/etc/letsencrypt/renewal/your_domain.conf</div><pre class=\"code-pre \"><code>...\nrenew_hook = systemctl reload jupyterlab\n</code></pre>\n<p>Save and exit the file.</p>\n\n<p>Finally, run a dry-run of the renewal process to verify that your configuration file is valid:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot renew --dry-run\n</li></ul></code></pre>\n<p>If the command runs without any error, your Certbot renewal has been set up successfully and will automatically renew and restart your server when the certificate is near the date of expiry.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>In this article, you set up a JupyterLab environment on your server and made it accessible remotely. Now you can access your machine learning or data science projects from any browser and rest assured that all exchanges are happening with SSL encryption in place. Along with that, your environment has all the benefits of cloud-based servers.</p>\n","descriptionType":"html","publishedDate":"Tue, 25 Aug 2020 23:10:51 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/jupyterlab_1804/step5.png","linkMd5":"fc30ef8432ef45436603870128d4654b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn8@2020_5/2020/08/31/07-48-27-446_cbd8056c70131692.webp","destWidth":1600,"destHeight":900,"sourceBytes":53522,"destBytes":30628,"author":"Anubhav Singh","articleImgCdnMap":{"https://assets.digitalocean.com/articles/jupyterlab_1804/step5.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn8@2020_5/2020/08/31/07-48-27-446_cbd8056c70131692.webp"},"publishedOrCreatedDate":1598860106986},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Verwenden von ThreadPoolExecutor in Python 3","link":"https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3-de","description":"<p><em>Der Autor hat den <a href=\"https://www.brightfunds.org/funds/write-for-donations-covid-19-relief-fund\">COVID-19 Relief Fund</a> dazu ausgewählt, eine Spende im Rahmen des Programms <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> zu erhalten.</em></p>\n\n<h3 id=\"einführung\">Einführung</h3>\n\n<p><a href=\"https://www.python.org/\">Python</a><em>-Threads</em> stellen eine Form von Parallelismus dar, mit der Ihr Programm verschiedene Operationen gleichzeitig ausführen kann. Parallelismus in Python lässt sich auch durch Verwendung mehrerer Prozesse erzielen; Threads eignen sich jedoch besonders gut für die Beschleunigung von Anwendungen, die hohe I/O-Leistung benötigen.</p>\n\n<p>Beispiel: <a href=\"https://en.wikipedia.org/wiki/I/O_bound#:%7E:text=In%20computer%20science%2C%20I%2FO,a%20task%20being%20CPU%20bound.\">I/O-gerichtete Operationen</a> umfassen die Erstellung von Webanfragen und das Lesen von Daten aus Dateien. Im Gegensatz zu I/O-gerichteten Operationen werden <a href=\"https://en.wikipedia.org/wiki/CPU-bound\">CPU-gerichtete Operationen</a> (wie die Ausführung von Berechnungen mit der Python-Standardbibliothek) von Python-Threads nur wenig profitieren.</p>\n\n<p>Python 3 enthält das Dienstprogramm <code>ThreadPoolExecutor</code> zur Ausführung von Code in einem Thread.</p>\n\n<p>In diesem Tutorial werden wir <code>ThreadPoolExecutor</code> verwenden, um zügige Netzwerkanfragen zu erstellen. Wir werden eine Funktion definieren, die für Aufrufe innerhalb von Threads geeignet ist, <code>ThreadPoolExecutor</code> zur Ausführung dieser Funktion nutzen und Ergebnisse aus diesen Ausführungen verarbeiten.</p>\n\n<p>In diesem Tutorial werden wir Netzwerkanfragen stellen, um die Existenz von <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipedia</a>-Seiten zu überprüfen.</p>\n\n<p><span class='note'><strong>Anmerkung:</strong> Die Tatsache, dass I/O-gerichtete Operationen mehr von Threads profitieren als I/O-orientierte Operationen, hängt mit einer Eigenart von Python zusammen, die<a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">_ global interpreter loc_</a>k genannt wird. Wenn Sie möchten, können Sie <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">in der offiziellen Python-Dokumentation</a> mehr über „global interpreter lock“ von Python erfahren.<br></span></p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Für eine optimale Nutzung des Tutorials empfiehlt sich Vertrautheit mit der Programmierung in Python und einer lokalen Python-Programmierumgebung mit installiertem <code>requests</code>-Paket.</p>\n\n<p>Sie können für die notwendigen Hintergrundinformationen diese Tutorials durchsehen:</p>\n\n<ul>\n<li><a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-python-3\">Codieren in Python 3</a></li>\n<li><p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">Installieren von Python 3 und Einrichten einer lokalen Programmierumgebung unter Ubuntu 18.04</a></p></li>\n<li><p>Um das <code>requests</code>-Paket in Ihrer <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">lokalen Python-Programmierumgebung</a> zu installieren, können Sie folgenden Befehl ausführen:</p></li>\n</ul>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pip install --user requests==2.23.0\n</li></ul></code></pre>\n<h2 id=\"schritt-1-—-definieren-einer-funktion-zur-ausführung-in-threads\">Schritt 1 — Definieren einer Funktion zur Ausführung in Threads</h2>\n\n<p>Definieren wir zunächst eine Funktion, die wir mithilfe von Threads ausführen möchten.</p>\n\n<p>Mit <code>nano</code> oder Ihrem bevorzugten Texteditor/Ihrer bevorzugten Entwicklungsumgebung können Sie diese Datei öffnen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano wiki_page_function.py\n</li></ul></code></pre>\n<p>In diesem Tutorial werden wir eine Funktion schreiben, die ermittelt, ob eine Wikipedia-Seite vorhanden ist oder nicht:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n</code></pre>\n<p>Die <a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-python-3\">Funktion</a> <code>get_wiki_page_existence</code> akzeptiert zwei Argumente: eine URL zu einer Wikipedia-Seite (<code>wiki_page_url</code>) und eine <code>timeout</code>-Anzahl von Sekunden, während der auf eine Antwort von dieser URL gewartet werden soll.</p>\n\n<p><code>get_wiki_page_existence</code> nutzt das <a href=\"https://requests.readthedocs.io/en/master/\"><code>requests</code></a>-Paket, um eine Webanfrage an diese URL zu stellen. Je nach <a href=\"https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes\">Statuscode</a> der HTTP-<code>Antwort</code> wird eine Zeichenfolge zurückgegeben, die beschreibt, ob die Seite vorhanden ist oder nicht. Verschiedene Statuscodes stellen verschiedene Ergebnisse einer HTTP-Anfrage dar. Hier gehen wir davon aus, dass ein <code>200</code>-Statuscode („Erfolg“) bedeutet, dass die Wikipedia-Seite existiert, und ein <code>404</code>-Statuscode („Nicht gefunden“) bedeutet, dass die Wikipedia-Seite nicht existiert.</p>\n\n<p>Wie im Abschnitt zu den Voraussetzungen beschrieben, benötigen Sie das installierte <code>requests</code>-Paket, um diese Funktion ausführen zu können.</p>\n\n<p>Versuchen wir, die Funktion auszuführen, indem wir die <code>url</code> und den Funktionsaufruf nach der Funktion <code>get_wiki_page_existence</code> hinzufügen:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">. . .\nurl = \"https://en.wikipedia.org/wiki/Ocean\"\nprint(get_wiki_page_existence(wiki_page_url=url))\n</code></pre>\n<p>Nachdem Sie den Code hinzugefügt haben, speichern und schließen Sie die Datei.</p>\n\n<p>Wenn wir diesen Code ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Erhalten wir eine Ausgabe wie die folgende:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Ocean - exists\n</code></pre>\n<p>Bei Aufruf der Funktion <code>get_wiki_page_existence</code> mit einer gültigen Wikipedia-Seite wird eine Zeichenfolge zurückgegeben, die bestätigt, dass die Seite tatsächlich existiert.</p>\n\n<p><span class='warning'><strong>Achtung:</strong> Im Allgemeinen ist es nicht sicher, Python-Objekte oder -Status zwischen Threads zu teilen, ohne sorgfältig darauf zu achten, dass keine Parallelitätsfehler auftreten. Wenn Sie eine Funktion definieren, die in einem Thread ausgeführt werden soll, ist es am besten, eine Funktion festzulegen, die einen einzelnen Auftrag ausführt und den Status nicht an andere Threads weitergibt oder veröffentlicht. <code>get_wiki_page_existence</code> ist ein Beispiel für eine solche Funktion.<br></span></p>\n\n<h2 id=\"schritt-2-—-verwenden-von-threadpoolexecutor-zur-ausführung-einer-funktion-in-threads\">Schritt 2 — Verwenden von ThreadPoolExecutor zur Ausführung einer Funktion in Threads</h2>\n\n<p>Nachdem wir nun über eine Funktion verfügen, die sich in Threads aufrufen lässt, können wir <code>ThreadPoolExecutor</code> verwenden, um zügig mehrere Aufrufe dieser Funktion auszuführen.</p>\n\n<p>Fügen Sie Ihrem Programm in <code>wiki_page_function.py</code> den folgenden hervorgehobenen Code hinzu:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n<span class=\"highlight\">import concurrent.futures</span>\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Ocean\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Island\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/this_page_does_not_exist\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Shark\",</span>\n<span class=\"highlight\">]</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n</code></pre>\n<p>Werfen wir einen Blick auf die Funktionsweise dieses Codes:</p>\n\n<ul>\n<li><code>concurrent.futures</code> wird importiert, um uns Zugriff auf <code>ThreadPoolExecutor</code> zu gewähren.</li>\n<li>Eine <code>with</code>-Anweisung dient der Erstellung eines <code>ThreadPoolExecutor</code>-Instanz-<code>Executors</code>, der Threads unmittelbar nach dem Abschluss bereinigt.</li>\n<li>Vier Aufträge werden dem <code>Executor</code> <code>übergeben</code>: einer für jede der URLs in der Liste <code>wiki_page_urls</code>.</li>\n<li>Jeder Aufruf an <code>submit</code> gibt eine <a href=\"https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future\"><code>Future</code>-Instanz</a> zurück, die in der <code>futures</code>-Liste gespeichert ist.</li>\n<li>Die Funktion <code>as_completed</code> wartet, bis jeder <code>Future</code> <code>get_wiki_page_existence</code>-Aufruf abgeschlossen ist, damit wir das Ergebnis ausgeben können.</li>\n</ul>\n\n<p>Wenn wir dieses Programm mit dem folgenden Befehl erneut ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Erhalten wir eine Ausgabe wie die folgende:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Island - exists\nhttps://en.wikipedia.org/wiki/Ocean - exists\nhttps://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\nhttps://en.wikipedia.org/wiki/Shark - exists\n</code></pre>\n<p>Diese Ausgabe ergibt Sinn: drei der URLs sind gültige Wikipedia-Seiten, eine nicht (<code>this_page_does_not_exist</code>). Beachten Sie, dass Ihre Ausgabe eine andere Reihenfolge aufweisen kann als diese Ausgabe. Die Funktion <code>concurrent.futures.as_completed</code> in diesem Beispiel gibt Ergebnisse zurück, sobald sie verfügbar sind. Dabei ist es egal, in welcher Reihenfolge die Aufträge übermittelt wurden.</p>\n\n<h2 id=\"schritt-3-—-vearbeiten-von-ausnahmen-bei-funktionsausführungen-in-threads\">Schritt 3 — Vearbeiten von Ausnahmen bei Funktionsausführungen in Threads</h2>\n\n<p>Im vorherigen Schritt hat <code>get_wiki_page_existence</code> bei allen unseren Aufrufen erfolgreich einen Wert zurückgegeben. In diesem Schritt sehen wir, dass <code>ThreadPoolExecutor</code> auch Ausnahmen auslösen kann, die in Threaded-Funktionsaufrufen generiert werden.</p>\n\n<p>Betrachten wir den folgenden beispielhaften Codeblock:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n\nwiki_page_urls = [\n    \"https://en.wikipedia.org/wiki/Ocean\",\n    \"https://en.wikipedia.org/wiki/Island\",\n    \"https://en.wikipedia.org/wiki/this_page_does_not_exist\",\n    \"https://en.wikipedia.org/wiki/Shark\",\n]\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(</span>\n            <span class=\"highlight\">executor.submit(</span>\n                <span class=\"highlight\">get_wiki_page_existence, wiki_page_url=url, timeout=0.00001</span>\n            <span class=\"highlight\">)</span>\n        <span class=\"highlight\">)</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">try:</span>\n            <span class=\"highlight\">print(future.result())</span>\n        <span class=\"highlight\">except requests.ConnectTimeout:</span>\n            <span class=\"highlight\">print(\"ConnectTimeout.\")</span>\n</code></pre>\n<p>Dieser Codeblock ist fast identisch mit dem, den wir in Schritt 2 verwendet haben; er weist jedoch zwei wichtige Unterschiede auf:</p>\n\n<ul>\n<li>Wir übergeben nun <code>timeout=0.00001</code> an <code>get_wiki_page_existence</code>. Da das <code>requests</code>-Paket seine Webanfrage an Wikipedia in <code>0,00001</code>  Sekunden nicht abschließen kann, wird eine <code>ConnectTimeout</code>-Ausnahme ausgelöst.</li>\n<li>Wir erfassen <code>ConnectTimeout</code>-Ausnahmen, die durch <code>future.result()</code> ausgelöst werden, und drucken dabei jedes Mal eine Zeichenfolge aus.</li>\n</ul>\n\n<p>Wenn wir das Programm erneut ausführen, sehen wir die folgende Ausgabe:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>ConnectTimeout.\nConnectTimeout.\nConnectTimeout.\nConnectTimeout.\n</code></pre>\n<p>Vier <code>ConnectTimeout</code>-Nachrichten werden ausgegeben (eine für jede unserer vier <code>wiki_page_urls</code>), da keine davon in <code>0,00001</code> Sekunden abgeschlossen werden konnte und jede der vier <code>get_wiki_page_existence</code>-Aufrufe eine <code>ConnectTimeout</code>-Ausnahme ausgelöst hat.</p>\n\n<p>Sie haben gesehen, dass wenn ein Funktionsaufruf an einen <code>ThreadPoolExecutor</code> eine Ausnahme auslöst, diese Ausnahme normalerweise durch Aufruf von <code>Future.result</code> ausgelöst werden kann. Ein Aufruf von <code>Future.result</code> bei all Ihren übermittelten Aufrufen stellt sicher, dass Ihr Programm keine Ausnahmen verpasst, die von Ihrer Threaded-Funktion ausgelöst werden.</p>\n\n<h2 id=\"schritt-4-—-vergleichen-der-ausführungszeit-mit-und-ohne-threads\">Schritt 4 — Vergleichen der Ausführungszeit mit und ohne Threads</h2>\n\n<p>Überprüfen wir nun, ob die Verwendung von <code>ThreadPoolExecutor</code> Ihr Programm tatsächlich schneller macht.</p>\n\n<p>Lassen Sie uns zunächst die Ausführung von <code>get_wiki_page_existence</code> ohne Threads messen:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\"><span class=\"highlight\">import time</span>\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]</span>\n\n<span class=\"highlight\">print(\"Running without threads:\")</span>\n<span class=\"highlight\">without_threads_start = time.time()</span>\n<span class=\"highlight\">for url in wiki_page_urls:</span>\n    <span class=\"highlight\">print(get_wiki_page_existence(wiki_page_url=url))</span>\n<span class=\"highlight\">print(\"Without threads time:\", time.time() - without_threads_start)</span>\n</code></pre>\n<p>Im Codebeispiel rufen wir unsere <code>get_wiki_page_existence</code>-Funktion mit fünfzig verschiedenen URLs von Wikipedia-Seiten hintereinander auf. Wir verwenden die <a href=\"https://docs.python.org/3/library/time.html#time.time\">Funktion <code>time.time()</code></a>, um die Anzahl der Sekunden auszugeben, die für die Ausführung unseres Programms benötigt wurde.</p>\n\n<p>Wenn wir diesen Code wie zuvor erneut ausführen, erhalten wir eine Ausgabe wie die folgende:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running without threads:\nhttps://en.wikipedia.org/wiki/0 - exists\nhttps://en.wikipedia.org/wiki/1 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nWithout threads time: 5.803015232086182\n</code></pre>\n<p>Einträge 2 bis 47 in dieser Ausgabe wurden der Kürze halber ausgelassen.</p>\n\n<p>Die Anzahl der Sekunden, die nach <code>Without threads time</code> (Zeit ohne Threads) ausgegeben wird, wird sich bei Ausführung auf Ihrem Computer unterscheiden. Das ist in Ordnung; Sie erhalten einfach eine Baseline-Zahl, die Sie mit einer Lösung vergleichen können, die <code>ThreadPoolExecutor</code> nutzt. In diesem Fall waren es <code>~5,803</code> Sekunden.</p>\n\n<p>Führen wir nun die gleichen fünfzig Wikipedia-URLs über <code>get_wiki_page_existence</code> aus, diesmal jedoch mit <code>ThreadPoolExecutor</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import time\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\nwiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n\n<span class=\"highlight\">print(\"Running threaded:\")</span>\n<span class=\"highlight\">threaded_start = time.time()</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n<span class=\"highlight\">print(\"Threaded time:\", time.time() - threaded_start)</span>\n</code></pre>\n<p>Der Code ist der gleiche Code, den wir in Schritt 2 erstellt haben; diesmal enthält er jedoch zusätzlich einige Druckanweisungen, um die Anzahl der Sekunden anzuzeigen, die zur Ausführung unseres Codes benötigt wurden.</p>\n\n<p>Wenn wir das Programm erneut ausführen, erhalten wir die folgende Ausgabe:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running threaded:\nhttps://en.wikipedia.org/wiki/1 - exists\nhttps://en.wikipedia.org/wiki/0 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nThreaded time: 1.2201685905456543\n</code></pre>\n<p>Auch die Anzahl der Sekunden, die nach <code>Threaded time</code> (Zeit mit Threads) ausgegeben wird, wird sich auf Ihrem Computer unterscheiden (ebenso die Reihenfolge Ihrer Ausgabe).</p>\n\n<p>Jetzt können Sie die Ausführungszeit beim Abrufen der fünfzig URLs von Wikipedia-Seiten mit und ohne Threads miteinander vergleichen.</p>\n\n<p>Auf dem in diesem Tutorial verwendeten Rechner dauerte es ohne Threads <code>~5,803</code> Sekunden; mit Threads waren es <code>~1,220</code> Sekunden. Unser Programm lief mit Threads also deutlich schneller.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>In diesem Tutorial haben Sie erfahren, wie Sie das Dienstprogramm <code>ThreadPoolExecutor</code> in Python 3 verwenden können, um I/O-gerichteten Code effizient auszuführen. Sie haben eine Funktion erstellt, die sich für Aufrufe innerhalb von Threads eignet, gelernt, wie man sowohl Ausgaben als auch Ausnahmen von Threaded-Ausführungen dieser Funktion abruft, und den Leistungsschub beobachten können, der durch Verwendung von Threads entsteht.</p>\n\n<p>Nun können Sie mehr über andere Parallelitätsfunktionen des <a href=\"https://docs.python.org/3/library/concurrent.futures.html\"><code>concurrent.futures</code>-Moduls</a> erfahren.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:36 +0000","feedId":8037,"bgimg":"","linkMd5":"24404e3277d57ce895e608d2fa283d76","bgimgJsdelivr":"","metaImg":"","author":"DavidMuller","publishedOrCreatedDate":1598860106965},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo configurar un servidor VPN IKEv2 con StrongSwan en Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-an-ikev2-vpn-server-with-strongswan-on-ubuntu-20-04-es","description":"<p><em><a href=\"https://www.digitalocean.com/community/users/jellingwood\">Justin Ellingwood</a> y <a href=\"https://www.digitalocean.com/community/users/namo\">Namo</a> escribieron una versión anterior de este tutorial.</em></p>\n\n<h3 id=\"introducción\">Introducción</h3>\n\n<p>Un red virtual privad,(VPN, por sus siglas en inglés) le permite cifrar de forma segura el tráfico mientras tiene lugar a través de redes no confiables, como las de una cafetería, una sala de conferencias o un aeropuerto.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Internet_Key_Exchange\">Internet Key Exchange v2</a>, o IKEv2, es un protocolo que permite la implementación directa de túneles de IPSec entre un servidor y un cliente. En las implementaciones de VPN IKEv2, IPSec proporciona cifrado para el tráfico de red. IKEv2 es compatible de forma nativa con algunas plataformas (OS X 10.11+, iOS 9.1+ y Windows 10) sin necesidad de aplicaciones adicionales y maneja los picos de los clientes sin problemas.</p>\n\n<p>En este tutorial, configurará un servidor VPN IKEv2 con <a href=\"https://www.strongswan.org/\">StrongSwan</a> en un servidor con Ubuntu 20.04. Luego, aprenderá a conectarse con él con clientes de Windows, macOS, Ubuntu, iOS y Android.</p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Para completar este tutorial, necesitará lo siguiente:</p>\n\n<ul>\n<li>Un servidor de Ubuntu 20.04 configurado mediante la <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Guía de configuración inicial de servidores para Ubuntu 20.04</a>, un usuario <code>sudo</code> non-root y un firewall.</li>\n</ul>\n\n<h2 id=\"paso-1-instalar-strongswan\">Paso 1: Instalar StrongSwan</h2>\n\n<p>Primero, instalaremos StrongSwan, un demonio IPSec de código abierto que configuraremos para que funcione como nuestro servidor VPN. También instalaremos el componente de infraestructura de clave pública (PKI) para poder crear una Entidad de certificación (CA) para proporcionar las credenciales para nuestra infraestructura.</p>\n\n<p>Comience por actualizar la caché del paquete local:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>A continuación, instale el software escribiendo lo siguiente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan strongswan-pki libcharon-extra-plugins libcharon-extauth-plugins\n</li></ul></code></pre>\n<p>Se utiliza el paquete adicional <code>libcharon-extauth-plugins</code> para garantizar que varios clientes pueden autenticarse en su servidor utilizando un nombre de usuario y una frase de contraseña compartidos.</p>\n\n<p>Ahora que se instaló todo, crearemos nuestros certificados.</p>\n\n<h2 id=\"paso-2-crear-una-autoridad-de-certificación\">Paso 2: Crear una autoridad de certificación</h2>\n\n<p>Un servidor IKEv2 requiere un certificado para identificarse ante los clientes. Para que podamos crear el certificado requerido, el paquete <code>strongswan-pki</code> incluye una utilidad para generar una entidad de certificación y certificados del servidor denominada <code>pki</code>.</p>\n\n<p>Para comenzar, crearemos algunos directorios para almacenar todos los activos en los que trabajaremos. La estructura de directorios coincide con algunos de los directorios de <code>/etc/ipsec.d</code>, adonde, eventualmente, moveremos todos los elementos que creemos.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir -p ~/pki/{cacerts,certs,private}\n</li></ul></code></pre>\n<p>A continuación, bloquearemos los permisos para que otros usuarios no puedan ver nuestros archivos privados:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod 700 ~/pki\n</li></ul></code></pre>\n<p>Ahora que disponemos de una estructura de directorios para almacenar todo, podemos generar una clave de root. Será una clave RSA de 4096 bits que se usará para firmar nuestra autoridad de certificación de root.</p>\n\n<p>Ejecute estos comandos para generar la clave:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/ca-key.pem\n</li></ul></code></pre>\n<p>Luego, podemos seguir creando nuestra entidad de certificación de root, utilizando la clave que acabamos de generar para firmar el certificado root:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --self --ca --lifetime 3650 --in ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">    --type rsa --dn \"CN=VPN root CA\" --outform pem &gt; ~/pki/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>El indicador <code>---life 3650</code> se utiliza para garantizar que el certificado root de la entidad de certificación sea válido por 10 años. El certificado root de una entidad no suele cambiar, dado que debería redistribuirse a todos los servidores y clientes que confían en él, por lo tanto, 10 años es un valor de vencimiento predeterminado seguro.</p>\n\n<p>Puede cambiar el valor del <em>nombre distintivo</em> (DN) por otro si lo desea. El nombre común (campo CN) aquí es simplemente el indicador, por lo que no tiene que coincidir con ninguna otra cosa de su infraestructura.</p>\n\n<p>Ahora que nuestra autoridad de certificación de root está lista, podemos crear un certificado que usará el servidor de VPN.</p>\n\n<h2 id=\"paso-3-generar-un-certificado-para-el-servidor-de-vpn\">Paso 3: Generar un certificado para el servidor de VPN</h2>\n\n<p>Ahora, crearemos un certificado y la contraseña para el servidor de VPN. Esta certificación permitirá a los clientes verificar la autenticidad del servidor usando la certificación de CA que acabamos de generar.</p>\n\n<p>Primero, cree una clave privada para el servidor de VPN con el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/server-key.pem\n</li></ul></code></pre>\n<p>Ahora, cree y firme el certificado del servidor de VPN con la clave de la autoridad de certificación que creó en el paso anterior. Ejecute el siguiente comando, pero cambie los campos de nombre común (CN) y nombre alternativo de sujeto (SAN) por el nombre de DNS o la dirección IP de su servidor de VPN:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --pub --in ~/pki/private/server-key.pem --type rsa \\\n</li><li class=\"line\" data-prefix=\"$\">    | pki --issue --lifetime 1825 \\\n</li><li class=\"line\" data-prefix=\"$\">        --cacert ~/pki/cacerts/ca-cert.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --cakey ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --dn \"CN=<span class=\"highlight\">server_domain_or_IP</span>\" --san <span class=\"highlight\">server_domain_or_IP</span> \\\n</li><li class=\"line\" data-prefix=\"$\">        --flag serverAuth --flag ikeIntermediate --outform pem \\\n</li><li class=\"line\" data-prefix=\"$\">    &gt;  ~/pki/certs/server-cert.pem\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: Si utiliza una dirección IP en lugar de un nombre DNS, deberá especificar varias entradas <code>--san</code>. Deberá modificar la línea del bloque de comandos anterior en la que se especifica el nombre distintivo (<code>--dn ...</code>) con la entrada adicional como se indica en la siguiente línea extraída:</p>\n<pre class=\"code-pre \"><code>--dn \"CN=<span class=\"highlight\">IP address</span> --san @<span class=\"highlight\">IP_address</span> --san <span class=\"highlight\">IP_address</span> \\\n</code></pre>\n<p>Esta entrada adicional <code>--san @<span class=\"highlight\">IP_address</span></code> se añade porque algunos clientes comprobarán si el certificado TLS tiene tanto una entrada de DNS como una de dirección IP para un servidor al verificar su identidad.<br></p></span>\n\n<p>La opción <code>--flag serverAuth</code> se utiliza para indicar que el certificado se utilizará de forma explícita para la autenticación de servidores antes de que se establezca el túnel cifrado. La opción <code>--flag ikeIntermediate</code> se utiliza para admitir clientes de macOS más antiguos.</p>\n\n<p>Ahora que generamos todos los archivos TLS/SSL que necesita StrongSwan, podemos moverlos a su lugar en el directorio <code>/etc/ipsec.d</code> escribiendo lo siguiente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp -r ~/pki/* /etc/ipsec.d/\n</li></ul></code></pre>\n<p>En este paso, creamos un par de certificados que se utilizarán para proteger las comunicaciones entre el cliente y el servidor. También, firmamos los certificados con la clave de CA, para que el cliente pueda verificar la autenticidad del servidor de VPN usando el certificado de CA. Con todos estos certificados listos, procederemos a configurar el software.</p>\n\n<h2 id=\"paso-4-configurar-strongswan\">Paso 4: Configurar StrongSwan</h2>\n\n<p>StrongSwan tiene un archivo de configuración predeterminado con algunos ejemplos, pero tendremos que hacer la mayor parte de la configuración por nuestra cuenta. Haremos una copia de seguridad del archivo a modo de referencia antes de empezar de cero:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/ipsec.conf{,.original}\n</li></ul></code></pre>\n<p>Cree y abra un nuevo archivo de configuración en blanco con el editor de texto que prefiera. En este caso, utilizaremos <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: Mientras trabaje en esta sección para configurar la porción del servidor de su VPN, encontrará ajustes que se refieren a los lados <em>izquierdo</em> y <em>derecho</em> de una conexión. Al trabajar con una VPN IPSec, por convención, el lado *izquierdo *se refiere al sistema local que está configurando, que, en este caso, es el servidor. Las directivas del lado derecho de estas configuraciones se refieren a clientes remotos, como teléfonos y otras computadoras.</p>\n\n<p>Cuando procedamos a configurar clientes más adelante en este tutorial, los archivos de configuración de los clientes harán referencia a sí mismos utilizando varias directivas de la <em>izquierda</em> y se hará referencia al servidor con terminología del lado <em>derecho</em>.<br></p></span>\n\n<p>Primero, le diremos a StrongSwan que registre los estados de los demonios para depurar y permitir conexiones duplicadas. Añada estas líneas al archivo:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n</code></pre>\n<p>Luego, crearemos una sección de configuración para nuestra VPN. También le indicaremos a StrongSwan que cree túneles de VPN IKEv2 y cargue de forma automática esta sección de configuración cuando se inicie. Agregue las siguientes líneas al archivo:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n</code></pre>\n<p>También configuraremos la detección de pares inactivos para eliminar cualquier conexión “pendiente” en caso de que el cliente se desconecte de forma inesperada. Agregue estas líneas:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n</code></pre>\n<p>A continuación, configuraremos los parámetros de IPSec del lado &ldquo;izquierdo&rdquo; del servidor. Cada uno de los siguientes parámetros garantiza que el servidor esté configurado para aceptar conexiones de clientes e identificarse correctamente. Añada cada una de estas configuraciones al archivo <code>/etc/ipsec.conf</code> una vez que esté familiarizado con ellas y el motivo por el cual se utilizan:</p>\n\n<ul>\n<li><code>left=%any</code> El valor <code>%any</code> garantiza que el servidor utilice la interfaz de red en la que recibe conexiones entrantes para la posterior comunicación con los clientes. Por ejemplo, si conecta un cliente a través de una red privada, el servidor utilizará la dirección IP privada en la que recibe tráfico para el resto de la conexión.</li>\n<li><code>leftid=<span class=\"highlight\">@server_domain_or_IP</span></code> Esta opción controla el nombre que el servidor presenta a los clientes. Cuando se combina con la siguiente opción, <code>leftcert</code>, la opción <code>leftid</code> garantiza que el nombre configurado del servidor y el nombre distintivo (DN) indicado en el certificado público concuerden.</li>\n<li><code>leftcert=server-cert.pem</code> Esta opción es la ruta al certificado público del servidor que configuró en el paso 3. Sin ella, el servidor no podrá autenticarse con clientes ni terminar de negociar la configuración de IKEv2.</li>\n<li><code>leftsendcert=always</code> El valor <code>always</code> garantiza que cualquier cliente que se conecte al servidor reciba siempre una copia del certificado público del servidor como parte de la configuración de la conexión inicial.</li>\n<li><code>leftsubnet=0.0.0.0/0</code> Es la última opción &ldquo;izquierda&rdquo; que agregará, que les indica a los clientes las subredes accesibles detrás del servidor. En este caso, <code>0.0.0.0/0</code> se utiliza para representar todo el conjunto de direcciones IPv4, lo que significa que el servidor les indicará a los clientes que envíen todo su tráfico a través de la VPN  por defecto.</li>\n</ul>\n\n<p>Ahora que está familiarizado con cada una de las opciones del lado &ldquo;izquierdo&rdquo; pertinentes, añádalas al archivo de este modo:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n</code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: Cuando configure el ID del servidor (<code>leftid</code>), incluya únicamente el carácter <code>@</code> si su servidor de VPN se identificará por un nombre de dominio:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .    leftid=<span class=\"highlight\">@vpn.example.com</span>\n    . . .\n</code></pre>\n<p>Si el servidor se identifica por su dirección IP, simplemente introdúzcala:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .\n    leftid=<span class=\"highlight\">your_server_ip</span>\n    . . .\n</code></pre>\n<p></p></span>\n\n<p>A continuación, podemos configurar los parámetros de IPSec del lado &ldquo;derecho&rdquo; del cliente. Cada uno de los siguientes parámetros le indica al servidor cómo aceptar conexiones de los clientes, cómo deben autenticarse los clientes al servidor y los intervalos de direcciones IP privadas y  servidores DNS que utilizarán los clientes. Añada cada una de estas configuraciones al archivo <code>/etc/ipsec.conf</code> una vez que esté familiarizado con ellas y el motivo por el cual se utilizan:</p>\n\n<ul>\n<li><code>right=%any</code> La opción <code>%any</code> del lado <code>derecho</code> de la conexión le indica al servidor que acepte las conexiones entrantes de cualquier cliente remoto.</li>\n<li><code>rightid=%any</code> Esta opción garantiza que el servidor no rechace conexiones de clientes que proporcionan una identidad antes de que se establezca el túnel cifrado.</li>\n<li><code>rightauth=eap-mschapv2</code> Esta opción configura el método de autenticación que utilizarán los clientes para autenticarse en el servidor. <code>eap-mschapv2</code> se utiliza aquí para tener una amplia compatibilidad y poder admitir clientes como dispositivos de Windows, macOS y Android.</li>\n<li><code>rightsourceip=10.10.10.0/24</code> Esta opción le indica al servidor que asigne direcciones IP privadas a los clientes del grupo de IP especificado <code>10.10.10.0/24</code>.</li>\n<li><code>rightdns=8.8.4.4</code> Estas direcciones IP son las resoluciones DNS públicas de Google. Se pueden cambiar para usar otras resoluciones públicas, las del servidor VPN o cualquier otra resolución disponible para los clientes.</li>\n<li><code>rightsendcert=never</code> Esta opción le indica al servidor que los clientes no necesitan enviar un certificado para autenticarse.</li>\n</ul>\n\n<p>Ahora que está familiarizado con las opciones del lado &ldquo;derecho&rdquo; necesarias para la VPN, añada las siguientes líneas a <code>/etc/ipsec.conf</code>:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n</code></pre>\n<p>Ahora, le indicaremos a StrongSwan que solicite a los clientes las credenciales de los usuarios cuando se conecten:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    eap_identity=%identity\n</code></pre>\n<p>Por último, añada las siguientes líneas para admitir clientes de Linux, Windows, macOS, iOS y Android. Estas líneas especifican los diversos algoritmos de intercambio de clave, hash, autenticación y cifrado (denominados comúnmente <em>Conjuntos de cifrado</em>) que StrongSwan permitirá que utilicen los diferentes clientes:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Cada conjunto de cifrado compatible se separa de los demás con una coma. Por ejemplo, <code>chacha20poly1305-sha512-curve25519-prfsha512</code> es un conjunto y <code>aes256gcm16-sha384-prfsha384-ecp384</code> es otro. Los conjuntos de cifrado que se enumeran aquí se seleccionaron para garantizar el mayor grado de compatibilidad con los clientes de Windows, macOS, iOS, Android y Linux.</p>\n\n<p>El archivo de configuración completo debe tener el siguiente aspecto:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n    eap_identity=%identity\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Guarde y cierre el archivo una vez que haya verificado que añadió correctamente cada línea. Si utiliza <code>nano</code>, podrá hacerlo presionando <code>CTRL+X</code>, <code>Y</code> y luego <code>ENTER</code>.</p>\n\n<p>Ahora que configuramos los parámetros de VPN, crearemos una cuenta para que nuestros usuarios puedan conectarse al servidor.</p>\n\n<h2 id=\"paso-5-configurar-la-autenticación-de-vpn\">Paso 5: Configurar la autenticación de VPN</h2>\n\n<p>Nuestro servidor de VPN ahora está configurado para aceptar conexiones de clientes, pero aún no establecimos credenciales. Tendremos que  <code>realizar algunas configuraciones en un archivo de configuración especial llamado ipsec.secrets</code>:</p>\n\n<ul>\n<li>Debemos indicar a StrongSwan dónde encontrar la clave privada para el certificado de nuestro servidor, de modo que este último pueda autenticar a los clientes.</li>\n<li>También, tendremos que configurar una lista de usuarios a quienes se les permitirá conectarse al VPN.</li>\n</ul>\n\n<p>Abramos el archivos de secretos para editarlo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.secrets\n</li></ul></code></pre>\n<p>Primero, le indicaremos a StrongSwan dónde encontrar nuestra clave privada:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code>: RSA \"server-key.pem\"\n</code></pre>\n<p>Luego, definiremos las credenciales de los usuarios. Puede crear cualquier combinación de nombre de usuario o contraseña que desee:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Guarde y cierre el archivo. Ahora que terminamos de trabajar con los parámetros de VPN, reiniciaremos el servicio de VPN para que se aplique nuestra configuración:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart strongswan-starter\n</li></ul></code></pre>\n<p>Ahora que el servidor de VPN quedó totalmente configurado, tanto con opciones de servidor como con las credenciales de usuarios, es el momento de proseguir con la configuración de la parte más importante: el firewall.</p>\n\n<h2 id=\"paso-6-configurar-el-firewall-y-el-reenvío-de-ip-de-kernel\">Paso 6: Configurar el firewall y el reenvío de IP de kernel</h2>\n\n<p>Ahora que completamos la configuración de StrongSwan, debemos configurar el firewall para que permita tráfico VPN y lo reenvíe.</p>\n\n<p>Si siguió el tutorial de configuración inicial para servidores indicado en los requisitos previos, debería tener un firewall UFW. Si todavía no tiene un firewall UFW configurado, comience por añadir una regla para permitir conexiones SSH a través del firewall de modo que su sesión actual no se cierre cuando habilite UFW:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow OpenSSH\n</li></ul></code></pre>\n<p>A continuación, habilite el firewall escribiendo lo siguiente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>A continuación, agregue una regla para permitir tráfico UDP a los puertos de IPSec estándar <code>500</code> y <code>4500</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 500,4500/udp\n</li></ul></code></pre>\n<p>A continuación, abriremos uno de los archivos de configuración de UFW para agregar algunas políticas de bajo nivel a fin de dirigir y reenviar paquetes IPSec. Sin embargo, para poder hacerlo, debemos encontrar la interfaz de red de nuestro servidor que se utiliza para acceder a Internet. Busque esta interfaz al consultar el dispositivo asociado con la ruta predeterminada:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ip route show default\n</li></ul></code></pre>\n<p>Su interfaz pública debe ir después de la palabra “dev”. Por ejemplo, este resultado muestra la interfaz llamada <code>eth0</code>, que se resalta a continuación:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>default via <span class=\"highlight\">your_server_ip</span> dev <span class=\"highlight\">eth0</span> proto static\n</code></pre>\n<p>Cuando tenga una interfaz de red pública, abra el archivo <code>/etc/ufw/before.rules</code> en su editor de texto. Las reglas de este archivo se añaden al firewall antes del resto de las reglas de entrada y salida habituales. Se utilizan para configurar la traducción de direcciones de red (NAT) para que el servidor pueda dirigir correctamente las conexiones desde y hacia los clientes e Internet.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/before.rules\n</li></ul></code></pre>\n<p>Cerca de la parte superior del archivo (antes de la línea <code>*filter</code>), agregue el siguiente bloque de configuración: Cambie cada instancia de <code>eth0</code> en la configuración superior para que coincida con el nombre de interfaz que encontró con <code>ip route</code>. Las líneas <code>*nat</code> crean reglas para que el firewall pueda dirigir y manipular de forma correcta el tráfico entre los clientes de VPN e Internet. La línea <code>*mangle</code> ajusta el tamaño máximo del segmento de paquete para evitar posibles problemas con determinados clientes de VPN.</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code><span class=\"highlight\">*nat</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -m policy --pol ipsec --dir out -j ACCEPT</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -j MASQUERADE</span>\n<span class=\"highlight\">COMMIT</span>\n\n<span class=\"highlight\">*mangle</span>\n<span class=\"highlight\">-A FORWARD --match policy --pol ipsec --dir in -s 10.10.10.0/24 -o eth0 -p tcp -m tcp --tcp-flags SYN,RST SYN -m tcpmss --mss 1361:1536 -j TCPMSS --set-mss 1360</span>\n<span class=\"highlight\">COMMIT</span>\n\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n. . .\n</code></pre>\n<p>A continuación, después de las líneas <code>*filter</code> y de definición de cadenas, agregue un bloque más de configuración:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code>. . .\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir in --proto esp -s 10.10.10.0/24 -j ACCEPT</span>\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir out --proto esp -d 10.10.10.0/24 -j ACCEPT</span>\n</code></pre>\n<p>Estas líneas solicitan al firewall que reenvíe el tráfico <a href=\"https://wiki.wireshark.org/ESP\">de carga de seguridad encapsuladora (ESP)</a>, para que los clientes de VPN puedan conectarse. ESP proporciona seguridad adicional para nuestros paquetes de VPN a medida que circulan por redes no confiables.</p>\n\n<p>Cuando haya terminado, guarde y cierre el archivo una vez que haya verificado que añadió correctamente cada línea. Si utiliza <code>nano</code>, podrá hacerlo presionando <code>CTRL+X</code>, <code>Y</code> y luego <code>ENTER</code>.</p>\n\n<p>Antes de reiniciar el firewall, cambiaremos algunos parámetros de kernel de red para permitir el enrutamiento de una interfaz a otra. El archivo que controla estas configuraciones se llama <code>/etc/ufw/sysctl.conf</code>. Vamos a tener que configurar algunas cosas en el archivo.</p>\n\n<p>El primer reenvío de paquetes IPv4 se debe activar para que el tráfico pueda moverse entre la VPN y las interfaces de red de acceso público en el servidor. A continuación, inhabilitaremos la detección de MTU de ruta para evitar problemas de fragmentación de paquetes. Tampoco aceptaremos redireccionamientos de ICMP ni los enviaremos para prevenir ataques de intermediarios (<a href=\"https://en.wikipedia.org/wiki/Man-in-the-middle_attack\">man-in-the-middle</a>).</p>\n\n<p>Abra el archivo de configuración de parámetros del kernel de UFW con <code>nano</code> o su editor de texto preferido:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/sysctl.conf\n</li></ul></code></pre>\n<p>Ahora, añada la siguiente configuración <code>net/ipv4/ip_forward=1</code> al final del archivo para habilitar el reenvío de paquetes entre interfaces:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_forward=1</span>\n</code></pre>\n<p>A continuación, bloquee el envío y la recepción de paquetes de redireccionamiento de ICMP añadiendo las siguientes líneas al final del archivo:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/conf/all/accept_redirects=0</span>\n<span class=\"highlight\">net/ipv4/conf/all/send_redirects=0</span>\n</code></pre>\n<p>Por último, desactive la detección de MTU de ruta al agregar esta línea al final del archivo:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_no_pmtu_disc=1</span>\n</code></pre>\n<p>Guarde el archivo cuando termine. Ahora, podemos habilitar todos nuestros cambios al deshabilitar y volver a habilitar el firewall, dado que UFW aplica estos ajustes siempre que se reinicia:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw disable\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Se le solicitará confirmar el proceso. Escriba <code>Y</code> para activar UFW nuevamente con las configuraciones nuevas.</p>\n\n<h2 id=\"paso-7-probar-la-conexión-vpn-en-windows-macos-ubuntu-ios-y-android\">Paso 7: Probar la conexión VPN en Windows, macOS, Ubuntu, iOS y Android</h2>\n\n<p>Ahora que todo está configurado, es hora de probarlo. Primero, deberá copiar el certificado de CA que creó e instalarlo en sus dispositivos clientes que se conectarán a la VPN. La forma más sencilla de hacerlo es iniciar sesión en su servidor y mostrar el contenido del archivo de certificado:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cat /etc/ipsec.d/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Visualizará un resultado similar a esto:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>-----BEGIN CERTIFICATE-----\nMIIFNDCCAxygAwIBAgIIHCsidG5mXzgwDQYJKoZIhvcNAQEMBQAwODELMAkGA1UE\n\n. . .\n\nH2YUdz8XNHrJHvMQKWFpi0rlEcMs+MSXPFWE3Q7UbaZJ/h8wpSldSUbQRUlphExJ\ndJ4PX+MUJO/vjG1/ie6Kh25xbBAc3qNq8siiJZDwrg6vjEK7eiZ1rA==\n-----END CERTIFICATE-----\n</code></pre>\n<p>Copie este resultado a su computadora, incluidas las líneas <code>-----BEGIN CERTIFICATE-----</code> y <code>-----END CERTIFICATE-----</code>, y guárdelo en un archivo con un nombre que pueda reconocer, <code>como ca-cert.pem</code>. Asegúrese de que el archivo que cree tenga la extensión <code>.pem.</code></p>\n\n<p>De forma alternativa, <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server\">use SFTP para transferir el archivo a su computadora</a>.</p>\n\n<p>Una vez que descargue el archivo <code>ca-cert.pem</code> a su computadora, podrá configurar la conexión a la VPN.</p>\n\n<h3 id=\"establecer-conexión-desde-windows\">Establecer conexión desde Windows</h3>\n\n<p>Hay varias formas de importar el certificado root y configurar Windows para conectarse a una VPN. En el primer método, se utilizan herramientas gráficas para cada paso. En el segundo, se utilizan los comandos de PowerShell, que se pueden cifrar y modificar para adaptarlos a la configuración de su VPN.</p>\n\n<p><span class='note'>** Nota**: Estas instrucciones se han probado en instalaciones de Windows 10 con versiones 1903 y 1909.<br></span></p>\n\n<h4 id=\"configurar-windows-con-herramientas-gráficas\">Configurar Windows con herramientas gráficas</h4>\n\n<p>Primero, importe el certificado de root siguiendo estos pasos:</p>\n\n<ol>\n<li>Pulse <code>WINDOWS+R</code> para abrir el diálogo <strong>Ejecutar</strong> e ingrese <code>mmc.exe</code> para iniciar la Consola de administración de Windows.</li>\n<li>En el menú <strong>Archivo</strong>, diríjase a <strong>Agregar o quitar complemento</strong>, seleccione <strong>Certificados</strong> en la lista de complementos disponibles y haga clic en <strong>Agregar</strong>.</li>\n<li>Nuestro propósito es que la VPN funcione con cualquier usuario. Por ello, debe seleccionar** Cuenta de equipo** y hacer clic en <strong>Siguiente</strong>.</li>\n<li>Realizaremos algunas configuraciones en la computadora local. Seleccione <strong>Equipo local y</strong> luego haga clic en <strong>Finalizar</strong>.</li>\n<li><p>Debajo del nodo <strong>Raíz de consola,</strong> expanda la entrada <strong>Certificados (equipo local)</strong>, expanda <strong>Entidades de certificación</strong> raíz de confianza, y seleccione la entrada Certificados: <img src=\"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png\" alt=\"de certificados Vista\"> </p></li>\n<li><p>En el menú <strong>Acción</strong>, seleccione <strong>Todas las tareas</strong> y haga clic en <strong>Importar&hellip;</strong> para visualizar el Asistente para importación de certificados. Haga clic en <strong>Siguiente</strong> para pasar la introducción.</p></li>\n<li><p>En la pantalla <strong>Archivo para importar</strong>, presione el botón <strong>Examinar</strong>, asegúrese de cambiar el tipo de archivo de “Certificado X.509 (  <em>.cer;</em> .crt)” a “Todos los archivos (  <em>.</em> )” y seleccione el archivo <code>ca-cert.pem</code> que guardó. Luego haga clic <strong>en Siguiente</strong>.</p></li>\n<li><p>Asegúrese de que el valor de Almacén de certificados sea Entidades de certificación raíz de confianza y haga clic en Siguiente************.</p></li>\n<li><p>Haga clic en <strong>Finalizar</strong> para importar el certificado.</p></li>\n</ol>\n\n<p>Luego, configure la VPN siguiendo estos pasos:</p>\n\n<ol>\n<li>Inicie <strong>el Panel de control y</strong> diríjase a <strong>Centro de redes y recursos compartidos</strong>.</li>\n<li>Haga clic en <strong>Configurar una nueva conexión o red y luego seleccione Conectarse</strong>** a un área de trabajo**.</li>\n<li>Seleccione <strong>Usar mi conexión a Internet (VPN)</strong>.</li>\n<li>Ingrese la información del servidor VPN. Ingrese el nombre del dominio o la dirección IP del servidor en el campo <strong>Dirección de Internet</strong> y luego complete <strong>Nombre de destino</strong> con algo que describa su conexión de VPN. Luego haga clic <strong>en Conectar</strong>.</li>\n</ol>\n\n<h4 id=\"configurar-windows-con-powershell\">Configurar Windows con PowerShell</h4>\n\n<p>Para importar el certificado root de la CA utilizando PowerShell, primero, abra una línea de comandos de PowerShell con privilegios de administrador. Para hacerlo, haga clic con el botón derecho en el icono del menú Inicio y seleccione <code>Windows PowerShell (Admin)</code>. También puede abrir un mensaje de comandos como administrador y escribir <code>powershell</code>.</p>\n\n<p>A continuación, importaremos el certificado con el cmdlet <code>Import-Certificate</code> de PowerShell. En el siguiente comando, el primer argumento <code>-CertStoreLocation</code> garantizará que el certificado se importe en la tienda de <strong>Entidades de certificación root de confianza</strong> de la computadora de modo que todos los programas y usuarios puedan verificar el certificado del servidor VPN. El argumento <code>-FilePath</code> debe apuntar a la ubicación en la que copió el certificado. En el siguiente ejemplo, la ruta es <code>C:\\Users\\sammy\\Documents\\ca-cert.pem</code>. Asegúrese de editar el comando para que coincida con la ubicación que utilizó.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Import-Certificate `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CertStoreLocation cert:\\LocalMachine\\Root\\ `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -FilePath <span class=\"highlight\">C:\\users\\sammy\\Documents\\ca-cert.pem</span>\n</li></ul></code></pre>\n<p>El comando generará algo similar a esto:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>   PSParentPath: Microsoft.PowerShell.Security\\Certificate::LocalMachine\\Root\n\nThumbprint                                Subject\n----------                                -------\nDB00813B4087E9367861E8463A60CEA0ADC5F002  CN=VPN root CA\n</code></pre>\n<p>Ahora, para configurar la VPN con PowerShell, ejecute el siguiente comando. Sustituya el nombre DNS o la dirección IP de su servidor en la línea <code>-ServerAddress</code>. Los diversos indicadores garantizarán que Windows esté configurado correctamente con los parámetros de seguridad adecuados que concuerdan con las opciones que estableció en <code>/etc/ipsec.conf</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Add-VpnConnection -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -ServerAddress \"<span class=\"highlight\">server_domain_or_IP</span>\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -TunnelType \"IKEv2\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationMethod \"EAP\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionLevel \"Maximum\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -RememberCredential `\n</li></ul></code></pre>\n<p>Si el comando es exitoso, no habrá ningún resultado. Para confirmar que la VPN esté configurada correctamente, utilice el cmdlet <code>Get-VPNConnection</code>:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Get-VpnConnection -Name \"VPN Connection\"\n</li></ul></code></pre>\n<p>Verá un resultado como el siguiente:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Name                  : VPN Connection\nServerAddress         : <span class=\"highlight\">your_server_ip</span>\nAllUserConnection     : False\nGuid                  : {B055A1AB-175C-4028-B4A8-D34309A2B20E}\nTunnelType            : Ikev2\nAuthenticationMethod  : {Eap}\nEncryptionLevel       : Maximum\nL2tpIPsecAuth         :\nUseWinlogonCredential : False\nEapConfigXmlStream    : #document\nConnectionStatus      : Disconnected\nRememberCredential    : True\nSplitTunneling        : False\nDnsSuffix             :\nIdleDisconnectSeconds : 0\n</code></pre>\n<p>Por defecto, Windows selecciona algoritmos más antiguos y lentos. Ejecute el cmdlet <code>Set-VpnConnectionIPsecConfiguration</code> para actualizar los parámetros de cifrado que Windows utilizará para el intercambio de claves IKEv2 y para cifrar paquetes:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Set-VpnConnectionIPsecConfiguration -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CipherTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -DHGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -IntegrityCheckMethod SHA384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -PfsGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionMethod GCMAES256\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: Si desea eliminar la conexión VPN y volver a configurarla con diferentes opciones, puede ejecutar el cmdlet <code>Remove-VpnConnection</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Remove-VpnConnection -Name \"VPN Connection\" -Force\n</li></ul></code></pre>\n<p>El indicador <code>-Force</code> omite el mensaje de confirmación de la eliminación. Para eliminar la VPN con este comando, debe estar desconectado de ella.<br></p></span>\n\n<h4 id=\"conectarse-a-la-vpn\">Conectarse a la VPN</h4>\n\n<p>Una vez que tenga el certificado importado y la VPN configurada con cualquier método, su nueva conexión VPN será visible en la lista de redes. Seleccione la VPN y haga clic <strong>en Conectar</strong>. Se le solicitará su nombre de usuario y contraseña. Escríbalos y haga clic <strong>en Aceptar. Con esto,</strong> establecerá la conexión.</p>\n\n<h3 id=\"establecer-conexión-desde-macos\">Establecer conexión desde macOS</h3>\n\n<p>Siga estos pasos para importar el certificado:</p>\n\n<ol>\n<li>Haga doble clic en el archivo de certificado. <strong>Acceso a Llaveros aparecerá con el diálogo “Acceso a Llaveros</strong> está intentando modificar el sistema de administración de contraseñas. Ingrese su contraseña para autorizarlo”.</li>\n<li>Ingrese su contraseña y haga clic en <strong>Modificar llavero.</strong></li>\n<li>Haga clic en el certificado de VPN recién importado. Con esto, se abrirá abre una pequeña ventana de propiedades en la que podrá especificar los niveles de confianza. Fije <strong>Seguridad de IP (IPSec)</strong> en <strong>Confiar siempre.</strong> Se solicitará que ingrese su contraseña nuevamente. Esta configuración guarda de forma automática la contraseña una vez que se ingresa.</li>\n</ol>\n\n<p>Ahora que el certificado se importó y es confiable, configure la conexión VPN con estos pasos:</p>\n\n<ol>\n<li>Diríjase a <strong>Preferencias del Sistema</strong> y seleccione <strong>Red</strong>.</li>\n<li>Haga clic en el botón pequeño de “adición” en la parte inferior izquierda de la lista de redes.</li>\n<li>En la ventana emergente que aparecerá, fije el <strong>valor de Interfaz en VPN y el de Tipo de</strong> VPN en <strong>IKEv2,</strong> y asigne un nombre a la conexión.</li>\n<li>En los campos <strong>Servidor</strong> e <strong>ID remoto,</strong> ingrese el nombre de dominio o la dirección IP del servidor. Deje ID <strong>local</strong> en blanco.</li>\n<li>Haga clic en <strong>Ajustes de autenticación</strong>, seleccione <strong>Nombre del usuario</strong>, e ingrese el nombre de usuario y la contraseña que configuró para su usuario de VPN. Luego haga clic <strong>en Aceptar</strong>.</li>\n</ol>\n\n<p>Por último, haga clic en <strong>Conectar</strong> para conectarse a la VPN. Con esto, debería establecer la conexión con la VPN.</p>\n\n<h3 id=\"establecer-conexión-desde-ubuntu\">Establecer conexión desde Ubuntu</h3>\n\n<p>Para conectarse desde un equipo con Ubuntu, puede configurar y administrar StrongSwan como un servicio o usar un comando único cada vez que desee conectarse. Se proporcionan instrucciones para ambas alternativas.</p>\n\n<h4 id=\"administrar-strongswan-como-un-servicio\">Administrar StrongSwan como un servicio</h4>\n\n<p>Para administrar StrongSwan como servicio, deberá realizar los siguientes pasos de configuración.</p>\n\n<p>Primero, actualice su caché de paquetes local con <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo apt update\n</li></ul></code></pre>\n<p>A continuación, instale StrongSwan y los complementos necesarios para la autenticación:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Ahora, necesitará tener una copia del certificado de CA en el directorio <code>/etc/ipsec.d/cacerts</code> para que su cliente pueda verificar la identidad del servidor. Ejecute el siguiente comando para copiar el archivo <code>ca-cert.pem</code> a su lugar:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Para garantizar que la VPN solo se ejecute bajo demanda, utilice <code>systemctl</code> para deshabilitar la ejecución automática de StrongSwan:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl disable --now strongswan-starter\n</li></ul></code></pre>\n<p>A continuación, configure el nombre de usuario y la contraseña que utilizará para la autenticación en el servidor VPN. Edite <code>/etc/ipsec.secrets</code> con nano o su editor preferido:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<p>Añada la siguiente línea, asegurándose de editar los valores resaltados de nombre de usuario y contraseña para que coincidan con los que configuró en el servidor:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Por último, edite el archivo <code>/etc/ipsec.conf</code> para configurar su cliente para que coincida con la configuración del servidor:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code>config setup\n\nconn ikev2-rw\n    right=<span class=\"highlight\">server_domain_or_IP</span>\n    # This should match the `leftid` value on your server's configuration\n    rightid=<span class=\"highlight\">server_domain_or_IP</span>\n    rightsubnet=0.0.0.0/0\n    rightauth=pubkey\n    leftsourceip=%config\n    leftid=<span class=\"highlight\">username</span>\n    leftauth=eap-mschapv2\n    eap_identity=%identity\n    auto=start\n</code></pre>\n<p>Para conectarse a la VPN, escriba lo siguiente:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start strongswan-starter\n</li></ul></code></pre>\n<p>Para desconectarse nuevamente, escriba lo siguiente:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop strongswan-starter\n</li></ul></code></pre>\n<h4 id=\"usar-el-cliente-charon-cmd-para-conexiones-únicas\">Usar el cliente <code>charon-cmd</code> para conexiones únicas</h4>\n\n<p>Para administrar StrongSwan como servicio, deberá realizar los siguientes pasos de configuración.</p>\n\n<p>Primero, actualice su caché de paquetes local con <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>A continuación, instale StrongSwan y los complementos necesarios para la autenticación:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Ahora, necesitará tener una copia del certificado de CA en el directorio <code>/etc/ipsec.d/cacerts</code> para que su cliente pueda verificar la identidad del servidor. Ejecute el siguiente comando para copiar el archivo <code>ca-cert.pem</code> a su lugar:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>En este punto, puede conectarse al servidor VPN con <code>charon-cmd</code> utilizando el certificado de CA del servidor, la dirección IP del servidor VPN y el nombre de usuario que configuró.</p>\n\n<p>Ejecute el siguiente comando siempre que quiera conectarse a la VPN:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo charon-cmd --cert ca-cert.pem --host <span class=\"highlight\">vpn_domain_or_IP</span> --identity <span class=\"highlight\">your_username</span>\n</li></ul></code></pre>\n<p>Cuando se le solicite, proporcione la contraseña del usuario de la VPN para conectarse a ella. Para desconectarse, pulse <code>CTRL+C</code> en la terminal y espere que la conexión se cierre.</p>\n\n<h3 id=\"establecer-conexión-desde-ios\">Establecer conexión desde iOS</h3>\n\n<p>Para configurar la conexión de VPN en un dispositivo iOS, siga estos pasos:</p>\n\n<ol>\n<li>Envíese un correo electrónico con el certificado de root adjunto.</li>\n<li>Abra el correo electrónico en su dispositivo iOS, toque el archivo del certificado adjunto y luego seleccione <strong>Instalar</strong> e ingrese su código de acceso. Una vez que se <strong>instale, pulse Listo</strong>.</li>\n<li>Diríjase a <strong>Configuración</strong>, <strong>General</strong>, <strong>VPN</strong> y toque <strong>Agregar configuración de VPN</strong>. Con esto, se mostrará la pantalla de configuración de la conexión de la VPN.</li>\n<li>Toque <strong>Tipo</strong> y seleccione <strong>IKEv2</strong>.</li>\n<li>En el campo <strong>Descripción,</strong> ingrese un nombre corto para la conexión de VPN. Puede ser el que desee.</li>\n<li>En los campos <strong>Servidor</strong> e <strong>ID remoto,</strong> ingrese el nombre de dominio o la dirección IP del servidor. Puede dejar el campo <strong>ID local</strong> vacío.</li>\n<li>Ingrese su nombre de usuario y contraseña en la sección <strong>Autenticación</strong> y toque <strong>Listo</strong>.</li>\n<li>Seleccione la conexión de VPN que acaba de crear y toque el conmutador en la parte superior de la página. Con esto, se conectará.</li>\n</ol>\n\n<h3 id=\"establecer-conexión-desde-android\">Establecer conexión desde Android</h3>\n\n<p>Siga estos pasos para importar el certificado:</p>\n\n<ol>\n<li>Envíese un correo electrónico con el certificado de CA adjunto. Guarde el certificado CA en su carpeta de descargas.</li>\n<li>Descargue <a href=\"https://play.google.com/store/apps/details?id=org.strongswan.android&amp;hl=en_US\">StrongSwan VPN Client</a> de Play Store.</li>\n<li>Abra la aplicación. Presione el icono &ldquo;más&rdquo; (<strong>&hellip;</strong>) en la esquina superior derecha y seleccione <strong>Certificados de CA</strong>.</li>\n<li>Toque nuevamente el ícono “más” ( <strong>&hellip;</strong>) en la esquina superior derecha. Seleccione <strong>Importar certificado</strong>.</li>\n<li>Busque el archivo del certificado de CA en su carpeta de descargas y selecciónelo para importarlo a la aplicación.</li>\n</ol>\n\n<p>Ahora que se importó el certificado a la aplicación StrongSwan, puede configurar la conexión de VPN con los siguientes pasos:</p>\n\n<ol>\n<li>En la aplicación, toque <strong>ADD VPN PROFILE</strong> en la parte superior.</li>\n<li>Complete el <strong>campo Server</strong> con el nombre de dominio o la dirección IP pública de su servidor de VPN.</li>\n<li>Asegúrese de seleccionar <strong>IKEv2 EAP (Username/Password)</strong> en la categoría “Type” para la VPN.</li>\n<li>Complete los <strong>campos Username</strong> y <strong>Password</strong> con las credenciales que definió en el servidor.</li>\n<li>Anule la selección de <strong>Select automatically</strong> en la sección <strong>CA certificate</strong> y haga clic en  <strong>Select CA certificate</strong> .</li>\n<li>Toque la pestaña <strong>IMPORTED</strong> en la parte superior de la pantalla y elija la CA que importó (recibirá el nombre “CA rootVPN” si no cambió “DN” previamente).</li>\n<li>Si desea, complete <strong>el campo Profile name (optional)</strong> con un nombre más descriptivo.</li>\n</ol>\n\n<p>Cuando desee conectarse a la VPN, haga clic en el perfil que acaba de crear en la aplicación StrongSwan.</p>\n\n<h3 id=\"solución-de-problemas-en-conexiones\">Solución de problemas en conexiones</h3>\n\n<p>Si no puede importar el certificado, asegúrese de que el archivo contenga la extensión <code>.pem en lugar .pem.txt</code><code>.</code></p>\n\n<p>Si no puede conectarse a la VPN, verifique el nombre o la dirección IP del servidor que usó. El nombre de dominio o la dirección IP del servidor debe coincidir con lo que configuró como nombre común (CN) al crear el certificado. Si no coinciden, la conexión de VPN no funcionará. Por ejemplo, si configura un certificado con el CN <code>vpn.example.com</code>, <em>debe</em> usar <code>vpn.example.com</code> cuando ingrese la información del servidor VPN. Verifique bien el comando que usó para generar el certificado y los valores que empleó al crear su conexión de VPN.</p>\n\n<p>Por último, verifique la configuración de VPN para garantizar que el valor <code>leftid</code> esté configurado con el símbolo <code>@</code> si usa un nombre de dominio:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    leftid=<span class=\"highlight\">@</span>vpn.example.com\n</code></pre>\n<p>Y si usa una dirección IP, asegúrese de que se omita el símbolo <code>@</code>. También asegúrese de haber incluido tanto <code>--san @<span class=\"highlight\">IP_address</span></code> como <code>--san <span class=\"highlight\">IP_address</span></code> al generar el archivo <code>server-cert.pem</code>.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>A través de este tutorial, creó un servidor de VPN que usa el protocolo IKEv2. Aprendió sobre las directivas que controlan los lados <code>izquierdo</code> y <code>derecho</code> de una conexión tanto en el servidor como en los clientes. También configuró un cliente de Windows, macOS, iOS, Android o Linux para conectarse a la VPN.</p>\n\n<p>Para agregar o eliminar usuarios, regrese al Paso 5. Cada línea de <code>/etc/ipsec.secrets</code> corresponde a un usuario, por lo tanto, para agregar o eliminar usuarios, o modificar contraseñas, solo se debe editar el archivo.</p>\n\n<p>Ahora, puede estar seguro de que sus actividades en línea se mantendrán seguras esté donde esté y en cualquier dispositivo que utilice para acceder a Internet.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:11 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png","linkMd5":"ad3d959e24463022254533efb50ad457","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp","destWidth":1436,"destHeight":754,"sourceBytes":109775,"destBytes":168410,"author":"Jamon Camisso","articleImgCdnMap":{"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp"},"publishedOrCreatedDate":1598860106969},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como usar o ThreadPoolExecutor em Python 3","link":"https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3-pt","description":"<p><em>O autor selecionou a <a href=\"https://www.brightfunds.org/funds/write-for-donations-covid-19-relief-fund\">COVID-19 Relief Fund</a>​​​​​ para receber uma doação como parte do programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introdução\">Introdução</h3>\n\n<p>Os <em>threads</em> em <a href=\"https://www.python.org/\">Python</a> são uma forma de paralelismo que permitem que seu programa execute vários procedimentos ao mesmo tempo. O paralelismo em Python também pode ser alcançado usando vários processos, mas os threads são particularmente adequados para acelerar aplicativos que envolvam quantidades significativas de E/S (entrada/saída).</p>\n\n<p>Alguns exemplo de <a href=\"https://en.wikipedia.org/wiki/I/O_bound#:%7E:text=In%20computer%20science%2C%20I%2FO,a%20task%20being%20CPU%20bound.\">operações limitadas por E/S</a> incluem realizar solicitações Web e ler dados de arquivos. Em contraste com as operações limitadas por E/S, <a href=\"https://en.wikipedia.org/wiki/CPU-bound\">as operações limitadas por CPU</a> (como realizar operações matemáticas com a biblioteca padrão do Python) não serão tão beneficiadas com os threads em Python.</p>\n\n<p>O Python 3 inclui o utilitário <code>ThreadPoolExecutor</code> para executar o código em um thread.</p>\n\n<p>Neste tutorial, usaremos o <code>ThreadPoolExecutor</code> para fazer solicitações de rede de forma conveniente. Definiremos uma função adequada para a invocação dentro de threads, usaremos o <code>ThreadPoolExecutor</code> para executar essa função e processaremos os resultados dessas execuções.</p>\n\n<p>Para este tutorial, faremos solicitações de rede para verificar a existência de páginas da <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipédia</a>.</p>\n\n<p><span class='note'><strong>Nota:</strong> o fato de as operações limitadas por E/S se beneficiarem mais dos threads do que as operações limitadas por CPU tem origem em uma idiossincrasia em Python chamada <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\"><em>global interpreter lock</em></a>. Saiba mais sobre o global interpreter lock <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">do Python na documentação oficial do Python</a>.<br></span></p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Para aproveitar ao máximo este tutorial, é recomendado ter alguma familiaridade com a programação em Python e a um ambiente de programação local do Python com <code>requests</code> (solicitações) instaladas.</p>\n\n<p>Você pode revisar estes tutoriais para as informações básicas necessárias:</p>\n\n<ul>\n<li><a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-python-3\">Como programar em Python 3</a></li>\n<li><p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">Como instalar o Python 3 e configurar um ambiente de programação local no Ubuntu 18.04</a></p></li>\n<li><p>Para instalar o pacote <code>requests</code> em seu <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">ambiente de programação local do Python</a>, execute este comando:</p></li>\n</ul>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pip install --user requests==2.23.0\n</li></ul></code></pre>\n<h2 id=\"passo-1-—-definindo-uma-função-para-ser-executada-em-threads\">Passo 1 — Definindo uma função para ser executada em threads</h2>\n\n<p>Vamos começar definindo uma função que gostaríamos de executar com a ajuda dos threads.</p>\n\n<p>Usando o <code>nano</code> ou seu editor de texto/ambiente de desenvolvimento preferido, abra este arquivo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano wiki_page_function.py\n</li></ul></code></pre>\n<p>Para este tutorial, vamos escrever uma função que determina se uma página da Wikipédia existe ou não:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n</code></pre>\n<p>A <a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-python-3\">função</a> <code>get_wiki_page_existence</code> aceita dois argumentos: uma URL de uma página da Wikipédia (<code>wiki_page_url</code>) e um número de segundos <code>timeout</code> para se esperar por uma resposta dessa URL.</p>\n\n<p>A <code>get_wiki_page_existence</code> usa o pacote <a href=\"https://requests.readthedocs.io/en/master/\"><code>requests</code></a> para fazer uma solicitação Web a essa URL. Dependendo do <a href=\"https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes\">código de status</a> da <code>response</code> (resposta) HTTP, uma string que descreve se a página existe ou não é retornada. Códigos de status diferentes representam resultados diferentes de uma solicitação HTTP. Este procedimento pressupõe que um código de status <code>200</code> de &ldquo;sucesso&rdquo; significa que a página da Wikipédia existe e um código de status <code>404</code> &ldquo;não encontrado&rdquo; significa que a página da Wikipédia não existe.</p>\n\n<p>Conforme descrito na seção Pré-requisitos, você precisará do pacote <code>requests</code> instalado para executar esta função.</p>\n\n<p>Vamos tentar executar a função adicionando a <code>url</code> e a chamada de função após a função <code>get_wiki_page_existence</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">. . .\nurl = \"https://en.wikipedia.org/wiki/Ocean\"\nprint(get_wiki_page_existence(wiki_page_url=url))\n</code></pre>\n<p>Uma vez adicionado o código, salve e feche o arquivo.</p>\n\n<p>Se executarmos este código:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Veremos um resultado como o seguinte:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Ocean - exists\n</code></pre>\n<p>Chamar a função <code>get_wiki_page_existence</code> com uma página da Wikipédia válida retorna uma string que confirma que a página, de fato, existe.</p>\n\n<p><span class='warning'><strong>Aviso:</strong> em geral, não é seguro compartilhar o estado ou objetos Python entre threads sem tomar cuidados especiais para evitar erros de simultaneidade. Ao definir uma função a ser executada em um thread, é melhor definir uma função que execute uma tarefa única e não compartilhe ou publique o estado em outros threads. A <code>get_wiki_page_existence</code> é um exemplo de uma função como essa.<br></span></p>\n\n<h2 id=\"passo-2-—-usando-o-threadpoolexecutor-para-executar-uma-função-em-threads\">Passo 2 — Usando o ThreadPoolExecutor para executar uma função em threads</h2>\n\n<p>Agora que temos uma função adequada à invocação com threads, podemos usar o <code>ThreadPoolExecutor</code> para realizar várias invocações dessa função de maneira conveniente.</p>\n\n<p>Vamos adicionar o seguinte código destacado ao seu programa em <code>wiki_page_function.py</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n<span class=\"highlight\">import concurrent.futures</span>\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Ocean\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Island\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/this_page_does_not_exist\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Shark\",</span>\n<span class=\"highlight\">]</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n</code></pre>\n<p>Vamos dar uma olhada em como esse código funciona:</p>\n\n<ul>\n<li>O <code>concurrent.futures</code> é importado para nos dar acesso ao <code>ThreadPoolExecutor</code>.</li>\n<li>A declaração <code>with</code> é usada para criar um <code>executor</code> de instância do <code>ThreadPoolExecutor</code> que irá esvaziar os threads imediatamente após a conclusão.</li>\n<li>Quatro tarefas são <code>submitted</code> (submetidas) ao <code>executor</code>: uma para cada uma das URLs na lista <code>wiki_page_urls</code>.</li>\n<li>Cada chamada a <code>submit</code> retorna uma <a href=\"https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future\">instância <code>Future</code></a> que está armazenada na lista <code>futures</code>.</li>\n<li>A função <code>as_completed</code> espera cada chamada <code>get_wiki_page_existence</code> <code>Future</code> ser concluída para podermos imprimir seu resultado.</li>\n</ul>\n\n<p>Se executarmos esse programa novamente com o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Veremos um resultado como o seguinte:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Island - exists\nhttps://en.wikipedia.org/wiki/Ocean - exists\nhttps://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\nhttps://en.wikipedia.org/wiki/Shark - exists\n</code></pre>\n<p>Esse resultado faz sentido: 3 das URLs são páginas válidas da Wikipédia, e uma delas, a <code>this_page_does_not_exist</code>, não é. Observe que seu resultado pode estar ordenado de maneira diferente do que este. A função <code>concurrent.futures.as_completed</code> nesse exemplo retorna resultados assim que eles estiverem disponíveis, independentemente da ordem em que as tarefas foram enviadas.</p>\n\n<h2 id=\"passo-3-—-processando-exceções-de-execuções-de-funções-em-threads\">Passo 3 — Processando exceções de execuções de funções em threads</h2>\n\n<p>No passo anterior, <code>get_wiki_page_existence</code> retornou com sucesso um valor para todas as nossas invocações. Neste passo, veremos que o <code>ThreadPoolExecutor</code> também pode apurar exceções geradas em invocações de função em threads.</p>\n\n<p>Vamos considerar o seguinte bloco de código de exemplo:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n\nwiki_page_urls = [\n    \"https://en.wikipedia.org/wiki/Ocean\",\n    \"https://en.wikipedia.org/wiki/Island\",\n    \"https://en.wikipedia.org/wiki/this_page_does_not_exist\",\n    \"https://en.wikipedia.org/wiki/Shark\",\n]\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(</span>\n            <span class=\"highlight\">executor.submit(</span>\n                <span class=\"highlight\">get_wiki_page_existence, wiki_page_url=url, timeout=0.00001</span>\n            <span class=\"highlight\">)</span>\n        <span class=\"highlight\">)</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">try:</span>\n            <span class=\"highlight\">print(future.result())</span>\n        <span class=\"highlight\">except requests.ConnectTimeout:</span>\n            <span class=\"highlight\">print(\"ConnectTimeout.\")</span>\n</code></pre>\n<p>Este bloco de código é quase idêntico ao que usamos no Passo 2, mas possui duas diferenças chave:</p>\n\n<ul>\n<li>Agora, passamos <code>timeout=0.001</code> para <code>get_wiki_page_existence</code>. Como o pacote <code>requests</code> não será capaz de completar sua solicitação Web à Wikipédia em <code>0.00001</code> segundos, ele criará uma exceção <code>ConnectTimeout</code>.</li>\n<li>Nós capturamos exceções <code>ConnectTimeout</code> geradas pelo <code>future.result()</code> e imprimimos uma string cada vez que fazemos isso.</li>\n</ul>\n\n<p>Se executarmos o programa novamente, veremos o seguinte resultado:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>ConnectTimeout.\nConnectTimeout.\nConnectTimeout.\nConnectTimeout.\n</code></pre>\n<p>Quatro mensagens <code>ConnectTimeout</code> são impressas — uma para cada uma de nossas quatro <code>wiki_page_urls</code>, uma vez que nenhuma delas pôde ser concluída em <code>0.00001</code> segundos e cada uma das quatro chamadas <code>get_wiki_page_existence</code> gerou a exceção <code>ConnectTimeout</code>.</p>\n\n<p>Agora, você viu que se uma chamada de função submetida a um <code>ThreadPoolExecutor</code> gera uma exceção, então essa exceção pode ser apurada normalmente chamando o <code>Future.result</code>. Chamar o <code>Future.result</code> em todas as suas invocações enviadas garante que seu programa não perca nenhuma exceção gerada em sua função em threads.</p>\n\n<h2 id=\"passo-4-—-comparando-o-tempo-de-execução-com-e-sem-threads\">Passo 4 — Comparando o tempo de execução com e sem threads</h2>\n\n<p>Agora, vamos verificar se usar o <code>ThreadPoolExecutor</code> realmente torna seu programa mais rápido.</p>\n\n<p>Primeiro, vamos cronometrar o <code>get_wiki_page_existence</code> se executarmos ele sem threads:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\"><span class=\"highlight\">import time</span>\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]</span>\n\n<span class=\"highlight\">print(\"Running without threads:\")</span>\n<span class=\"highlight\">without_threads_start = time.time()</span>\n<span class=\"highlight\">for url in wiki_page_urls:</span>\n    <span class=\"highlight\">print(get_wiki_page_existence(wiki_page_url=url))</span>\n<span class=\"highlight\">print(\"Without threads time:\", time.time() - without_threads_start)</span>\n</code></pre>\n<p>Nesse exemplo de código, chamamos nossa função <code>get_wiki_page_existence</code> com cinquenta URLs de páginas diferentes da Wikipedia uma a uma. Usamos a <a href=\"https://docs.python.org/3/library/time.html#time.time\">função <code>time.time()</code></a> para imprimir o número de segundos que nosso programa leva para ser executado.</p>\n\n<p>Se executarmos esse código novamente como antes, veremos um resultado como o seguinte:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running without threads:\nhttps://en.wikipedia.org/wiki/0 - exists\nhttps://en.wikipedia.org/wiki/1 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nWithout threads time: 5.803015232086182\n</code></pre>\n<p>As entradas 2-47 nesse resultado foram omitidas para maior concisão.</p>\n\n<p>O número de segundos impressos depois de <code>Without threads time</code> será diferente quando você executar o código em sua máquina – não tem problema, você só está recebendo um número que servirá como base para se comparar com uma solução que usa o <code>ThreadPoolExecutor</code>. Neste caso, foram <code>~5.803</code> segundos.</p>\n\n<p>Vamos executar as mesmas cinquenta URLs da Wikipedia através do <code>get_wiki_page_existence</code>, mas desta vez usando o <code>ThreadPoolExecutor</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import time\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\nwiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n\n<span class=\"highlight\">print(\"Running threaded:\")</span>\n<span class=\"highlight\">threaded_start = time.time()</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n<span class=\"highlight\">print(\"Threaded time:\", time.time() - threaded_start)</span>\n</code></pre>\n<p>O código é o mesmo que criamos no Passo 2, apenas com a adição de algumas declarações de impressão que nos mostram o número de segundos que o nosso código leva para ser executado.</p>\n\n<p>Se executarmos o programa novamente, veremos o seguinte:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running threaded:\nhttps://en.wikipedia.org/wiki/1 - exists\nhttps://en.wikipedia.org/wiki/0 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nThreaded time: 1.2201685905456543\n</code></pre>\n<p>Novamente, o número de segundos impressos após <code>Threaded time</code> será diferente em seu computador (assim como a ordem do seu resultado).</p>\n\n<p>Agora, compare o tempo de execução para obter as cinquenta URLs de páginas da Wikipédia com e sem threads.</p>\n\n<p>Na máquina usada neste tutorial, o processo sem threads levou <code>~5.803</code> segundos e com threads levou <code>~1.220</code> segundos. Nosso programa foi executado de maneira significativamente mais rápida com threads.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Neste tutorial, você aprendeu como usar o utilitário <code>ThreadPoolExecutor</code> em Python 3 para executar eficientemente códigos limitados por E/S. Você criou uma função adequada à invocação dentro de threads, aprendeu como recuperar tanto o resultado quanto as exceções de execuções em threads dessa função e observou o ganho de desempenho obtido usando threads.</p>\n\n<p>A partir daqui, você pode aprender mais sobre outras funções de simultaneidade oferecidas pelo <a href=\"https://docs.python.org/3/library/concurrent.futures.html\">módulo <code>concurrent.futures</code></a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:49 +0000","feedId":8037,"bgimg":"","linkMd5":"c3f751981a282cf419889cd6b8fe6b74","bgimgJsdelivr":"","metaImg":"","author":"DavidMuller","publishedOrCreatedDate":1598860106963},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"How To Create Your First Cross-Platform Desktop Application with Electron on macOS","link":"https://www.digitalocean.com/community/tutorials/how-to-create-your-first-cross-platform-desktop-application-with-electron-on-macos","description":"<p><em>The author selected <a href=\"https://www.brightfunds.org/organizations/apache-software-foundation\">the Apache Software Foundation</a> to receive a donation as part of the <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> program.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://www.electronjs.org/\">Electron</a> is an open source framework for creating native applications with web technologies like JavaScript, HTML, and CSS. It combines support for building and running applications cross platform on Mac, Windows, and Linux. Many popular desktop applications have been built using Electron, such as Visual Studio Code, WhatsApp, Twitch, Slack, and Figma.</p>\n\n<p>Electron facilitates designing more complex application features like automatic updates or native menus, which means that developers can focus on the core design of their application. Further, Electron is an open source project maintained by GitHub with an active community of contributors.</p>\n\n<p>In this tutorial, you&rsquo;ll first set up a project and install Electron. After that you&rsquo;ll create your first &ldquo;Hello World!&rdquo; application using Electron and customize it. You&rsquo;ll implement graceful window setup and create new windows for the application. After following all of these steps, you will have an Electron cross-platform desktop application on macOS.</p>\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\n<p>To complete this tutorial, you will need:</p>\n\n<ul>\n<li>Node.js installed on your machine and a local development environment on macOS. Follow the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">How to Install Node.js and Create a Local Development Environment on macOS</a> tutorial.</li>\n</ul>\n\n<p><span class='note'><strong>Note</strong>: This tutorial was tested on macOS 10.15.3.<br></span></p>\n\n<h2 id=\"step-1-—-creating-the-project\">Step 1 — Creating the Project</h2>\n\n<p>First you&rsquo;ll install Electron to your machine and create the project folder to build the desktop application.</p>\n\n<p>To start the Electron installation process, create the project folder called <code>hello-world</code> and navigate to the folder with the following commands:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir hello-world\n</li><li class=\"line\" data-prefix=\"$\">cd hello-world\n</li></ul></code></pre>\n<p>Next, you&rsquo;ll initiate your project by creating the <code>package.json</code> file.</p>\n\n<p>The <code>package.json</code> file is an essential part of a Node.js application, it performs the following:</p>\n\n<ul>\n<li>Lists the packages that your project depends on.</li>\n<li>Specifies the package version your project can use.</li>\n</ul>\n\n<p>To create the <code>package.json</code> file, run the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm init\n</li></ul></code></pre>\n<p>You will be asked a series of questions, starting with the package name. You can use the default application name, <code>hello-world</code>, as your package name.</p>\n\n<p>Then it asks for the version. To use v1.0.0, which comes as default, press <code>ENTER</code>.</p>\n\n<p>After that, it asks for a description. There you can add a description of your project, something like: <code>hello world application on Electron.js</code>.</p>\n\n<p>Next, for the entry point, enter <code>main.js</code>.</p>\n\n<p>The file invoked at the initial run time of application is known as the entry point. In this case, <code>main.js</code> is the entry point of the <code>package.json</code> file.</p>\n\n<p>For the remaining questions, accept the defaults with <code>ENTER</code>.</p>\n\n<p><span class='note'><strong>Note:</strong> In this tutorial we&rsquo;re leaving the author and license empty, but you can use your first and last name as the author depending on your project status. The license of your package specifies how others are permitted to use the application, and any restrictions you&rsquo;re placing on it. The most common licenses are: <em>MIT</em>, <em>BSD-2-Clause</em>, and <em>ISC</em>. For more details, check the <a href=\"https://spdx.org/licenses/\">full list of SPDX license IDs</a>. From there you can use a preferred license for your project, but this is not mandatory.<br></span></p>\n\n<p>Having followed the prompts you&rsquo;ll receive the following output:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output:\">Output:</div>. . .\nUse `npm install &lt;pkg&gt;` afterwards to install a package and\nsave it as a dependency in the package.json file.\nPress ^C at any time to quit.\npackage name: (hello-world)\nversion: (1.0.0)\ndescription: hello world application on Electron.js\nentry point: (index.js) main.js\ntest command:\ngit repository:\nkeywords:\nauthor:\nlicense: (ISC)\n</code></pre>\n<p>After that, you&rsquo;ll be asked to confirm the configuration:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output:\">Output:</div>About to write to /hello-world/package.json:\n\n{\n  \"name\": \"hello-world\",\n  \"version\": \"1.0.0\",\n  \"description\": \"hello world application on Electron.js\",\n  \"main\": \"main.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"\n  },\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n\nIs this OK? (yes)\n</code></pre>\n<p>You&rsquo;ll now have the newly generated <code>package.json</code> file inside your <code>hello-world</code> project directory. Next you&rsquo;ll install Electron.</p>\n\n<h2 id=\"step-2-—-installing-electron\">Step 2 — Installing Electron</h2>\n\n<p>Now you&rsquo;ll implement the configuration of the <code>package.json</code> file and install Electron.</p>\n\n<p>For that, open the <code>package.json</code> file in your preferred text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano package.json\n</li></ul></code></pre>\n<p>Add the following highlighted line inside the <code>scripts</code> object:</p>\n<div class=\"code-label \" title=\"package.json\">package.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-json\">{\n  \"name\": \"hello-world\",  \"version\": \"1.0.0\",\n  \"description\": \"hello world application on Electron.js\",\n  \"main\": \"main.js\",\n  \"scripts\": {\n    <span class=\"highlight\">\"start\": \"electron .\",</span>\n    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"\n },\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n</code></pre>\n<p>The <code>scripts</code> property takes an object with as many key/value pairs as desired. Each one of the keys in these key/value pairs is the name of a command that can be run. The corresponding value of each key is the actual command that can be run. Scripts are frequently used for testing, building, and streamlining of the needed commands.</p>\n\n<p>In this project, you&rsquo;ll use <code>start</code> as a key and <code>electron .</code> as a value.</p>\n\n<p>Once you&rsquo;re done, save and exit the file.</p>\n\n<p>Next, you&rsquo;ll install Electron as a development dependency in your project. Run the following command inside your <code>hello-world</code> project directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm install --save-dev electron\n</li></ul></code></pre>\n<p>After successfully installing the Electron dependency to your project, the <code>package.json</code> file will be similar to this:</p>\n<div class=\"code-label \" title=\"package.json\">package.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-json\">{\n  \"name\": \"hello-world\",\n  \"version\": \"1.0.0\",\n  \"description\": \"hello world application on Electron.js\",\n  \"main\": \"main.js\",\n  \"scripts\": {\n    \"start\": \"electron .\",\n    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"\n  },\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"devDependencies\": {\n    \"electron\": \"^8.2.1\"\n  }\n}\n</code></pre>\n<p>The dependency property takes an object that has the name and version for each dependency.</p>\n\n<p>There are two dependency properties <code>dependencies</code> and <code>devDependencies</code> that can be identified with a key difference. The <code>dependencies</code> property is used to define the dependencies that a module needs to run in production. The <code>devDependencies</code> property is usually used to define the dependencies the module needs to run in development. To install the package as <code>devDependencies</code> use the <code>--save-dev</code> flag with your command.</p>\n\n<p>You&rsquo;ve installed Electron to your machine and created the project folder to build your application. Now you&rsquo;ll write your first <code>hello-world</code> application using the Electron framework.</p>\n\n<h2 id=\"step-3-—-writing-the-quot-hello-world-quot-application\">Step 3 — Writing the &ldquo;Hello World!&rdquo; Application</h2>\n\n<p>Let&rsquo;s start writing your first Electron application.</p>\n\n<p>Electron operates with two types of processes: the main process (server-side) and the renderer process (client-side). The Electron main process is run on the Node.js runtime.</p>\n\n<p>For that, you&rsquo;ll be working with two files: <code>main.js</code> and <code>index.html</code>.</p>\n\n<p><code>main.js</code> is your application&rsquo;s main process and <code>index.html</code> is your Electron application renderer process.</p>\n<pre class=\"code-pre \"><code>hello-world\n+-- package.json\n+-- main.js\n+-- index.html\n</code></pre>\n<p>Next, we create a manual browser window and load the content using <a href=\"https://www.electronjs.org/docs/api\">Electron API</a> calls, which you can use to execute HTML, CSS, JavaScript, and so on.</p>\n\n<p>First open your <code>main.js</code> file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano main.js\n</li></ul></code></pre>\n<p>Then add the following line of code to implement the <code>BrowserWindow</code> module:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const { app, BrowserWindow } = require('electron')\n</code></pre>\n<p>This contains two <a href=\"https://www.digitalocean.com/community/tutorials/understanding-destructuring-rest-parameters-and-spread-syntax-in-javascript#destructuring\">destructuring assignments</a> called <code>app</code> and <code>BrowserWindow</code>, which are required for an Electron module. The <code>Browserwindow</code> module is used to create a new window in your Electron application.</p>\n\n<p>Next, add the following code to your <code>main.js</code> file:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">. . .\nfunction createWindow () {\n  const mainWindow = new BrowserWindow({\n    width: 800,\n    height: 600\n  })\n\n  mainWindow.loadFile('index.html')\n}\n\napp.whenReady().then(createWindow)\n</code></pre>\n<p>You add an Electron <code>createWindow</code> function to your <code>hello-world</code> application. In this function, you create a <code>new BrowserWindow</code> renderer process and pass the <code>width</code> and <code>height</code> parameters. The width and height will set the application window size.</p>\n\n<p>The <code>mainWindow.loadFile()</code> method renders some contents into the <code>BrowserWindow</code>. The <code>index.html</code> file will load the content.</p>\n\n<p>The main process will be started when the <code>app.whenReady().then(windowName)</code> method is ready. At this point, the main process calls the <code>createWindow</code> function. This function creates a new renderer process, or browser window instance, with a width of 800px and height of 600px. Then the renderer process proceeds to load content using <code>mainWindow.loadFile('index.html')</code> method. In this tutorial, you use <code>index.html</code> as the filename.</p>\n\n<p>Next add the following events code to your file:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">. . .\napp.on('window-all-closed', () =&gt; {\n  if (process.platform !== 'darwin') {\n    app.quit()\n  }\n})\n\napp.on('activate', () =&gt; {\n  if (BrowserWindow.getAllWindows().length === 0) {\n    createWindow()\n  }\n})\n</code></pre>\n<p>You add the two main system <a href=\"https://www.electronjs.org/docs/api/app\">events</a> into the project—<code>window-all-closed</code> and <code>activate</code> events:</p>\n\n<ul>\n<li><code>window-all-closed</code>: Quits the application when all windows are closed. On macOS it is common for applications and their menu bar to stay active until the user quits explicitly with <code>CMD</code>+<code>Q</code>.</li>\n<li><code>activate</code>: Various actions can trigger this event, such as launching the application for the first time, attempting to re-launch the application when it&rsquo;s already running, or clicking on the application&rsquo;s dock (macOS) or taskbar icon.</li>\n</ul>\n\n<p>After adding these code blocks, your final output of the <code>main.js</code> file will be similar to this:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const { app, BrowserWindow } = require('electron')\n\nfunction createWindow () {\n  const mainWindow = new BrowserWindow({\n    width: 800,\n    height: 600\n  })\n\n  mainWindow.loadFile('index.html')\n\n}\n\napp.whenReady().then(createWindow)\n\napp.on('window-all-closed', () =&gt; {\n  if (process.platform !== 'darwin') {\n    app.quit()\n  }\n})\n\napp.on('activate', () =&gt; {\n  if (BrowserWindow.getAllWindows().length === 0) {\n    createWindow()\n  }\n})\n</code></pre>\n<p>Once you&rsquo;re done, save and exit this file.</p>\n\n<p>Next, create and open the <code>index.html</code> file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.html\n</li></ul></code></pre>\n<p>Add the following code, which is sent as the final output:</p>\n<div class=\"code-label \" title=\"index.html\">index.html</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Hello World!&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body\n    &lt;h1&gt;Hello World!&lt;/h1&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>Here you create a static HTML web page. The Electron application renderer process supports all HTML syntax since Electron uses Chromium for the rendering process.</p>\n\n<p>Now that you&rsquo;re done, you can run your application:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm start\n</li></ul></code></pre>\n<p>You will get an application window as an output.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/electron_macos/step3.png\" alt=\"Hello world printed output window of the application\"></p>\n\n<p>You&rsquo;ve created your first cross-platform application with the Electron framework. Next you&rsquo;ll work with some customizations, which you can add for interactivity.</p>\n\n<h2 id=\"step-4-—-customizing-your-quot-hello-world-quot-quot-application\">Step 4 — Customizing Your &ldquo;Hello World!&rdquo;&ldquo; Application</h2>\n\n<p>Now you have completed the initial setup of your first cross-platform application using the Electron framework. Let&rsquo;s see what else you can do to improve the native behavior of the application.</p>\n\n<p>Electron has a number of built-in features such as dialog boxes, windows options, new windows, menus, shortcuts, notifications, touch bars, session controls, and so on, that improve the user experience of your desktop application. Let&rsquo;s add some features to customize the <code>hello-world</code> application.</p>\n\n<h3 id=\"graceful-window-setup-of-the-application\">Graceful Window Setup of the Application</h3>\n\n<p>When you load a page into the window directly, at the startup of your application you may see the page does not load at once. This isn&rsquo;t a great experience in native applications. Let&rsquo;s fix this issue in a few steps.</p>\n\n<p>To do this, you need to hide the <code>BrowserWindow</code> by passing new configuration parameters at the time it gets created.</p>\n\n<p>For that, open the <code>main.js</code> file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano main.js\n</li></ul></code></pre>\n<p>Add the <code>show: false</code> parameter to the body of the <code>BrowserWindow</code> object:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const mainWindow = new BrowserWindow({\n   width: 800,\n   height: 600,\n   <span class=\"highlight\">show: false</span>\n })\n</code></pre>\n<p>Next, you&rsquo;ll add a new listener to the <code>BrowserWindow</code> instance by adding the highlighted code line inside the <code>createWindow</code> function body. You&rsquo;ll also add new configuration parameters into the <code>BrowserWindow</code> to change the background color of the initially built window.</p>\n\n<p>For that, you have to add the following code line of <code>backgroundColor</code> object, inside the <code>BrowserWindow</code> function. Feel free to change the hex color code as you wish.</p>\n<pre class=\"code-pre \"><code class=\"code-highlight language-js\">backgroundColor: '#Your hex color code'\n</code></pre>\n<p>Add this line like the following highlighted code to your <code>createWindow</code> function:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">function createWindow () {\n const mainWindow = new BrowserWindow({\n   width: 800,\n   height: 600,\n   show: false,\n   <span class=\"highlight\">backgroundColor: '#ffff00'</span>\n })\n mainWindow.loadFile('index.html')\n\n <span class=\"highlight\">mainWindow.once('ready-to-show', mainWindow.show)</span>\n\n}\n</code></pre>\n<p>To reduce the garbage collection, you need to execute this listener one time by using the <code>once</code> keyword. Therefore, the <code>mainWindow.show</code> method executes only once at the run time of this application.</p>\n\n<p>Now save your file and run your application using the terminal:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm start\n</li></ul></code></pre>\n<p>Your application will show with a yellow background.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/electron_macos/step4.png\" alt=\"Hello world printed output window with the background color of yellow\"></p>\n\n<p>Finally, you will see the application window loading gracefully.</p>\n\n<h3 id=\"creating-a-new-window-for-the-application\">Creating a New Window for the Application</h3>\n\n<p>The use of more than one window is a common feature of basic to advanced applications. Let&rsquo;s add that feature to your newly created application.</p>\n\n<p>Electron can create multiple renderer processes (multiple windows) from a single main process.</p>\n\n<p>First, open <code>main.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano main.js\n</li></ul></code></pre>\n<p>Create a new method called <code>secWindow</code> and set the <code>width</code> and <code>height</code> parameters of the newly created window by adding the highlighted code:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">function createWindow () {\nconst mainWindow = new BrowserWindow({\n  width: 800,\n  height: 600,\n  show: false,\n  backgroundColor: '#ffff00'\n})\n\n<span class=\"highlight\">const secWindow = new BrowserWindow({</span>\n  <span class=\"highlight\">width: 600,</span>\n  <span class=\"highlight\">height: 400,</span>\n<span class=\"highlight\"> })</span>\n. . .\n}\n</code></pre>\n<p>Now load content to the newly created <code>BrowserWindow</code> renderer process. At this time you&rsquo;ll load some remote URL (Website) content.</p>\n\n<p>In this tutorial, you&rsquo;re using <code><span class=\"highlight\">https://www.digitalocean.com</span></code> web content for the second window of the application. For that, in the second window initialization <code>secWindow.loadURL</code>, you add the following code line to the body of the <code>createWindow</code> function:</p>\n<div class=\"code-label \" title=\"main.js\">main.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\"> function createWindow () {\n const mainWindow = new BrowserWindow({\n   width: 800,\n   height: 600,\n   show: false,\n   backgroundColor: '#ffff00'\n })\n\nconst secWindow = new BrowserWindow({\n   width: 600,\n   height: 400,\n })\n\n mainWindow.loadFile('index.html')\n\n <span class=\"highlight\">secWindow.loadURL('https://www.digitalocean.com/')</span>\n\n mainWindow.once('ready-to-show', mainWindow.show)\n}\n</code></pre>\n<p>Now save and exit your file and run your application in the terminal:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm start\n</li></ul></code></pre>\n<p>You will get your initial window with the yellow background and a new application with the loaded URL.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/electron_macos/step4b.png\" alt=\"New desktop application window of loaded URL with previously hello world printed output window\"></p>\n\n<p>You&rsquo;ve made customizations to your newly created application to make it more interactive for users. Now it&rsquo;s time to build your Electron application.</p>\n\n<h2 id=\"step-5-—-building-your-first-application\">Step 5 — Building Your First Application</h2>\n\n<p>After adding some features to your application, you need to build it for the purpose of distribution. In this section, you will learn how to build the application for various platforms.</p>\n\n<p>The build process of the Electron application is considered somewhat hard because it needs a lot of tools. However, here you&rsquo;ll use the <a href=\"https://www.electron.build/\"><code>electron-builder</code></a> CLI tool that provides the best way to build your application for any platform.</p>\n\n<p>First, you&rsquo;ll install the <code>electron-builder</code> CLI tools globally. To do this run the following command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo npm install -g electron-builder\n</li></ul></code></pre>\n<p><span class='note'><strong>Note:</strong> You can use either <code>npm</code> or <code>yarn</code> to install <code>electron-builder</code>—there are no noted differences in performance. If you intend to develop your application in the long term, the makers of <code>electron-builder</code> recommend <code>yarn</code> to avoid potential compatibility issues. To install using <code>yarn</code>, you&rsquo;ll need to ensure it&rsquo;s <a href=\"https://classic.yarnpkg.com/en/docs/install#mac-stable\">installed</a> on your computer and then run <code>yarn add electron-builder --dev</code> to install <code>electron-builder</code> with <code>yarn</code>.<br></span></p>\n\n<p>After completing the installation of the <code>electron-builder</code>, you can verify the success of it by running the following command in your terminal:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">electron-builder --version\n</li></ul></code></pre>\n<p>You&rsquo;ll receive the current version of Electron in your output.</p>\n\n<p>Now you can build your first cross-platform application. To do this open your terminal and run the following command in your project directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">electron-builder -mwl\n</li></ul></code></pre>\n<p>You use the flags <code>-mwl</code> to build applications for macOS, Windows, and Linux respectively.</p>\n\n<p><span class='note'><strong>Note:</strong> Only macOS users can build for all platforms. Windows users can build the application for Windows and Linux platforms only. Linux users can build only for Linux platforms. For more details, you can refer to the <a href=\"https://www.electron.build/cli\">documentation</a>.<br></span></p>\n\n<p>To build applications for separate operating systems use the following:</p>\n\n<p>Build applications for <code>macOS</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">electron-builder --mac\n</li></ul></code></pre>\n<p>Build applications for <code>Windows:</code></p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">electron-builder --win\n</li></ul></code></pre>\n<p>Build applications for <code>Linux</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">electron-builder --linux\n</li></ul></code></pre>\n<p>This process takes some time while dependencies download and your application builds.</p>\n\n<p>Your project directory creates a new folder called <code>dist</code>. All your built applications and unzip versions of the application are located in that folder.</p>\n\n<p>As an example, if you build your application for all platforms, your project <code>dist</code> folder is similar to the following file structure:</p>\n<pre class=\"code-pre \"><code>hello-world\n  +-- hello-world-1.0.0-mac.zip\n  +-- hello-world-1.0.0.dmg\n  +-- hello-world Setup 1.0.0.exe\n  +-- win-unpacked\n  +-- mac\n  +-- linux-unpacked\n  +-- hello-world_1.0.0_amd64.snap\n</code></pre>\n<p><code>electron-builder</code> builds the Electron app for the current platform and current architecture as the default target.</p>\n\n<ul>\n<li> macOS: DMG and ZIP for Squirrel.Mac</li>\n<li> Windows: NSIS (.exe)</li>\n<li> Linux: If you build on Windows or macOS, Snap and AppImage for <code>x64</code> will be the output. Otherwise if you build on Linux, the output will be Snap and AppImage files for the current architecture.</li>\n</ul>\n\n<p>You&rsquo;ve now built your application for all platforms.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>In this tutorial, you created your first cross-platform application with the Electron framework, added native features, and built it for distribution, on macOS.</p>\n\n<p>To learn more about Electron, you can check out their <a href=\"https://www.electronjs.org/docs\">documentation</a>. Now you can also share your newly created desktop application with anyone by <a href=\"https://www.electronjs.org/docs/tutorial/application-distribution\">creating an installer</a>.</p>\n","descriptionType":"html","publishedDate":"Tue, 25 Aug 2020 22:37:23 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/electron_macos/step3.png","linkMd5":"4adc87fa81c0f6a7965e53d80b41d035","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_1/2020/08/31/07-48-27-736_e3f96fdcf5b98dca.webp","destWidth":817,"destHeight":618,"sourceBytes":76356,"destBytes":6366,"author":"Maneesha Dedigama","articleImgCdnMap":{"https://assets.digitalocean.com/articles/electron_macos/step3.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_1/2020/08/31/07-48-27-736_e3f96fdcf5b98dca.webp","https://assets.digitalocean.com/articles/electron_macos/step4.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn97@2020_5/2020/08/31/07-48-31-723_e31fa8af578f086e.webp","https://assets.digitalocean.com/articles/electron_macos/step4b.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn90@2020_2/2020/08/31/07-48-33-135_566d0efe78411139.webp"},"publishedOrCreatedDate":1598860106986},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Настройка сервера IKEv2 VPN с StrongSwan в Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-an-ikev2-vpn-server-with-strongswan-on-ubuntu-20-04-ru","description":"<p><em>Предыдущая версия данного обучающего руководства была написана <a href=\"https://www.digitalocean.com/community/users/jellingwood\">Джастином Эллингвудом (Justin Ellingwood)</a> и <a href=\"https://www.digitalocean.com/community/users/namo\">Намо (Namo)</a></em></p>\n\n<h3 id=\"Введение\">Введение</h3>\n\n<p>Виртуальная частная сеть (VPN) позволяет выполнять защищенное шифрование трафика, передаваемого через незащищенные сети, например, в кафе, на конференции или в аэропорту.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Internet_Key_Exchange\">Internet Key Exchange v2</a> или IKEv2 — это протокол, который позволяет создавать прямые туннели IPSec между сервером и клиентом. IPSec обеспечивает шифрование сетевого трафика в виртуальных частных сетях IKEv2. IKEv2 изначально поддерживается на ряде платформ (OS X 10.11+, iOS 9.1+, Windows 10) без дополнительных приложений и легко решает проблемы с подключением клиентов.</p>\n\n<p>В этом обучающем руководстве мы настроим сервер IKEv2 VPN с помощью <a href=\"https://www.strongswan.org/\">StrongSwan</a> на сервере Ubuntu 20.04. Затем вы узнаете, как подключиться к нему с помощью клиентов Windows, macOS, Ubuntu, iOS и Android.</p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для данного обучающего руководства вам потребуется следующее:</p>\n\n<ul>\n<li>Один сервер Ubuntu 20.04, настроенный в соответствии с <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">руководством по начальной настройке сервера Ubuntu 20.04</a>, с пользователем без прав root с привилегиями <code>sudo</code> и брандмауэром.</li>\n</ul>\n\n<h2 id=\"Шаг-1-—-Установка-strongswan\">Шаг 1 — Установка StrongSwan</h2>\n\n<p>Вначале мы установим StrongSwan, демона IPSec с открытым исходным кодом, а затем настроим его как наш сервер VPN. Также мы установим компонент инфраструктуры открытых ключей (PKI), чтобы создать центр сертификации (СА), который будет предоставлять учетные данные для нашей инфраструктуры.</p>\n\n<p>Начните с обновления кэша локальных пакетов:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Затем установите программное обеспечение с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan strongswan-pki libcharon-extra-plugins libcharon-extauth-plugins\n</li></ul></code></pre>\n<p>Дополнительный пакет <code>libcharon-extauth-plugins</code> используется для обеспечения возможности аутентификации различных клиентов для вашего сервера с помощью общего имени пользователя и кодовой фразы.</p>\n\n<p>После завершения установки перейдем к созданию сертификатов.</p>\n\n<h2 id=\"Шаг-2-—-Создание-центра-сертификации\">Шаг 2 — Создание центра сертификации</h2>\n\n<p>Для идентификации на клиентских системах серверу IKEv2 требуется сертификат. Для упрощения формирования требуемого сертификата пакет <code>strongswan-pki</code> включает утилиту <code>pki</code>, которая может сгенерировать центр сертификации и сертификаты сервера.</p>\n\n<p>Для начала создадим несколько каталогов для хранения всех активо, с которыми мы будем работать. Структура каталогов соответствует некоторым каталогам в <code>/etc/ipsec.d</code>, куда мы постепенно переместим все создаваемые элементы:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir -p ~/pki/{cacerts,certs,private}\n</li></ul></code></pre>\n<p>Затем мы заблокируем разрешения, чтобы другие пользователи не могли видеть наши частные файлы:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod 700 ~/pki\n</li></ul></code></pre>\n<p>Располагая структурой каталогов для хранения всех элементов, мы можем сгенерировать ключ root. Это будет 4096-битный ключ RSA, который будет использоваться для подписи корневого центра сертификации.</p>\n\n<p>Запустите следующие команды, чтобы сгенерировать ключ:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/ca-key.pem\n</li></ul></code></pre>\n<p>После этого мы можем переходить к созданию корневого центра сертификации, используя ключ, который мы только что сгенерировали для подписания корневого сертификата:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --self --ca --lifetime 3650 --in ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">    --type rsa --dn \"CN=VPN root CA\" --outform pem &gt; ~/pki/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Флаг <code>--lifetime 3650</code> используется для обеспечения действительности корневого сертификата центра сертификации на протяжении 10 лет. Корневой сертификат центра обычно не меняется, поскольку его необходимо перераспределять на каждый использующий его сервер и клиент. Исходя из этого, 10 лет — это безопасный срок действия по умолчанию.</p>\n\n<p>Вы можете изменить значение различимого имени <em>distinguished name</em> (DN) на любое другое имя по своему желанию. Обычное имя (поле CN) здесь используется только как индикатор, поэтому оно не обязательно должно совпадать с чем-либо в вашей инфраструктуре.</p>\n\n<p>Настроив и запустив корневой центр сертификации, мы можем создать сертификат, который будет использоваться сервером VPN.</p>\n\n<h2 id=\"Шаг-3-—-Генерирование-сертификата-для-сервера-vpn\">Шаг 3 — Генерирование сертификата для сервера VPN</h2>\n\n<p>Теперь мы создадим сертификат и ключ для сервера VPN. Этот сертификат позволит клиентам проверять подлинность сервера, используя только что сгенерированный нами сертификат CA.</p>\n\n<p>Вначале создайте закрытый ключ сервера VPN с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/server-key.pem\n</li></ul></code></pre>\n<p>Затем создайте и подпишите сертификат сервера VPN, используя ключ центра сертификации, созданный на предыдущем шаге. Запустите следующую команду, но измените поля Common Name (CN) и Subject Alternate Name (SAN) на имя DNS или IP-адрес вашего сервера VPN:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --pub --in ~/pki/private/server-key.pem --type rsa \\\n</li><li class=\"line\" data-prefix=\"$\">    | pki --issue --lifetime 1825 \\\n</li><li class=\"line\" data-prefix=\"$\">        --cacert ~/pki/cacerts/ca-cert.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --cakey ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --dn \"CN=<span class=\"highlight\">server_domain_or_IP</span>\" --san <span class=\"highlight\">server_domain_or_IP</span> \\\n</li><li class=\"line\" data-prefix=\"$\">        --flag serverAuth --flag ikeIntermediate --outform pem \\\n</li><li class=\"line\" data-prefix=\"$\">    &gt;  ~/pki/certs/server-cert.pem\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Примечание</strong>. Если вы используете IP-адрес вместо имени DNS, вам потребуется указать несколько входов <code>--san</code>. Строка в предыдущем блоке команд, где вы указываете distinguished name (<code>--dn ...</code>), должна быть дополнена еще одной строкой, например следующей:</p>\n<pre class=\"code-pre \"><code>--dn \"CN=<span class=\"highlight\">IP address</span> --san @<span class=\"highlight\">IP_address</span> --san <span class=\"highlight\">IP_address</span> \\\n</code></pre>\n<p>Дополнение <code>--san @<span class=\"highlight\">IP_address</span></code> необходимо, так как некоторые клиенты буду проверять наличие в сертификате TLS как записи DNS, так и записи IP-адреса для сервера при проверке его подлинности.<br></p></span>\n\n<p>Опция <code>--flag serverAuth</code> используется для указания того, что сертификат будет использоваться для аутентификации сервера, прежде чем будет установлен зашифрованный туннель. Опция <code>--flag ikeIntermediate</code> используется для поддержки более старых клиентов macOS.</p>\n\n<p>Теперь мы сгенерировали все файлы TLS/SSL, необходимые StrongSwan, и можем переместить их в каталог <code>/etc/ipsec.d</code> следующим образом:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp -r ~/pki/* /etc/ipsec.d/\n</li></ul></code></pre>\n<p>На этом шаге мы создали пару сертификатов, которые будут использоваться для защиты связи между клиентом и сервером. Также мы подписали сертификаты ключом CA, и теперь клиент сможет проверять подлинность сервера VPN, используя сертификат CA. После подготовки всех этих сертификатов мы переходим к настройке программного обеспечения.</p>\n\n<h2 id=\"Шаг-4-—-Настройка-strongswan\">Шаг 4 — Настройка StrongSwan</h2>\n\n<p>StrongSwan имеет файл конфигурации по умолчанию с несколькими образцами, но большинство настроек нужно будет выполнить самостоятельно. Прежде чем начинать, создадим резервную копию файла для справки:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/ipsec.conf{,.original}\n</li></ul></code></pre>\n<p>Создайте и откройте новый пустой файл конфигурации с помощью предпочитаемого текстового редактора. Мы будем использовать <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Примечание</strong>. По мере выполнения данного раздела по конфигурации серверной части VPN вы столкнетесь с настройками, которые относятся к <em>левой</em> и <em>правой</em> сторонам соединения. При работе с VPN IPSec <em>левая</em> сторона, по правилам, обращается к локальной системе, которую вы настраиваете. В данном случае — это сервер. Директивы правой стороны в данных настройках будут обращаться к удаленным клиентам, таким как телефоны или компьютеры.</p>\n\n<p>Когда вы позже перейдете к настройке клиентов в этом обучающем руководстве, файлы конфигурации клиентов будут обращаться к самим себе, используя различные директивы <em>левой</em> стороны, а к серверу будут обращаться, используя терминологию <em>правой</em> стороны.<br></p></span>\n\n<p>Вначале мы укажем StrongSwan регистрировать состояния демонов для целей отладки и разрешить дублирующиеся соединения. Добавьте в файл следующие строки:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n</code></pre>\n<p>Затем мы создадим раздел конфигурации для сервера VPN. Также мы укажем StrongSwan создать туннели IKEv2 VPN и автоматически загружать этот раздел конфигурации при запуске. Добавьте в файл следующие строки:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n</code></pre>\n<p>Также мы настроем обнаружение отсутствующих узлов, чтобы закрывать неиспользуемые соединения при непредвиденном отключении клиента. Добавьте следующие строки:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n</code></pre>\n<p>Затем мы настроим параметры IPSec «левой» стороны сервера. Каждый из следующих параметров обеспечивает конфигурацию сервера для приема соединений от клиентов и корректной идентификации себя. Вы добавите каждую из этих настроек в файл <code>/etc/ipsec.conf</code> после того, как вы изучите их и поймете, для чего они используются:</p>\n\n<ul>\n<li><code>left=%any</code> Значение <code>%any</code> гарантирует использование сервером сетевого интерфейса при получении входящих соединений для последующей связи с клиентами. Например, если вы подключаете клиента через частную сеть, сервер будет использовать частный IP-адрес, где он получает трафик для остальной части подключения.</li>\n<li><code>leftid=<span class=\"highlight\">@server_domain_or_IP</span></code> Эта опция контролирует имя, которое сервер показывает клиентам. При совмещении со следующей опцией <code>leftcert</code>, опция <code>leftid</code> обеспечивает совпадение настроенного имени сервера и различимого имени (DN), содержащегося в публичном сертификате.</li>\n<li><code>leftcert=server-cert.pem</code> Эта опция — это путь к публичному сертификату для сервера, который вы настроили на шаге 3. Без него сервер не сможет аутентифицировать себя с клиентами или завершить переговоры по настройке IKEv2.</li>\n<li><code>leftsendcert=always</code> Значение <code>always</code> гарантирует, что любой клиент, который подключается к серверу, всегда будет получать копию публичного сертификата сервера в рамках настроек первоначального соединения.</li>\n<li><code>leftsubnet=0.0.0.0/0</code> Последняя опция «слева», которую вы добавите, указывает клиентам на подсети, которые доступны за сервером. В этом случае <code>0.0.0.0/0</code> используется для представления всего набора адресов IPv4, что означает, что сервер будет указывать клиентам передавать весь свой трафик через VPN по умолчанию.</li>\n</ul>\n\n<p>Теперь, когда вы ознакомились с каждой из соответствующих опций «слева», добавьте их в файл следующим образом:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n</code></pre>\n<span class='note'><p>\n<strong>Примечание.</strong> При настройке идентификатора сервера (<code>leftid</code>) символ <code>@</code> нужно указывать только в случае, если ваш сервер VPN будет идентифицироваться по доменному имени:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .    leftid=<span class=\"highlight\">@vpn.example.com</span>\n    . . .\n</code></pre>\n<p>Если сервер будет идентифицироваться по IP-адресу, просто укажите IP-адрес:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .\n    leftid=<span class=\"highlight\">your_server_ip</span>\n    . . .\n</code></pre>\n<p></p></span>\n\n<p>Далее мы можем настроить параметры IPSec клиента «справа». Каждый из следующих параметров указывает серверу, как принимать соединения от клиентов, как клиенты должны аутентифицироваться на сервере, а также сообщает диапазоны частных IP-адресов и серверы которые будут использовать клиенты. Добавьте каждую из этих настроек в файл <code>/etc/ipsec.conf</code> после того, как изучите их и поймете, для чего они используются:</p>\n\n<ul>\n<li><code>right=%any</code> Опция <code>%any</code> для стороны соединения <code>right</code> предписывает серверу принимать входящие соединения от удаленных клиентов.</li>\n<li><code>rightid=%any</code> Эта опция гарантирует, что сервер не будет отклонять соединения от клиентов, которые предоставляют идентификатор до создания зашифрованного туннеля.</li>\n<li><code>rightauth=eap-mschapv2</code> Эта опция настраивает метод аутентификации, который будут использовать клиенты для аутентификации на сервере. <code>eap-mschapv2</code> используется здесь для расширения возможностей совместимости и поддержки таких клиентов, как устройства на базе Windows, macOS и Android.</li>\n<li><code>rightsourceip=10.10.10.0/24</code> Эта опция предписывает серверу назначать частные IP-адреса клиентам из указанного пула IP-адресов <code>10.10.10.0/24</code>.</li>\n<li><code>rightdns=8.8.8.8,8.8.4.4</code> Эти IP-адреса являются публичными интерпретаторами DNS Google. Вместо них можно использовать другие публичные интерпретаторы, интерпретаторы сервера VPN или любые другие, к которым у клиента есть доступ.</li>\n<li><code>rightsendcert=never</code> Эта опция сообщает серверу, что клиентам не нужно отправлять сертификат для аутентификации себя.</li>\n</ul>\n\n<p>Теперь, когда вы ознакомились с необходимыми опциями «справа», добавьте следующие строки в <code>/etc/ipsec.conf</code>:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n</code></pre>\n<p>Теперь мы укажем StrongSwan запрашивать у клиента учетные данные пользователя при подключении:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    eap_identity=%identity\n</code></pre>\n<p>И наконец, добавьте следующие строки для поддержки клиентов на базе Linux, Windows, macOS, iOS и Android. Эти строки определяют различные алгоритмы обмена ключами, хэширования, аутентификации и шифрования (обычно их называют <em>набор шифров</em>), которые StrongSwan разрешит использовать разным клиентам.</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Каждый поддерживаемый набор шифров отделяется от других запятой. Например, <code>chacha20poly1305-sha512-curve25519-prfsha512</code> — это один набор, а <code>aes256gcm16-sha384-prfsha384-ecp384</code> — другой. Перечисленные здесь наборы шифров выбраны для обеспечения самых широких возможностей совместимости с клиентами на базе Windows, macOS, iOS, Android и Linux.</p>\n\n<p>Полный файл конфигурации должен выглядеть следующим образом:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n    eap_identity=%identity\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Сохраните и закройте файл после того, как проверите, что все строки добавлены корректно. Если вы используете <code>nano</code>, нажмите <code>CTRL+X</code>, <code>Y</code>, затем <code>ENTER</code>.</p>\n\n<p>Теперь мы настроили параметры VPN и можем перейти к созданию учетной записи, чтобы наши пользователи могли подключаться к серверу.</p>\n\n<h2 id=\"Шаг-5-—-Настройка-аутентификации-vpn\">Шаг 5 — Настройка аутентификации VPN</h2>\n\n<p>Теперь наш сервер VPN настроен на принятие подключений клиентов, но мы еще не настроили учетные данные. Нам нужно задать пару настроек в специальном файле конфигурации с именем <code>ipsec.secrets</code>:</p>\n\n<ul>\n<li>Нам нужно указать StrongSwan, где можно найти закрытый ключ для нашего сертификата сервера, чтобы сервер мог пройти аутентификацию на стороне клиента.</li>\n<li>Также нам потребуется список пользователей, которым будет разрешено подключаться к VPN.</li>\n</ul>\n\n<p>Откроем для редактирования файл secrets</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.secrets\n</li></ul></code></pre>\n<p>Вначале мы укажем StrongSwan, где можно найти закрытый ключ:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code>: RSA \"server-key.pem\"\n</code></pre>\n<p>Затем мы зададим учетные данные пользователя. Вы можете создать любую комбинацию имени пользователя и пароля:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Сохраните и закройте файл. Мы завершили настройку параметров VPN и теперь можем перезапустить службу VPN, чтобы применить новую конфигурацию:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart strongswan-starter\n</li></ul></code></pre>\n<p>Мы полностью настроили параметры сервера и учетные данные пользователя на сервере VPN и теперь можем перейти к самой важной части: настройке брандмауэра.</p>\n\n<h2 id=\"Шаг-6-—-Настройка-брандмауэра-и-переадресации-ip-ядра\">Шаг 6 — Настройка брандмауэра и переадресации IP ядра</h2>\n\n<p>После завершения настройки StrongSwan нам нужно настроить брандмауэр, чтобы разрешить прохождение и перенаправление трафика VPN.</p>\n\n<p>Если вы следовали указаниям модуля по начальной настройке сервера, у вас должен быть включен брандмауэр UFW. Если вы еще не настроили UFW, вам следует начать с добавления правила, разрешающего соединения SSH через брандмауэр, чтобы ваш текущий сеанс не был прерван при активации UFW:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow OpenSSH\n</li></ul></code></pre>\n<p>Затем активируйте брандмауэр с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Теперь добавьте правило, которое будет разрешать трафик UDP на стандартных портах IPSec <code>500</code> и <code>4500</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 500,4500/udp\n</li></ul></code></pre>\n<p>Затем мы откроем один из файлов конфигурации UFW, чтобы добавить несколько политик нижнего уровня для маршрутизации и перенаправления пакетов IPSec. Но прежде чем мы сможем сделать это, нам нужно определить, какой сетевой интерфейс на нашем сервере используется для доступа в Интернет. Определите этот интерфейс с помощью запроса устройства, связанного с маршрутом по умолчанию:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ip route show default\n</li></ul></code></pre>\n<p>Ваш публичный интерфейс должен содержать слово «dev». Например, в этом результате показан интерфейс с именем <code>eth0</code>, который выделен ниже:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>default via <span class=\"highlight\">your_server_ip</span> dev <span class=\"highlight\">eth0</span> proto static\n</code></pre>\n<p>Определив интерфейс публичной сети, откройте файл <code>/etc/ufw/before.rules</code> в своем текстовом редакторе: Правила из этого файла добавляются в брандмауэр перед остальными правилами ввода и вывода. Они используются для настройки перевода сетевых адресов (NAT), чтобы сервер мог корректно настраивать соединения между клиентами и сетью Интернет.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/before.rules\n</li></ul></code></pre>\n<p>Добавьте в верхнюю часть файла (перед строкой <code>*filter</code>) следующий блок конфигурации: Измените каждый экземпляр <code>eth0</code> в конфигурации выше для соответствия имени интерфейса, которое вы определили с <code>помощью ip route</code>. Строки <code>*nat</code> создают правила, благодаря которым брандмауэр может обеспечивать маршрутизацию и управление трафиком между клиентами VPN и интернетом. Строка <code>*mangle</code> позволяет настроить максимальный размер сегмента пакета, чтобы предотвратить возможные проблемы с некоторыми клиентами VPN:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code><span class=\"highlight\">*nat</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -m policy --pol ipsec --dir out -j ACCEPT</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -j MASQUERADE</span>\n<span class=\"highlight\">COMMIT</span>\n\n<span class=\"highlight\">*mangle</span>\n<span class=\"highlight\">-A FORWARD --match policy --pol ipsec --dir in -s 10.10.10.0/24 -o eth0 -p tcp -m tcp --tcp-flags SYN,RST SYN -m tcpmss --mss 1361:1536 -j TCPMSS --set-mss 1360</span>\n<span class=\"highlight\">COMMIT</span>\n\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n. . .\n</code></pre>\n<p>После строки <code>*filter</code> и строк определения цепочки нужно добавить еще один блок конфигурации:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code>. . .\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir in --proto esp -s 10.10.10.0/24 -j ACCEPT</span>\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir out --proto esp -d 10.10.10.0/24 -j ACCEPT</span>\n</code></pre>\n<p>Эти строки указывают брандмауэру перенаправлять трафик <a href=\"https://wiki.wireshark.org/ESP\">ESP</a> (защищенная инкапсуляция полезной нагрузки), чтобы дать клиентам VPN возможность подключения. ESP обеспечивает дополнительную защиту пакетов VPN, когда они проходят через ненадежные сети.</p>\n\n<p>Сохраните и закройте файл после того, как проверите, что все строки добавлены корректно. Если вы используете <code>nano</code>, нажмите <code>CTRL+X</code>, <code>Y</code>, затем <code>ENTER</code>.</p>\n\n<p>Прежде чем перезапустить брандмауэр, нам нужно изменить некоторые параметры ядра сети, чтобы разрешить маршрутизацию с одного интерфейса на другой. Файл, который контролирует эти настройки, называется <code>/etc/ufw/sysctl.conf</code>. Нам потребуется настроить в файле несколько вещей.</p>\n\n<p>Для начала необходимо активировать перенаправление пакетов IPv4, чтобы трафик мог перемещаться между VPN и публичными сетями на сервере. Далее мы отключим обнаружение путей MTU, чтобы предотвратить проблемы с фрагментацией пакетов. И наконец, мы запретим перенаправление ICMP и отправку перенаправлений ICMP, чтобы предотвратить атаки <a href=\"https://en.wikipedia.org/wiki/Man-in-the-middle_attack\">через посредников</a>.</p>\n\n<p>Откройте файл конфигурации параметров ядра UFW, используя <code>nano</code> или предпочитаемый текстовый редактор:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/sysctl.conf\n</li></ul></code></pre>\n<p>Теперь добавьте следующую настройку <code>net/ipv4/ip_forward=1</code> в конце файла, чтобы активировать перенаправление пакетов между интерфейсами:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_forward=1</span>\n</code></pre>\n<p>Следующий блок, отправляющий и принимающий ICMP , перенаправляет пакеты путем добавления следующих строк в конец файла:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/conf/all/accept_redirects=0</span>\n<span class=\"highlight\">net/ipv4/conf/all/send_redirects=0</span>\n</code></pre>\n<p>И наконец, отключите обнаружение путей MTU, добавив следующую строку в конец файла:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_no_pmtu_disc=1</span>\n</code></pre>\n<p>Завершив изменения, сохраните файл. Теперь мы можем активировать все изменения путем отключения и повторного подключения брандмауэра, поскольку UFW применяет эти настройки во время каждой перезагрузки.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw disable\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Вам будет предложено подтвердить процесс. Введите <code>Y</code>, чтобы активировать UFW с новыми настройками.</p>\n\n<h2 id=\"Шаг-7-—-Тестирование-подключения-vpn-на-windows-macos-ubuntu-ios-и-android\">Шаг 7 — Тестирование подключения VPN на Windows, macOS, Ubuntu, iOS и Android</h2>\n\n<p>Мы завершили подготовку, и пришло время для тестирования. Вначале нужно скопировать созданный вами сертификат CA и установить его на клиентские устройства, которые будут подключаться к VPN. Для этого удобнее всего выполнить вход на ваш сервер и вывести содержимое файла сертификата:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cat /etc/ipsec.d/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Вывод будет выглядеть следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>-----BEGIN CERTIFICATE-----\nMIIFNDCCAxygAwIBAgIIHCsidG5mXzgwDQYJKoZIhvcNAQEMBQAwODELMAkGA1UE\n\n. . .\n\nH2YUdz8XNHrJHvMQKWFpi0rlEcMs+MSXPFWE3Q7UbaZJ/h8wpSldSUbQRUlphExJ\ndJ4PX+MUJO/vjG1/ie6Kh25xbBAc3qNq8siiJZDwrg6vjEK7eiZ1rA==\n-----END CERTIFICATE-----\n</code></pre>\n<p>Скопируйте эти данные на свой компьютер, включая строки <code>-----BEGIN CERTIFICATE-----</code> и <code>-----END CERTIFICATE-----</code>, и сохраните их в файл с понятным именем, например, <code>ca-cert.pem</code>. Созданный файл должен иметь расширение <code>.pem</code>.</p>\n\n<p>Также вы <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server\">можете использовать SFTP, чтобы перенести файл на свой компьютер</a>.</p>\n\n<p>Когда файл <code>ca-cert.pem</code> будет загружен на ваш компьютер, вы можете настроить подключение к VPN.</p>\n\n<h3 id=\"Подключение-из-windows\">Подключение из Windows</h3>\n\n<p>Существует множество способов импорта корневого сертификата и настройки Windows для подключения к VPN. Первый метод использует графические инструменты для каждого шага. Второй метод использует команды PowerShell, которые могут выполняться с помощью скриптов и меняться в зависимости от конфигурации VPN.</p>\n\n<p><span class='note'><strong>Примечание.</strong> Эти инструкции протестированы на установках Windows 10, использующих версии 1903 и 1909.<br></span></p>\n\n<h4 id=\"Настройка-windows-с-помощью-графических-инструментов\">Настройка Windows с помощью графических инструментов</h4>\n\n<p>Вначале импортировать сертификат root, выполнив следующие шаги:</p>\n\n<ol>\n<li>Нажмите <code>WINDOWS+R</code>, чтобы открыть диалоговое окно <strong>Выполнить</strong> и введите <code>mmc.exe</code>, чтобы открыть консоль управления Windows.</li>\n<li>Из меню <strong>Файл</strong> перейдите в раздел <strong>Добавить или удалить оснастку</strong>, выберите <strong>Сертификаты</strong> из списка доступных оснасток и нажмите <strong>Добавить</strong>.</li>\n<li>Чтобы разрешить VPN работать для любых пользователей, выберите <strong>Учетная запись</strong> компьютера и нажмите <strong>Далее</strong>.</li>\n<li>Поскольку мы выполняем настройку на локальном компьютере, выберите пункт <strong>Локальный компьютер</strong> и нажмите <strong>Готово</strong>.</li>\n<li><p>Под узлом <strong>Корень консоли</strong> откройте запись <strong>Сертификаты (локальный компьютер)</strong>, раскройте <strong>Доверенные корневые центры сертификации</strong> и выберите запись <strong>Сертификаты:</strong> <img src=\"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png\" alt=\"Просмотр сертификатов\"></p></li>\n<li><p>В меню <strong>Действие</strong> выберите пункт <strong>Все задачи</strong> и нажмите <strong>Импорт</strong>, чтобы открыть мастер импорта сертификатов. Нажмите <strong>Далее</strong>, чтобы пролистать вводное окно.</p></li>\n<li><p>На экране <strong>Импортируемый файл</strong> нажмите кнопку <strong>Обзор</strong>, убедитесь, что вы изменили тип файла с “X.509 Certificate (<em>.cer;</em>.crt)” на “All Files (<em>.</em>) и выберите сохраненный ранее файл <code>ca-cert.pem</code>. Затем нажмите <strong>Далее</strong>.</p></li>\n<li><p>Убедитесь, что <strong>Хранилище сертификатов</strong> имеет значение <strong>Доверенные корневые центры сертификации</strong> и нажмите <strong>Далее</strong>.</p></li>\n<li><p>Нажмите <strong>Готово</strong>, чтобы импортировать сертификат.</p></li>\n</ol>\n\n<p>Затем выполните следующие шаги по настройке VPN:</p>\n\n<ol>\n<li>Откройте <strong>Панель управления</strong> и перейдите в <strong>Центр управления сетями и общим доступом</strong>.</li>\n<li>Нажмите <strong>Создание и настройка нового подключения или сети</strong> и выберите пункт <strong>Подключение к рабочем месту</strong>.</li>\n<li>Выберите пункт <strong>Использовать мое подключение к Интернету (VPN)</strong>.</li>\n<li>Введите данные сервера VPN. Введите доменное имя сервера или IP-адрес в поле <strong>Адрес в Интернете</strong>, затем введите в поле <strong>Имя пункта назначения</strong> описание своего соединения VPN. Затем нажмите <strong>Готово</strong>.</li>\n</ol>\n\n<h4 id=\"Настройка-windows-с-помощью-powershell\">Настройка Windows с помощью PowerShell</h4>\n\n<p>Для импорта корневого сертификата СА с помощью PowerShell сначала откройте командную строку PowerShell с правами администратора. Для этого нажмите правой кнопкой мыши значок Пуск и выберите <code>Windows PowerShell (Admin)</code>. Также вы можете открыть командную строку как администратор и ввести <code>powershell</code>.</p>\n\n<p>Затем мы импортируем сертификат, используя командлет PowerShell <code>Import-Certificate</code>. В следующей команде первый аргумент <code>-CertStoreLocation</code> гарантирует, что сертификат импортируется в хранилище <strong>доверенных корневых центров сертификации</strong> компьютера, чтобы все программы и пользователи могли проверить сертификат сервера VPN. Аргумент <code>-FilePath</code> должен указать расположение, куда вы скопировали сертификат. В следующем примере путь — это <code>C:\\Users\\sammy\\Documents\\ca-cert.pem</code>. Убедитесь, что вы отредактировали команду в соответствии с используемым расположением.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Import-Certificate `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CertStoreLocation cert:\\LocalMachine\\Root\\ `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -FilePath <span class=\"highlight\">C:\\users\\sammy\\Documents\\ca-cert.pem</span>\n</li></ul></code></pre>\n<p>Команда выведет примерно следующее:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>   PSParentPath: Microsoft.PowerShell.Security\\Certificate::LocalMachine\\Root\n\nThumbprint                                Subject\n----------                                -------\nDB00813B4087E9367861E8463A60CEA0ADC5F002  CN=VPN root CA\n</code></pre>\n<p>Теперь для настройки VPN с помощью PowerShell запустите следующую команду. Подставьте имя DNS или IP-адрес вашего сервера в строку <code>-ServerAddress</code>. Различные флаги обеспечат корректную настройку Windows с необходимыми параметрами безопасности, которые соответствуют опциям, заданным в <code>/etc/ipsec.conf</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Add-VpnConnection -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -ServerAddress \"<span class=\"highlight\">server_domain_or_IP</span>\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -TunnelType \"IKEv2\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationMethod \"EAP\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionLevel \"Maximum\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -RememberCredential `\n</li></ul></code></pre>\n<p>Если команда выполнена успешно, вы не увидите никакого вывода. Чтобы убедиться, что VPN настроен корректно, используйте командлет <code>Get-VPNConnection</code>:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Get-VpnConnection -Name \"VPN Connection\"\n</li></ul></code></pre>\n<p>Вывод будет выглядеть следующим образом:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Name                  : VPN Connection\nServerAddress         : <span class=\"highlight\">your_server_ip</span>\nAllUserConnection     : False\nGuid                  : {B055A1AB-175C-4028-B4A8-D34309A2B20E}\nTunnelType            : Ikev2\nAuthenticationMethod  : {Eap}\nEncryptionLevel       : Maximum\nL2tpIPsecAuth         :\nUseWinlogonCredential : False\nEapConfigXmlStream    : #document\nConnectionStatus      : Disconnected\nRememberCredential    : True\nSplitTunneling        : False\nDnsSuffix             :\nIdleDisconnectSeconds : 0\n</code></pre>\n<p>По умолчанию Windows выбирает более старые и медленные алгоритмы. Запустите командлет <code>Set-VpnConnectionIPsecConfiguration</code> для обновления параметров шифрования, которые будет использовать Windows для обмена ключами IKEv2, а также чтобы провести шифрование пакетов:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Set-VpnConnectionIPsecConfiguration -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CipherTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -DHGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -IntegrityCheckMethod SHA384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -PfsGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionMethod GCMAES256\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Примечание</strong>. Если вы хотите удалить соединение VPN и перенастроить его с другими опциями, вы можете запустить командлет <code>Remove-VpnConnection</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Remove-VpnConnection -Name \"VPN Connection\" -Force\n</li></ul></code></pre>\n<p>С помощью флага <code>-Force</code> можно пропустить предложение подтвердить удаление. Вы должны быть отключены от VPN, если хотите удалить его с помощью данной команды.<br></p></span>\n\n<h4 id=\"Подключение-к-vpn\">Подключение к VPN</h4>\n\n<p>После того, как вы импортировали сертификат и настроили VPN любым методом, ваше новое подключение к VPN будет отображаться в списке сетей. Выберите VPN и нажмите <strong>Подключиться</strong>. Вам будет предложено ввести свои имя пользователя и пароль. Введите эти данные, нажмите <strong>OK</strong>, и подключение будет установлено.</p>\n\n<h3 id=\"Подключение-из-macos\">Подключение из macOS</h3>\n\n<p>Выполните следующие шаги по импорту сертификата:</p>\n\n<ol>\n<li>Дважды щелкните файл сертификата. Откроется экран <strong>«Keychain Access»</strong> с диалоговым окном, где будет указано: «Keychain Access is trying to modify the system keychain. Enter your password to allow this».</li>\n<li>Введите свой пароль и нажмите <strong>Modify Keychain</strong></li>\n<li>Дважды щелкните импортированный сертификат VPN. После этого откроется небольшое окно свойств, где вы сможете указать уровни доверия. Укажите для параметра <strong>IP Security (IPSec)</strong> значение <strong>Always Trust (всегда доверять)</strong>, после чего вам нужно будет снова ввести пароль. Настройка будет сохранена автоматически после ввода пароля.</li>\n</ol>\n\n<p>После импорта и подтверждения надежности сертификата настройте подключение к VPN, выполнив следующие шаги:</p>\n\n<ol>\n<li>Откройте раздел <strong>System Preferences (настройки системы)</strong> и выберите пункт <strong>Network (сеть)</strong>.</li>\n<li>Нажмите небольшую кнопку «плюс» в нижнем левом углу списка сетей.</li>\n<li>В открывшемся всплывающем окне установите для параметра <strong>Interface (интерфейс)</strong> значение <strong>VPN</strong>, установите для параметра <strong>VPN Type (тип VPN)</strong> значение <strong>IKEv2</strong> и присвойте имя соединению.</li>\n<li>В поле <strong>Server (сервер)</strong> и <strong>Remote ID (удаленный идентификатор)</strong> введите доменное имя или IP-адрес сервера. Оставьте поле <strong>Local ID (локальный идентификатор)</strong> пустым.</li>\n<li>Нажмите <strong>Authentication Settings (настройки аутентификации)</strong>, выберите пункт <strong>Username (имя пользователя)</strong> и введите имя пользователя и пароль, которые вы настроили для своего пользователя VPN. Затем нажмите <strong>OK</strong>.</li>\n</ol>\n\n<p>Наконец, нажмите кнопку <strong>Connect (подключение)</strong> для подключения к VPN. Теперь вы должны быть подключены к VPN.</p>\n\n<h3 id=\"Подключение-из-ubuntu\">Подключение из Ubuntu</h3>\n\n<p>Чтобы подключиться с компьютера под управлением Ubuntu, вы должны настроить и управлять StrongSwan как службой или использовать разовую команду при каждой попытке подключения. Далее приводятся инструкции для обоих случаев.</p>\n\n<h4 id=\"Управление-strongswan-как-службой\">Управление StrongSwan как службой</h4>\n\n<p>Чтобы управлять StrongSwan как службой, вам нужно выполнить следующие шаги по настройке.</p>\n\n<p>Сначала обновите свой локальный кэш пакетов с помощью <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo apt update\n</li></ul></code></pre>\n<p>Затем установите StrongSwan и необходимые плагины для аутентификации:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Теперь вам потребуется копия сертификата СА в каталоге <code>/etc/ipsec.d/cacerts</code>, чтобы ваш клиент мог проверить подлинность сервера. Запустите следующую команду, чтобы скопировать файл <code>ca-cert.pem</code> в каталог:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Чтобы убедиться, что VPN работает только по запросу, используйте <code>systemctl</code> для автоматического отключения StrongSwan:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl disable --now strongswan-starter\n</li></ul></code></pre>\n<p>Затем настройте имя пользователя и пароль, которые вы будете использовать для аутентификации на сервере VPN. Отредактируйте <code>/etc/ipsec.secrets</code> с помощью nano или любого предпочитаемого редактора:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<p>Добавьте следующую строку, редактируя выделенные значения имени пользователя и пароля, чтобы они соответствовали настроенным на сервере:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>А теперь отредактируйте файл <code>/etc/ipsec.conf</code> для настройки вашего клиента в соответствии с конфигурацией сервера:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code>config setup\n\nconn ikev2-rw\n    right=<span class=\"highlight\">server_domain_or_IP</span>\n    # This should match the `leftid` value on your server's configuration\n    rightid=<span class=\"highlight\">server_domain_or_IP</span>\n    rightsubnet=0.0.0.0/0\n    rightauth=pubkey\n    leftsourceip=%config\n    leftid=<span class=\"highlight\">username</span>\n    leftauth=eap-mschapv2\n    eap_identity=%identity\n    auto=start\n</code></pre>\n<p>Чтобы подключиться к VPN, введите:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start strongswan-starter\n</li></ul></code></pre>\n<p>Чтобы снова отключиться, введите:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop strongswan-starter\n</li></ul></code></pre>\n<h4 id=\"Использование-клиента-charon-cmd-для-разовых-подключений\">Использование клиента <code>charon-cmd</code> для разовых подключений</h4>\n\n<p>Чтобы управлять StrongSwan как службой, вам нужно выполнить следующие шаги по настройке.</p>\n\n<p>Сначала обновите свой локальный кэш пакетов с помощью <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Затем установите StrongSwan и необходимые плагины для аутентификации:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Теперь вам потребуется копия сертификата СА в каталоге <code>/etc/ipsec.d/cacerts</code>, чтобы ваш клиент мог проверить подлинность сервера. Запустите следующую команду, чтобы скопировать файл <code>ca-cert.pem</code> в каталог:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>На этом этапе вы можете подключиться к серверу VPN с помощью <code>charon-cmd</code>, используя сертификат СА сервера, IP-адрес сервера VPN и настроенное имя пользователя.</p>\n\n<p>Запустите следующую команду для подключения к VPN в любое время:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo charon-cmd --cert ca-cert.pem --host <span class=\"highlight\">vpn_domain_or_IP</span> --identity <span class=\"highlight\">your_username</span>\n</li></ul></code></pre>\n<p>При запросе укажите пароль пользователя VPN. После этого вы подключитесь к VPN. Чтобы отключиться, нажмите <code>CTRL+C</code> в терминале и дождитесь, пока соединение не будет закрыто.</p>\n\n<h3 id=\"Подключение-из-ios\">Подключение из iOS</h3>\n\n<p>Чтобы настроить соединение VPN на устройстве iOS, выполните следующие действия:</p>\n\n<ol>\n<li>Отправьте себе электронное письмо с прикрепленным корневым сертификатом.</li>\n<li>Откройте электронное письмо на устройстве iOS, нажмите на вложенный файл сертификата, затем нажмите <strong>Установить</strong> и введите код доступа. После установки нажмите <strong>Готово</strong>.</li>\n<li>Откройте <strong>Настройки</strong>, <strong>Общие</strong>, <strong>VPN</strong> и нажмите <strong>Добавить конфигурацию VPN</strong>. После этого откроется экран конфигурации подключения VPN.</li>\n<li>Нажмите <strong>Тип</strong> и выберите <strong>IKEv2</strong>.</li>\n<li>В поле <strong>Описание</strong> введите короткое имя подключения VPN. Вы можете выбрать все, что угодно.</li>\n<li>В поле <strong>Server (сервер)</strong> и <strong>Remote ID (удаленный идентификатор)</strong> введите доменное имя или IP-адрес сервера. Поле <strong>Local ID (локальный идентификатор)</strong> нельзя оставлять пустым.</li>\n<li>Введите имя пользователя и пароль в разделе <strong>Аутентификация</strong>, а затем нажмите <strong>Готово</strong>.</li>\n<li>Выберите соединение VPN, которое вы только что создали, нажмите переключатель вверху страницы, и подключение будет установлено.</li>\n</ol>\n\n<h3 id=\"Подключение-из-android\">Подключение из Android</h3>\n\n<p>Выполните следующие шаги по импорту сертификата:</p>\n\n<ol>\n<li>Отправьте себе электронное письмо с прикрепленным сертификатом CA. Сохраните сертификат CA в папку «Загрузки».</li>\n<li>Загрузите <a href=\"https://play.google.com/store/apps/details?id=org.strongswan.android&amp;hl=en_US\">клиент StrongSwan VPN</a> из магазина Play Store.</li>\n<li>Откройте приложение. Нажмите значок «подробнее» (<strong>&hellip;</strong>) в правом верхнем углу и выберите <strong>Сертификаты СА</strong>.</li>\n<li>Снова нажмите значок «подробнее» <strong>&hellip;</strong> в правом верхнем углу. Выберите пункт <strong>Импорт сертификата</strong>.</li>\n<li>Найдите файл сертификата CA в папке «Загрузки» и выберите его для импорта в приложение.</li>\n</ol>\n\n<p>Теперь сертификат импортирован в приложение StrongSwan, и вы можете настроить соединение VPN следующим образом:</p>\n\n<ol>\n<li>В приложении нажмите <strong>ADD VPN PROFILE (добавить профиль VPN)</strong> сверху.</li>\n<li>Введите в поле <strong>Server (сервер)</strong> доменное имя или публичный IP-адрес вашего сервера VPN.</li>\n<li>Обязательно выберите тип VPN: <strong>IKEv2 EAP (Username/Password)</strong>.</li>\n<li>Введите поля <strong>Username (имя пользователя)</strong> и <strong>Password (пароль)</strong> учетные данные, определенные на сервере.</li>\n<li>Уберите флажок <strong>Select automatically (выбирать автоматически)</strong> в разделе <strong>CA certificate (сертификат CA)</strong> и нажмите <strong>Select CA certificate (выбрать сертификат CA)</strong>.</li>\n<li>Откройте вкладку <strong>IMPORTED (импортированные)</strong> вверху экрана и выберите импортированный CA (он будет иметь имя «VPN root CA», если вы до этого не изменяли значение «DN»).</li>\n<li>Если хотите, можете ввести в поле <strong>Profile name (optional) (имя профиля, необязательно)</strong> более понятное имя.</li>\n</ol>\n\n<p>Когда вы захотите подключится к VPN, нажмите на профиль, созданный в приложении StrongSwan.</p>\n\n<h3 id=\"Диагностика-и-устранение-неисправностей-подключения\">Диагностика и устранение неисправностей подключения</h3>\n\n<p>Если вы не сможете импортировать сертификат, убедитесь, что файл имеет расширение <code>.pem</code>, а не <code>.pem.txt</code>.</p>\n\n<p>Если вы не можете подключиться к VPN, проверьте используемые имя сервера и IP-адрес. Доменное имя или IP-адрес сервера должны соответствовать настроенным как общее имя (CN) при создании сертификата. Если они не совпадают, соединение VPN не будет работать. Например, если вы настроили сертификат с CN <code>vpn.example.com</code>, вы <em>должны</em> использовать <code>vpn.example.com</code> при вводе данных сервера VPN. Еще раз проверьте команду, которую вы использовали для генерирования сертификата и значения, которые использовали при создании соединения VPN.</p>\n\n<p>Наконец, проверьте конфигурацию VPN и убедитесь, что значение <code>leftid</code> настроено с символом <code>@</code>, если вы используете доменное имя:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    leftid=<span class=\"highlight\">@</span>vpn.example.com\n</code></pre>\n<p>Если вы используете IP-адрес, убедитесь, что символ <code>@</code> опущен. Также убедитесь, что при генерировании файла <code>server-cert.pem</code> вы включили флаги <code>--san @<span class=\"highlight\">IP_address</span></code> и <code>--san <span class=\"highlight\">IP_address</span></code>.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>В этом обучающем модуле вы создали сервер VPN, использующий протокол IKEv2. Вы узнали о директивах, которые контролируют <code>левую</code> и <code>правую</code> стороны подключения как на сервере, так и на клиентах. Также вы настроили клиент Windows, macOS, iOS, Android или Linux для подключения к VPN.</p>\n\n<p>Чтобы добавить или удалить пользователей, снова перейдите на Шаг 5. Каждая строка в <code>/etc/ipsec.secrets</code> предназначена для одного пользователя, поэтому добавление или удаление пользователей или изменение паролей требует редактирования файла.</p>\n\n<p>Теперь вы можете быть уверены, что ваша деятельность онлайн будет защищена, куда бы вы ни зашли, независимо от устройства, которое вы используете для входа в Интернет.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:26 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png","linkMd5":"dc95098eb17cd270464f91d93da4490c","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp","destWidth":1436,"destHeight":754,"sourceBytes":109775,"destBytes":168410,"author":"Jamon Camisso","articleImgCdnMap":{"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp"},"publishedOrCreatedDate":1598860106967},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment dimensionner et sécuriser une application Django avec Docker, Nginx et Let's Encrypt","link":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-fr","description":"<h3 id=\"introduction\">Introduction</h3>\n\n<p>Dans les environnements basés sur le cloud, il existe de multiples façons de faire évoluer et de sécuriser une application <a href=\"https://www.djangoproject.com/\">Django</a>. En <em>dimensionnant horizontalement</em> et en exécutant plusieurs copies de votre application, vous pouvez construire un système plus tolérant aux défauts et très disponible, tout en augmentant également son <em>débit</em>, afin que les demandes puissent être traitées simultanément. Une manière de faire évoluer à l'échelle horizontale une application Django consiste à fournir des <em>serveurs d'application</em> supplémentaires qui exécutent votre application Django et son serveur HTTP WSGI (comme <a href=\"https://gunicorn.org/\">Gunicorn</a> ou <a href=\"https://uwsgi-docs.readthedocs.io/en/latest/\">uWSGI</a>). Pour acheminer et distribuer les demandes entrantes sur cet ensemble de serveurs d'application, vous pouvez utiliser un <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#load-balancing\">équilibreur de charge</a> et un <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">proxy inverse</a> comme <a href=\"https://www.nginx.com/\">Nginx</a>. Nginx peut également mettre en cache le contenu statique et mettre fin aux connexions <em>TLS</em> (Transport Layer Security Security), utilisées pour fournir des connexions HTTPS, et sécuriser les connexions à votre application.</p>\n\n<p>L'exécution de votre application Django et du proxy Nginx à l'intérieur des <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#container\">conteneurs</a> Docker garantit que ces composants se comportent de la même manière quel que soit l'environnement dans lequel ils sont déployés. De plus, les conteneurs fournissent de nombreuses fonctionnalités qui facilitent l'emballage et la configuration de votre application.</p>\n\n<p>Dans ce tutoriel, vous allez à mettre l'échelle horizontalement une application de <a href=\"https://docs.djangoproject.com/en/3.0/intro/tutorial01/\">sondages</a> pour Django et Gunicorn conteneurisé en fournissant deux serveurs d'application qui exécuteront chacune une copie d'un conteneur d'application Django et Gunicorn.</p>\n\n<p>Vous allez également activer HTTPS, en fournissant et en configurant un troisième serveur proxy qui exécutera un conteneur proxy inverse Nginx et un conteneur client <a href=\"https://certbot.eff.org/\">Certbot</a>. Certbot fournira des certificats TLS pour Nginx à partir de l'autorité de certification <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>. Cela garantira que votre site bénéficie d'une cote de sécurité élevée de la part de <a href=\"https://www.ssllabs.com/\">SSL Labs</a>. Ce serveur proxy recevra toutes les demandes externes de votre application et sera en face des deux serveurs d'application Django <em>en amont</em>. Enfin, vous allez <em>renforcer</em> ce système distribué en limitant l'accès externe au serveur proxy uniquement.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour suivre ce tutoriel, vous aurez besoin de :</p>\n\n<ul>\n<li><p>Trois serveurs Ubuntu 18.04 :</p>\n\n<ul>\n<li>Deux serveurs seront des serveurs <strong>d'application</strong>, utilisés pour exécuter vos applications Django et Gunicorn.</li>\n<li>Un serveur sera un serveur <strong>proxy</strong> utilisé pour exécuter Nginx et Certbot.</li>\n<li>Tous devraient avoir un non-root user avec des privilèges <code>sudo</code> et un pare-feu actif. Pour savoir comment les configurer, veuillez consulter le présent <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Guide de configuration initiale du serveur</a>.</li>\n</ul></li>\n<li><p>Docker installé sur les trois serveurs. Pour obtenir de l'aide sur l'installation de Docker, suivez les Étapes 1 et 2 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04\">Comment installer et utiliser Docker sur Ubuntu 18.04</a>.</p></li>\n<li><p>Un nom de domaine enregistré. Ce tutoriel utilisera <code><span class=\"highlight\">your_domain.com</span></code>tout au long. Vous pouvez en obtenir un gratuitement sur <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> ou utiliser le registre de domaine de votre choix.</p></li>\n<li><p>Un enregistrement DNS <code>A</code> avec <code><span class=\"highlight\">your_domain.com</span></code> pointant sur l'adresse IP publique de votre serveur <strong>proxy</strong>. Vous pouvez suivre <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">cette introduction au DNS DigitalOcean</a> pour plus de détails sur la façon de l'ajouter à un compte DigitalOcean, si c'est ce que vous utilisez.</p></li>\n<li><p>Un object storage bucket S3 comme un <a href=\"https://www.digitalocean.com/products/spaces/\">espace DigitalOcean</a>pour stocker les fichiers statiques de votre projet Django et un ensemble de clés d'accès pour cet espace. Pour apprendre à créer un espace, consultez la documentation produit <a href=\"https://www.digitalocean.com/docs/spaces/how-to/create/\">Comment créer des espaces</a>. Pour apprendre à créer des clés d'accès pour les espaces, consultez <a href=\"https://www.digitalocean.com/docs/spaces/how-to/administrative-access/#access-keys\">Partager l'accès aux espaces avec les clés d'accès</a>. Avec des modifications mineures, vous pouvez utiliser n'importe quel service de stockage d'objets que le plugin <a href=\"https://django-storages.readthedocs.io/en/latest/\">django-storages</a> prend en charge.</p></li>\n<li><p>Une instance serveur PostgreSQL, une base de données et un utilisateur pour votre application Django. Avec des modifications mineures, vous pouvez utiliser n'importe quelle base de données que <a href=\"https://docs.djangoproject.com/en/2.2/ref/databases/\">Django prend en charge</a>.</p>\n\n<ul>\n<li>La base de données PostgreSQL doit être appelée <strong>polls</strong> (ou porter un autre nom facile à retenir et à saisir dans vos fichiers de configuration ci-dessous) ; dans ce tutoriel, l'utilisateur de la base de données sera nommé <strong>sammy</strong>. Pour obtenir des conseils sur la création de ces applications, suivez l'Étape 1 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Comment construire une application Django et Gunicorn avec Docker</a>. Vous pouvez effectuer ces étapes à partir de l'un des trois serveurs.</li>\n<li>Un <a href=\"https://www.digitalocean.com/products/managed-databases/\">cluster PostgreSQL</a> géré par DigitalOcean est utilisé dans ce tutoriel. Pour apprendre à créer un cluster, consultez la <a href=\"https://www.digitalocean.com/docs/databases/how-to/clusters/create/\">documentation produit des bases de données</a> gérées par DigitalOcean</li>\n<li>Vous pouvez également installer et exécuter votre propre instance PostgreSQL. Pour obtenir des conseils sur l'installation et l'administration de PostgreSQL sur un serveur Ubuntu, consultez <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04\">Comment installer et utiliser PostgreSQL sur Ubuntu 18.04</a>.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"Étape 1-—-configuration-du-premier-serveur-d-39-application-django\">Étape 1 — Configuration du premier serveur d'application Django</h2>\n\n<p>Pour commencer, nous allons cloner le référentiel d'application Django sur le premier serveur d'application. Ensuite, nous allons configurer et construire l'image de l'application Docker, et tester l'application en exécutant le conteneur Django.</p>\n\n<p><span class='note'><strong>Remarque :</strong> si vous continuez en suivant <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Comment construire une application Django et Gunicorn avec Docker</a>, vous aurez déjà terminé Étape 1 et pouvez passer à <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-2-%E2%80%94-configuring-the-second-django-application-server\">l'étape 2</a> pour configurer le <strong>deuxième</strong> serveur d'application.<br></span></p>\n\n<p>Commencez par vous connecter au premier des deux serveurs d'application Django et utilisez <code>git</code> pour cloner la branche <code>polls-docker</code> du <a href=\"https://github.com/do-community/django-polls\">référentiel GitHub</a> du tutoriel des applications Django Polls. Ce référentiel contient le code pour l&rsquo;<a href=\"https://docs.djangoproject.com/en/3.0/intro/\">application de sondages</a> dans la documentation de Django. La branche de <code>polls-docker</code> contient une version Dockerisée de l'application de sondage. Pour savoir comment l'application de sondage a été modifiée pour fonctionner efficacement dans un environnement conteneurisé, consultez <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker\">Comment construire une application Django et Gunicorn avec Docker</a>.</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Naviguez dans le répertoire <code>django-polls</code> :</p>\n<pre class=\"code-pre  second-environment\"><code>cd django-polls\n</code></pre>\n<p>Ce répertoire contient le code Python de l'application Django, un <code>Dockerfile</code> que Docker utilisera pour construire l'image du conteneur, ainsi qu'un fichier <code>env</code> contenant une liste de variables d'environnement à passer dans l'environnement d'exécution du conteneur. Inspectez le <code>Dockerfile</code> à l'aide de <code>cat</code> :</p>\n<pre class=\"code-pre  second-environment\"><code>cat Dockerfile\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>FROM python:3.7.4-alpine3.10\n\nADD django-polls/requirements.txt /app/requirements.txt\n\nRUN set -ex \\\n    &amp;&amp; apk add --no-cache --virtual .build-deps postgresql-dev build-base \\\n    &amp;&amp; python -m venv /env \\\n    &amp;&amp; /env/bin/pip install --upgrade pip \\\n    &amp;&amp; /env/bin/pip install --no-cache-dir -r /app/requirements.txt \\\n    &amp;&amp; runDeps=\"$(scanelf --needed --nobanner --recursive /env \\\n        | awk '{ gsub(/,/, \"\\nso:\", $2); print \"so:\" $2 }' \\\n        | sort -u \\\n        | xargs -r apk info --installed \\\n        | sort -u)\" \\\n    &amp;&amp; apk add --virtual rundeps $runDeps \\\n    &amp;&amp; apk del .build-deps\n\nADD django-polls /app\nWORKDIR /app\n\nENV VIRTUAL_ENV /env\nENV PATH /env/bin:$PATH\n\nEXPOSE 8000\n\nCMD [\"gunicorn\", \"--bind\", \":8000\", \"--workers\", \"3\", \"mysite.wsgi\"]\n</code></pre>\n<p>Ce Dockerfile utilise l&rsquo;<a href=\"https://hub.docker.com/_/python\">image Docker</a> officielle de Python 3.7.4 comme base, et installe les exigences du paquet Python de Django et Gunicorn, telles que définies dans le fichier <code>django-polls/requirements.txt</code>. Il supprime ensuite quelques fichiers de construction inutiles, copie le code de l'application dans l'image, et définit le <code>PATH</code> d'exécution. Enfin, il déclare que le port <code>8000</code> sera utilisé pour accepter les connexions de conteneurs entrantes, et exécute <code>gunicorn</code> avec 3 travailleurs, en écoutant sur le port <code>8000</code>.</p>\n\n<p>Pour en savoir plus sur chacune des étapes de ce Dockerfile, consultez l'Étape 6 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-6-%E2%80%94-writing-the-application-dockerfile\">Comment construire une application Django et Gunicorn avec Docker</a>.</p>\n\n<p>Maintenant, construisez l'image à l'aide de <code>docker build</code> :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Nous nommons l'image <code>polls</code> en utilisant le drapeau <code>-t</code> et passons dans le répertoire courant comme <em>contexte de construction</em>, l'ensemble de fichiers à faire référence lors de la construction de l'image.</p>\n\n<p>Après que Docker ait construit et étiqueté l'image, listez les images disponibles à l'aide de <code>docker images</code> :</p>\n<pre class=\"code-pre  second-environment\"><code>docker images\n</code></pre>\n<p>Vous devriez voir l'image <code>polls</code> listée :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\npolls               latest              80ec4f33aae1        2 weeks ago         197MB\npython              3.7.4-alpine3.10    f309434dea3a        8 months ago        98.7MB\n</code></pre>\n<p>Avant de lancer le conteneur Django, nous devons configurer son environnement d'exécution à l'aide du fichier <code>env</code> présent dans le répertoire actuel. Ce fichier sera transmis dans la commande <code>docker run</code> utilisée pour exécuter le conteneur, et Docker injectera les variables d'environnement configurées dans l'environnement d'exécution du conteneur.</p>\n\n<p>Ouvrez le fichier <code>env</code> avec <code>nano</code> ou votre éditeur préféré :</p>\n<pre class=\"code-pre  second-environment\"><code>nano env\n</code></pre>\n<p>Nous allons configurer le fichier comme ceci, et vous devrez ajouter quelques valeurs supplémentaires comme indiqué ci-dessous.</p>\n<div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  second-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Remplissez les valeurs manquantes pour les clés suivantes :</p>\n\n<ul>\n<li><code>DJANGO_SECRET_KEY</code> : définissez cette valeur à une valeur unique et imprévisible, comme indiqué dans les <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#secret-key\">docs de Django</a>. Une méthode de génération de cette clé est fournie dans <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Ajustement des paramètres du tutoriel</a> sur les <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">applications Django dimensionnables</a>.</li>\n<li><code>DJANGO_ALLOWED_HOSTS</code>: : cette variable sécurise l'application et prévient les attaques d'en-tête d'hôte HTTP. Pour les besoins de test, définissez cette variable à <code>*</code>, un joker qui correspondra à tous les hôtes. En production, vous devriez la définir sur <code><span class=\"highlight\">your_domain.com</span></code>. Pour en savoir plus sur ce paramètre Django, consultez <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#allowed-hosts\">les paramètres de base</a> dans les docs Django.</li>\n<li><code>DATABASE_USERNAME</code> : définissez ce paramètre sur l'utilisateur de la base de données PostgreSQL créé dans les étapes préalables.</li>\n<li><code>DATABASE_NAME</code> : définissez ce paramètres sur <code>polls</code> ou le nom de la base de données PostgreSQL créée dans les étapes préalables.</li>\n<li><code>DATABASE_PASSWORD</code> : définissez ce paramètre sur le mot de passe de l'utilisateur PostgreSQL créé dans les étapes préalables.</li>\n<li><code>DATABASE_HOST</code> : définissez ce paramètre sur le nom d'hôte de votre base de données.</li>\n<li><code>DATABASE_PORT</code> : définissez ce paramètre sur le port de votre base de données.</li>\n<li><code>STATIC_ACCESS_KEY_ID</code> : définissez ce paramètre sur votre bucket S3 ou sur la clé d'accès à l'espace.</li>\n<li><code>STATIC_ACCESS_KEY_ID</code> : définissez ce paramètre sur votre bucket S3 ou sur la clé secrète d'accès à l'espace.</li>\n<li><code>STATIC_BUCKET_NAME</code> : définissez ce paramètre sur votre bucket S3 ou votre nom d'espace.</li>\n<li><code>STATIC_ENDPOINT_URL</code> : définissez ce paramètre sur le bucket S3 approprié ou l'URL de votre espace, par exemple <code>https://<span class=\"highlight\">space-name</span>.nyc3.digitaloceanspaces.com</code> si votre espace se trouve dans la région <code>nyc3</code>.</li>\n</ul>\n\n<p>Une fois que vous avez terminé de le modifier, enregistrez et fermez le fichier.</p>\n\n<p>Nous allons maintenant utiliser <code>docker run</code> pour remplacer le paramètre <code>CMD</code> dans le Dockerfile et créer le schéma de base de données à l'aide des commandes <code>manage.py</code> et <code>manage.py migrate</code> :</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"\n</code></pre>\n<p>Nous lançons le container d'images <code>polls:latest</code>, nous passons dans le fichier variable d'environnement que nous venons de modifier, et remplacons la commande Dockerfile par <code>sh -c \"python manage.py makemigrations python manage.py image\"</code>, qui créera le schéma de base de données défini par le code de l'application. Si vous exécutez cette opération pour la première fois, vous devriez voir ce qui suit :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>No changes detected\nOperations to perform:\n  Apply all migrations: admin, auth, contenttypes, polls, sessions\nRunning migrations:\n  Applying contenttypes.0001_initial... OK\n  Applying auth.0001_initial... OK\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying contenttypes.0002_remove_content_type_name... OK\n  Applying auth.0002_alter_permission_name_max_length... OK\n  Applying auth.0003_alter_user_email_max_length... OK\n  Applying auth.0004_alter_user_username_opts... OK\n  Applying auth.0005_alter_user_last_login_null... OK\n  Applying auth.0006_require_contenttypes_0002... OK\n  Applying auth.0007_alter_validators_add_error_messages... OK\n  Applying auth.0008_alter_user_username_max_length... OK\n  Applying auth.0009_alter_user_last_name_max_length... OK\n  Applying auth.0010_alter_group_name_max_length... OK\n  Applying auth.0011_update_proxy_permissions... OK\n  Applying polls.0001_initial... OK\n  Applying sessions.0001_initial... OK\n</code></pre>\n<p>Cela indique que le schéma de base de données a été créé avec succès.</p>\n\n<p>Si vous exécutez <code>migrate</code> une, fois de plus, Django effectuera un no-op à moins que le schéma de base de données ait changé.</p>\n\n<p>Ensuite, nous allons exécuter une autre instance du conteneur de l'application et utiliser un shell interactif à l'intérieur de celui-ci pour créer un utilisateur administratif pour le projet Django.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -i -t --env-file env polls sh\n</code></pre>\n<p>Vous obtiendrez une invite shell à l'intérieur du conteneur en cours d'exécution que vous pouvez utiliser pour créer l'utilisateur Django :</p>\n<pre class=\"code-pre  second-environment\"><code>python manage.py createsuperuser\n</code></pre>\n<p>Entrez un nom d'utilisateur, une adresse email et un mot de passe pour votre utilisateur, et après avoir créé l'utilisateur, appuyez sur <code>CTRL+D</code> pour quitter le conteneur et le fermer.</p>\n\n<p>Enfin, nous allons générer les fichiers statiques pour l'application et les télécharger sur l'espace DigitalOcean à l'aide de <code>collectstatic</code>. Notez que cela peut prendre un peu de temps.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py collectstatic --noinput\"\n</code></pre>\n<p>Une fois que ces fichiers sont générés et téléchargés, vous obtiendrez la sortie suivante.</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>121 static files copied.\n</code></pre>\n<p>Nous pouvons maintenant exécuter l'application :</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env -p 80:8000 polls\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>[2019-10-17 21:23:36 +0000] [1] [INFO] Starting gunicorn 19.9.0\n[2019-10-17 21:23:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8000 (1)\n[2019-10-17 21:23:36 +0000] [1] [INFO] Using worker: sync\n[2019-10-17 21:23:36 +0000] [7] [INFO] Booting worker with pid: 7\n[2019-10-17 21:23:36 +0000] [8] [INFO] Booting worker with pid: 8\n[2019-10-17 21:23:36 +0000] [9] [INFO] Booting worker with pid: 9\n</code></pre>\n<p>Ici, nous exécutons la commande par défaut définie dans le Dockerfile, <code>gunicorn --bind :8000 --workers 3 mysite.wsgi:application</code>, et exposons le port de conteneur <code>8000</code> afin que le port <code>80</code> sur le serveur Ubuntu soit mappé sur le port <code>8000</code> du conteneur <code>polls</code>.</p>\n\n<p>Vous devriez maintenant pouvoir naviguez jusqu'à l'application <code>de sondages</code> à l'aide de votre navigateur web en tapant : <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> dans la barre d'URL. Comme il n'y a pas de route définie pour le chemin d'accès <code>/</code> , vous obtiendrez probablement une erreur de recherche <code>404 Page Not Found</code>, qui est prévisible.</p>\n\n<p><span class='warning'><strong>Attention :</strong> Lorsque vous utilisez le pare-feu UFW avec Docker, Docker contourne les règles de pare-feu UFW, comme indiqué dans ce <a href=\"https://github.com/docker/for-linux/issues/690\">numéro de GitHub</a>. Cela explique pourquoi vous avez accès au port <code>80</code> de votre serveur, même si vous n'avez pas explicitement créé de règle d'accès UFW dans aucune étape préalable. Dans l&rsquo;<a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-5-%E2%80%94-preventing-external-access-to-django-app-servers\">Étape 5</a>, nous aborderons cette faille de sécurité en corrigeant la configuration d'UFW. Si vous n'utilisez pas UFW et que vous utilisez les <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">pare-feu Cloud</a> de DigitalOcean, vous pouvez ignorer cet avertissement.<br></span></p>\n\n<p>Naviguez sur <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> pour voir l'interface de l'application de sondage :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Interface des applications de sondage\"></p>\n\n<p>Pour voir l'interface administrative, allez à <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/admin</code>. Vous devriez voir la fenêtre d'authentification de l'application de sondage :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin.png\" alt=\"Page Auth admin des sondages\"></p>\n\n<p>Entrez le nom d'utilisateur administratif et le mot de passe que vous avez créé avec la commande <code>createsuperuser</code>.</p>\n\n<p>Après avoir été authentifié, vous pouvez accéder à l'interface administrative de l'application de sondage :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png\" alt=\"Interface principale de l'administration de sondages\"></p>\n\n<p>Notez que les actifs statiques pour les applications d&rsquo;<code>administration</code> et <code>de sondage</code> sont livrées directement depuis le stockage d'objets. Pour confirmer ceci, consultez <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#testing-spaces-static-file-delivery\">Testing Spaces Static File Delivery</a>.</p>\n\n<p>Lorsque vous avez terminé d'explorer, appuyez sur <code>CTRL+C</code> dans la fenêtre de terminal en exécutant le conteneur de Docker pour terminer le conteneur.</p>\n\n<p>Maintenant que vous avez confirmé que le conteneur d'application fonctionne comme prévu, vous pouvez l'exécuter en mode <em>détaché</em>, qui l'exécutera en arrière-plan et vous permettra de vous déconnecter de votre session SSH :</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Le drapeau <code>-d</code> demande à Docker d'exécuter le conteneur en mode détaché, le drapeau <code>-rm</code> nettoie le système de fichiers du conteneur après la fermeture du conteneur, et nous donnons un nom aux <code>sondages</code> de conteneur.</p>\n\n<p>Déconnectez-vous du premier serveur d'application Django, et naviguez vers <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> pour confirmer que le conteneur fonctionne comme prévu.</p>\n\n<p>Maintenant que votre premier serveur d'application Django est opérationnel, vous pouvez configurer votre deuxième serveur d'application Django.</p>\n\n<h2 id=\"Étape-2-—-configuration-du-deuxième-serveur-d-39-application-django\">Étape 2 — Configuration du deuxième serveur d'application Django</h2>\n\n<p>Comme beaucoup de commandes pour configurer ce serveur seront les mêmes que celles de l'étape précédente, elles seront présentées ici sous forme abrégée. Veuillez consulter l&rsquo;<a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Étape 1</a> pour plus d'informations sur une commande particulière de cette étape.</p>\n\n<p>Commencez par vous connecter au <strong>deuxième</strong> serveur d'application Django.</p>\n\n<p>Clonez la branche <code>polls-docker</code> du référentiel GitHub <code>django-polls</code> :</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Naviguez dans le répertoire <code>django-polls</code> :</p>\n<pre class=\"code-pre  third-environment\"><code>cd django-polls\n</code></pre>\n<p>Maintenant, construisez l'image à l'aide de <code>docker build</code> :</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Ouvrez le fichier <code>env</code> avec <code>nano</code> ou votre éditeur préféré :</p>\n<pre class=\"code-pre  third-environment\"><code>nano env\n</code></pre><div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  third-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Remplissez les valeurs manquantes comme à <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">l'Étape 1</a>. Lorsque vous avez terminé les modifications, enregistrez et fermez le fichier.</p>\n\n<p>Enfin, exécutez le conteneur d'application en mode détaché :</p>\n<pre class=\"code-pre  third-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Naviguez jusqu'à <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span>/polls</code> pour confirmer que le conteneur fonctionne comme prévu. Vous pouvez vous déconnecter en toute sécurité du deuxième serveur d'application sans mettre fin à votre conteneur en cours d'exécution.</p>\n\n<p>Une fois les conteneurs d'application Django opérationnels, vous pouvez passer à la configuration du conteneur proxy inverse Nginx.</p>\n\n<h2 id=\"Étape 3-—-configuration-du-conteneur-docker-nginx\">Étape 3 — Configuration du conteneur Docker Nginx</h2>\n\n<p><a href=\"https://www.nginx.com/\">Nginx</a> est un serveur web polyvalent qui offre un certain nombre de fonctionnalités, dont <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\">le proxy inverse</a>, <a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\">l'équilibrage de la charge</a> et la <a href=\"https://en.wikipedia.org/wiki/Web_cache\">mise en cache</a>. Dans ce tutoriel, nous avons déchargé les ressources statiques de Django pour le stockage d'objets, nous n'utiliserons donc pas les capacités de mise en cache de Nginx. Cependant, nous utiliserons Nginx comme proxy inverse sur nos deux serveurs d'application Django de backend et distribuerons les demandes entrantes entre eux. En outre, Nginx effectuera <a href=\"https://en.wikipedia.org/wiki/TLS_termination_proxy\">la terminaison</a> et la redirection TLS à l'aide d'un certificat TLS fourni par Certbot. Cela signifie qu'il forcera les clients à utiliser HTTPS, redirigeant les requêtes HTTPS vers le port 443. Il déchiffrera ensuite les requêtes HTTPS, puis les enverra par proxy aux serveurs Django en amont.</p>\n\n<p>Dans ce tutoriel, nous avons pris la décision de découpler les conteneurs Nginx des serveurs de backend. En fonction de votre cas d'utilisation, vous pouvez choisir d'exécuter le conteneur Nginx sur l'un des serveurs d'application Django, en envoyant les requêtes par proxy localement et ainsi que vers l'autre serveur Django. Une autre architecture possible serait d'exécuter deux conteneurs Nginx, un sur chaque serveur de backend avec un <a href=\"https://www.digitalocean.com/products/load-balancer/\">load balancer</a> en cloud en avant. Chaque architecture présente différents avantages de sécurité et de performance, et vous devriez <a href=\"https://en.wikipedia.org/wiki/Load_testing\">tester la charge</a> de votre système pour découvrir les goulets d'étranglement. L'architecture flexible décrite dans ce tutoriel vous permet d'évaluer à la fois la couche d'application Django de backend et la couche proxy Nginx. Une fois que le conteneur Nginx unique devient un goulot d'étranglement, vous pouvez échelonner sur plusieurs proxies Nginx, et ajouter un load balancer en cloud ou un load balancer L4 rapide comme <a href=\"http://www.haproxy.org/\">HAProxy</a>.</p>\n\n<p>Une fois les deux serveurs d'applications Django en place, nous pouvons commencer à configurer le serveur proxy Nginx. Connectez-vous à votre serveur proxy et créez un répertoire appelé <code>conf</code> :</p>\n<pre class=\"code-pre  fourth-environment\"><code>mkdir conf\n</code></pre>\n<p>Créez un fichier de configuration appelé <code>nginx.conf</code> à l'aide de <code>nano</code> ou de votre éditeur préféré :</p>\n<pre class=\"code-pre  fourth-environment\"><code>nano conf/nginx.conf\n</code></pre>\n<p>Collez dans la configuration Nginx suivante :</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>\nupstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n\nserver {\n    listen 80 default_server;\n    return 444;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n\n    # SSL\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n\n    client_max_body_size 4G;\n    keepalive_timeout 5;\n\n        location / {\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header X-Forwarded-Proto $scheme;\n          proxy_set_header Host $http_host;\n          proxy_redirect off;\n          proxy_pass http://django;\n        }\n\n    location ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n    }\n\n}\n</code></pre>\n<p>Ces blocs <code>upstream</code>, <code>server</code> et <code>location</code> configurent Nginx pour rediriger les requêtes HTTP vers HTTPS, et et équilibrent la charge entre les deux serveurs d'applications Django configurés aux Étapes 1 et 2. Pour en savoir plus sur la structure du fichier de configuration Nginx, consultez cet article sur <a href=\"https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts#understanding-nginx-configuration-contexts\">la compréhension de la structure du fichier de configuration Nginx et les contextes de configuration</a>. En outre, cet article sur <a href=\"https://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\">La compréhension des algorithmes de sélection des serveurs Nginx et des blocs de localisation</a> peut être utile.</p>\n\n<p>Cette configuration a été assemblée à partir d'exemplesde fichiers de configuration fournis par <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Gunicorn</a>, <a href=\"https://github.com/certbot/certbot/blob/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf\">Cerbot</a> et <a href=\"https://hub.docker.com/_/nginx\">Nginx</a> et est conçue comme une configuration Nginx minimale pour que cette architecture soit opérationnelle. L'adaptation de cette configuration Nginx dépasse la portée de cet article, mais vous pouvez utiliser un outil comme <a href=\"https://www.digitalocean.com/community/tools/nginx\">NGINXConfig</a> pour générer des fichiers de configuration Nginx performants et sécurisés pour votre architecture.</p>\n\n<p>Le bloc <code>upstream</code> définit le groupe de serveurs utilisés pour les demandes de proxy à l'aide de la directive <code>proxy_pass</code> :</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>upstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n. . .\n</code></pre>\n<p>Dans ce bloc, nous nommons le upstream <code>django</code> et incluons les adresses IP des deux serveurs d'application Django. Si les serveurs d'application fonctionnent sur DigitalOcean et que le réseau VPC est activé, vous devriez utiliser leurs adresses IP privées ici. Pour apprendre à activer le VPC Networking sur DigitalOcean, consultez <a href=\"https://www.digitalocean.com/docs/networking/vpc/how-to/enable/\">Comment activer le VPC Networking sur les droplets existants</a>.</p>\n\n<p>Le premier bloc <code>server</code> capture les demandes qui ne correspondent pas à votre domaine et met fin à la connexion. Par exemple, une requête HTTP directe vers l'adresse IP de votre serveur serait traitée par ce bloc :</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80 default_server;\n    return 444;\n}\n. . .\n</code></pre>\n<p>Le bloc <code>server</code> suivant redirige les requêtes HTTP, vers votre domaine, à l'aide d'un redirect <a href=\"https://en.wikipedia.org/wiki/HTTP_301\">HTTP 301 redirect</a>. Ces demandes sont ensuite traitées par le bloc <code>server</code> final :</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name your_domain.com;\n    return 301 https://$server_name$request_uri;\n}\n. . .\n</code></pre>\n<p>Ces deux directives définissent les chemins d'accès au certificat TLS et à la clé secrète. Ceux-ci seront fournis à l'aide de Certbot et montés dans le conteneur Nginx à l'étape suivante.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\nssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n. . .\n</code></pre>\n<p>Ces paramètres sont les valeurs par défaut de la sécurité SSL recommandées par Certbot. Pour en savoir plus sur ces questions, consultez le <a href=\"https://nginx.org/en/docs/http/ngx_http_ssl_module.html\">Module ngx_http_ssl_module</a> dans les docs Nginx. <a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\">Security/Server Side TLS</a> de Mozilla est un autre guide utile que vous pouvez utiliser pour ajuster la configuration SSL.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n. . .\n</code></pre>\n<p>Ces deux directives d&rsquo;<a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">exemple de configuration Nginx</a> de Gunicorn définissent la taille maximale autorisée du corps de requête client et attribuent le timeout pour les connexions keep-alive avec le client. Nginx fermera les connexions avec le client après <code>keepalive_timeout</code> secondes.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nclient_max_body_size 4G;\nkeepalive_timeout 5;\n. . .\n</code></pre>\n<p>Le premier bloc <code>location</code> permet à Nginx d'accéder aux demandes de proxy vers les serveurs <code>upstream django</code> sur HTTP. Il préserve également les en-têtes HTTP du client qui capturent l'adresse IP d'origine, le protocole utilisé pour la connexion et l'hôte cible :</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation / {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://django;\n}\n. . .\n</code></pre>\n<p>Pour en savoir plus sur ces directives, consultez <a href=\"https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration\">Deploying Gunicorn</a> et <a href=\"http://nginx.org/en/docs/http/ngx_http_proxy_module.html\">Module ngx_http_proxy_module</a> à partir des docs Deploying</p>\n\n<p>Le bloc <code>location</code> final capture les demandes vers le chemin <code>/well-known/acme-challenge/</code> utilisé par Certbot pour les défis HTTP-01 pour vérifier votre domaine avec Let&rsquo;s Encrypt et fournir ou renouveler les certificats TLS. Pour plus d'informations sur le défi HTTP-01 utilisé par Certbot, consultez <a href=\"https://letsencrypt.org/docs/challenge-types/\">les Types de défi</a> dans les docs Let&rsquo;s Encrypt.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n}\n</code></pre>\n<p>Une fois que vous avez terminé de le modifier, enregistrez et fermez le fichier.</p>\n\n<p>Vous pouvez maintenant utiliser ce fichier de configuration pour exécuter un conteneur Docker Nginx. Dans ce tutoriel, nous utiliserons l'image <code>nginx:1.19.0</code>, version <code>1</code>.19.0 de l&rsquo;<a href=\"https://hub.docker.com/_/nginx\">image Docker officielle</a> maintenue par Nginx.</p>\n\n<p>Lorsque nous exécutons le conteneur pour la première fois, Nginx lancera une erreur et échouera car nous n'avons pas encore fourni les certificats définis dans le fichier de configuration. Cependant, nous allons toujours exécuter la commande pour télécharger l'image Nginx localement et tester que tout le reste fonctionne correctement :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Ici, nous nommons le conteneur <code>nginx</code> et cartographions les ports hôtes <code>80</code> et <code>443</code> vers les ports conteneur respectifs. Le drapeau <code>-v</code> monte le fichier de configuration dans le conteneur Nginx à <code>/etc/nginx/conf.d/nginx.conf</code>, que l'image Nginx est préconfigurée pour charger. Il est monté en mode <code>ro</code> ou &ldquo;read only&rdquo;, de sorte que le conteneur ne peut pas modifier le fichier. Le répertoire racine web <code>/var/www/html</code> est également monté dans le conteneur. Enfin, <code>nginx:1.19.0</code> demande à Docker de tirer et d'exécuter l'image <code>nginx:1.19.0</code> depuis Dockerhub.</p>\n\n<p>Docker tirera et exécutera l'image, puis Nginx lancera une erreur lorsqu'il ne trouvera pas le certificat TLS configuré et la clé secrète. Dans la prochaine étape, nous allons les fournir à l'aide d'un client Certbot Dockerizé et de l'autorité de certification Let&rsquo;s Encrypt.</p>\n\n<h2 id=\"Étape 4-—-configuration-de-cerbot-et-renouvellement-du-certificat-let-39-s-encrypt\">Étape 4 — Configuration de Cerbot et renouvellement du certificat Let&rsquo;s Encrypt</h2>\n\n<p><a href=\"https://github.com/certbot/certbot\">Certbot</a> est un client Let&rsquo;s Encrypt développé par la <a href=\"https://www.eff.org/\">Electronic Frontier Foundation</a>. Il fournit des certificats TLS gratuits depuis l'autorité de certification <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> qui permet aux navigateurs de vérifier l'identité de vos serveurs web. Comme Docker a été installé sur notre serveur proxy Nginx, nous utiliserons l&rsquo;<a href=\"https://hub.docker.com/r/certbot/certbot/\">image Certbot Docker</a> pour fournir et renouveler les certificats TLS.</p>\n\n<p>Commencez par vous assurer que vous disposez d'un enregistrement DNS <code>A</code> mappé à l'adresse IP publique du serveur proxy. Ensuite, sur votre serveur proxy, proposez une version de mise en scène des certificats à l'aide de l'image <code>certbot</code> Docker :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone --staging -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Cette commande exécute l'image <code>certbot</code> Docker en mode interactif, et achemine le port <code>80</code> de l'hôte au port <code>80</code> du conteneur. Il crée et monte deux répertoires hôtes dans le conteneur : <code>/etc/letsencrypt/</code> et <code>/var/lib/letsencrypt/</code> <code>certbot</code> est exécuté en mode <code>stand alone</code>, sans Nginx, et utilisera les serveurs <code>staging</code> de Let&rsquo;s Encrypt pour effectuer la validation du domaine.</p>\n\n<p>Lorsque vous y êtes invité, entrez votre adresse email et acceptez les conditions de service. Si la validation du domaine a réussi, vous devriez voir la sortie suivante :</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Obtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for stubb.dev\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem\n   Your cert will expire on 2020-09-15. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - Your account credentials have been saved in your Certbot\n   configuration directory at /etc/letsencrypt. You should make a\n   secure backup of this folder now. This configuration directory will\n   also contain certificates and private keys obtained by Certbot so\n   making regular backups of this folder is ideal.\n</code></pre>\n<p>Vous pouvez inspecter le certificat à l'aide de <code>cat</code> :</p>\n<pre class=\"code-pre  fourth-environment\"><code>sudo cat /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n</code></pre>\n<p>Une fois le certificat TLS fourni, nous pouvons tester la configuration Nginx assemblée à l'étape précédente :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>C'est la même commande exécutée à l&rsquo;<a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Étape 3</a>, avec l'ajout des deux répertoires Let&rsquo;s Encrypt récemment créés.</p>\n\n<p>Une fois que Nginx est opérationnel, naviguez jusqu'à <code>http://<span class=\"highlight\">your_domain.com</span></code>. Vous pouvez recevoir un avertissement dans votre navigateur signalant que l'autorité de certification est invalide. C'est normal car nous avons fourni des certificats de mise en scène et non pas des certificats Let&rsquo;s Encrypt. Vérifiez la barre d'URL de votre navigateur pour confirmer que votre requête HTTP a été redirigée vers HTTPS.</p>\n\n<p>Entrez <code>CTRL+C</code> dans votre terminal pour quitter Nginx et exécutez à nouveau le client <code>certbot</code>, cette fois en omettant le drapeau <code>--staging</code> flag :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Lorsque vous êtes invité à conserver le certificat existant ou à le renouveler et à le remplacer, tapez <code>2</code> pour le renouveler et ensuite <code>ENTER</code> (ENTRÉE) pour confirmer votre choix.</p>\n\n<p>Une fois le certificat de production TLS fourni, exécutez à nouveau le serveur Nginx :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Dans votre navigateur, naviguez vers <code>http://<span class=\"highlight\">your_domain.com</span></code>. Dans la barre d'URL, vérifiez que la requête HTTP a été redirigée vers HTTPS. Comme l'application de sondage n'a pas de route configurée par défaut, vous devriez voir une erreur Django <strong>Page not found</strong>. Naviguez vers <code>https://<span class=\"highlight\">your_domain.com</span>/polls</code> et vous verrez l'interface standard de l'application de sondage :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Interface des applications de sondage\"></p>\n\n<p>Vous avez maintenant fourni un certificat TLS de production à l'aide du client Certbot Docker, et vous effectuez un proxying inverse et un équilibrage de charge des requêtes externes vers les deux serveurs d'application Django.</p>\n\n<p>Les certificats Let&rsquo;s Encrypt expirent tous les 90 jours. Pour vous assurer que votre certificat reste valide, vous devriez le renouveler régulièrement avant son expiration prévue. Avec Nginx en cours d'exécution, vous devriez utiliser le client Certbot en mode <code>webroot</code> au lieu d'un mode <code>standalone</code>. Cela signifie que Certbot effectuera la validation en créant un fichier dans le répertoire <code>/var/www/html/.well-known/acme-challenge/</code> et les demandes de validation Let&rsquo;s Encrypt vers ce chemin seront captées par la règle <code>location</code> définie dans la configuration Nginx à l&rsquo;<a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Étape 3</a>. Certbot effectuera ensuite la rotation des certificats, et vous pouvez recharger Nginx afin qu'il utilise ce certificat qui vient d'être fourni.</p>\n\n<p>Il existe de multiples façons d'automatiser cette procédure et le renouvellement automatique des certificats TLS va au-delà de la portée de ce tutoriel. Pour effectuer un processus similaire à l'aide de l'utilitaire de planification <code>cron</code>, consultez l'Étape 6 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates%5D(https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates)\">Comment sécuriser une application Node.js avec Nginx, Let&rsquo;s Encrypt et Docker Compose</a>.</p>\n\n<p>Dans votre terminal, entrez sur <code>CTRL+C</code> pour terminer le conteneur Nginx. Exécutez-le à nouveau en mode détaché en apposant le drapeau <code>-d</code> :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -d -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n  -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Avec Nginx en cours d'exécution en arrière-plan, utilisez la commande suivante pour effectuer un essai de la procédure de renouvellement du certificat :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm --name certbot \\\n    -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n  -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n  -v \"/var/www/html:/var/www/html\" \\\n  certbot/certbot renew --webroot -w /var/www/html --dry-run\n</code></pre>\n<p>Nous utilisons le plugin <code>--webroot</code>, spécifions le chemin racine web, et utilisons le drapeau <code>--dry-run</code> pour vérifier que tout fonctionne correctement sans réellement effectuer le renouvellement du certificat.</p>\n\n<p>Si la simulation de renouvellement réussit, vous devriez voir la sortie suivante :</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Cert not due for renewal, but simulating renewal for dry run\nPlugins selected: Authenticator webroot, Installer None\nRenewing an existing certificate\nPerforming the following challenges:\nhttp-01 challenge for <span class=\"highlight\">your_domain.com</span>\nUsing the webroot path /var/www/html for all unmatched domains.\nWaiting for verification...\nCleaning up challenges\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nnew certificate deployed without reload, fullchain is\n/etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates below have not been saved.)\n\nCongratulations, all renewals succeeded. The following certs have been renewed:\n  /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem (success)\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates above have not been saved.)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n</code></pre>\n<p>Dans un environnement de production, après avoir renouvelé les certificats, vous devez recharger Nginx pour que les modifications prennent effet. Pour recharger Nginx, exécutez la commande suivante :</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker kill -s HUP nginx\n</code></pre>\n<p>Cette commande enverra un signal Unix <a href=\"https://en.wikipedia.org/wiki/SIGHUP\">HUP</a> au processus Nginx en cours d'exécution dans le conteneur Docker <code>nginx</code>. À la réception de ce signal, Nginx rechargera sa configuration et les certificats renouvelés.</p>\n\n<p>Une fois HTTPS activé, et tous les composants de cette architecture opérationnels, la dernière étape consiste à verrouiller la configuration en empêchant l'accès externe aux deux serveurs d'application backend ; toutes les requêtes HTTP devraient passer par le proxy Nginx.</p>\n\n<h2 id=\"Étape 5-—-prévention-de-l-39-accès-externe-aux-serveurs-d-39-application-django\">Étape 5 — Prévention de l'accès externe aux serveurs d'application Django</h2>\n\n<p>Dans l'architecture décrite dans ce tutoriel, la terminaison SSL se produit au niveau du proxy Nginx. Cela signifie que Nginx décrypte la connexion SSL, et que les paquets sont acheminés vers les serveurs d'application Django non cryptés. Pour de nombreux cas d'utilisation, ce niveau de sécurité est suffisant. Pour les applications impliquant des données financières ou sanitaires, vous souhaiterez peut-être mettre en place le cryptage de bout en bout. Vous pouvez le faire en envoyant des paquets cryptés via le répartiteur de charge et en les décryptant sur les serveurs d'application, ou en les cryptant à niveau du proxy et en décryptant une fois de plus sur les serveurs d'application Django. Ces techniques vont au-delà de la portée de cet article, mais pour en savoir plus veuillez consulter le <a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">Cryptage de bout en bout</a>.</p>\n\n<p>Le proxy Nginx agit comme une passerelle entre le trafic externe et le réseau interne. En théorie, aucun client externe ne doit avoir un accès direct aux serveurs d'application internes, et toutes les demandes doivent passer par le serveur Nginx. La remarque de l&rsquo;<a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Étape 1</a> décrit brièvement un <a href=\"https://github.com/docker/for-linux/issues/690\">problème ouvert</a> avec Docker où Docker contourne les paramètres du pare-feu <code>ufw</code> par défaut et ouvre les ports à l'extérieur, ce qui peut se révéler dangereux. Pour répondre à cette préoccupation de sécurité, il est recommandé d'utiliser <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">les pare-feu en cloud</a> lors de l'utilisation de serveurs Docker. Pour obtenir plus d'informations sur la création de pare-feu en cloud avec DigitalOcean, consultez <a href=\"https://www.digitalocean.com/docs/networking/firewalls/how-to/create/\">Comment créer des pare-feu</a>. Vous pouvez également manipuler directement les <code>iptables</code> au lieu d'utiliser <code>ufw</code>. Pour en savoir plus sur l'utilisation d&rsquo;<code>iptables</code> avec Docker, consultez <a href=\"https://docs.docker.com/network/iptables/\">Docker et iptables</a>.</p>\n\n<p>Au cours de cette étape, nous allons modifier la configuration d'UFW pour bloquer l'accès externe aux ports hôtes ouverts par Docker. En exécutant Django sur les serveurs d'application, nous avons passé le drapeau <code>-p 80:8000</code> à <code>docker</code>, qui achemine le port <code>80</code> de l'hôte au port de conteneur <code>8000</code>. Cela a également ouvert le port <code>80</code> à des clients externes, ce que vous pouvez vérifier en visitant <code>http://<span class=\"highlight\">your_app_server_1_IP</span></code>. Pour éviter un accès direct, nous allons modifier la configuration d'UFW à l'aide de la méthode décrite dans le <a href=\"https://github.com/chaifeng/ufw-docker\">référentiel GitHub ufw-docker</a>.</p>\n\n<p>Commencez par vous connecter au premier serveur d'application Django. Ensuite, ouvrez le fichier <code>/etc/ufw/after.rules</code> avec des privilèges super-utilisateur, à l'aide de <code>nano</code> ou de votre éditeur préféré :</p>\n<pre class=\"code-pre  second-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Entrez votre mot de passe lorsque vous y serez invité, et appuyez sur <code>ENTER</code> pour confirmer.</p>\n\n<p>Vous devriez voir les règles <code>ufw</code> suivantes :</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>#\n# rules.input-after\n#\n# Rules that should be run after the ufw command line added rules. Custom\n# rules should be added to one of these chains:\n#   ufw-after-input\n#   ufw-after-output\n#   ufw-after-forward\n#\n\n# Don't delete these required lines, otherwise there will be errors\n*filter\n:ufw-after-input - [0:0]\n:ufw-after-output - [0:0]\n:ufw-after-forward - [0:0]\n# End required lines\n\n# don't log noisy services by default\n-A ufw-after-input -p udp --dport 137 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 138 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 139 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 445 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 67 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 68 -j ufw-skip-to-policy-input\n\n# don't log noisy broadcast\n-A ufw-after-input -m addrtype --dst-type BROADCAST -j ufw-skip-to-policy-input\n\n# don't delete the 'COMMIT' line or these rules won't be processed\nCOMMIT\n</code></pre>\n<p>Faites défiler vers le bas, et collez dans le bloc suivant des règles de configuration UFW :</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Ces règles limitent l'accès du public aux ports ouverts par Docker, et permettent un accès à partir des plages IP privées <code>10.0.0/8</code>, <code>172.16.0.0/12</code> et <code>192.168.0.0/16</code>. Si vous utilisez VPC avec DigitalOcean, alors les Droplets de votre réseau VPC aura accès au port ouvert sur l'interface réseau privée, mais les clients externes ne l'auront pas. Pour plus d'informations sur VPC, consultez la <a href=\"https://www.digitalocean.com/docs/networking/vpc/\">documentation officielle de VPC</a>. Pour en savoir plus sur les règles appliquées dans ce snippet, consultez <a href=\"https://github.com/chaifeng/ufw-docker#how-it-works\">Comment ça marche ?</a> du <a href=\"https://github.com/chaifeng/ufw-docker\">fichier README ufw-docker</a>.</p>\n\n<p>Si vous n'utilisez pas VPC avec DigitalOcean et que vous avez entré les adresses IP publiques des serveurs d'application dans le bloc <code>upstream</code> de votre configuration Nginx, vous devrez modifier explicitement le pare-feu UFW pour autoriser le trafic depuis le serveur Nginx par le port <code>80</code> sur les serveurs d'application Django. Pour obtenir des conseils sur la création de règles <code>allow</code> avec le pare-feu UFW, consultez <a href=\"https://www.digitalocean.com/community/tutorials/ufw-essentials-common-firewall-rules-and-commands\">les Essentiels  d'UFW: Règles et commandes communes du pare-feu</a>.</p>\n\n<p>Quand vous avez terminé de le modifier, enregistrez et fermez le fichier.</p>\n\n<p>Redémarrez <code>ufw</code> afin qu'il adopte la nouvelle configuration :</p>\n<pre class=\"code-pre  second-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Naviguez vers <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> dans votre navigateur web pour vérifier que vous ne pouvez plus accéder au serveur d'application sur le port <code>80</code>.</p>\n\n<p>Répétez ce processus sur le deuxième serveur d'application Django.</p>\n\n<p>Déconnectez-vous du premier serveur d'application ou ouvrez une autre fenêtre de terminal, et connectez-vous au deuxième serveur d'application Django. Ensuite, ouvrez le fichier <code>/etc/ufw/after.rules</code> avec des privilèges super-utilisateur, à l'aide de <code>nano</code> ou de votre éditeur préféré :</p>\n<pre class=\"code-pre  third-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Entrez votre mot de passe lorsque vous y serez invité, et appuyez sur <code>ENTER</code> pour confirmer.</p>\n\n<p>Faites défiler vers le bas, et collez dans le bloc suivant des règles de configuration UFW :</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  third-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Quand vous avez terminé de le modifier, enregistrez et fermez le fichier.</p>\n\n<p>Redémarrez <code>ufw</code> afin qu'il adopte la nouvelle configuration :</p>\n<pre class=\"code-pre  third-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Naviguez vers <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span></code> dans votre navigateur web pour vérifier que vous ne pouvez plus accéder au serveur d'application sur le port <code>80</code>.</p>\n\n<p>Enfin, naviguez jusqu'à <code>https://<span class=\"highlight\">your_domain_here</span>/polls</code> pour confirmer que le proxy Nginx a toujours accès aux serveurs Django en amont. Vous devriez voir l'interface de &lsquo;application de sondage.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans ce tutoriel, vous avez mis en place une application de sondage Django évolutive à l'aide de conteneurs Docker. Au fur et à mesure que votre trafic et la charge sur le système grandissent, vous pouvez faire évoluer chaque couche séparément : la couche proxy Nginx, la couche d'application backend Django et la couche de base de données PostgreSQL.</p>\n\n<p>Lorsque vous construisez un système distribué, vous devez souvent faire face à de multiples décisions de conception, et plusieurs architectures peuvent satisfaire votre cas d'utilisation. L'architecture décrite dans ce tutoriel est conçue comme un modèle flexible pour la conception d'applications évolutives avec Django et Docker.</p>\n\n<p>Vous pouvez vouloir contrôler le comportement de vos conteneurs lorsqu'ils rencontrent des erreurs, ou exécuter automatiquement les conteneurs lorsque votre système démarre. Pour ce faire, vous pouvez utiliser un gestionnaire de processus comme <a href=\"https://en.wikipedia.org/wiki/Systemd\">Systemd</a> ou mettre en œuvre des politiques de redémarrage. Pour plus d'informations à ce propos, consultez la section <a href=\"https://docs.docker.com/config/containers/start-containers-automatically/\">Démarrer les conteneurs automatiquement</a> dans la documentation Docker.</p>\n\n<p>Lorsque vous travaillez à l'échelle avec plusieurs hôtes exécutant la même image Docker, il peut être plus efficace d'automatiser les étapes à l'aide d'un outil de gestion de configuration comme <a href=\"https://www.ansible.com/\">Ansible</a> ou <a href=\"https://www.chef.io/\">Chef</a>. Pour en savoir plus sur la gestion de la configuration, consultez <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-configuration-management\">Une Introduction à la gestion de la configuration</a> et <a href=\"https://www.digitalocean.com/community/meetup_kits/automating-server-setup-with-ansible-a-digitalocean-workshop-kit\">Configuration de serveur automatisée avec Ansible : un kit d'atelier DigitalOcean</a>.</p>\n\n<p>Au lieu de construire la même image sur chaque hôte, vous pouvez également rationaliser le déploiement à l'aide d'un registre d'images comme <a href=\"https://hub.docker.com/\">Docker Hub</a>, qui construit, stocke et distribue des images Docker à plusieurs serveurs de manière centralisée. En plus d'un registre d'images, un pipeline d'intégration et de déploiement continu peut vous aider à construire, tester et déployer des images sur vos serveurs d'application. Pour plus d'informations sur les CI/CD, veuillez consulter <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-ci-cd-best-practices\">Une Introduction aux meilleures pratiques de CI/CD</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:48 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/scalable_django/polls_app.png","linkMd5":"3907b9e1835be8bac72033ab91b97c78","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","destWidth":474,"destHeight":473,"sourceBytes":43341,"destBytes":1896,"author":"Hanif Jetha","articleImgCdnMap":{"https://assets.digitalocean.com/articles/scalable_django/polls_app.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/31/07-48-31-305_44661f4fc2769a02.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn38@2020_6/2020/08/31/07-48-31-498_6d93c2bd68b66072.webp"},"publishedOrCreatedDate":1598860106976},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo centralizar los registros con Journald en Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-journald-on-ubuntu-20-04-es","description":"<p><em>El autor seleccionó la <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> para recibir una donación como parte del programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introducción\">Introducción</h3>\n\n<p>Los registros de sistemas son un componente extremadamente importante para administrar sistemas Linux. Proporcionan una visión valiosa sobre cómo funcionan los sistemas y cómo se utilizan porque, además de errores, registran información operativa como eventos de seguridad. La configuración estándar para sistemas Linux es almacenar sus registros localmente en el mismo sistema donde se produjeron. Esto funciona para sistemas independientes, pero rápidamente se convierte en un problema, ya que aumenta el número de sistemas. La solución para administrar todos estos registros es crear un servidor de registro centralizado donde cada host Linux envía sus registros en tiempo real a un servidor de administración de registros específico.</p>\n\n<p>Una solución de registro centralizada ofrece varias ventajas en comparación con el almacenamiento de registros en cada host:</p>\n\n<ul>\n<li>Reduce la cantidad de espacio de disco necesaria en cada host para almacenar archivos de registro.</li>\n<li>Los registros pueden mantenerse más tiempo, ya que el servidor de registro específico puede configurarse con más capacidad de almacenamiento.</li>\n<li>Pueden realizarse análisis de registro avanzados que requieren registros de varios sistemas y también más recursos informáticos de los que puede estar disponible en los hosts.</li>\n<li>Los administradores de sistemas pueden acceder a los registros para todos sus sistemas a los que, quizá, no puedan acceder directamente por razones de seguridad.</li>\n</ul>\n\n<p>En esta guía, configurará un componente de la serie de herramientas <a href=\"https://systemd.io/\">systemd</a> para transmitir mensajes de registro desde los sistemas de cliente a un servidor de recopilación de registros centralizado. Configurará el servidor y el cliente para que utilicen certificados TLS para cifrar los mensajes de registro, ya que se transmiten a través de redes inseguras como Internet y también para autenticarse.</p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Para completar esta guía, necesitará lo siguiente:</p>\n\n<ul>\n<li>Dos servidores Ubuntu 20.04.</li>\n<li>Un usuario no root con privilegios sudo en ambos servidores. Siga la guía de <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">configuración inicial de servidor con Ubuntu 20.04</a> para obtener instrucciones sobre cómo hacerlo. También debería configurar el firewall UFW en ambos servidores como se explica en la guía.</li>\n<li>Dos nombres de host que apuntan a sus servidores. Un nombre de host para el sistema <strong>cliente</strong> que genera los registros y otro para el <strong>servidor</strong> de compilación de registros. Descubra cómo apuntar nombres de host a DigitalOcean Droplets consultando la documentación sobre <a href=\"https://www.digitalocean.com/docs/networking/dns/\">dominios y DNS</a>.</li>\n</ul>\n\n<p>Esta guía utilizará los dos nombres de host siguientes:</p>\n\n<ul>\n<li><code><span class=\"highlight\">client.your_domain</span></code>: el sistema de cliente que genera los registros.</li>\n<li><code><span class=\"highlight\">server.your_domain</span></code>: el servidor de compilación de registro.</li>\n</ul>\n\n<p>Inicie sesión en el cliente y en el servidor en terminales independientes a través de SSH como en el usuario sudo no root para empezar este tutorial.</p>\n\n<p><span class='note'><strong>Nota</strong>: A lo largo del tutorial, se etiquetan los bloques de comandos con el nombre de servidor (<strong>cliente</strong> o <strong>servidor</strong>) en el que debería ejecutarse el comando.<br></span></p>\n\n<h2 id=\"paso-1-instalar-systemd-journal-remote\">Paso 1: Instalar <code>systemd-journal-remote</code></h2>\n\n<p>En este paso, instalará el paquete <code>systemd-journal-remote</code> en el <strong>cliente</strong> y en el <strong>servidor</strong>. Este paquete contiene los componentes que utilizan el <strong>cliente</strong> y el <strong>servidor</strong> para transmitir los mensajes de registro.</p>\n\n<p>Primero, en el <strong>cliente</strong> y en el <strong>servidor</strong>, ejecute una actualización de sistema para garantizar que la base de datos de paquetes y el sistema estén actualizados:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li><li class=\"line\" data-prefix=\"$\">sudo apt upgrade\n</li></ul></code></pre>\n<p>A continuación, instale el paquete <code>systemd-journal-remote</code>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install systemd-journal-remote\n</li></ul></code></pre>\n<p>En el <strong>servidor</strong>, habilite e inicie los dos componentes <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\"><code>systemd</code></a> que necesita para recibir mensajes de registro con el siguiente comando:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable --now systemd-journal-remote.socket\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-remote.service\n</li></ul></code></pre>\n<p>La opción <code>--now</code> en el primer comando inicia los servicios de inmediato. No lo utilizó en el segundo comando, ya que este servicio no se iniciará hasta que tenga certificados TLS, lo que creará en el siguiente paso.</p>\n\n<p>En el <strong>cliente</strong>, habilite el componente que <code>systemd</code> utiliza para enviar los mensajes de registro al servidor:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-upload.service\n</li></ul></code></pre>\n<p>A continuación, en el servidor, abra los puertos <code>19532</code> y <code>80</code> en el firewall UFW. Esto permitirá al servidor recibir los mensajes de registro del cliente. El puerto <code>80</code> es el puerto que <code>certbot</code> utilizará para generar el certificado TLS. Los siguientes comandos abrirán estos puertos:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 19532/tcp\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>En el cliente, solo deberá abrir el puerto <code>80</code> con este comando:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Ahora ha instalado los componentes necesarios y ha completado la configuración del sistema base en el cliente y en el servidor. Antes de que pueda configurar estos componentes para que empiecen a retransmitir los mensajes de registro, registrará los certificados TLS <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> para el <strong>cliente</strong> y el <strong>servidor</strong> usando la utilidad <a href=\"https://certbot.eff.org/\"><code>certbot</code></a>.</p>\n\n<h2 id=\"paso-2-instalar-certificados-de-registro-y-certbot\">Paso 2: Instalar certificados de registro y Certbot</h2>\n\n<p>Let&rsquo;s Encrypt es una <a href=\"https://en.wikipedia.org/wiki/Certificate_authority\">autoridad de certificación</a> que emite certificados TLS gratuitos. Estos certificados permiten a los ordenadores cifrar los datos que envían entre ellos y también verificar la identidad de cada uno. Estos certificados le permiten proteger su navegación en Internet con HTTPS. Cualquier otra aplicación que quiera el mismo nivel de seguridad, puede usar los mismos certificados. El proceso de registro del certificado es el mismo sin importar para lo que los use.</p>\n\n<p>En este paso, instalará la utilidad <code>certbot</code> y la usará para registrar los certificados. También automáticamente se ocupará de renovar los certificados cuando expiren. El proceso de registro aquí es el mismo en el <strong>cliente</strong> y en el <strong>servidor</strong>. Solo deberá cambiar el nombre de host para que coincida con el host donde está ejecutando el comando de registro.</p>\n\n<p>Primero, habilite el repositorio <code>universe</code> de Ubuntu, ya que la utilidad <code>certbot</code> reside en el repositorio <code>universe</code>. Si ya tiene el repositorio <code>universe</code> habilitado, la ejecución de estos comandos es segura y no le hará a su sistema:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install software-properties-common\n</li><li class=\"line\" data-prefix=\"$\">sudo add-apt-repository universe\n</li><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>A continuación, instale <code>certbot</code> en ambos hosts:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install certbot\n</li></ul></code></pre>\n<p>Ahora que ha instalado <code>certbot</code>, ejecute el siguiente comando para registrar los certificados en el <strong>cliente</strong> y en el <strong>servidor</strong>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot certonly --standalone --agree-tos --email <span class=\"highlight\">sammy@your_domain</span> -d <span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Las opciones de este comando significan lo siguiente:</p>\n\n<ul>\n<li><code>certonly</code>: registra el certificado y no realiza otros cambios en el sistema.</li>\n<li><code>--standalone</code>: utiliza el servidor web integrado de certbot para verificar la solicitud de certificado.</li>\n<li><code>--agree-tos</code>: acepta de forma automática los Términos de uso de Let&rsquo;s Encrypt.</li>\n<li><code>--email <span class=\"highlight\">your-email</span></code>: esta es la dirección de correo electrónico que Let&rsquo;s Encrypt usará para notificarle sobre la expiración del certificado y otra información importante.</li>\n<li><code>-d <span class=\"highlight\">your_domain</span></code>: el nombre de host para el que se registrará el certificado. Debe coincidir con el sistema donde lo ejecuta.</li>\n</ul>\n\n<p>Cuando ejecute este comando, se le solicitará si quiere compartir la dirección de correo electrónico con Let&rsquo;s Encrypt para que puedan enviarle por correo electrónico noticias y otra información sobre su trabajo. Hacerlo es opcional, si no comparte su dirección de correo electrónico, el registro de certificados se completará de forma normal.</p>\n\n<p>Cuando se complete el proceso de registro de certificado, colocará el certificado y los archivos de clave en <code>/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/</code> donde <code>your_domain</code> es el nombre de host para el que registró el certificado.</p>\n\n<p>Por último, deberá descargar una copia de los certificados intermedios y de la autoridad de certificación Let&rsquo;s Encrypt y ponerlos en el mismo archivo. <code>journald</code> usará este archivo para verificar la autenticidad de los certificados en el <strong>cliente</strong> y en el <strong>servidor</strong> cuando se comuniquen entre ellos.</p>\n\n<p>El siguiente comando descargará los dos certificados desde el sitio web Let&rsquo;s Encrypt y los pondrá en un solo archivo llamado <code>letsencrypt-combined-certs.pem</code> en el directorio de inicio de su usuario.</p>\n\n<p>Ejecute este comando en el <strong>cliente</strong> y en el <strong>servidor</strong> para descargar los certificados y crear un archivo combinado:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -s https://letsencrypt.org/certs/{isrgrootx1.pem.txt,letsencryptauthorityx3.pem.txt} &gt; ~/letsencrypt-combined-certs.pem\n</li></ul></code></pre>\n<p>A continuación, mueva este archivo al directorio Let&rsquo;s Encrypt que contiene los certificados y las claves:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp ~/letsencrypt-combined-certs.pem /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/\n</li></ul></code></pre>\n<p>Ahora ha registrado los certificados y las claves. En el siguiente paso, configurará el <strong>servidor</strong> de compilación de registro para que empiece a escuchar y almacenar los mensajes de registro del <strong>cliente</strong>.</p>\n\n<h2 id=\"paso-3-configuración-del-servidor\">Paso 3: Configuración del servidor</h2>\n\n<p>En este paso, configurará el <strong>servidor</strong> para que utilice el certificado y los archivos de clave que generó en el último paso, de forma que pueda comenzar a aceptar los mensajes de registro del <strong>cliente</strong>.</p>\n\n<p><code>systemd-journal-remote</code> es el componente que escucha los mensajes de registro. Abra su archivo de configuración en <code>/etc/systemd/journal-remote.conf</code> con un editor de texto para empezar a configurarlo en el <strong>servidor</strong>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-remote.conf\n</li></ul></code></pre>\n<p>A continuación, elimine todas las líneas de la sección <code>[remoto]</code> y establezca las rutas para que apunten a los archivos TLS que acaba de crear:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-remote.conf\">/etc/systemd/journal-remote.conf</div><pre class=\"code-pre \"><code>[Remote]\nSeal=false\nSplitMode=host\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Aquí están las opciones que ha utilizado:</p>\n\n<ul>\n<li><code>Seal=false</code>: firma los datos de registro en el diario. Habilítelo si necesita una máxima seguridad; de lo contrario, puede dejarlo como <code>false</code>.</li>\n<li><code>SplitMode=host</code>: los registros de los clientes remotos se dividen host en <code>/var/log/journal/remote</code>. Si prefiere que se añadan todos los registros a un solo archivo configúrelo a <code>SplitMode=false</code>.</li>\n<li><code>ServerKeyFile</code>: el archivo de clave privada del servidor.</li>\n<li><code>ServerCertificateFile</code>: el archivo de certificado del servidor.</li>\n<li><code>TrustedCertificateFile</code>: el archivo que contiene los certificados de la autoridad de certificación Let&rsquo;s Encrypt.</li>\n</ul>\n\n<p>Ahora, deberá cambiar los permisos en los directorios Let&rsquo;s Encrypt que contienen los certificados y la clave para que <code>systemd-journal-remote</code> los pueda leer y usar.</p>\n\n<p>Primero, cambie los <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-permissions\">permisos</a> para que el certificado y la clave privada se puedan leer:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>A continuación, cambie la propiedad de grupo de la clave privada al grupo <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-remote /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Ahora puede iniciar <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start systemd-journal-remote.service\n</li></ul></code></pre>\n<p>Ahora se está ejecutando su <strong>servidor</strong> de compilación de registro y está listo para comenzar a aceptar mensajes de registro de un <strong>cliente</strong>. En el siguiente paso, configurará el <strong>cliente</strong> para que envíe los registros a su <strong>servidor</strong> de compilación.</p>\n\n<h2 id=\"paso-4-configurar-el-cliente\">Paso 4: Configurar el cliente</h2>\n\n<p>En este paso, configurará el componente que transmite los mensajes de registro al servidor de compilación de registro. Este componente se llama <code>systemd-journal-upload</code>.</p>\n\n<p>La configuración predeterminada para <code>systemd-journal-upload</code> es la que utiliza un usuario temporal que solo existe mientras se está ejecutando. Esto permite que <code>systemd-journal-upload</code> lea los certificados TLS y las claves más complicadas. Para resolverlo, creará un nuevo usuario de sistema con el mismo nombre que el usuario temporal que se utilizará en su lugar.</p>\n\n<p>Primero, cree el nuevo usuario llamado <code>systemd-journal-upload</code> en el <strong>cliente</strong> con el siguiente comando <code>adduser</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo adduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload\n</li></ul></code></pre>\n<p>Estas opciones al comando son:</p>\n\n<ul>\n<li><code>--system</code>: crea el nuevo usuario como un usuario de sistema. Le da al usuario un número UID (Identificador de usuario) inferior a <code>1000</code>. Normalmente, los UID superiores a <code>1000</code> se dan a las cuentas de usuario con las que un humano iniciará sesión.</li>\n<li><code>--home /run/systemd</code>: establece <code>/run/systemd</code> como el directorio de inicio de este usuario.</li>\n<li><code>--no-create-home</code>: no crea el conjunto de directorio de inicio, puesto que ya existe.</li>\n<li><code>--disabled-login</code>: el usuario no puede iniciar sesión en el servidor a través de SSH, por ejemplo.</li>\n<li><code>--group</code>: crea un grupo con el mismo nombre que el usuario.</li>\n</ul>\n\n<p>A continuación, establezca los permisos y la propiedad de los archivos del certificado Let&rsquo;s Encrypt:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-upload /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Ahora, edite la configuración para <code>systemd-journal-upload</code>, que está en <code>/etc/systemd/journal-upload.conf</code>. Abra este archivo con un editor de texto:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-upload.conf\n</li></ul></code></pre>\n<p>Edite este archivo de forma que se parezca a lo siguiente:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-upload.conf\">/etc/systemd/journal-upload.conf</div><pre class=\"code-pre \"><code>[Upload]\nURL=https://<span class=\"highlight\">server.your_domain</span>:19532\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Por último, reinicie el servicio <code>systemd-journal-upload</code> para que utilice la nueva configuración:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Ahora su <strong>cliente</strong> está configurado y ejecutándose, y envía sus mensajes de registro al servidor de compilación de registro. En el siguiente paso, comprobará que se están enviando los registros de forma correcta.</p>\n\n<h2 id=\"paso-5-probar-el-cliente-y-el-servidor\">Paso 5: Probar el cliente y el servidor</h2>\n\n<p>En este paso, probará que el <strong>cliente</strong> está enviando mensajes de registro al <strong>servidor</strong> y que el <strong>servidor</strong> los almacena correctamente.</p>\n\n<p>El servidor de compilación de registro almacena los registros de los clientes en un directorio en <code>/var/log/journal/remote/</code>. Cuando reinició el <strong>cliente</strong> al final del último paso, comenzó a enviar mensajes de registro, de forma que ahora hay un archivo de registro en <code>/var/log/journal/remote/</code>. El archivo será llamará como el nombre de host que utilizó para el certificado TLS.</p>\n\n<p>Utilice el comando <code>ls</code> para comprobar que el archivo de registro del <strong>cliente</strong> está presente en el <strong>servidor</strong>:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ls -la /var/log/journal/remote/\n</li></ul></code></pre>\n<p>Esto imprimirá el contenido del directorio que muestra el archivo de registro:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>total 16620\ndrwxr-xr-x  2 systemd-journal-remote systemd-journal-remote     4096 Jun 30 16:17  .\ndrwxr-sr-x+ 4 root                   systemd-journal            4096 Jun 30 15:55  ..\n-rw-r-----  1 systemd-journal-remote systemd-journal-remote 8388608 Jul  1 10:46 '<span class=\"highlight\">remote-CN=client.your_domain</span>'\n</code></pre>\n<p>A continuación, escriba un mensaje de registro en el <strong>cliente</strong> para comprobar que el <strong>servidor</strong> está recibiendo los mensajes del <strong>cliente</strong> como se espera. Usará la utilidad <a href=\"https://man7.org/linux/man-pages/man1/logger.1.html\">logger</a> para crear un mensaje de registro personalizado en el <strong>cliente</strong>. Si todo está funcionando, <code>systemd-journal-upload</code> transmitirá este mensaje al <strong>servidor</strong>.</p>\n\n<p>En el <strong>cliente</strong> ejecute el siguiente comando <code>logger</code>:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo logger -p syslog.debug \"### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\"\n</li></ul></code></pre>\n<p>El <code>-p syslog.debug</code> en este comando establece <a href=\"https://en.wikipedia.org/wiki/Syslog#Message_components\">la instalación y la gravedad</a> del mensaje. Configurar esto a <code>syslog.debug</code> aclarará que es un mensaje de prueba. Este comando grabará el mensaje <code>### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###</code> al diario del cliente, que <code>systemd-journal-upload</code> transmitirá al <strong>servidor</strong>.</p>\n\n<p>A continuación, lea el archivo de diario del <strong>cliente</strong> en el <strong>servidor</strong> para comprobar que los mensajes de registro están llegando desde el <strong>cliente</strong>. Este archivo es un archivo de registro binario, de forma que no podrá leerlo con herramientas como <code>less</code>. En su lugar, lea el archivo usando <code>journalctl</code> con la opción <code>--file=</code> que le permite especificar un archivo de diario personalizado:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo journalctl --file=/var/log/journal/remote/remote-CN=<span class=\"highlight\">client.your_domain.journal</span>\n</li></ul></code></pre>\n<p>El mensaje de registro aparecerá como se muestra:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Test log message\">Test log message</div>. . .\nJun 29 13:10:09 client root[3576]: ### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\n</code></pre>\n<p>Ahora su servidor de centralización de registro está recopilando correctamente los registros de su sistema de cliente.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>En este artículo, configuró un servidor de compilación central de registro y configuró un cliente para que transmitiera una copia de sus registros de sistema al servidor. Puede configurar tantos clientes como necesite para transmitir los mensajes al servidor de compilación de registro usando los pasos de configuración del cliente que utilizó aquí.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:49 +0000","feedId":8037,"bgimg":"","linkMd5":"95884002f9335e3c715041efab272f0e","bgimgJsdelivr":"","metaImg":"","author":"Elliot Cooper","publishedOrCreatedDate":1598860106983},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment configurer l'accès à distance pour MongoDB sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-configure-remote-access-for-mongodb-on-ubuntu-20-04-fr","description":"<p><em>Une version antérieure de ce tutoriel a été écrite par <a href=\"https://www.digitalocean.com/community/users/melissaanderson\">Brennan Bearnes</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://www.mongodb.com/\">MongoDB</a>, également connu sous le nom de <em>Mongo</em>, est une base de données de documents open-source utilisée couramment dans des applications web modernes. Par défaut, il n'autorise que les connexions provenant du même serveur que celui où il est installée. Si vous souhaitez gérer MongoDB à distance ou le connecter à un serveur d'application distinct, vous devrez apporter quelques changements à la configuration par défaut.</p>\n\n<p>Dans ce tutoriel, vous allez configurer une installation MongoDB pour permettre un accès sécurisé à partir d'un ordinateur distant de confiance. Pour ce faire, vous allez mettre à jour vos règles de pare-feu pour permettre à la machine distante d'accéder au port sur lequel MongoDB écoute des connexions, puis vous mettrez à jour son fichier de configuration pour modifier son paramètre de liaison IP. Ensuite, comme dernière étape, vous testerez si votre machine distante est capable de se connecter avec succès à votre base de données.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour suivre ce tutoriel, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li>Un serveur fonctionnant sous Ubuntu 20.04 Ce serveur doit avoir un non-root user administratif et un pare-feu configuré avec UFW. Pour cela, suivez notre <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">guide de configuration initiale du serveur pour Ubuntu 20.04</a>.</li>\n<li>MongoDB installé sur votre serveur. Ce tutoriel suppose que vous avez installé MongoDB <span class=\"highlight\">4.4</span> ou une version plus récente. Vous pouvez installer cette version en suivant notre tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-mongodb-on-ubuntu-20-04\">Comment installer MongoDB sur Ubuntu 20.04</a>.</li>\n<li>Un deuxième ordinateur à partir duquel vous allez accéder à votre instance MongoDB. Pour plus de simplicité, ce tutoriel suppose que cette machine est un autre serveur Ubuntu 20.04, avec un utilisateur administratif non root et un pare-feu UFW configuré en suivant notre <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">guide de configuration initiale du serveur pour Ubuntu 20.04</a>. Cependant, les étapes 1 et 2, qui décrivent la procédure réelle d'activation de la connectivité à distance sur le serveur de base de données, fonctionneront quel que soit le système d'exploitation de la machine distante.</li>\n</ul>\n\n<p>Enfin, bien que ce ne soit pas nécessaire pour terminer ce tutoriel, nous vous recommandons <strong>fortement</strong> de sécuriser votre installation MongoDB en créant un compte utilisateur administratif pour la base de données et en activant l'authentification. Pour ce faire, suivez notre tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-mongodb-on-ubuntu-20-04\">Comment sécuriser MongoDB sur Ubuntu 20.04</a>.</p>\n\n<h2 id=\"Étape-2-—-ajustement-du-pare-feu\">Étape 2 — Ajustement du pare-feu</h2>\n\n<p>En supposant que vous ayez suivi le tutoriel de configuration initiale du serveur et <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04#step-4-%E2%80%94-setting-up-a-basic-firewall\">activé un pare-feu UFW sur votre serveur</a>, votre installation MongoDB sera inaccessible depuis Internet. Si vous avez l'intention d'utiliser MongoDB uniquement en local avec des applications fonctionnant sur le même serveur, il s'agit de la configuration recommandée et sécurisée. Cependant, si vous souhaitez pouvoir vous connecter à votre serveur MongoDB à distance, vous devez autoriser les connexions entrantes sur le port où la base de données est à l'écoute en ajoutant une nouvelle règle UFW.</p>\n\n<p>Commencez par vérifier quel port votre installation MongoDB écoute avec la commande <code>lsof</code>. Cette commande renvoie généralement une liste contenant tous les fichiers ouverts d'un système, mais lorsqu'elle est combinée à l'option <code>-i</code>, elle ne répertorie que les fichiers ou les flux de données liés au réseau.</p>\n\n<p>La commande suivante redirigera la sortie produite par <code>lsof -i</code> vers une commande <code>grep</code> qui recherche une chaîne nommée <code>mongo</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo lsof -i | grep mongo\n</li></ul></code></pre>\n<p>Cet exemple de sortie montre que MongoDB écoute les connexions sur son port par défaut, <code>27017</code> :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>mongod    82221         mongodb   11u  IPv4 913411      0t0  TCP localhost:<span class=\"highlight\">27017</span> (LISTEN)\n</code></pre>\n<p>Dans la plupart des cas, MongoDB ne doit être accessible qu'à partir de certains lieux de confiance (un autre serveur hébergeant une application, par exemple). Une façon de configurer cette méthode consiste à exécuter la commande suivante sur votre serveur MongoDB, qui ouvre un accès sur le port par défaut de MongoDB tout en n'autorisant explicitement que l'adresse IP de l'autre serveur de confiance.</p>\n\n<p>Exécutez la commande suivante, en vous assurant de remplacer <code><span class=\"highlight\">trusted_server_ip</span></code> par l'adresse IP de la machine distante de confiance que vous utiliserez pour accéder à votre instance MongoDB :</p>\n\n<p><span class='note'><strong>Remarque</strong> : si la sortie de la commande précédente a indiqué que votre installation de MongoDB écoute sur un port non par défaut, utilisez ce numéro de port à la place de <code>27017</code> dans cette commande.<br></span></p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow from <span class=\"highlight\">trusted_server_ip</span> to any port <span class=\"highlight\">27017</span>  \n</li></ul></code></pre>\n<p>À l'avenir, si jamais vous souhaitez accéder à MongoDB à partir d'une autre machine, exécutez à nouveau cette commande avec l'adresse IP de la nouvelle machine à la place de <code><span class=\"highlight\">trusted_server_ip</span></code>.</p>\n\n<p>Vous pouvez vérifier le changement dans les paramètres de pare-feu avec <code>ufw</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>La sortie montrera que le trafic vers le port <code>27017</code> du serveur distant est maintenant autorisé :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Status: active\n\nTo                         Action      From\n--                         ------      ----\nOpenSSH                    ALLOW       Anywhere\n27017                      ALLOW       <span class=\"highlight\">trusted_server_ip</span>\nOpenSSH (v6)               ALLOW       Anywhere (v6)\n</code></pre>\n<p>Vous pouvez trouver des paramètres de pare-feu plus avancés pour restreindre l'accès aux services dans <a href=\"https://www.digitalocean.com/community/tutorials/ufw-essentials-common-firewall-rules-and-commands\">les Essentiels d'UFW : Règles et commandes communes du pare-feu</a>.</p>\n\n<p>Ensuite, vous allez lier MongoDB à l'adresse IP publique du serveur afin de pouvoir y accéder à partir de votre machine distante.</p>\n\n<h2 id=\"Étape-2-—-configurer-une-bindip-publique\">Étape 2 — Configurer une bindIP publique</h2>\n\n<p>À ce stade, même si le port est ouvert, MongoDB est actuellement lié à <code>127.0.0.1</code>, l'interface du réseau de rebouclage local. Cela signifie que MongoDB n'est en mesure d'accepter que les connexions originaires du serveur où il est installé.</p>\n\n<p>Pour permettre des connexions distantes, vous devez modifier le fichier de configuration de MongoDB — <code>/etc/mongod.conf</code> — pour lier également MongoDB à l'adresse IP routable publique de votre serveur. De cette façon, votre installation MongoDB sera en mesure d'écouter les connexions faites à votre serveur MongoDB à partir de machines distantes.</p>\n\n<p>Ouvrez le fichier de configuration de MongoDB dans votre éditeur de texte préféré. L'exemple suivant utilise <code>nano</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mongod.conf\n</li></ul></code></pre>\n<p>Trouvez la section <code>network interfaces</code>, puis la valeur <code>bindIp</code> :</p>\n<div class=\"code-label \" title=\"/etc/mongod.conf\">/etc/mongod.conf</div><pre class=\"code-pre \"><code>. . .\n# network interfaces\nnet:\n  port: 27017\n  bindIp: 127.0.0.1\n\n. . .\n</code></pre>\n<p>Ajoutez une virgule à cette ligne suivie de l'adresse IP publique de votre serveur MongoDB :</p>\n<div class=\"code-label \" title=\"/etc/mongod.conf\">/etc/mongod.conf</div><pre class=\"code-pre \"><code>. . .\n# network interfaces\nnet:\n  port: 27017\n  bindIp: 127.0.0.1<span class=\"highlight\">,mongodb_server_ip</span>\n\n. . .\n</code></pre>\n<p>Enregistrez et fermez le fichier. Si vous avez utilisé <code>nano</code>, faites-le en appuyant sur <code>CTRL+X</code>, <code>Y</code>, puis <code>ENTER</code>.</p>\n\n<p>Ensuite, redémarrez MongoDB pour mettre ce changement en vigueur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mongod\n</li></ul></code></pre>\n<p>Suite à cela, votre installation MongoDB sera en mesure d'accepter des connexions à distance à partir de toutes les machines que vous avez autorisées à accéder au port <code>27017</code>. En dernière étape, vous pouvez vérifier si le serveur distant de confiance que vous avez autorisé à travers le pare-feu à l'Étape 1 peut atteindre l'instance de MongoDB exécutée sur votre serveur.</p>\n\n<h2 id=\"Étape-3-—-test-de-la-connectivité-à-distance\">Étape 3 — Test de la connectivité à distance</h2>\n\n<p>Maintenant que vous avez configuré votre installation MongoDB pour écouter des connexions qui proviennent de son adresse IP publique routable et que vous avez accordé à votre machine distante l'accès au port par défaut de Mongo via le pare-feu de votre serveur, vous pouvez tester si la machine distante est capable de se connecter.</p>\n\n<p><span class='note'><strong>Remarque</strong> : comme mentionné dans la section Conditions préalables, ce tutoriel suppose que votre machine distante est un autre serveur fonctionnant sous Ubuntu 20.04. La procédure d'activation des connexions à distance décrite aux Étapes 1 et 2 devrait fonctionner indépendamment du système d'exploitation de votre machine distante, mais les méthodes de test décrites dans cette étape ne fonctionnent pas de manière universelle pour tous les systèmes d'exploitation.<br></span></p>\n\n<p>Une façon de tester si votre serveur distant de confiance est capable de se connecter à l'instance MongoDB, consiste à utiliser la commande <code>nc</code>. <code>nc</code>, abréviation de <em>netcat</em>, est un utilitaire utilisé pour établir des connexions réseau avec TCP ou UDP. Il est utile pour effectuer des tests dans des cas comme celui-ci car il vous permet de spécifier à la fois une adresse IP et un numéro de port.</p>\n\n<p>Tout d'abord, connectez-vous à votre serveur de confiance en utilisant SSH :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">sammy</span>@<span class=\"highlight\">trusted_server_ip</span>\n</li></ul></code></pre>\n<p>Ensuite, exécutez la commande <code>nc</code> suivante, qui inclut l'option <code>-z</code>. Cela limite <code>nc</code> à ne chercher qu'un démon d'écoute sur le serveur cible sans lui envoyer de données. Rappelez-vous du <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-mongodb-on-ubuntu-20-04\">tutoriel d'installation préalable</a> qui explique que MongoDB fonctionne en tant que démon service, ce qui rend cette option utile pour tester la connectivité. Elle inclut également l'option <code>v</code> qui augmente la verbosité de la commande, ce qui fait que netcat renvoie des données qu'il ne renverrait pas autrement.</p>\n\n<p>Exécutez la commande <code>nc</code> suivante <strong>à partir de votre serveur distant de confiance</strong>, en vous assurant de remplacer <code><span class=\"highlight\">mongodb_server_ip</span></code> par l'adresse IP du serveur sur lequel vous avez installé MongoDB :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nc -zv <span class=\"highlight\">mongodb_server_ip</span> 27017\n</li></ul></code></pre>\n<p>Si le serveur de confiance peut accéder au démon MongoDB, sa sortie indiquera que la connexion a réussi :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Connection to <span class=\"highlight\">mongodb_server_ip</span> 27017 port [tcp/*] succeeded!\n</code></pre>\n<p>En supposant que vous disposez d'une version compatible du shell <code>mongo</code> installé sur votre serveur distant, vous pouvez à ce stade vous connecter directement à l'instance de MongoDB installée sur le serveur hôte.</p>\n\n<p>Une façon de se connecter est d'utiliser une <a href=\"https://docs.mongodb.com/manual/reference/connection-string/\">chaîne de connexion URI</a>, comme celle-ci :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mongo \"mongodb://<span class=\"highlight\">mongo_server_ip</span>:27017\"\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Remarque</strong> : si vous avez suivi le tutoriel recommandé <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-mongodb-on-ubuntu-20-04\">Comment sécuriser MongoDB sur Ubuntu 20.04</a>, vous aurez fermé l'accès à votre base de données aux utilisateurs non authentifiés. Dans ce cas, vous devrez utiliser une URI spécifiant un nom d'utilisateur valide, comme celle-ci :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mongo \"mongodb://<span class=\"highlight\">username</span>@<span class=\"highlight\">mongo_server_ip</span>:27017\"\n</li></ul></code></pre>\n<p>Le shell vous invitera automatiquement à entrer le mot de passe de l'utilisateur.<br></p></span>\n\n<p>Avec cela, vous avez confirmé que votre serveur MongoDB pouvait accepter les connexions du serveur de confiance.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Vous pouvez maintenant accéder à votre installation MongoDB à partir d'un serveur distant. À ce stade, vous pouvez gérer à distance votre base de données Mongo du serveur de confiance. Vous pouvez également configurer une application pour qu'elle s'exécute sur le serveur de confiance et utiliser la base de données à distance.</p>\n\n<p>Si vous n'avez pas configuré d'utilisateur administratif et activé l'authentification, toute personne ayant accès à votre serveur distant peut également accéder à votre installation MongoDB. Si vous ne l'avez pas encore fait, nous vous recommandons fortement de suivre notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-mongodb-on-ubuntu-20-04\">Comment sécuriser MongoDB sur Ubuntu 20.04</a> pour ajouter un utilisateur administratif et verrouiller les choses plus avant.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:07 +0000","feedId":8037,"bgimg":"","linkMd5":"9f9e6d391660cb0004c7e976d5fca3eb","bgimgJsdelivr":"","metaImg":"","author":"Mark Drake","publishedOrCreatedDate":1598860106980},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Масштабирование и обеспечение безопасности приложения Django с помощью Docker, Nginx и Let's Encrypt","link":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-ru","description":"<h3 id=\"Введение\">Введение</h3>\n\n<p>В облачных средах существует множество способов масштабирования и защиты приложения <a href=\"https://www.djangoproject.com/\">Django</a>. Используя <em>горизонтальное масштабирование</em> и запустив несколько экземпляров приложения, вы можете создать более отказоустойчивую систему с высоким уровнем доступности, а также увеличить ее <em>пропускную способность</em> для одновременной обработки запросов. Одним из способов горизонтального масштабирования приложения Django является предоставление дополнительных <em>серверов приложения</em>, запускающих ваше приложение Django и его HTTP-сервер WSGI (например, <a href=\"https://gunicorn.org/\">Gunicorn</a> или <a href=\"https://uwsgi-docs.readthedocs.io/en/latest/\">uWSGI</a>). Чтобы направить и распределить входящие запросы через эту группу серверов приложения, вы можете использовать <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#load-balancing\">балансировщик нагрузки</a> и <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">обратный прокси-сервер</a>, например <a href=\"https://www.nginx.com/\">Nginx</a>. Nginx также может кэшировать статический контент и прерывать протокол безопасности <em>Transport Layer Security</em> (TLS), который используется для активации HTTPS и безопасных подключений к вашему приложению.</p>\n\n<p>Запуск приложения Django и прокси-сервера Nginx в <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#container\">контейнерах</a> Docker гарантирует одинаковое поведение этих компонентов, независимо от среды развертывания. Кроме того, контейнеры предоставляют много возможностей, облегчающих упаковку и настройку вашего приложения.</p>\n\n<p>В этом обучающем руководстве вы выполните горизонтальное масштабирование контейнеризированного приложения Django и Gunicorn <a href=\"https://docs.djangoproject.com/en/3.0/intro/tutorial01/\">«Опросы»</a>, активировав два сервера приложения, каждый из которых будет выполнять экземпляр контейнера приложения Django и Gunicorn.</p>\n\n<p>Также вы активируете HTTPS, предоставив и настроив третий прокси-сервер, который будет выполнять запуск контейнера обратного прокси-сервера Nginx и контейнера клиента <a href=\"https://certbot.eff.org/\">Certbot</a>. Certbot будет предоставлять сертификаты TLS для Nginx от имени органа сертификации <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>. Это позволит вашему сайту получить высокий рейтинг безопасности от <a href=\"https://www.ssllabs.com/\">SSL Labs</a>. Этот прокси-сервер будет получать все внешние запросы приложения и находиться перед двумя <em>исходящими</em> серверами приложения Django. И наконец, вы <em>усилите</em> данную распределенную систему, оставив внешний доступ только к прокси-серверу.</p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для данного обучающего модуля вам потребуется следующее:</p>\n\n<ul>\n<li><p>Три сервера Ubuntu 18.04:</p>\n\n<ul>\n<li>Два сервера будут выполнять функции серверов <strong>приложения</strong>, используемых для запуска приложения Django и Gunicorn.</li>\n<li>Один сервер будет выполнять роль <strong>прокси-сервера</strong>, используемого для запуска Nginx и Certbot.</li>\n<li>Все должны иметь пользователя non-root user с привилегиями <code>sudo</code> и активный брандмауэр. Дополнительную информацию о настройке этих параметров см. в <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">руководстве по первоначальной настройке сервера</a>.</li>\n</ul></li>\n<li><p>Установленный на всех трех серверах Docker. Инструкции по установке Docker см. в шагах 1 и 2 руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04\">Установка и использование Docker в Ubuntu 18.04</a>.</p></li>\n<li><p>Зарегистрированное доменное имя. В этом обучающем руководстве мы будем использовать <code><span class=\"highlight\">your_domain.com</span></code>. Вы можете получить бесплатный домен на <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> или зарегистрировать доменное имя по вашему выбору.</p></li>\n<li><p>Запись DNS <code>A</code>, где <code><span class=\"highlight\">your_domain.com</span></code>​​​ указывает на публичный IP-адрес вашего <strong>прокси-сервера</strong>. Вы можете воспользоваться <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">введением в работу с DigitalOcean DNS</a>, чтобы получить подробную информацию о добавлении доменов в учетную запись DigitalOcean, если вы используете этот способ.</p></li>\n<li><p>Хранилище объектов S3, например <a href=\"https://www.digitalocean.com/products/spaces/\">пространство DigitalOcean</a>, для хранения статических файлов проекта Django и набор ключей доступа к этому пространству. Чтобы узнать, как создать пространство, ознакомьтесь с документом <a href=\"https://www.digitalocean.com/docs/spaces/how-to/create/\">Как создавать пространства</a>. Чтобы узнать, как создать ключи доступа, ознакомьтесь со статьей <a href=\"https://www.digitalocean.com/docs/spaces/how-to/administrative-access/#access-keys\">Предоставление доступа к пространству с помощью ключей доступа</a>. Внеся незначительные изменения, вы можете использовать любой сервис хранения, который поддерживает плагин <a href=\"https://django-storages.readthedocs.io/en/latest/\">django-storages</a>.</p></li>\n<li><p>Экземпляр сервера PostgreSQL, база данных и пользователь для приложения Django. Внеся незначительные изменения, вы можете использовать любую базу данных, которую <a href=\"https://docs.djangoproject.com/en/2.2/ref/databases/\">поддерживает Django</a>.</p>\n\n<ul>\n<li>База данных PostgreSQL должна называться <strong>polls</strong> (можно использовать любое другое запоминающееся имя для ввода в ваши файлы конфигурации ниже). В качестве имени пользователя в данном руководстве будет использоваться <strong>sammy</strong>. Инструкции, как это сделать, см. в шаге 1 руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Создание приложения Django и Gunicorn с помощью Docker</a>. Вы можете выполнить эти шаги, используя любой из трех серверов.</li>\n<li>В этом обучающем модуле используется <a href=\"https://www.digitalocean.com/products/managed-databases/\">управляемый кластер PostgreSQL</a> от DigitalOcean. Чтобы узнать, как создать кластер, ознакомьтесь с <a href=\"https://www.digitalocean.com/docs/databases/how-to/clusters/create/\">документацией по управляемым базам данных</a> от DigitalOcean.</li>\n<li>Также вы можете установить и запустить свой собственный экземпляр PostgreSQL. Инструкции по установке и администрированию PostgreSQL на сервере Ubuntu см. в руководстве <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04\">Установка и использование PostgreSQL на Ubuntu 18.04</a>.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"Шаг-1-—-Настройка-первого-сервера-приложения-django\">Шаг 1 — Настройка первого сервера приложения Django</h2>\n\n<p>Для начала мы клонируем репозиторий приложения Django на первый сервер приложения. Затем настроим и создадим образ приложения Docker, после чего протестируем приложение, запустив контейнер Django.</p>\n\n<p><span class='note'><strong>Примечание.</strong> Если вы уже выполнили инструкции руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Создание приложения Django и Gunicorn с помощью Docker</a>, то вы уже выполнили шаг 1 и можете переходить к <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-2-%E2%80%94-configuring-the-second-django-application-server\">шагу 2</a>, чтобы настроить <strong>второй</strong> сервер приложения.<br></span></p>\n\n<p>Начните с входа в первый из двух серверов приложения Django и используйте <code>git</code> для клонирования ветки <code>polls-docker</code> <a href=\"https://github.com/do-community/django-polls\">репозитория GitHub</a> для приложения опросов Django Tutorial Polls App. В этом репозитории содержится код документации Django для <a href=\"https://docs.djangoproject.com/en/3.0/intro/\">образца приложения «Опросы»</a>. Ветка <code>polls-docker</code> содержит контейнеризированную версию приложения «Опросы». Чтобы узнать об изменениях, внесенных в приложение «Опросы» для эффективной работы в контейнеризированной среде, см. руководство <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker\">Создание приложения Django и Gunicorn с помощью Docker</a>.</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Перейдите в каталог <code>django-polls</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cd django-polls\n</code></pre>\n<p>В этом каталоге содержится код Python приложения Django, <code>Dockerfile</code>, который Docker будет использовать для построения образа контейнера, а также файл <code>env</code>, содержащий список переменных среды для прохождения в рабочую среду контейнера. Проверьте файл <code>Dockerfile</code> с помощью <code>cat</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cat Dockerfile\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>FROM python:3.7.4-alpine3.10\n\nADD django-polls/requirements.txt /app/requirements.txt\n\nRUN set -ex \\\n    &amp;&amp; apk add --no-cache --virtual .build-deps postgresql-dev build-base \\\n    &amp;&amp; python -m venv /env \\\n    &amp;&amp; /env/bin/pip install --upgrade pip \\\n    &amp;&amp; /env/bin/pip install --no-cache-dir -r /app/requirements.txt \\\n    &amp;&amp; runDeps=\"$(scanelf --needed --nobanner --recursive /env \\\n        | awk '{ gsub(/,/, \"\\nso:\", $2); print \"so:\" $2 }' \\\n        | sort -u \\\n        | xargs -r apk info --installed \\\n        | sort -u)\" \\\n    &amp;&amp; apk add --virtual rundeps $runDeps \\\n    &amp;&amp; apk del .build-deps\n\nADD django-polls /app\nWORKDIR /app\n\nENV VIRTUAL_ENV /env\nENV PATH /env/bin:$PATH\n\nEXPOSE 8000\n\nCMD [\"gunicorn\", \"--bind\", \":8000\", \"--workers\", \"3\", \"mysite.wsgi\"]\n</code></pre>\n<p>Dockerfile использует официальный <a href=\"https://hub.docker.com/_/python\">образ Docker</a> Python 3.7.4 в качестве базы и устанавливает пакетные требования Python для Django и Gunicorn в соответствии с файлом <code>django-polls/requirements.txt</code>. Затем он удаляет некоторые ненужные файлы сборки, копирует код приложения в образ и устанавливает параметр выполнения <code>PATH</code>. И в заключение заявляет, что порт <code>8000</code> будет использоваться для принятия входящих подключений контейнера, и запускает <code>gunicorn</code> с тремя рабочими элементами, прослушивающими порт <code>8000</code>.</p>\n\n<p>Дополнительную информацию о каждом этапе в Dockerfile см. в шаге 6 руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-6-%E2%80%94-writing-the-application-dockerfile\">Создание приложения Django и Gunicorn с помощью Docker</a>.</p>\n\n<p>Теперь создайте образ с помощью <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Назовем образ <code>polls</code>, используя флаг <code>-t</code>, и передадим в текущий каталог как <em>контекст сборки</em> набор файлов для справки при построении образа.</p>\n\n<p>После того как Docker создаст и отметит образ, перечислите доступные образы, используя <code>docker images</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>docker images\n</code></pre>\n<p>Вы должны увидеть образ <code>polls</code>:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\npolls               latest              80ec4f33aae1        2 weeks ago         197MB\npython              3.7.4-alpine3.10    f309434dea3a        8 months ago        98.7MB\n</code></pre>\n<p>Перед запуском контейнера Django нам нужно настроить его рабочую среду с помощью файла <code>env</code>, присутствующего в текущем каталоге. Этот файл будет передан в команду <code>docker run</code>, которая используется для запуска контейнера, а Docker будет вводить настроенные переменные среды в рабочую среду контейнера.</p>\n\n<p>Откройте файл <code>env</code> с помощью <code>nano</code> или своего любимого редактора:</p>\n<pre class=\"code-pre  second-environment\"><code>nano env\n</code></pre>\n<p>Мы настроим файл примерно так, и вам потребуется добавить некоторые дополнительные значения, как показано ниже.</p>\n<div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  second-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Заполните недостающие значения для следующих ключей:</p>\n\n<ul>\n<li><code>DJANGO_SECRET_KEY</code>: задает уникальное, непрогнозируемое значение, как описано в <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#secret-key\">документации Django</a>. Один метод генерирования этого ключа представлен в разделе <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Изменение настроек приложения</a> руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Масштабируемое приложение Django</a>.</li>\n<li><code>DJANGO_ALLOWED_HOSTS</code>: эта переменная защищает приложение и предотвращает атаки через заголовки хоста HTTP. С целью тестирования установите <code>*</code> как подстановочный символ, подходящий для всех хостов. В производственной среде вы должны задать значение <code><span class=\"highlight\">your_domain.com</span></code>. Дополнительную информацию об этой настройке Django см. в разделе <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#allowed-hosts\">Базовые настройки</a> документации Django.</li>\n<li><code>DATABASE_USERNAME</code>: задает пользователя базы данных PostgreSQL, созданного на предварительных этапах.</li>\n<li><code>DATABASE_NAME</code>: задает <code>polls</code> или имя базы данных, созданной на предварительных этапах.</li>\n<li><code>DATABASE_PASSWORD</code>: задает пароль пользователя базы данных PostgreSQL, созданного на предварительных этапах.</li>\n<li><code>DATABASE_HOST</code>: задает имя хоста базы данных.</li>\n<li><code>DATABASE_PORT</code>: задает порт базы данных.</li>\n<li><code>STATIC_ACCESS_KEY_ID</code>: задает хранилище S3 или ключ доступа к пространству.</li>\n<li><code>STATIC_SECRET_KEY</code>: задает хранилище S3 или секретный ключ доступа к пространству.</li>\n<li><code>STATIC_BUCKET_NAME</code>: задает хранилище S3 или имя пространства.</li>\n<li><code>STATIC_ENDPOINT_URL</code>: задает соответствующее хранилище S3 или URL-адрес пространства, например <code>https://<span class=\"highlight\">space-name</span>.nyc3.digitaloceanspaces.com</code>, если ваше пространство находится в регионе <code>nyc3</code>.</li>\n</ul>\n\n<p>После завершения редактирования сохраните и закройте файл.</p>\n\n<p>Теперь мы будем использовать <code>docker run</code>, чтобы переопределить <code>CMD</code>, установленный в Dockerfile, и создать схему базы данных с помощью команд <code>manage.py makemigrations</code> и <code>manage.py migrate</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"\n</code></pre>\n<p>Мы запускаем образ контейнера <code>polls:latest</code>, передаем в только что измененный файл переменной среды и переопределяем команду Dockerfile с помощью <code>sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"</code>, которая создаст схему базы данных, определяемую кодом приложения. Если вы проводите запуск впервые, вы должны увидеть следующее:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>No changes detected\nOperations to perform:\n  Apply all migrations: admin, auth, contenttypes, polls, sessions\nRunning migrations:\n  Applying contenttypes.0001_initial... OK\n  Applying auth.0001_initial... OK\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying contenttypes.0002_remove_content_type_name... OK\n  Applying auth.0002_alter_permission_name_max_length... OK\n  Applying auth.0003_alter_user_email_max_length... OK\n  Applying auth.0004_alter_user_username_opts... OK\n  Applying auth.0005_alter_user_last_login_null... OK\n  Applying auth.0006_require_contenttypes_0002... OK\n  Applying auth.0007_alter_validators_add_error_messages... OK\n  Applying auth.0008_alter_user_username_max_length... OK\n  Applying auth.0009_alter_user_last_name_max_length... OK\n  Applying auth.0010_alter_group_name_max_length... OK\n  Applying auth.0011_update_proxy_permissions... OK\n  Applying polls.0001_initial... OK\n  Applying sessions.0001_initial... OK\n</code></pre>\n<p>Это означает, что схема базы данных успешно создана.</p>\n\n<p>Если в следующий раз вы запускаете <code>migrate</code>, Django будет выполнять холостую команду, если не изменить схему базы данных.</p>\n\n<p>Затем мы запустим еще один экземпляр контейнера приложения и используем внутри него интерактивную оболочку для создания административного пользователя проекта Django.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -i -t --env-file env polls sh\n</code></pre>\n<p>Вы получите строку оболочки внутри работающего контейнера, которую сможете использовать для создания пользователя Django:</p>\n<pre class=\"code-pre  second-environment\"><code>python manage.py createsuperuser\n</code></pre>\n<p>Введите имя пользователя, адрес электронной почты и пароль для пользователя, а после создания пользователя нажмите <code>CTRL+D</code> для выхода из контейнера и его удаления.</p>\n\n<p>В заключение мы создадим статические файлы приложения и загрузим их в пространство DigitalOcean с помощью <code>collectstatic</code>. Обратите внимание, что для завершения процесса может потребоваться время.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py collectstatic --noinput\"\n</code></pre>\n<p>После создания и загрузки файлов вы получите следующий вывод.</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>121 static files copied.\n</code></pre>\n<p>Теперь мы можем запустить приложение:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env -p 80:8000 polls\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>[2019-10-17 21:23:36 +0000] [1] [INFO] Starting gunicorn 19.9.0\n[2019-10-17 21:23:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8000 (1)\n[2019-10-17 21:23:36 +0000] [1] [INFO] Using worker: sync\n[2019-10-17 21:23:36 +0000] [7] [INFO] Booting worker with pid: 7\n[2019-10-17 21:23:36 +0000] [8] [INFO] Booting worker with pid: 8\n[2019-10-17 21:23:36 +0000] [9] [INFO] Booting worker with pid: 9\n</code></pre>\n<p>Мы запустим команду по умолчанию, определенную в Dockerfile, <code>gunicorn --bind :8000 --workers 3 mysite.wsgi:application</code> и раскроем порт контейнера <code>8000</code>, чтобы сопоставить порт <code>80</code> на сервере Ubuntu с портом <code>8000</code> контейнера <code>polls</code>.</p>\n\n<p>Теперь вы сможете перейти к приложению <code>polls</code> с использованием веб-браузера, набрав в адресной-строке URL <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code>. Поскольку маршрут для пути <code>/</code> не определен, скорее всего, вы получите ошибку <code>404 Страница не найдена</code>.</p>\n\n<p><span class='warning'><strong>Предупреждение.</strong> При использовании с Docker брандмауэра UFW, Docker обходит любые настроенные правила брандмауэра UFW. Об этой ситуации можно прочитать в <a href=\"https://github.com/docker/for-linux/issues/690\">GitHub</a>. Это объясняет, почему у вас есть доступ к порту <code>80</code> сервера, хотя вы не создавали правило доступа UFW на предварительном этапе. На <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-5-%E2%80%94-preventing-external-access-to-django-app-servers\">шаге 5</a> мы рассмотрим эту брешь в системе безопасности и скорректируем настройки UFW. Если вы не используете UFW, а используете <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">облачные брандмауэры</a> DigitalOcean, вы можете спокойно игнорировать это предупреждение.<br></span></p>\n\n<p>Перейдите в адрес <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code>, чтобы увидеть интерфейс приложения «Опросы»:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Интерфейс приложения «Опросы»\"></p>\n\n<p>Чтобы посмотреть административный интерфейс, перейдите по адресу <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/admin</code>. Вы должны увидеть окно аутентификации администратора приложения «Опросы»:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin.png\" alt=\"Страница аутентификации администратора приложения\"></p>\n\n<p>Введите имя администратора и пароль, которые вы создали с помощью команды <code>createsuperuser</code>.</p>\n\n<p>После аутентификации вы сможете получить доступ к административному интерфейсу приложения «Опросы»:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png\" alt=\"Основной интерфейс администратора приложения\"></p>\n\n<p>Обратите внимание, что статические активы приложений <code>admin</code> и <code>polls</code> поступают напрямую из хранилища объекта. Чтобы убедиться в этом, ознакомьтесь с материалами <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#testing-spaces-static-file-delivery\">Тестирование доставки статических файлов пространства</a>.</p>\n\n<p>После завершения изучения данных нажмите <code>CTRL+C</code> в окне терминала, где запущен контейнер Docker, чтобы удалить контейнер.</p>\n\n<p>Когда мы убедились, что контейнер приложения работает, как и ожидалось, можно запустить его в <em>раздельном</em> режиме, при котором контейнер будет работать в фоновом режиме, что позволит вам выйти из сеанса SSH.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Флаг <code>-d</code> предписывает Docker запустить контейнер в раздельном режиме, флаг <code>-rm</code> очищает файловую систему контейнера после выхода контейнера, а мы называем контейнер <code>polls</code>.</p>\n\n<p>Выйдите из первого сервера приложения Django и перейдите к адресу <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> для подтверждения того, что контейнер работает корректно.</p>\n\n<p>После запуска и активации первого сервера приложения Django вы можете настроить второй сервер приложения Django.</p>\n\n<h2 id=\"Шаг-2-—-Настройка-второго-сервера-приложения-django\">Шаг 2 — Настройка второго сервера приложения Django</h2>\n\n<p>Поскольку многие команды для настройки сервера будут выглядеть так же, как и в предыдущем шаге, мы представим их здесь в сокращенном виде. Дополнительную информацию о каждой команде из этого этапа можно найти в <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">шаге 1</a>.</p>\n\n<p>Начните с входа на <strong>второй</strong> сервер приложения Django.</p>\n\n<p>Клонируйте ветку <code>polls-docker</code> репозитория GitHub <code>django-polls</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Перейдите в каталог <code>django-polls</code>:</p>\n<pre class=\"code-pre  third-environment\"><code>cd django-polls\n</code></pre>\n<p>Создайте образ с помощью <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Откройте файл <code>env</code> с помощью <code>nano</code> или своего любимого редактора:</p>\n<pre class=\"code-pre  third-environment\"><code>nano env\n</code></pre><div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  third-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Заполните недостающие значения, как показано в <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">шаге 1</a>. После завершения редактирования сохраните и закройте файл.</p>\n\n<p>Наконец, запустите контейнер приложения в раздельном режиме:</p>\n<pre class=\"code-pre  third-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Перейдите на <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span>/polls</code> для подтверждения того, что контейнер работает корректно. Вы можете безопасно выйти из второго сервера приложения без завершения работы контейнера.</p>\n\n<p>Когда вы настроили и запустили оба контейнера приложения Django, можно переходить к настройке обратного прокси-сервера Nginx.</p>\n\n<h2 id=\"Шаг-3-—-Настройка-контейнера-docker-nginx\">Шаг 3 — Настройка контейнера Docker Nginx</h2>\n\n<p><a href=\"https://www.nginx.com/\">Nginx</a> — это универсальный веб-сервер, предлагающий ряд функций, включая <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\">обратное проксирование</a>, <a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\">балансирование нагрузки</a> и <a href=\"https://en.wikipedia.org/wiki/Web_cache\">кэширование</a>. В этом обучающем руководстве мы вызгрузили статические активы Django в хранилище объектов, поэтому мы не будем использовать возможности кэширования Nginx. Однако мы будем использовать Nginx как обратный прокси-сервер для двух серверов приложения Django и распределим входящие запросы между ними. Кроме того, Nginx будет осуществлять <a href=\"https://en.wikipedia.org/wiki/TLS_termination_proxy\">прекращение TLS</a> и перенаправление с помощью сертификата TLS, предоставленного Certbot. Это означает, что он заставит клиентов использовать HTTPS, перенаправляя входящие запросы HTTP в порт 443. Затем он расшифрует запросы HTTPS и передаст их на серверы Django.</p>\n\n<p>В этом обучающем руководстве мы приняли проектное решение отделить контейнеры Nginx от серверов. В зависимости от своих потребностей вы можете запускать контейнер Nginx на одном из серверов приложения Django, обрабатывая запросы с помощью прокси-сервера локально или на другом сервере Django. Еще один вариант архитектуры: запуск двух контейнеров Nginx, по одному на каждом сервере, и облачного <a href=\"https://www.digitalocean.com/products/load-balancer/\">балансировщика нагрузки</a> перед ними. Каждая архитектура имеет свои преимущества безопасности и производительности, и вам потребуется провести <a href=\"https://en.wikipedia.org/wiki/Load_testing\">нагрузочное тестирование</a>, чтобы определить узкие места. Гибкая архитектура, описанная в данном руководстве, позволяет масштабировать как серверный слой приложения Django, так и прокси-сервер Nginx. Если узким местом станет единственный контейнер Nginx, вы сможете масштабировать несколько прокси-серверов Nginx и добавить облачный балансировщик нагрузок или быстрый балансировщик нагрузок L4, например <a href=\"http://www.haproxy.org/\">HAProxy</a>.</p>\n\n<p>Когда вы создадите и запустите оба сервера приложения Django, можно начинать настройку прокси-сервера Nginx. Войдите на ваш прокси-сервер и создайте каталог с именем <code>conf</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>mkdir conf\n</code></pre>\n<p>Создайте файл конфигурации <code>nginx.conf</code> с помощью <code>nano</code> или своего любимого редактора:</p>\n<pre class=\"code-pre  fourth-environment\"><code>nano conf/nginx.conf\n</code></pre>\n<p>Вставьте следующую конфигурацию Nginx:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>\nupstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n\nserver {\n    listen 80 default_server;\n    return 444;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n\n    # SSL\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n\n    client_max_body_size 4G;\n    keepalive_timeout 5;\n\n        location / {\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header X-Forwarded-Proto $scheme;\n          proxy_set_header Host $http_host;\n          proxy_redirect off;\n          proxy_pass http://django;\n        }\n\n    location ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n    }\n\n}\n</code></pre>\n<p>Блоки <code>upstream</code>, <code>server</code> и <code>location</code> настраивают Nginx таким образом, чтобы перенаправлять HTTP-запросы на HTTPS и распределять нагрузку на два сервера приложения Django, настроенных в шагах 1 и 2. Дополнительную информацию о структуре файла конфигурации Nginx см. в статье <a href=\"https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts#understanding-nginx-configuration-contexts\">Понимание структуры файла конфигурации и контекста конфигурации</a>. Также может быть полезна статья <a href=\"https://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\">Понимание работы сервера Nginx и алгоритмов выбора блоков расположения</a>.</p>\n\n<p>Эта конфигурация была собрана из примеров файлов конфигурации из <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Gunicorn</a>, <a href=\"https://github.com/certbot/certbot/blob/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf\">Certbot</a> и <a href=\"https://hub.docker.com/_/nginx\">Nginx</a> и является минимальной конфигурацией Nginx, необходимой для построения и запуска данной архитектуры. Настройка данной конфигурации Nginx выходит за рамки этой статьи, но вы можете использовать такой инструмент, как <a href=\"https://www.digitalocean.com/community/tools/nginx\">NGINXConfig</a>, для генерирования исполнительных и безопасных файлов конфигурации для вашей архитектуры.</p>\n\n<p>Блок <code>upstream</code> определяет группу серверов, которые используются для передачи запросов с использованием директивы <code>proxy_pass</code>:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>upstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n. . .\n</code></pre>\n<p>В этом блоке мы используем имя <code>django</code> и включаем IP-адреса обоих серверов приложения Django. Если серверы приложения работают на DigitalOcean с активированной сетью VPC, вам следует использовать их частные IP-адреса. Чтобы узнать, как активировать сеть VPC на DigitalOcean, см. <a href=\"https://www.digitalocean.com/docs/networking/vpc/how-to/enable/\">Как активировать сеть VPC на существующих дроплетах</a>.</p>\n\n<p>Первый блок <code>server</code> захватывает запросы, которые не соответствуют вашему домену, и прерывает соединение. Например, в этом блоке будет обрабатываться прямой запрос HTTP на IP-адрес вашего сервера:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80 default_server;\n    return 444;\n}\n. . .\n</code></pre>\n<p>Следующий блок <code>server</code> перенаправляет запросы HTTP на ваш домен на HTTPS, используя <a href=\"https://en.wikipedia.org/wiki/HTTP_301\">перенаправление HTTP 301</a>. Эти запросы рассматриваются в последнем блоке <code>server</code>:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name your_domain.com;\n    return 301 https://$server_name$request_uri;\n}\n. . .\n</code></pre>\n<p>Эти две директивы определяют путь к сертификату TLS и секретному ключу. Они предоставляются с помощью Certbot и монтируются в контейнер Nginx на следующем шаге.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\nssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n. . .\n</code></pre>\n<p>Это по умолчанию параметры безопасности SSL, рекомендованные Certbot. Дополнительную информацию о них см. в разделе <a href=\"https://nginx.org/en/docs/http/ngx_http_ssl_module.html\">Модуль ngx_http_ssl_module</a> в документации Nginx. Еще одним полезным руководством, которое вы можете использовать для настройки конфигурации SSL, является инструкция по безопасности от Mozilla <a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\">Security/Server Side TLS</a>.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n. . .\n</code></pre>\n<p>Эти две директивы из <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">примерной конфигурации Nginx</a> от Gunicorn определяют максимальный разрешенный размер тела запроса клиента и назначают временной интервал поддержки соединения с клиентом. Nginx закроет соединения с клиентом после <code>keepalive_timeout</code>.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nclient_max_body_size 4G;\nkeepalive_timeout 5;\n. . .\n</code></pre>\n<p>Первый блок <code>location</code> предписывает Nginx направлять запросы на серверы <code>upstream django</code> через HTTP. Также он сохраняет клиентские заголовки HTTP, захватывающие исходный IP-адрес, протокол, используемый для соединения, и целевой хост:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation / {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://django;\n}\n. . .\n</code></pre>\n<p>Дополнительную информацию об этих директивах см. в разделах <a href=\"https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration\">развертывание Gunicorn</a> и <a href=\"http://nginx.org/en/docs/http/ngx_http_proxy_module.html\">Модуль ngx_http_proxy_module</a> из документации Nginx.</p>\n\n<p>Последний блок <code>location</code> захватывает запросы на путь <code>/well-known/acme-challenge/</code>, используемый Certbot для задач HTTP-01 по проверке вашего домена с помощью Let&rsquo;s Encrypt и предоставлению или обновлению сертификатов TLS. Дополнительную информацию о задаче HTTP-01, используемой Certbot, см. в разделе <a href=\"https://letsencrypt.org/docs/challenge-types/\">Виды задач</a> из документации Let&rsquo;s Encrypt.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n}\n</code></pre>\n<p>После завершения редактирования сохраните и закройте файл.</p>\n\n<p>Теперь вы можете использовать этот файл конфигурации для запуска контейнера Nginx Docker. В этом обучающем руководстве мы будем использовать образ <code>nginx:1.19.0</code>, версия <code>1.19.0</code> <a href=\"https://hub.docker.com/_/nginx\">официального образа Docker</a>, обслуживаемого Nginx.</p>\n\n<p>При первом запуске контейнера Nginx будет выдавать ошибку и отказывать в работе, так как мы еще не предоставили сертификаты, определенные в файле конфигурации. Однако мы все равно будем выполнять команду для локальной загрузки образа Nginx и протестируем корректность работы остальных элементов.</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Давайте назовем контейнер <code>nginx</code> и свяжем порты хоста <code>80</code> и <code>443</code> с соответствующими портами контейнера. Флаг <code>-v</code> монтирует файл конфигурации в контейнер Nginx на <code>/etc/nginx/conf.d/nginx.conf</code>, который образ Nginx предварительно настраивает для загрузки. Он монтируется в режиме <code>ro</code> или «только для чтения», поэтому контейнер не может изменять файл. Также в контейнер монтируется корневой веб-каталог <code>/var/www/html</code>. Наконец, <code>nginx:1.19.0</code> предписывает Docker вытащить и запустить образ <code>nginx:1.19.0</code> из Dockerhub.</p>\n\n<p>Docker вытащит и запустит образ, затем Nginx выдаст ошибку, т.к. не найдет настроенный сертификат TLS и секретный ключ. На следующем шаге мы предоставим их с помощью клиента Dockerized Certbot и органа сертификации Let&rsquo;s Encrypt.</p>\n\n<h2 id=\"Шаг-4-—-Настройка-certbot-и-обновление-сертификата-let-39-s-encrypt\">Шаг 4 — Настройка Certbot и обновление сертификата Let&rsquo;s Encrypt</h2>\n\n<p><a href=\"https://github.com/certbot/certbot\">Certbot</a> — это клиент Let&rsquo;s Encrypt, разработанный фондом <a href=\"https://www.eff.org/\">Electronic Frontier Foundation</a>. Он предоставляет бесплатные сертификаты TLS от органа сертификации <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>, которые позволяют браузерам идентифицировать ваши веб-серверы. Поскольку мы установили Docker на нашем прокси-сервере Nginx, мы будем использовать <a href=\"https://hub.docker.com/r/certbot/certbot/\">образ Docker Certbot</a> для предоставления и обновления сертификатов</p>\n\n<p>Для начала проверьте наличие записи <code>А</code> DNS, соединенной с публичным IP-адресом прокси-сервера. Затем на вашем прокси-сервере представьте тестовую версию сертификатов с помощью образа Docker <code>certbot</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone --staging -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Эта команда запускает образ Docker <code>certbot</code> в интерактивном режиме и направляет порт <code>80</code> на хосте на порт контейнера <code>80</code>. Она создает и монтирует два каталога хоста в контейнер: <code>/etc/letsencrypt/</code> и <code>/var/lib/letsencrypt/</code>. <code>certbot</code> работает в режиме <code>standalone</code> без Nginx и будет использовать серверы <code>staging</code> Let&rsquo;s Encrypt для валидации домена.</p>\n\n<p>Когда появится строка ввода, укажите свой электронный адрес и примите Условия обслуживания. Если валидация домена прошла успешно, вы увидете следующий вывод:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Obtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for stubb.dev\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem\n   Your cert will expire on 2020-09-15. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - Your account credentials have been saved in your Certbot\n   configuration directory at /etc/letsencrypt. You should make a\n   secure backup of this folder now. This configuration directory will\n   also contain certificates and private keys obtained by Certbot so\n   making regular backups of this folder is ideal.\n</code></pre>\n<p>Вы можете проверить сертификат с помощью <code>cat</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>sudo cat /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n</code></pre>\n<p>После предоставления сертификата TLS мы можем протестировать конфигурацию Nginx, собранную на предыдущем шаге:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Задаем те же команды, что и на <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">шаге 3</a>, добавив оба только что созданных каталога Let&rsquo;s Encrypt.</p>\n\n<p>После установки и активации Nginx перейдите на <code>http://<span class=\"highlight\">your_domain.com</span></code>. Вы можете получить предупреждение в браузере о том, что орган сертификации недействителен. Это ожидаемо, так как мы предоставили тестовые, а не рабочие сертификаты Let&rsquo;s Encrypt. Проверьте строку URL-адреса вашего браузера, чтобы убедиться, что ваш запрос HTTP был перенаправлен на HTTPS.</p>\n\n<p>Нажмите <code>CTRL+C</code> на вашем терминале, чтобы выйти из Nginx, и снова запустите клиент <code>certbot</code>, на этот раз опустив флаг <code>--staging</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Когда появится окно выбора: сохранить действующий сертификат или обновить и заменить, нажмите <code>2</code>, чтобы обновить, а затем <code>ENTER</code>, чтобы подтвердить свой выбор.</p>\n\n<p>После предоставления рабочего сертификата TLS запустите сервер Nginx снова:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>В вашем браузере перейдите на <code>http://<span class=\"highlight\">your_domain.com</span></code>. В строке URL-адреса подтвердите, что запрос HTTP был перенаправлен на HTTPS. Поскольку приложение «Опросы» не имеет настроенного по умолчанию маршрута, вы увидите ошибку Django <strong>Страница не найдена</strong>. Перейдите на <code>https://<span class=\"highlight\">your_domain.com</span>/polls</code> и вы увидите стандартный интерфейс приложения «Опросы»:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Интерфейс приложения «Опросы»\"></p>\n\n<p>На этом этапе вы предоставили рабочий сертификат TLS с помощью клиента Docker Certbot, направляете внешние запросы с помощью обратного прокси-сервера и распределяете нагрузку между двумя серверами приложения Django.</p>\n\n<p>Срок действия сертификатов Let&rsquo;s Encrypt истекает каждые 90 дней. Чтобы удостовериться в действительности вашего сертификата, необходимо регулярно обновлять его до истечения срока действия. После запуска Nginx вы должны использовать клиент Certbot в режиме <code>webroot</code> вместо режима <code>standalone</code>. Это означает, что Certbot будет выполнять проверку путем создания файла в каталоге <code>/var/www/html/.well-known/acme-challenge/</code>, и запросы Let&rsquo;s Encrypt о валидации на этом пути будут захватываться правилом <code>location</code>, определенном в конфигурации Nginx на <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">шаге 3</a>. Certbot будет менять сертификаты, и вы сможете перезагрузить Nginx, чтобы он использовал уже новый предоставленный сертификат.</p>\n\n<p>Существует множество способов автоматизации этой процедуры, но автоматическое обновление сертификатов TLS выходит за рамки данного обучающего руководства. Для аналогичного процесса с помощью утилиты планирования <code>cron</code> см. шаг 6 руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates%5D(https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates)\">Обеспечение безопасности контейнеризированного приложения Node.js с помощью Nginx, Let&rsquo;s Encrypt и Docker Compose</a>.</p>\n\n<p>На вашем терминале нажмите <code>CTRL+C</code>, чтобы удалить контейнер Nginx. Запустите его снова в раздельном режиме, добавив флаг <code>-d</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -d -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n  -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>При запущенном в фоновом режиме Nginx используйте следующую команду для выполнения сухого запуска процедуры обновления сертификата:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm --name certbot \\\n    -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n  -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n  -v \"/var/www/html:/var/www/html\" \\\n  certbot/certbot renew --webroot -w /var/www/html --dry-run\n</code></pre>\n<p>Мы используем плагин <code>--webroot</code>, указываем корневой путь и используем флаг -<code>--dry-run</code>, чтобы убедиться, что все работает корректно без обновления сертификата.</p>\n\n<p>Если моделирование обновления завершится успешно, вы увидите следующий вывод:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Cert not due for renewal, but simulating renewal for dry run\nPlugins selected: Authenticator webroot, Installer None\nRenewing an existing certificate\nPerforming the following challenges:\nhttp-01 challenge for <span class=\"highlight\">your_domain.com</span>\nUsing the webroot path /var/www/html for all unmatched domains.\nWaiting for verification...\nCleaning up challenges\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nnew certificate deployed without reload, fullchain is\n/etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates below have not been saved.)\n\nCongratulations, all renewals succeeded. The following certs have been renewed:\n  /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem (success)\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates above have not been saved.)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n</code></pre>\n<p>В рабочей настройке после обновления сертификата вы должны перезагрузить Nginx, чтобы изменения вступили в силу. Чтобы перезагрузить Nginx, запустите следующую команду:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker kill -s HUP nginx\n</code></pre>\n<p>Эта команда будет отправлять сигнал Unix <a href=\"https://en.wikipedia.org/wiki/SIGHUP\">HUP</a> для процесса Nginx, работающего внутри контейнера Docker <code>nginx</code>. После получения этого сигнала Nginx перезагрузит конфигурацию и обновленные сертификаты.</p>\n\n<p>После активации HTTPS и всех компонентов данной архитектуры итоговым шагом является блокировка настройки от внешнего доступа к двум серверам приложения. Все запросы HTTP должны проходить через прокси-сервер Nginx.</p>\n\n<h2 id=\"Шаг-5-—-Предотвращение-внешнего-доступа-к-серверу-приложения-django\">Шаг 5 — Предотвращение внешнего доступа к серверу приложения Django</h2>\n\n<p>В описанной в этом руководстве архитектуре прекращение SSL происходит на прокси-сервере Nginx. Это означает, что Nginx расшифровывает соединение SSL, а пакеты передаются на серверы приложения Django без шифрования. Для многих случаев использования этого уровня безопасности достаточно. Для приложений, содержащих финансовые данные или данные о состоянии здоровья, вам может понадобится внедрение сквозного шифрования. Вы можете сделать это, передавая зашифрованные пакеты через балансировщик нагрузки и расшифровывая их на серверах приложения, или зашифровывая на прокси-сервере и снова расшифровывая на серверах приложения Django. Эти методы выходят за рамки данного руководства, но для получения более подробной информации можно ознакомиться со статьей <a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">Сквозное шифрование</a>.</p>\n\n<p>Прокси-сервер Nginx действует как шлюз между внешним трафиком и внутренней сетью. Теоретически ни один внешний клиент не должен иметь прямого доступа к внутренним серверам приложения, и все запросы должны проходить через сервер Nginx. В примечании на <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">шаге 1</a> кратко описывается <a href=\"https://github.com/docker/for-linux/issues/690\">проблема</a> с Docker, где Docker обходит настройки брандмауэра по умолчанию <code>ufw</code> и открывает порты внешним способом, что может быть небезопасным. Чтобы решить эту проблему безопасности, рекомендуется использовать <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">облачные брандмауэры</a> при работе с серверами на базе Docker. Дополнительную информацию о создании облачного брандмауэра с помощью DigitalOcean можно найти в руководстве <a href=\"https://www.digitalocean.com/docs/networking/firewalls/how-to/create/\">Создание брандмауэра</a>. Также вы можете использовать непосредственно <code>iptables</code> вместо <code>ufw</code>. Дополнительную информацию об использовании <code>iptables</code> с Docker можно найти в статье <a href=\"https://docs.docker.com/network/iptables/\">Docker and iptables</a>.</p>\n\n<p>На этом шаге мы изменим конфигурацию UFW, чтобы заблокировать внешний доступ к портам хоста, которые открывает Docker. При запуске Django на серверах приложения мы передаем флаг <code>-p 80:8000</code> на <code>docker</code>, который направляет порт <code>80</code> на хосте в порт контейнера <code>8000</code>. Это также открывает порт <code>80</code> для внешних клиентов, которых вы можете верифицировать, посетив <code>http://<span class=\"highlight\">your_app_server_1_IP</span></code>. Чтобы предотвратить прямой доступ, мы изменим конфигурацию UFW с помощью метода, описанного в <a href=\"https://github.com/chaifeng/ufw-docker\">репозитории GitHub ufw-docker</a>.</p>\n\n<p>Начните с входа на первый сервер приложения Django. Затем откройте файл <code>/etc/ufw/after.rules</code> с привилегиями суперпользователя, используя <code>nano</code> или свой любимый редактор:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Введите свой пароль при запросе и нажмите <code>ENTER</code> для подтверждения.</p>\n\n<p>Вы должны увидеть следующие правила <code>ufw</code>:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>#\n# rules.input-after\n#\n# Rules that should be run after the ufw command line added rules. Custom\n# rules should be added to one of these chains:\n#   ufw-after-input\n#   ufw-after-output\n#   ufw-after-forward\n#\n\n# Don't delete these required lines, otherwise there will be errors\n*filter\n:ufw-after-input - [0:0]\n:ufw-after-output - [0:0]\n:ufw-after-forward - [0:0]\n# End required lines\n\n# don't log noisy services by default\n-A ufw-after-input -p udp --dport 137 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 138 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 139 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 445 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 67 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 68 -j ufw-skip-to-policy-input\n\n# don't log noisy broadcast\n-A ufw-after-input -m addrtype --dst-type BROADCAST -j ufw-skip-to-policy-input\n\n# don't delete the 'COMMIT' line or these rules won't be processed\nCOMMIT\n</code></pre>\n<p>Прокрутите вниз и вставьте следующий блок правил конфигурации UFW:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Эти правила ограничивают публичный доступ к портам, которые открывает Docker, и позволяют получить доступ от частных диапазонов IP-диапазонов <code>10.0.0.0/8</code>, <code>172.16.0.0/12</code> и <code>192.168.0.0/16</code>. Если вы используете VPC с DigitalOcean, тогда дроплеты в вашей сети VPC получат доступ к открытому порту через закрытый интерфейс, а внешние клиенты не получат. Дополнительную информацию о VPC см. в <a href=\"https://www.digitalocean.com/docs/networking/vpc/\">официальной документации VPC</a>. Дополнительную информацию о правилах, которые использованы в этом фрагменте, ищите в разделе <a href=\"https://github.com/chaifeng/ufw-docker#how-it-works\">Как это работает?</a> инструкции <a href=\"https://github.com/chaifeng/ufw-docker\">ufw-docker README</a>.</p>\n\n<p>Если вы не используете VPC с Digitalocean и ввели публичные IP-адреса серверов приложений в блоке <code>upstream</code> вашей конфигурации Nginx, вам придется изменить брандмауэр UFW, чтобы разрешить трафик с сервера Nginx через порт <code>80</code> на серверы приложения Django. Инструкции по созданию правил <code>allow</code> с брандмауэром UFW см. в руководстве <a href=\"https://www.digitalocean.com/community/tutorials/ufw-essentials-common-firewall-rules-and-commands\">Основы UFW: общие правила и команды брандмауэра</a>.</p>\n\n<p>После завершения редактирования сохраните и закройте файл.</p>\n\n<p>Перезапустите <code>ufw</code> для выбора новой конфигурации:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Перейдите на <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> в вашем браузере для подтверждения того, что вы больше не можете получить доступ к серверу приложения через порт <code>80</code>.</p>\n\n<p>Повторите этот процесс на втором сервере приложения Django.</p>\n\n<p>Выйдите из первого сервера приложения или откройте другое окно терминала и войдите на второй сервер приложения Django. Затем откройте файл <code>/etc/ufw/after.rules</code> с привилегиями суперпользователя, используя <code>nano</code> или свой любимый редактор:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Введите свой пароль при запросе и нажмите <code>ENTER</code> для подтверждения.</p>\n\n<p>Прокрутите вниз и вставьте следующий блок правил конфигурации UFW:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  third-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>После завершения редактирования сохраните и закройте файл.</p>\n\n<p>Перезапустите <code>ufw</code> для выбора новой конфигурации:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Перейдите на <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span></code> в вашем браузере для подтверждения того, что вы больше не можете получить доступ к серверу приложения через порт <code>80</code>.</p>\n\n<p>В заключение перейдите на <code>https://<span class=\"highlight\">your_domain_here</span>/polls</code>, чтобы подтвердить, что прокси-сервер Nginx все еще имеет доступ к серверам Django. Вы должны увидеть интерфейс приложения «Опросы» по умолчанию.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>В этом обучающем руководстве мы настроили масштабируемое приложение Django «Опросы» при помощи контейнеров Docker. По мере увеличения трафика и загрузки системы вы можете масштабировать каждый слой отдельно: слой прокси-сервера Nginx, слой серверного приложения Django и слой базы данных PostgreSQL.</p>\n\n<p>При построении распределенной системы вам часто приходится выбирать из нескольких проектных решений и архитектур. Архитектура, описанная в этом руководстве, является гибким планом для разработки масштабируемых приложений с Django и Docker.</p>\n\n<p>Вам бы хотелось контролировать поведение контейнеров при возникновении ошибок или автоматически запускать контейнеры во время загрузки системы. Для этого вы можете использовать диспетчер процесса, например <a href=\"https://en.wikipedia.org/wiki/Systemd\">Systemd</a>, или применять политики перезапуска. Дополнительную информацию можно прочитать в разделе <a href=\"https://docs.docker.com/config/containers/start-containers-automatically/\">Автоматический запуск контейнера</a> из документации Docker.</p>\n\n<p>При работе в масштабе с несколькими хостами на одном и том же образе Docker более эффективной может стать автоматизация шагов с использованием инструмента управления конфигурацией, например <a href=\"https://www.ansible.com/\">Ansible</a> или <a href=\"https://www.chef.io/\">Chef</a>. Дополнительную информацию об управлении конфигурацией см. в руководствах <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-configuration-management\">Введение в управление конфигурацией</a> и <a href=\"https://www.digitalocean.com/community/meetup_kits/automating-server-setup-with-ansible-a-digitalocean-workshop-kit\">Автоматизированная настройка сервера с помощью Ansible: набор материалов для тренинга DigitalOcean</a>.</p>\n\n<p>Вместо создания такого же образа на каждом хосте вы можете также упорядочить развертывание с помощью реестра образов, такого как <a href=\"https://hub.docker.com/\">Docker Hub</a>, который централизованно строит, хранит и распределяет образы Docker на несколько серверов. Наряду с реестром образов непрерывный конвейер интеграции и развертывания может помочь вам строить, тестировать и развертывать образы на ваших серверах приложения. Дополнительную информацию о CI/CD см. в руководстве <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-ci-cd-best-practices\">Введение в передовой опыт CI/CD</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:57 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/scalable_django/polls_app.png","linkMd5":"a4defe178e448cd4f5967fe95415435a","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","destWidth":474,"destHeight":473,"sourceBytes":43341,"destBytes":1896,"author":"Hanif Jetha","articleImgCdnMap":{"https://assets.digitalocean.com/articles/scalable_django/polls_app.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/31/07-48-31-305_44661f4fc2769a02.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn38@2020_6/2020/08/31/07-48-31-498_6d93c2bd68b66072.webp"},"publishedOrCreatedDate":1598860106972},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment durcir OpenSSH sur Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-harden-openssh-on-ubuntu-18-04-fr","description":"<p><em>L'auteur a choisi que le <a href=\"https://www.brightfunds.org/organizations/electronic-frontier-foundation-inc\">Electronic Frontier Foundation Inc</a> recevrait une donation dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for Donations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Les serveurs Linux sont souvent administrés à distance en utilisant SSH en se connectant à un serveur <a href=\"https://www.openssh.com/\">OpenSSH</a>, qui est le logiciel serveur SSH par défaut utilisé dans Ubuntu, Debian, CentOS, FreeBSD et la plupart des autres systèmes basés sur Linux/BSD.</p>\n\n<p>Le serveur OpenSSH est le côté serveur de SSH, également connu sous le nom de démon SSH ou <code>sshd</code>. Vous pouvez vous connecter à un serveur OpenSSH en utilisant le client OpenSSH — la commande <code>ssh</code>. Vous pouvez en apprendre plus sur le modèle client-serveur SSH dans <a href=\"https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys\">Les Essentiels de SSH : Travailler avec les serveurs SSH, les clients et les clés</a>. Il est important de sécuriser correctement votre serveur OpenSSH, car il agit comme la porte d'entrée ou l'entrée de votre serveur.</p>\n\n<p>Dans ce tutoriel, vous allez durcir votre serveur OpenSSH en utilisant différentes options de configuration pour vous assurer que l'accès à distance à votre serveur est aussi sécurisé que possible.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour suivre ce tutoriel, vous aurez besoin de :</p>\n\n<ul>\n<li>Un serveur Ubuntu 18.04 configuré en suivant la <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Configuration initiale du serveur avec Ubuntu 18.04</a>, y compris un utilisateur sudo non root.</li>\n</ul>\n\n<p>Une fois que tout est prêt, connectez-vous à votre serveur en tant que non-root user pour commencer.</p>\n\n<h2 id=\"Étape-1-—-durcissement-général\">Étape 1 — Durcissement général</h2>\n\n<p>Dans cette première étape, vous allez implémenter quelques configurations de durcissement initiales pour améliorer la sécurité globale de votre serveur SSH.</p>\n\n<p>La configuration de durcissement exacte qui est la plus appropriée à votre propre serveur dépend fortement de votre propre <a href=\"https://owasp.org/www-community/Application_Threat_Modeling\">modèle de menace et de votre seuil de risque</a>. Cependant, la configuration que vous utiliserez dans cette étape est une configuration sécurisée générale qui conviendra à la majorité des serveurs.</p>\n\n<p>La plupart des configurations de durcissement pour OpenSSH que vous implémentez utilisent le fichier de configuration standard du serveur OpenSSH, qui est situé dans <code>/etc/ssh/sshd_config</code>. Avant de poursuivre ce tutoriel, il est recommandé de faire une sauvegarde de votre fichier de configuration existant, afin de pouvoir le restaurer dans le cas improbable où quelque chose se passerait mal.</p>\n\n<p>Faites une sauvegarde du fichier en utilisant la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak\n</li></ul></code></pre>\n<p>Cela enregistrera une copie de sauvegarde du fichier situées à <code>/etc/ssh/sshd_config.bak</code>.</p>\n\n<p>Avant de modifier votre fichier de configuration, vous pouvez examiner les options qui sont actuellement configurées. Pour ce faire, lancez la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo sshd -T\n</li></ul></code></pre>\n<p>Cela exécutera le serveur OpenSSH en mode test étendu, qui validera l'intégralité du fichier de configuration et imprimera les valeurs de configuration effectives.</p>\n\n<p>Vous pouvez maintenant ouvrir le fichier de configuration en utilisant votre éditeur de texte préféré pour commencer à implémenter les mesures de durcissement initial :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ssh/sshd_config\n</li></ul></code></pre>\n<p><span class='note'><strong>Remarque :</strong> le fichier de configuration du serveur OpenSSH comprend de nombreuses options et configurations par défaut. En fonction de la configuration actuelle de votre serveur, certaines des options de durcissement recommandées peuvent déjà avoir été définies.<br></span></p>\n\n<p>Lorsque vous éditez votre fichier de configuration, certaines options peuvent être commentées par défaut en utilisant un simcaractère dièse (<code>#</code>) au début de la ligne. Pour modifier ces options, ou pour que l'option commentée soit reconnue, vous devrez les décommenter, en supprimant le dièse.</p>\n\n<p>Tout d'abord, désactivez la connexion via SSH en tant qu'utilisateur <strong>root</strong> en réglant l'option suivante :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>PermitRootLogin <span class=\"highlight\">no</span>\n</code></pre>\n<p>Ceci est très avantageux, car cela empêchera un attaquant potentiel de se connecter directement en tant que root. Cela encourage également de bonnes pratiques de sécurité opérationnelles, telles que le fait de travailler en tant qu'utilisateur non privilégié et d'utiliser <code>sudo</code> pour augmenter les privilèges seulement lorsque cela est absolument nécessaire.</p>\n\n<p>Ensuite, vous pouvez limiter le nombre maximum de tentatives d'authentification pour une session de connexion particulière en configurant ce qui suit :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>MaxAuthTries <span class=\"highlight\">3</span>\n</code></pre>\n<p>Une valeur standard de <code>3</code> est acceptable pour la plupart des configurations, mais vous pouvez souhaiter la fixer à un niveau supérieur ou inférieur en fonction de votre propre seuil de risque.</p>\n\n<p>Si nécessaire, vous pouvez également définir un délai de grâce de connexion réduit, qui correspond au temps dont dispose un utilisateur pour terminer l'authentification après sa première connexion à votre serveur SSH :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>LoginGraceTime 20\n</code></pre>\n<p>Le fichier de configuration spécifie cette valeur en secondes.</p>\n\n<p>Le fait de définir une valeur inférieure permet d'éviter certaines <a href=\"https://www.cloudflare.com/learning/ddos/glossary/denial-of-service/\">attaques par déni de service</a> lorsque plusieurs sessions d'authentification sont maintenues ouvertes pendant une période prolongée.</p>\n\n<p>Si vous avez configuré des clés SSH pour l'authentification, plutôt que d'utiliser des mots de passe, désactivez l'authentification par mots de passe SSH pour empêcher que les mots de passe divulgués des utilisateurs puissent permettre à un attaquant de se connecter :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>PasswordAuthentication <span class=\"highlight\">no</span>\n</code></pre>\n<p>Comme mesure de durcissement supplémentaire liée aux mots de passe, vous pouvez également souhaiter désactiver l'authentification avec des mots de passe vides. Cela empêchera les connexions si le mot de passe d'un utilisateur est défini à une valeur vierge ou vide :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>PermitEmptyPasswords <span class=\"highlight\">no</span>\n</code></pre>\n<p>Dans la majorité des cas d'utilisation, SSH sera configuré avec une clé d'authentification publique comme seule méthode d'authentification en cours d'utilisation. Cependant, le serveur OpenSSH prend également en charge de nombreuses autres méthodes d'authentification, dont certaines sont activées par défaut. Si ce elles ne sont pas nécessaire, vous pouvez les désactiver pour réduire encore la surface d'attaque de votre serveur SSH :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>ChallengeResponseAuthentication <span class=\"highlight\">no</span>\nKerberosAuthentication <span class=\"highlight\">no</span>\nGSSAPIAuthentication <span class=\"highlight\">no</span>\n</code></pre>\n<p>Si vous souhaitez en savoir plus sur certaines des méthodes d'authentification supplémentaires disponibles dans SSH, vous pouvez consulter ces ressources :</p>\n\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Challenge%E2%80%93response_authentication\">Authentification défi-réponse</a></li>\n<li><a href=\"https://docstore.mik.ua/orelly/networking_2ndEd/ssh/ch11_04.htm\">Authentification Kerberos</a></li>\n<li><a href=\"https://www.ssh.com/manuals/clientserver-product/52/Secureshell-gssapiuserauthentication.html\">Authentification GSSAPI</a></li>\n</ul>\n\n<p>X11 forwarding permet l'affichage d'applications graphiques à distance via une connexion SSH, mais cela est rarement utilisé dans la pratique.  Il est recommandé de la désactiver s'il n'est pas nécessaire sur votre serveur :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>X11Forwarding <span class=\"highlight\">no</span>\n</code></pre>\n<p>Le serveur OpenSSH permet aux clients connectés de passer des variables d'environnement personnalisées, c'est-à-dire de définir un <code>$PATH</code> ou de configurer des paramètres de terminal. Cependant, tout comme X11 forwarding, ces fonctions ne sont pas couramment utilisées, et peuvent donc être désactivées dans la plupart des cas :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>PermitUserEnvironment <span class=\"highlight\">no</span>\n</code></pre>\n<p>Si vous décidez de configurer cette option, vous devriez également vous assurer de commenter toute référence à <code>AcceptEnv</code> en ajoutant un dièse(<code>#</code>) au début de la ligne.</p>\n\n<p>Ensuite, vous pouvez désactiver plusieurs options diverses liées au tunneling, et à la redirection si vous ne les utilisez pas sur votre serveur :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>AllowAgentForwarding <span class=\"highlight\">no</span>\nAllowTcpForwarding <span class=\"highlight\">no</span>\nPermitTunnel <span class=\"highlight\">no</span>\n</code></pre>\n<p>Enfin, vous pouvez désactiver la bannière SSH verbeuse activée par défaut, car elle montre diverses informations sur votre système, telles que la version du système d'exploitation :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>DebianBanner <span class=\"highlight\">no</span>\n</code></pre>\n<p>Notez que cette option ne sera probablement pas déjà présente dans le fichier de configuration, vous devrez donc probablement l'ajouter manuellement. Enregistrez et quittez le fichier une fois que vous avez terminé.</p>\n\n<p>Validez maintenant la syntaxe de votre nouvelle configuration en exécutant <code>sshd</code> en mode test :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo sshd -t\n</li></ul></code></pre>\n<p>Si la syntaxe de votre fichier de configuration est valide, il n'y aura aucune sortie. En cas d'erreur de syntaxe, vous recevrez une sortie décrivant le problème.</p>\n\n<p>Une fois que vous êtes satisfait de votre fichier de configuration, vous pouvez recharger <code>sshd</code> pour appliquer les nouveaux paramètres :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo service sshd reload\n</li></ul></code></pre>\n<p>Dans cette étape, vous avez terminé un durcissement général de votre fichier de configuration du serveur OpenSSH. Ensuite, vous allez implémenter une liste d'adresse IP pour restreindre davantage ceux qui peuvent se connecter à votre serveur.</p>\n\n<h2 id=\"Étape-2-—-mise-en-place-d-39-une-liste-d-39-adresses-ip-autorisées\">Étape 2 — Mise en place d'une liste d'adresses IP autorisées</h2>\n\n<p>Vous pouvez utiliser des listes d'adresse IP pour limiter les utilisateurs autorisés à se connecter à votre serveur sur base de leur adresse IP. Dans cette étape, vous allez configurer une liste d'adresse IP autorisées pour votre serveur OpenSSH.</p>\n\n<p>Dans de nombreux cas, vous ne vous connecterez à votre serveur qu'à partir d'un petit nombre d'adresses IP connues et de confiance. Par exemple, votre connexion à Internet à domicile, un appareil VPN d'entreprise, ou une <a href=\"https://en.wikipedia.org/wiki/Jump_server\">boîte de saut</a> statique ou un <a href=\"https://en.wikipedia.org/wiki/Bastion_host\">hôte bastion</a> dans un centre de données.</p>\n\n<p>En implémentant une liste d'adresse IP autorisées, vous pouvez vous assurer que les personnes ne pourront se connecter qu'à partir de l'une des adresses IP pré-approuvées, ce qui réduit considérablement le risque d'une violation en cas de fuite de vos clés privées ou de vos mots de passe.</p>\n\n<p><span class='note'><strong>Remarque :</strong> veillez à identifier les adresses IP correctes à ajouter à votre liste d'adresse autorisées et à vous assurer il ne s'agit pas d'adresses flottantes ou dynamiques susceptibles de changer régulièrement, comme c'est souvent le cas avec les fournisseurs de services Internet grand public.<br></span></p>\n\n<p>Vous pouvez identifier l'adresse IP avec laquelle vous vous connectez actuellement à votre serveur en utilisant la commande <code>w</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">w\n</li></ul></code></pre>\n<p>Il en résultera quelque chose de similaire à ce qui suit :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div> 14:11:48 up 2 days, 12:25,  1 user,  load average: 0.00, 0.00, 0.00\n         USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT\n<span class=\"highlight\">your_username</span>     pts/0    <span class=\"highlight\">203.0.113.1</span>     12:24    1.00s  0.20s  0.00s w\n</code></pre>\n<p>Localisez votre compte utilisateur dans la liste et prenez note de l'adresse IP connectée. Ici, nous utilisons l'IP <code><span class=\"highlight\">203.0.113.1</span></code> à titre d'exemple</p>\n\n<p>Pour commencer à implémenter votre liste d'adresse IP autorisées, ouvrez le fichier de configuration du serveur OpenSSH dans votre éditeur de texte préféré :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ssh/sshd_config\n</li></ul></code></pre>\n<p>Vous pouvez implémenter des listes d'adresse IP autorisées en utilisant la directive de configuration <code>AllowUsers</code> qui restreint les authentifications des utilisateurs en fonction du nom d'utilisateur ou de l'adresse IP.</p>\n\n<p>La configuration et les exigences de votre système détermineront la configuration spécifique la plus appropriée. Les exemples suivants vous aideront à identifier la plus appropriée :</p>\n\n<ul>\n<li>Restreindre tous les utilisateurs à une adresse IP spécifique :</li>\n</ul>\n<pre class=\"code-pre \"><code>AllowUsers *@<span class=\"highlight\">203.0.113.1</span>\n</code></pre>\n<ul>\n<li>Restreindre tous les utilisateurs à une plage d'adresse IP spécifique en utilisant la <a href=\"https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing\">notation Classless Inter-Domain Routing (CIDR)</a> :</li>\n</ul>\n<pre class=\"code-pre \"><code>AllowUsers *@<span class=\"highlight\">203.0.113.0/24</span>\n</code></pre>\n<ul>\n<li>Restreindre tous les utilisateurs à une plage d'adresse IP spécifique (en utilisant des jokers) :</li>\n</ul>\n<pre class=\"code-pre \"><code>AllowUsers *@<span class=\"highlight\">203.0.113.*</span>\n</code></pre>\n<ul>\n<li>Restreindre tous les utilisateurs à plusieurs adresses IP et à plusieurs plages spécifiques :</li>\n</ul>\n<pre class=\"code-pre \"><code>AllowUsers *@<span class=\"highlight\">203.0.113.1</span> *@<span class=\"highlight\">203.0.113.2</span> *@<span class=\"highlight\">192.0.2.0/24</span> *@<span class=\"highlight\">172.16.*.1</span>\n</code></pre>\n<ul>\n<li>Interdire tous les utilisateurs à l'exception des utilisateurs nommés à partir d'adresses IP spécifiques :</li>\n</ul>\n<pre class=\"code-pre \"><code>AllowUsers <span class=\"highlight\">sammy</span>@<span class=\"highlight\">203.0.113.1</span> <span class=\"highlight\">alex</span>@203.0.113.2&lt;^&gt;\n</code></pre>\n<ul>\n<li>Restreindre un utilisateur spécifique à une adresse IP spécifique, tout en continuant à permettre à tous les autres utilisateurs de se connecter sans restriction :</li>\n</ul>\n<pre class=\"code-pre \"><code>Match User <span class=\"highlight\">ashley</span>\n  AllowUsers <span class=\"highlight\">ashley</span>@<span class=\"highlight\">203.0.113.1</span>\n</code></pre>\n<p><span class='warning'><strong>Avertissement :</strong> Dans un fichier de configuration OpenSSH, toutes les configurations sous un bloc <code>Match</code> ne s'appliqueront qu'aux connexions qui correspondent aux critères, indépendamment de l'indentation ou des sauts de ligne. Cela signifie que vous devez être prudent et vous assurer que les configurations destinées à s'appliquer globalement ne sont pas accidentellement placées dans un bloc <code>Match</code>. Il est recommandé de placer tous les blocs <code>Match</code> au bas/à la fin de votre fichier de configuration pour éviter cela.<br></span></p>\n\n<p>Une fois que vous avez terminé votre configuration, ajoutez-la au bas de votre fichier de configuration OpenSSH :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>AllowUsers *@<span class=\"highlight\">203.0.113.1</span>\n</code></pre>\n<p>Enregistrez et fermez le fichier, puis testez la syntaxe de votre configuration :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo sshd -t\n</li></ul></code></pre>\n<p>Si aucune erreur n'est signalée, vous pouvez recharger le serveur OpenSSH pour appliquer votre configuration :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo service sshd reload\n</li></ul></code></pre>\n<p>Dans cette étape, vous avez implémenté une liste d'adresse IP autorisées sur votre serveur OpenSSH. Ensuite, vous allez restreindre le shell d'un utilisateur à limiter les commandes qu'il est autorisé à utiliser.</p>\n\n<h2 id=\"Étape-3-—-restreindre-le-shell-d-39-un-utilisateur\">Étape 3 — Restreindre le Shell d'un utilisateur</h2>\n\n<p>Dans cette étape, vous examinerez les différentes options pour restreindre le shell d'un utilisateur SSH.</p>\n\n<p>En plus de fournir un accès distant au shell, SSH est également très utile pour le transfert de fichiers et d'autres données, par exemple, via SFTP. Cependant, vous ne voudrez peut-être pas toujours accorder un accès en shell complet aux utilisateurs lorsqu'ils doivent seulement pouvoir effectuer des transferts de fichier.</p>\n\n<p>Il existe plusieurs configurations au sein du serveur OpenSSH que vous pouvez utiliser pour restreindre l'environnement shell d'utilisateurs particuliers. Par exemple, dans ce tutoriel, nous les utiliserons pour créer des utilisateurs uniquement SFTP.</p>\n\n<p>Tout d'abord, vous pouvez utiliser le shell <code>/usr/sbin/nologin</code> pour désactiver les connexions interactives de certains comptes utilisateurs, tout en permettant aux sessions non interactives de fonctionner, comme les transferts de fichiers, le tunneling, etc.</p>\n\n<p>Pour créer un nouvel utilisateur avec le shell <code>nologin</code>, utilisez la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo adduser --shell /usr/sbin/nologin <span class=\"highlight\">alex</span>\n</li></ul></code></pre>\n<p>Vous pouvez également modifier le shell d'un utilisateur existant pour qu'il devienne <code>nologin</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo usermod --shell /usr/sbin/nologin <span class=\"highlight\">sammy</span>\n</li></ul></code></pre>\n<p>Si vous tentez ensuite de vous connecter de manière interactive en tant qu'un de ces utilisateurs, la requête sera rejetée :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo su <span class=\"highlight\">alex</span>\n</li></ul></code></pre>\n<p>Il en résultera quelque chose de similaire à ce message :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>This account is currently not available.\n</code></pre>\n<p>Malgré le message de rejet sur les connexions interactives, d'autres actions telles que les transferts de fichiers seront toujours autorisées.</p>\n\n<p>Ensuite, vous devriez combiner votre utilisation du shell <code>nologin</code> avec quelques options de configuration supplémentaires pour restreindre davantage les comptes d'utilisateurs pertinents.</p>\n\n<p>Commencez par ouvrir le fichier de configuration du serveur OpenSSH dans votre éditeur de texte préféré :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ssh/sshd_config\n</li></ul></code></pre>\n<p>Il existe deux options de configuration que vous pouvez implémenter ensemble pour créer un compte utilisateur uniquement SFTP très restreint : <code>ForceCommand internal-sftp</code> et <code>ChrootDirectory</code>.</p>\n\n<p>L'option <code>ForceCommand</code> dans le serveur OpenSSH force un utilisateur à exécuter une commande spécifique lors de sa connexion. Ceci peut être utile pour certaines communications de machine à machine, ou pour lancer de force un programme particulier.</p>\n\n<p>Cependant, dans ce cas, la commande <code>internal-sftp</code> est particulièrement utile. Il s'agit d'une fonction spéciale du serveur OpenSSH qui lance un démon de base en place qui ne nécessite aucun fichier ou configuration système.</p>\n\n<p>Idéalement, cette fonction devrait être combinée avec l'option <code>ChrootDirectory</code> qui va remplacer/changer le répertoire racine perçu d'un utilisateur particulier, en le limitant essentiellement à un répertoire spécifique du système.</p>\n\n<p>Ajoutez la section de configuration suivante à votre fichier de configuration OpenSSH pour ce faire :</p>\n<div class=\"code-label \" title=\"sshd_config\">sshd_config</div><pre class=\"code-pre sshd_config\"><code>Match User <span class=\"highlight\">alex</span>\n  ForceCommand internal-sftp\n  ChrootDirectory /home/<span class=\"highlight\">alex</span>/\n</code></pre>\n<p><span class='warning'><strong>Warning :</strong> comme indiqué à l'Étape 2, dans un fichier de configuration OpenSSH, toutes les configurations sous un bloc <code>Match</code> ne s'appliqueront qu'aux connexions qui correspondent aux critères, indépendamment de l'indentation ou des sauts de ligne. Cela signifie que vous devez être prudent et vous assurer que les configurations destinées à s'appliquer globalement ne sont pas accidentellement placées dans un bloc <code>Match</code>. Il est recommandé de placer tous les blocs <code>Match</code> au bas/à la fin de votre fichier de configuration pour éviter cela.<br></span></p>\n\n<p>Enregistrez et fermez votre fichier de configuration, puis testez à nouveau votre configuration :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo sshd -t\n</li></ul></code></pre>\n<p>S'il n'y a pas d'erreurs, vous pouvez alors appliquer votre configuration :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo service sshd reload\n</li></ul></code></pre>\n<p>Ceci a créé une configuration robuste pour l'utilisateur <code><span class=\"highlight\">alex</span></code>, où les connexions interactives sont désactivées, et toute l'activité SFTP est limitée au répertoire d'accueil de l'utilisateur. Du point de vue de l'utilisateur, la racine du système, c'est-à-dire <code>/</code>, est son répertoire d'accueil, et il ne pourra pas remonter le système de fichiers pour accéder à d'autres zones.</p>\n\n<p>Vous avez implémenté le shell <code>nologin</code> pour un utilisateur et vous avez ensuite créé une configuration pour restreindre l'accès SFTP à un répertoire spécifique.</p>\n\n<h2 id=\"Étape-4-—-durcissement-avancé\">Étape 4 — Durcissement avancé</h2>\n\n<p>Dans cette dernière étape, vous allez implémenter diverses mesures de durcissement supplémentaires pour rendre l'accès à votre serveur SSH aussi sécurisé que possible.</p>\n\n<p>Une fonction moins connue du serveur OpenSSH est la capacité d'imposer des restrictions sur une base par clé, c'est-à-dire des restrictions qui ne s'appliquent qu'aux clés publiques spécifiques présentes dans le fichier <code>.ssh/authorized_keys</code>. Ceci est particulièrement utile pour contrôler l'accès aux sessions de machine à machine, et pour permettre aux utilisateurs non sudo de contrôler les restrictions de leur propre compte utilisateur.</p>\n\n<p>Vous pouvez également appliquer la plupart de ces restrictions au niveau du système ou de l'utilisateur, mais il est toujours plus avantageux de les implémenter au niveau clé également afin de fournir une <a href=\"https://en.wikipedia.org/wiki/Defense_in_depth_(computing)\">défense en profondeur</a> et une sécurité supplémentaire en cas d'erreurs de configuration accidentelles à l'échelle du système.</p>\n\n<p><span class='note'><strong>Remarque :</strong> vous ne pouvez implémenter ces configurations de sécurité supplémentaires que si vous utilisez l'authentification par clé publique SSH. Si vous utilisez seulement l'authentification par mot de passe, ou si vous disposes d'une configuration plus complexe telle qu'une autorité de certification SSH, elles ne seront malheureusement pas utilisables.<br></span></p>\n\n<p>Commencez par ouvrir votre fichier <code>.ssh/authorized_keys</code> dans votre éditeur de texte préféré :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano ~/.ssh/authorized_keys\n</li></ul></code></pre>\n<p><span class='note'><strong>Note :</strong> Comme ces configurations s'appliquent à chaque clé, vous devrez modifier chaque clé individuelle dans chaque fichier <code>authorized_keys</code> auquel vous voulez qu'elles s'appliquent, pour tous les utilisateurs de votre système. En général, vous devrez seulement modifier qu'une seule clé/un seul fichier, mais cela vaut la peine d'être pris en considération si vous disposez d'un système multi-utilisateurs complexe.<br></span></p>\n\n<p>Une fois que vous aurez ouvert votre fichier <code>authorized_keys</code>, vous verrez que chaque ligne contient une clé publique SSH, qui commencera très probablement par quelque chose comme <code>ssh-rsa AAAB...</code> Des options de configuration supplémentaires peuvent être ajoutées au début de la ligne, et elles ne s'appliqueront qu'aux authentifications réussies avec cette clé publique spécifique.</p>\n\n<p>Les options de restriction suivantes sont disponibles :</p>\n\n<ul>\n<li><code>no-agent-forwarding</code> : désactiver le transfert de l'agent SSH.</li>\n<li><code>no-port-forwarding</code> : désactiver le transfert de port SSH.</li>\n<li><code>no-pty</code> : désactiver la capacité d'allouer un tty (c'est-à-dire lancer un shell).</li>\n<li><code>no-user-rc</code> : Empêcher l'exécution du fichier <code>~/.ssh/rc</code>.</li>\n<li><code>no-X11-forwarding</code> : désactiver le déport d'affichage X11.</li>\n</ul>\n\n<p>Vous pouvez les appliquer pour désactiver des fonctionnalités SSH spécifiques pour des clés spécifiques. Par exemple, pour désactiver le déport d'agent et le déport X11 pour une clé, vous utiliserez la configuration suivante :</p>\n<div class=\"code-label \" title=\"~/.ssh/authorized_keys\">~/.ssh/authorized_keys</div><pre class=\"code-pre authorized_keys\"><code>no-agent-forwarding,no-X11-forwarding ssh-rsa AAAB...\n</code></pre>\n<p>Par défaut, ces configurations fonctionnent en utilisant une méthode &ldquo;autoriser par défaut, bloquer par exception &rdquo; ; cependant, il est également possible d'utiliser &ldquo;bloquer par défaut, autoriser par exception &rdquo;, qui est généralement préférable pour assurer la sécurité.</p>\n\n<p>Vous pouvez le faire en utilisant l'option <code>restrict</code> qui reniera implicitement toutes les fonctionnalités SSH pour la clé spécifique, en exigeant qu'elles soient explicitement réactivées seulement lorsque cela est absolument nécessaire. Vous pouvez réactiver des fonctionnalités en utilisant les mêmes options de configuration décrites plus haut dans ce tutoriel, mais sans le préfixe <code>no-</code>.</p>\n\n<p>Par exemple, pour désactiver toutes les fonctionnalités SSH d'une clé particulière, à l'exception du déport d'affichage X11, vous pouvez utiliser la configuration suivante :</p>\n<div class=\"code-label \" title=\"~/.ssh/authorized_keys\">~/.ssh/authorized_keys</div><pre class=\"code-pre authorized_keys\"><code>restrict,X11-forwarding ssh-rsa AAAB...\n</code></pre>\n<p>Vous pouvez également envisager d'utiliser l'option <code>command</code>, qui est très similaire à l'option <code>ForceCommand</code> décrite à l'Étape 3. Cela n'apporte pas d'avantage direct si vous utilisez déjà <code>ForceCommand</code>, mais la mettre en place constitue une bonne défense en profondeur dans le cas (peu probable) où votre fichier de configuration principal du serveur OpenSSH serait écrasé, modifié, etc.</p>\n\n<p>Par exemple, pour forcer les utilisateurs qui s'authentifient avec une clé spécifique à exécuter une commande spécifique lors de leur connexion, vous pouvez ajouter la configuration suivante :</p>\n<div class=\"code-label \" title=\"~/.ssh/authorized_keys\">~/.ssh/authorized_keys</div><pre class=\"code-pre authorized_keys\"><code>command=\"<span class=\"highlight\">top</span>\" ssh-rsa AAAB...\n</code></pre>\n<p><span class='warning'><strong>Avertissement :</strong> l'option de configuration <code>command</code> agit purement comme méthode de défense en profondeur et ne doit pas être uniquement invoquée pour restreindre les activités d'un utilisateur SSH, car il existe des moyens potentiels de la remplacer ou de la contourner en fonction de votre environnement. Vous devriez plutôt utiliser la configuration en tandem avec les autres contrôles décrits dans cet article.<br></span></p>\n\n<p>Enfin, pour utiliser au mieux les restrictions par clé pour l'utilisateur uniquement SFTP que vous avez créé à l'Étape 3, vous pouvez utiliser la configuration suivante :</p>\n<div class=\"code-label \" title=\"~/.ssh/authorized_keys\">~/.ssh/authorized_keys</div><pre class=\"code-pre authorized_keys\"><code>restrict,command=\"false\" ssh-rsa AAAB...\n</code></pre>\n<p>L'option <code>restrict</code> désactivera tout accès interactif, et l'option <code>command=\"false\"</code> agit comme une deuxième ligne de défense au cas où l'option <code>ForceCommand</code> ou le shell <code>nologin</code> devaient échouer.</p>\n\n<p>Enregistrez et fermez le fichier pour appliquer la configuration. Cela prendra effet immédiatement pour tous les nouveaux logins, vous n'avez donc pas besoin de recharger OpenSSH manuellement.</p>\n\n<p>Dans cette étape, vous avez implémenté des mesures de durcissement avancées supplémentaires pour le serveur OpenSSH en utilisant les options personnalisées dans votre (vos) fichier(s) <code>.ssh/authorized_keys</code>.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans cet article, vous avez passé en revue la configuration de votre serveur OpenSSH et implémenté diverses mesures de durcissement pour aider à sécuriser votre serveur.</p>\n\n<p>Cela aura permis de réduire la surface d'attaque globale de votre serveur en désactivant les fonctionnalités inutilisées et en bloquant l'accès à des utilisateurs spécifiques.</p>\n\n<p>Vous pouvez consulter les <a href=\"https://linux.die.net/man/8/sshd\">pages du manuel pour le serveur OpenSSH</a> et son <a href=\"https://linux.die.net/man/5/sshd_config\">fichier de configuration</a> associé, pour identifier tout autre ajustement potentiel que vous souhaiteriez apporter.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:14 +0000","feedId":8037,"bgimg":"","linkMd5":"9ec78c5a13ca66e46ba1c8f44fe07192","bgimgJsdelivr":"","metaImg":"","author":"Jamie Scaife","publishedOrCreatedDate":1598860106980},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment installer TensorFlow sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-tensorflow-on-ubuntu-20-04-fr","description":"<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://www.tensorflow.org/\">TensorFlow</a> est une bibliothèque de logiciels d'apprentissage automatique open-source, utilisée pour former des réseaux neuronaux. Exprimé sous la forme de <a href=\"https://www.tensorflow.org/programmers_guide/graphs\">graphiques de flux de données dynamiques</a>, chaque nœud du graphique représente les opérations effectuées par les réseaux neuronaux sur des tableaux multidimensionnels. Ces tableaux multidimensionnels sont communément appelés &ldquo;tensors&rdquo;, d'où le nom de TensorFlow.</p>\n\n<p>Dans ce tutoriel, vous allez installer TensorFlow dans un environnement virtuel Python avec <code>virtualenv</code>. Cette approche permet d'isoler l'installation TensorFlow et de mettre rapidement les choses en place. Une fois l'installation terminée, vous la validerez en important Tensorflow pour vous assurer qu'il n'y a pas d'erreurs.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Avant de commencer ce tutoriel, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li><p>Un serveur Ubuntu 20.04 avec au moins *<em>4 Go de RAM *</em>configuré en suivant le guide <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Configuration initiale du serveur Ubuntu 20.04</a>, comprenant un non-root user avec privilèges sudo et un pare-feu.</p></li>\n<li><p>Python 3.8 ou supérieur et <code>virtualenv</code> installés. Suivez <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-programming-environment-on-an-ubuntu-20-04-server\">Comment installer Python 3 sur Ubuntu 20.04</a> pour configurer Python et <code>virtualenv</code>.</p></li>\n</ul>\n\n<h2 id=\"Étape-1-—-création-d-39-un-environnement-de-programmation\">Étape 1 — Création d'un environnement de programmation</h2>\n\n<p>Au cours de cette étape, nous allons créer un environnement virtuel afin d'y installer TensorFlow sans compromettre nos autres projets de programmation. Si vous avez configuré un environnement de programmation propre, n'hésitez pas à sauter cette étape.</p>\n\n<p>Tout d'abord, créez un répertoire de projets. Nous l'appellerons <code>tf-demo</code> à des fins de démonstration, mais choisissez un nom de répertoire qui soit significatif pour vous :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Naviguez vers votre répertoire <code>tf-demo</code> nouvellement créé :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Créez ensuite un nouvel environnement virtuel appelé <code>tensorflow-dev</code>, par exemple. Exécutez la commande suivante pour créer l'environnement :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python3 -m venv <span class=\"highlight\">tensorflow-dev</span>\n</li></ul></code></pre>\n<p>Cette action entraine la création d'un nouveau répertoire <code>tensorflow-dev</code> qui contiendra tous les paquets que vous installez lorsque cet environnement est activé. Il comprend également <code>pip</code> et une version autonome de Python.</p>\n\n<p>Activez maintenant votre environnement virtuel :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">source <span class=\"highlight\">tensorflow-dev</span>/bin/activate\n</li></ul></code></pre>\n<p>Une fois activé, l'invite de votre terminal indiquera que vous êtes dans l'environnement virtuel :</p>\n<pre class=\"code-pre \"><code>(<span class=\"highlight\">tensorflow-dev</span>)username@hostname:~/tf-demo $\n</code></pre>\n<p>À ce stade, vous pouvez installer TensorFlow dans votre environnement virtuel.</p>\n\n<h2 id=\"Étape-2-—-installation-de-tensorflow\">Étape 2 — Installation de TensorFlow</h2>\n\n<p>Lors de l'installation de TensorFlow, nous voulons nous assurer que nous installons et mettons à jour la dernière version disponible dans <a href=\"https://pypi.python.org/pypi\">PyPi</a>.</p>\n\n<p>Par conséquent, nous utiliserons la commande syntax suivante avec pip :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">pip install --upgrade tensorflow\n</li></ul></code></pre>\n<p>Dès lors que vous aurez appuyé sur <code>ENTER</code> (ENTRÉE), TensorFlow s'installera, et vous devriez recevoir un message indiquant que son installation, ainsi que celles de tous les paquets dépendants, ont réussi.</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nSuccessfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 numpy-1.16.2 pbr-5.1.3 protobuf-3.7.0 setuptools-40.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.0 wheel-0.33.1\n...\n\nSuccessfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 markdown-2.6.9 numpy-1.13.3 protobuf-3.5.0.post1 setuptools-38.2.3 six-1.11.0 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0rc3 werkzeug-0.12.2 wheel-0.30.0\n</code></pre>\n<span class='note'><p>\nVous pouvez désactiver votre environnement virtuel à tout moment en utilisant la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">deactivate\n</li></ul></code></pre>\n<p>Pour réactiver l'environnement plus tard, naviguez dans le répertoire de votre projet et exécutez le <code>source <span class=\"highlight\">tensorflow-dev</span>/bin/activate</code>.<br></p></span>\n\n<p>Maintenant que vous avez installé TensorFlow, assurons-nous que l'installation de TensorFlow fonctionne.</p>\n\n<h2 id=\"Étape-3-—-validation-de-l-39-installation\">Étape 3 — Validation de l'installation</h2>\n\n<p>Pour valider l'installation de TensorFlow, nous allons nous assurer que nous pouvons importer le paquet TensorFlow.</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">python\n</li></ul></code></pre>\n<p>L'invite suivante apparaîtra sur votre terminal :</p>\n<pre class=\"code-pre \"><code>&gt;&gt;&gt;\n</code></pre>\n<p>C'est l'invite de l'interpréteur Python, et il indique qu'il est prêt à ce que vous commenciez à entrer quelques instructions Python.</p>\n\n<p>Tout d'abord, tapez cette ligne pour importer le paquet TensorFlow et le rendre disponible comme variable locale <code>tf</code>. Appuyez sur <code>ENTER</code> après avoir tapé dans la ligne de code :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;&gt;&gt;\">import tensorflow as tf\n</li></ul></code></pre>\n<p>Tant que vous n'avez reçu aucune erreur, vous avez installé TensorFlow avec succès. Si vous avez reçu un message d'erreur, vous devez vous assurer que votre serveur est suffisamment puissant pour gérer TensorFlow. Vous devrez peut-être redimensionner votre serveur, en vous assurant qu'il dispose d'au moins 4 Go de mémoire.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans ce tutoriel, vous avez installé TensorFlow dans un environnement virtuel Python et validé que TensorFlow fonctionne en l'important.</p>\n\n<p><a href=\"https://www.tensorflow.org/programmers_guide/\">Le guide du programmeur</a> de TensorFlow constitue une ressource et une référence utile pour le développement de TensorFlow. Vous pouvez également explorer <a href=\"https://www.kaggle.com/\">Kaggle</a>, un environnement compétitif pour l'application pratique des concepts d'apprentissage machine qui vous met en concurrence avec d'autres passionnés d'apprentissage machine, de science des données et de statistiques.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:20 +0000","feedId":8037,"bgimg":"","linkMd5":"b0ae0d2381b1493adc85ad2ec8c1f1b7","bgimgJsdelivr":"","metaImg":"","author":"Lisa Tagliaferri","publishedOrCreatedDate":1598860106974},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como criar um bot no Discord com o Node.js","link":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-pt","description":"<p><em>O autor selecionou o <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> para receber uma doação como parte do programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introdução\">Introdução</h3>\n\n<p>O <a href=\"https://discord.com/\">Discord</a> é um aplicativo de chat que permite a milhões de usuários em todo o mundo enviar mensagens e bate-papo de voz online em comunidades chamadas <a href=\"https://discord.com/developers/docs/resources/guild\">guilds</a> ou servidores. O Discord também fornece uma extensa API que os desenvolvedores podem usar para criar poderosos bots no Discord. Os bots podem realizar várias ações, como enviar mensagens para servidores, enviar mensagens diretas a usuários, moderar servidores e reproduzir áudio em conversas de voz. Isso permite que desenvolvedores criem robôs poderosos que incluem recursos avançados e complexos, como ferramentas de moderação ou até mesmo jogos. Por exemplo, o bot utilitário <a href=\"https://dyno.gg/bot\">Dyno</a> serve milhões de guilds e contém recursos úteis, como proteção contra spam, um reprodutor de música e outras funções utilitárias. Aprender como criar bots no Discord lhe permite implementar muitas possibilidades, com as quais milhares de pessoas poderiam interagir todos os dias.</p>\n\n<p>Neste tutorial, você irá criar um bot Discord a partir do zero, usando o <a href=\"https://nodejs.org/en/\">Node.js</a> e a biblioteca <a href=\"https://discord.js.org/#/\">Discord.js</a>, que permite aos usuários interagir diretamente com a API do Discord. Você irá configurar um perfil para um bot do Discord, obter tokens de autenticação para o bot, e programá-lo com a capacidade de processar comandos, com argumentos, dos usuários.</p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Antes de começar, você precisará do seguinte:</p>\n\n<ul>\n<li><p>Node.js instalado em sua máquina de desenvolvimento. Para instalar essa versão em macOS ou Ubuntu 18.04, siga os passos descritos no artigo sobre <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">Como instalar o Node.js e criar um ambiente de desenvolvimento local em macOS</a> ou a seção intitulada <strong>Instalando e usando um PPA</strong>, do artigo sobre <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">Como instalar o Node.js no Ubuntu 18.04</a>.</p></li>\n<li><p>Qualquer editor de texto de sua escolha, como o <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>, <a href=\"https://atom.io\">Atom</a>, <a href=\"https://www.sublimetext.com/\">Sublime</a> ou <a href=\"https://www.nano-editor.org/\">Nano</a>.</p></li>\n<li><p>Uma <a href=\"https://discord.com/register\">conta Discord gratuita</a> com uma conta de e-mail verificada e um <a href=\"https://support.discord.com/hc/en-us/articles/204849977-How-do-I-create-a-server-\">servidor Discord gratuito</a> que você usará para testar seu bot Discord.</p></li>\n</ul>\n\n<h2 id=\"passo-1-—-configurando-um-bot-discord\">Passo 1 — Configurando um bot Discord</h2>\n\n<p>Neste passo você usará a GUI de desenvolvedores do Discord para configurar um bot Discord e obter o token do bot, que você passará para o seu programa.</p>\n\n<p>Para registrar um bot na plataforma Discord, use o <a href=\"https://discord.com/developers/applications/\">painel da aplicação Discord</a>. Aqui os desenvolvedores podem criar aplicações Discord, incluindo bots Discord.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png\" alt=\"Image of the Discord application dashboard after first visiting https://discord.com/developers/applications\"></p>\n\n<p>Para começar, clique em <strong>New Application</strong>. O Discord vai lhe pedir que digite um nome para a sua nova aplicação. Em seguida, clique em <strong>Create</strong> para criar a aplicação.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1b.png\" alt='Image of the prompt to create an application, with \"Test Node.js Bot\" entered as the name of the application'></p>\n\n<p><span class='note'><strong>Nota:</strong> o nome para sua aplicação é independente do nome do bot, e o bot não precisa ter o mesmo nome que a aplicação.<br></span></p>\n\n<p>Agora, abra seu painel de aplicação. Para adicionar um bot à aplicação, navegue até a guia <strong>Bot</strong> na barra de navegação à esquerda.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1c.png\" alt=\"Image of the bot tab of the application dashboard\"></p>\n\n<p>Clique no botão <strong>Add Bot</strong> para adicionar um bot à aplicação. Clique no botão <strong>Yes, do it!</strong> quando ele lhe pedir confirmação. Você estará então em um painel contendo detalhes do nome do seu bot, token de autenticação e foto do perfil.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1d.png\" alt=\"Dashboard containing details of your bot\"></p>\n\n<p>Você pode modificar o nome do seu bot ou a imagem do perfil aqui no painel. Você também precisa copiar o token de autenticação do bot, clicando em <strong>Click to Reveal Token</strong> e copiando o token que aparece.</p>\n\n<p><span class='warning'><strong>Atenção:</strong> nunca compartilhe ou faça o upload do seu token do bot, pois ele permite que alguém faça login no seu bot.<br></span></p>\n\n<p>Agora, você precisa criar um convite que lhe permita adicionar as guilds do bot Discord onde você pode testar o bot. Primeiro, navegue até a guia <strong>OAuth2</strong> do painel da aplicação. Para criar um convite, desça e selecione <strong>bot</strong> abaixo de <strong>scopes</strong> Você também deve definir permissões para controlar quais ações o seu bot pode realizar nas guilds. Para os propósitos deste tutorial, selecione <strong>Administrator</strong>, que dará ao seu bot permissão para realizar quase todas as ações nas guilds. Copie o link com o botão <strong>Copy</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1e.png\" alt='OAuth2 tab, with scope set to \"bot\" and permissions set to \"administator\"'></p>\n\n<p>Em seguida, adicione o bot a um servidor. Siga o link do convite que você acabou de criar. Você pode adicionar o bot a qualquer servidor que você possua, ou que tenha permissões de administrador, a partir do menu suspenso.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1f.png\" alt=\"Page from following the invite link, allowing users to add the bot to servers\"></p>\n\n<p>Agora, clique em <strong>Continue</strong>. Certifique-se de que a caixa de seleção ao lado de <strong>Administrator</strong> esteja assinalada — isso concederá ao bot permissões de administrador. Em seguida, clique em <strong>Authorize</strong>. O Discord irá lhe pedir que resolva um <a href=\"https://en.wikipedia.org/wiki/CAPTCHA\">CAPTCHA</a> antes que o bot se junte ao servidor. Agora, você terá o bot Discord na lista de membros no servidor que você adicionou o bot, abaixo de <strong>offline</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1g.png\" alt='Members list of a Discord server with the newly created bot under the \"offline\" section of the members list'></p>\n\n<p>Você criou com sucesso um bot Discord e o adicionou a um servidor. Em seguida, você irá escrever um programa para fazer login no bot.</p>\n\n<h2 id=\"passo-2-—-criando-o-seu-projeto\">Passo 2 — Criando o seu projeto</h2>\n\n<p>Neste passo, você irá configurar o ambiente de codificação básico onde você irá criar seu bot e fazer login nele programaticamente.</p>\n\n<p>Primeiro, você precisa configurar uma pasta de projeto e os arquivos de projeto necessários para o bot.</p>\n\n<p>Crie sua pasta de projeto:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Vá para a pasta do projeto que você acabou de criar:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Em seguida, use seu editor de texto para criar um arquivo chamado <code>config.json</code> para armazenar o token de autenticação do seu bot:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano config.json\n</li></ul></code></pre>\n<p>Em seguida, adicione o seguinte código ao arquivo de configuração, substituindo o texto destacado pelo token de autenticação do seu bot:</p>\n<div class=\"code-label \" title=\"config.json\">config.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">{\n    \"BOT_TOKEN\": \"<span class=\"highlight\">YOUR BOT TOKEN</span>\"\n}\n</code></pre>\n<p>Salve e saia do arquivo.</p>\n\n<p>Em seguida, você irá criar um arquivo <code>package.json</code>, que irá armazenar detalhes do seu projeto e informações sobre as dependências que você usará para o projeto. Você irá criar um arquivo <code>package.json</code> executando o seguinte comando <code>npm</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm init\n</li></ul></code></pre>\n<p>O <code>npm</code> irá lhe perguntar vários detalhes sobre seu projeto. Se você quiser orientação sobre como preencher esses prompts, pode ler sobre eles em <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-node-js-modules-with-npm-and-package-json#step-1-%E2%80%94-creating-a-packagejson-file\">How To Use Node.js Modules with npm and package.json</a>.</p>\n\n<p>Agora, você irá instalar o pacote <code>discord.js</code> que você usará para interagir com a API do Discord. Você pode instalar <code>discord.js</code> através do npm com o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm install discord.js\n</li></ul></code></pre>\n<p>Agora que você definiu o arquivo de configuração e instalou a dependência necessária, você está pronto para começar a criar seu bot. Em uma aplicação no mundo real, um bot grande seria dividido em muitos arquivos, mas para os fins deste tutorial, o código para o bot estará em um único arquivo.</p>\n\n<p>Primeiro, crie um arquivo chamado <code>index.js</code> na pasta <code><span class=\"highlight\">discord-bot</span></code> para o código:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Comece a codificação do bot exigindo a dependência <code>discord.js</code> e o arquivo de configuração com o token do bot:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n</code></pre>\n<p>Após isso, adicione as duas linhas de código seguintes:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Salve e saia do seu arquivo.</p>\n\n<p>A primeira linha de código cria um novo <code>Discord.Client</code> e o atribui à constante <code>client</code>. Este cliente, em parte, é como você irá interagir com a API do Discord e como o Discord irá notificá-lo de eventos como novas mensagens. O client e, na verdade, representa o bot Discord.</p>\n\n<p>A segunda linha de código usa o método <code>login</code> no <code>client</code> para fazer login no bot Discord que você criou, usando o token no arquivo <code>config.json</code> como uma senha. O token permite que a API do Discord saiba a qual bot o programa se destina e que você está autenticado para usar o bot.</p>\n\n<p>Agora, execute o arquivo <code>index.js</code> usando o Node:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>O status do seu bot irá se alterar para online no servidor Discord ao qual você o adicionou.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step2a.png\" alt=\"Image of the bot online\"></p>\n\n<p>Você criou com sucesso um ambiente de codificação e criou o código básico para fazer login em um bot Discord. No próximo passo, você irá lidar com comandos de usuário e fazer com que seu bot execute ações, como o envio de mensagens.</p>\n\n<h2 id=\"passo-3-—-lidando-com-seu-primeiro-comando-de-usuário\">Passo 3 — Lidando com seu primeiro comando de usuário</h2>\n\n<p>Neste passo, você irá criar um bot que possa lidar com comandos de usuário. Você irá implementar seu primeiro comando <code>ping</code>, que irá responder com <code>\"pong\"</code> e o tempo necessário para responder ao comando.</p>\n\n<p>Primeiro, você precisa detectar e receber quaisquer mensagens que os usuários enviam para que você possa processar quaisquer comandos. Usando o método <code>on</code> no cliente Discord, o Discord irá lhe enviar uma notificação sobre novos eventos. O método <code>on</code> leva dois argumentos: o nome de um evento para esperar e uma função a executar cada vez que esse evento ocorre. Com este método, você pode esperar pelo evento <code>message</code> — isso ocorrerá cada vez que uma mensagem for enviada a uma guild onde o bot tiver a permissão para visualizar mensagens. Portanto, vamos criar uma função que será executada cada vez que uma mensagem for enviada, para processar comandos.</p>\n\n<p>Primeiro abra seu arquivo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Adicione o código a seguir ao seu arquivo:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\n\n<span class=\"highlight\">client.on(\"message\", function(message) { </span>\n<span class=\"highlight\">                                         </span>\n<span class=\"highlight\">});                                      </span>\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Essa função, que executa no evento <code>message</code>, toma <code>message</code> como um parâmetro. <code>message</code> terá o valor de uma instância <a href=\"https://discord.js.org/#/docs/main/stable/class/Message\">Discord.js message</a>, que contém informações sobre a mensagem enviada e os métodos para ajudar o bot a responder.</p>\n\n<p>Agora, adicione a seguinte linha de código à sua função de tratamento de comandos:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  <span class=\"highlight\">if (message.author.bot) return;</span>\n});\n...\n</code></pre>\n<p>Essa linha verifica se o autor da mensagem é um bot e, se assim for, para de processar o comando. Isso é importante, pois geralmente você não quer processar ou responder a mensagens de bots. Os bots geralmente não precisam ou não querem usar nosso bot, portanto, ignorar suas mensagens economiza energia de processamento e ajuda a evitar respostas acidentais.</p>\n\n<p>Agora, você irá escrever um handler de comando. Para realizar isso, é bom entender o formato usual de um comando Discord. Normalmente, a estrutura de um comando Discord contém três partes na seguinte ordem: um prefixo, um nome de comando e, às vezes, argumentos de comando.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png\" alt='An image of a typical Discord command reading \"! add 1 2\" '></p>\n\n<ul>\n<li><p>Prefix: o prefixo pode ser qualquer coisa, mas normalmente é um pedaço de pontuação ou frase abstrata que normalmente não estaria no início de uma mensagem. Isso significa que quando você incluir o prefixo no início da mensagem, o bot irá saber que a intenção para este comando é para um bot processá-lo.</p></li>\n<li><p>Command name: o nome do comando que o usuário quer usar. Isso significa que o bot pode suportar vários comandos com diferentes funcionalidades e permitir aos usuários escolher entre eles fornecendo um nome de comando diferente.</p></li>\n<li><p>Arguments: às vezes, se o comando exigir ou usar informações extras do usuário, o usuário pode fornecer argumentos após o nome do comando, com cada argumento separado por um espaço.</p></li>\n</ul>\n\n<p><span class='note'><strong>Nota:</strong> não há nenhuma estrutura de comando obrigatória, e os bots podem processar comandos como eles quiserem, mas a estrutura aqui apresentada é uma estrutura eficiente que a grande maioria dos bots usam.<br></span></p>\n\n<p>Para começar a criar um parser de comando que lida com este formato, adicione as seguintes linhas de código à função de tratamento de mensagens:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n<span class=\"highlight\">const prefix = \"!\";</span>\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  <span class=\"highlight\">if (!message.content.startsWith(prefix)) return;</span>\n});\n...\n</code></pre>\n<p>Você adiciona a primeira linha de código para atribuir o valor <code>\"!\"</code> à constante <code>prefix</code>, que você usará como o prefixo do bot.</p>\n\n<p>A segunda linha de código que você adiciona , verifica se o conteúdo da mensagem que o bot está processando começa com o prefixo que você definiu e, se não começar, interrompe o processamento da mensagem.</p>\n\n<p>Agora, converta o resto da mensagem em um nome de comando e todos os argumentos da mensagem. Adicione as linhas destacadas a seguir:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  <span class=\"highlight\">const commandBody = message.content.slice(prefix.length);</span>\n  <span class=\"highlight\">const args = commandBody.split(' ');</span>\n  <span class=\"highlight\">const command = args.shift().toLowerCase();</span>\n});\n...\n</code></pre>\n<p>Você usa a primeira linha aqui para remover o prefixo do conteúdo da mensagem e atribuir o resultado à constante <code>commandBody</code>. Isso é necessário, uma vez que você não quer incluir o prefixo no nome de comando no qual você fez a varredura.</p>\n\n<p>A segunda linha pega a mensagem com o prefixo removido e usa o <a href=\"https://www.digitalocean.com/community/tutorials/how-to-index-split-and-manipulate-strings-in-javascript#splitting-strings\">método <code>split</code></a> nela, com um espaço como separador. Isso a divide em um array de sub-strings, fazendo uma divisão onde quer que haja um espaço. Isso resulta em um array contendo o nome do comando e, se incluído na mensagem, quaisquer argumentos. Você atribui este array à constante <code>args</code>.</p>\n\n<p>A terceira linha remove o primeiro elemento do array <code>args</code> (que será o nome de comando fornecido), o converte em minúsculas e, em seguida, o atribui à constante <code>command</code>. Isso lhe permite isolar o nome do comando e deixar apenas argumentos no array. Você também usa o método <code>toLowerCase</code>, pois os comandos normalmente não diferenciam maiúsculas de minúsculas em bots do Discord.</p>\n\n<p>Você concluiu a construção de um parser de comando, implementando um prefixo necessário e obtendo o nome do comando e quaisquer argumentos das mensagens. Agora, você irá implementar e criar o código para os comandos específicos.</p>\n\n<p>Adicione o código a seguir para iniciar a implementação do comando <code>ping</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  <span class=\"highlight\">if (command === \"ping\") {</span>\n  <span class=\"highlight\">                         </span>\n  <span class=\"highlight\">}                        </span>\n});\n...\n</code></pre>\n<p>Esta <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-conditional-statements-in-javascript\">declaração <code>if</code></a> verifica se o nome de comando que você analisou (atribuído à constante <code>command</code>) corresponde ao <code>\"ping\"</code>. Se sim, isso indica que o usuário quer usar o comando <code>\"ping\"</code>. Você irá aninhar o código para o comando específico dentro do bloco da declaração <code>if</code>. Você irá repetir este padrão para outros comandos que você deseja implementar.</p>\n\n<p>Agora, você pode implementar o código para o comando <code>\"ping\"</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    <span class=\"highlight\">const timeTaken = Date.now() - message.createdTimestamp;</span>\n    <span class=\"highlight\">message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);</span>\n  }\n...\n</code></pre>\n<p>Salve e saia do seu arquivo.</p>\n\n<p>Você adiciona o bloco do comando <code>\"ping\"</code> que calcula a diferença entre o tempo atual — encontrado usando o <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now\">método <code>now</code></a> no objeto <code>Date</code> — e o timestamp de quando a mensagem foi criada em milisegundos. Isso calcula quanto tempo a mensagem levou para processar o <code>\"ping\"</code> do bot.</p>\n\n<p>A segunda linha responde ao comando do usuário usando o método <code>reply</code> na constante <code>message</code>. O <a href=\"https://discord.js.org/#/docs/main/stable/class/Message?scrollTo=reply\">método <code>reply</code></a> faz um ping (que notifica o usuário e destaca a mensagem para o usuário especificado) no usuário que invocou o comando, seguido pelo conteúdo fornecido como o primeiro argumento para o método. Você fornece um <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">modelo literal</a> contendo uma mensagem e o ping calculado como a resposta que o método <code>reply</code> usará.</p>\n\n<p>Isso conclui a implementação do comando <code>\"ping\"</code>.</p>\n\n<p>Execute seu bot usando o comando a seguir (na mesma pasta que <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Agora, use o comando <code>\"! ping\"</code>&ldquo; em qualquer canal onde o bot possa visualizar e enviar mensagens, resultando em uma resposta.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png\" alt='Image of bot replying in Discord to \"! ping\" with \"@T0M, Pong! This message had a latency of 1128ms.\"'></p>\n\n<p>Você criou com sucesso um bot que pode lidar com comandos de usuário e implementou seu primeiro comando. No próximo passo, você irá continuar desenvolvendo seu bot implementando um comando sum.</p>\n\n<h2 id=\"passo-4-—-implementando-o-comando-sum\">Passo 4 — Implementando o comando Sum</h2>\n\n<p>Agora, você irá estender seu programa implementando o comando <code>\"! sum\"</code>. O comando irá tomar qualquer número de argumentos e adicioná-los juntos, antes de retornar a soma de todos os argumentos ao usuário.</p>\n\n<p>Se seu bot Discord ainda estiver em execução, você pode parar seu processo com <code>CTRL + C</code>.</p>\n\n<p>Abra seu arquivo <code>index.js</code> novamente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Para começar a implementar o comando <code>\"! sum\"</code>, você usará um bloco <code>else-if</code>. Depois de verificar o nome do comando ping, ele irá verificar se o nome do comando é igual a <code>\"sum\"</code>. Usamos um bloco <code>else-if</code> já que apenas um comando irá processar de cada vez, então se o programa corresponder ao nome de comando <code>\"ping\"</code>, ele não precisa verificar o comando <code>\"sum\"</code>. Adicione as seguintes linhas destacadas ao seu arquivo:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Ping! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  <span class=\"highlight\">else if (command === \"sum\") {</span>\n  <span class=\"highlight\">                             </span>\n  <span class=\"highlight\">}                            </span>\n});\n...\n</code></pre>\n<p>Você pode começar a implementar o código para o comando <code>\"sum\"</code>. O código para o comando <code>\"sum\"</code> irá entrar dentro do bloco <code>else-if</code> que você acabou de criar. Agora, adicione o código a seguir:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  else if (command === \"sum\") {\n    <span class=\"highlight\">const numArgs = args.map(x =&gt; parseFloat(x));</span>\n    <span class=\"highlight\">const sum = numArgs.reduce((counter, x) =&gt; counter += x);</span>\n    <span class=\"highlight\">message.reply(`The sum of all the arguments you provided is ${sum}!`);</span>\n  }\n...\n</code></pre>\n<p>Você usa o <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#map()\">método <code>map</code></a> na lista argumentos para criar uma nova lista usando a função <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseFloat\"><code>parseFloat</code></a> em cada item no array <code>args</code>. Isso cria um novo array (atribuído à constante <code>numArgs</code>) no qual todos os itens são números em vez de strings. Isso significa que mais tarde você pode encontrar com sucesso a soma dos números adicionando-os.</p>\n\n<p>A segunda linha usa o <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#reduce()\">método <code>reduce</code></a> na constante <code>numArgs</code>, fornecendo uma função que totaliza todos os elementos na lista. Você atribui a soma de todos os elementos em <code>numArgs</code> à constante. <code>sum</code>.</p>\n\n<p>Em seguida, você usa o método <code>reply</code> no objeto message para responder ao comando do usuário com <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">modelo literal</a>, que contém a soma de todos os argumentos que o usuário envia para o bot.</p>\n\n<p>Isso conclui a implementação do comando <code>\"sum\"</code>. Agora, execute o bot usando o comando a seguir (na mesma pasta que <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Agora, você pode usar o comando <code>\"! sum\"</code>&rdquo; em qualquer canal em que o bot possa visualizar e enviar mensagem.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step4a.png\" alt='Image of bot replying \"The sum of all the arguments you provided is 6!\" to \"! sum 1 2 3\", then replying \"The sum of all the arguments you provided is 13! to \"! sum 1.5 1.5 10\"'></p>\n\n<p>A seguir está uma versão finalizada do script <code>index.js</code> do bot:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n\nconst client = new Discord.Client();\n\nconst prefix = \"!\";\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  const commandBody = message.content.slice(prefix.length);\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  else if (command === \"sum\") {\n    const numArgs = args.map(x =&gt; parseFloat(x));\n    const sum = numArgs.reduce((counter, x) =&gt; counter += x);\n    message.reply(`The sum of all the arguments you provided is ${sum}!`);\n  }\n});\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Neste passo, você melhorou ainda mais seu bot Discord implementando o comando <code>sum</code>.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Você implementou com sucesso um bot Discord que pode lidar com vários comandos de usuário e argumentos de comando diferentes. Se você quiser expandir seu bot, você pode possivelmente implementar mais comandos ou experimentar mais partes da API do Discord para criar um bot Discord poderoso. Você pode revisar a <a href=\"https://discord.js.org/#/docs/main/stable/general/welcome\">documentação do Discord.js</a> ou a <a href=\"https://discord.com/developers/docs/intro\">documentação da API do Discord</a> para expandir seu conhecimento da API Discord.</p>\n\n<p>Ao criar bots no Discord, você deve sempre ter em mente os <a href=\"https://discord.com/developers/docs/legal\">termos de serviço da API do Discord</a>, que descreve como os desenvolvedores devem utilizar a API. Você também pode ler <a href=\"https://github.com/meew0/discord-bot-best-practices/blob/master/README.md\">este conjunto de diretrizes</a> sobre como implementar melhor um bot Discord, e fornece dicas sobre como projetar bots no Discord. Se você quiser aprender mais sobre o Node.js confira nossa série <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">How To Code in Node.js</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:35 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png","linkMd5":"f47ccc598c59c8525a156701452c31ae","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","destWidth":1920,"destHeight":973,"sourceBytes":66395,"destBytes":26384,"author":"Tom","articleImgCdnMap":{"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1b.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn9@2020_3/2020/08/31/07-48-31-275_690c64ccbc0c5170.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1c.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn30@2020_4/2020/08/31/07-48-31-778_f5a474e22c90438c.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1d.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_6/2020/08/31/07-48-31-392_d550c10707834d3f.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1e.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/31/07-48-31-921_817dcbabd0b27a3d.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1f.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn89@2020_2/2020/08/31/07-48-31-288_1d3824d3640df0a3.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1g.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn77@2020_3/2020/08/31/07-48-31-225_5aca524b04a26500.webp","https://assets.digitalocean.com/articles/node_discord_bot/step2a.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn74@2020_2/2020/08/31/07-48-31-293_81968c3f6c9ff261.webp","https://assets.digitalocean.com/articles/node_discord_bot/step3a.png":null,"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn98@2020_5/2020/08/31/07-48-33-506_74310bb53d7bafb2.webp","https://assets.digitalocean.com/articles/node_discord_bot/step4a.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn70@2020_4/2020/08/31/07-48-31-272_5589082ccebd5fbf.webp"},"publishedOrCreatedDate":1598860106984},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment sécuriser MongoDB sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-secure-mongodb-on-ubuntu-20-04-fr","description":"<p><em>Une version antérieure de ce tutoriel a été écrite par <a href=\"https://www.digitalocean.com/community/users/melissaanderson\">Brennan Bearnes</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://www.mongodb.com/\">MongoDB</a> , également connu sous le nom de <em>Mongo</em> , est une base de données de documents open-source utilisée dans de nombreuses applications web modernes. Elle est classée comme une <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">base de données NoSQL</a> car elle ne repose pas sur une structure de base de données relationnelle traditionnelle basée sur des tableaux. Elle utilise plutôt des documents de type JSON avec des schémas dynamiques.</p>\n\n<p>MongoDB n'a pas d'authentification activée par défaut, ce qui signifie que tout utilisateur ayant accès au serveur où la base de données est installée peut ajouter et supprimer des données sans restriction. Afin de sécuriser cette vulnérabilité, ce tutoriel vous guidera dans la création d'un administrative user et l'activation de l'authentification. Vous ferez ensuite des tests pour confirmer que seul cet administrative user a accès à la base de données.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour terminer ce tutoriel, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li>Un serveur fonctionnant sous Ubuntu 20.04 Ce serveur doit avoir un utilisateur administratif non root et un pare-feu configuré avec UFW. Pour cela, suivez notre <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">guide de configuration initiale du serveur pour Ubuntu 20.04</a> .</li>\n<li>MongoDB installé sur votre serveur. Ce tutoriel a été validé en utilisant la version de MongoDB <span class=\"highlight\">4.4</span>, bien qu'il devrait généralement fonctionner pour les anciennes versions de MongoDB également. Pour installer Mongo sur votre serveur, suivez notre tutoriel sur <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-mongodb-on-ubuntu-20-04\">Comment installer MongoDB sur Ubuntu 20.04</a>.</li>\n</ul>\n\n<h2 id=\"Étape-1-ajouter-un-administrative-user\">Étape 1 - Ajouter un administrative user</h2>\n\n<p>Depuis la sortie de la version <span class=\"highlight\">3.0</span>, le démon MongoDB est configuré pour n'accepter que les connexions provenant de la socket Unix locale, et il n'est pas automatiquement ouvert à l'Internet  dans toute son étendue. Toutefois, l'authentification est toujours désactivée par défaut. Cela signifie que tous les utilisateurs qui ont accès au serveur où MongoDB est installé ont également un accès complet aux bases de données.</p>\n\n<p>Dans un premier temps, pour sécuriser cette vulnérabilité, vous créerez un administrative user. Plus tard, vous activerez l'authentification et vous vous connecterez en tant qu'administrative user pour accéder à la base de données.</p>\n\n<p>Pour ajouter un administrative user, vous devez d'abord vous connecter au shell Mongo. L'authentification étant désactivée, vous pouvez le faire avec la commande <code>mongo</code>, sans aucune autre option :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mongo\n</li></ul></code></pre>\n<p>Il y aura une sortie au-dessus de l'invite du shell Mongo. Comme vous n'avez pas encore activé l'authentification, vous recevrez un avertissement indiquant que le contrôle d'accès n'est pas activé pour la base de données et que l'accès en lecture et en écriture aux données et la configuration de la base de données ne sont pas restreints :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>MongoDB shell version v<span class=\"highlight\">4.4.0</span>\n\n . . .\n\n2020-06-09T13:26:51.391+0000 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.\n2020-06-09T13:26:51.391+0000 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.\n\n . . .\n\n&gt;\n</code></pre>\n<p>Ces avertissements disparaîtront une fois que vous aurez activé l'authentification, mais pour l'instant, ils signifient que toute personne pouvant accéder à votre serveur Ubuntu pourrait également prendre le contrôle de votre base de données.</p>\n\n<p>Pour illustrer le tout, faites fonctionner la commande <code>show dbs</code> de Mongo :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">show dbs\n</li></ul></code></pre>\n<p>Cette commande renvoie une liste de toutes les bases de données sur le serveur. Cependant, lorsque l'authentification est activée, la liste change en fonction du <em>rôle</em> de l'utilisateur Mongo ou de son niveau d'accès à certaines bases de données. Cependant, comme l'authentification est désactivée, elle renvoie toutes les bases de données actuellement présentes sur le système sans restriction :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>admin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n</code></pre>\n<p>Dans cet exemple de sortie, seules les bases de données par défaut apparaissent. Cependant, si vous avez des bases de données contenant des données sensibles sur votre système, n'importe quel utilisateur pourrait les trouver avec cette commande.</p>\n\n<p>Dans le cadre de l'atténuation de cette vulnérabilité, cette étape est axée sur l'ajout d'un administrative user. Pour ce faire, vous devez d'abord vous connecter à la base de données <code>admin</code>. C'est là que sont stockées les informations sur les utilisateurs, comme leurs noms d'utilisateur, mots de passe et rôles :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">use admin\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>switched to db admin\n</code></pre>\n<p>MongoDB est installé avec <a href=\"https://docs.mongodb.com/manual/reference/method/\">un certain nombre de méthodes de shell basées sur JavaScript</a> que vous pouvez utiliser pour gérer votre base de données. L'une d'entre elles, la méthode <code>db.createUser</code>, est utilisée pour créer de nouveaux utilisateurs au sein de la base de données sur laquelle la méthode est exécutée.</p>\n\n<p>Lancez la méthode <code>db.createUser</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">db.createUser(\n</li></ul></code></pre>\n<p>Cette méthode exige que vous spécifiiez un nom d'utilisateur et un mot de passe pour l'utilisateur, ainsi que les rôles que vous souhaitez lui attribuer. Rappelons que MongoDB stocke ses données dans des documents de type JSON. Ainsi, lorsque vous créez un nouvel utilisateur, tout ce que vous faites est de créer un document contenant les données appropriées de l'utilisateur sous forme de champs individuels.</p>\n\n<p>Comme pour les objets dans JSON, les documents dans MongoDB commencent et se terminent par des accolades ( <code>{</code> et <code>}</code> ). Pour commencer à ajouter un utilisateur, entrez une accolade d'ouverture :</p>\n\n<p><span class='note'><strong>Note</strong> : Mongo n'enregistrera pas la méthode <code>db.createUser</code> comme complète tant que vous n'aurez pas entré une parenthèse de fermeture. En attendant, l'invite passera d'un signe plus grand que ( <code>&gt;</code> ) à une ellipse ( <code>...</code> ).<br></span></p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">{\n</li></ul></code></pre>\n<p>Ensuite, remplissez un champ <code>user:</code> en indiquant entre guillemets le nom d'utilisateur souhaité, suivi d'une virgule. L'exemple suivant précise le nom d'utilisateur <strong>AdminSammy</strong>, mais vous pouvez entrer le nom d'utilisateur que vous souhaitez :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">user: \"<span class=\"highlight\">AdminSammy</span>\",\n</li></ul></code></pre>\n<p>Ensuite, entrez un champ <code>pwd</code> avec la méthode <code>passwordPrompt()</code> comme valeur. Lorsque vous exécutez la méthode <code>db.createUser</code>, la méthode <code>passwordPrompt()</code> vous invite à saisir votre mot de passe. Cette méthode est plus sûre que l'autre, ce qui consiste à taper votre mot de passe en clair comme vous l'avez fait pour votre nom d'utilisateur.</p>\n\n<span class='note'><p>\n<strong>Note</strong> : La méthode <code>passwordPrompt()</code> est uniquement compatible avec les versions de MongoDB <span class=\"highlight\">4.2</span> et plus récentes.  Si vous utilisez une ancienne version de Mongo, vous devrez écrire votre mot de passe en clair, de la même manière que vous avez écrit votre nom d'utilisateur :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">pwd: \"<span class=\"highlight\">password</span>\",\n</li></ul></code></pre>\n<p></p></span>\n\n<p>Veillez également à faire suivre ce champ d'une virgule :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">pwd: passwordPrompt(),\n</li></ul></code></pre>\n<p>Saisissez ensuite les rôles que vous souhaitez attribuer à votre administrative user. Comme vous créez un administrative user, vous devez au minimum lui accorder le rôle de <code>userAdminAnyDatabase</code> par rapport à la base de données <code>admin</code>. Cela permettra à l'administrative user de créer et de modifier de nouveaux utilisateurs et rôles. Comme l'administrative user a ce rôle dans la base de données <code>admin</code>, cela lui donnera également un <a href=\"https://docs.mongodb.com/manual/reference/built-in-roles/#superuser\">accès de superuser à l'ensemble du cluster</a>.</p>\n\n<p>En outre, l'exemple suivant accorde également à l'administrative user le rôle de <code>ReadWriteAnyDatabase</code>.  Cela donne à l'administrative user la possibilité de lire et de modifier les données de n'importe quelle base de données du cluster, à l'exception des bases de données <code>config</code> et <code>local</code>, qui sont pour la plupart à usage interne :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" }, \"readWriteAnyDatabase\" ]\n</li></ul></code></pre>\n<p>Puis entrez une accolade de fermeture pour marquer la fin du document :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">}\n</li></ul></code></pre>\n<p>Ensuite, entrez une parenthèse de fermeture pour fermer et exécutez la méthode <code>db.createUser</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"...\">)\n</li></ul></code></pre>\n<p>En résumé, voici à quoi devrait ressembler votre méthode <code>db.createUser</code> :</p>\n<pre class=\"code-pre \"><code>&gt; db.createUser(\n... {\n... user: \"<span class=\"highlight\">AdminSammy</span>\",\n... pwd: passwordPrompt(),\n... roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" }, \"readWriteAnyDatabase\" ]\n... }\n... )\n</code></pre>\n<p>Si la syntaxe de chaque ligne est correcte, la méthode s'exécutera correctement et vous serez invité(e) à entrer un mot de passe :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enter password:\n</code></pre>\n<p>Entrez un mot de passe fort de votre choix. Ensuite, vous recevrez une confirmation que l'utilisateur a été ajouté :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Successfully added user: {\n    \"user\" : \"<span class=\"highlight\">AdminSammy</span>\",\n    \"roles\" : [\n        {\n            \"role\" : \"userAdminAnyDatabase\",\n            \"db\" : \"admin\"\n        },\n        \"readWriteAnyDatabase\"\n    ]\n}\n</code></pre>\n<p>Ensuite, vous pouvez quitter le client MongoDB :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">exit\n</li></ul></code></pre>\n<p>À ce stade, votre utilisateur sera autorisé à saisir des informations d'identification. Cependant, il ne sera pas tenu de le faire tant que vous n'aurez pas activé l'authentification et redémarré le démon MongoDB.</p>\n\n<h2 id=\"Étape-2-activer-l-39-authentification\">Étape 2 - Activer l'authentification</h2>\n\n<p>Pour activer l'authentification, vous devez éditer <code>mongod.conf</code>, le fichier de configuration de MongoDB. Une fois que vous l'aurez activé et redémarré le service Mongo, les utilisateurs pourront toujours se connecter à la base de données sans s'authentifier. Toutefois, ils ne pourront lire ou modifier aucune donnée tant qu'ils n'auront pas fourni un nom d'utilisateur et un mot de passe corrects.</p>\n\n<p>Ouvrez le fichier de configuration avec votre éditeur. Ici, nous utiliserons <code>nano</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mongod.conf\n</li></ul></code></pre>\n<p>Faites défiler la page vers le bas pour trouver la section <code>security</code> commentée :</p>\n<div class=\"code-label \" title=\"/etc/mongod.conf\">/etc/mongod.conf</div><pre class=\"code-pre \"><code>. . .\n#security:\n\n#operationProfiling:\n\n. . .\n</code></pre>\n<p>Décommentez cette ligne en enlevant le signe dièse ( <code>#</code> ) :</p>\n<div class=\"code-label \" title=\"/etc/mongod.conf\">/etc/mongod.conf</div><pre class=\"code-pre \"><code>. . .\nsecurity:\n\n#operationProfiling:\n\n. . .\n</code></pre>\n<p>Ajoutez ensuite le paramètre <code>authorization</code> et réglez-le sur <code>« enabled »</code>. Quand vous aurez terminé, les lignes devraient ressembler à ceci :</p>\n<div class=\"code-label \" title=\"/etc/mongod.conf\">/etc/mongod.conf</div><pre class=\"code-pre \"><code>. . .\nsecurity:\n  <span class=\"highlight\">authorization: \"enabled\"</span>\n. . .\n</code></pre>\n<p>Notez que la ligne <code>security:</code> ne comporte pas d'espace au début, tandis que la ligne <code>authorization:</code> est en retrait de deux espaces.</p>\n\n<p>Après avoir ajouté ces lignes, enregistrez et fermez le fichier. Si vous avez utilisé <code>nano</code> pour ouvrir le fichier, faites-le en appuyant sur <code>CTRL + X</code>, <code>Y</code>, puis <code>ENTER</code> </p>\n\n<p>Ensuite, redémarrez le démon pour que ces nouveaux changements soient pris en compte :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mongod\n</li></ul></code></pre>\n<p>Ensuite, vérifiez l'état du service pour vous assurer qu'il a redémarré correctement :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl status mongod\n</li></ul></code></pre>\n<p>Si la commande <code>restart</code> a réussi, vous recevrez une sortie qui indique que le <code>mongod</code> est actif et a été lancé récemment :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>● mongod.service - MongoDB Database Server\n     Loaded: loaded (/lib/systemd/system/mongod.service; enabled; vendor preset: enabled)\n     Active: active (running) since Tue 2020-06-09 22:06:20 UTC; 7s ago\n       Docs: https://docs.mongodb.org/manual\n   Main PID: 15370 (mongod)\n     Memory: 170.1M\n     CGroup: /system.slice/mongod.service\n             └─15370 /usr/bin/mongod --config /etc/mongod.conf\n\nJun 09 22:06:20 <span class=\"highlight\">your_host</span> systemd[1]: Started MongoDB Database Server.\n</code></pre>\n<p>Après avoir vérifié que le démon est de nouveau opérationnel, vous pouvez tester que le paramètre d'authentification que vous avez ajouté fonctionne comme prévu.</p>\n\n<h2 id=\"Étape-3-tester-les-paramètres-d-39-authentification\">Étape 3 - Tester les paramètres d'authentification</h2>\n\n<p>Pour vérifier que les exigences d'authentification que vous avez ajoutées à l'étape précédente fonctionnent correctement, commencez par vous connecter sans spécifier d'identifiants, pour vous assurer que vos actions sont bien limitées :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mongo\n</li></ul></code></pre>\n<p>Maintenant que vous avez activé l'authentification, aucun des avertissements que vous avez rencontrés précédemment n'apparaîtra :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>MongoDB shell version v<span class=\"highlight\">4.4.0</span>\nconnecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodb\nImplicit session: session { \"id\" : UUID(\"5d50ed96-f7e1-493a-b4da-076067b2d898\") }\nMongoDB server version: <span class=\"highlight\">4.4.0</span>\n&gt;\n</code></pre>\n<p>Confirmez si votre accès est restreint en exécutant à nouveau la commande <code>show dbs</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">show dbs\n</li></ul></code></pre>\n<p>Rappelez-vous de l'étape 1 qu'il y a au moins quelques bases de données par défaut sur votre serveur. Cependant, dans ce cas, la commande n'aura aucune sortie, car vous ne vous êtes pas authentifié en tant qu'utilisateur privilégié.</p>\n\n<p>Comme cette commande ne renvoie aucune information, on peut dire sans se tromper que le paramètre d'authentification fonctionne comme prévu. Vous ne pourrez pas non plus créer d'utilisateurs ou effectuer d'autres tâches privilégiées sans vous authentifier au préalable.</p>\n\n<p>Continuez et sortez du shell MongoDB :</p>\n\n<p><span class='note'><strong>Note</strong> : Au lieu d'exécuter la commande <code>exit</code> suivante comme vous l'avez fait précédemment à l'étape 1, une autre façon de fermer le shell est d'appuyer simplement sur <code>CTRL + C</code> .<br></span></p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">exit\n</li></ul></code></pre>\n<p>Ensuite, assurez-vous que votre administrative user est capable de s'authentifier correctement en exécutant la commande <code>mongo</code> suivante pour vous connecter en tant qu'utilisateur. Cette commande comprend le drapeau <code>-u</code>, qui précède le nom de l'utilisateur sous lequel vous voulez vous connecter.  Veillez à remplacer <strong>AdminSammy</strong> par le nom d'utilisateur de votre propre administrative user. Il comprend également le drapeau <code>-p</code>, qui vous demandera le mot de passe de l'utilisateur, et spécifie <code>admin</code> comme la base de données d'authentification où le nom d'utilisateur spécifié a été créé :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mongo -u <span class=\"highlight\">AdminSammy</span> -p --authenticationDatabase admin\n</li></ul></code></pre>\n<p>Saisissez le mot de passe de l'utilisateur lorsque vous y êtes invité, et vous serez ensuite déposé dans le shell. Une fois sur place, essayez de lancer à nouveau la commande <code>show dbs</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;\">show dbs\n</li></ul></code></pre>\n<p>Cette fois, parce que vous vous êtes authentifié correctement, la commande retournera avec succès une liste de toutes les bases de données actuellement sur le serveur :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>admin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n</code></pre>\n<p>Cela confirme que l'authentification a été activée avec succès.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>En complétant ce guide, vous avez mis en place un administrative MongoDB user que vous pouvez utiliser pour créer et modifier de nouveaux utilisateurs et rôles, et pour gérer votre instance MongoDB. Vous avez également configuré votre instance MongoDB pour exiger que les utilisateurs s'authentifient avec un nom d'utilisateur et un mot de passe valides avant de pouvoir interagir avec des données.</p>\n\n<p>Pour plus d'informations sur la gestion des utilisateurs de MongoDB, consultez <a href=\"https://docs.mongodb.com/manual/tutorial/manage-users-and-roles/\">la documentation officielle sur le sujet</a> .  Vous pourriez également vouloir en savoir plus sur le <a href=\"https://docs.mongodb.com/manual/core/authentication/\">fonctionnement de l'authentification sur MongoDB</a>.</p>\n\n<p>De plus, si vous envisagez d'interagir avec votre instance MongoDB à distance, vous pouvez suivre notre guide sur <a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-remote-access-for-mongodb-on-ubuntu-20-04\">Comment configurer l'accès à distance pour MongoDB sur Ubuntu 20.04</a> .</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:02 +0000","feedId":8037,"bgimg":"","linkMd5":"71fdba7bb8c3f4f3a35127dbfcb533ea","bgimgJsdelivr":"","metaImg":"","author":"Mark Drake","publishedOrCreatedDate":1598860106970},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Compreendendo bancos de dados relacionais","link":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-pt","description":"<h3 id=\"introdução\">Introdução</h3>\n\n<p>Os <em>sistemas de gerenciamento de banco de dados</em> (SGDB, no inglês DMBS) são programas de computador que permitem que usuários interajam com um banco de dados. Um DBMS permite que os usuários controlem o acesso a um banco de dados, gravem dados, executem consultas e façam outras tarefas relacionadas ao gerenciamento de banco de dados.</p>\n\n<p>No entanto, para realizar qualquer uma dessas tarefas, o DBMS deve possuir algum modelo subjacente que defina como os dados são organizados. O <em>modelo relacional</em> é uma abordagem para organizar dados que vem sendo bastante usada em softwares de banco de dados desde que foram criados no final dos anos 60. Tanto é que, no momento em que este artigo está sendo escrito, <a href=\"https://db-engines.com/en/ranking\">quatro dos cinco DBMS mais populares</a> são relacionais.</p>\n\n<p>Este artigo conceitual descreve o histórico do modelo relacional, como os bancos de dados relacionais organizam dados e como são usados hoje.</p>\n\n<h2 id=\"história-do-modelo-relacional\">História do modelo relacional</h2>\n\n<p>Os <em>bancos de dados</em> são clusters de informações logicamente modelados, ou <em>dados</em>. Qualquer coleção de dados é um banco de dados, independentemente de como ou onde é armazenada. Mesmo um armário de arquivos que contém informações de folha de pagamento é um banco de dados, assim como uma pilha de formulários hospitalares ou uma coleção de informações de cliente de uma empresa espalhada em vários locais. Antes do armazenamento e gerenciamento de dados com computadores ser uma prática comum, bancos de dados físicos como esses eram os únicos disponíveis para as organizações governamentais e empresariais que precisavam armazenar informações.</p>\n\n<p>Em meados do século XX, pesquisas na área da ciência da computação levaram à criação de máquinas com maior poder de processamento, bem como maior capacidade de armazenamento local e externo. Esses avanços levaram os cientistas da computação a começar a reconhecer o potencial que essas máquinas tinham para armazenar e gerenciar quantidades cada vez maiores de dados.</p>\n\n<p>No entanto, não havia nenhuma teoria para explicar como os computadores poderiam organizar os dados de maneiras lógicas e significativas. Uma coisa é armazenar dados não ordenados em uma máquina, e outra, muito mais complicada, é projetar sistemas que permitam adicionar, recuperar, classificar e gerenciar os dados de maneira consistente e prática. A necessidade de uma estrutura lógica para armazenar e organizar dados levou a uma série de propostas sobre como tirar proveito dos computadores para gerenciar dados.</p>\n\n<p>Um modelo de banco de dados inicial foi o <a href=\"https://en.wikipedia.org/wiki/Hierarchical_database_model\"><em>modelo hierárquico</em></a>, no qual os dados são organizados em uma estrutura que se assemelha a uma árvore, semelhante aos sistemas de arquivos modernos. O exemplo a seguir mostra como o layout de parte de um banco de dados hierárquico usado para categorizar animais se pareceria:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png\" alt=\"Exemplo de um banco de dados hierárquico: categorização de animais\"></p>\n\n<p>O modelo hierárquico foi amplamente implementado nos primeiros sistemas de gerenciamento banco de dados, mas também se mostrou um pouco inflexível. Neste modelo, mesmo que os registros individuais possam ter vários &ldquo;filhos&rdquo;, cada registro só pode ter um &ldquo;pai&rdquo; na hierarquia. Por conta disso, esses primeiros bancos de dados hierárquicos ficavam limitados a representar apenas relações &ldquo;um a um&rdquo; e &ldquo;um para muitos&rdquo;. Essa falta de relações&quot;muitos para muitos&quot; poderia levar a problemas quando se estivesse trabalhando com pontos de dados que você gostaria de associar a mais de um pai.</p>\n\n<p>No final dos anos 60, Edgar F. Codd, um cientista da computação que trabalhava na IBM, criou o modelo relacional de gerenciamento de banco de dados. O modelo relacional de Codd permitiu que registros individuais fossem associados a mais de uma tabela, permitindo assim relações &ldquo;muitos para muitos&rdquo; entre pontos de dados, além de relacionamentos &ldquo;um para muitos&rdquo;. Isso proporcionou maior flexibilidade do que outros modelos existentes no que diz respeito ao projeto de banco de dados. Isso fez com que os sistemas de gerenciamento de banco de dados relacionais (RDBMSs) pudessem atender a uma gama muito maior de necessidades de negócios.</p>\n\n<p>Codd propôs uma linguagem para gerenciar dados relacionais, conhecida como <a href=\"https://dl.acm.org/doi/pdf/10.1145/1734714.1734718\">Alpha</a>, que influenciou o desenvolvimento de linguagens de banco de dados posteriores. Dois dos colegas de Codd na IBM, Donald Chamberlin e Raymond Boyce, criaram uma dessas linguagens inspirada no Alpha. Eles deram a ela o nome de <em>SEQUEL</em>, abreviação de <strong>S</strong>tructured <strong>E</strong>nglish <strong>Que</strong>ry <strong>L</strong>anguage. No entanto, por causa de uma marca registrada existente, eles reduziram o nome de sua linguagem para <em>SQL</em> (conhecida mais formalmente como <em>Structured Query Language</em>).</p>\n\n<p>Devido às restrições de hardware, os primeiros bancos de dados relacionais ainda eram proibitivamente lentos, e foi necessário algum tempo até que a tecnologia se tornasse difundida. Mas em meados dos anos 80, o modelo relacional de Codd já havia sido implementado em diversos produtos de gerenciamento de banco de dados comercial tanto da IBM quando de seus concorrentes. Esses fornecedores também seguiram a iniciativa da IBM desenvolvendo e implementando seus próprios dialetos de SQL. Em 1987, tanto o American National Standards Institute quanto a International Organization for Standardization haviam ratificado e publicado padrões para SQL, solidificando seu status como a linguagem aceita para gerenciar RDBMSs.</p>\n\n<p>O uso difundido do modelo relacional em várias indústrias fez com que ele se tornasse reconhecido como o modelo padrão para o gerenciamento de dados. Mesmo com o surgimento de vários <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">bancos de dados NoSQL</a> nos últimos anos, os bancos de dados relacionais continuam sendo as ferramentas dominantes para armazenar e organizar dados.</p>\n\n<h2 id=\"como-os-bancos-de-dados-relacionais-organizam-os-dados\">Como os bancos de dados relacionais organizam os dados</h2>\n\n<p>Agora que você compreende de maneira geral a história do modelo relacional, vamos dar uma olhada mais de perto em como o modelo organiza os dados.</p>\n\n<p>Os elementos mais fundamentais no modelo relacional são <em>as relações</em>, que os usuários e RDBMS modernos reconhecem como <em>tabelas</em>. Uma relação é um conjunto de <em>tuplas</em>, ou linhas em uma tabela, com cada tupla compartilhando um conjunto de <em>atributos</em>, ou colunas:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png\" alt=\"Diagrama exemplo de como as relações, tuplas e atributos se relacionam entre si\"></p>\n\n<p>Uma coluna é a menor estrutura organizacional de um banco de dados relacional e representa as diversas facetas que definem os registros na tabela. Daí seu nome mais formal, atributos. Você pode pensar em cada tupla como sendo uma instância única de qualquer tipo de pessoas, objetos, eventos ou associações que a tabela possua. Essas instâncias podem representar coisas como funcionários em uma empresa, vendas de um negócio on-line ou resultados de testes de laboratório. Por exemplo, em uma tabela que contenha registros de funcionário de professores em uma escola, as tuplas podem possuir atributos como <code>name</code> (nome), <code>subjects</code> (disciplinas), <code>start_date</code> (data de início), e assim por diante.</p>\n\n<p>Ao criar colunas, você especifica um <em>tipo de dados</em> que dita qual o tipo das entradas que são permitidas nessa coluna. Os RDBMSs muitas vezes implementam seus próprios tipos de dados únicos, que podem não ser diretamente intercambiáveis com tipos de dados semelhantes de outros sistemas. Alguns tipos de dados comuns incluem datas, strings, inteiros e booleanos.</p>\n\n<p>No modelo relacional, cada tabela contém pelo menos uma coluna que pode ser usada para identificar de maneira única cada linha, chamada de <em>chave primária</em>. Isso é importante, pois significa que os usuários não precisam saber onde seus dados ficam fisicamente armazenados em uma máquina. Em vez disso, seu DBMS pode manter o controle de cada registro e retorná-los conforme necessário. Por sua vez, isso significa que os registros não possuem ordem lógica definida, e os usuários têm a capacidade de retornar seus dados em qualquer ordem ou sob o efeito do filtro que quiserem.</p>\n\n<p>Se você tiver duas tabelas que gostaria de se associar uma com a outra, uma maneira de fazer isso é com uma <em>chave estrangeira</em>. Uma chave estrangeira é essencialmente uma cópia da chave primária de uma tabela (a tabela &ldquo;pai&rdquo;) inserida em uma coluna em outra tabela (o &ldquo;filho&rdquo;). O exemplo a seguir destaca a relação entre duas tabelas. Uma é usada para registrar informações sobre funcionários em uma empresa e a outra é usada para acompanhar as vendas dela. Neste exemplo, a chave primária da tabela <code>EMPLOYEES</code> (funcionários) é usada como a chave estrangeira na tabela <code>SALES</code> (vendas):</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png\" alt=\"Diagrama exemplo de como a chave primária da tabela de funcionários funciona como chave estrangeira da tabela SALES\"></p>\n\n<p>Se você tentar adicionar um registro à tabela filho e o valor inserido na coluna de chaves estrangeiras não existir na chave primária da tabela de origem, a declaração de inserção será inválida. Isso ajuda a manter a integridade de nível de relação, já que as linhas em ambas as tabelas sempre estarão relacionadas corretamente.</p>\n\n<p>Os elementos estruturais do modelo relacional ajudam a manter os dados armazenados de forma organizada, mas o armazenamento de dados só é útil se for possível recuperá-los. Para recuperar informações de um RDBMS, é possível emitir uma <em>consulta</em>, ou uma solicitação estruturada para um conjunto de informações. Como mencionado anteriormente, a maioria dos bancos de dados relacionais usa SQL para gerenciar e consultar dados. O SQL permite que você filtre e manipule os resultados da consulta com uma variedade de cláusulas, predicados e expressões, dando-lhe um controle fino sobre quais dados aparecerão no conjunto de resultados.</p>\n\n<h2 id=\"vantagens-e-limitações-dos-bancos-de-dados-relacionais\">Vantagens e limitações dos bancos de dados relacionais</h2>\n\n<p>Com a estrutura organizacional subjacente de bancos de dados relacionais em mente, vamos considerar algumas de suas vantagens e desvantagens.</p>\n\n<p>Hoje em dia, tanto o SQL quanto os bancos de dados que o implementam se desviam do modelo relacional de Codd de várias maneiras. Por exemplo, o modelo de Codd determina que cada linha em uma tabela deve ser única, enquanto que, por razões de praticidade, a maioria dos bancos de dados relacionais modernos permite linhas duplicadas. Existem algumas pessoas que não consideram os bancos de dados SQL como verdadeiros bancos de dados relacionais se não conseguem aderir às especificações de Codd para o modelo relacional. No entanto, em termos práticos, qualquer DBMS que use SQL e de certa forma acate ao modelo relacional de dados provavelmente será referido como um sistema de gerenciamento de banco de dados relacional.</p>\n\n<p>Embora os bancos de dados relacionais tenham rapidamente crescido em popularidade, algumas das desvantagens do modelo relacional começaram a se tornar aparentes à medida que os dados se tornaram mais valiosos e as empresas começaram a armazenar uma maior quantidade deles. Por exemplo, pode ser difícil dimensionar um banco de dados relacional horizontalmente. O <em>dimensionamento horizontal</em>, ou <em>ampliamento</em>, é a prática de adicionar mais máquinas a uma pilha existente para espalhar a carga e permitir um maior tráfego e processamento mais rápido. Isso é muitas vezes contrastado com <em>o dimensionamento vertical</em>, que envolve atualizar o hardware de um servidor existente, geralmente adicionando mais RAM ou CPU.</p>\n\n<p>A razão pela qual é difícil dimensionar um banco de dados relacional de dados horizontalmente tem a ver com o fato de que o modelo relacional foi projetado para garantir a <em>consistência</em>, ou seja, clientes que consultarem o mesmo banco de dados sempre receberão os mesmos dados. Se você fosse dimensionar um banco de dados relacional horizontalmente em várias máquinas, tornaria-se difícil garantir a consistência, pois os clientes poderiam escrever dados em um nó mas não nos outros. Provavelmente haveria um atraso entre a gravação inicial e o momento em que os outros nós fossem atualizados para refletir as alterações, resultando em inconsistências entre eles.</p>\n\n<p>Outra limitação apresentada pelos RDBMSs é que o modelo relacional foi projetado para gerenciar <em>dados estruturados</em>, ou dados que se alinhem a um tipo de dados pré-definido ou que pelo menos estejam organizados de alguma forma pré-determinada, tornando-os facilmente categorizáveis e pesquisáveis. No entanto, com a propagação da computação pessoal e o aumento da internet no início dos anos 90, <em>dados não estruturados</em> — como mensagens de e-mail, fotos, vídeos, etc — se tornaram mais comuns.</p>\n\n<p>Nada disso é para dizer que os bancos de dados relacionais não são úteis. Muito pelo contrário, o modelo relacional ainda é a estrutura dominante para o gerenciamento de dados após mais de 40 anos. Sua prevalência e longevidade significam que os bancos de dados relacionais são uma tecnologia madura, que por si só é uma de suas principais vantagens. Existem muitos aplicativos projetados para trabalhar com o modelo relacional, bem como muitos profissionais administradores de banco de dados que são especialistas no assunto. Também há uma grande variedade de recursos disponíveis on-line e em livros para aqueles que querem começar com bancos de dados relacionais.</p>\n\n<p>Outra vantagem dos bancos de dados relacionais é que quase todos os RDBMS suportam <em>transações</em>. Uma transação consiste em uma ou mais declarações SQL individuais realizadas em sequência como uma única unidade de trabalho. As transações apresentam uma abordagem tudo ou nada, o que significa que cada declaração SQL na transação deve ser válida; caso contrário, toda a transação falhará. Isso é muito útil para garantir a integridade dos dados ao fazer alterações em várias linhas ou tabelas.</p>\n\n<p>Por fim, os bancos de dados relacionais são extremamente flexíveis. Eles foram usados para construir uma grande variedade de aplicativos diferentes e continuam funcionando de maneira eficiente, mesmo com grandes quantidades de dados. O SQL também é extremamente poderoso, permitindo adicionar e alterar os dados em tempo real, bem como alterar a estrutura de esquemas e tabelas do banco de dados sem afetar os dados existentes.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Graças à sua flexibilidade e design para a integridade dos dados, os bancos de dados relacionais ainda representam a principal maneira de os dados serem gerenciados e armazenados mais de cinquenta anos após terem sido concebidos pela primeira vez. Mesmo com o surgimento de diversos bancos de dados NoSQL nos últimos anos, compreender o modelo relacional e como trabalhar com RDBMSs é muito importante para quem quiser construir aplicativos que tirem proveito do poder dos dados.</p>\n\n<p>Para aprender mais sobre alguns RDBMSs populares de código aberto, recomendamos que você consulte <a href=\"https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\">nossa comparação entre vários bancos de dados SQL relacionais de código aberto</a>. Se tiver interesse em aprender mais sobre bancos de dados de maneira geral, recomendamos que verifique <a href=\"https://www.digitalocean.com/community/tags/databases\">nossa biblioteca completa de conteúdos relacionados a banco de dados</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:47:13 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png","linkMd5":"621722b6627b6f6ffc438eca502d5e4e","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","destWidth":1440,"destHeight":820,"sourceBytes":26442,"destBytes":57080,"author":"Mark Drake","articleImgCdnMap":{"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn42@2020_2/2020/08/31/07-48-32-526_c309571f1ca0d468.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png":null},"publishedOrCreatedDate":1598860106961},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo instalar Elasticsearch, Logstash y Kibana (Elastic Stack) en Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-es","description":"<h3 id=\"introducción\">Introducción</h3>\n\n<p>Elastic Stack, previamente conocida como <em>la pila ELK</em>, es una colección de software de código abierto producido por <a href=\"https://www.elastic.co/\">Elastic</a> que le permite buscar, analizar, y visualizar registros generados desde cualquier fuente y en cualquier formato, una práctica conocida como <em>registro centralizado</em>. El registro centralizado puede ser muy útil al intentar identificar problemas en sus servidores o aplicaciones, ya que le permite realizar búsquedas en todos sus registros desde un solo sitio. También es útil porque le permite identificar problemas que abarcan varios servidores vinculando sus registros durante un período de tiempo específico.</p>\n\n<p>Elastic Stack cuenta con cuatro componentes principales:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/elasticsearch\"><strong>Elasticsearch</strong></a>: motor de búsqueda de <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\"><em>RESTful</em></a>distribuido que almacena todos los datos recopilados.</li>\n<li><a href=\"https://www.elastic.co/products/logstash\"><strong>Logstash</strong></a>: componente de procesamiento de datos de Elastic Stack que envía datos entrantes a Elasticsearch.</li>\n<li><a href=\"https://www.elastic.co/products/kibana\"><strong>Kibana</strong></a>: interfaz web para buscar y visualizar registros.</li>\n<li><a href=\"https://www.elastic.co/products/beats\"><strong>Beats</strong></a>: transportadores de datos ligeros de uso único que pueden enviar datos de cientos o miles de máquinas a Logstash o Elasticsearch.</li>\n</ul>\n\n<p>A través de este tutorial, instalará <a href=\"https://www.elastic.co/elk-stack\">Elastic Stack</a> en un servidor de Ubuntu 20.04. Aprenderá a instalar todos los componentes de Elastic Stack, incluido <a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>, un Beat que se usa para reenviar y centralizar registros y archivos, y los configurará para recopilar y visualizar registros del sistema. Además, debido a que Kibana normalmente está solo disponible en el <code>localhost</code>, usaremos <a href=\"https://www.nginx.com/\">Nginx</a> para hacer un proxy de modo que el acceso sea posible a través de un navegador web. Instalaremos todos estos componentes en un único servidor al que nos referiremos como nuestro <em>servidor de pila de Elastic</em>.</p>\n\n<p><span class='note'><strong>Nota</strong>: Al instalar Elastic Stack, debe usar la misma versión en toda la pila. En este tutorial, instalaremos las últimas versiones de toda la pila que, al redactarse el presente artículo, eran Elasticsearch 7.7.1, Kibana 7.7.1, Logstash 7.7.1 y Filebeat 7.7.1.<br></span></p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Para completar este tutorial, necesitará lo siguiente:</p>\n\n<ul>\n<li><p>Un servidor de Ubuntu 20.04, con 4 GB de RAM y 2 CPU configuradas con un usuario sudo no root. Puede hacerlo siguiendo la <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Configuración inicial de servidores para Ubuntu 20.04</a>. En este tutorial, trabajaremos con la cantidad mínima de CPU y RAM requerida para ejecutar Elasticsearch. Tenga en cuenta que la cantidad de CPU, RAM y almacenamiento que su servidor de Elasticsearch requiera dependerá del volumen de registros que prevé.</p></li>\n<li><p>OpenJDK 11 instalado. Consulte la sección <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04-es\">Instalación de JRE y del JDK predeterminados</a> en nuestra guía <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04\">Cómo instalar Java con Apt en Ubuntu 20.04</a> para configurarlo. </p></li>\n<li><p>Nginx instalado en su servidor, que configuraremos más adelante en esta guía como proxy inverso para Kibana. Para configurarlo, siga nuestra guía <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">Cómo instalar Nginx en Ubuntu 20.04</a>.</p></li>\n</ul>\n\n<p>Además, debido a que Elastic Stack se usa para acceder a información valiosa sobre su servidor a la que no quiere que accedan usuarios no autorizados, es importante que mantenga su servidor protegido instalando un certificado TLS o SSL. Esto es opcional, pero <strong>se recomienda enfáticamente</strong>.</p>\n\n<p>Sin embargo, ya que eventualmente realizará cambios en su bloque de servidor de Nginx a lo largo de esta guía, es probable que tenga más sentido completar la guía de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Let´s Encrypt sobre Ubuntu 20.04</a> al final del segundo paso de este tutorial. Teniendo eso en cuenta, si planea configurar Let´s Encrypt en su servidor, necesitará lo siguiente antes de hacerlo:</p>\n\n<ul>\n<li>Un nombre de dominio totalmente apto (FQDN). Para este tutorial, se utilizará <code><span class=\"highlight\">your_domain</span></code> en todo momento. Puede adquirir un nombre de dominio en <a href=\"https://namecheap.com\">Namecheap</a>, obtener uno gratuito en <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> o utilizar un registrador de dominios de su elección.</li>\n<li><p>Los dos registros DNS que se indican a continuación se han configurado para su servidor. Puede utilizar <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">esta introducción al DNS de DigitalOcean</a> para obtener más información sobre cómo agregarlos.</p>\n\n<ul>\n<li>Un registro A con <code><span class=\"highlight\">your_domain</span></code> orientado a la dirección IP pública de su servidor.</li>\n<li>Un registro A con <code>www.<span class=\"highlight\">your_domain</span></code> orientado a la dirección IP pública de su servidor.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"paso-1-instalar-y-configurar-elasticsearch\">Paso 1: Instalar y configurar Elasticsearch</h2>\n\n<p>Los componentes de Elasticsearch no están disponibles en los repositorios de paquetes predeterminados de Ubuntu. Sin embargo, pueden instalarse con APT una vez que agregue la lista de fuentes de paquetes de Elastic.</p>\n\n<p>Todos los paquetes de Elasticsearch están firmados con la clave de firma de Elasticsearch para proteger su sistema contra la suplantación de paquetes. Su administrador de paquetes considerará confiables los paquetes autenticados con la clave. En este paso, importará la clave GPG pública de Elasticsearch y agregará la lista de fuentes de paquetes de Elastic para instalar Elasticsearch.</p>\n\n<p>Para comenzar, utilice cURL, la herramienta de línea de comandos para transferir datos con URL, para importar la clave GPG pública de Elasticsearch a APT. Tenga en cuenta que estamos usando los argumentos -fsSL para silenciar todos los progresos y posibles errores (excepto los de errores del servidor) y para permitir a cURL hacer una solicitud en una ubicación nueva si se redirige.  Canalice el resultado del comando cURL al programa apt-key, que añade la clave GPG pública a APT.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n</li></ul></code></pre>\n<p>A continuación, agregue la lista de fuentes de Elastic al directorio <code>sources.list.d</code>, donde APT buscará nuevas fuentes:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n</li></ul></code></pre>\n<p>A continuación, actualice sus listas de paquetes para que APT lea la nueva fuente de Elastic:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Luego, instale Elasticsearch con este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install elasticsearch\n</li></ul></code></pre>\n<p>Ahora, Elasticsearch está instalada y lista para usarse. Utilice su editor de texto preferido para editar el archivo de configuración principal de Elasticsearch, <code>elasticsearch.yml</code>. En este caso, utilizaremos <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/elasticsearch/elasticsearch.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Nota:</strong> El archivo de configuración de Elasticsearch se encuentra en formato YAML, lo que significa que debemos mantener el formato de sangrías. Asegúrese de no añadir espacios adicionales al editar este archivo.<br></span></p>\n\n<p>El archivo <code>elasticsearch.yml</code> ofrece opciones de configuración para su clúster, nodo, rutas, memoria, red, detección y puerta de enlace. La mayoría de estas opciones están preconfiguradas en el archivo, pero las puede cambiar según sus necesidades. Para los fines de nuestra demostración de una configuración de un solo servidor, modificaremos únicamente la configuración del host de red.</p>\n\n<p>Elasticsearch escucha el tráfico de todos los lugares en el puerto <code>9200</code>. Es conveniente restringir el acceso externo a su instancia de Elasticsearch para evitar que terceros lean sus datos o cierren su clúster de Elasticsearch a través de su <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">API REST</a>.  Para restringir el acceso y, por lo tanto, aumentar la seguridad, busque la línea que especifica <code>network.host</code>, elimine los comentarios y reemplace su valor por <code>localhost</code> para que tenga el siguiente aspecto:</p>\n<div class=\"code-label \" title=\"/etc/elasticsearch/elasticsearch.yml\">/etc/elasticsearch/elasticsearch.yml</div><pre class=\"code-pre \"><code>. . .\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: <span class=\"highlight\">localhost</span>\n. . .\n</code></pre>\n<p>Hemos especificado <code>localhost</code> para que Elasticsearch escuche en todas las interfaces y las IP vinculadas. Si desea que escuche únicamente en una interfaz específica, puede especificar su IP en lugar de <code>localhost</code>. Guarde y cierre <code>elasticsearch.yml</code>. Si utiliza <code>nano</code>, puede hacerlo pulsando <code>CTRL+X</code>, seguido de <code>Y</code> y, luego, <code>ENTER</code>.</p>\n\n<p>Estos son los ajustes mínimos con los que puede comenzar para usar Elasticsearch. Ahora, puede iniciar Elasticsearch por primera vez.</p>\n\n<p>Inicie el servicio de Elasticsearch con <code>systemctl</code>. Elasticsearch tardará unos minutos en iniciarse. Espere, de lo contrario, es posible que reciba errores de que no se puede conectar.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start elasticsearch\n</li></ul></code></pre>\n<p>Luego, ejecute el siguiente comando para permitir que Elasticsearch se cargue cada vez que su servidor se inicia:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable elasticsearch\n</li></ul></code></pre>\n<p>Puede comprobar si su servicio de Elasticsearch se está ejecutando enviando una solicitud HTTP:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -X GET \"localhost:9200\"\n</li></ul></code></pre>\n<p>Visualizará una respuesta que mostrará información básica sobre su nodo local, similar a la siguiente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\n  \"name\" : \"Elasticsearch\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"qqhFHPigQ9e2lk-a7AvLNQ\",\n  \"version\" : {\n    \"number\" : \"7.7.1\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"deb\",\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\",\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.5.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n\n</code></pre>\n<p>Ahora que Elasticsearch está configurado y activo, instalaremos Kibana, el siguiente componente de Elastic Stack.</p>\n\n<h2 id=\"paso-2-instalar-y-configurar-el-panel-de-kibana\">Paso 2: Instalar y configurar el panel de Kibana</h2>\n\n<p>De acuerdo con la <a href=\"https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html\">documentación oficial</a>, deberá instalar Kibana solo después de instalar Elasticsearch. La instalación en este orden garantiza que los componentes de los que depende cada producto estén correctamente implementados.</p>\n\n<p>Debido a que ya agregó la fuente de paquetes de Elastic en el paso anterior, puede instalar los componentes restantes de Elastic Stack usando <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install kibana\n</li></ul></code></pre>\n<p>A continuación, habilite e inicie el servicio de Kibana:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable kibana\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl start kibana\n</li></ul></code></pre>\n<p>Debido a que Kibana está configurado para escuchar solo en <code>localhost</code>, debemos configurar un <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">proxy inverso</a> para permitir el acceso externo a este. Utilizaremos Nginx para este propósito, que ya debería estar instalado en su servidor.</p>\n\n<p>Primero, utilice el comando <code>openssl</code> para crear un usuario administrativo de Kibana que usará para acceder a la interfaz web de Kibana. Como ejemplo, nombraremos esta cuenta <code><span class=\"highlight\">kibanaadmin</span></code>, pero, para garantizar una mayor seguridad, le recomendamos elegir un nombre no estándar para su usuario que sea difícil de adivinar.</p>\n\n<p>Con el siguiente comando se crearán el usuario y la contraseña administrativa de Kibana, y se almacenarán en el archivo <code>htpasswd.users</code>. Configurará Nginx para que requiera este nombre de usuario y contraseña, y lea este archivo de manera momentánea:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"<span class=\"highlight\">kibanaadmin</span>:`openssl passwd -apr1`\" | sudo tee -a /etc/nginx/htpasswd.users\n</li></ul></code></pre>\n<p>Introduzca y confirme una contraseña cuando se le solicite. Recuerde este dato de inicio de sesión o tome nota de él, ya que lo necesitará para acceder a la interfaz web de Kibana.</p>\n\n<p>A continuación, crearemos un archivo de bloque de servidor de Nginx. Como ejemplo, nos referiremos a este archivo como <code><span class=\"highlight\">your_domain</span></code>, aunque podría resultarle más útil darle al suyo un nombre más descriptivo. Por ejemplo, si tiene un FQDN y registros de DNS configurados para este servidor, podría darle a este archivo el nombre de su FQDN.</p>\n\n<p>Cree el archivo de bloque de servidor de Nginx usando nano o su editor de texto preferido:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Añada el siguiente bloque de código al archivo, y asegúrese de actualizar <code><span class=\"highlight\">your_domain</span></code> para que coincida con la FQDN o la dirección IP pública de su servidor. Con este código, se configura Nginx para dirigir el tráfico HTTP de su servidor a la aplicación de Kibana, que escucha en <code>localhost:5601</code>. También se configura Nginx para leer el archivo <code>htpasswd.users</code> y requerir la autenticación básica.</p>\n\n<p>Tenga en cuenta que, si siguió todo el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">tutorial de los requisitos previos de Nginx</a>, es posible que ya haya creado este archivo y lo haya completado con contenido. En ese caso, elimine todo el contenido existente en el archivo antes de añadir lo siguiente:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/your_domain\">/etc/nginx/sites-available/your_domain</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n\n    server_name <span class=\"highlight\">your_domain</span>;\n\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/htpasswd.users;\n\n    location / {\n        proxy_pass http://localhost:5601;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n</code></pre>\n<p>Cuando termine, guarde y cierre el archivo.</p>\n\n<p>A continuación, habilite la nueva configuración creando un enlace simbólico al directorio <code>sites-enabled</code>. Si ya creó un archivo de bloque de servidor con el mismo nombre en el requisito previo de Nginx, no necesitará ejecutar este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>A continuación, compruebe que no haya errores de sintaxis en la configuración:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Si se muestran errores en su resultado, regrese y verifique bien que el contenido que ingresó en su archivo de configuración se haya agregado correctamente. Una vez que vea <code>syntax is ok</code> en el resultado, reinicie el servicio de Nginx:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Si siguió la guía de configuración inicial para servidores, debería tener activado un firewall UFW. Para permitir las conexiones con Nginx, podemos ajustar las reglas escribiendo lo siguiente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 'Nginx Full'\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota:</strong> Si siguió el tutorial de los requisitos previos de Nginx, es posible que haya creado una regla de UFW que admita el perfil <code>Nginx HTTP</code> en el firewall. Debido a que el perfil <code>Nginx Full</code> admite el paso del tráfico HTTP y HTTPS por el firewall, puede eliminar de forma segura la regla que creó en el tutorial de los requisitos previos. Hágalo con el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw delete allow 'Nginx HTTP'\n</li></ul></code></pre>\n<p></p></span>\n\n<p>Con esto, el acceso a Kibana será posible a través de su FQDN o de la dirección IP pública de su servidor de Elastic Stack. Puede comprobar la página de estado del servidor de Kibana visitando la siguiente dirección e ingresando sus credenciales de inicio de sesión cuando se le soliciten:</p>\n<pre class=\"code-pre \"><code>http://<span class=\"highlight\">your_domain</span>/status\n</code></pre>\n<p>En esta página de estado, se muestra información sobre el uso de los recursos del servidor y se enumeran los complementos instalados.</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png\" alt=\"Página de estado de |Kibana\"></p>\n\n<p><span class='note'><strong>Nota</strong>: Como se indica en la sección de requisitos previos, se le recomienda habilitar SSL o TLS en su servidor. Ahora, puede seguir la guía de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Let’s Encrypt</a> para obtener un certificado SSL gratuito para Nginx en Ubuntu 20.04. Una vez que obtenga sus certificados SSL y TLS, puede volver y completar este tutorial.<br></span></p>\n\n<p>Ahora que el panel de Kibana está configurado, instalaremos el siguiente componente: Logstash.</p>\n\n<h2 id=\"paso-3-instalar-y-configurar-logstash\">Paso 3: Instalar y configurar Logstash</h2>\n\n<p>Aunque es posible que Beats envíe datos de manera directa a la base de datos de Elasticsearch, recomendamos usar Logstash para procesar los datos. Esto le permitirá, de forma más flexible, recopilar datos de diferentes fuentes, transformarlos en un formato común y exportarlos a otra base de datos.</p>\n\n<p>Instale Logstash con este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install logstash\n</li></ul></code></pre>\n<p>Después de instalar Logstash, puede seguir configurándolo. Los archivos de configuración de Logstash residen en el directorio <code>/etc/logstash/conf.d</code>. Para obtener más información sobre la sintaxis de configuración, puede consultar la <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\">referencia de configuración</a> que proporciona Elastic. A medida que configura el archivo, le resultará útil pensar que Logstash es un proceso que toma datos en un extremo, los procesa de una u otra manera y los envía a su destino (en este caso, el destino es Elasticsearch). Un proceso de Logstash tiene dos elementos necesarios, <code>input</code> y <code>output</code>, y un elemento opcional, <code>filter</code>. Los complementos de entrada consumen datos de una fuente, los complementos del filtro procesan los datos, y los complementos de salida escriben los datos en un destino.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png\" alt=\"Proceso de Logstash\"></p>\n\n<p>Cree un archivo de configuración llamado <code>02-beats-input.conf</code> en el que establecerá su entrada de Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/02-beats-input.conf\n</li></ul></code></pre>\n<p>Introduzca la siguiente configuración de <code>input</code>. Con esto, se especifica una entrada de <code>beats</code> que escuchará en el puerto TCP <code>5044</code>.</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/02-beats-input.conf\">/etc/logstash/conf.d/02-beats-input.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">input {\n  beats {\n    port =&gt; 5044\n  }\n}\n</code></pre>\n<p>Guarde y cierre el archivo.</p>\n\n<p>A continuación, cree un archivo de configuración llamado <code>30-elasticsearch-output.conf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf\n</li></ul></code></pre>\n<p>Introduzca la siguiente configuración de <code>output</code>. Básicamente, con este resultado, se configura Logstash para almacenar los datos de Beats en Elasticsearch, que se ejecuta en <code>localhost:9200</code>, en un índice con el nombre del Beat utilizado. El Beat utilizado en este tutorial es Filebeat:</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/30-elasticsearch-output.conf\">/etc/logstash/conf.d/30-elasticsearch-output.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">output {\n  if [@metadata][pipeline] {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    pipeline =&gt; \"%{[@metadata][pipeline]}\"\n    }\n  } else {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n\n\n</code></pre>\n<p>Guarde y cierre el archivo.</p>\n\n<p>Pruebe su configuración de Logstash con el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t\n</li></ul></code></pre>\n<p>Si no hay errores de sintaxis, su resultado mostrará <code>Config Validation Result: OK. Existing Logstash</code> después de unos segundos. Si no visualiza esto en su resultado, verifique cualquier error que aparezca en su resultado y actualice su configuración para corregirlo. Tenga en cuenta que recibirá advertencias de OpenJDK, pero no deberían causar ningún problema y pueden ignorarse.</p>\n\n<p>Si su prueba de configuración tiene éxito, inicie y habilite Logstash para implementar los cambios de configuración:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start logstash\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable logstash\n</li></ul></code></pre>\n<p>Ahora que Logstash se ejecuta de manera correcta y está totalmente configurado, instalaremos Filebeat.</p>\n\n<h2 id=\"paso-4-instalar-y-configurar-filebeat\">Paso 4: Instalar y configurar Filebeat</h2>\n\n<p>La pila de Elastic utiliza varios transportadores de datos ligeros llamados Beats para recopilar datos de varias fuentes y transportarlos a Logstash o Elasticsearch. Aquí se muestran los Beats que ahora están disponibles en Elastic:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>: recopila y envía archivos de registro.</li>\n<li><a href=\"https://www.elastic.co/products/beats/metricbeat\">Metricbeat</a>: recopila métricas de sus sistemas y servicios.</li>\n<li><a href=\"https://www.elastic.co/products/beats/packetbeat\">Packetbeat</a>: recopila y analiza datos de red.</li>\n<li><a href=\"https://www.elastic.co/products/beats/winlogbeat\">Winlogbeat</a>: recopila registros de eventos de Windows.</li>\n<li><a href=\"https://www.elastic.co/products/beats/auditbeat\">Auditbeat</a>: recopila datos del marco de trabajo de auditoría de Linux y supervisa la integridad de los archivos.</li>\n<li><a href=\"https://www.elastic.co/products/beats/heartbeat\">Heartbeat</a>: supervisa la disponibilidad de los servicios con sondeo activo.</li>\n</ul>\n\n<p>En este tutorial, usaremos Filebeat para reenviar registros locales a nuestra pila de Elastic.</p>\n\n<p>Instale Filebeat usando <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install filebeat\n</li></ul></code></pre>\n<p>A continuación, configure Filebeat para que se conecte a Logstash. Aquí, modificaremos el archivo de configuración de ejemplo que viene con Filebeat.</p>\n\n<p>Abra el archivo de configuración de Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/filebeat/filebeat.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Nota:</strong> Al igual que con Elasticsearch, el archivo de configuración de Filebeat está en formato YAML. Esto significa que una correcta sangría es esencial. Por lo tanto, asegúrese de usar el mismo número de espacios que se indican en estas instrucciones.<br></span></p>\n\n<p>Filebeat admite numerosas salidas, pero por lo general solo enviará eventos directamente a Elasticsearch o a Logstash para su procesamiento adicional. En este tutorial, usaremos Logstash para aplicar procesamiento adicional a los datos recopilados por Filebeat. Filebeat no tendrá que enviar datos de manera directa a Elasticsearch, por lo que desactivaremos esa salida. Para hacerlo, encuentre la sección <code>output.elasticsearch</code> y comente las siguientes líneas anteponiéndoles <code>#</code>:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>...\n<span class=\"highlight\">#</span>output.elasticsearch:\n  # Array of hosts to connect to.\n  <span class=\"highlight\">#</span>hosts: [\"localhost:9200\"]\n...\n</code></pre>\n<p>A continuación, configure la sección <code>output.logstash</code>. Elimine el comentario de las líneas <code>output.logstash:</code> y <code>hosts: [\"localhost:5044\"]</code> quitando <code>#</code>. Con esto, se configurará Filebeat para establecer conexión con Logstash en su servidor de Elastic Stack en el puerto <code>5044</code>, para el que especificamos una entrada de Logstash previamente:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>output.logstash:\n  # The Logstash hosts\n  hosts: [\"localhost:5044\"]\n</code></pre>\n<p>Guarde y cierre el archivo.</p>\n\n<p>La funcionalidad de Filebeat puede ampliarse con <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-modules.html\">módulos de Filebeat</a>. En este tutorial usaremos el módulo de <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-module-system.html\">sistema</a>, que recopila y analiza registros creados por el servicio de registro del sistema de distribuciones comunes de Linux.</p>\n\n<p>Vamos a habilitarlo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules enable system\n</li></ul></code></pre>\n<p>Puede ver una lista de módulos habilitados y desactivados ejecutando lo siguiente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules list\n</li></ul></code></pre>\n<p>Verá una lista similar a la siguiente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enabled:\nsystem\n\nDisabled:\napache2\nauditd\nelasticsearch\nicinga\niis\nkafka\nkibana\nlogstash\nmongodb\nmysql\nnginx\nosquery\npostgresql\nredis\ntraefik\n...\n</code></pre>\n<p>Por defecto, Filebeat está configurado para usar rutas predeterminadas para los registros syslog y de autorización. En el caso de este tutorial, no necesita aplicar cambios en la configuración. Puede ver los parámetros del módulo en el archivo de configuración <code>/etc/filebeat/modules.d/system.yml</code>.</p>\n\n<p>A continuación, debemos configurar los procesos de ingesta de Filebeat, que analizan los datos de registro antes de enviarlos a través de Logstash a Elasticsearch. Para cargar el proceso de ingesta para el módulo de sistema, introduzca el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --pipelines --modules system\n</li></ul></code></pre>\n<p>A continuación, cargue la plantilla de índice en Elasticsearch. Un <a href=\"https://www.elastic.co/blog/what-is-an-elasticsearch-index\"><em>índice de Elasticsearch</em></a> es un conjunto de documentos que tienen características similares. Los índices se identifican con un nombre, que se utiliza para referirse al índice cuando se realizan varias operaciones dentro de este. La plantilla de índice se aplicará de forma automática al crear un nuevo índice.</p>\n\n<p>Para cargar la plantilla, utilice el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=[\"localhost:9200\"]'\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Index setup finished.\n</code></pre>\n<p>Filebeat incluye paneles de muestra de Kibana que le permiten visualizar datos de Filebeat en Kibana. Para poder usar los paneles, deberá crear el patrón de índice y cargar los paneles en Kibana.</p>\n\n<p>Al cargarse los paneles, Filebeat se conecta a Elasticsearch para verificar la información de la versión. Para cargar paneles cuando se habilite Logstash, deberá desactivar el resultado de Logstash y habilitar el de Elasticsearch:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601\n</li></ul></code></pre>\n<p>Debería recibir un resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Overwriting ILM policy is disabled. Set `setup.ilm.overwrite:true` for enabling.\n\nIndex setup finished.\nLoading dashboards (Kibana must be running and reachable)\nLoaded dashboards\nSetting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.\nSee more: https://www.elastic.co/guide/en/elastic-stack-overview/current/xpack-ml.html\nLoaded machine learning job configurations\nLoaded Ingest pipelines\n</code></pre>\n<p>Ahora podrá iniciar y habilitar Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start filebeat\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable filebeat\n</li></ul></code></pre>\n<p>Si configuró su pila de Elastic de manera correcta, Filebeat iniciará el envío de sus registros syslog y de autorización a Logstash, que a su vez cargará esos datos en Elasticsearch.</p>\n\n<p>Para verificar que Elasticsearch realmente reciba estos datos, consulte el índice de Filebeat con este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'\n</li></ul></code></pre>\n<p>Debería recibir un resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\n{\n{\n  \"took\" : 4,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 2,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 4040,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"filebeat-7.7.1-2020.06.04\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"FiZLgXIB75I8Lxc9ewIH\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"cloud\" : {\n            \"provider\" : \"digitalocean\",\n            \"instance\" : {\n              \"id\" : \"194878454\"\n            },\n            \"region\" : \"nyc1\"\n          },\n          \"@timestamp\" : \"2020-06-04T21:45:03.995Z\",\n          \"agent\" : {\n            \"version\" : \"7.7.1\",\n            \"type\" : \"filebeat\",\n            \"ephemeral_id\" : \"cbcefb9a-8d15-4ce4-bad4-962a80371ec0\",\n            \"hostname\" : \"june-ubuntu-20-04-elasticstack\",\n            \"id\" : \"fbd5956f-12ab-4227-9782-f8f1a19b7f32\"\n          },\n\n\n...\n</code></pre>\n<p>Si su resultado no muestra coincidencias, Elasticsearch no está cargando ningún registro bajo el índice que buscó, y deberá verificar su configuración en busca de errores. Si obtuvo el resultado esperado, continúe con el siguiente paso, en el que veremos la manera de explorar algunos de los paneles de Kibana.</p>\n\n<h2 id=\"paso-5-explorar-los-paneles-de-kibana\">Paso 5: Explorar los paneles de Kibana</h2>\n\n<p>Volvamos a la interfaz web de Kibana que instalamos antes.</p>\n\n<p>En un navegador web, diríjase al FQDN o a la dirección IP pública de su servidor de Elastic Stack. Si su sesión se ha interrumpido, deberá volver a introducir las credenciales que definió en el paso 2. Una vez que haya iniciado sesión, debería recibir la página de inicio de Kibana:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg\" alt=\"Página de inicio de Kibana\"></p>\n\n<p>Haga clic en el enlace <strong>Descubrir</strong> de la barra de navegación a la izquierda (puede tener que hacer clic en el icono <strong>Expandir</strong> de la parte inferior izquierda para ver los elementos del menú de navegación). En la página <strong>Discover</strong>, seleccione el patrón de índice predeterminado de <strong>filebeat-</strong>* para ver datos de Filebeat. Por defecto, esto le mostrará todos los datos de registro de los últimos 15 minutos. Visualizará un histograma con eventos de registro y algunos mensajes de registro a continuación:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg\" alt=\"Página de Discover\"></p>\n\n<p>Aquí puede buscar y explorar sus registros y también personalizar su panel. Sin embargo, en este punto, no habrá muchos registros porque solo recopila syslogs de su servidor de Elastic Stack.</p>\n\n<p>Utilice el panel del lado izquierdo para acceder a la página <strong>Dashboard</strong> y buscar los paneles de <strong>Filebeat System</strong>. Ahí puede seleccionar los paneles de muestra que vienen con el módulo <code>system</code> de Filebeat.</p>\n\n<p>Por ejemplo, puede ver estadísticas detalladas basadas en sus mensajes de syslog:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg\" alt=\"Panel Syslog\"></p>\n\n<p>También puede ver los usuarios que utilizaron el comando <code>sudo</code> y el momento en que lo hicieron:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg\" alt=\"Panel Sudo\"></p>\n\n<p>Kibana tiene muchas otras características, como graficar y filtrar. No dude en explorarlas.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>A través de este tutorial, aprendió a instalar y configurar Elastic Stack para recopilar y analizar registros del sistema. Recuerde que puede enviar casi cualquier tipo de datos de registro o de índice a Logstash usando <a href=\"https://www.elastic.co/products/beats\">Beats</a>, pero los datos se vuelven aún más útiles si se analizan y estructuran con un filtro de Logstash, ya que transforma los datos en un formato uniforme que Elasticsearch puede leer de forma sencilla.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:46 +0000","feedId":8037,"bgimg":"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png","linkMd5":"4aaa22fe5dfc497540cc577f2eea64f3","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","destWidth":1833,"destHeight":948,"sourceBytes":40417,"destBytes":48810,"author":"Erin Glass","articleImgCdnMap":{"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn82@2020_2/2020/08/31/07-48-31-557_41a6f5cccef041e1.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn1@2020_3/2020/08/31/07-48-32-396_0638f11900b9faf4.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn37@2020_3/2020/08/31/07-48-33-221_1dfbe5e28e76fefb.webp","http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn10@2020_4/2020/08/31/07-48-32-522_c0c2011e332e864d.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn5@2020_6/2020/08/31/07-48-32-458_2cfaecfed9ac513b.webp"},"publishedOrCreatedDate":1598860106979},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"How To Debug React Components Using React Developer Tools","link":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","description":"<p><em>The author selected <a href=\"https://creativecommons.org/\">Creative Commons</a> to receive a donation as part of the <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> program.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Since React apps are made to scale and grow quickly, it&rsquo;s easy for subtle bugs to infiltrate your code. The <a href=\"https://reactjs.org/blog/2019/08/15/new-react-devtools.html\">React Developer Tools browser extension</a> can help you track down these bugs by giving you more insight into the current <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-on-react-class-components\">state</a> for each <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-custom-components-in-react\">component</a>. React Developer Tools gives you an interface for exploring the React component tree along with the current <a href=\"https://www.digitalocean.com/community/tutorials/how-to-customize-react-components-with-props\">props</a>, state, and <a href=\"https://www.digitalocean.com/community/tutorials/how-to-share-state-across-react-components-with-context\">context</a> for individual components. React Developer Tools also lets you determine which components are re-rendering and can generate graphs to show how long individual components take to render. You can use this information to track down inefficient code or to optimize data-heavy components.</p>\n\n<p>This tutorial begins by installing the React Developer Tools browser extension. You&rsquo;ll then build a text analyzer as a test application, which will take a block of text and display information such as word count, character count, and character usage. Finally, you will use React Developer Tools to explore the text analyzer&rsquo;s components and keep track of the changing props and context. The examples will use the <a href=\"https://www.google.com/chrome/\">Chrome browser</a>, but you can also use the plugin for <a href=\"https://addons.mozilla.org/en-US/firefox/addon/react-devtools/\">Firefox</a>.</p>\n\n<p>By the end of this tutorial, you&rsquo;ll be able to start using the React Developer Tools to debug and explore any React project.</p>\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\n<ul>\n<li><p>To use the Chrome React Developer Tools extension, you will need to download and install the <a href=\"https://www.google.com/chrome/\">Google Chrome web browser</a> or the open-source <a href=\"https://www.chromium.org/\">Chromium web browser</a>. You can also following along using the <a href=\"https://addons.mozilla.org/en-US/firefox/addon/react-devtools/\">React Developer Tools FireFox plugin</a> for the <a href=\"https://www.mozilla.org/en-US/firefox/new/\">FireFox web browser</a>.</p></li>\n<li><p>You will need a development environment running <a href=\"https://nodejs.org/en/about/\">Node.js</a>; this tutorial was tested on Node.js version 10.22.0 and npm version 6.14.6. To install this on macOS or Ubuntu 18.04, follow the steps in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">How to Install Node.js and Create a Local Development Environment on macOS</a> or the <strong>Installing Using a PPA</strong> section of <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">How To Install Node.js on Ubuntu 18.04</a>.</p></li>\n<li><p>A React development environment set up with <a href=\"https://github.com/facebook/create-react-app\">Create React App</a>. To set this up, follow <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-on-react-class-components#step-1-%E2%80%94-creating-an-empty-project\"><strong>Step 1 — Creating an Empty Project</strong> of the How To Manage State on React Class Components tutorial</a>, which will remove the non-essential boilerplate. This tutorial will use <code>debug-tutorial</code> as the project name.</p></li>\n<li><p>You will be using React components and Hooks in this tutorial, including the <code>useState</code> and context Hooks. You can learn about components and Hooks in our tutorials <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-custom-components-in-react\">How To Create Custom Components in React</a>, <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-with-hooks-on-react-components\">How To Manage State with Hooks on React Components</a>, and <a href=\"https://www.digitalocean.com/community/tutorials/how-to-share-state-across-react-components-with-context\">How To Share State Across React Components with Context</a>.</p></li>\n<li><p>You will also need a basic knowledge of JavaScript and HTML, which you can find in our <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-build-a-website-with-html\">How To Build a Website with HTML series</a> and in <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-javascript\">How To Code in JavaScript</a>. Basic knowledge of CSS would also be useful, which you can find at the <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS\">Mozilla Developer Network</a>.</p></li>\n</ul>\n\n<h2 id=\"step-1-—-installing-the-react-developer-tools-extension\">Step 1 — Installing the React Developer Tools Extension</h2>\n\n<p>In this step, you&rsquo;ll install the React Developer Tools broswer extension in Chrome. You&rsquo;ll use the developer tools in the Chrome <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-the-javascript-developer-console#working-with-the-console-in-a-browser\">JavaScript console</a> to explore the component tree of the <code>debug-tutorial</code> project you made in the Prerequisites. This step will use Chrome, but the steps will be nearly identical for installing the React Developer Tools as an <a href=\"https://addons.mozilla.org/en-US/firefox/addon/react-devtools/\">add-on</a> in Firefox.</p>\n\n<p>By the end of this step, you&rsquo;ll have the React Developer Tools installed in your browser and you&rsquo;ll be able to explore and filter components by name.</p>\n\n<p>The React Developer Tools is a plugin for the Chrome and Firefox browser. When you add the extension, you are adding additional tools to the developer console. Visit the <a href=\"https://chrome.google.com/webstore/detail/react-developer-tools/fmkadmapgofadopljbjfkapdkoienihi\">Chrome plugin page</a> for React Developer Tools to install the extension.</p>\n\n<p>Click on the <strong>Add to Chrome</strong> button. Then click on the <strong>Add extension</strong> button to confirm:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/add_extension_button.png\" alt=\"Chrome add extension button\"></p>\n\n<p>Chrome will install the extension, and a success message and a new icon will appear in the upper right corner of your browser next to the address bar:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/chrome_success_message.png\" alt=\"Chrome success message\"></p>\n\n<p>If the icon does not appear, you can add it by clicking on the puzzle piece, then clicking on the pushpin icon by the React Developer Tools:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/pin_extension.png\" alt=\"Pin extension\"></p>\n\n<p>When you are on a page that does not have any React components, the icon will appear gray. However, if you are on a page with React components, the icon will appear blue and green. If you click on the icon, it will indicate that the application is running a production version of React.</p>\n\n<p>Visit <a href=\"https://www.digitalocean.com/\"><code>digitalocean.com</code></a>, to find that the homepage is running a production version of React:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/DO_React_production_build.png\" alt=\"DigitalOcean React Production Build information\"></p>\n\n<p>Now that you are on a website that uses React, open the console to access the React Developer Tools. Open the console by either right-clicking and inspecting an element or by opening the toolbar by clicking <strong>View &gt; Developer &gt; JavaScript console</strong>.</p>\n\n<p>When you open the console, you&rsquo;ll find two new tabs: <strong>Components</strong> and <strong>Profiler</strong>:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/console_open.png\" alt=\"Console Open\"></p>\n\n<p>The <strong>Components</strong> tab will show the current React component tree, along with any props, state, or context. The <strong>Profiler</strong> tab lets you record interactions and measure component rendering. You&rsquo;ll explore the <strong>Profiler</strong> tab in <a href=\"\">Step 3</a>.</p>\n\n<p>Click on the <strong>Components</strong> tab to see the current component tree.</p>\n\n<p>Since this is a production build, the code will be <a href=\"https://en.wikipedia.org/wiki/Minification_(programming)\">minified</a> and the components will not have descriptive names:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/components_for_DO.png\" alt=\"Components for digitalocean.com in the console\"></p>\n\n<p>Now that you&rsquo;ve tried out React Developer Tools on a working website, you can use it on your test application. If you haven&rsquo;t started your <code>debug-tutorial</code> application yet, go to a terminal window and run <code>npm start</code> from the root of the project.</p>\n\n<p>Open a browser to <a href=\"http://localhost:3000\"><code>http://localhost:3000</code></a>.</p>\n\n<p>Notice that the icon for React Developer Tools is now red and white. If you click on the React Developer Tools icon, you&rsquo;ll see a warning that the page is in development mode. Since you are still working on the sample application, this is expected.</p>\n\n<p>Open the console and you&rsquo;ll find the name of the <code>App</code> component in the <strong>Components</strong> tab.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/base_component.png\" alt=\"Base Component\"></p>\n\n<p>There&rsquo;s not a lot of information yet, but as you build out the project in the next step, you&rsquo;ll see all of your components forming a navigable tree.</p>\n\n<p>In this step, you added the React Developer Tools extension to Chrome. You activated the tools on both a production and a development page, and you briefly explored your <code>debug-tutorial</code> project in the <strong>Components</strong> tab. In the next step, you&rsquo;ll build the text analyzer that you&rsquo;ll use to try out the features of the React Developer Tools.</p>\n\n<h2 id=\"step-2-—-identifying-real-time-component-props-and-context\">Step 2 — Identifying Real-Time Component Props and Context</h2>\n\n<p>In this step, you&rsquo;ll build a small application to analyze a block of text. The app will determine and report the word count, character count, and character frequency of the text in the input field. As you build the application, you&rsquo;ll use React Developer Tools to explore the current state and props of each component. You&rsquo;ll also use React Developer Tools to view the current context in deeply nested components. Finally, you&rsquo;ll use the tools to identify components that re-render as state changes.</p>\n\n<p>By the end of this step, you&rsquo;ll be able to use the React Developer Tools to explore a live application and to observe the current props and state without console statements or debuggers.</p>\n\n<p>To start, you will create an input component that will take a large amount of text.</p>\n\n<p>Open the <code>App.js</code> file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/App/App.js\n</li></ul></code></pre>\n<p>Inside the component, add a <code>div</code> with a class of <code>wrapper</code>, then create a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/label\"><code>&lt;label&gt;</code> element</a> surrounding a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element/textarea\"><code>&lt;textarea&gt;</code> element</a>:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/App/App.js\">debug-tutorial/src/components/App/App.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React from 'react';\nimport './App.css';\n\nfunction App() {\n  return<span class=\"highlight\">(</span>\n    <span class=\"highlight\">&lt;div className=\"wrapper\"&gt;</span>\n     <span class=\"highlight\">&lt;label htmlFor=\"text\"&gt;</span>\n       <span class=\"highlight\">Add Your Text Here:</span>\n       <span class=\"highlight\">&lt;br&gt;</span>\n       <span class=\"highlight\">&lt;textarea</span>\n         <span class=\"highlight\">id=\"text\"</span>\n         <span class=\"highlight\">name=\"text\"</span>\n         <span class=\"highlight\">rows=\"10\"</span>\n         <span class=\"highlight\">cols=\"100\"</span>\n       <span class=\"highlight\">&gt;</span>\n       <span class=\"highlight\">&lt;/textarea&gt;</span>\n      <span class=\"highlight\">&lt;/label&gt;</span>\n    <span class=\"highlight\">&lt;/div&gt;</span>\n  <span class=\"highlight\">)</span>\n}\n\nexport default App;\n</code></pre>\n<p>This will be the input area for your user. The <code>htmlFor</code> attribute links the <code>label</code> element to elements with an <code>id</code> of <code>text</code> using <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-react-elements-with-jsx\">JSX</a>. You also give the <code>&lt;textarea&gt;</code> component <code>10</code> rows and <code>100</code> columns to provide room for a large amount of text.</p>\n\n<p>Save and close the file. Next, open <code>App.css</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/App/App.css\n</li></ul></code></pre>\n<p>Add some styling to the application by replacing the contents with the following:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/App.App.css\">debug-tutorial/src/components/App.App.css</div><pre class=\"code-pre \"><code class=\"code-highlight language-css\">.wrapper {\n    padding: 20px;\n}\n\n.wrapper button {\n    background: none;\n    border: black solid 1px;\n    cursor: pointer;\n    margin-right: 10px;\n}\n\n.wrapper div {\n    margin: 20px 0;\n}\n</code></pre>\n<p>Here you add some padding to the <code>wrapper</code> class, then simplify child <code>&lt;button&gt;</code> elements by removing the background color and adding some margin. Finally, you add a small margin to child <code>&lt;div&gt;</code> elements. These styles will apply to components you will build to display information about the text.</p>\n\n<p>Save the file. When you do, the browser will refresh and you&rsquo;ll see the input:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/Text_area.png\" alt=\"Text area\"></p>\n\n<p>Open <code>App.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/App/App.js\n</li></ul></code></pre>\n<p>Next, create a <a href=\"https://www.digitalocean.com/community/tutorials/how-to-share-state-across-react-components-with-context\">context</a> to hold the value from the <code>&lt;textarea&gt;</code> element. Capture the data using the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-with-hooks-on-react-components#step-2-%E2%80%94-setting-state-with-usestate\"><code>useState</code> Hook</a>:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/App/App.js\">debug-tutorial/src/components/App/App.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React<span class=\"highlight\">, { createContext, useState }</span> from 'react';\nimport './App.css';\n\n<span class=\"highlight\">export const TextContext = createContext();</span>\n\nfunction App() {\n  <span class=\"highlight\">const [text, setText] = useState('');</span>\n\n  return(\n    <span class=\"highlight\">&lt;TextContext.Provider value={text}&gt;</span>\n      &lt;div className=\"wrapper\"&gt;\n        &lt;label htmlFor=\"text\"&gt;\n          Add Your Text Here:\n          &lt;br&gt;\n          &lt;textarea\n            id=\"text\"\n            name=\"text\"\n            rows=\"10\"\n            cols=\"100\"\n            <span class=\"highlight\">onChange={e =&gt; setText(e.target.value)}</span>\n          &gt;\n          &lt;/textarea&gt;\n        &lt;/label&gt;\n      &lt;/div&gt;\n    <span class=\"highlight\">&lt;/TextContext.Provider&gt;</span>\n  )\n}\n\nexport default App;\n</code></pre>\n<p>Be sure to export <code>TextContext</code>, then wrap the whole component with the <code>TextContext.Provider</code>. Capture the data by adding an <code>onChange</code> prop to your <code>&lt;textarea&gt;</code> element.</p>\n\n<p>Save the file. The browser will reload. Be sure that you have React Developer Tools open and notice that <code>App</code> component now shows the<code>Context.Provider</code> as a child component.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/component_context.png\" alt=\"Component context in React Developer Tools\"></p>\n\n<p>The component by default has a generic name—<code>Context</code>—but you can change that by adding a <code>displayName</code> property to the generated context. Inside <code>App.js</code>, add a line where you set the <code>displayName</code> to <code>TextContext</code>:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/App/App.js\">debug-tutorial/src/components/App/App.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { createContext, useState } from 'react';\nimport './App.css';\n\nexport const TextContext = createContext();\n<span class=\"highlight\">TextContext.displayName = 'TextContext';</span>\n\nfunction App() {\n    ...\n}\n\nexport default App;\n</code></pre>\n<p>It is not necessary to add a <code>displayName</code>, but it does help to navigate components when analyzing the component tree in the console. You will also see the value of the <code>useState</code> Hook in the side bar. Type some text in the input and you&rsquo;ll see the updated value in React Developer Tools under the <strong>hooks</strong> section on the <code>App</code> component.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/update_value_devtools.png\" alt=\"Update Value in Developer Tools\"></p>\n\n<p>The Hook also has a generic name of <code>State</code>, but this is not as easy to update as the context. There is a <a href=\"https://reactjs.org/docs/hooks-reference.html#usedebugvalue\"><code>useDebugValue</code></a> Hook, but it only works on custom Hooks and is not recommended for all custom Hooks.</p>\n\n<p>In this case, the state for the <code>App</code> component is the prop to <code>TextContext.Provider</code>. Click on the <code>TextContext.Provider</code> in the React Developer Tools and you&rsquo;ll see that the <code>value</code> also reflects the input value that you set with the state:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/update_value_context.png\" alt=\"Updated value for the context\"></p>\n\n<p>React Developer Tools is showing you real time prop and context information, and the value will grow as you add components.</p>\n\n<p>Next, add a component called <code>TextInformation</code>. This component will be a container for the components with specific data analysis, such as the word count.</p>\n\n<p>First, make the directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir src/components/TextInformation\n</li></ul></code></pre>\n<p>Then open <code>TextInformation.js</code> in your text editor.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/TextInformation/TextInformation.js\n</li></ul></code></pre>\n<p>Inside the component, you will have three separate components: <code>CharacterCount</code>, <code>WordCount</code>, and <code>CharacterMap</code>. You&rsquo;ll make these components in just a moment.</p>\n\n<p>The <code>TextInformation</code> component will use the <code>useReducer</code> Hook to toggle the display of each component. Create a <code>reducer</code> function that toggles the display value of each component and a button to toggle each component with an <code>onClick</code> action:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/TextInformation/TextInformation.js\">debug-tutorial/src/components/TextInformation/TextInformation.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useReducer } from 'react';\n\nconst reducer = (state, action) =&gt; {\n  return {\n    ...state,\n    [action]: !state[action]\n  }\n}\nexport default function TextInformation() {\n  const [tabs, toggleTabs] = useReducer(reducer, {\n    characterCount: true,\n    wordCount: true,\n    characterMap: true\n  });\n\n  return(\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; toggleTabs('characterCount')}&gt;Character Count&lt;/button&gt;\n      &lt;button onClick={() =&gt; toggleTabs('wordCount')}&gt;Word Count&lt;/button&gt;\n      &lt;button onClick={() =&gt; toggleTabs('characterMap')}&gt;Character Map&lt;/button&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>Notice that your <code>useReducer</code> Hook starts with an object that maps each key to a boolean. The reducer function uses the <a href=\"https://www.digitalocean.com/community/tutorials/js-spread-operator\">spread operator</a> to preserve the previous value while setting a new value using the <code>action</code> parameter.</p>\n\n<p>Save and close the file. Then open <code>App.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/App/App.js\n</li></ul></code></pre>\n<p>Add in your new component:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/App/App.js\">debug-tutorial/src/components/App/App.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { createContext, useState } from 'react';\nimport './App.css';\n<span class=\"highlight\">import TextInformation from '../TextInformation/TextInformation';</span>\n\n...\n\nfunction App() {\n  const [text, setText] = useState('');\n\n  return(\n    &lt;TextContext.Provider value={text}&gt;\n      &lt;div className=\"wrapper\"&gt;\n        &lt;label htmlFor=\"text\"&gt;\n          Add Your Text Here:\n          &lt;br&gt;\n          &lt;textarea\n            id=\"text\"\n            name=\"text\"\n            rows=\"10\"\n            cols=\"100\"\n            onChange={e =&gt; setText(e.target.value)}\n          &gt;\n          &lt;/textarea&gt;\n        &lt;/label&gt;\n        <span class=\"highlight\">&lt;TextInformation /&gt;</span>\n      &lt;/div&gt;\n    &lt;/TextContext.Provider&gt;\n  )\n}\n\nexport default App;\n</code></pre>\n<p>Save and close the file. When you do, the browser will reload, and you&rsquo;ll see the updated component. If you click on <code>TextInformation</code> in React Developer Tools, you&rsquo;ll see the value update on each button click:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/update_reducer_on_click.gif\" alt=\"Update Reducer on Click\"></p>\n\n<p>Now that you have the container component, you&rsquo;ll need to create each informational component. Each component will take a prop called <code>show</code>. If <code>show</code> is falsy, the component will return <code>null</code>. The components will consume the <code>TextContext</code>, analyze the data, and display the result.</p>\n\n<p>To start, create the <code>CharacterCount</code> component.</p>\n\n<p>First, make a new directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir src/components/CharacterCount\n</li></ul></code></pre>\n<p>Then, open <code>CharacterCount.js</code> in your text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/CharacterCount/CharacterCount.js\n</li></ul></code></pre>\n<p>Inside the component, create a function that uses the <code>show</code> prop and displays <code>null</code> if <code>show</code> is falsy:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/CharacterCount/CharacterCount.js\">debug-tutorial/src/components/CharacterCount/CharacterCount.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useContext } from 'react';\nimport PropTypes from 'prop-types';\nimport { TextContext } from '../App/App';\n\nexport default function CharacterCount({ show }) {\n  const text = useContext(TextContext);\n\n  if(!show) {\n    return null;\n  }\n\n  return(\n    &lt;div&gt;\n      Character Count: {text.length}\n    &lt;/div&gt;\n  )\n}\n\nCharacterCount.proTypes = {\n  show: PropTypes.bool.isRequired\n}\n</code></pre>\n<p>Inside the <code>CharacterCount</code> function, you assign the value of <code>TextContext</code> to a variable using the <code>useContext</code> Hook. You then return a <code>&lt;div&gt;</code> that shows the character count using the <code>length</code> method. Finally, <a href=\"https://www.digitalocean.com/community/tutorials/how-to-customize-react-components-with-props#step-3-%E2%80%94-creating-predictable-props-with-proptypes-and-defaultprops\"><code>PropTypes</code></a> adds a weak typing system to provide some enforcement to make sure the wrong prop type is not passed.</p>\n\n<p>Save and close the file. Open <code>TextInformation.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/TextInformation/TextInformation.js\n</li></ul></code></pre>\n<p>Import <code>CharacterCount</code> and add the component after the buttons, passing <code>tabs.characterCount</code> as the <code>show</code> prop:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/TextInformation/TextInformation.js\">debug-tutorial/src/components/TextInformation/TextInformation.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useReducer } from 'react';\n<span class=\"highlight\">import CharacterCount from '../CharacterCount/CharacterCount';</span>\n\nconst reducer = (state, action) =&gt; {\n  return {\n    ...state,\n    [action]: !state[action]\n  }\n}\n\nexport default function TextInformation() {\n  const [tabs, toggleTabs] = useReducer(reducer, {\n    characterCount: true,\n    wordCount: true,\n    characterMap: true\n  });\n\n  return(\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; toggleTabs('characterCount')}&gt;Character Count&lt;/button&gt;\n      &lt;button onClick={() =&gt; toggleTabs('wordCount')}&gt;Word Count&lt;/button&gt;\n      &lt;button onClick={() =&gt; toggleTabs('characterMap')}&gt;Character Map&lt;/button&gt;\n      <span class=\"highlight\">&lt;CharacterCount show={tabs.characterCount} /&gt;</span>\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>Save the file. The browser will reload and you&rsquo;ll see the component in the React Developer Tools. Notice that as you add words in the input, the context will update. If you toggle the component, you&rsquo;ll see the props update after each click:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/adding_text_toggling.gif\" alt=\"Adding text and toggling\"></p>\n\n<p>You can also manually add or change a prop by clicking on the property and updating the value:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/manually_changing_props.gif\" alt=\"Manually Changing Props\"></p>\n\n<p>Next, add a <code>WordCount</code> component.</p>\n\n<p>Create the directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir src/components/WordCount\n</li></ul></code></pre>\n<p>Open the file in a text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/WordCount/WordCount.js\n</li></ul></code></pre>\n<p>Make a component that is similar to <code>CharacterCount</code>, but use the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-index-split-and-manipulate-strings-in-javascript#splitting-strings\"><code>split</code> method</a> on spaces to create an <a href=\"https://www.digitalocean.com/community/tutorials/understanding-arrays-in-javascript\">array</a> of words before showing the length:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/WordCount/WordCount.js\">debug-tutorial/src/components/WordCount/WordCount.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useContext } from 'react';\nimport PropTypes from 'prop-types';\nimport { TextContext } from '../App/App';\n\nexport default function WordCount({ show }) {\n  const text = useContext(TextContext);\n\n  if(!show) {\n    return null;\n  }\n\n  return(\n    &lt;div&gt;\n      Word Count: {text.split(' ').length}\n    &lt;/div&gt;\n  )\n}\n\nWordCount.proTypes = {\n  show: PropTypes.bool.isRequired\n}\n</code></pre>\n<p>Save and close the file.</p>\n\n<p>Finally, create a <code>CharacterMap</code> component. This component will show how often a specific character is used in a block of text. It will then sort the characters by frequency in the passage and display the results.</p>\n\n<p>First, make the directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir src/components/CharacterMap\n</li></ul></code></pre>\n<p>Next, open <code>CharacterMap.js</code> in a text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/CharacterMap/CharacterMap.js\n</li></ul></code></pre>\n<p>Import and use the <code>TextContext</code> component and use the <code>show</code> prop to display results as you did in the previous components:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/CharacterMap/CharacterMap.js\">debug-tutorial/src/components/CharacterMap/CharacterMap.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useContext } from 'react';\nimport PropTypes from 'prop-types';\nimport { TextContext } from '../App/App';\n\nexport default function CharacterMap({ show }) {\n  const text = useContext(TextContext);\n\n  if(!show) {\n    return null;\n  }\n\n  return(\n    &lt;div&gt;\n      Character Map: {text.length}\n    &lt;/div&gt;\n  )\n}\n\nCharacterMap.proTypes = {\n  show: PropTypes.bool.isRequired\n}\n</code></pre>\n<p>This component will need a slightly more complicated function to create the frequency map for each letter. You&rsquo;ll need to go through each character and increment a value anytime there is a repeat. Then you&rsquo;ll need to take that data and sort it so that the most frequent letters are at the top of the list.</p>\n\n<p>To do this, add the following highlighted code:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/CharacterMap/CharacterMap.js\">debug-tutorial/src/components/CharacterMap/CharacterMap.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">\nimport React, { useContext } from 'react';\nimport PropTypes from 'prop-types';\nimport { TextContext } from '../App/App';\n\n<span class=\"highlight\">function itemize(text){</span>\n <span class=\"highlight\">const letters = text.split('')</span>\n   <span class=\"highlight\">.filter(l =&gt; l !== ' ')</span>\n   <span class=\"highlight\">.reduce((collection, item) =&gt; {</span>\n     <span class=\"highlight\">const letter = item.toLowerCase();</span>\n     <span class=\"highlight\">return {</span>\n       <span class=\"highlight\">...collection,</span>\n       <span class=\"highlight\">[letter]: (collection[letter] || 0) + 1</span>\n     <span class=\"highlight\">}</span>\n   <span class=\"highlight\">}, {})</span>\n <span class=\"highlight\">return Object.entries(letters)</span>\n   <span class=\"highlight\">.sort((a, b) =&gt; b[1] - a[1]);</span>\n<span class=\"highlight\">}</span>\n\nexport default function CharacterMap({ show }) {\n  const text = useContext(TextContext);\n\n  if(!show) {\n    return null;\n  }\n\n  return(\n    &lt;div&gt;\n     Character Map:\n     <span class=\"highlight\">{itemize(text).map(character =&gt; (</span>\n       <span class=\"highlight\">&lt;div key={character[0]}&gt;</span>\n         <span class=\"highlight\">{character[0]}: {character[1]}</span>\n       <span class=\"highlight\">&lt;/div&gt;</span>\n     <span class=\"highlight\">))}</span>\n    &lt;/div&gt;\n  )\n}\n\nCharacterMap.proTypes = {\n  show: PropTypes.bool.isRequired\n}\n</code></pre>\n<p>In this code, you create a function called <code>itemize</code> that splits the text into an <a href=\"https://www.digitalocean.com/community/tutorials/understanding-arrays-in-javascript\">array</a> of characters using the <code>split()</code> string method. Then you <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#reduce()\"><code>reduce</code></a> the array to an object by adding the character and then incrementing the count for each subsequent character. Finally, you convert the object to an array of pairs using <a href=\"https://www.digitalocean.com/community/tutorials/js-object-entries-values#objectentries\"><code>Object.entries</code></a> and <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-mutator-methods#sort()\"><code>sort</code></a> to put the most used characters at the top.</p>\n\n<p>After you create the function, you pass the text to the function in the <code>render</code> method and <code>map</code> over the results to display the character—array value <code>[0]</code>—and the count—array value <code>[1]</code>—inside a <code>&lt;div&gt;</code>.</p>\n\n<p>Save and close the file. This function will give you an opportunity to explore some performance features of the React Developer Tools in the next section.</p>\n\n<p>Next, add the new components to <code>TextInformation</code> and look at the values in React Developer Tools.</p>\n\n<p>Open <code>TextInformation.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/TextInformation/TextInformation.js\n</li></ul></code></pre>\n<p>Import and render the new components:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/TextInformation/TextInformation.js\">debug-tutorial/src/components/TextInformation/TextInformation.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useReducer } from 'react';\nimport CharacterCount from '../CharacterCount/CharacterCount';\n<span class=\"highlight\">import CharacterMap from '../CharacterMap/CharacterMap';</span>\n<span class=\"highlight\">import WordCount from '../WordCount/WordCount';</span>\n\nconst reducer = (state, action) =&gt; {\n  return {\n    ...state,\n    [action]: !state[action]\n  }\n}\n\nexport default function TextInformation() {\n  const [tabs, toggleTabs] = useReducer(reducer, {\n    characterCount: true,\n    wordCount: true,\n    characterMap: true\n  });\n\n  return(\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; toggleTabs('characterCount')}&gt;Character Count&lt;/button&gt;\n      &lt;button onClick={() =&gt; toggleTabs('wordCount')}&gt;Word Count&lt;/button&gt;\n      &lt;button onClick={() =&gt; toggleTabs('characterMap')}&gt;Character Map&lt;/button&gt;\n      &lt;CharacterCount show={tabs.characterCount} /&gt;\n      <span class=\"highlight\">&lt;WordCount show={tabs.wordCount} /&gt;</span>\n      <span class=\"highlight\">&lt;CharacterMap show={tabs.characterMap} /&gt;</span>\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>Save and close the file. When you do, the browser will refresh, and if you add in some data, you&rsquo;ll find the character frequency analysis in the new components:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/characterMap_component_devtools.png\" alt=\"CharacterMap Component in React Developer Tools\"></p>\n\n<p>In this section, you used React Developer Tools to explore the component tree. You also learned how to see the real-time props for each component and how to manually change the props using the developer tools. Finally, you viewed the context for the component change with input.</p>\n\n<p>In the next section, you&rsquo;ll use the React Developer Tools <strong>Profiler</strong> tab to identify components that have long render times.</p>\n\n<h2 id=\"step-3-—-tracking-component-rendering-across-interactions\">Step 3 — Tracking Component Rendering Across Interactions</h2>\n\n<p>In this step, you&rsquo;ll use the React Developer Tools profiler to track component rendering and re-rendering as you use the sample application. You&rsquo;ll navigate <em>flamegraphs</em>, or visualizations of your app&rsquo;s relevant optimization metrics, and use the information to identify inefficient components, reduce rendering time, and increase application speed.</p>\n\n<p>By the end of this step, you&rsquo;ll know how to identify components that render during user interactions and how to compose components to reduce inefficient rendering.</p>\n\n<p>A quick way to see how components change each other is to enable highlighting when a component is re-rendered. This will give you a visual overview of how the components respond to changing data.</p>\n\n<p>In React Developer Tools, click on the <strong>Settings</strong> icon. It will look like a gear:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/settings_icon.png\" alt=\"Settings icon\"></p>\n\n<p>Then select the option under <strong>General</strong> that says <strong>Highlight updates when components render</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/highlight_changes.png\" alt=\"Highlight changes\"></p>\n\n<p>When you make any changes, React Developer Tools will highlight components that re-render. For example, when you change input, every component re-renders because the data is stored on a Hook at the root level and every change will re-render the whole component tree.</p>\n\n<p>Notice the highlighting around the components, including the top of the screen around the root component:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/highlighting_text.gif\" alt=\"Highlighting Text\"></p>\n\n<p>Compare that to how the components re-render when you click on one of the buttons to toggle the data. If you click one of the buttons, the components under <code>TextInformation</code> will re-render, but not the root component:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/rerendering_lower_components.gif\" alt=\"Rerendering lower components only\"></p>\n\n<p>Showing the re-renders will give you a quick idea of how the components are related, but it doesn&rsquo;t give you a lot of data to analyze specific components. To gain more insight, let&rsquo;s look at the profiler tools.</p>\n\n<p>The profiler tools are designed to help you measure precisely how long each component takes to render. This can help you identify components that may be slow or process intense.</p>\n\n<p>Re-open the settings and uncheck the box for <strong>Highlight updates when components render</strong>. Then click on the <strong>Profiler</strong> tab in the console.</p>\n\n<p>To use the profiler, click the blue circle on the left of the screen to begin recording and click it again when you are finished:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/start_profiling.png\" alt=\"Start profiling\"></p>\n\n<p>When you stop recording, you&rsquo;ll find a graph of the component changes including, how long each item took to render.</p>\n\n<p>To get a good sense of the relative efficiency of the components, paste in the <a href=\"https://en.wikipedia.org/wiki/Creative_Commons\">Wikipedia page for Creative Commons</a>. This text is long enough to give interesting results, but not so big that it will crash the application.</p>\n\n<p>After pasting in the text, start the profiler, then make a small change to the input. Stop profiling after the component has finished re-rendering. There will be a long pause, because the application is handling a long re-rendering:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/adding_change_lot_text.gif\" alt=\"Adding a change with a lot of text\"></p>\n\n<p>When you end the recording, React Developer Tools will create a flamegraph that shows every component that re-rendered and how long it took to re-render each component.</p>\n\n<p>In this case, every keypress from the word &ldquo;Change&rdquo; causes a re-render. More importantly, it shows how long each render takes and why there was a long delay. The components <code>App</code>, <code>TextContext.Provider</code>, and <code>TextInformation</code> take about .2 milliseconds to rerender. But the <code>CharacterMap</code> component takes around 1 second per keystroke to re-render because of the complicated data parsing in the <code>itemize</code> function.</p>\n\n<p>In the display, each yellow bar is a new keystroke. You can replay the sequence one at a time by clicking on each bar. Notice that there is slight variation in the render times, but the <code>CharacterMap</code> is consistently slow:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/looking_at_flamegraph.gif\" alt=\"Looking at the flamegraph\"></p>\n\n<p>You can get more information by selecting the option <strong>Record why each component rendered while profiling.</strong> under the <strong>Profiler</strong> section of the settings.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/record_why_option.png\" alt='\"Record why\" Option of the Profiler Tab'></p>\n\n<p>Try toggling the <strong>Word Count</strong> component and notice how long the changes take. The application still lags even though you haven&rsquo;t changed the text content:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/word_count_flamegraph.gif\" alt=\"Word Count toggle flamegraph\"></p>\n\n<p>Now when you hover your cursor over a component, you&rsquo;ll find that it includes a reason the component re-rendered. In this case, the reason the component changed is <strong>The parent component rendered</strong>. That&rsquo;s a problem for the <code>CharacterMap</code> component. <code>CharacterMap</code> is doing an expensive calculation every time the parent changes, even if the props and the context do not change. That is, it&rsquo;s recalculating data even though the data is identical to the previous render.</p>\n\n<p>Click on the <strong>Ranked</strong> tab and you&rsquo;ll find how much more time <code>CharacterMap</code> takes when compared to all other components:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/ranked_tab.png\" alt=\"Ranked Tab\"></p>\n\n<p>React Developer Tools have helped isolate a problem: the <code>CharacterMap</code> component re-renders and performs an expensive calculation anytime any parent component changes.</p>\n\n<p>There are multiple ways to solve the problem, but they all involve some sort of caching via <em>memoization</em>, a process by which already calculated data is remembered rather than recalculated. You can either use a library like <a href=\"https://lodash.com/docs/4.17.15#memoize\">lodash/memoize</a> or <a href=\"https://www.npmjs.com/package/memoize-one\">memoize-one</a> to cache the results of the <code>itemize</code> function, or you can use the built in React <a href=\"https://reactjs.org/docs/react-api.html#reactmemo\"><code>memo</code></a> function to memoize the whole component.</p>\n\n<p>If you use the React <code>memo</code>, the function will only re-render if the props or context change. In this case, you&rsquo;ll use React <code>memo</code>. In general, you should memoize the data itself first since it&rsquo;s a more isolated case, but there are some interesting changes in the React Developer Tools if you memoize the whole component, so you&rsquo;ll use that approach in this tutorial.</p>\n\n<p>Open <code>CharacterMap.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/CharacterMap/CharacterMap.js\n</li></ul></code></pre>\n<p>Import <code>memo</code> from React, then pass the entire function into the <code>memo</code> function:</p>\n<div class=\"code-label \" title=\"debug-tutorial/src/components/CharacterMap/CharacterMap.js\">debug-tutorial/src/components/CharacterMap/CharacterMap.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { <span class=\"highlight\">memo,</span> useContext } from 'react';\nimport PropTypes from 'prop-types';\nimport { TextContext } from '../App/App';\n\n...\n\nfunction CharacterMap({ show }) {\n  const text = useContext(TextContext);\n\n  if(!show) {\n    return null;\n  }\n\n  return(\n    &lt;div&gt;\n     Character Map:\n     {itemize(text).map(character =&gt; (\n       &lt;div key={character[0]}&gt;\n         {character[0]}: {character[1]}\n       &lt;/div&gt;\n     ))}\n    &lt;/div&gt;\n  )\n}\n\nCharacterMap.proTypes = {\n  show: PropTypes.bool.isRequired\n}\n\n<span class=\"highlight\">export default memo(CharacterMap);</span>\n\n</code></pre>\n<p>You move the <code>export default</code> line to the end of the code in order to pass the component to <code>memo</code> right before exporting. After that, React will compare the props before re-rendering.</p>\n\n<p>Save and close the file. The browser will reload, and when you toggle the <code>WordCount</code>, the component will update much faster. This time, <code>CharacterMap</code> does not re-render. Instead, in React Developer Tools, you&rsquo;ll see a gray rectangle showing re-rendering was prevented.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/CharacterMap_did_not_re-render.gif\" alt=\"React Developer Tools showing that CharacterMap did not re-render\"></p>\n\n<p>If you look at the <strong>Ranked</strong> tab, you&rsquo;ll find that both the <code>CharacterCount</code> and the <code>WordCount</code> re-rendered, but for different reasons. Since <code>CharacterCount</code> is not memoized, it re-rendered because the parent changed. The <code>WordCount</code> re-rendered because the props changed. Even if it was wrapped in <code>memo</code>, it would still rerender.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67372/ranked_view_memoized_app.png\" alt=\"Ranked view of memoized app\"></p>\n\n<p><span class='note'><strong>Note:</strong> Memoizing is helpful, but you should only use it when you have a clear performance problem, as you did in this case. Otherwise, it can create a performance problem: React will have to check props every time it re-renders, which can cause a delay on smaller components.<br></span></p>\n\n<p>In this step, you used the profiler to identify re-renders and componenent re-rendering. You also used flamegraphs and ranked graphs to identify components that are slow to re-render and then used the <code>memo</code> function to prevent re-rendering when there are no changes to the props or context.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>The React Developer Tools browser extension gives you a powerful set of utilities to explore your components in their applications. With these tools, you&rsquo;ll be able to explore a component&rsquo;s state and identify bugs using real data without console statements or debuggers. You can also use the profiler to explore how components interact with each other, allowing you to identify and optimize components that have slow rendering in your full application. These tools are a crucial part of the development process and give you an opportunity to explore the components as part of an application and not just as static code.</p>\n\n<p>If you would like to learn more about debugging JavaScript, see our article on <a href=\"https://www.digitalocean.com/community/tutorials/how-to-debug-node-js-with-the-built-in-debugger-and-chrome-devtools\">How To Debug Node.js with the Built-In Debugger and Chrome DevTools</a>. For more React tutorials, check out our <a href=\"https://www.digitalocean.com/community/tags/react\">React Topic page</a>, or return to the <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-react-js\">How To Code in React.js series page</a>.</p>\n","descriptionType":"html","publishedDate":"Thu, 20 Aug 2020 22:07:27 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67372/add_extension_button.png","linkMd5":"5735b63fd89047b3fcf525f7eac7a839","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn70@2020_5/2020/08/31/07-48-29-881_2620fdc0eb454c8f.webp","destWidth":2192,"destHeight":738,"sourceBytes":171415,"destBytes":51672,"author":"Joe Morgan","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67372/add_extension_button.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn70@2020_5/2020/08/31/07-48-29-881_2620fdc0eb454c8f.webp","https://assets.digitalocean.com/articles/67372/chrome_success_message.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn53@2020_5/2020/08/31/07-48-32-881_a329d5d0c52d08b3.webp","https://assets.digitalocean.com/articles/67372/pin_extension.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn15@2020_6/2020/08/31/07-48-31-906_426ea33d3b9056e4.webp","https://assets.digitalocean.com/articles/67372/DO_React_production_build.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn29@2020_2/2020/08/31/07-48-32-645_acc4b2ab3b9664b0.webp","https://assets.digitalocean.com/articles/67372/console_open.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn94@2020_1/2020/08/31/07-48-31-785_f220c17a487f9e84.webp","https://assets.digitalocean.com/articles/67372/components_for_DO.png":null,"https://assets.digitalocean.com/articles/67372/base_component.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn45@2020_1/2020/08/31/07-48-31-570_c1fa2febe8442927.webp","https://assets.digitalocean.com/articles/67372/Text_area.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn18@2020_3/2020/08/31/07-48-31-493_e0304d6882cba836.webp","https://assets.digitalocean.com/articles/67372/component_context.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn34@2020_2/2020/08/31/07-48-33-141_0a6c5080c6230b93.webp","https://assets.digitalocean.com/articles/67372/update_value_devtools.png":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn21@2020_6/2020/08/31/07-48-31-471_8b0584a2ee24e0ec.webp","https://assets.digitalocean.com/articles/67372/update_value_context.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn2@2020_6/2020/08/31/07-48-33-795_e84e9955894dba0b.webp","https://assets.digitalocean.com/articles/67372/update_reducer_on_click.gif":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn1@2020_6/2020/08/31/07-48-36-250_90a1aa47dd69038d.webp","https://assets.digitalocean.com/articles/67372/adding_text_toggling.gif":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn6@2020_3/2020/08/31/07-48-39-495_cc43cd5e1351ffcf.webp","https://assets.digitalocean.com/articles/67372/manually_changing_props.gif":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn74@2020_3/2020/08/31/07-48-47-036_5362110a73985cb1.webp","https://assets.digitalocean.com/articles/67372/characterMap_component_devtools.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn33@2020_5/2020/08/31/07-48-32-030_dfcffe5803c02691.webp","https://assets.digitalocean.com/articles/67372/settings_icon.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn56@2020_4/2020/08/31/07-48-31-772_1d95d8a85e858555.webp","https://assets.digitalocean.com/articles/67372/highlight_changes.png":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn70@2020_3/2020/08/31/07-48-31-491_7ea4448be3c833ea.webp","https://assets.digitalocean.com/articles/67372/highlighting_text.gif":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn54@2020_1/2020/08/31/07-48-37-382_72452453f561dafd.webp","https://assets.digitalocean.com/articles/67372/rerendering_lower_components.gif":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn26@2020_6/2020/08/31/07-48-37-656_c28771fa84a630a6.webp","https://assets.digitalocean.com/articles/67372/start_profiling.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn30@2020_6/2020/08/31/07-48-31-451_f8f1f7e02bbedf9c.webp","https://assets.digitalocean.com/articles/67372/adding_change_lot_text.gif":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_1/2020/08/31/07-48-41-277_e635f226af8fc373.webp","https://assets.digitalocean.com/articles/67372/looking_at_flamegraph.gif":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn77@2020_2/2020/08/31/07-48-40-185_a2dd88e48858f846.webp","https://assets.digitalocean.com/articles/67372/record_why_option.png":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn42@2020_4/2020/08/31/07-48-31-378_18e5d11ff8450e5d.webp","https://assets.digitalocean.com/articles/67372/word_count_flamegraph.gif":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn22@2020_3/2020/08/31/07-48-38-416_55e6b3c3e40a636e.webp","https://assets.digitalocean.com/articles/67372/ranked_tab.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn50@2020_3/2020/08/31/07-48-32-854_1d927d9ab39a7465.webp","https://assets.digitalocean.com/articles/67372/CharacterMap_did_not_re-render.gif":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn5@2020_6/2020/08/31/07-48-38-814_036dd4d7cd0762c7.webp","https://assets.digitalocean.com/articles/67372/ranked_view_memoized_app.png":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn65@2020_3/2020/08/31/07-48-32-854_858ed0abd37ea2d3.webp"},"publishedOrCreatedDate":1598860106988},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Verstehen relationaler Datenbanken","link":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-de","description":"<h3 id=\"einführung\">Einführung</h3>\n\n<p><em>Datenbankmanagementsysteme</em> (DBMS) sind Computerprogramme, mit denen Benutzer mit einer Datenbank interagieren können. Ein DBMS ermöglicht es Benutzern, den Zugriff auf eine Datenbank zu steuern, Daten zu schreiben, Abfragen auszuführen und andere Aufgaben im Zusammenhang mit der Datenbankverwaltung durchzuführen.</p>\n\n<p>Um eine dieser Aufgaben auszuführen, muss das DBMS jedoch eine Art zugrunde liegendes Modell haben, das definiert, wie die Daten organisiert sind. Das <em>relationale Modell</em> ist ein Ansatz zur Organisation von Daten, der in der Datenbanksoftware seit seiner Entwicklung in den späten 60er Jahren breite Verwendung gefunden hat, sodass zum Zeitpunkt der Erstellung dieses Artikels <a href=\"https://db-engines.com/en/ranking\">vier der fünf beliebtesten DBMS</a> relational sind.</p>\n\n<p>Dieser konzeptionelle Artikel skiziert die Geschichte des relationalen Modells, wie relationale Datenbanken Daten organisieren und wie sie heute verwendet werden.</p>\n\n<h2 id=\"geschichte-des-relationalen-modells\">Geschichte des relationalen Modells</h2>\n\n<p><em>Datenbanken</em> sind logisch modellierte Cluster von Informationen oder <em>Daten</em>. Jede Sammlung von Daten ist eine Datenbank, unabhängig davon, wie oder wo sie gespeichert ist. Sogar ein Aktenschrank mit Lohn- und Gehaltsabrechnungsinformationen ist eine Datenbank, ebenso wie ein Stapel von Krankenhauspatientenformularen oder die Sammlung von Kundeninformationen eines Unternehmens, die über mehrere Standorte verteilt sind. Bevor die Speicherung und Verwaltung von Daten mit Computern gängige Praxis war, waren physische Datenbanken wie diese die einzigen Datenbanken, die Behörden und Unternehmen zur Speicherung von Informationen zur Verfügung standen.</p>\n\n<p>Um die Mitte des 20. Jahrhunderts führten Entwicklungen in der Informatik zu Computern mit mehr Verarbeitungsleistung sowie größerer lokaler und externer Speicherkapazität. Diese Fortschritte führten dazu, dass Computerwissenschaftler begannen, das Potenzial für die Speicherung und Verwaltung immer größerer Datenmengen zu erkennen.</p>\n\n<p>Es gab jedoch keine Theorien darüber, wie Computer Daten auf sinnvolle, logische Weise organisieren können. Es ist eine Sache, unsortierte Daten auf einem Computer zu speichern, aber es ist viel komplizierter, Systeme zu entwerfen, die es erlauben, diese Daten auf konsistente, praktische Weise hinzuzufügen, abzurufen, zu sortieren und anderweitig zu verwalten. Der Bedarf an einem logischen Rahmen zur Speicherung und Organisation von Daten führte zu einer Reihe von Vorschlägen, wie Computer für die Datenverwaltung nutzbar gemacht werden können.</p>\n\n<p>Ein frühes Datenbankmodell war das <a href=\"https://en.wikipedia.org/wiki/Hierarchical_database_model\"><em>hierarchische Modell</em></a>, bei dem die Daten in einer baumartigen Struktur organisiert sind, ähnlich wie bei modernen Dateisystemen. Das folgende Beispiel zeigt, wie das Layout eines Teils einer hierarchischen Datenbank zur Kategorisierung von Tieren aussehen könnte:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png\" alt=\"Beispiel einer hierarchischen Datenbank: Kategorisierung von Tieren\"></p>\n\n<p>Das hierarchische Modell wurde in den frühen Datenbankmanagementsystemen verbreitet eingesetzt, erwies sich aber auch als etwas unflexible. Obwohl in diesem Modell einzelne Datensätze mehrere „untergeordnete Datensätze“ haben können, kann jeder Datensatz nur einen „übergeordneten“ Datensatz in der Hierarchie haben. Aus diesem Grund waren diese früheren hierarchischen Datenbanken darauf beschränkt, nur „Eins-zu-Eins“ und „Eins-zu-Viele“-Beziehungen darzustellen. Dieser Mangel an „Viele-zu-Viele“-Beziehungen könnte zu Problemen führen, wenn Sie mit Datenpunkten arbeiten, die Sie mit mehr als einem übergeordneten Datensatz verknüpfen möchten.</p>\n\n<p>In den späten 1960er Jahren entwickelte Edgar F. Codd, ein Informatiker, der bei IBM arbeitete, das relationale Modell der Datenbankverwaltung. Das relationale Modell von Codd ermöglichte es, einzelne Datensätze mit mehr als einer Tabelle zu verknüpfen, wodurch zusätzlich zu den „Eins-zu-Viele“-Beziehungen auch „Viele-zu-Viele“-Beziehungen zwischen Datenpunkten möglich wurden. Dies bot mehr Flexibilität als andere existierende Modelle, wenn es um die Gestaltung von Datenbankstrukturen ging, und bedeutetet, dass relationale Datenbankmanagementsysteme (RDBMS) ein wesentlich breiteres Spektrum von Geschäftsanforderungen erfüllen können.</p>\n\n<p>Codd schlug eine Sprache zur Verwaltung relationaler Daten vor, bekannt als <a href=\"https://dl.acm.org/doi/pdf/10.1145/1734714.1734718\">Alpha</a>, die die Entwicklung späterer Datenbanksprachen beeinflusste. Zwei Kollegen von Codd bei IBM, Donald Chamberlin und Raymond Boyce, schufen eine solche Sprache, die von Alpha inspiriert ist. Sie nannten ihre Sprache <em>SEQUEL</em>, kurz für <strong>S</strong>tructured <strong>E</strong>nglish <strong>Q</strong>uery <strong>L</strong>anguage, aber aufgrund eines bestehenden Warenzeichens kürzten sie den Namen ihrer Sprache auf <em>SQL</em> (formal eher als <em>Structured Query Language</em> bezeichnet).</p>\n\n<p>Aufgrund von Hardware-Beschränkungen waren die frühen relationalen Datenbanken noch ungemein langsam, und es dauerte einige Zeit, bis die Technologie weit verbreitet war. Aber Mitte der 1980er Jahre war das relationale Modell von Codd bereits in einer Reihe kommerzieller Datenbankmanagementprodukte sowohl von IBM als auch seinen Konkurrenten implementiert worden. Diese Anbieter folgten ebenfalls dem IBM-Vorbild, indem sie ihre eigenen Dialekte von SQL entwickelten und implementierten. Bis 1987 hatten sowohl das American Standards Institute als auch die International Organization for Standardization Standards für SQL ratifiziert und veröffentlicht und damit den Status von SQL als akzeptierte Sprache für die Verwaltung von RDBMS gefestigt.</p>\n\n<p>Die weite Verwendung des relationalen Modells in mehreren Branchen führte dazu, dass es als Standardmodell für das Datenmanagement anerkannt wurde. Selbst mit dem Aufkommen verschiedener <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">NoSQL-Datenbanken</a> in den letzten Jahren bleiben relationale Datenbanken die dominierenden Werkzeuge zur Speicherung und Organisation von Daten.</p>\n\n<h2 id=\"wie-relationale-datenbanken-daten-organisieren\">Wie relationale Datenbanken Daten organisieren</h2>\n\n<p>Nachdem Sie nun ein allgemeines Verständnis für die Geschichte des relationalen Modells haben, lassen Sie uns einen genaueren Blick darauf werfen, wie das Modell Daten organisiert.</p>\n\n<p>Die grundlegendsten Elemente des relationalen Modells sind <em>Beziehungen</em>, die von Benutzern und modernen RDBMS als <em>Tabellen</em> erkannt werden. Eine Beziehung ist ein Satz von <em>Tupeln</em> oder Zeilen in einer Tabelle, wobei jedes Tupel einen Satz von <em>Attributen</em> oder Spalten gemeinsam hat:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png\" alt=\"Diagrammbeispiel, wie Beziehungen, Tupel und Attribute miteinander verknüpft sind\"></p>\n\n<p>Eine Spalte ist die kleinste Organisationsstruktur einer relationalen Datenbank und stellt die verschiedenen Facetten dar, die die Datensätze in der Tabelle definieren. Daher ihr formellerer Name, Attribute. Sie können sich jedes Tupel als eine einzigartige Instanz jeder Art von Personen, Objekten, Ereignissen oder Assoziationen vorstellen, die die Tabelle enthält. Diese Instanzen können z. B. Mitarbeiter eines Unternehmens, Verkäufe aus einem Online-Geschäft oder Labor-Testergebnisse sein. In einer Tabelle, die beispielsweise Mitarbeiterdaten von Lehrern an einer Schule enthält, können die Tupel Attribute wie <code>name</code>, <code>subjects</code>, <code>start_date</code> usw. haben.</p>\n\n<p>Bei der Erstellung von Spalten geben Sie einen <em>Datentyp</em> an, der festlegt, welche Art von Einträge in dieser Spalte zulässig sind. RDBMS implementieren oft ihre eigenen eindeutigen Datentypen, die möglicherweise nicht direkt mit ähnlichen Datentypen in anderen Systemen austauschbar sind. Einige gängige Datentypen umfassen Datumsangaben, Zeichenketten, Ganzzahlen und Boolesche.</p>\n\n<p>Im relationalen Modell enthält jede Tabelle mindestens eine Spalte, die zur eindeutigen Identifizierung jeder Zeile verwendet werden kann, was als <em>Primärschlüssel</em> bezeichnet wird. Dies ist wichtig, da es bedeutet, dass Benutzer nicht wissen müssen, wo ihre Daten physisch auf einem Computer gespeichert sind; stattdessen können ihre DBMS jeden Datensatz verfolgen und ad hoc zurückgeben. Dies wiederum bedeutet, dass die Datensätze keine definierte logische Reihenfolge haben und die Benutzer die Möglichkeit haben, ihre Daten in beliebiger Reihenfolge oder durch beliebige Filter zurückgeben.</p>\n\n<p>Wenn Sie zwei Tabellen haben, die Sie miteinander verknüpfen möchten, können Sie dies unter anderem mit einem <em>Fremdschlüssel</em> tun. Ein Fremdschlüssel ist im Wesentlichen eine Kopie des Primärschlüssels einer Tabelle (der „übergeordneten“ Tabelle), der in eine Spalte einer anderen Tabelle (der „untergeordneten“ Tabelle) eingefügt wird. Das folgende Beispiel verdeutlicht die Beziehung zwischen zwei Tabellen, von denen die eine zur Aufzeichnung von Informationen über die Mitarbeiter eines Unternehmens und die andere zur Verfolgung der Verkäufe des Unternehmens verwendet wird. In diesem Beispiel wird der Primärschlüssel der Tabelle <code>EMPLOYEES</code> als Fremdschlüssel der Tabelle <code>SALES</code> verwendet:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png\" alt=\"Diagrammbeispiel, wie der Primärschlüssel der Tabelle EMPLOYEES als Fremdschlüssel der Tabelle SALES fungiert\"></p>\n\n<p>Wenn Sie versuchen, der untergeordneten Tabelle einen Datensatz hinzuzufügen, und der in die Fremdschlüsselspalte eingegebene Wert im Primärschlüssel der übergeordneten Tabelle nicht existiert, ist die Einfügeanweisung ungültig. Dies hilft, die Integrität der Beziehungsebene aufrechtzuerhalten, da die Zeilen in beiden Tabellen immer korrekt zueinander in Beziehung stehen werden.</p>\n\n<p>Die Strukturelemente des relationalen Modells tragen dazu bei, die Daten auf organisierte Weise zu speichern, aber die Speicherung von Daten ist nur dann sinnvoll, wenn Sie diese auch abrufen können. Um Informationen aus einem RDBMS abzurufen, können Sie eine *Abfrage *oder eine strukturierte Anfrage nach einem Satz von Informationen stellen. Wie zuvor erwähnt, verwenden die meisten relationalen Datenbanken SQL zur Verwaltung und Abfrage von Daten. SQL ermöglicht es Ihnen, Abfrageergebnisse mit einer Vielzahl von Klauseln, Prädikaten und Ausdrücken zu filtern und zu manipulieren, wodurch Sie eine genaue Kontrolle darüber erhalten, welche Daten im Ergebnissatz angezeigt werden.</p>\n\n<h2 id=\"vorteile-und-grenzen-relationaler-datenbanken\">Vorteile und Grenzen relationaler Datenbanken</h2>\n\n<p>Lassen Sie uns mit Blick auf die zugrunde liegende Organisationsstruktur relationaler Datenbanken einige ihrer Vor- und Nachteile betrachten.</p>\n\n<p>Heute weichen sowohl SQL als auch die Datenbanken, die es implementieren, in mehrfacher Hinsicht von Codds relationalem Modell ab. Beispielsweise schreibt das Modell von Codd vor, dass jede Zeile in einer Tabelle eindeutig sein sollte, während die meisten modernen relationalen Datenbanken aus Gründen der Praktikabilität duplizierte Zeilen zulassen. Es gibt einige, die SQL-Datenbanken nicht als echte relationale Datenbanken betrachten, wenn sich nicht an jede von Codds Spezifikationen für das relationale Modell halten. In der Praxis wird jedoch jedes DBMS, das SQL verwendet und sich zumindest teilweise an das relationale Modell hält, als relationales Datenbankmanagementsystem bezeichnet.</p>\n\n<p>Obwohl relationale Datenbanken schnell an Popularität gewannen, wurden einige Unzulänglichkeiten des relationalen Modells offensichtlich, als Daten immer wertvoller wurden und Unternehmen begannen, mehr davon zu speichern. Zum einen kann es schwierig sein, eine relationale Datenbank horizontal zu skalieren. <em>Horizontale Skalierung</em> oder <em>Herausskalieren</em> ist die Praxis des Hinzufügens weiterer Computer zu einem bestehenden Stack, um die Last zu verteilen und mehr Datenverkehr und eine schnellere Verarbeitung zu ermöglichen. Dies steht oft im Gegensatz zur <em>vertikalen Skalierung</em>, bei der die Hardware eines vorhandenen Servers aufgerüstet wird, in der Regel durch Hinzufügen von mehr RAM oder CPU.</p>\n\n<p>Der Grund dafür, dass die horizontale Skalierung einer relationalen Datenbank schwierig ist, hängt damit zusammen, dass das relationale Modell auf <em>Konsistenz</em> ausgelegt ist, d, h. Clients, die dieselbe Datenbank abfragen, werden immer dieselben Daten abrufen. Wenn Sie eine relationale Datenbank horizontal über mehrere Computer skalieren, wird es schwierig, die Konsistenz zu gewährleisten, da Clients Daten auf einen Knoten Schreiben können, aber nicht auf die anderen. Es gäbe wahrscheinlich eine Verzögerung zwischen dem anfänglichen Schreiben und dem Zeitpunkt, zu dem die anderen Knoten aktualisiert werden, um die Änderungen widerspiegeln, was zu Inkonsistenzen zwischen ihnen führen würde.</p>\n\n<p>Eine weitere Einschränkung bei RDBMS besteht darin, dass das relationale Modell für die Verwaltung <em>strukturierter Daten</em> oder von Daten konzipiert wurde, die mit einem vordefinierten Datentyp übereinstimmen oder zumindest auf eine vorher festgelegte Weise organisiert sind, sodass sie leicht sortierbar und durchsuchbar sind. Mit der Verbreitung von Personal Computing und dem Aufkommen des Internets in den frühen 1990er Jahren wurden jedoch <em>unstrukturierte Daten</em> – wie E-Mail-Nachrichten, Fotos, Videos usw. – immer üblicher.</p>\n\n<p>All dies bedeutet nicht, dass relationale Datenbanken nicht nützlich sind. Ganz im Gegenteil, das relationale Modell ist auch nach über 40 Jahren noch immer der dominierende Rahmen für das Datenmanagement. Ihre Verbreitung und Langlebigkeit bedeuten, das relationale Datenbanken eine ausgereifte Technologie darstellen, was wiederum einer ihrer wichtigsten Vorteile ist. Es gibt viele Anwendungen, die für die Arbeit mit dem relationalen Modell konzipiert wurden, sowie viele Datenbankadministratoren, die in ihrer Laufbahn Experten auf dem Gebiet der relationalen Datenbanken sind. Für diejenigen, die mit relationalen Datenbanken beginnen möchten, gibt es ein breites Angebot an Ressourcen, in gedruckter Form und online.</p>\n\n<p>Ein weiterer Vorteil relationaler Datenbanken besteht darin, dass fast jedes RDBMS <em>Transaktionen</em> unterstützt. Eine Transaktion besteht aus einer oder mehreren einzelnen SQL-Anweisungen, die nacheinander als eine einzige Arbeitseinheit ausgeführt werden. Transaktionen stellen einen Alles-oder-Nichts-Ansatz dar, was bedeutet, dass jede SQL-Anweisung in der Transaktion gültig sein muss, da ansonsten die gesamte Transaktion fehlschlägt. Dies ist sehr hilfreich, um die Datenintegrität zu gewährleisten, wenn Änderungen an mehreren Zeilen oder Tabellen vorgenommen werden.</p>\n\n<p>Und schließlich sind relationale Datenbanken äußerst flexibel. Sie wurden zum Aufbau einer Vielzahl unterschiedlicher Anwendungen verwendet und arbeiten auch bei sehr großen Datenmengen weiterhin effizient. SQL ist ebenfalls extrem leistungsfähig, sodass Sie im Handumdrehen Daten hinzufügen und ändern sowie die Struktur von Datenbankschemata und Tabellen ändern können, ohne die vorhandenen Daten zu beeinträchtigen.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>Dank ihrer Flexibilität und ihres Designs für Datenintegrität sind relationale Datenbanken auch mehr als fünfzig Jahre nach ihrer ersten Konzeption immer noch die wichtigste Art und Weise, wie Daten verwaltet und gespeichert werden. Selbst mit dem Aufkommen verschiedener NoSQL-Datenbanken in den letzten Jahren sind das Verständnis des relationalen Modells und die Arbeit mit RDBMS der Schlüssel für jeden, der Anwendungen entwickeln möchte, die die Datenleistung nutzen.</p>\n\n<p>Um mehr über einige beliebte Open-Source-RDBMS zu erfahren, empfehlen wir Ihnen, sich <a href=\"https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\">unseren Vergleich verschiedener relationaler Open-Source-Datenbanken</a> anzusehen. Wenn Sie mehr über Datenbanken im Allgemeinen erfahren möchten, empfehlen wir Ihnen, <a href=\"https://www.digitalocean.com/community/tags/databases\">einen Blick in unsere vollständige Bibliothek datenbankbezogener Inhalte</a> zu werfen.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:58 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png","linkMd5":"d3cc2a34945fb61874cc0335bc19dee6","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","destWidth":1440,"destHeight":820,"sourceBytes":26442,"destBytes":57080,"author":"Mark Drake","articleImgCdnMap":{"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn42@2020_2/2020/08/31/07-48-32-526_c309571f1ca0d468.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png":null},"publishedOrCreatedDate":1598860106961},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Установка комплекса ERPNext в Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-ru","description":"<p><em>Автор выбрал <a href=\"https://www.brightfunds.org/organizations/software-in-the-public-interest-inc\">Software in the Public Interest</a> для получения пожертвования в рамках программы <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"Введение\">Введение</h3>\n\n<p><a href=\"https://erpnext.com//\">ERPNext</a> — это набор планирования ресурсов предприятия (Enterprise Resource Planning, ERP), который позволяет использовать производительность и гибкость технологий с открытым кодом. Он отлично справляется с такими бизнес-процессами, как финансы, продажи, человеческие ресурсы, производство, снабжение, обслуживание, служба поддержки и многое другое. В числе преимуществ внедрения системы, как ERPNext, можно отметить следующее:</p>\n\n<ul>\n<li>Повышение производительности за счет автоматизации повторяющихся рабочих процессов</li>\n<li>Повышение эффективности ИТ путем совместного использования базы данных всеми подразделениями компании</li>\n<li>Оптимизация принятия решения благодаря комплексному видению взаимосвязи между структурными единицами</li>\n</ul>\n\n<p>ERPNext создан на базе <a href=\"https://frappe.io/frappe\">Frappe</a>, платформы комплексной разработки веб-приложений, написанной на <a href=\"https://www.python.org/\">Python</a>, со всеми преимуществами <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">среды выполнения Node/JavaScript</a> и использует <a href=\"https://mariadb.org/\">MariaDB</a> в качестве сервера базы данных. Одним из многих преимуществ приложений на базе Frappe, в том числе ERPNext, является утилита командной строки <a href=\"https://github.com/frappe/bench\">bench</a>. CLI bench экономит время администратора за счет автоматизации таких задач, как установка, обновление, настройка и управление многочисленными сайтами Frappe/ERPNext.</p>\n\n<p>В этом обучающем модуле мы установим и настроим комплекс ERPNext на одном сервере под управлением Ubuntu 18.04. Это позволит вам настроить стек для различных сред разработки или производства в зависимости от ваших потребностей и подготовит вас к созданию более сложной отказоустойчивой архитектуры.</p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<ul>\n<li>Один сервер Ubuntu 18.04 с не менее 4 Гбайт оперативной памяти и пользователем <code>sudo</code> без прав root. Настроить сервер и пользователя можно с помощью <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">нашего руководства по первоначальной настройке сервера Ubuntu 18.04</a>.</li>\n</ul>\n\n<p><span class='note'><strong>Примечание.</strong> При выборе спецификаций сервера следует учитывать, что системы ERP могут потреблять множество ресурсов. В этом руководстве рекомендуется использовать один сервер с 4 ГБ оперативной памяти, чего будет достаточно для базовых случаев использования, но конкретные аппаратные требования могут отличаться в зависимости от количества пользователей и размера вашего бизнеса.<br></span></p>\n\n<ul>\n<li>Зарегистрированное полное доменное имя с записью A, указывающее на ваш сервер. Если вы используете дроплет DigitalOcean, воспользуйтесь <a href=\"https://www.digitalocean.com/community/tutorials/how-to-point-to-digitalocean-nameservers-from-common-domain-registrars\">этим руководством</a> для надлежащей настройки DNS. В этом обучающем руководстве мы будем использовать <code><span class=\"highlight\">your_domain</span></code>.</li>\n</ul>\n\n<h2 id=\"Шаг-1-—-Настройка-брандмауэра\">Шаг 1 — Настройка брандмауэра</h2>\n\n<p>Хотя настройка брандмауэра для разработки опциональна, для производства она является обязательной с точки зрения безопасности.</p>\n\n<p>Вам потребуется открыть следующие порты на вашем сервере ERPNext:</p>\n\n<ul>\n<li><code>80/tcp</code> и <code>443/tcp</code> для HTTP и HTTPS соответственно</li>\n<li><code>3306/tcp</code> для подключения MariaDB (рекомендуется только при необходимости удаленного доступа к базе данных)</li>\n<li><code>143/tcp</code> и <code>25/tcp</code> для IMAP и STMP соответственно</li>\n<li><code>22/tcp</code> для SSH (если вы еще не включили <code>OpenSSH</code>)</li>\n<li><code>8000/tcp</code> для тестирования разработки перед развертыванием вашего сайта</li>\n</ul>\n\n<p>Чтобы сразу открыть несколько портов можно использовать следующую команду:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 22,25,143,80,443,3306,8000/tcp\n</li></ul></code></pre>\n<p>Также можно разрешить подключения с определенных IP-адресов на конкретных портах с помощью этой команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow from <span class=\"highlight\">server_IP</span> to any port <span class=\"highlight\">port_number</span>\n</li></ul></code></pre>\n<p>После открытия всех необходимых портов активируйте брандмауэр:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>После активации брандмауэра проверьте статус открытых портов:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>Дополнительную информацию о настройке брандмауэра можно найти в нашем <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-18-04\">руководстве «Настройка брандмауэра с UFW в Ubuntu 18.04</a>».</p>\n\n<p>Настройка соответствующего брандмауэра — это первый из двух предварительных шагов. Теперь мы настроим раскладку клавиатуры и кодирование символов на вашем сервере.</p>\n\n<h2 id=\"Шаг-2-—-Конфигурация-локальных-настроек\">Шаг 2 — Конфигурация локальных настроек</h2>\n\n<p>Настоятельно рекомендуется настроить раскладку клавиатуры для консоли, а также язык и кодирование символов на вашем хосте. Это необходимо, чтобы избежать возможных проблем во время установки ERPNext 12. Обратите внимание, что эта конфигурация не имеет никакого отношения к языку пользовательского интерфейса на вашей фактической платформе ERPNext, а служит для конфигурации локальных настроек системы.</p>\n\n<p>Сначала обновите ваш сервер:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Теперь настройте раскладку клавиатуры, язык и кодирование символов:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo localectl set-keymap us &amp;&amp; sudo localectl set-locale LANG=en_US.utf8\n</li></ul></code></pre>\n<p>Утилита <code>localectl</code> используется Ubuntu 18.04 и другими дистрибутивами Linux для контроля и изменения языковых настроек всей системы, а также настроек раскладки клавиатуры перед входом пользователя, что требует ERPNext 12.</p>\n\n<p>Также вам потребуется добавить следующие строки в файл <code>/etc/environment</code>. Используйте <code>nano</code> или предпочитаемый текстовый редактор, чтобы открыть файл:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/environment\n</li></ul></code></pre>\n<p>Добавьте в него следующее содержание:</p>\n<div class=\"code-label \" title=\"/etc/environment\">/etc/environment</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">LC_ALL=en_US.UTF-8\nLC_CTYPE=en_US.UTF-8\nLANG=en_US.UTF-8\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Перезагрузите ваш сервер для внесения всех изменений:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo reboot\n</li></ul></code></pre>\n<p>Дайте своему серверу несколько минут на перезагрузку, а затем снова выполните вход через <code>ssh</code>. Теперь вы готовы установить свою базу данных.</p>\n\n<h2 id=\"Шаг-3-mdash-Установка-mariadb-10-4\">Шаг 3 — Установка MariaDB 10.4</h2>\n\n<p>Теперь добавьте MariaDB в стек сервера. Для работы ERPNext 12 требуется версия MariaDB 10.2 или выше, однако в официальный репозиторий Ubuntu 18.04 входит версия 10.1, то есть вам нужно будет самостоятельно установить нужную версию. В этом обучающем модуле мы будем использовать последнюю стабильную версию MariaDB (версия 10.4 на момент написания этого документа).</p>\n\n<p>Для установки MariaDB 10.4 в Ubuntu 18.04 вам нужно будет добавить соответствующий ключ подписи и репозиторий. Эту информацию можно найти в <a href=\"https://downloads.mariadb.org/mariadb/repositories/#mirror=klaus\">мастере репозитория MariaDB Foundation</a>. Откройте этот URL-адрес в браузере. В разделе <strong>1. Choose a Distro</strong> нажмите <strong>Ubuntu</strong>. Откроется второй столбец с заголовком <strong>2. Choose a Release</strong>. Нажмите под этим заголовком <strong>18.04 LTS &ldquo;bionic&rdquo;</strong>. Появится третий столбец с заголовком <strong>3.Choose a Version</strong>. Под этим столбцом нажмите <strong>10.4 stable</strong>. Появится еще один столбец с заголовком <strong>4.Choose a Mirror</strong>. Выберите зеркало в зависимости от вашего расположения, и MariaDB заполнит необходимые команды для выбранной установки.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_0.png\" alt=\"Мастер репозитория MariaDB\"></p>\n\n<p>Запустите три заполненные команды, которые надлежащим образом добавят репозиторий и ключ MariaDB. Ваши собственные команды будут выглядеть следующим образом:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt-get install software-properties-common &amp;&amp; sudo apt-key adv --fetch-keys <span class=\"highlight\">'https://mariadb.org/mariadb_release_signing_key.asc'</span> &amp;&amp; sudo add-apt-repository 'deb [arch=amd64,arm64,ppc64el] <span class=\"highlight\">http://mirror.klaus-uwe.me/mariadb/repo/10.4/ubuntu</span> bionic main'\n</li></ul></code></pre>\n<p>После добавления репозитория выполните установку MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install mariadb-server\n</li></ul></code></pre>\n<p>После установки <code>mariadb-server</code> установите следующие пакеты:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install libmysqlclient-dev python3-mysqldb\n</li></ul></code></pre>\n<p>ERPNext 12 — приложение Python, и ему требуется библиотека <code>python3-mysqldb</code> для управления базами данных. Пакеты <code>libmysqlclient-dev</code>, <code>mariadb-client</code> и <code>libmariadbclient18</code> позволяют пользователям взаимодействовать со службой MariaDB, а <code>ntpdate</code> и <code>libdate-manip-perl</code> используются ERPNext для синхронизации времени сервера.</p>\n\n<p>Затем добавьте базовый уровень безопасности на сервер MariaDB, запустив скрипт <code>mysql_secure_installation</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql_secure_installation\n</li></ul></code></pre>\n<p>Скрипт <code>mysql_secure_installation</code> будет давать подсказки с помощью вопросов:</p>\n\n<ul>\n<li>В первом диалоговом окне вам будет предложено ввести пароль <strong>root</strong>, но так как пароль еще не задан, нажмите <code>ENTER</code>.</li>\n<li>Затем вам нужно будет решить, будете ли вы использовать аутентификацию Unix. Ответьте <code>Y</code>, чтобы принять этот метод аутентификации.</li>\n<li>Когда вам будет предложено изменить пароль пользователя <strong>root</strong> для MariaDB, ответьте <code>N</code>. Использование пароля по умолчанию с аутентификацией Unix рекомендуется для систем на базе Ubuntu, потому что учетная запись <strong>root</strong> тесно связана с автоматическими задачами по обслуживанию системы.</li>\n<li>Оставшиеся вопросы будут связаны с удалением анонимного пользователя базы данных для ограничения возможности входа в учетную запись <strong>root</strong> дистанционно на localhost, удалением тестовой базы данных и перезагрузкой таблиц привилегий. На эти вопросы можно спокойно ответить <code>Y</code>.</li>\n</ul>\n\n<p>После завершения выполнения скрипта <code>mysql_secure_installation</code> MariaDB начнет запуск с использованием настройки по умолчанию. Для стандартной установки ERPNext используется пользователь <strong>root</strong> для всех операций базы данных. Хотя этот подход может быть удобен для настроек одного сервера, он не является оптимальным с точки зрения безопасности. Поэтому в следующем разделе вы узнаете, как избежать этой проблемы путем создания нового пользователя со специальными привилегиями.</p>\n\n<h3 id=\"Создание-пользователя-суперадминистратора-mariadb\">Создание пользователя-суперадминистратора MariaDB</h3>\n\n<p>ERPNext будет использовать пользователя <strong>root</strong> MariaDB для управления подключениями базы данных, но это не всегда идеальное решение. Чтобы преодолеть это ограничение и разрешить управление MariaDB пользователю без прав root, вам нужно будет вручную создать базу данных, названную по имени пользователя. Затем вы сможете присвоить специальные привилегии новому пользователю для управления операциями базы данных ERPNext.</p>\n\n<p>Откройте командную строку MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql\n</li></ul></code></pre>\n<p>Теперь создайте новую базу данных с именем пользователя, которое вы хотите назначить для подключений MariaDB. В этом обучающем модуле мы будем использовать имя пользователя <code><span class=\"highlight\">sammy</span></code>, но вы можете выбрать любое другое имя:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">CREATE DATABASE <span class=\"highlight\">sammy</span>;\n</li></ul></code></pre>\n<p>Убедитесь, что база данных была создана с помощью этого оператора SQL:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SHOW DATABASES;\n</li></ul></code></pre>\n<p>Вы увидите примерно следующий вывод:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| <span class=\"highlight\">sammy</span>             |\n+--------------------+\n</code></pre>\n<p>Создайте пользователя MariaDB с именем <code><span class=\"highlight\">sammy</span></code>**** с привилегиями, и назначьте этому пользователю надежный пароль по своему выбору. Сохраните пароль в надежном месте, он понадобится вам позже:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">GRANT ALL PRIVILEGES ON *.* TO '<span class=\"highlight\">sammy</span>'@'%' IDENTIFIED BY '<span class=\"highlight\">mariadb_password</span>' WITH GRANT OPTION;\n</li></ul></code></pre>\n<p>Теперь подтвердите создание пользователя и новые привилегии пользователя:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SELECT host, user, Super_priv FROM mysql.user;\n</li></ul></code></pre>\n<p>Результат должен будет выглядеть следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+-----------+-------+------------+\n| Host      | User  | Super_priv |\n+-----------+-------+------------+\n| localhost | root  | Y          |\n| localhost | mysql | Y          |\n| %         | <span class=\"highlight\">sammy</span> | <span class=\"highlight\">Y</span>          |\n+-----------+-------+------------+\n3 rows in set (0.001 sec)\n</code></pre>\n<p>Теперь очистите привилегии, чтобы вступили в силу все изменения:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">FLUSH PRIVILEGES;\n</li></ul></code></pre>\n<p>После этого закройте сеанс:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">exit\n</li></ul></code></pre>\n<p>Теперь, после создания пользователя базы данных, необходимо только сделать отладку MariaDB для обеспечения надлежащей работы ERPNext 12. К счастью, команда ERPNext предоставляет превосходный шаблон настроек, который вы будете использовать в качестве отправной точки для внедрения. В следующем разделе вы узнаете, как правильно настроить базу данных MariaDB.</p>\n\n<h2 id=\"Шаг-4-—-Настройка-mariadb-для-erpnext\">Шаг 4 — Настройка MariaDB для ERPNext</h2>\n\n<p>После установки и обеспечения безопасности MariaDB пришло время для отладки подключений ERPNext.</p>\n\n<p>Сначала остановите <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop mariadb\n</li></ul></code></pre>\n<p>Теперь с помощью <code>nano</code> или вашего любимого текстового редактора создайте файл конфигурации MariaDB под названием <code>settings.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/conf.d/settings.cnf\n</li></ul></code></pre>\n<p>Добавьте шаблон конфигурации ERPNext:</p>\n<div class=\"code-label \" title=\"/etc/mysql/conf.d/settings.cnf\">/etc/mysql/conf.d/settings.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\n\n# GENERAL #\nuser                           = mysql\ndefault-storage-engine         = InnoDB\nsocket                         = /var/lib/mysql/mysql.sock\npid-file                       = /var/lib/mysql/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n# SAFETY #\nmax-allowed-packet             = 256M\nmax-connect-errors             = 1000000\ninnodb                         = FORCE\n\n# DATA STORAGE #\ndatadir                        = /var/lib/mysql/\n\n# BINARY LOGGING #\nlog-bin                        = /var/lib/mysql/mysql-bin\nexpire-logs-days               = 14\nsync-binlog                    = 1\n\n# REPLICATION #\nserver-id                      = 1\n\n# CACHES AND LIMITS #\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\nquery-cache-type               = 0\nquery-cache-size               = 0\nmax-connections                = 500\nthread-cache-size              = 50\nopen-files-limit               = 65535\ntable-definition-cache         = 4096\ntable-open-cache               = 10240\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\ninnodb-log-file-size           = 512M\ninnodb-flush-log-at-trx-commit = 1\ninnodb-file-per-table          = 1\ninnodb-buffer-pool-size        = 5462M\ninnodb-file-format             = barracuda\ninnodb-large-prefix            = 1\ncollation-server               = utf8mb4_unicode_ci\ncharacter-set-server           = utf8mb4\ncharacter-set-client-handshake = FALSE\nmax_allowed_packet             = 256M\n\n# LOGGING #\nlog-error                      = /var/lib/mysql/mysql-error.log\nlog-queries-not-using-indexes  = 0\nslow-query-log                 = 1\nslow-query-log-file            = /var/lib/mysql/mysql-slow.log\n\n[mysql]\ndefault-character-set = utf8mb4\n\n[mysqldump]\nmax_allowed_packet=256M\n\n!includedir /etc/mysql/mariadb.conf.d/\n</code></pre>\n<p>Сохраните и закройте файл. Для получения дополнительной информации об этих настройках посмотрите этот файл шаблона в <a href=\"https://github.com/frappe/erpnext/wiki/MySQL-configuration-file\">репозитории ERPNext Github</a>. Это полезное начало для изучения этих опций.</p>\n\n<p>Создайте еще один файл с именем <code>erpnext.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/mariadb.conf.d/erpnext.cnf\n</li></ul></code></pre>\n<p>Добавьте в файл следующие строки:</p>\n<div class=\"code-label \" title=\"/etc/mysql/mariadb.conf.d/erpnext.cnf\">/etc/mysql/mariadb.conf.d/erpnext.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nbind-address    = 0.0.0.0\n</code></pre>\n<p>Первый файл, <code>/etc/mysql/conf.d/settings.cnf</code>, дополняет и перезаписывает несколько значений, включенных по умолчанию в конфигурацию MariaDB, расположенную в файле <code>/etc/mysql/my.cnf</code>. Этот файл дает вам шаблон с рекомендациями, который значительно повышает производительность базы данных для ERPNext. Хотя этот шаблон является отличным началом, ничто не мешает вам еще больше повысить производительность MariaDB, настроив эти параметры в соответствии с вашими потребностями.</p>\n\n<p>Второй файл, <code>/etc/mysql/mariadb.conf.d/erpnext.cnf</code>, также перезаписывает некоторые значения, добавляя конкретную информацию по подключению вашей базы данных.</p>\n\n<h3 id=\"Тестирование-подключения-mariadb\">Тестирование подключения MariaDB</h3>\n\n<p>Поскольку ERPNext использует подключение базы данных почти для всех внутренних операций, желательно проверить подключение перед тем, как продолжить.</p>\n\n<p>Запустите <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mariadb\n</li></ul></code></pre>\n<p>Для проверки подключения можно использовать следующую команду. Не забудьте заменить <code><span class=\"highlight\">sammy</span></code> и <code><span class=\"highlight\">mariadb_password</span></code> своими учетными данными:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mysql --user <span class=\"highlight\">sammy</span> --password <span class=\"highlight\">mariadb_password</span> --host=localhost --protocol=tcp --port=3306 test\n</li></ul></code></pre>\n<p>Вы увидите вывод, в котором будет показано содержание базовой справки и ряд параметров. Это означает, что ваше подключение было успешным:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>mysql  Ver 15.1 Distrib 10.4.13-MariaDB, for debian-linux-gnu (x86_64) using readline 5.2\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nUsage: mysql [OPTIONS] [database]\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\n\n...\n\n  --ssl-verify-server-cert\n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n\n...\n\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\nbinary-mode                       FALSE\nconnect-expired-password          FALSE\n</code></pre>\n<p>Если потребуется внести какие-либо изменения в настройки MariaDB или исправить ошибки, не забудьте перегрузить службу с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mariadb\n</li></ul></code></pre>\n<p>После этого включите MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mariadb\n</li></ul></code></pre>\n<p>Теперь, после проверки подключения базы данных, можно продолжить установку вашего приложения ERPNext.</p>\n\n<h2 id=\"Шаг-5-—-Настройка-erpnext-12\">Шаг 5 — Настройка ERPNext 12</h2>\n\n<p>Теперь, после подготовки серверной части вашей базы данных, можно продолжить настройку вашего веб-приложения ERPNext. В этом разделе вы узнаете, как установить и выполнить настройку всех компонентов, необходимых для ERPNext 12, и затем установить непосредственно приложение.</p>\n\n<p>Начните с подготовки сервера с помощью всех системных пакетов, необходимых для ERPNext 12. Установите общесистемные зависимости с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo DEBIAN_FRONTEND=noninteractive apt install -y curl build-essential mariadb-client python3-setuptools python3-dev libffi-dev python3-pip libcurl4 dnsmasq fontconfig git htop libcrypto++-dev libfreetype6-dev liblcms2-dev libwebp-dev libxext6 libxrender1 libxslt1-dev libxslt1.1 libffi-dev ntpdate postfix python3-dev python-tk screen vim xfonts-75dpi xfonts-base zlib1g-dev apt-transport-https libsasl2-dev libldap2-dev libcups2-dev pv libjpeg8-dev libtiff5-dev tcl8.6-dev tk8.6-dev libssl1.0-dev python3-mysqldb libdate-manip-perl logwatch\n</li></ul></code></pre>\n<p>Переменная <code>DEBIAN_FRONTEND=noninteractive</code> была передана в команду установки для отключения подсказок Postfix. Для получения подробной информации о настройке Postfix ознакомьтесь с нашим руководством <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-postfix-on-ubuntu-18-04\">Установка и настройка Postfix в Ubuntu 18.04</a></p>\n\n<p>Выполните обновление <code>pip3</code> и установите последние версии трех дополнительных модулей Python, которые требуются ERPNext:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo -H python3 -m pip install --upgrade setuptools cryptography psutil\n</li></ul></code></pre>\n<p>Теперь, после установки всех необходимых глобальных зависимостей, вы установите все службы и библиотеки, необходимые для ERPNext 12.</p>\n\n<h3 id=\"Настройка-node-js-и-yarn\">Настройка Node.js и Yarn</h3>\n\n<p>ERPNext 12 может работать с версией 8+ среды сервера Node.js. На момент составления этого обучающего модуля официальный скрипт ERPNext <code>easy_install</code> использует Node 8. Однако с точки зрения безопасности рекомендуется установить новую версию, так как срок использования Node 8 закончился в 2020 г., и для него больше не будут выпускаться обновления безопасности. Для этого обучающего модуля мы установим Node.js версии 12 LTS вместе с соответствующими диспетчерами пакетов <code>npm</code> и <code>yarn</code>. Обратите внимание, что в каркасе Frappe используется <code>yarn</code> для установки зависимостей. Если вы решите использовать другой метод установки, убедитесь, что в вашей системе работает конечная версия <code>yarn</code> 1.12+.</p>\n\n<p>Добавьте в вашу систему репозиторий NodeSource:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -sL https://deb.nodesource.com/setup_12.x -o nodesource_setup.sh\n</li></ul></code></pre>\n<p>Теперь вы можете проверить содержание загруженного скрипта:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano nodesurce_setup.sh\n</li></ul></code></pre>\n<p>Проверьте настройки и запустите скрипт:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bash nodesource_setup.sh\n</li></ul></code></pre>\n<p>Этот скрипт автоматически обновит список <code>apt</code>. Теперь вы можете установить <code>nodejs</code> на вашем сервере:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install nodejs\n</li></ul></code></pre>\n<p>Выполните глобальную установку <code>yarn</code>, используя входящий в комплект пакет <code>npm</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo npm install -g yarn\n</li></ul></code></pre>\n<p>Теперь, после установки Node, можно продолжить настройку <code>wkhtmltopdf</code> для вашей платформы.</p>\n\n<p>ERPNext использует инструмент с открытым исходным кодом <code>wkhtmltopdf</code> для конвертации содержимого HTML в PDF с помощью механизма исполнения Qt WebKit. Эта функция используется главным образом для печати счетов-фактур, ценовых предложений и других отчетов. В случае ERPNext 12 требуется определенная версия <code>wkhtmltopdf</code> <code>0.12.5</code> с обновленным Qt.</p>\n\n<p>Для установки <code>wkhtmltopdf</code> начните с перехода в подходящий каталог для загрузки пакета, в данном случае <code>/tmp</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /tmp\n</li></ul></code></pre>\n<p>Загрузите соответствующую версию <code>wkhtmltopdf</code> и пакет для Ubuntu 18.04 со страницы проекта:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.5/wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Теперь установите пакет с помощью инструмента <code>dpkg</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo dpkg -i wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Затем скопируйте все относящиеся исполняемые файлы в каталог <code>/usr/bin/</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /usr/local/bin/wkhtmlto* /usr/bin/\n</li></ul></code></pre>\n<p>Когда файлы будут на месте, измените их разрешения, чтобы они стали исполняемыми:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod a+x /usr/bin/wk*\n</li></ul></code></pre>\n<p>Теперь, после надлежащей установки <code>wkhtmltopdf</code>, мы добавим Redis в стек нашей базы данных.</p>\n\n<h3 id=\"Установка-redis\">Установка Redis</h3>\n\n<p>ERPNext 12 использует Redis для повышения производительности MariaDB. В частности, <a href=\"https://discuss.erpnext.com/t/why-erpnext-need-redis/6194\">он помогает с кэшированием</a>.</p>\n\n<p>Сначала установите Redis из официального репозитория Ubuntu 18.04:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install redis-server\n</li></ul></code></pre>\n<p>Затем активируйте Redis при запуске:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable redis-server\n</li></ul></code></pre>\n<p>Мы добавили Redis в наш комплект и теперь посмотрим, что мы уже сделали. Мы установили все основные компоненты, необходимые ERPNext 12, в том числе:</p>\n\n<ul>\n<li>Серверная часть базы данных MariaDB</li>\n<li>Среда сервера Node.js JavaScript</li>\n<li>Диспетчер пакетов Yarn</li>\n<li>Кэш базы данных Redis</li>\n<li>Генератор документов PDF <code>wkhtmltopdf</code></li>\n</ul>\n\n<p>Независимо от того, устанавливаете ли вы систему ERP для разработки или производства, вы готовы к следующему шагу, а именно к установке каркаса комплексной разработки Frappe и фактического веб-приложения ERPNext 12.</p>\n\n<h2 id=\"Шаг-6-—-Установка-командной-строки-bench-frappe\">Шаг 6 — Установка командной строки Bench Frappe</h2>\n\n<p>Теперь, когда вы установили все требования стека ERPNext, вы можете свободно пользоваться возможностями утилиты командной строки <code>bench</code>. CLI <code>bench</code> была разработана для оказания помощи пользователям в процессе установки, настройки и управления такими приложениями, как ERPNext, которые созданы на базе каркаса Frappe Framework. В следующих разделах вы установите CLI <code>bench</code> для дальнейшего использования при выполнении настройки ERPNext 12.</p>\n\n<p>Убедитесь, что пользователь Frappe (в данном случае <code><span class=\"highlight\">sammy</span></code>) имеет соответствующие права в своем каталоге <code>home</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chown <span class=\"highlight\">sammy</span> -R /home/<span class=\"highlight\">sammy</span>\n</li></ul></code></pre>\n<p>Теперь клонируйте репозиторий <code>frappe/bench</code> в свой домашний каталог. Не забудьте заменить <code><span class=\"highlight\">sammy</span></code> вашим именем пользователя системы:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone https://github.com/frappe/bench /home/<span class=\"highlight\">sammy</span>/.bench --depth 1 --branch master\n</li></ul></code></pre>\n<p>Установите CLI <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo pip3 install -e /home/<span class=\"highlight\">sammy</span>/.bench\n</li></ul></code></pre>\n<p>В данном руководстве предполагается, что вы устанавливаете ERPNext 12 для сценариев тестирования/производства и поэтому используете ветку <code>master</code>. Но если вы намерены разрабатывать приложения или пользовательские модули ERPNext, лучше выбрать ветку <code>develop</code>. В любом случае вы готовы к установке каркаса Frappe Framework. Это последнее действие перед установкой непосредственно ERPNext.</p>\n\n<h3 id=\"Настройка-среды-каркаса-frappe-framework\">Настройка среды каркаса Frappe Framework</h3>\n\n<p>В этом разделе вы создадите <a href=\"https://frappe.io/docs/user/en/architecture\">среду Frappe</a> с помощью CLI <code>bench</code>.</p>\n\n<p>Во время установки Frappe вы можете превысить лимит просмотра файлов Ubuntu, который по умолчанию установлен на 8192. Чтобы избежать этого, установите более высокий лимит с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p\n</li></ul></code></pre>\n<p>Затем инициализируйте каркас Frappe Framework 12. Замените Sammy на имя пользователя системы:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench init /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> --frappe-path https://github.com/frappe/frappe --frappe-branch version-12 --python python3\n</li></ul></code></pre>\n<p>Во время выполнения вы можете увидеть одну ошибку, связанную с вашим путем, и несколько предупреждений. Пусть процесс продолжается до конца. По его завершении вы увидите вывод, который будет выглядеть следующим образом и указывать, что среда успешно создана:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nDone in 82.23s.\nINFO:bench.utils:setting up backups\nno crontab for <span class=\"highlight\">sammy</span>\nSUCCESS: Bench /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> initialized\n</code></pre>\n<p><span class='note'><strong>Примечание.</strong> Процесс <code>bench init</code> может быть остановлен при возникновении ошибки <code>spawn ENOMEM</code>. Эта ошибка возникает, когда в системе заканчивается память. Ее необходимо устранить перед продолжением либо путем установки дополнительной физической памяти, либо путем выделения пространства подкачки.<br></span></p>\n\n<p>Рассмотрим более подробно команду, которая используется для создания среды:</p>\n\n<ul>\n<li><code>/home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span></code> — это путь установки каркаса Frappe Framework, веб-сайтов и связанных приложений. Для размещения всех необходимых файлов в данном примере будет создан новый каталог с именем <code><span class=\"highlight\">frappe-bench</span></code>.</li>\n<li><code>--frappe-path</code> указывает на репозиторий Frappe, который в данном случае является официальным репозиторием Github.</li>\n<li><code>--frappe-branch</code> — это версия Frappe для установки. Поскольку вы хотите установить ERPNext 12, выбранная версия — Frappe 12.</li>\n<li><code>--python</code> — это версия Python, которая будет использоваться. Для ERPNext 12 требуется Python 3.6+. Однако в предыдущих версиях по-прежнему используется Python 2.7.</li>\n</ul>\n\n<p>Дополнительную информацию о командах CLI <code>bench</code> см. в <a href=\"https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html\">Справочнике команд Bench</a>.</p>\n\n<p>Гибкость, предлагаемая каркасом Frappe, превосходит возможности изолированных сред. Также вы можете создавать различные веб-сайты и устанавливать на них приложения.</p>\n\n<h2 id=\"Шаг-7-—-Установка-веб-приложения-erpnext-12\">Шаг 7 — Установка веб-приложения ERPNext 12</h2>\n\n<p>В этом разделе вы настроите сайт на базе Frappe, а затем установите на нем приложение ERPNext 12.</p>\n\n<p>Перейдите в каталог, где был инициирован Frappe.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Загрузите ERPNext 12 из репозитория с помощью инструмента командной строки <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench get-app erpnext https://github.com/frappe/erpnext --branch version-12\n</li></ul></code></pre>\n<p>Затем создайте новый сайт, заменив <code><span class=\"highlight\">your_domain</span></code> на домен, который вы связали с IP-адресом этого сервера:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench new-site <span class=\"highlight\">your_domain</span> --admin-password '<span class=\"highlight\">erpnext_admin_password</span>' --mariadb-root-username <span class=\"highlight\">sammy</span> --mariadb-root-password '<span class=\"highlight\">mariadb_password</span>'\n</li></ul></code></pre>\n<p>Давайте рассмотрим опции, используемые в команде выше:</p>\n\n<ul>\n<li><code>bench new-site</code> создает новый сайт на базе каркаса Frappe Framework.</li>\n<li><code><span class=\"highlight\">your_domain</span></code> — это имя нового сайта. Убедитесь, что DNS вашего домена имеет запись A, указывающую на IP-адрес вашего сервера.</li>\n<li><code><span class=\"highlight\">erpnext_admin_password</span></code> — желаемый пароль для <strong>пользователя-администратора</strong> ERPNext. Сохраните этот пароль в надежном месте, он вскоре вам понадобится.</li>\n<li><code><span class=\"highlight\">mariadb_password</span></code> — это пароль, который вы создали в начале руководства для пользователя <code><span class=\"highlight\">sammy</span></code> MariaDB.</li>\n</ul>\n\n<p>Затем установите приложение ERPNext на сайт:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench --site <span class=\"highlight\">your_domain</span> install-app erpnext\n</li></ul></code></pre>\n<p>По завершении установки вы получите работающее приложение ERPNext 12. Теперь протестируем его с помощью команды <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench start\n</li></ul></code></pre>\n<p>Команда выше инициализирует консоль мониторинга в реальном времени, на которой будут отображаться различные сообщения о веб-сервере и других службах. Откройте веб-браузер и перейдите к <code>localhost:8000</code> (для локальных установок) или <code><span class=\"highlight\">your_domain</span>:8000</code> (если вы используете удаленный сервер). Вы увидите экран входа ERPNext (мы перейдем к входу и настройке позже, после подготовки нашего сайта к производству).</p>\n\n<p>После просмотра тестового развертывания вернитесь в свой терминал и нажмите <code>CTRL+C</code>. Это остановит ERPNext и закроет консоль мониторинга.</p>\n\n<p>Если ваша главная задача — создать модули или модифицировать ERPNext 12, можно остановиться на данном этапе. Компоненты для разработки больше не требуются. Однако, если вам нужна готовая система для производства, для которой не требуется ручная инициализация, необходимо установить и настроить еще несколько компонентов. Это ваш следующий шаг.</p>\n\n<h2 id=\"Шаг-8-—-Настройка-erpnext-12-для-производства\">Шаг 8 — Настройка ERPNext 12 для производства</h2>\n\n<p>Хотя приложение ERPNext 12 уже готово, система еще не готова к использованию в производственной среде. Чтобы обеспечить надежность и безопасность ERPNext, необходимо подключить несколько дополнительных служб:</p>\n\n<ul>\n<li><strong>Fail2ban</strong> обеспечивает дополнительный слой защиты от попыток грубого вмешательства со стороны злоумышленников и ботов.</li>\n<li><strong>Nginx</strong> в основном работает как прокси-сервер и перенаправляет весь трафик с порта <code>8000</code> в порт <code>80</code> (HTTP) или порт <code>443</code> (HTTPS)</li>\n<li><strong>Supervisor</strong> следит за постоянным выполнением ключевых процессов ERPNext и при необходимости перезапускает их.</li>\n</ul>\n\n<p>К этому моменту вы установили и настроили вручную ERPNext 12, что позволило вам отрегулировать процесс под ваш конкретный сценарий использования. Тем не менее для остальной части производственной настройки можно воспользоваться удобством CLI <code>bench</code> и автоматизировать установку и настройку остальных служб.</p>\n\n<p>Убедитесь, что вы находитесь в рабочем каталоге Frappe:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Теперь используйте следующую команду для завершения настройки ERPNext 12 для производства:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bench setup production <span class=\"highlight\">sammy</span> --yes\n</li></ul></code></pre>\n<p>Команда выше установит и настроит Nginx, Supervisor и Fail2Ban установит <code><span class=\"highlight\">sammy</span></code> в качестве владельца среды производства.</p>\n\n<p>Файлы конфигурации, созданные командой <code>bench</code>:</p>\n\n<ul>\n<li>Два файла конфигурации Nginx, расположенные в <code>/etc/nginx/nginx.conf</code> и <code>/etc/nginx/conf.d/<span class=\"highlight\">frappe-bench</span>.conf</code></li>\n<li>Один прокси-изолятор Fail2Ban, расположенный в <code>/etc/fail2ban/jail.d/nginx-proxy.conf</code> и один фильтр, расположенный в <code>/etc/fail2ban/filter.d/nginx-proxy.conf</code></li>\n</ul>\n\n<p>Этих настроек по умолчанию достаточно для целей нашего обучающего модуля, но вы можете свободно изучать эти файлы и подстраивать их под свои нужды.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl stop all\n</li></ul></code></pre>\n<p>And then, once you are ready, you can restart your services:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl start all\n</li></ul></code></pre>\n<p>Now you are ready to test your installation.</p>\n\n<h3 id=\"Проверка-установки-erpnext-12\">Проверка установки ERPNext 12</h3>\n\n<p>Для начала проверьте работу основных производственных служб, для чего используйте следующую команду <code>systemctl</code>, а затем отправьте ее на конвейер <code>grep</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">systemctl list-unit-files | grep 'fail2ban\\|nginx\\|supervisor'\n</li></ul></code></pre>\n<p>Результат должен будет выглядеть следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>fail2ban.service                       enabled\nnginx.service                          enabled\nsupervisor.service                     enabled\n</code></pre>\n<p>Убедившись в том, что все работает ожидаемым образом, вы можете протестировать ERPNext 12 в реальном времени на своем сервере. Откройте свой любимый браузер и перейдите в домен, где размещено приложение ERPNext 12.</p>\n\n<p>Через несколько секунд вы должны увидеть экран входа в ERPNext 12. Используйте имя пользователя <strong>Administrator</strong> и ранее созданный пароль <code><span class=\"highlight\">erpnext_admin_password</span></code>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_1.png\" alt=\"Экран входа в ERPNext\"></p>\n\n<p>На следующем экране вы увидите выпадающее меню, где вы можете выбрать язык пользовательского интерфейса для приложения:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_2.png\" alt=\"Выбор языка\"></p>\n\n<p>После выбора языка ERPNext подскажет вашу страну, часовой пояс и валюту:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_3.png\" alt=\"Выбор региона\"></p>\n\n<p>После заполнения информации о регионе вы сможете создать своего первого пользователя ERPNext. Предоставленная информация будет использоваться в качестве учетных данных для входа пользователя.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_4.png\" alt=\"Первый пользователь ERPNext\"></p>\n\n<p>На следующем экране вы увидите вопрос о <strong>доменах</strong>, которые вызывает ERPNext. Если вы не уверены в том, какой у вас домен, выберите <strong>Distribution</strong> и нажмите кнопку <strong>Next</strong> (далее).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_5.png\" alt=\"Выбор доменов\"></p>\n\n<p>Затем вам потребуется указать название компании и сокращенное название.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_6.png\" alt=\"Название компании\"></p>\n\n<p>На последнем экране ERPNext попросит ввести информацию о деятельности компании, название банка, план счетов и период финансового года. Дополнительные банки вы сможете ввести позже. Теперь заполните все поля на свое усмотрение и нажмите кнопку <strong>Complete Setup</strong> (Завершить настройку).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_7.png\" alt=\"Финансовая информация\"></p>\n\n<p>Далее вы увидите строку хода выполнения.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_8.png\" alt=\"Настройка ERPNext\"></p>\n\n<p>По завершении настройки появится главная панель ERPNext 12.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_9.png\" alt=\"Панель ERPNext 12\"></p>\n\n<p>Теперь вы полностью установили и настроили приложение ERPNext 12.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>Теперь, когда вы соответствующим образом установили приложение ERPNext 12, возможно, вы захотите начать внедрение системы для потребностей своей компании. Лучше всего начать, нажав на кнопку <strong>Getting Started</strong> (Начало работы) на панели ERPNext. ERPNext поможет вам настроить платформу для всех потребностей бизнеса и электронной коммерции.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_10.png\" alt=\"Начало работы\"></p>\n\n<p>Также вы, возможно, захотите повысить скорость ERPNext. В этом случае ознакомьтесь с документом <a href=\"https://github.com/frappe/erpnext/wiki/ERPNext-Performance-Tuning\">«Настройка производительности ERPNext</a>», где вы узнаете о лучших практиках и способах устранения проблем, связанных с производительностью.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:37 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67031/erpnext_0.png","linkMd5":"f57bebdffa936870bdf9f361d318434c","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","destWidth":3584,"destHeight":2022,"sourceBytes":966173,"destBytes":375664,"author":"Damaso Sanoja","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67031/erpnext_0.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","https://assets.digitalocean.com/articles/67031/erpnext_1.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_3/2020/08/31/07-48-32-714_e6b982f1d7fe90cd.webp","https://assets.digitalocean.com/articles/67031/erpnext_2.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn94@2020_6/2020/08/31/07-48-32-235_5dfe5b1d282ec7f1.webp","https://assets.digitalocean.com/articles/67031/erpnext_3.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_3/2020/08/31/07-48-31-862_07721efc54737d85.webp","https://assets.digitalocean.com/articles/67031/erpnext_4.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn45@2020_1/2020/08/31/07-48-32-664_c2f620996c337847.webp","https://assets.digitalocean.com/articles/67031/erpnext_5.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn13@2020_2/2020/08/31/07-48-33-137_5b1867188f4eb783.webp","https://assets.digitalocean.com/articles/67031/erpnext_6.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn25@2020_3/2020/08/31/07-48-31-288_1f4bd367e3868d6d.webp","https://assets.digitalocean.com/articles/67031/erpnext_7.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn14@2020_2/2020/08/31/07-48-31-596_2e4f2cf158e027fc.webp","https://assets.digitalocean.com/articles/67031/erpnext_8.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn65@2020_2/2020/08/31/07-48-31-323_2f22aaf79a58e762.webp","https://assets.digitalocean.com/articles/67031/erpnext_9.png":null,"https://assets.digitalocean.com/articles/67031/erpnext_10.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn97@2020_3/2020/08/31/07-48-32-254_dccc24f52c8f5d64.webp"},"publishedOrCreatedDate":1598860106979},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Erstellen eines Discord-Bots mit Node.js","link":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-de","description":"<p><em>Der Autor wählte den <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a>, um eine Spende im Rahmen des Programms <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> zu erhalten.</em></p>\n\n<h3 id=\"einführung\">Einführung</h3>\n\n<p><a href=\"https://discord.com/\">Discord</a> ist eine Chat-Anwendung, die Millionen von Benutzern auf der ganzen Welt für Messaging und Voice Chat nutzen – in Communities, die <a href=\"https://discord.com/developers/docs/resources/guild\">Gilden</a> oder Server genannt werden. Außerdem bietet Discord eine umfangreiche API, die Entwickler zum Einrichten leistungsfähiger Discord-Bots verwenden können. Bots können verschiedene Aktionen wie das Senden von Nachrichten an Server, das Ausführen von DM-Befehlen für Benutzer, das Moderieren von Servern und das Abspielen von Audio in Voice Chats erledigen. So können Entwickler leistungsstarke Bots entwickeln, die erweiterte, anspruchsvolle Merkmale wie Moderationstools oder auch Spiele umfassen. Der Utility-Bot <a href=\"https://dyno.gg/bot\">Dyno</a> zum Beispiel stellt Millionen von Gilden bereit und bietet nützliche Merkmale wie Spamschutz, einen Musikplayer und andere Dienstprogrammfunktionen. Wenn Sie wissen, wie man Discord-Bots erstellt, können Sie viele Möglichkeiten implementieren, mit denen Tausende von Menschen täglich interagieren können.</p>\n\n<p>In diesem Tutorial erstellen Sie von Grund auf einen Discord-Bot mit <a href=\"https://nodejs.org/en/\">Node.js</a> und der <a href=\"https://discord.js.org/#/\">Discord.js</a>-Bibliothek, sodass Benutzer direkt mit der Discord-API interagieren können. Sie werden ein Profil für einen Discord-Bot einrichten, Authentifizierungstoken für den Bot erhalten und den Bot mit der Fähigkeit zur Verarbeitung von Befehlen mit Argumenten von Benutzern programmieren.</p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Bevor Sie beginnen, benötigen Sie Folgendes:</p>\n\n<ul>\n<li><p>Node.js, auf Ihrem Entwicklungs-Rechner installiert. Um dies unter MacOS oder Ubuntu 18.04 zu installieren, folgen Sie den Schritten in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">Installation von Node.js und Erstellen einer lokalen Entwicklungsumgebung auf MacOS</a>oder dem Abschnitt <strong>Installation unter Verwendung eines PPA</strong> von <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">Installation von Node.js auf Ubuntu 18.04</a>.</p></li>\n<li><p>Einen Texteditor Ihrer Wahl wie <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>, <a href=\"https://atom.io\">Atom</a>, <a href=\"https://www.sublimetext.com/\">Sublime</a> oder <a href=\"https://www.nano-editor.org/\">Nano</a>.</p></li>\n<li><p>Ein <a href=\"https://discord.com/register\">kostenloses Discord-Konto</a> mit einem verifizierten E-Mail-Konto und einem <a href=\"https://support.discord.com/hc/en-us/articles/204849977-How-do-I-create-a-server-\">kostenlosen Discord-Server</a>, den Sie zum Testen Ihres Discord-Bots verwenden werden.</p></li>\n</ul>\n\n<h2 id=\"schritt-1-—-einrichten-eines-discord-bots\">Schritt 1 — Einrichten eines Discord-Bots</h2>\n\n<p>In diesem Schritt verwenden Sie die Entwickler-GUI von Discord, um einen Discord-Bot einzurichten und das Token des Bots zu empfangen, das Sie an Ihr Programm übergeben werden.</p>\n\n<p>Um einen Bot in der Discord-Plattform zu registrieren, verwenden Sie das <a href=\"https://discord.com/developers/applications/\">Dashboard der Discord-Anwendung</a>. Hier können Entwickler Discord-Anwendungen einschließlich Discord-Bots erstellen.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png\" alt=\"Abbildung des Dashboards der Discord-Anwendung nach dem ersten Besuch von https://discord.com/developers/applications\"></p>\n\n<p>Um zu beginnen, klicken Sie auf <strong>Neue Anwendung</strong>. Discord wird Sie bitten, einen Namen für Ihre neue Anwendung einzugeben. Klicken Sie dann auf <strong>Erstellen</strong>, um die Anwendung zu erstellen.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1b.png\" alt=\"Abbildung der Eingabeaufforderung für die Erstellung einer Anwendung, mit „Test Node.js Bot“ als Name der Anwendung\"></p>\n\n<p><span class='note'><strong>Anmerkung:</strong> Der Name Ihrer Anwendung ist unabhängig vom Namen des Bots und der Bot muss nicht den gleichen Namen tragen wie die Anwendung.<br></span></p>\n\n<p>Öffnen Sie nun Ihr Anwendungs-Dashboard. Um der Anwendung einen Bot hinzuzufügen, navigieren Sie links in der Navigationsleiste zur Registerkarte <strong>Bot</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1c.png\" alt=\"Abbildung der Registerkarte Bot des Anwendungs-Dashboards\"></p>\n\n<p>Klicken Sie auf die Schaltfläche <strong>Bot hinzufügen</strong>, um der Anwendung einen Bot hinzuzufügen. Klicken Sie auf die Schaltfläche <strong>Ja, los!</strong>, wenn sie Sie zur Bestätigung aufgefordert werden. Nun befinden Sie sich in einem Dashboard, das Details wie den Namen des Bots, das Authentifizierungstoken und das Profilbild enthält.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1d.png\" alt=\"Dashboard mit Details Ihres Bots\"></p>\n\n<p>Sie können den Namen oder das Profilbild Ihres Bots hier im Dashboard ändern. Außerdem müssen Sie das Authentifizierungstoken des Bots kopieren, indem Sie auf Klicken, <strong>um Token anzuzeigen klicken</strong> und das angezeigte Token kopieren.</p>\n\n<p><span class='warning'><strong>Achtung:</strong> Teilen oder laden Sie Ihr Bot-Token niemals hoch, damit sich andere Personen nicht bei Ihrem Bot anmelden können.<br></span></p>\n\n<p>Jetzt müssen Sie eine Einladung erstellen, mit der Sie die Discord-Gilden des Bots hinzufügen, in denen Sie den Bot testen können. Navigieren Sie zunächst zum Tab <strong>OAuth2</strong> des Anwendungs-Dashboards. Um eine Einladung zu erstellen, scrollen Sie nach unten und wählen Sie unter <strong>Bereiche</strong> <strong>Bot</strong> aus. Außerdem müssen Sie Berechtigungen festlegen, um zu kontrollieren, welche Aktionen Ihr Bot in Gilden ausführen darf. Wählen Sie für die Zwecke dieses Tutorials <strong>Administrator</strong>, wodurch Ihr Bot die Berechtigung erhält, fast alle Aktionen in Gilden auszuführen. Kopieren Sie den Link mit der Schaltfläche <strong>Kopieren</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1e.png\" alt=\"OAuth2-Registerkarte, mit dem Bereich auf „bot“ und Berechtigungen auf „administator“ gesetzt\"></p>\n\n<p>Als Nächstes fügen Sie den Bot einem Server hinzu. Folgen Sie dem gerade erstellten Einladungs-Link. Sie können den Bot jedem Server hinzufügen, den Sie besitzen oder für den Sie über Administratorberechtigungen verfügen (über das Dropdownmenü).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1f.png\" alt=\"Seite nach dem Folgen des Einladungs-Links, über die Benutzer den Bot Servern hinzufügen können\"></p>\n\n<p>Klicken Sie nun auf <strong>Weiter</strong>. Stellen Sie sicher, dass Sie das Kontrollkästchen neben <strong>Administrator</strong> aktiviert haben – dadurch erhält der Bot Administratorberechtigungen. Klicken Sie dann auf <strong>Autorisieren</strong>. Discord wird Sie bitten, eine <a href=\"https://en.wikipedia.org/wiki/CAPTCHA\">CAPTCHA</a> zu lösen, bevor der Bot dem Server beitritt. Sie werden den Discord-Bot nun auf der Mitgliederliste in dem Server sehen, dem Sie den Bot unter <strong>offline</strong> hinzugefügt haben.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1g.png\" alt=\"Mitgliederliste eines Discord-Servers mit dem neu erstellten Bot unter dem Abschnitt „offline“ der Mitgliederliste\"></p>\n\n<p>Sie haben erfolgreich einen Discord-Bot erstellt und einem Server hinzugefügt. Als Nächstes schreiben Sie ein Programm, um sich bei dem Bot anzumelden.</p>\n\n<h2 id=\"schritt-2-—-erstellen-ihres-projekts\">Schritt 2 — Erstellen Ihres Projekts</h2>\n\n<p>In diesem Schritt richten Sie die grundlegende Codierungsumgebung ein, in der Sie Ihren Bot erstellen und sich programmatisch beim Bot anmelden werden.</p>\n\n<p>Zuerst müssen Sie einen Projektordner und die erforderlichen Projektdateien für den Bot einrichten.</p>\n\n<p>Erstellen Sie Ihren Projektordner:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Wechseln Sie in den gerade erstellten Projektordner:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Als Nächstes verwenden Sie Ihren Texteditor, um eine Datei namens <code>config.json</code> zu erstellen und das Authentifizierungstoken Ihres Bots zu speichern:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano config.json\n</li></ul></code></pre>\n<p>Fügen Sie dann den folgenden Code der config-Datei hinzu und ersetzen Sie den hervorgehobenen Text durch das Authentifizierungstoken Ihres Bots:</p>\n<div class=\"code-label \" title=\"config.json\">config.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">{\n    \"BOT_TOKEN\": \"<span class=\"highlight\">YOUR BOT TOKEN</span>\"\n}\n</code></pre>\n<p>Speichern und schließen Sie die Datei.</p>\n\n<p>Als Nächstes erstellen Sie eine <code>package.json</code>-Datei, in der Details Ihres Projekts und Informationen über die Abhängigkeiten gespeichert werden, die Sie für das Projekt verwenden werden. Sie erstellen eine <code>package.json</code>-Datei, indem Sie den folgenden <code>npm</code>-Befehl ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm init\n</li></ul></code></pre>\n<p><code>npm</code> wird Sie nach verschiedenen Details zu Ihrem Projekt fragen. Wenn Sie eine Anleitung für diese Eingabeaufforderungen wünschen, konsultieren Sie <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-node-js-modules-with-npm-and-package-json#step-1-%E2%80%94-creating-a-packagejson-file\">Verwenden von Node.js-Modulen mit npm und package.json</a>.</p>\n\n<p>Sie installieren nun das <code>discord.js</code>-Paket, das Sie zur Interaktion mit der Discord-API verwenden werden. Sie können <code>discord.js</code> über npm mit dem folgenden Befehl installieren:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm install discord.js\n</li></ul></code></pre>\n<p>Nachdem Sie die Konfigurationsdatei eingerichtet und die erforderliche Abhängigkeit installiert haben, können Sie nun mit der Einrichtung Ihres Bots beginnen. In einer realen Anwendung würde ein großer Bot auf viele Dateien verteilt, aber für die Zwecke dieses Tutorials wird sich der Code Ihres Bots in einer Datei befinden.</p>\n\n<p>Erstellen Sie zunächst für den Code eine Datei mit dem Namen <code>index.js</code> im Ordner <code><span class=\"highlight\">discord-bot</span></code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Beginnen Sie mit dem Codieren des Bots, indem Sie die <code>discord.js</code>-Abhängigkeit und die Konfigurationsdatei mit dem Token des Bots vorschreiben:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n</code></pre>\n<p>Fügen Sie danach die folgenden zwei Codezeilen hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Speichern und schließen Sie Ihre Datei.</p>\n\n<p>Die erste Zeile des Codes erstellt einen neuen <code>Discord.Client</code> und weist ihn der Konstanten <code>client</code> zu. Dieser Client ist ein Teil davon, wie Sie mit der Discord-API interagieren werden und wie Discord Sie bei Ereignissen wie neuen Meldungen benachrichtigen wird. Der Client ist in Wirklichkeit der Discord-Bot.</p>\n\n<p>Die zweite Zeile des Codes verwendet die <code>login</code>-Methode für den <code>Client</code>, um sich bei dem von Ihnen erstellten Discord-Bot anzumelden, wobei das Token in der Datei <code>config.json</code> als Passwort verwendet wird. Mit dem Token erfährt die Discord-API, an welches Programm sich der Bot richtet und dass Sie für die Nutzung des Bots authentifiziert sind.</p>\n\n<p>Führen Sie nun mit Node die Datei <code>index.js</code> aus:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Der Status Ihres Bots wird sich auf dem Discord-Server, dem er hinzugefügt wurde, in „online“ ändern.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step2a.png\" alt=\"Abbildung des Bots im Online-Zustand\"></p>\n\n<p>Sie haben erfolgreich eine Codierungsumgebung eingerichtet und den grundlegenden Code für die Anmeldung bei einem Discord-Bot erstellt. Im nächsten Schritt werden Sie Benutzerbefehle verwalten und Ihren Bot zur Durchführung von Aktionen veranlassen, wie z. B. zum Senden von Nachrichten.</p>\n\n<h2 id=\"schritt-3-—-verwendung-ihres-ersten-benutzerbefehls\">Schritt 3 — Verwendung Ihres ersten Benutzerbefehls</h2>\n\n<p>In diesem Schritt erstellen Sie einen Bot, der Benutzerbefehle handhaben kann. Sie werden Ihren ersten Befehl (<code>ping</code>) implementieren, der mit <code>\"pong\"</code> und der Zeit antworten wird, die zum Antworten auf den Befehl benötigt wurde.</p>\n\n<p>Zunächst müssen Sie alle Nachrichten erkennen und empfangen, die Benutzer senden, damit Sie Befehle verarbeiten können. Mit der Methode <code>on</code> auf dem Discord-Client wird Ihnen Discord eine Benachrichtigung zu neuen Ereignissen senden. Die Methode <code>on</code> hat zwei Argumente: den Namen eines Ereignisses, auf das gewartet wird, und eine Funktion, die jedes Mal ausgeführt wird, wenn das Ereignis eintritt. Bei dieser Methode können Sie auf das Ereignis <code>message</code> warten – es wird jedes Mal eintreten, wenn eine Nachricht an eine Gilde gesendet wird, in der der Bot die Berechtigung zum Anzeigen von Nachrichten hat. Lassen Sie uns daher eine Funktion erstellen, die bei jeder Übermittlung einer Nachricht ausgeführt wird, um Befehle zu verarbeiten.</p>\n\n<p>Öffnen Sie zunächst Ihre Datei:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Fügen Sie den folgenden Code zur Datei hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\n\n<span class=\"highlight\">client.on(\"message\", function(message) { </span>\n<span class=\"highlight\">                                         </span>\n<span class=\"highlight\">});                                      </span>\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Diese Funktion, die beim Ereignis <code>message</code> ausgeführt wird, nutzt <code>message</code> als Parameter. <code>message</code> wird den Wert einer <a href=\"https://discord.js.org/#/docs/main/stable/class/Message\">Discord.js message</a>-Instanz haben, die Informationen über die gesendete Nachricht und Methoden enthält, um dem Bot beim Antworten zu helfen.</p>\n\n<p>Fügen Sie nun Ihrer Befehlsverarbeitungsfunktion die folgende Codezeile hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  <span class=\"highlight\">if (message.author.bot) return;</span>\n});\n...\n</code></pre>\n<p>Diese Zeile prüft, ob der Autor der Nachricht ein Bot ist; wenn ja, wird die Verarbeitung des Befehls gestoppt. Dies ist wichtig, da Sie Nachrichten von Bots im Allgemeinen weder bearbeiten noch beantworten möchten. Bots müssen oder wollen unseren Bot in der Regel nicht verwenden, sodass ein Ignorieren ihrer Nachrichten Rechenleistung spart und unbeabsichtigte Antworten verhindert.</p>\n\n<p>Jetzt schreiben Sie einen Befehlshandler. Um das zu erreichen, ist es hilfreich, das übliche Format eines Discord-Befehls zu verstehen. In der Regel enthält die Struktur eines Discord-Befehls drei Teile in der folgenden Reihenfolge: ein Präfix, einen Befehlsnamen und (manchmal) Befehlsargumente.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png\" alt='Abbildung eines typischen Discord-Befehls, der \"! add 1 2\" lautet'></p>\n\n<ul>\n<li><p>Präfix: Das Präfix kann alles sein, ist aber in der Regel eine Interpunktion oder abstrakte Phrase, die normalerweise nicht am Anfang einer Nachricht stehen würde. Das bedeutet, dass bei Eingabe des Präfix am Anfang der Nachricht der Bot weiß, dass der Befehl von einem Bot verarbeitet werden soll.</p></li>\n<li><p>Befehlsname: Der Name des Befehls, den der Benutzer verwenden möchte. Das bedeutet, dass der Bot mehrere Befehle mit unterschiedlicher Funktionalität unterstützen kann und Benutzer durch Angabe eines anderen Befehlsnamens zwischen ihnen wählen können.</p></li>\n<li><p>Argumente: Wenn der Befehl ggf. zusätzliche Informationen vom Benutzer benötigt oder verwendet, kann der Benutzer nach dem Befehlsnamen Argumente angeben, wobei jedes Argument durch ein Leerzeichen getrennt wird.</p></li>\n</ul>\n\n<p><span class='note'><strong>Anmerkung:</strong> Es gibt keine zwingende Befehlsstruktur; Bots können Befehle verarbeiten, wie sie wollen. Die hier dargestellte Struktur ist jedoch eine effiziente Struktur, die eine überwiegende Mehrheit der Bots verwendet.<br></span></p>\n\n<p>Um mit der Erstellung eines Befehlsparsers zu beginnen, der dieses Format handhabt, fügen Sie der Nachrichtenverarbeitungsfunktion folgende Codezeilen hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n<span class=\"highlight\">const prefix = \"!\";</span>\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  <span class=\"highlight\">if (!message.content.startsWith(prefix)) return;</span>\n});\n...\n</code></pre>\n<p>Sie fügen die erste Codezeile hinzu, um den Wert <code>\"!\"</code> der Konstanten <code>prefix</code> zuzuweisen, die Sie als Präfix des Bots nutzen werden.</p>\n\n<p>Die zweite Codezeile, die Sie hinzufügen, prüft, ob der Inhalt der Nachricht, die der Bot verarbeitet, mit dem von Ihnen festgelegten Präfix beginnt; wenn nicht, wird die Weiterverarbeitung der Nachricht gestoppt.</p>\n\n<p>Jetzt müssen Sie den Rest der Nachricht in einen Befehlsnamen und jegliche Argumente konvertieren, die in der Nachricht vorhanden sind. Fügen Sie die folgenden hervorgehobenen Zeilen hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  <span class=\"highlight\">const commandBody = message.content.slice(prefix.length);</span>\n  <span class=\"highlight\">const args = commandBody.split(' ');</span>\n  <span class=\"highlight\">const command = args.shift().toLowerCase();</span>\n});\n...\n</code></pre>\n<p>Sie verwenden hier die erste Zeile, um das Präfix aus dem Nachrichteninhalt zu entfernen und das Ergebnis der Konstanten <code>commandBody</code> zuzuweisen. Dies ist notwendig, da Sie das Präfix nicht in den analysierten Befehlsnamen einfügen möchten.</p>\n\n<p>Die zweite Zeile nimmt die Nachricht mit dem entfernten Präfix und wendet die <a href=\"https://www.digitalocean.com/community/tutorials/how-to-index-split-and-manipulate-strings-in-javascript#splitting-strings\"><code>split</code>-Methode</a> darauf an, wobei ein Leerzeichen als Trennzeichen dient. Dadurch wird eine Aufspaltung in eine Gruppe von untergeordneten Zeichenfolgen vorgenommen, wobei bei jedem Leerzeichen eine Trennung vorgenommen wird. So entsteht ein Array, das den Befehlsnamen und dann (wenn in der Nachricht enthalten) Argumente beinhaltet. Sie weisen dieses Array der Konstanten <code>args</code> zu.</p>\n\n<p>Die dritte Zeile entfernt das erste Element aus dem Array <code>args</code> (was der bereitgestellte Befehlsname sein wird), konvertiert es in Kleinbuchstaben und weist es dann der Konstanten <code>command</code> zu. Dadurch können Sie den Befehlsnamen isolieren und nur Argumente im Array belassen. Außerdem verwenden Sie die Methode <code>toLowerCase</code>, da bei Befehlen in Discord-Bots typischerweise nicht zwischen Groß-/Kleinschreibung unterschieden wird.</p>\n\n<p>Sie haben die Erstellung eines Befehlsparsers, die Implementierung eines erforderlichen Präfix und das Erhalten des Befehlsnamens und der Argumente von Nachrichten abgeschlossen. Sie werden nun den Code für die spezifischen Befehle implementieren und erstellen.</p>\n\n<p>Fügen Sie folgenden Code hinzu, um den <code>ping</code>-Befehl zu implementieren:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  <span class=\"highlight\">if (command === \"ping\") {</span>\n  <span class=\"highlight\">                         </span>\n  <span class=\"highlight\">}                        </span>\n});\n...\n</code></pre>\n<p>Diese <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-conditional-statements-in-javascript\"><code>if</code>-Anweisung</a> prüft, ob der analysierte Befehlsname (der der Konstanten <code>command</code> zugewiesen ist) mit <code>\"ping\"</code> übereinstimmt. Wenn ja, heißt das, dass der Benutzer den Befehl <code>\"ping\"</code> verwenden möchte. Sie werden den Code für den spezifischen Befehl im <code>if</code>-Anweisungsblock verschachteln. Sie werden dieses Muster für andere Befehle, die Sie implementieren möchten, wiederholen.</p>\n\n<p>Jetzt können Sie den Code für den Befehl <code>\"ping\"</code> implementieren:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    <span class=\"highlight\">const timeTaken = Date.now() - message.createdTimestamp;</span>\n    <span class=\"highlight\">message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);</span>\n  }\n...\n</code></pre>\n<p>Speichern und schließen Sie Ihre Datei.</p>\n\n<p>Sie fügen den Befehlsblock <code>\"ping\"</code> hinzu, der die Differenz zwischen der aktuellen Zeit (ermittelt durch Anwendung der <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now\">Methode <code>now</code></a> auf das Objekt <code>Date</code>) und dem Zeitstempel, als die Nachricht erstellt wurde, berechnet (in Millisekunden). Dadurch wird berechnet, wie lang die Verarbeitung der Nachricht und das <code>\"ping\"</code> des Bots benötigt haben.</p>\n\n<p>Die zweite Zeile reagiert auf den Befehl des Benutzers mit der <code>reply</code>-Methode in der Konstanten <code>message</code>. Die <a href=\"https://discord.js.org/#/docs/main/stable/class/Message?scrollTo=reply\"><code>reply</code>-Methode</a> pingt (wodurch der Benutzer benachrichtigt und die Nachricht für den angegebenen Benutzer hervorgehoben wird) den Benutzer an, der den Befehl aufgerufen hat, gefolgt von dem Inhalt, der als erstes Argument der Methode angegeben wurde. Sie stellen ein <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">template literal</a> bereit, das eine Nachricht und den errechneten Ping als Antwort enthält, die die <code>reply</code>-Methode verwenden wird.</p>\n\n<p>Damit ist die Implementierung des Befehls <code>\"ping\"</code> abgeschlossen.</p>\n\n<p>Führen Sie Ihren Bot mit dem folgenden Befehl aus (im selben Ordner wie <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Sie können nun den Befehl <code>\"! ping\"</code> in jedem Kanal nutzen, den der Bot anzeigen und in dem der Bot Nachrichten senden kann; dabei kommt es zu einer Antwort.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png\" alt='Abbildung von Bot, der in Discord auf \"! ping\" mit \"@T0M, Pong! This message had a latency of 1128ms.\" antwortet.'></p>\n\n<p>Sie haben nun erfolgreich einen Bot erstellt, der Benutzerbefehle handhaben kann, und Ihren ersten Befehl implementiert. Im nächsten Schritt werden Sie Ihren Bot weiterentwickeln, indem Sie einen sum-Befehl implementieren.</p>\n\n<h2 id=\"schritt-4-—-implementieren-des-sum-befehls\">Schritt 4 — Implementieren des sum-Befehls</h2>\n\n<p>Jetzt werden Sie Ihr Programm durch Implementieren des <code>\"! sum\"</code>-Befehls erweitern. Der Befehl nimmt eine beliebige Anzahl von Argumenten an und fügt sie zusammen, bevor die Summe aller Argumente an den Benutzer zurückgegegen wird.</p>\n\n<p>Wenn Ihr Discord-Bot noch ausgeführt wird, können Sie den Prozess mit <code>Strg+C</code> anhalten.</p>\n\n<p>Öffnen Sie erneut Ihre <code>index.js</code>-Datei:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Um mit der Implementierung des <code>\"! sum\"</code>-Befehls zu beginnen, werden Sie einen <code>else-if</code>-Block verwenden. Nach der Prüfung des ping-Befehlsnamens wird geprüft, ob der Befehlsname gleich <code>\"sum\"</code> ist. Wir verwenden einen <code>else-if</code>-Block, da nur ein Befehl auf einmal verarbeitet wird; wenn das Programm dem Befehlsnamen <code>\"ping\"</code> entspricht, muss also nicht auf den Befehl <code>\"sum\"</code> geprüft werden. Fügen Sie in Ihrer Datei die folgenden hervorgehobenen Zeilen hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Ping! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  <span class=\"highlight\">else if (command === \"sum\") {</span>\n  <span class=\"highlight\">                             </span>\n  <span class=\"highlight\">}                            </span>\n});\n...\n</code></pre>\n<p>Sie können mit der Implementierung des Codes für den <code>\"sum\"</code>-Befehl beginnen. Der Code für den Befehl <code>\"sum\"</code> wird in den gerade erstellten <code>else-if</code>-Block eingebunden. Fügen Sie nun folgenden Code hinzu:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  else if (command === \"sum\") {\n    <span class=\"highlight\">const numArgs = args.map(x =&gt; parseFloat(x));</span>\n    <span class=\"highlight\">const sum = numArgs.reduce((counter, x) =&gt; counter += x);</span>\n    <span class=\"highlight\">message.reply(`The sum of all the arguments you provided is ${sum}!`);</span>\n  }\n...\n</code></pre>\n<p>Sie verwenden die <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#map()\"><code>map</code>-Methode</a> in der Argumentenliste, um eine neue Liste zu erstellen, indem Sie die Funktion <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseFloat\"><code>parseFloat</code></a> auf jedes Element im Array <code>args</code> anwenden. Dadurch ensteht ein neues Array (das der Konstanten <code>numArgs</code> zugewiesen ist), in dem alle Elemente Zahlen anstelle von Zeichenfolgen sind. Das bedeutet, dass Sie durch Addieren die Summe der Zahlen ermitteln können.</p>\n\n<p>Die zweite Zeile wendet die <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#reduce()\"><code>reduce</code>-Methode</a> auf die Konstante <code>numArgs</code> an; so ist eine Funktion verfügbar, die die Summe aller Elemente in der Liste errechnet. Sie weisen die Summe aller Elemente in <code>numArgs</code> der Konstanten <code>sum</code> zu.</p>\n\n<p>Dann wenden Sie die <code>reply</code>-Methode auf das Nachrichtenobjekt an, um auf den Befehl des Benutzers mit einem <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">template literal</a> zu antworten, das die Summe aller Argumente enthält, die der Benutzer an den Bot sendet.</p>\n\n<p>Damit ist die Implementierung des Befehls <code>\"sum\"</code> abgeschlossen. Führen Sie Ihren Bot nun mit dem folgenden Befehl aus (im selben Ordner wie <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Sie können den Befehl <code>\"! sum\"</code> jetzt in jedem Kanal verwenden, den der Bot anzeigen und in dem er Nachrichten senden kann.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step4a.png\" alt='Abbildung von Bot, der mit „Die Summe aller von Ihnen angegebenen Argumente ist 6!“ auf \"! sum 1 2 3\" und dann mit „Die Summe aller von Ihnen angegebenen Argumente ist 13!“ auf \"! sum 1.5 1.5 10\" antwortet'></p>\n\n<p>Im Folgenden finden Sie eine fertige Version des <code>index.js</code>-Bot-Skripts:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n\nconst client = new Discord.Client();\n\nconst prefix = \"!\";\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  const commandBody = message.content.slice(prefix.length);\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  else if (command === \"sum\") {\n    const numArgs = args.map(x =&gt; parseFloat(x));\n    const sum = numArgs.reduce((counter, x) =&gt; counter += x);\n    message.reply(`The sum of all the arguments you provided is ${sum}!`);\n  }\n});\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>In diesem Schritt haben Sie Ihren Discord-Bot durch Implementieren des <code>sum</code>-Befehls weiterentwickelt.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>Sie haben einen Discord-Bot implementiert, der verschiedene Benutzerbefehle und Befehlsargumente handhaben kann. Wenn Sie Ihren Bot erweitern möchten, können Sie ggf. weitere Befehle implementieren oder weitere Bestandteile der Discord-API zur Erstellung eines leistungsfähigen Discord-Bots testen. Konsultieren Sie die <a href=\"https://discord.js.org/#/docs/main/stable/general/welcome\">Discord.js-Dokumentation</a> oder <a href=\"https://discord.com/developers/docs/intro\">Discord-API-Dokumentation</a>, um mehr über die Discord-API zu erfahren.</p>\n\n<p>Bei der Erstellung von Discord-Bots müssen Sie stets die <a href=\"https://discord.com/developers/docs/legal\">allgemeinen Geschäftsbedingungen der Discord-API</a> im Auge behalten; darin wird umrissen, wie Entwickler die Discord-API verwenden müssen. Außerdem können Sie <a href=\"https://github.com/meew0/discord-bot-best-practices/blob/master/README.md\">diesen Satz an Leitfäden</a> lesen, um einen Discord-Bot optimal zu implementieren und Tipps zur Gestaltung von Discord-Bots zu erhalten. Wenn Sie mehr über Node.js erfahren möchten, lesen Sie unsere Serie zum <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">Codieren in Node.js</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:19 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png","linkMd5":"447e70a1f3e8a777994877fd01b67679","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","destWidth":1920,"destHeight":973,"sourceBytes":66395,"destBytes":26384,"author":"Tom","articleImgCdnMap":{"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1b.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn9@2020_3/2020/08/31/07-48-31-275_690c64ccbc0c5170.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1c.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn30@2020_4/2020/08/31/07-48-31-778_f5a474e22c90438c.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1d.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_6/2020/08/31/07-48-31-392_d550c10707834d3f.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1e.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/31/07-48-31-921_817dcbabd0b27a3d.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1f.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn89@2020_2/2020/08/31/07-48-31-288_1d3824d3640df0a3.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1g.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn77@2020_3/2020/08/31/07-48-31-225_5aca524b04a26500.webp","https://assets.digitalocean.com/articles/node_discord_bot/step2a.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn74@2020_2/2020/08/31/07-48-31-293_81968c3f6c9ff261.webp","https://assets.digitalocean.com/articles/node_discord_bot/step3a.png":null,"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn98@2020_5/2020/08/31/07-48-33-506_74310bb53d7bafb2.webp","https://assets.digitalocean.com/articles/node_discord_bot/step4a.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn70@2020_4/2020/08/31/07-48-31-272_5589082ccebd5fbf.webp"},"publishedOrCreatedDate":1598860106985},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment installer une pile ERPNext sur Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-fr","description":"<p><em>L'auteur a choisi <a href=\"https://www.brightfunds.org/organizations/software-in-the-public-interest-inc\">Software in the Public Interest</a> pour recevoir un don dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://erpnext.com//\">ERPNext</a> est une suite de planification des ressources d'entreprise (ERP) qui tire parti de la puissance et de la flexibilité des technologies open-source. Elle excelle dans la gestion des processus opérationnels de base tels que la finance, les ventes, les ressources humaines, la fabrication, les achats, les services, les besoins du helpdesk, et plus encore. Parmi les avantages de la mise en œuvre d'un système comme ERPNext, on peut citer :</p>\n\n<ul>\n<li>Une meilleure productivité en automatisant les processus commerciaux répétitifs</li>\n<li>Une amélioration de l'efficacité informatique en partageant une base de données pour tous les départements de la société</li>\n<li>Une meilleure prise de décisions grâce à une vision intégrale de la relation entre les unités commerciales</li>\n</ul>\n\n<p>ERPNext repose sur <a href=\"https://frappe.io/frappe\">Frappe</a>, un cadre d'application web full-stack écrit en <a href=\"https://www.python.org/\">Python</a> qui tire pleinement parti de <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">l'environnement d'exécution Node/JavaScript</a> et utilise <a href=\"https://mariadb.org/\">MariaDB</a> comme backend de base de données. L'un des nombreux avantages des applications reposant sur Frappe, comme ERPNext, est l'utilitaire de ligne de commande <a href=\"https://github.com/frappe/bench\">bench</a>. L'ILC bench permet aux administrateurs de gagner du temps en automatisant des tâches telles que l'installation, la mise à jour, la configuration et la gestion de plusieurs sites Frappe/ERPNext.</p>\n\n<p>Dans ce tutoriel, vous installerez et configurez une pile ERPNext sur un serveur tournant sous Ubuntu 18.04. Cela vous permettra de configurer votre pile pour divers environnements de développement ou de production en fonction de vos besoins, et cela vous préparera à construire une architecture plus complexe et tolérante aux défauts.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<ul>\n<li>Un serveur Ubuntu 18.04 avec au moins 4 Go de RAM et un utilisateur <code>sudo</code> non root. Vous pouvez configurer votre serveur et votre utilisateur en suivant <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">le guide de configuration initiale de serveur Ubuntu 18.04</a>.</li>\n</ul>\n\n<p><span class='note'><strong>Note :</strong> Lorsque vous choisissez les spécifications de votre serveur, n'oubliez pas que les systèmes ERP sont gourmands en ressources. Ce guide préconise un serveur de 4 Go de RAM, ce qui est suffisant pour les cas d'utilisation de base, mais les exigences matérielles spécifiques peuvent varier en fonction du nombre d'utilisateurs et de la taille de votre entreprise.<br></span></p>\n\n<ul>\n<li>Un nom de domaine entièrement enregistré avec un enregistrement A pointant vers votre serveur. Si vous utilisez un droplet DigitalOcean, vous pouvez suivre <a href=\"https://www.digitalocean.com/community/tutorials/how-to-point-to-digitalocean-nameservers-from-common-domain-registrars\">ce guide</a> pour configurer correctement votre DNS. Ce tutoriel utilisera <code><span class=\"highlight\">your_domain</span></code>.</li>\n</ul>\n\n<h2 id=\"Étape 1-—-configuration-du-pare-feu\">Étape 1 — Configuration du pare-feu</h2>\n\n<p>Bien que la configuration d'un pare-feu pour le développement soit facultative, pour la production il s'agit d'une pratique de sécurité obligatoire.</p>\n\n<p>Vous devrez ouvrir les ports suivants sur votre serveur ERPNext :</p>\n\n<ul>\n<li><code>80/tcp</code> et <code>443/tcp</code> pour HTTP et HTTPS, respectivement</li>\n<li><code>3306/tcp</code> pour la connexion à MariaDB (recommandé uniquement si vous avez besoin d'un accès à la base de données à distance)</li>\n<li><code>143/tcp</code> et <code>25/tcp</code> pour IMAP et STMP, respectivement</li>\n<li><code>22/tcp</code> pour SSH (si vous n'avez pas encore activé <code>OpenSSH</code>)</li>\n<li><code>8000/tcp</code> pour les tests de développement avant de déployer votre site</li>\n</ul>\n\n<p>Pour ouvrir plusieurs ports à la fois, vous pouvez utiliser la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 22,25,143,80,443,3306,8000/tcp\n</li></ul></code></pre>\n<p>Vous pouvez également autoriser des connexions à partir d'adresses IP spécifiques sur des ports spécifiques en utilisant cette commande :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow from <span class=\"highlight\">server_IP</span> to any port <span class=\"highlight\">port_number</span>\n</li></ul></code></pre>\n<p>Après avoir ouvert tous les ports nécessaires, activez le pare-feu :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Après avoir activé le pare-feu, confirmez l'état de vos ports ouverts :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>Pour plus d'informations concernant la configuration du pare-feu, veuillez lire notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-18-04\">Comment configurer un pare-feu avec UFW sur Ubuntu 18.04</a>.</p>\n\n<p>La mise en place d'un pare-feu approprié est la première des deux étapes préliminaires. Vous allez maintenant configurer le mappage du clavier et l'encodage des caractères sur votre serveur.</p>\n\n<h2 id=\"Étape 2-—-configuration-des-sites\">Étape 2 — Configuration des sites</h2>\n\n<p>Il est fortement recommandé de configurer le mappage du clavier pour la console ainsi que la langue et l'encodage des caractères sur votre hôte. Ceci est nécessaire pour éviter les problèmes éventuels lors du processus d'installation d'ERPNext 12. Remarquez que cette configuration n'a rien à voir avec la langue de l'interface utilisateur sur votre plateforme ERPNext actuelle, mais avec la configuration locale du système.</p>\n\n<p>Tout d'abord, mettez à jour votre serveur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Configurez maintenant le keymap, la langue et l'encodage des caractères :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo localectl set-keymap us &amp;&amp; sudo localectl set-locale LANG=en_US.utf8\n</li></ul></code></pre>\n<p>L'utilitaire <code>localectl</code> est utilisé par Ubuntu 18.04 et d'autres distributions Linux pour contrôler et modifier les paramètres locaux et la disposition du clavier à l'échelle du système, avant que l'utilisateur ne se connecte, ce qui est exactement ce dont ERPNext 12 a besoin.</p>\n\n<p>Vous devrez également ajouter les lignes suivantes à votre fichier <code>/etc/environment</code>. Utilisez <code>nano</code> ou votre éditeur de texte préféré pour ouvrir le fichier :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/environment\n</li></ul></code></pre>\n<p>Maintenant ajoutez le contenu suivant :</p>\n<div class=\"code-label \" title=\"/etc/environment\">/etc/environment</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">LC_ALL=en_US.UTF-8\nLC_CTYPE=en_US.UTF-8\nLANG=en_US.UTF-8\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>Redémarrez votre serveur pour appliquer tous les changements :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo reboot\n</li></ul></code></pre>\n<p>Patientez quelques minutes pendant que votre serveur redémarre, puis réintégrez le <code>ssh</code>. Vous êtes maintenant prêt à installer votre base de données.</p>\n\n<h2 id=\"Étape-3-—-installation-de-mariadb-10-4\">Étape 3 — Installation de MariaDB 10.4</h2>\n\n<p>Vous allez maintenant ajouter MariaDB à la pile de votre serveur. ERPNext 12 requiert MariaDB 10.2+, mais la version incluse dans le dépôt officiel d'Ubuntu 18.04 est 10.1, ce qui signifie que vous devrez installer une version supérieure. Pour les besoins de ce guide, vous utiliserez la dernière version stable de MariaDB, qui, au moment de la rédaction de ce document, est la version 10.4.</p>\n\n<p>Pour installer MariaDB 10.4 sur Ubuntu 18.04, vous devrez ajouter la clé de signature et le dépôt appropriés. Vous pouvez trouver ces informations sur <a href=\"https://downloads.mariadb.org/mariadb/repositories/#mirror=klaus\">l'assistant de dépôt de la Fondation MariaDB</a>. Pour visualiser la page, collez cette URL dans votre navigateur web. Maintenant, sous <strong>1. Choose a Distro</strong>, cliquez sur <strong>Ubuntu</strong>. Une deuxième colonne intitulée <strong>2. Choose a Release</strong> (Choisir une version) apparaîtra. Sous ce titre, cliquez sur <strong>18.04 LTS &ldquo;bionic&rdquo;</strong>. Une troisième colonne intitulée <strong>3.Choose a Version</strong> apparaîtra alors. Sous ce titre, cliquez sur <strong>10.4 stable</strong>. Une quatrième colonne intitulée <strong>4.Choose a Mirror</strong> apparaîtra alors. Choisissez un miroir en fonction de votre emplacement, puis MariaDB remplira les commandes appropriées pour votre installation personnalisée.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_0.png\" alt=\"Assistant de dépôt MariaDB\"></p>\n\n<p>Exécutez les trois commandes remplies, ce qui ajoutera correctement le dépôt et la clé MariaDB. Vos propres commandes ressembleront à ceci :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt-get install software-properties-common &amp;&amp; sudo apt-key adv --fetch-keys <span class=\"highlight\">'https://mariadb.org/mariadb_release_signing_key.asc'</span> &amp;&amp; sudo add-apt-repository 'deb [arch=amd64,arm64,ppc64el] <span class=\"highlight\">http://mirror.klaus-uwe.me/mariadb/repo/10.4/ubuntu</span> bionic main'\n</li></ul></code></pre>\n<p>Une fois que vous avez fini d'ajouter le référentiel, installez MariaDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install mariadb-server\n</li></ul></code></pre>\n<p>Après avoir installé <code>mariadb-server</code>, installez les packages suivants :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install libmysqlclient-dev python3-mysqldb\n</li></ul></code></pre>\n<p>ERPNext 12 est une application Python et nécessite donc la bibliothèque <code>python3-mysqldb</code> pour la gestion de la base de données. Concernant <code>libmysqlclient-dev</code>, <code>mariadb-client</code>, et <code>libmariadbclient18</code> : ces paquets permettent aux utilisateurs de communiquer avec le service MariaDB. <code>ntpdate</code> et <code>libdate-manip-perl</code> sont utilisés par ERPNext pour la synchronisation horaire du serveur.</p>\n\n<p>Ensuite, ajoutez une couche de sécurité basique supplémentaire au serveur MariaDB en exécutant le script <code>mysql_secure_installation</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql_secure_installation\n</li></ul></code></pre>\n<p>Le script <code>mysql_secure_installation</code> vous posera plusieurs questions :</p>\n\n<ul>\n<li>La première invite vous demandera le mot de passe <strong>root</strong>, mais comme aucun de mot de passe n'a été configuré, appuyez sur <code>ENTER</code>.</li>\n<li>Ensuite, vous devrez décider d'utiliser ou non l'authentification Unix. Répondez <code>Y</code> pour accepter cette méthode d'authentification.</li>\n<li>Lorsqu'il vous sera demandé de modifier le mot de passe <strong>root</strong> de MariaDB, répondez <code>N</code>. L'utilisation du mot de passe par défaut avec l'authentification Unix est la configuration recommandée pour les systèmes basés sur Ubuntu, car le compte <strong>root</strong> est étroitement lié aux tâches de maintenance automatisées du système.</li>\n<li>Les questions restantes concernent la suppression de l'utilisateur anonyme de la base de données, la restriction du compte <strong>root</strong> pour vous connecter à distance sur localhost, la suppression de la base de données de test et le rechargement des tables de privilèges. Vous pouvez répondre <code>Y</code> à toutes ces questions en toute sécurité.</li>\n</ul>\n\n<p>Après avoir terminé le script <code>mysql_secure_installation</code>, MariaDB commencera à fonctionner en utilisant sa configuration par défaut. L'installation standard ERPNext utilise le <strong>root</strong> user de MariaDB, pour toutes les opérations de la base de données. Bien que cette approche soit pratique sur les configurations de serveur unique, elle n'est pas considérée comme une bonne pratique en matière de sécurité. Par conséquent, dans la section suivante, vous apprendrez à éviter ce problème en créant un nouvel utilisateur avec des privilèges spéciaux.</p>\n\n<h3 id=\"création-d-39-un-super-utilisateur-admin-de-mariadb\">Création d'un Super utilisateur admin de MariaDB</h3>\n\n<p>ERPNext prévoit d'utiliser le <strong>root</strong> user de MariaDB pour gérer les connexions aux bases de données, mais ce n'est pas toujours idéal. Pour contourner cette limitation et laisser un utilisateur non-root gérer MariaDB, vous allez maintenant créer manuellement une base de données portant le nom de l'utilisateur. Ensuite, vous serez en mesure d'attribuer des privilèges spéciaux au nouvel utilisateur pour conduire les opérations de la base de données d'ERPNext.</p>\n\n<p>Ouvrez l'invite MariaDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql\n</li></ul></code></pre>\n<p>Créez maintenant une nouvelle base de données nommée d'après l'utilisateur que vous souhaitez affecter aux connexions MariaDB. Ce tutoriel utilisera <code><span class=\"highlight\">sammy</span></code> mais vous êtes libre de choisir votre propre nom :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">CREATE DATABASE <span class=\"highlight\">sammy</span>;\n</li></ul></code></pre>\n<p>Confirmez que la base de données a été créée en utilisant cette instruction SQL :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SHOW DATABASES;\n</li></ul></code></pre>\n<p>Vous obtiendrez une sortie semblable à ceci :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| <span class=\"highlight\">sammy</span>             |\n+--------------------+\n</code></pre>\n<p>Créez maintenant l'utilisateur MariaDB <code><span class=\"highlight\">sammy</span></code> avec des privilèges similaires à <strong>root</strong>, puis donnez à l'utilisateur le mot de passe fort de votre choix. Conservez le mot de passe dans un endroit sûr, vous en aurez besoin plus tard :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">GRANT ALL PRIVILEGES ON *.* TO '<span class=\"highlight\">sammy</span>'@'%' IDENTIFIED BY '<span class=\"highlight\">mariadb_password</span>' WITH GRANT OPTION;\n</li></ul></code></pre>\n<p>Confirmez maintenant la création de l'utilisateur et les privilèges du nouvel utilisateur :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SELECT host, user, Super_priv FROM mysql.user;\n</li></ul></code></pre>\n<p>Vous verrez un résultat similaire à ce qui suit :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+-----------+-------+------------+\n| Host      | User  | Super_priv |\n+-----------+-------+------------+\n| localhost | root  | Y          |\n| localhost | mysql | Y          |\n| %         | <span class=\"highlight\">sammy</span> | <span class=\"highlight\">Y</span>          |\n+-----------+-------+------------+\n3 rows in set (0.001 sec)\n</code></pre>\n<p>Maintenant videz les privilèges pour appliquer tous les changements :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">FLUSH PRIVILEGES;\n</li></ul></code></pre>\n<p>Une fois que vous avez terminé, quittez la session :</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">exit\n</li></ul></code></pre>\n<p>Maintenant que vous avez créé un utilisateur de la base de données, il ne vous reste plus qu'à régler MariaDB pour vous assurer le fonctionnement correct d’ERPNext 12. Heureusement, l'équipe ERPNext fournit un excellent modèle de configuration que vous utiliserez comme point de départ pour votre implémentation. Dans la section suivante, vous apprendrez à configurer correctement la base de données MariaDB en utilisant ce modèle.</p>\n\n<h2 id=\"Étape 4-—-configuration-de-mariadb-pour-erpnext\">Étape 4 — Configuration de MariaDB pour ERPNext</h2>\n\n<p>Une fois MariaDB installé et sécurisé, il est temps de le mettre au point pour les connexions ERPNext.</p>\n\n<p>Tout d'abord, arrêtez <code>mariadb.service</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop mariadb\n</li></ul></code></pre>\n<p>Utilisez maintenant <code>nano</code> ou votre éditeur de texte préféré pour créer un fichier de configuration MariaDB appelé <code>settings.cnf</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/conf.d/settings.cnf\n</li></ul></code></pre>\n<p>Ajoutez maintenant le modèle de configuration d'ERPNext :</p>\n<div class=\"code-label \" title=\"/etc/mysql/conf.d/settings.cnf\">/etc/mysql/conf.d/settings.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\n\n# GENERAL #\nuser                           = mysql\ndefault-storage-engine         = InnoDB\nsocket                         = /var/lib/mysql/mysql.sock\npid-file                       = /var/lib/mysql/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n# SAFETY #\nmax-allowed-packet             = 256M\nmax-connect-errors             = 1000000\ninnodb                         = FORCE\n\n# DATA STORAGE #\ndatadir                        = /var/lib/mysql/\n\n# BINARY LOGGING #\nlog-bin                        = /var/lib/mysql/mysql-bin\nexpire-logs-days               = 14\nsync-binlog                    = 1\n\n# REPLICATION #\nserver-id                      = 1\n\n# CACHES AND LIMITS #\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\nquery-cache-type               = 0\nquery-cache-size               = 0\nmax-connections                = 500\nthread-cache-size              = 50\nopen-files-limit               = 65535\ntable-definition-cache         = 4096\ntable-open-cache               = 10240\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\ninnodb-log-file-size           = 512M\ninnodb-flush-log-at-trx-commit = 1\ninnodb-file-per-table          = 1\ninnodb-buffer-pool-size        = 5462M\ninnodb-file-format             = barracuda\ninnodb-large-prefix            = 1\ncollation-server               = utf8mb4_unicode_ci\ncharacter-set-server           = utf8mb4\ncharacter-set-client-handshake = FALSE\nmax_allowed_packet             = 256M\n\n# LOGGING #\nlog-error                      = /var/lib/mysql/mysql-error.log\nlog-queries-not-using-indexes  = 0\nslow-query-log                 = 1\nslow-query-log-file            = /var/lib/mysql/mysql-slow.log\n\n[mysql]\ndefault-character-set = utf8mb4\n\n[mysqldump]\nmax_allowed_packet=256M\n\n!includedir /etc/mysql/mariadb.conf.d/\n</code></pre>\n<p>Enregistrez et fermez le fichier. Pour obtenir des informations plus détaillées sur ces configurations, <a href=\"https://github.com/frappe/erpnext/wiki/MySQL-configuration-file\">consultez ce fichier modèle sur le référentiel Github d'ERPNext</a>. C'est un point de départ utile pour explorer ces options.</p>\n\n<p>Ensuite, créez un autre fichier appelé <code>erpnext.cnf</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/mariadb.conf.d/erpnext.cnf\n</li></ul></code></pre>\n<p>Ajoutez le contenu suivant au fichier :</p>\n<div class=\"code-label \" title=\"/etc/mysql/mariadb.conf.d/erpnext.cnf\">/etc/mysql/mariadb.conf.d/erpnext.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nbind-address    = 0.0.0.0\n</code></pre>\n<p>Le premier fichier,<code>/etc/mysql/conf.d/settings.cnf</code>, complète et remplace également quelques valeurs incluses dans la configuration par défaut de MariaDB située dans <code>/etc/mysql/my.cnf</code>. Ce fichier vous donne un modèle de conservation qui améliore considérablement les performances de la base de données pour ERPNext. N'oubliez pas toutefois que si ce modèle est un excellent point de départ, rien ne vous empêche d'améliorer encore plus les performances de MariaDB en ajustant ces paramètres à vos besoins.</p>\n\n<p>Le deuxième fichier, <code>/etc/mysql/mariadb.conf.d/erpnext.cnf</code>, permet également de remplacer certaines valeurs par des informations spécifiques concernant la connexion à votre base de données.</p>\n\n<h3 id=\"test-de-la-connexion-mariadb\">Test de la connexion MariaDB</h3>\n\n<p>Comme ERPNext dépend de la connexion à la base de données pour presque toutes ses opérations internes, il est bon de tester la connexion avant de continuer.</p>\n\n<p>Démarrez <code>mariadb.service</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mariadb\n</li></ul></code></pre>\n<p>Pour tester la connexion, vous pouvez utiliser la commande suivante. N'oubliez pas de remplacer <code><span class=\"highlight\">sammy</span></code> et <code><span class=\"highlight\">mariadb_password</span></code> par vos propres identifiants :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mysql --user <span class=\"highlight\">sammy</span> --password <span class=\"highlight\">mariadb_password</span> --host=localhost --protocol=tcp --port=3306 test\n</li></ul></code></pre>\n<p>Vous verrez un résultat montrant le contenu de l'aide de base de MariaDB et plusieurs paramètres. Cela signifie que votre connexion a réussi :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>mysql  Ver 15.1 Distrib 10.4.13-MariaDB, for debian-linux-gnu (x86_64) using readline 5.2\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nUsage: mysql [OPTIONS] [database]\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\n\n...\n\n  --ssl-verify-server-cert\n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n\n...\n\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\nbinary-mode                       FALSE\nconnect-expired-password          FALSE\n</code></pre>\n<p>Si vous devez apporter des ajustements aux paramètres de MariaDB ou corriger des erreurs, n'oubliez pas de recharger le service en utilisant la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mariadb\n</li></ul></code></pre>\n<p>Une fois que vous avez terminé, activez MariaDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mariadb\n</li></ul></code></pre>\n<p>Maintenant que vous avez testé la connexion à la base de données, vous pouvez continuer à installer votre application ERPNext.</p>\n\n<h2 id=\"Étape 5-—-configuration-erpnext-12\">Étape 5 — Configuration ERPNext 12</h2>\n\n<p>Maintenant que le backend de votre  base de données est prêt, vous pouvez continuer à configurer votre application web ERPNext. Dans cette section, vous apprendrez à installer et configurer tous les composants requis par ERPNext 12, puis à installer l'application elle-même.</p>\n\n<p>Commencez par préparer le serveur avec tous les paquets système requis par ERPNext 12. Installez les dépendances dans tout le système en utilisant la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo DEBIAN_FRONTEND=noninteractive apt install -y curl build-essential mariadb-client python3-setuptools python3-dev libffi-dev python3-pip libcurl4 dnsmasq fontconfig git htop libcrypto++-dev libfreetype6-dev liblcms2-dev libwebp-dev libxext6 libxrender1 libxslt1-dev libxslt1.1 libffi-dev ntpdate postfix python3-dev python-tk screen vim xfonts-75dpi xfonts-base zlib1g-dev apt-transport-https libsasl2-dev libldap2-dev libcups2-dev pv libjpeg8-dev libtiff5-dev tcl8.6-dev tk8.6-dev libssl1.0-dev python3-mysqldb libdate-manip-perl logwatch\n</li></ul></code></pre>\n<p>La variable <code>DEBIAN_FRONTEND=noninteractive</code> a été transmise à la commande d'installation afin d'éviter les invites Postfix. Pour obtenir des informations détaillées sur la configuration de Postfix, lisez notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-postfix-on-ubuntu-18-04\">Comment installer et configurer Postfix sur Ubuntu 18.04</a></p>\n\n<p>Ensuite, mettez à jour <code>pip3</code> et installez les dernières versions de trois modules Python supplémentaires requis par ERPNext :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo -H python3 -m pip install --upgrade setuptools cryptography psutil\n</li></ul></code></pre>\n<p>Maintenant que vous avez installé toutes les dépendances générales nécessaires, vous allez installer tous les services et les bibliothèques nécessaires à ERPNext 12.</p>\n\n<h3 id=\"configuration-de-node-js-et-yarn\">Configuration de Node.js et Yarn</h3>\n\n<p>ERPNext 12 peut fonctionner avec la version 8+ de l'environnement serveur Node.js. En réalité, au moment de la rédaction de ce texte, le script officiel <code>easy_install</code> d'ERPNext utilise Node 8. Mais du point de vue de la sécurité, il est conseillé d'installer une version plus récente, car Node 8 a atteint sa fin de vie (EOL) en 2020 et ne bénéficiera donc plus de correctifs de sécurité. Pour les besoins de ce guide, la version 12 LTS de Node.js sera installée en même temps que les gestionnaires de paquets <code>npm</code> et <code>yarn</code> correspondants. Veuillez noter que le framework Frappe utilise <code>yarn</code> pour installer les dépendances. Si vous décidez d'utiliser une autre méthode d'installation, vérifiez que la version 1.12+ de <code>yarn</code> fonctionne sur votre système.</p>\n\n<p>Ajoutez le référentiel NodeSource à votre système :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -sL https://deb.nodesource.com/setup_12.x -o nodesource_setup.sh\n</li></ul></code></pre>\n<p>Vous pouvez maintenant inspecter le contenu du script téléchargé :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano nodesurce_setup.sh\n</li></ul></code></pre>\n<p>Une fois que vous êtes satisfait, vous pouvez exécuter le script :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bash nodesource_setup.sh\n</li></ul></code></pre>\n<p>Ce script mettra à jour automatiquement la liste <code>apt</code>. Vous pouvez maintenant installer <code>nodejs</code> sur votre serveur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install nodejs\n</li></ul></code></pre>\n<p>Ensuite, installez <code>yarn</code> globalement en utilisant le paquet <code>npm</code> inclus :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo npm install -g yarn\n</li></ul></code></pre>\n<p>Maintenant que vous avez installé Node, vous pouvez continuer à configurer <code>wkhtmltopdf</code> pour votre plate-forme.</p>\n\n<p>ERPNext utilise l'outil open source <code>wkhtmltopdf</code> pour convertir le contenu HTML en PDF, en utilisant le moteur de rendu Qt WebKit. Cette fonction est principalement utilisée pour l'impression de factures, de devis et d'autres rapports. Dans le cas d'ERPNext 12, une version spécifique de <code>wkhtmltopdf</code> est requise, <code>0.12.5</code> avec Qt patché.</p>\n\n<p>Pour installer <code>wkhtmltopdf</code>, commencez par passer à un répertoire approprié pour télécharger le paquet, dans ce cas <code>/tmp</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /tmp\n</li></ul></code></pre>\n<p>Téléchargez la version <code>wkhtmltopdf</code> appropriée et le paquet pour Ubuntu 18.04 depuis la page du projet :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.5/wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Installez maintenant le paquet en utilisant l'outil <code>dpkg</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo dpkg -i wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Ensuite, copiez tous les exécutables pertinents dans votre répertoire <code>/usr/bin/</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /usr/local/bin/wkhtmlto* /usr/bin/\n</li></ul></code></pre>\n<p>Une fois les fichiers en place, modifiez leurs autorisations pour les rendre exécutables :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod a+x /usr/bin/wk*\n</li></ul></code></pre>\n<p>Maintenant que <code>wkhtmltopdf</code> est correctement installé, nous ajouterons Redis à notre pile de base de données.</p>\n\n<h3 id=\"installation-de-redis\">Installation de Redis</h3>\n\n<p>ERPNext 12 utilise Redis pour améliorer les performances de MariaDB. Plus précisément, <a href=\"https://discuss.erpnext.com/t/why-erpnext-need-redis/6194\">il aide à la mise en cache</a>.</p>\n\n<p>Tout d'abord, installez Redis depuis le référentiel officiel Ubuntu 18.04 :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install redis-server\n</li></ul></code></pre>\n<p>Ensuite, activez Redis au démarrage :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable redis-server\n</li></ul></code></pre>\n<p>Maintenant que vous avez ajouté Redis à votre pile, prenons un moment pour résumer ce que vous avez accompli jusqu'à présent. Jusqu'à présent, vous avez installé tous les principaux composants nécessaires à ERPNext 12, dont :</p>\n\n<ul>\n<li>Un backend de base de données MariaDB</li>\n<li>L'environnement serveur JavaScript Node.js</li>\n<li>Le gestionnaire de paquets Yarn</li>\n<li>Un cache de la base de donnée de Redis</li>\n<li>Le générateur de documents PDF <code>wkhtmltopdf</code></li>\n</ul>\n\n<p>Que vous installiez le système ERP pour le développement ou pour la production, vous êtes maintenant prêt pour la prochaine étape, qui consiste à installer le framework full-stack Frappe et l'application web ERPNext 12 actuelle.</p>\n\n<h2 id=\"Étape 6-—-configuration-de-l-39-ilc-bench-de-frappe\">Étape 6 — Configuration de l'ILC Bench de Frappe</h2>\n\n<p>Maintenant que vous avez mis en place toutes les exigences de pile d'ERPNext, vous pouvez exploiter la flexibilité de l'utilitaire de ligne de commande <code>bench</code> de Frappe. L'ILC <code>bench</code> a été conçue dans le but d'aider les utilisateurs dans le processus d'installation, de mise en place et de gestion d'applications comme ERPNext, qui reposent sur le Framework Frappe. Dans les sections suivantes, vous allez installer l'ILC <code>bench</code> et l'utiliser ensuite pour terminer le processus de configuration d'ERPNext 12.</p>\n\n<p>Assurez-vous que l'utilisateur de Frappe (dans ce cas <code><span class=\"highlight\">sammy</span></code>) dispose des droits appropriés sur son répertoire <code>home</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chown <span class=\"highlight\">sammy</span> -R /home/<span class=\"highlight\">sammy</span>\n</li></ul></code></pre>\n<p>Maintenant, clonez le référentiel <code>frappe/bench</code> vers votre répertoire de base. N'oubliez pas de remplacer <code><span class=\"highlight\">sammy</span></code> par votre nom d'utilisateur système :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone https://github.com/frappe/bench /home/<span class=\"highlight\">sammy</span>/.bench --depth 1 --branch master\n</li></ul></code></pre>\n<p>Installez l'ILC <code>bench</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo pip3 install -e /home/<span class=\"highlight\">sammy</span>/.bench\n</li></ul></code></pre>\n<p>Ce guide suppose que vous installez ERPNext 12 pour des scénarios de test/production et que vous utilisez donc la branche <code>master</code>. Mais si votre intention est de développer des applications ou des modules ERPNext personnalisés, la branche <code>develop</code> pourrait être préférable. Dans les deux cas, vous êtes maintenant prêt à installer le Framework de Frappe. Ce sera la dernière étape avant d'installer ERPNext lui-même.</p>\n\n<h3 id=\"configuration-de-l-39-environnement-du-framework-de-frappe\">Configuration de l'environnement du framework de Frappe</h3>\n\n<p>Dans cette section, vous allez créer un <a href=\"https://frappe.io/docs/user/en/architecture\">environnement Frappe</a> en utilisant l'ILC <code>bench</code>.</p>\n\n<p>Pendant l'installation de Frappe, vous pouvez dépasser la limite de surveillance des fichier d'Ubuntu, qui par défaut est fixée à 8192. Pour éviter ce problème, définissez une limite supérieure en utilisant la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p\n</li></ul></code></pre>\n<p>Ensuite, initialisez Frappe framework 12. Remplacez Sammy par votre nom d'utilisateur système :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench init /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> --frappe-path https://github.com/frappe/frappe --frappe-branch version-12 --python python3\n</li></ul></code></pre>\n<p>Au cours de l'exécution, vous pouvez voir une erreur concernant votre chemin d'accès, ainsi que plusieurs avertissements. Laissez le processus se poursuivre jusqu'à la fin. Une fois terminé, vous verrez un résultat similaire à celui qui suit, indiquant que votre environnement a été créé avec succès :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nDone in 82.23s.\nINFO:bench.utils:setting up backups\nno crontab for <span class=\"highlight\">sammy</span>\nSUCCESS: Bench /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> initialized\n</code></pre>\n<p><span class='note'><strong>Note :</strong> le processus <code>bench init</code> pourrait s'arrêter si une erreur <code>spawn ENOMEM</code> était rencontrée. Cette erreur se produit lorsque votre système manque de mémoire. Vous devez corriger le problème avant de continuer, soit en installant plus de mémoire physique, soit en attribuant l'espace SWAP.<br></span></p>\n\n<p>Examinons de plus près la commande utilisée pour créer l'environnement :</p>\n\n<ul>\n<li><code>/home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span></code> est le chemin où le framework Frappe, les sites web et les applications connexes seront installés. Un nouveau répertoire, appelé <code><span class=\"highlight\">frappe-bench</span></code> dans cet exemple, sera créé pour accueillir tous les fichiers nécessaires.</li>\n<li><code>--frappe-path</code> pointe vers le référentiel de Frappe, qui dans ce cas est le référentiel officiel de Github.</li>\n<li><code>--frappe-branch</code> est la version Frappe à installer. Comme vous souhaitez installer ERPNext 12, la version choisie est Frappe 12.</li>\n<li><code>--python</code> est la version Python qui sera utilisée. ERPNext 12 requiert Python 3.6+. Les versions antérieures, cependant, utilisent toujours Python 2.7.</li>\n</ul>\n\n<p>Pour plus d'informations sur les commandes ILC <code>bench</code>, veuillez vous référer à la <a href=\"https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html\">fiche d'aide des commandes de Bench.</a></p>\n\n<p>La flexibilité offerte par le framework Frappe va bien au-delà de l'utilisation d'environnements isolés. Vous pouvez également créer différents sites web et y installer des applications.</p>\n\n<h2 id=\"Étape 7-—-configuration-de-l-39-application-web-erpnext 12\">Étape 7 — Configuration de l'application web ERPNext 12</h2>\n\n<p>Dans cette section, vous allez configurer un site reposant sur Frappe, puis installer l'application ERPNext 12 sur celui-ci.</p>\n\n<p>Passez dans le répertoire où Frappe a été initialisé.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Maintenant, téléchargez ERPNext 12 depuis son référentiel en utilisant l'ILC <code>bench</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench get-app erpnext https://github.com/frappe/erpnext --branch version-12\n</li></ul></code></pre>\n<p>Ensuite, créez le nouveau site, en remplaçant <code><span class=\"highlight\">your_domain</span></code> par le domaine que vous avez associé à l'IP de ce serveur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench new-site <span class=\"highlight\">your_domain</span> --admin-password '<span class=\"highlight\">erpnext_admin_password</span>' --mariadb-root-username <span class=\"highlight\">sammy</span> --mariadb-root-password '<span class=\"highlight\">mariadb_password</span>'\n</li></ul></code></pre>\n<p>Prenons un moment pour examiner les options utilisées dans la commande ci-dessus :</p>\n\n<ul>\n<li><code>bench new-site</code> crée un nouveau site reposant sur le framework Frappe.</li>\n<li><code><span class=\"highlight\">your_domain</span></code> est le nom du nouveau site. Assurez-vous que le DNS de votre domaine a un enregistrement A pointant vers l'IP de votre serveur.</li>\n<li><code><span class=\"highlight\">erpnext_admin_password</span></code>est le mot de passe souhaité pour l'utilisateur <strong>Administrator</strong> d'ERPNext. Conservez ce mot de passe dans un endroit sûr, vous en aurez besoin sous peu.</li>\n<li><code><span class=\"highlight\">mariadb_password</span></code> est le mot de passe que vous avez créé au début du guide de l'utilisateur <code><span class=\"highlight\">sammy</span></code> de MariaDB.</li>\n</ul>\n\n<p>Ensuite, installez l'application ERPNext sur le site :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench --site <span class=\"highlight\">your_domain</span> install-app erpnext\n</li></ul></code></pre>\n<p>Une fois l'installation terminée, vous disposerez d'une application ERPNext 12 fonctionnelle. Maintenant, testons-la à l'aide d'une commande <code>bench</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench start\n</li></ul></code></pre>\n<p>La commande ci-dessus lancera une console de surveillance en temps réel vous montrant divers messages concernant le serveur web et d'autres services. Ouvrez un navigateur web et naviguez vers <code>localhost:8000</code> (pour les installations locales) ou <code><span class=\"highlight\">your_domain</span>:8000</code> (si vous utilisez un serveur distant). Vous verrez l'écran de connexion ERPNext (nous procéderons à la connexion et à la configuration dans une étape ultérieure, une fois que notre site sera prêt pour la production).</p>\n\n<p>Après avoir consulté votre déploiement de test, retournez à votre terminal et appuyez sur <code>CTRL+C</code>. Cela arrêtera ERPNext et permettra de quitter la console de surveillance.</p>\n\n<p>Si votre objectif principal est de créer des modules ou de modifier ERPNext 12, vous pouvez alors vous arrêter à ce stade. Aucun autre composant n'est nécessaire pour le développement. Cependant, si vous avez besoin d'un système prêt pour la production qui ne requiert pas d'initialisation manuelle, vous devrez alors installer et configurer quelques composants supplémentaires. C'est votre prochaine étape.</p>\n\n<h2 id=\"Étape 8-—-configuration-d-39-erpnext 12-pour-la-production\">Étape 8 — Configuration d'ERPNext 12 pour la production</h2>\n\n<p>Bien que l'application ERPNext 12 soit prête, le système dans son ensemble n'est pas encore complètement prêt pour la production. Pour garantir la fiabilité et la sécurité d'ERPNext, vous devrez activer quelques services supplémentaires :</p>\n\n<ul>\n<li><strong>Fail2ban</strong> fournit une couche supplémentaire de protection contre les tentatives de recours abusif des utilisateurs et des bots malveillants.</li>\n<li><strong>Nginx</strong> fonctionne principalement comme un proxy web, redirigeant tout le trafic depuis le port <code>8000</code> vers le port <code>80</code> (HTTP) ou le port <code>443</code> (HTTPS)</li>\n<li><strong>Supervisor</strong> veille à ce que les processus clés d'ERPNext soient constamment opérationnels, en les redémarrant au besoin.</li>\n</ul>\n\n<p>Jusqu'à ce stade, vous avez installé et configuré manuellement ERPNext 12, ce qui vous a permis de personnaliser le processus pour qu'il corresponde à n'importe quel cas d'utilisation particulier. Néanmoins, pour le reste de la configuration de la production, vous pouvez tirer parti de la commodité de l'ILC <code>bench</code>, afin d'automatiser l'installation et la configuration de ces services restants.</p>\n\n<p>Assurez-vous que vous êtes bien dans le répertoire de travail de Frappe :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Maintenant, utilisez la commande suivante pour terminer la configuration d'ERPNext 12 pour la production :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bench setup production <span class=\"highlight\">sammy</span> --yes\n</li></ul></code></pre>\n<p>La commande ci-dessus installera et configurera aNginx, Supervisor, et Fail2Ban, et définira <code><span class=\"highlight\">sammy</span></code> comme propriétaire de l'environnement de production.</p>\n\n<p>Les fichiers de configuration créés par la commande <code>bench</code>  sont les suivants :</p>\n\n<ul>\n<li>Deux fichiers de configuration Nginx situés dans <code>/etc/nginx/nginx.conf</code> et <code>/etc/nginx/conf.d/<span class=\"highlight\">frappe-bench</span>.conf</code></li>\n<li>Un proxy jail Fail2Ban situé dans <code>/etc/fail2ban/jail.d/nginx-proxy.conf</code> et un filtre situé dans <code>/etc/fail2ban/filter.d/nginx-proxy.conf</code></li>\n</ul>\n\n<p>Ces configurations par défaut suffiront pour ce tutoriel, mais n'hésitez pas à explorer et ajuster ces fichiers pour qu'ils correspondent à vos besoins. Vous pouvez arrêter tous les services en exécutant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl stop all\n</li></ul></code></pre>\n<p>Et ensuite, une fois que vous êtes prêt, vous pouvez redémarrer vos services :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl start all\n</li></ul></code></pre>\n<p>Maintenant vous êtes prêt pour tester votre installation.</p>\n\n<h3 id=\"test-de-votre-installation-erpnext 12\">Test de votre installation ERPNext 12</h3>\n\n<p>Tout d'abord, vérifiez que les principaux services de production fonctionnent en utilisant la commande <code>systemctl</code> suivante, puis en la transmettant à <code>grep</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">systemctl list-unit-files | grep 'fail2ban\\|nginx\\|supervisor'\n</li></ul></code></pre>\n<p>Vous verrez un résultat similaire à ce qui suit :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>fail2ban.service                       enabled\nnginx.service                          enabled\nsupervisor.service                     enabled\n</code></pre>\n<p>Après avoir confirmé que tout fonctionne comme prévu, vous pouvez tester ERPNext 12 en direct sur votre serveur. Ouvrez votre navigateur préféré et naviguez jusqu'au domaine où vous hébergez votre application ERPNext 12.</p>\n\n<p>Après quelques secondes, vous devriez voir l'écran de connexion d'ERPNext 12. Utilisez <strong>Administrator</strong> pour le nom d'utilisateur et <code><span class=\"highlight\">erpnext_admin_password</span></code> que vous avez créé précédemment pour le mot de passe.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_1.png\" alt=\"Écran de connexion d'ERPNext\"></p>\n\n<p>Dans l'écran suivant, vous verrez un menu déroulant où vous pouvez sélectionner la langue de l'interface utilisateur pour l'application :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_2.png\" alt=\"Sélection de la langue\"></p>\n\n<p>Après la sélection de la langue, ERPNext vous demandera d'entrer votre pays, votre fuseau horaire et votre devise :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_3.png\" alt=\"Sélectionnez votre région\"></p>\n\n<p>Une fois que vous aurez complété les informations sur votre région, vous pourrez créer le premier utilisateur ERPNext. Les informations que vous fournissez seront utilisées comme identifiants de connexion de l'utilisateur.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_4.png\" alt=\"Premier utilisateur ERPNext\"></p>\n\n<p>Dans l'écran suivant, vous serez questionné sur ce qu’ERPNext appelle <strong>Domains</strong>. Si vous n'êtes pas sûr de savoir quel est votre domaine, sélectionnez <strong>Distribution</strong> et cliquez sur le bouton <strong>Next</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_5.png\" alt=\"Sélectionnez vos domaines\"></p>\n\n<p>Ensuite, vous devrez fournir un nom de société et une abréviation.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_6.png\" alt=\"Nom de la société\"></p>\n\n<p>Dans le dernier écran, ERPNext vous demandera d'indiquer l'activité de votre société, le nom de sa banque, le type de plan comptable et la période de l'exercice. Vous pourrez entrer des banques supplémentaires plus tard. Pour l'instant, remplissez tous les champs comme vous le souhaitez, puis cliquez sur le bouton <strong>Complete Setup</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_7.png\" alt=\"Informations financières\"></p>\n\n<p>Ensuite, vous verrez un barre de progression.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_8.png\" alt=\"Configuration d'ERPNext\"></p>\n\n<p>Une fois le processus de configuration terminé, le tableau de bord principal d'ERPNext 12 apparaît.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_9.png\" alt=\"Tableau de bord d'ERPNext 12\"></p>\n\n<p>Vous avez maintenant entièrement installé et configuré une application ERPNext 12.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Maintenant que vous avez correctement installé votre application ERPNext 12, vous pouvez commencer à mettre en œuvre le système pour vos besoins commerciaux. Un bon point de départ consiste à cliquer sur le bouton <strong>Getting Started</strong> sur le tableau de bord d'ERPNext. ERPNext vous aidera alors à configurer la plate-forme pour tous vos besoins commerciaux et de commerce électronique.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_10.png\" alt=\"Mise en route\"></p>\n\n<p>Vous pouvez également souhaiter améliorer la vitesse d'ERPNext. Si c'est le cas, vous pouvez lire <a href=\"https://github.com/frappe/erpnext/wiki/ERPNext-Performance-Tuning\">les informations sur le réglage de performance ERPNext</a>, qui vous guideront sur les meilleures pratiques et sur la manière de résoudre les problèmes liés aux performances.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:27 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67031/erpnext_0.png","linkMd5":"0eab903a325a6b0b5cf420e264649d5b","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","destWidth":3584,"destHeight":2022,"sourceBytes":966173,"destBytes":375664,"author":"Damaso Sanoja","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67031/erpnext_0.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","https://assets.digitalocean.com/articles/67031/erpnext_1.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_3/2020/08/31/07-48-32-714_e6b982f1d7fe90cd.webp","https://assets.digitalocean.com/articles/67031/erpnext_2.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn94@2020_6/2020/08/31/07-48-32-235_5dfe5b1d282ec7f1.webp","https://assets.digitalocean.com/articles/67031/erpnext_3.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_3/2020/08/31/07-48-31-862_07721efc54737d85.webp","https://assets.digitalocean.com/articles/67031/erpnext_4.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn45@2020_1/2020/08/31/07-48-32-664_c2f620996c337847.webp","https://assets.digitalocean.com/articles/67031/erpnext_5.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn13@2020_2/2020/08/31/07-48-33-137_5b1867188f4eb783.webp","https://assets.digitalocean.com/articles/67031/erpnext_6.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn25@2020_3/2020/08/31/07-48-31-288_1f4bd367e3868d6d.webp","https://assets.digitalocean.com/articles/67031/erpnext_7.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn14@2020_2/2020/08/31/07-48-31-596_2e4f2cf158e027fc.webp","https://assets.digitalocean.com/articles/67031/erpnext_8.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn65@2020_2/2020/08/31/07-48-31-323_2f22aaf79a58e762.webp","https://assets.digitalocean.com/articles/67031/erpnext_9.png":null,"https://assets.digitalocean.com/articles/67031/erpnext_10.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn97@2020_3/2020/08/31/07-48-32-254_dccc24f52c8f5d64.webp"},"publishedOrCreatedDate":1598860106981},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Установка TensorFlow в Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-tensorflow-on-ubuntu-20-04-ru","description":"<h3 id=\"Введение\">Введение</h3>\n\n<p>Программная библиотека машинного обучения <a href=\"https://www.tensorflow.org/\">TensorFlow</a> с открытым исходным кодом используется для обучения нейросетей. Каждый узел графика отражает операции, выполняемые нейросетями в многомерных массивах, в форме <a href=\"https://www.tensorflow.org/programmers_guide/graphs\">графиков потока данных с сохранением состояния</a>. Эти многомерные массивы часто называют тензорами, и отсюда идет название библиотеки TensorFlow.</p>\n\n<p>В этом обучающем модуле мы выполним установку TensorFlow в виртуальной среде Python с помощью <code>virtualenv</code>. Этот подход изолирует установку TensorFlow и позволяет быстро начать работу. После завершения установки вы сможете проверить ее посредством импорта Tensorflow, чтобы убедиться в отсутствии ошибок.</p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для прохождения этого обучающего модуля вам потребуется следующее:</p>\n\n<ul>\n<li><p>Один сервер Ubuntu 20.04 с не менее <strong>4 Гбайт оперативной памяти</strong>, настроенный в соответствии с <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">руководством по начальной настройке сервера Ubuntu 20.0</a>4, включая пользователя без прав root с привилегиями sudo и брандмауэр.</p></li>\n<li><p>Python версии 3.8 или выше с установленной средорй <code>virtualenv</code>. Следуйте <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-programming-environment-on-an-ubuntu-20-04-server\">указаниям руководства по установке Python 3 в Ubuntu 20.04</a> для настройки Python и <code>virtualenv</code>.</p></li>\n</ul>\n\n<h2 id=\"Шаг-1-—-Создание-среды-программирования\">Шаг 1 — Создание среды программирования</h2>\n\n<p>На этом шаге мы создадим виртуальную среду для установки в нее TensorFlow без ущерба для других проектов программирования. Если у вас уже имеется готовая настроенная среда программирования, вы можете пропустить этот шаг.</p>\n\n<p>Для начала создайте каталог проекта. Для демонстрационных целей мы присвоим ему имя <code>tf-demo</code>, но вы можете выбрать другое имя каталога, имеющее для вас значение:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Перейдите в созданный каталог <code>tf-demo</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Затем создайте новую виртуальную среду с именем <code>tensorflow-dev</code> или другим похожим именем. Запустите следующую команду для создания среды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python3 -m venv <span class=\"highlight\">tensorflow-dev</span>\n</li></ul></code></pre>\n<p>Эта команда создает новый каталог <code>tensorflow-dev</code>, который будет содержать все пакеты, устанавливаемые в период активации этой среды. Также он содержит <code>pip</code> и отдельную версию Python.</p>\n\n<p>Активируйте вашу виртуальную среду:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">source <span class=\"highlight\">tensorflow-dev</span>/bin/activate\n</li></ul></code></pre>\n<p>После активации в командной строке терминала будет показано, что вы находитесь в виртуальной среде:</p>\n<pre class=\"code-pre \"><code>(<span class=\"highlight\">tensorflow-dev</span>)username@hostname:~/tf-demo $\n</code></pre>\n<p>Теперь вы можете установить TensorFlow в вашей виртуальной среде.</p>\n\n<h2 id=\"Шаг-2-—-Установка-tensorflow\">Шаг 2 — Установка TensorFlow</h2>\n\n<p>При установке TensorFlow нужно убедиться, что мы выполняем установку и обновление до самой новой версии, доступной в <a href=\"https://pypi.python.org/pypi\">PyPi</a>.</p>\n\n<p>Поэтому мы будем использовать следующий синтаксис команды pip:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">pip install --upgrade tensorflow\n</li></ul></code></pre>\n<p>После нажатия <code>ENTER</code> TensorFlow выполнит установку, и вы получите вывод, указывающий, что установка со всеми зависимыми пакетами была успешно выполнена.</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nSuccessfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 numpy-1.16.2 pbr-5.1.3 protobuf-3.7.0 setuptools-40.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.0 wheel-0.33.1\n...\n\nSuccessfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 markdown-2.6.9 numpy-1.13.3 protobuf-3.5.0.post1 setuptools-38.2.3 six-1.11.0 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0rc3 werkzeug-0.12.2 wheel-0.30.0\n</code></pre>\n<span class='note'><p>\nВы можете отключить виртуальную среду в любое время с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">deactivate\n</li></ul></code></pre>\n<p>Чтобы повторно активировать среду позднее, перейдите в каталог проекта и запустите команду <code>source <span class=\"highlight\">tensorflow-dev</span>/bin/activate</code>.<br></p></span>\n\n<p>Мы установили TensorFlow, а теперь проверим работу установленной версии TensorFlow.</p>\n\n<h2 id=\"Шаг-3-—-Проверка-установки\">Шаг 3 — Проверка установки</h2>\n\n<p>Чтобы проверить установку TensorFlow, мы проверим возможность импортирования пакета TensorFlow.</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">python\n</li></ul></code></pre>\n<p>На вашем терминале появится следующая командная строка:</p>\n<pre class=\"code-pre \"><code>&gt;&gt;&gt;\n</code></pre>\n<p>Это командная строка для интерпретатора Python, указывающая, что вы можете начать ввод некоторых выражений Python.</p>\n\n<p>Для начала введите эту строку, чтобы импортировать пакет TensorFlow и сделать его доступным как локальную переменную <code>tf</code>. Нажмите <code>ENTER</code> после ввода строки кода:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;&gt;&gt;\">import tensorflow as tf\n</li></ul></code></pre>\n<p>Если вы не получите сообщений об ошибках, это означает, что вы успешно установили TensorFlow. Если получили сообщение об ошибке, проверьте, имеет ли ваш сервер достаточно ресурсов для работы TensorFlow. Возможно, вам потребуется увеличить объем ресурсов сервера и убедиться, что на нем есть не менее 4 Гбайт оперативной памяти.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>В этом обучающем модуле мы выполнили установку TensorFlow в виртуальной среде Python и проверили работу TensorFlow, выполнив импорт.</p>\n\n<p><a href=\"https://www.tensorflow.org/programmers_guide/\">Руководство программиста</a> по TensorFlow — это полезный ресурс и справочник для разработчиков, использующих TensorFlow. Также вы можете изучить конкурирующую среду <a href=\"https://www.kaggle.com/\">Kaggle</a> для практического применения концепций машинного обучения, чтобы получить преимущество перед другими энтузиастами машинного обучения, аналитики данных и статистики.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:29 +0000","feedId":8037,"bgimg":"","linkMd5":"80b6f830f9bb56ce329e6afea78ff201","bgimgJsdelivr":"","metaImg":"","author":"Lisa Tagliaferri","publishedOrCreatedDate":1598860106973},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment configurer un serveur VPN IKEv2 avec StrongSwan sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-an-ikev2-vpn-server-with-strongswan-on-ubuntu-20-04-fr","description":"<p><em>Une version précédente de ce tutoriel a été rédigée par <a href=\"https://www.digitalocean.com/community/users/jellingwood\">Justin Ellingwood</a> et <a href=\"https://www.digitalocean.com/community/users/namo\">Namo</a></em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Un réseau privé virtuel, ou VPN, vous permet de crypter en toute sécurité le trafic qui transite par des réseaux non fiables, comme ceux d'un coffee shop, d'une conférence ou d'un aéroport.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Internet_Key_Exchange\">Internet Key Exchange v2</a>, ou IKEv2, est un protocole qui permet de créer un tunnel IPSec direct entre le serveur et le client. Dans les implémentations VPN IKEv2, IPSec assure le cryptage du trafic réseau. IKEv2 est pris en charge en natif sur certaines plateformes (OS X 10.11+, iOS 9.1+ et Windows 10) sans aucune application supplémentaire, et il gère les problèmes clients de manière assez fluide.</p>\n\n<p>Dans ce tutoriel, vous allez configurer un serveur VPN IKEv2 en utilisant <a href=\"https://www.strongswan.org/\">StrongSwan</a> sur un serveur Ubuntu 20.04. Vous apprendrez ensuite comment vous y connecter avec les clients Windows, macOS, Ubuntu, iOS et Android.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour suivre ce tutoriel, vous aurez besoin de :</p>\n\n<ul>\n<li>Un serveur Ubuntu 20.04 configuré en suivant <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">le guide Configuration initiale de serveur Ubuntu 20.04</a>, comprenant un non-root user avec privilèges <code>sudo</code> et un pare-feu.</li>\n</ul>\n\n<h2 id=\"Étape-1-—-installation-de-strongswan\">Étape 1 — Installation de StrongSwan</h2>\n\n<p>Tout d'abord, nous allons installer StrongSwan, un démon iPSec open source que nous allons configurer en tant que serveur VPN. Nous allons également installer le composant infrastructure de clé publique (ICP) afin que nous puissions créer une autorité de certification (AC) pour fournir des identifiants pour notre infrastructure.</p>\n\n<p>Commencez par mettre à jour le cache local du paquets :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Ensuite, installez le logiciel en tapant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan strongswan-pki libcharon-extra-plugins libcharon-extauth-plugins\n</li></ul></code></pre>\n<p>Le paquet supplémentaire <code>libcharon-extauth-plugins</code> est utilisé pour vous assurer que divers clients puissent s'authentifier sur votre serveur à l'aide d'un nom d'utilisateur et d'une phrase de passe partagés.</p>\n\n<p>Maintenant que tout est installé, passons à la création de nos certificats.</p>\n\n<h2 id=\"Étape-2-—-création-d-39-une-autorité-de-certification\">Étape 2 — Création d'une autorité de certification</h2>\n\n<p>Un serveur IKEv2 requiert un certificat pour s'identifier auprès de ses clients. Pour vous aider à créer le certificat requis, le paquet <code>strongswan-pki</code> est livré avec un utilitaire appelé <code>pki</code> pour générer une autorité de certification et des certificats serveurs.</p>\n\n<p>Pour commencer, créons quelques répertoires pour stocker tous les actifs sur lesquels nous allons travailler. La structure du répertoire correspond à certains des répertoires dans <code>/etc/ipsec.d</code>, où nous allons déplacer tous les éléments que nous créons :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir -p ~/pki/{cacerts,certs,private}\n</li></ul></code></pre>\n<p>Ensuite, nous verrouillerons les autorisations afin que nos fichiers privés ne puissent pas être vus par d'autres utilisateurs :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod 700 ~/pki\n</li></ul></code></pre>\n<p>Maintenant que nous avons une structure de répertoire pour tout stocker, nous pouvons générer une clé racine. Il s'agira d'une clé RSA 4096-bit qui sera utilisée pour signer notre autorité de certification racine.</p>\n\n<p>Exécutez ces commandes pour générer la clé :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/ca-key.pem\n</li></ul></code></pre>\n<p>Ensuite, nous pouvons passer à la création de notre autorité de certification racine, en utilisant la clé que nous venons de générer pour signer le certificat racine :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --self --ca --lifetime 3650 --in ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">    --type rsa --dn \"CN=VPN root CA\" --outform pem &gt; ~/pki/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Le drapeau <code>--lifetime 3650</code> est utilisé pour garantir que le certificat racine de l'autorité de certification sera valable pour 10 ans. Le certificat root pour une autorité ne change généralement pas, puisqu'il doit être redistribué à chaque serveur et chaque client qui en dépend, de sorte que 10 ans est une valeur de d'expiration par défaut sûre.</p>\n\n<p>Vous pouvez changer la valeur du <em>nom distinctif</em> (DN) par autre chose si vous le souhaitez. Le nom commun (champ CN) n'est que l'indicateur, il n'a donc pas à correspondre à quoi que ce soit dans votre infrastructure.</p>\n\n<p>Maintenant que nous disposons d'une autorité de certification racine opérationnelle, nous pouvons créer un certificat que le serveur VPN utilisera.</p>\n\n<h2 id=\"Étape-3-—-génération-d-39-un-certificat-pour-le-serveur-vpn\">Étape 3 — Génération d'un certificat pour le serveur VPN</h2>\n\n<p>Nous allons maintenant créer un certificat et une clé pour le serveur VPN. Ce certificat permettra au client de vérifier l'authenticité du serveur à l'aide du certificat AC que nous venons de produire.</p>\n\n<p>Tout d'abord, créez une clé privée pour le serveur VPN avec la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/server-key.pem\n</li></ul></code></pre>\n<p>Maintenant, créez et signez le certificat serveur VPN avec la clé de l'autorité de certification que vous avez créée à l'étape précédente. Exécutez la commande suivante, mais changez le nom commun (CN) et le champ Subject Alternate Name (SAN) par le nom DNS ou à l'adresse IP de votre serveur VPN :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --pub --in ~/pki/private/server-key.pem --type rsa \\\n</li><li class=\"line\" data-prefix=\"$\">    | pki --issue --lifetime 1825 \\\n</li><li class=\"line\" data-prefix=\"$\">        --cacert ~/pki/cacerts/ca-cert.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --cakey ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --dn \"CN=<span class=\"highlight\">server_domain_or_IP</span>\" --san <span class=\"highlight\">server_domain_or_IP</span> \\\n</li><li class=\"line\" data-prefix=\"$\">        --flag serverAuth --flag ikeIntermediate --outform pem \\\n</li><li class=\"line\" data-prefix=\"$\">    &gt;  ~/pki/certs/server-cert.pem\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Remarque</strong> : si vous utilisez une adresse IP au lieu d'un nom DNS, vous devrez spécifier plusieurs entrées <code>--san</code>. La ligne dans le bloc de commande précédent où vous spécifiez le nom distinct (<code>--dn ...</code>) devra être modifiée avec l'entrée supplémentaire comme la ligne extraite suivante :</p>\n<pre class=\"code-pre \"><code>--dn \"CN=<span class=\"highlight\">IP address</span> --san @<span class=\"highlight\">IP_address</span> --san <span class=\"highlight\">IP_address</span> \\\n</code></pre>\n<p>La raison de cette entrée supplémentaire <code>--san @<span class=\"highlight\">IP_address</span></code> est que certains clients vérifieront si le certificat TLS comporte à la fois une entrée DNS et une entrée d'adresse IP pour un serveur lorsqu'ils vérifieront son identité.<br></p></span>\n\n<p>L'option <code>server -flag Auth</code> est utilisée pour indiquer que le certificat sera utilisé explicitement pour l'authentification du serveur, avant que le tunnel crypté ne soit établi. L'option <code>--flag ikeIntermediate</code> est utilisée pour soutenir les clients plus anciens de macOS.</p>\n\n<p>Maintenant que nous avons généré tous les fichiers TLS/SSL dont StrongSwan a besoin, nous pouvons déplacer les fichiers a leur place dans le répertoire <code>/etc/ipsec.d</code> en tapant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp -r ~/pki/* /etc/ipsec.d/\n</li></ul></code></pre>\n<p>Au cours de cette étape, nous avons créé une paire de certificats qui sera utilisée pour sécuriser les communications entre le client et le serveur. Nous avons également signé les certificats avec la clé AC, afin que le client puisse vérifier l'authenticité du serveur VPN à l'aide du certificat AC. Une fois tous ces certificats prêts, nous allons passer à la configuration du logiciel.</p>\n\n<h2 id=\"Étape-4-—-configuration-de-strongswan\">Étape 4 — Configuration de StrongSwan</h2>\n\n<p>StrongSwan dipose d'un fichier de configuration par défaut avec quelques exemples, mais nous allons devoir faire la plupart de la configuration nous-mêmes. Sauvegardons le fichier pour référence avant de repartir de zéro :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/ipsec.conf{,.original}\n</li></ul></code></pre>\n<p>Créez et ouvrez un nouveau fichier de configuration vide à l'aide de votre éditeur de texte préféré. Ici, nous utiliserons <code>nano</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Remarque</strong> : en parcourant cette section pour configurer la partie server de votre VPN, vous rencontrerez des paramètres qui font référence aux côtés gauche (<em>left</em>) et droit (<em>right</em>) d'une connexion. Lorsque vous travaillez avec les VPN d'IPSec, le côté <em>left</em> par convention fait référence au système local que vous configurez, dans ce cas le serveur. Les directives du côté droit de ces paramètres renverra à des clients distants comme des téléphones et autres ordinateurs.</p>\n\n<p>Lorsque vous passerez à la configuration des clients plus loin dans ce tutoriel, les fichiers de configuration du client se référeront à eux-mêmes en utilisant diverses directives <em>left</em>, et le serveur sera mentionné en utilisant la terminologie <em>right</em>.<br></p></span>\n\n<p>Tout d'abord, nous allons demander à StrongSwan d'enregistrer les états des démons pour le débogage et d'autoriser les connexions en double. Ajoutez ces lignes au fichier :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n</code></pre>\n<p>Ensuite, nous allons créer une section de configuration pour notre VPN. Nous allons également indiquer à StrongSwan de créer des tunnels VPN IKEv2 et de charger automatiquement cette section de configuration au démarrage. Ajoutez les lignes suivantes au fichier :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n</code></pre>\n<p>Nous allons également configurer la détection de dead-peer pour effacer les connexions &ldquo;en suspens&rdquo; au cas où le client se déconnecte de manière inattendue. Ajoutez ces lignes :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n</code></pre>\n<p>Ensuite, nous allons configurer les paramètres iPSec côté &ldquo;left&rdquo; du serveur. Chacun des paramètres suivants garantit que le serveur est configuré pour accepter les connexions des clients et pour s'identifier correctement. Vous ajouterez chacun de ces paramètres au fichier <code>/etc/ipsec.conf</code> une fois que vous serez familiarisé avec ce qu'ils sont et pourquoi ils sont utilisés :</p>\n\n<ul>\n<li><code>left=%any</code> La valeur <code>%any</code> garantit que le serveur utilisera l'interface réseau où il reçoit les connexions entrantes pour les communications ultérieures avec les clients. Par exemple, si vous connectez un client sur un réseau privé, le serveur utilisera l'adresse IP privée où il reçoit le trafic pour le reste de la connexion.</li>\n<li><code>leftid=<span class=\"highlight\">@server_domain_or_IP</span></code> Cette option contrôle le nom que le serveur présente aux clients. Combiné à l'option suivante <code>leftcert</code>, l'option <code>leftid</code> garantit que le nom configuré du serveur et le nom distinctif (DN) contenus dans le certificat public correspondent.</li>\n<li><code>leftcert=server-cert.pem</code> Cette option est le chemin d'accès au certificat public pour le serveur que vous avez configuré à l'Étape 3. Sans celui-ci, le serveur ne pourra pas s'authentifier lui-même aupr1es des clients, ou terminer de négocier la configuration d'IKEv2.</li>\n<li><code>leftsendcert=always</code> La valeur <code>always</code> garantit que tout client qui se connecte au serveur recevra toujours une copie du certificat public du serveur dans le cadre de la configuration initiale de la connexion.</li>\n<li><code>leftsubnet=0.0.0.0/0</code> La dernière option de côté &ldquo;left&rdquo; que vous ajouterez indique aux clients les sous réseaux qui sont accessibles derrière le serveur. Dans ce cas, <code>0.0.0.0/0</code> est utilisé pour représenter l'ensemble des adresses IPv4, ce qui signifie que le serveur indiquera aux clients d'envoyer tout leur trafic sur le VPN par défaut.</li>\n</ul>\n\n<p>Maintenant que vous êtes familiarisé avec chacune des options du côté &ldquo;left&rdquo;, ajoutez-les toutes dans le fichier, comme ceci :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n</code></pre>\n<span class='note'><p>\n<strong>Remarque</strong> : Lorsque vous configurez l'ID du serveur (<code>leftid</code>), n'incluez le caractère <code>@</code> que si votre serveur VPN sera identifié par un nom de domaine :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .    leftid=<span class=\"highlight\">@vpn.example.com</span>\n    . . .\n</code></pre>\n<p>Si le serveur doit être identifié par son adresse IP, ajoutez simplement l'adresse IP :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .\n    leftid=<span class=\"highlight\">your_server_ip</span>\n    . . .\n</code></pre>\n<p></p></span>\n\n<p>Ensuite, nous pouvons configurer les paramètres iPSec du côté &ldquo;right&rdquo; du client. Chacun des paramètres suivants indique au serveur comment accepter les connexions des clients, comment les clients devraient s'authentifier auprès du serveur, et les plages d'adresse IP privées et les serveurs DNS que les clients utiliseront. Ajoutez chacun de ces paramètres au fichier <code>/etc/ipsec.conf</code> une fois que vous êtes familiarisé avec ce qu'ils sont et pourquoi ils sont utilisés :</p>\n\n<ul>\n<li><code>right=%any</code> L'option <code>%any</code> pour le côté <code>right</code> de la connexion permet au serveur d'accepter les connexions entrantes d'un client distant.</li>\n<li><code>rightid=%any</code> Cette option garantit que le serveur ne rejettera pas les connexions des clients qui fournissent une identité avant que le tunnel crypté ne soit établi.</li>\n<li><code>rightauth=eap-mschapv2</code> Cette option configure la méthode d'authentification que les clients utiliseront pour s'authentifier sur le serveur. <code>eap</code>-mschapv2 est utilisé ici pour une large compatibilité pour prendre en charge des clients comme Windows, macOS et Android.</li>\n<li><code>rightsourceip=10.10.10.0/24</code> Cette option permet au serveur d'attribuer des adresses IP privées aux clients du pool d'IP <code>1</code>0.10.10.0/24 spécifié.</li>\n<li><code>rightdns=8.8.8.8,8.8.4.4</code> Ces adresses IP sont les résolveurs DNS publics de Google. Ils peuvent être modifiés pour utiliser d'autres paramètres publics, les résolveurs du serveur VPN ou tout autre résolveur que les clients peuvent atteindre.</li>\n<li><code>rightsendcert=never</code> Cette option indique au serveur que les clients n'ont pas à envoyer de certificat pour s'authentifier.</li>\n</ul>\n\n<p>Maintenant que vous êtes familiarisé avec les options du côté &ldquo;right&rdquo; nécessaires pour le VPN, ajoutez les lignes suivantes dans <code>/etc/ipsec.conf</code> :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n</code></pre>\n<p>Nous allons maintenant indiquer à StrongSwan de demander au client ses identifiants d'utilisateur lorsqu'ils se connectent :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    eap_identity=%identity\n</code></pre>\n<p>Enfin, ajoutez les lignes suivantes pour prendre en charge les clients Linux, Windows, macOS, iOS et Android. Ces lignes spécifient les différents algorithmes d'échange de clés, de hachage,d'authentification et de cryptage (communément appelés <em>Suites de chiffrement</em>) que StrongSwan permettra à différents clients d'utiliser :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Chaque suite de chiffrement prise en charge est délimitée des autres par une virgule. Par exemple, <code>chacha20poly1305-sha512-curve25519-prfsha512</code> est une suite, et <code>aes256gcm16-sha384-prfsha384-ecp384</code> est une autre. Les suites de chiffrement qui sont énumérées ici sont sélectionnées pour garantir la plus large compatibilité entre les clients Windows, macOS, iOS, Android et Linux.</p>\n\n<p>La configuration complète devrait ressembler à ceci :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n    eap_identity=%identity\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Sauvegardez et fermez le fichier une fois que vous avez vérifié que vous avez correctement ajouté chaque ligne. Si vous avez utilisé <code>nano</code>, faites-le en appuyant sur <code>CTRL+X</code>, <code>Y</code>, puis <code>ENTER</code>.</p>\n\n<p>Maintenant que nous avons configuré les paramètres VPN, passons à la création d'un compte afin que nos utilisateurs puissent se connecter au serveur.</p>\n\n<h2 id=\"Étape-5-—-configuration-de-l-39-authentification-vpn\">Étape 5 — Configuration de l'authentification VPN</h2>\n\n<p>Notre serveur VPN est maintenant configuré pour accepter les connexions client, mais nous n'avons pas encore configuré d'identifiants. Nous allons devoir configurer quelques éléments dans un fichier de configuration spécial appelé <code>ipsec.secrets</code> :</p>\n\n<ul>\n<li>Nous devons indiquer à StrongSwan où trouver la clé privée pour notre certificat de serveur, afin que le serveur puisse s'authentifier auprès de ses clients.</li>\n<li>Nous devons également mettre en place une liste d'utilisateurs qui seront autorisés à se connecter au VPN.</li>\n</ul>\n\n<p>Ouvrons le fichier secrets pour le modifier :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.secrets\n</li></ul></code></pre>\n<p>Tout d'abord, nous allons indiquer à StrongSwan où trouver notre clé privée :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code>: RSA \"server-key.pem\"\n</code></pre>\n<p>Ensuite, nous définirons les identifiants de l'utilisateur. Vous pouvez choisir toute combinaison de nom d'utilisateur ou de mot de passe que vous souhaitez :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Enregistrez et fermez le fichier. Maintenant que nous avons fini de travailler avec les paramètres du VPN, nous allons redémarrer le service VPN afin que notre configuration soit appliquée :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart strongswan-starter\n</li></ul></code></pre>\n<p>Maintenant que le serveur VPN a été entièrement configuré avec les options du serveur et les identifiants de l'utilisateur, il est temps de passer à la configuration de la partie la plus importante : le pare-feu.</p>\n\n<h2 id=\"Étape-6-—-configuration-du-pare-feu-et-de-la-redirection-du-noyau-ip\">Étape 6 — Configuration du pare-feu et de la redirection du noyau IP</h2>\n\n<p>Une fois la configuration de StrongSwan terminée, nous devons configurer le pare-feu pour autoriser le passage et la redirection du trafic VPN au travers de celui-ci.</p>\n\n<p>Si vous avez suivi le guide de configuration initiale du serveur, vous devriez disposer d'un pare-feu UFW activé. Si vous n'avez pas encore configuré UFW, vous devriez commencer par ajouter une règle pour autoriser les connexions SSH au travers du pare-feu afin que votre session actuelle ne se ferme pas lorsque vous activez UFW :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow OpenSSH\n</li></ul></code></pre>\n<p>Ensuite, activez le pare-feu en tapant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Ensuite, ajoutez une règle pour autoriser le trafic UDP aux ports IPSec standard, <code>500 et</code> <code>4500</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 500,4500/udp\n</li></ul></code></pre>\n<p>Ensuite, nous allons ouvrir l'un des fichiers de configuration d'UFW pour ajouter quelques politiques de bas niveau pour le routage et la transmission de paquets IPSec. Mais avant cela, nous devons trouver quelle interface réseau sur notre serveur est utilisée pour l'accès à Internet. Trouvez cette interface en recherchant le périphérique associé à la route par défaut :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ip route show default\n</li></ul></code></pre>\n<p>Votre interface publique doit suivre le mot &ldquo;dev&rdquo;. Par exemple, ce résultat montre l'interface nommée <code>eth0</code>, qui est mise en évidence dans l'exemple qui suit  :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>default via <span class=\"highlight\">your_server_ip</span> dev <span class=\"highlight\">eth0</span> proto static\n</code></pre>\n<p>Lorsque vous disposez de votre interface de réseau public, ouvrez le fichier <code>/etc/ufw/before.rules</code> dans votre éditeur de texte. Les règles dans ce fichier sont ajoutées au pare-feu avant le reste des règles habituelles d'entrée et de sortie. Elles sont utilisées pour configurer la traduction d'adresse du réseau (NAT) afin que le serveur puisse correctement acheminer les connexions vers et depuis les clients et l'Internet.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/before.rules\n</li></ul></code></pre>\n<p>En haut du fichier (avant la ligne <code>*filtre</code>), ajoutez le bloc de configuration suivant. Modifiez chaque instance de <code>eth0</code> dans la configuration ci-dessus pour qu'elle corresponde au nom de l'interface que vous avez trouvé avec <code>ip route</code>. Les lignes <code>*nat</code> créent des règles afin que le pare-feu puisse correctement acheminer et manipuler le trafic entre les clients VPN et Internet. La ligne <code>*mangle</code> ajuste la taille maximale du segment de paquets pour prévenir les problèmes potentiels avec certains clients VPN :</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code><span class=\"highlight\">*nat</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -m policy --pol ipsec --dir out -j ACCEPT</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -j MASQUERADE</span>\n<span class=\"highlight\">COMMIT</span>\n\n<span class=\"highlight\">*mangle</span>\n<span class=\"highlight\">-A FORWARD --match policy --pol ipsec --dir in -s 10.10.10.0/24 -o eth0 -p tcp -m tcp --tcp-flags SYN,RST SYN -m tcpmss --mss 1361:1536 -j TCPMSS --set-mss 1360</span>\n<span class=\"highlight\">COMMIT</span>\n\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n. . .\n</code></pre>\n<p>Ensuite, après les lignes <code>*filter</code> et de définition de chaîne, ajoutez un autre bloc de configuration :</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code>. . .\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir in --proto esp -s 10.10.10.0/24 -j ACCEPT</span>\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir out --proto esp -d 10.10.10.0/24 -j ACCEPT</span>\n</code></pre>\n<p>Ces lignes indiquent au pare-feu qu'il doit acheminer le trafic <a href=\"https://wiki.wireshark.org/ESP\">ESP</a> (Encapsulating Security Payload) afin que les clients VPN puissent se connecter. ESP fournit une sécurité supplémentaire pour nos paquets VPN lorsqu'ils traversent les réseaux non fiables.</p>\n\n<p>Lorsque vous avez terminé, sauvegardez et fermez le fichier après avoir vérifié que vous avez correctement ajouté chaque ligne. Si vous avez utilisé <code>nano</code>, faites-le en appuyant sur <code>CTRL+X</code>, <code>Y</code>, puis <code>ENTER</code>.</p>\n\n<p>Avant de redémarrer, nous allons modifier certains paramètres du noyau réseau pour permettre le routage d'une interface à une autre. Le fichier qui contrôle ces paramètres est appelé <code>/etc/ufw/sysctl.conf</code>. Nous allons devoir configurer quelques éléments dans le fichier, et notamment :</p>\n\n<p>Le premier transfert de paquets IPv4 doit être activé afin que le trafic puisse circuler entre le VPN et les interfaces réseau publiques sur le serveur. Ensuite, nous allons désactiver la découverte de Path MTU pour prévenir les problèmes de fragmentation des paquets. Enfin, nous n'accepterons pas les redirections ICMP ni n'enverrons de redirections ICMP pour prévenir les attaques <a href=\"https://en.wikipedia.org/wiki/Man-in-the-middle_attack\">man-in-the-middle</a>.</p>\n\n<p>Ouvrez le fichier de configuration des paramètres du noyau d'UFW en utilisant <code>nano</code> ou votre éditeur de texte préféré :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/sysctl.conf\n</li></ul></code></pre>\n<p>Ajoutez maintenant le paramètre <code>net/ipv4/ip_forward=1</code> suivant à la fin du fichier pour activer la transmission de paquets entre les interfaces :</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_forward=1</span>\n</code></pre>\n<p>Ensuite, bloquez l'envoi et la réception de paquets de redirection ICMP en ajoutant les lignes suivantes à la fin du fichier :</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/conf/all/accept_redirects=0</span>\n<span class=\"highlight\">net/ipv4/conf/all/send_redirects=0</span>\n</code></pre>\n<p>Enfin, désactivez la découverte de Path MTU en ajoutant cette ligne à la fin du fichier :</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_no_pmtu_disc=1</span>\n</code></pre>\n<p>Enregistrez le fichier lorsque vous avez terminé. Nous pouvons maintenant activer toutes nos modifications en désactivant et en réactivant le pare-feu, car UFW applique ces paramètres à chaque fois qu'il redémarre :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw disable\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Vous serez invité à confirmer le processus. Tapez <code>Y</code> pour réactiver UFW avec les nouveaux paramètres.</p>\n\n<h2 id=\"Étape-7-—-test-de-la-connexion-vpn-sur-windows-macos-ubuntu-ios-et-android\">Étape 7 — Test de la connexion VPN sur Windows, macOS, Ubuntu, iOS et Android</h2>\n\n<p>Maintenant que vous avez tout configuré, il est temps essayerd&rsquo;. Tout d'abord, vous devrez copier le certificat AC que vous avez créé et l'installer sur votre ou vos dispositif(s) client(s) qui se connecteront au VPN. La manière la plus simple de le faire consiste à vous connecter à votre serveur et à générer le contenu du fichier de certificat :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cat /etc/ipsec.d/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Vous verrez une sortie semblable à celle-ci :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>-----BEGIN CERTIFICATE-----\nMIIFNDCCAxygAwIBAgIIHCsidG5mXzgwDQYJKoZIhvcNAQEMBQAwODELMAkGA1UE\n\n. . .\n\nH2YUdz8XNHrJHvMQKWFpi0rlEcMs+MSXPFWE3Q7UbaZJ/h8wpSldSUbQRUlphExJ\ndJ4PX+MUJO/vjG1/ie6Kh25xbBAc3qNq8siiJZDwrg6vjEK7eiZ1rA==\n-----END CERTIFICATE-----\n</code></pre>\n<p>Copiez cette sortie sur votre ordinateur, y compris les lignes <code>-----BEGIN CERTIFICATE-----</code> et <code>-----END CERTIFICATE-----</code>,et enregistrez-la dans un fichier avec un nom reconnaissable, tel que <code>ca-cert.pem</code> Assurez-vous que le fichier que vous créez porte bien l'extension <code>.pem</code>.</p>\n\n<p>Vous pouvez également <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server\">utiliser le protocole SFTP pour transférer le fichier à votre ordinateur</a>.</p>\n\n<p>Une fois le fichier <code>ca-cert.pem</code> téléchargé sur votre ordinateur, vous pouvez configurer la connexion au VPN.</p>\n\n<h3 id=\"connexion-à-partir-de-windows\">Connexion à partir de Windows</h3>\n\n<p>Il existe de multiples façons d'importer le certificat racine et configurer Windows pour qu'il se connecte à un VPN. La première méthode utilise des outils graphiques pour chaque étape. La deuxième méthode utilise les commandes PowerShell, qui peuvent être scriptées et modifiées en fonction de votre configuration VPN.</p>\n\n<p><span class='note'><strong>Remarque :</strong> ces instructions ont été testées sur les installations Windows 10 exécutant les versions 1903 et 1909.<br></span></p>\n\n<h4 id=\"configuration-de-windows-avec-des-outils-graphiques\">Configuration de Windows avec des outils graphiques</h4>\n\n<p>Tout d'abord, importez le certificat racine en suivant ces étapes :</p>\n\n<ol>\n<li>Appuyez sur <code>WINDOWS+R</code> pour faire apparaître la boîte de dialogue <strong>Run</strong>, et entrez <code>mmc.exe</code> pour lancer la console de gestion de Windows.</li>\n<li>Dans le menu <strong>File</strong>, naviguez jusqu'à <strong>Add or Remove Snap-in</strong>, sélectionnez <strong>Certificates</strong> dans la liste des instantanés disponibles, et cliquez sur <strong>Add</strong>.</li>\n<li>Nous voulons que le VPN fonctionne avec n'importe quel utilisateur, donc sélectionnez <strong>Computer Account</strong> et cliquez sur <strong>Next</strong>.</li>\n<li>Nous configurons les choses sur l'ordinateur local, donc sélectionnez <strong>Local Computer</strong>, puis cliquez sur <strong>Finish</strong>.</li>\n<li><p>Sous le nœud <strong>Console Root</strong>, développez l'entrée <strong>Certificates (Local Computer)</strong>, développez <strong>Trusted Root Certification Authorities</strong>, puis sélectionnez l'entrée <strong>Certificates</strong>: <img src=\"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png\" alt=\"Certificates view\"></p></li>\n<li><p>Dans le menu <strong>Action</strong>, sélectionnez <strong>All tasks</strong> et cliquez sur <strong>Import</strong> pour afficher l'Assistant d'importation de certificat. Cliquez sur <strong>Next</strong> pour passer l'introduction.</p></li>\n<li><p>Dans l'écran de <strong>File to Import</strong>, cliquez sur le bouton <strong>Browse</strong>, veillez à changer le type de fichier de “X.509 Certificate (<em>.cer;</em>.crt)” à “All Files (<em>.</em> )”, et sélectionnez le fichier <code>ca-cert.pem</code> que vous avez enregistré. Ensuite, cliquez sur <strong>Next</strong>.</p></li>\n<li><p>Assurez-vous que le <strong>Certificate Store</strong> est configuré à <strong>Trusted Root Certification Authorities</strong>, et cliquez sur <strong>Next</strong>.</p></li>\n<li><p>Cliquez sur <strong>Finish</strong> pour importer le certificat.</p></li>\n</ol>\n\n<p>Ensuite, configurez le VPN avec ces étapes :</p>\n\n<ol>\n<li>Lancez <strong>Control Panel</strong>, puis naviguez jusqu'au <strong>Network and Sharing Center</strong>.</li>\n<li>Cliquez sur <strong>Set up a new connection or network</strong>, puis sélectionnez <strong>Connect to a workplace</strong>.</li>\n<li>Sélectionnez <strong>Use my Internet connection (VPN)</strong>.</li>\n<li>Entrez les détails du serveur VPN. Entrez le nom de domaine ou l'adresse IP du serveur dans le champ <strong>Internet address</strong>, puis remplissez <strong>Destination name</strong> avec quelque chose qui décrit votre connexion VPN. Ensuite, cliquez sur <strong>Done</strong>.</li>\n</ol>\n\n<h4 id=\"configuration-de-windows-en-utilisant-powershell\">Configuration de Windows en utilisant PowerShell</h4>\n\n<p>Pour importer le certificat racine AC à l'aide de PowerShell, ouvrez d'abord une invite PowerShell avec des privilèges d'administrateur. Pour ce faire, cliquez avec le bouton droit sur l'icône du menu Démarrer et sélectionnez <code>Windows PowerShell (Admin)</code>. Vous pouvez également ouvrir une invite de commande en tant qu'administrateur et taper <code>powershell</code>.</p>\n\n<p>Ensuite, nous allons importer le certificat en utilisant le cmdlet PowerShell<code>Import-Certificate</code>. Dans la commande suivante, le premier argument <code>-CertStoreLocation</code> garantira que le certificat est importé dans le magasin <strong>Trusted Root Certification Authorities</strong> de l'ordinateur afin que tous les programmes et utilisateurs puissent vérifier le certificat du serveur VPN. L'argument <code>-FilePath</code> doit indiquer l'emplacement où vous avez copié le certificat. Dans l'exemple suivant, le chemin est <code>C:\\Users\\sammy\\Documents\\ca-cert.pem</code>. Assurez-vous de modifier la commande pour qu'elle corresponde à l'emplacement que vous avez utilisé.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Import-Certificate `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CertStoreLocation cert:\\LocalMachine\\Root\\ `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -FilePath <span class=\"highlight\">C:\\users\\sammy\\Documents\\ca-cert.pem</span>\n</li></ul></code></pre>\n<p>La commande produira quelque chose comme ce qui suit :</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>   PSParentPath: Microsoft.PowerShell.Security\\Certificate::LocalMachine\\Root\n\nThumbprint                                Subject\n----------                                -------\nDB00813B4087E9367861E8463A60CEA0ADC5F002  CN=VPN root CA\n</code></pre>\n<p>Maintenant pour configurer le VPN en utilisant PowerShell, exécutez la commande suivante. Remplacez le nom DNS ou l'adresse IP de votre serveur sur la ligne <code>-ServerAddress</code> Les différents drapeaux veilleront à ce que Windows soit correctement configuré avec les paramètres de sécurité appropriés qui correspondent aux options que vous avez définies dans <code>/etc/ipsec.conf</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Add-VpnConnection -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -ServerAddress \"<span class=\"highlight\">server_domain_or_IP</span>\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -TunnelType \"IKEv2\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationMethod \"EAP\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionLevel \"Maximum\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -RememberCredential `\n</li></ul></code></pre>\n<p>Si la commande est réussie, il n'y aura pas de sortie. Pour confirmer que le VPN est correctement configuré, utilisez l'applet de commande <code>Get-VPNConnection</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Get-VpnConnection -Name \"VPN Connection\"\n</li></ul></code></pre>\n<p>Vous allez recevoir une sortie comme suit :</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Name                  : VPN Connection\nServerAddress         : <span class=\"highlight\">your_server_ip</span>\nAllUserConnection     : False\nGuid                  : {B055A1AB-175C-4028-B4A8-D34309A2B20E}\nTunnelType            : Ikev2\nAuthenticationMethod  : {Eap}\nEncryptionLevel       : Maximum\nL2tpIPsecAuth         :\nUseWinlogonCredential : False\nEapConfigXmlStream    : #document\nConnectionStatus      : Disconnected\nRememberCredential    : True\nSplitTunneling        : False\nDnsSuffix             :\nIdleDisconnectSeconds : 0\n</code></pre>\n<p>Par défaut, Windows choisit les algorithmes plus anciens et plus lents. Exécutez l'applet de commande <code>Set-VpnConnectionIPsecConfiguration</code> pour mettre à niveau les paramètres de cryptage que Windows utilisera pour l'échange de clés IKEv2 et pour crypter les paquets :</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Set-VpnConnectionIPsecConfiguration -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CipherTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -DHGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -IntegrityCheckMethod SHA384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -PfsGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionMethod GCMAES256\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Remarque</strong> : si vous souhaitez supprimer la connexion VPN et la reconfigurer avec différentes options, vous pouvez exécuter l'applet de commande <code>Remove-VpnConnection</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Remove-VpnConnection -Name \"VPN Connection\" -Force\n</li></ul></code></pre>\n<p>Le drapeau <code>-Force</code> sautera l'invitation à confirmer la suppression. Vous devez être déconnecté du VPN si vous essayez de le supprimer à l'aide de cette commande.<br></p></span>\n\n<h4 id=\"connexion-au-vpn\">Connexion au VPN</h4>\n\n<p>Une fois le certificat importé et le VPN configuré en utilisant l'une ou l'autre méthode, votre nouvelle connexion VPN sera visible sous la liste des réseaux. Sélectionnez le VPN et cliquez sur <strong>Connect</strong>. Vous serez invité à indiquer votre nom d'utilisateur et votre mot de passe. Entrez ces éléments, cliquez sur <strong>OK</strong>, et vous serez connecté.</p>\n\n<h3 id=\"connexion-à-partir-de-macos\">Connexion à partir de macOS</h3>\n\n<p>Suivez ces étapes pour importer le certificat :</p>\n\n<ol>\n<li>Double-cliquez sur le fichier de certificat. <strong>Keychain Access</strong> apparaîtra avec une boîte de dialogue indiquant &ldquo;Keychain Access essaie de modifier le keychain système. Entrez votre mot de passe pour l'autoriser.&rdquo;</li>\n<li>Entrez votre mot de passe, puis cliquez sur <strong>Modify Keychain</strong></li>\n<li>Double-cliquez sur le certificat VPN nouvellement importé. Cela génère une petite fenêtre de propriétés dans laquelle vous pouvez spécifier les niveaux de confiance. Définissez <strong>IP Security (IPSec)</strong> sur <strong>Always Trust</strong> et vous serez invité à nouveau à introduire votre mot de passe. Ce paramètre s'enregistre automatiquement après avoir entré le mot de passe.</li>\n</ol>\n\n<p>Maintenant que le certificat est importé et fiable, configurez la connexion VPN en suivant ces étapes :</p>\n\n<ol>\n<li>Allez dans les <strong>System Preferences</strong> et choisissez <strong>Network</strong>.</li>\n<li>Cliquez sur le petit bouton &ldquo;plus&rdquo; dans la partie inférieure à gauche de la liste des réseaux.</li>\n<li>Dans le popup qui apparaît, définissez <strong>Interface</strong> sur <strong>VPN</strong>, définissez <strong>VPN Type</strong> sur <strong>IKEv2</strong> et donnez un nom à la connexion.</li>\n<li>Dans le champ <strong>Server</strong> et <strong>Remote ID</strong> , entrez le nom de domaine ou l'adresse IP du serveur. Laissez <strong>Local ID</strong> vierge.</li>\n<li>Cliquez sur <strong>Authentication Settings</strong>, sélectionnez <strong>Username</strong>, et entrez votre nom d'utilisateur et votre mot de passe que vous avez configuré pour votre utilisateur VPN. Ensuite, cliquez sur <strong>OK</strong>.</li>\n</ol>\n\n<p>Enfin, cliquez sur <strong>Connect</strong> pour vous connecter au VPN. Vous devriez maintenant être connecté au VPN.</p>\n\n<h3 id=\"connexion-à-partir-d-39-ubuntu\">Connexion à partir d'Ubuntu</h3>\n\n<p>Pour vous connecter à partir d'une machine Ubuntu, vous pouvez configurer et gérer StrongSwan comme service ou utiliser une commande unique chaque fois que vous souhaitez vous connecter. Des instructions sont fournies pour les deux.</p>\n\n<h4 id=\"gérer-strongswan-en-tant-que-service\">Gérer StrongSwan en tant que service</h4>\n\n<p>Pour gérer StrongSwan en tant que service, vous devrez effectuer les étapes de configuration suivantes.</p>\n\n<p>Tout d'abord, mettez à jour votre cache local de paquets en utilisant <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo apt update\n</li></ul></code></pre>\n<p>Ensuite, installez StrongSwan et les plugins nécessaires à l'authentification :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Vous aurez maintenant besoin d'une copie du certificat AC dans le répertoire <code>/etc/ipsec.d/cacerts</code> afin que votre client puisse vérifier l'identité du serveur. Exécutez la commande suivante pour copier le fichier <code>ca-cert.pem</code> en place :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Pour vous assurer que le VPN fonctionne uniquement sur demande, utilisez <code>systemctl</code> pour désactiver l'exécution automatique de StrongSwan :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl disable --now strongswan-starter\n</li></ul></code></pre>\n<p>Ensuite, configurez le nom d'utilisateur et le mot de passe que vous utiliserez pour vous authentifier auprès du serveur VPN. Modifiez <code>/etc/ipsec.secrets</code> en utilisant nano ou votre éditeur préféré :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<p>Ajoutez la ligne suivante, en modifiant les valeurs du nom d'utilisateur et du mot de passe mis en évidence pour qu'ils correspondent à celles que vous avez configurées sur le serveur :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Enfin, modifiez le fichier <code>/etc/ipsec.conf</code> pour configurer votre client afin qu'il corresponde à la configuration du serveur :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code>config setup\n\nconn ikev2-rw\n    right=<span class=\"highlight\">server_domain_or_IP</span>\n    # This should match the `leftid` value on your server's configuration\n    rightid=<span class=\"highlight\">server_domain_or_IP</span>\n    rightsubnet=0.0.0.0/0\n    rightauth=pubkey\n    leftsourceip=%config\n    leftid=<span class=\"highlight\">username</span>\n    leftauth=eap-mschapv2\n    eap_identity=%identity\n    auto=start\n</code></pre>\n<p>Pour vous connecter au VPN, tapez :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start strongswan-starter\n</li></ul></code></pre>\n<p>Pour vous déconnecter à nouveau, tapez :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop strongswan-starter\n</li></ul></code></pre>\n<h4 id=\"utilisation-du-client-charon-cmd-pour-les-connexions-uniques\">Utilisation du client <code>charon-cmd</code> pour les connexions uniques.</h4>\n\n<p>Pour gérer StrongSwan en tant que service, vous devrez effectuer les étapes de configuration suivantes.</p>\n\n<p>Tout d'abord, mettez à jour votre cache local de paquets en utilisant <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Ensuite, installez StrongSwan et les plugins nécessaires à l'authentification :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Vous aurez maintenant besoin d'une copie du certificat AC dans le répertoire <code>/etc/ipsec.d/cacerts</code> afin que votre client puisse vérifier l'identité du serveur. Exécutez la commande suivante pour copier le fichier <code>ca-cert.pem</code> en place :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>À ce stade, vous pouvez vous connecter au serveur VPN avec <code>charon-cmd</code> en utilisant le certificat AC du serveur, l'adresse IP du serveur VPN et le nom d'utilisateur que vous avez configuré.</p>\n\n<p>Exécutez la commande suivante chaque fois que vous souhaitez vous connecter au VPN :</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo charon-cmd --cert ca-cert.pem --host <span class=\"highlight\">vpn_domain_or_IP</span> --identity <span class=\"highlight\">your_username</span>\n</li></ul></code></pre>\n<p>Lorsque vous y êtes invité, fournissez le mot de passe de l'utilisateur VPN et vous serez connecté au VPN. Pour vous déconnecter, appuyez sur <code>CTRL+C</code> dans le terminal et attendez que la connexion se ferme.</p>\n\n<h3 id=\"connexion-à-partir-d-39-ios\">Connexion à partir d'iOS</h3>\n\n<p>Pour configurer la connexion VPN sur un appareil iOS, procédez comme suit :</p>\n\n<ol>\n<li>Envoyez-vous un email avec le certificat racine en annexe.</li>\n<li>Ouvrez l'adresse électronique sur votre appareil iOS et appuyez sur le fichier de certificat joint, puis appuyez sur <strong>Install</strong> et entrez votre code secret. Une fois qu'il s'installe, appuyez sur <strong>Done</strong>.</li>\n<li>Allez <strong>dansSs</strong>,etting <strong>General</strong>, <strong>VPN</strong> et appuyez sur <strong>Add VPN Configuration</strong>. Cela fera apparaître l'écran de configuration de connexion VPN.</li>\n<li>Appuyez sur <strong>Type</strong> et sélectionnez <strong>IKEv2</strong>.</li>\n<li>Dans le champ <strong>Description</strong> , entrez un nom court pour la connexion VPN. Cela peut être tout ce que vous voulez.</li>\n<li>Dans le champ <strong>Server</strong> et <strong>Remote ID</strong> , entrez le nom de domaine ou l'adresse IP du serveur. Le champ <strong>Local ID</strong> peut être laissé vierge.</li>\n<li>Entrez votre nom d'utilisateur et votre mot de passe dans la section <strong>Authentication</strong>, puis appuyez sur <strong>Done</strong>.</li>\n<li>Sélectionnez la connexion VPN que vous venez de créer, appuyez sur l'interrupteur en haut de la page, et vous serez connecté.</li>\n</ol>\n\n<h3 id=\"connexion-à-partir-d-39-android\">Connexion à partir d'Android</h3>\n\n<p>Suivez ces étapes pour importer le certificat :</p>\n\n<ol>\n<li>Envoyez-vous un email avec le certificat AC en annexe. Sauvegardez le certificat AC dans votre dossier de téléchargements.</li>\n<li>Téléchargez le <a href=\"https://play.google.com/store/apps/details?id=org.strongswan.android&amp;hl=en_US\">client VPN StrongSwan</a> dans le Play Store.</li>\n<li>Ouvrez l'application. Appuyez sur l'icône &ldquo;more&rdquo; (<strong>&hellip;</strong>) dans le coin supérieur droit et sélectionnez <strong>CA certificates</strong>.</li>\n<li>Appuyez à nouveau sur l'icône &ldquo;more&rdquo; (<strong>&hellip;</strong>) dans le coin supérieur droit. Sélectionnez <strong>Import certificat</strong>.</li>\n<li>Naviguez vers le fichier certificat AC dans votre dossier de téléchargements et sélectionnez-le pour l'importer dans l'application.</li>\n</ol>\n\n<p>Maintenant que le certificat est importé dans l'application StrongSwan, vous pouvez configurer la connexion VPN en suivant ces étapes :</p>\n\n<ol>\n<li>Dans l'application, appuyez sur <strong>ADD VPN PROFILE</strong> en haut.</li>\n<li>Remplissez <strong>Server</strong> avec le nom de domaine ou l'adresse IP publique de votre serveur VPN.</li>\n<li>Assurez-vous que <strong>IKEv2 EAP (Username/Password)</strong> est sélectionné comme Type de VPN.</li>\n<li>Remplissez les champs <strong>Username</strong> et <strong>Password</strong> avec les identifiants que vous avez définis sur le serveur.</li>\n<li>Désélectionnez <strong>Select automatically</strong> dans la section <strong>CA certificate</strong> et cliquez sur <strong>Select CA certificate</strong>.</li>\n<li>Appuyez sur l'onglet <strong>IMPORTED</strong> en haut de l'écran et choisissez l'AC que vous avez importé (il sera nommé &ldquo;VPN root CA&rdquo; si vous n'avez pas changé le nom &ldquo;DN&rdquo; auparavant).</li>\n<li>Si vous le souhaitez, remplissez <strong>Profile name (optional)</strong> avec un nom plus descriptif.</li>\n</ol>\n\n<p>Lorsque vous souhaitez vous connecter au VPN, cliquez sur le profil que vous venez de créer dans l'application StrongSwan.</p>\n\n<h3 id=\"dépannage-des-connexions\">Dépannage des Connexions</h3>\n\n<p>Si vous n'êtes pas en mesure d'importer le certificat, vérifiez que le fichier a l'extension <code>.pem</code>, et non pas <code>.pem.txt</code>.</p>\n\n<p>Si vous n'êtes pas en mesure de vous connecter au VPN, vérifiez le nom du serveur ou l'adresse IP que vous avez utilisée. Le nom de domaine ou l'adresse IP du serveur doit correspondre à ce que vous avez configuré en tant que nom commun (CN) en créant le certificat. S'ils ne correspondent pas, la connexion VPN ne fonctionnera pas. Par exemple, si vous configurez un certificat avec le CN de <code>vpn.example.com, vous</code> <em>devez</em> utiliser <code>vpn.example.com</code> lorsque vous entrez les détails du serveur VPN. Vérifiez scrupuleusement la commande que vous avez utilisée pour générer le certificat, et les valeurs que vous avez utilisées lors de la création de votre connexion VPN.</p>\n\n<p>Enfin, vérifiez bien la configuration VPN pour vous assurer que la valeur <code>leftid</code> est configurée avec le symbole <code>@</code> si vous utilisez un nom de domaine :</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    leftid=<span class=\"highlight\">@</span>vpn.example.com\n</code></pre>\n<p>Si vous utilisez une adresse IP, veillez à ce que le symbole <code>@</code> soit absent. Assurez-vous également que lorsque vous avez généré le fichier <code>server-cert.pem</code>, vous avez inclus à la fois les drapeaux <code>--san @<span class=\"highlight\">IP_address</span></code> et <code>--san <span class=\"highlight\">IP_address</span></code>.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans ce tutoriel, vous avez construit un serveur VPN qui utilise le protocole IKEv2. Vous avez appris les directives qui contrôlent les côtés <code>left</code> et <code>right</code> d'une connexion, tant sur le serveur et que sur les clients. Vous avez également configuré un client Windows, macOS, iOS, Android ou Linux pour vous connecter au VPN.</p>\n\n<p>Pour ajouter ou supprimer des utilisateurs, passez à nouveau à l'Étape 5. Chaque ligne dans <code>/etc/ipsec.secrets</code> est pour un utilisateur, donc ajouter ou supprimer les utilisateurs, ou modifier les mots de passe requiert simplement d'éditer le fichier.</p>\n\n<p>Vous pouvez désormais êtres vous assuré que vos activités en ligne resteront sécurisées où que vous alliez et avec tout appareil que vous utilisez pour accéder à Internet.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:16 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png","linkMd5":"5399aa66b310a4c3f70321f24d372a50","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp","destWidth":1436,"destHeight":754,"sourceBytes":109775,"destBytes":168410,"author":"Jamon Camisso","articleImgCdnMap":{"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp"},"publishedOrCreatedDate":1598860106975},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment mettre en place et sécuriser un cluster etcd avec Ansible sur Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-and-secure-an-etcd-cluster-with-ansible-on-ubuntu-18-04-fr","description":"<p><em>L'auteur a choisi <a href=\"https://wikimediafoundation.org/\">Wikimedia Foundation</a> pour recevoir un don dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for Donations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://etcd.io/\">etcd</a> est un magasin de valeurs clés distribué qui repose sur de nombreuses plateformes et outils, dont <a href=\"https://kubernetes.io/\">Kubernetes</a> , <a href=\"https://vulcand.github.io/\">Vulcand</a> et <a href=\"https://github.com/youtube/doorman\">Doorman</a> . Dans Kubernetes, etcd est utilisé comme magasin de configuration globale qui stocke l'état du cluster. Savoir administrer etcd est essentiel pour administrer un cluster Kubernetes. Bien qu'il existe de nombreuses offres Kubernetes gérées, également connues sous le nom de <em>Kubernetes-as-a-Service</em> , qui vous déchargent de cette charge administrative, de nombreuses entreprises choisissent encore de gérer des clusters Kubernetes autogérés sur site en raison de la flexibilité qu'ils apportent.</p>\n\n<p>La première moitié de cet article vous guidera dans la mise en place d'un cluster de 3 nœuds etcd sur les serveurs Ubuntu 18.04. La seconde moitié se concentrera sur la sécurisation du cluster en utilisant la <a href=\"https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs\"><em>Transport Layer Secutiry</em> (Sécurité de la couche transport), ou <em>TLS</em></a>  Pour exécuter chaque installation de manière automatisée, nous utiliserons <a href=\"https://www.digitalocean.com/community/conceptual_articles/an-introduction-to-configuration-management-with-ansible\">Ansible</a> tout au long de ce tutoriel. Ansible est un outil de <em>gestion de configuration</em> similaire à <a href=\"https://puppet.com/\">Puppet</a> , <a href=\"https://www.chef.io/\">Chef</a> , et <a href=\"https://www.saltstack.com/\">SaltStack</a> ; il nous permet de définir chaque étape de configuration de manière déclarative, dans des fichiers appelés <em>playbooks</em> .</p>\n\n<p>À la fin de ce tutoriel, vous disposerez d'un cluster sécurisé de 3 nœuds etcd fonctionnant sur vos serveurs.  Vous disposerez également d'un playbook Ansible qui vous permettra de recréer de manière répétée et cohérente la même configuration sur un nouvel ensemble de serveurs.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Avant de commencer ce guide, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li><p><a href=\"https://www.python.org/\">Python</a> , <code>pip</code> , et le package <a href=\"https://pypi.org/project/pyOpenSSL/\"><code>pyOpenSSL</code></a> installé sur votre machine locale.  Pour savoir comment installer Python3, pip et les packages Python, reportez-vous à <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">Comment installer Python 3 et mettre en place un environnement de programmation local sur Ubuntu 18.04</a> .</p></li>\n<li><p>Trois serveurs Ubuntu 18.04 sur le même réseau local, avec au moins 2 Go de RAM et un accès SSH root.  Vous devez également configurer les serveurs pour qu'ils aient les noms d'hôtes <strong>etcd1</strong> , <strong>etcd2</strong> , et <strong>etcd3</strong> . Les étapes décrites dans cet article fonctionneraient sur n'importe quel serveur générique, pas nécessairement DigitalOcean Droplets. Cependant, si vous souhaitez héberger vos serveurs sur DigitalOcean, vous pouvez suivre le guide <a href=\"https://www.digitalocean.com/docs/droplets/how-to/create/\">Comment créer un droplet du panneau de contrôle de DigitalOcean</a> pour remplir cette condition. Notez que vous devez activer l'option <strong>Private Networking</strong> lors de la création de votre droplet.  Pour activer la mise en réseau privée sur les droplets existants, reportez-vous à la section <a href=\"https://www.digitalocean.com/docs/networking/private-networking/how-to/enable/\">Comment activer la mise en réseau privée sur les droplets</a> .</p></li>\n</ul>\n\n<p><span class='warning'><strong>Avertissement :</strong> Le but de cet article étant de fournir une introduction à la mise en place d'un cluster etcd sur un réseau privé, les trois serveurs Ubuntu 18.04 de cette configuration n'ont pas été testés avec un pare-feu et sont accessibles en tant que <strong>root</strong> user Dans une installation de production, tout nœud exposé à l'internet public nécessiterait un pare-feu et un sudo user pour adhérer aux meilleures pratiques de sécurité. Pour plus d'informations, consultez le tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Configuration initiale du serveur avec Ubuntu 18.04</a>.<br></span></p>\n\n<ul>\n<li><p>Une paire de clés SSH permettant à votre machine locale d'accéder aux serveurs <strong>etcd1</strong> , <strong>etcd2</strong> , et <strong>etcd3</strong>. Si vous ne savez pas ce que sont les sciences humaines, ou si vous ne disposez pas d'une paire de clés, vous pouvez vous renseigner en lisant <a href=\"https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys#generating-and-working-with-ssh-keys\">Les Fondamentaux SSH : Travailler avec les serveurs, les clients et les clés SSH</a>.</p></li>\n<li><p>Ansible installé sur votre machine locale. Par exemple, si vous utilisez Ubuntu 18.04, vous pouvez installer Ansible en suivant <strong>l'étape 1</strong> de l'article <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-ansible-on-ubuntu-18-04\">Comment installer et configurer Ansible sur Ubuntu 18.04</a>. Les commandes <code>ansible</code> et <code>ansible-playbook</code> seront ainsi disponibles sur votre machine. Vous pouvez également conserver ce mode d'emploi <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-ansible-cheat-sheet-guide\">Comment utiliser Ansible : Un guide de référence</a> à portée de main. Les commandes de ce tutoriel devraient fonctionner avec Ansible v2.x ; nous l'avons testé sur Ansible v2.9.7 sous Python v3.8.2.</p></li>\n</ul>\n\n<h2 id=\"etape-1-configuration-d-39-ansible-pour-le-nœud-de-contrôle\">Etape 1 - Configuration d'Ansible pour le nœud de contrôle</h2>\n\n<p>Ansible est un outil utilisé pour gérer les serveurs.  Les serveurs qu'Ansible gère sont appelés les <em>nœuds gérés</em>, et la machine qui fait tourner Ansible est appelée le <em>nœud de contrôle</em>. Ansible fonctionne en utilisant les clés SSH sur le nœud de contrôle pour accéder aux nœuds gérés. Une fois qu'une session SSH est établie, Ansible exécute un ensemble de scripts pour fournir et configurer les nœuds gérés. Dans cette étape, nous allons tester que nous sommes capables d'utiliser Ansible pour nous connecter aux nœuds gérés et exécuter la <a href=\"https://docs.ansible.com/ansible/2.5/modules/hostname_module.html\">commande <code>hostname</code></a> .</p>\n\n<p>Une journée typique pour un administrateur système peut impliquer la gestion de différents ensembles de nœuds. Par exemple, vous pouvez utiliser Ansible pour mettre à disposition de nouveaux serveurs, mais l'utiliser ensuite pour reconfigurer un autre ensemble de serveurs. Pour permettre aux administrateurs de mieux organiser l'ensemble des nœuds gérés, Ansible propose le concept d&rsquo;<em>inventaire sur les hôtes</em> (ou <em>inventaire</em> en abrégé). Vous pouvez définir chaque nœud que vous souhaitez gérer avec Ansible à l'intérieur d'un <em>fichier d'inventaire</em> et les organiser en <em>groupes</em>. Ensuite, lorsque vous exécutez les commandes <code>ansible</code> et <code>ansible-playbook</code>, vous pouvez spécifier à quels hôtes ou groupes la commande s'applique.</p>\n\n<p>Par défaut, Ansible lit le fichier d'inventaire à partir de <code>/etc/ansible/hosts</code> ; cependant, nous pouvons spécifier un fichier d'inventaire différent en utilisant le drapeau <code>--inventory</code> (ou <code>-i</code> en abrégé).</p>\n\n<p>Pour commencer, créez un nouveau répertoire sur votre machine locale (le <strong>nœud de contrôle</strong>) pour y placer tous les fichiers de ce tutoriel :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir -p $HOME/playground/etcd-ansible\n</li></ul></code></pre>\n<p>Ensuite, entrez dans le répertoire que vous venez de créer :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd $HOME/playground/etcd-ansible\n</li></ul></code></pre>\n<p>À l'intérieur du répertoire, créez et ouvrez un fichier d'inventaire vierge nommé <code>hosts</code> à l'aide de votre éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/hosts\n</li></ul></code></pre>\n<p>Dans le fichier <code>hosts</code>, listez chacun de vos nœuds gérés selon le format suivant, en remplaçant les adresses IP publiques mises en évidence par les adresses IP publiques réelles de vos serveurs :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/hosts\">~/playground/etcd-ansible/hosts</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[etcd]\netcd1 ansible_host=<span class=\"highlight\">etcd1_public_ip</span>  ansible_user=root\netcd2 ansible_host=<span class=\"highlight\">etcd2_public_ip</span>  ansible_user=root\netcd3 ansible_host=<span class=\"highlight\">etcd3_public_ip</span>  ansible_user=root\n</code></pre>\n<p>La ligne <code>[etcd]</code> définit un groupe appelé <code>etcd</code> . Dans la définition du groupe, nous énumérons tous les nœuds que nous gérons. Chaque ligne commence par un alias (par exemple, <code>etcd1</code> ), ce qui nous permet de nous référer à chaque hôte en utilisant un nom facile à retenir au lieu d'une longue adresse IP. Les <em>variables</em> <code>ansible_host</code> et <code>ansible_user</code> sont des variables Ansible . Dans ce cas, elles sont utilisées pour fournir à Ansible les adresses IP publiques et les noms d'utilisateur SSH à utiliser lors de la connexion via SSH.</p>\n\n<p>Pour s'assurer qu'Ansible est capable de se connecter à nos nœuds gérés, nous pouvons tester la connectivité en utilisant Ansible pour exécuter la commande <code>hostname</code> sur chacun des hôtes du groupe <code>etcd</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible etcd -i hosts -m command -a hostname\n</li></ul></code></pre>\n<p>Décomposons cette commande pour apprendre ce que chaque partie signifie :</p>\n\n<ul>\n<li><code>etcd</code> : spécifie le <em>modèle d'hôte</em> à utiliser pour déterminer quels hôtes de l'inventaire sont gérés avec cette commande.  Ici, nous utilisons le nom du groupe comme modèle d'hôte.</li>\n<li><code>-i hosts</code> : spécifie le fichier d'inventaire à utiliser.</li>\n<li><code>Commande -m</code> : la fonctionnalité derrière Ansible est fournie par des <em>modules</em> . Le module de <code>commande</code> prend l'argument transmis et l'exécute comme une commande sur chacun des nœuds gérés. Ce tutoriel introduira quelques autres modules Ansible au fur et à mesure de notre progression.</li>\n<li><code>-a hostname</code> : l'argument à passer dans le module. Le nombre et les types d'arguments dépendent du module.</li>\n</ul>\n\n<p>Après avoir exécuté la commande, vous trouverez la sortie suivante, ce qui signifie qu'Ansible est configuré correctement :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>etcd2 | CHANGED | rc=0 &gt;&gt;\netcd2\n\netcd3 | CHANGED | rc=0 &gt;&gt;\netcd3\n\netcd1 | CHANGED | rc=0 &gt;&gt;\netcd1\n</code></pre>\n<p>Chaque commande qu'Ansible exécute est appelée une <em>tâche _. L'utilisation d&rsquo;<code>ansible</code> sur la ligne de commande pour exécuter des tâches est appelée exécution de commandes _ad hoc</em>. L'avantage des commandes ad hoc est qu'elles sont rapides et ne nécessitent que peu de réglages ; l'inconvénient est qu'elles fonctionnent manuellement et ne peuvent donc pas être confiées à un système de contrôle de version comme <a href=\"https://git-scm.com/\">Git</a> .</p>\n\n<p>Une légère amélioration serait d'écrire un script shell et d'exécuter nos commandes en utilisant le <a href=\"https://docs.ansible.com/ansible/latest/modules/script_module.html\">module de <code>script</code></a> d'Ansible .  Cela nous permettrait d'enregistrer les étapes de configuration que nous avons suivies pour le contrôle de version. Cependant, les scripts shell sont <em>impératifs</em>, ce qui signifie que nous sommes responsables de la détermination des commandes à exécuter (les « comment ») pour configurer le système dans l'état souhaité. Ansible, d'autre part, préconise une approche <em>déclarative</em>, où nous définissons « quel » état souhaité de notre serveur doit se trouver à l'intérieur des fichiers de configuration, et Ansible est responsable d'amener le serveur à cet état souhaité.</p>\n\n<p>L'approche déclarative est préférable parce que l'intention du fichier de configuration est immédiatement communiquée, ce qui signifie qu'il est plus facile à comprendre et à maintenir. De plus, il incombe à Ansible, et non plus à l'administrateur, de traiter les cas marginaux, ce qui nous épargne beaucoup de travail.</p>\n\n<p>Maintenant que vous avez configuré le nœud de contrôle Ansible pour communiquer avec les nœuds gérés, nous vous présenterons, dans une prochaine étape, les <em>playbooks</em> Ansible, qui vous permettent de spécifier des tâches de manière déclarative.</p>\n\n<h2 id=\"Étape-2-obtenir-les-noms-d-39-hôte-des-nœuds-gérés-à-l-39-aide-de-playbooks-ansible\">Étape 2 - Obtenir les noms d'hôte des nœuds gérés à l'aide de playbooks Ansible</h2>\n\n<p>Au cours de cette étape, nous reproduirons ce qui a été fait à l'étape 1 en imprimant les noms d'hôte des nœuds gérés, mais au lieu d'exécuter des tâches ad hoc, nous définirons chaque tâche de manière déclarative comme un playbook ansible et nous l'exécuterons. L'objectif de cette étape est de démontrer comment fonctionnent les playbooks Ansible ; nous réaliserons des tâches beaucoup plus substantielles avec des playbooks dans des étapes ultérieures.</p>\n\n<p>Dans le répertoire de votre projet, créez un nouveau fichier nommé <code>playbook.yaml</code> en utilisant votre éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>À l'intérieur de <code>playbook.yaml</code>, ajoutez les lignes suivantes :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  tasks:\n    - name: \"Retrieve hostname\"\n      command: hostname\n      register: output\n    - name: \"Print hostname\"\n      debug: var=output.stdout_lines\n</code></pre>\n<p>Fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code>, puis sur <code>Y</code>.</p>\n\n<p>Le playbook contient une liste de <em>plays</em> ; chaque play contient une liste de tâches qui doivent être exécutées sur tous les hôtes correspondant au modèle d'hôte spécifié par la clé d&rsquo;<code>hôtes</code>. Dans ce playbook, nous avons un play qui contient deux tâches. La première tâche exécute la commande <code>hostname</code> en utilisant le module de <code>commande</code> et enregistre la sortie dans une variable nommée <code>output</code> . Dans la deuxième tâche, nous utilisons le module <a href=\"https://docs.ansible.com/ansible/latest/modules/debug_module.html\"><code>debug</code></a> pour imprimer la propriété <code>stdout_lines</code> de la variable <code>output</code>.</p>\n\n<p>Nous pouvons maintenant exécuter ce playbook en utilisant la commande <code>ansible-playbook</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Vous trouverez la sortie suivante, ce qui signifie que votre playbook fonctionne correctement :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>PLAY [etcd] ***********************************************************************************************************************\n\nTASK [Gathering Facts] ************************************************************************************************************\nok: [etcd2]\nok: [etcd3]\nok: [etcd1]\n\nTASK [Retrieve hostname] **********************************************************************************************************\nchanged: [etcd2]\nchanged: [etcd3]\nchanged: [etcd1]\n\nTASK [Print hostname] *************************************************************************************************************\nok: [etcd1] =&gt; {\n    \"output.stdout_lines\": [\n        \"etcd1\"\n    ]\n}\nok: [etcd2] =&gt; {\n    \"output.stdout_lines\": [\n        \"etcd2\"\n    ]\n}\nok: [etcd3] =&gt; {\n    \"output.stdout_lines\": [\n        \"etcd3\"\n    ]\n}\n\nPLAY RECAP ************************************************************************************************************************\netcd1                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \netcd2                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \netcd3                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n</code></pre>\n<p><span class='note'><strong>Note :</strong> <code>ansible-playbook</code> utilise parfois <code>cowsay</code> comme moyen ludique d'imprimer les titres. Si vous trouvez beaucoup de vaches en ASCII imprimées sur votre terminal, vous savez maintenant pourquoi. Pour désactiver cette fonctionnalité, réglez la variable d'environnement <code>ANSIBLE_NOCOWS</code> sur <code>1</code> avant de lancer <code>ansible-playbook</code> en exécutant <code>export ANSIBLE_NOCOWS=1</code> dans votre shell.<br></span></p>\n\n<p>Dans cette étape, nous sommes passés de l'exécution de tâches ad hoc impératives à l'exécution de playbooks déclaratifs. Dans la prochaine étape, nous remplacerons ces deux tâches de démonstration par des tâches qui mettront en place notre cluster etcd.</p>\n\n<h2 id=\"Étape-3-installation-d-39-etcd-sur-les-nœuds-gérés\">Étape 3 - Installation d'etcd sur les nœuds gérés</h2>\n\n<p>Dans cette étape, nous vous montrerons les commandes pour installer <code>etcd</code> manuellement et nous vous montrerons comment traduire ces mêmes commandes en tâches à l'intérieur de notre playbook Ansible.</p>\n\n<p><code>etcd</code> et son client <code>etcdctl</code> sont disponibles sous forme de binaires, que nous allons télécharger, extraire et déplacer dans un répertoire qui fait partie de la variable d'environnement <code>PATH</code>. Lorsqu'ils sont configurés manuellement, voici les étapes que nous suivons pour chacun des nœuds gérés :</p>\n<pre class=\"code-pre super_user prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"#\">mkdir -p /opt/etcd/bin\n</li><li class=\"line\" data-prefix=\"#\">cd /opt/etcd/bin\n</li><li class=\"line\" data-prefix=\"#\">wget -qO- https://storage.googleapis.com/etcd/v<span class=\"highlight\">3.3.13</span>/etcd-v<span class=\"highlight\">3.3.13</span>-linux-amd64.tar.gz | tar --extract --gzip --strip-components=1\n</li><li class=\"line\" data-prefix=\"#\">echo 'export PATH=\"$PATH:/opt/etcd/bin\"' &gt;&gt; ~/.profile\n</li><li class=\"line\" data-prefix=\"#\">echo 'export ETCDCTL_API=3\" &gt;&gt; ~/.profile\n</li></ul></code></pre>\n<p>Les quatre premières commandes permettent de télécharger et d'extraire les binaires dans le répertoire <code>/opt/etcd/bin/</code>. Par défaut, le client <code>etcdctl</code> utilisera l'API v2 pour communiquer avec le serveur <code>etcd</code>. Puisque nous utilisons etcd v3.x, la dernière commande fixe la variable d'environnement <code>ETCDCTL_API</code> à <code>3</code> .</p>\n\n<p><span class='note'><strong>Note :</strong> Ici, nous utilisons etcd v3.3.13 construit pour une machine avec des processeurs qui utilisent le jeu d'instructions AMD64. Vous pouvez trouver des binaires pour d'autres systèmes et d'autres versions sur la page officielle des <a href=\"https://github.com/etcd-io/etcd/releases\">versions</a> de GitHub.<br></span></p>\n\n<p>Pour reproduire les mêmes étapes dans un format standardisé, nous pouvons ajouter des tâches à notre playbook. Ouvrez le fichier <code>playbook.yaml</code> dans votre éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Remplacez la totalité du fichier <code>playbook.yaml</code> par le contenu suivant :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    - name: \"Create directory for etcd binaries\"\n      file:\n        path: /opt/etcd/bin\n        state: directory\n        owner: root\n        group: root\n        mode: 0700\n    - name: \"Download the tarball into the /tmp directory\"\n      get_url:\n        url: https://storage.googleapis.com/etcd/v<span class=\"highlight\">3.3.13</span>/etcd-v<span class=\"highlight\">3.3.13</span>-linux-amd64.tar.gz\n        dest: /tmp/etcd.tar.gz\n        owner: root\n        group: root\n        mode: 0600\n        force: True\n    - name: \"Extract the contents of the tarball\"\n      unarchive:\n        src: /tmp/etcd.tar.gz\n        dest: /opt/etcd/bin/\n        owner: root\n        group: root\n        mode: 0600\n        extra_opts:\n          - --strip-components=1\n        decrypt: True\n        remote_src: True\n    - name: \"Set permissions for etcd\"\n      file:\n        path: /opt/etcd/bin/etcd\n        state: file\n        owner: root\n        group: root\n        mode: 0700\n    - name: \"Set permissions for etcdctl\"\n      file:\n        path: /opt/etcd/bin/etcdctl\n        state: file\n        owner: root\n        group: root\n        mode: 0700\n    - name: \"Add /opt/etcd/bin/ to the $PATH environment variable\"\n      lineinfile:\n        path: /etc/profile\n        line: export PATH=\"$PATH:/opt/etcd/bin\"\n        state: present\n        create: True\n        insertafter: EOF\n    - name: \"Set the ETCDCTL_API environment variable to 3\"\n      lineinfile:\n        path: /etc/profile\n        line: export ETCDCTL_API=3\n        state: present\n        create: True\n        insertafter: EOF\n</code></pre>\n<p>Chaque tâche utilise un module ; pour cet ensemble de tâches, nous utilisons les modules suivants :</p>\n\n<ul>\n<li><a href=\"https://docs.ansible.com/ansible/latest/modules/file_module.html\"><code>file</code></a> : pour créer le répertoire <code>/opt/etcd/bin</code>, et pour définir plus tard les permissions des fichiers pour les binaires <code>etcd</code> et <code>etcdctl</code>.</li>\n<li><a href=\"https://docs.ansible.com/ansible/latest/modules/get_url_module.html\"><code>get_url</code></a> : pour télécharger le tarball gzippé sur les nœuds gérés.</li>\n<li><a href=\"https://docs.ansible.com/ansible/latest/modules/unarchive_module.html\"><code>unarchive</code></a> : pour extraire et déballer les binaires <code>etcd</code> et <code>etcdctl</code> du tarball gzippé.</li>\n<li><a href=\"https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html\"><code>lineinfile</code></a> : pour ajouter une entrée dans le fichier <code>.profile</code>.</li>\n</ul>\n\n<p>Pour appliquer ces changements, fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code> suivi de <code>Y</code> . Ensuite, sur le terminal, exécutez à nouveau la même commande <code>ansible-playbook</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>La section <code>PLAY RECAP</code> de la sortie n'affichera que <code>ok</code> et <code>changed</code> :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nPLAY RECAP ************************************************************************************************************************\netcd1                      : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \netcd2                      : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \netcd3                      : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n</code></pre>\n<p>Pour confirmer une installation correcte d'etcd, il faut lancer manuellement SSH dans l'un des nœuds gérés et exécuter <code>etcd</code> et <code>etcdctl</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh root@<span class=\"highlight\">etcd1_public_ip</span>\n</li></ul></code></pre>\n<p><code><span class=\"highlight\">etcd1_public_ip</span></code> sont les adresses IP publiques du serveur nommé <strong>etcd1</strong> . Une fois que vous avez obtenu un accès SSH, lancez <code>etcd --version</code> pour imprimer la version d'etcd installée :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcd --version\n</li></ul></code></pre>\n<p>Vous trouverez une sortie similaire à ce qui est montré dans la suite, ce qui signifie que le binaire <code>etcd</code> est installé avec succès :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>etcd Version: <span class=\"highlight\">3.3.13</span>\nGit SHA: 98d3084\nGo Version: go1.10.8\nGo OS/Arch: linux/amd64\n</code></pre>\n<p>Pour confirmer qu&rsquo;<code>etcdctl</code> est installé avec succès, lancez la <code>version d'etcdctl</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl version\n</li></ul></code></pre>\n<p>Vous recevrez un résultat similaire à celui qui suit :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>etcdctl version: <span class=\"highlight\">3.3.13</span>\nAPI version: 3.3\n</code></pre>\n<p>Notez que la sortie indique <code>API version: 3.3</code>, ce qui confirme également que notre variable d'environnement <code>ETCDCTL_API</code> a été définie correctement.</p>\n\n<p>Sortez du serveur <strong>etcd1</strong> pour revenir à votre environnement local.</p>\n\n<p>Nous avons maintenant installé avec succès <code>etcd</code> et <code>etcdctl</code> sur tous nos nœuds gérés. Dans la prochaine étape, nous ajouterons d'autres tâches à notre play pour faire fonctionner etcd comme un service de fond.</p>\n\n<h2 id=\"etape-4-création-d-39-un-fichier-d-39-unité-pour-etcd\">Etape 4 - Création d'un fichier d'unité pour etcd</h2>\n\n<p>La façon la plus rapide d'exécuter etcd avec Ansible peut être d'utiliser le module <code>command</code> pour exécuter <code>/opt/etcd/bin/etcd</code> . Cependant, cela ne fonctionnera pas car cela fera fonctionner <code>etcd</code> comme un processus de premier plan. L'utilisation du module <code>command</code> entraînera le blocage d'Ansible en attendant le retour de la commande <code>etcd</code>, ce qu'il ne fera jamais. Dans cette étape, nous allons donc mettre à jour notre playbook afin d'utiliser notre binaire <code>etcd</code> en tant que <em>service</em> de fond à la place.</p>\n\n<p>Ubuntu 18.04 utilise <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\"><em>systemd</em></a> comme <em>système d'initialisation</em>, ce qui signifie que nous pouvons créer de nouveaux services en écrivant des <em>fichiers unitaires</em> et en les plaçant dans le répertoire <code>/etc/systemd/system/</code>.</p>\n\n<p>Tout d'abord, dans le répertoire de notre projet, créez un nouveau répertoire nommé <code>files/</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir files\n</li></ul></code></pre>\n<p>Ensuite, à l'aide de votre éditeur, créez un nouveau fichier nommé <code>etcd.service</code> dans ce répertoire :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano files/etcd.service\n</li></ul></code></pre>\n<p>Ensuite, copiez le bloc de code suivant dans le fichier <code>files/etcd.service</code> :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/files/etcd.service\">~/playground/etcd-ansible/files/etcd.service</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[Unit]\nDescription=etcd distributed reliable key-value store\n\n[Service]\nType=notify\nExecStart=/opt/etcd/bin/etcd\nRestart=always\n</code></pre>\n<p>Ce fichier d'unité définit un service qui exécute l'exécutable dans <code>/opt/etcd/bin/etcd</code> , notifie à systemd la fin de l'initialisation, et redémarre toujours s'il se termine.</p>\n\n<p><span class='note'><strong>Note :</strong> Si vous souhaitez en savoir plus sur les fichiers systemd et les fichiers d'unité, ou si vous voulez adapter le fichier d'unité à vos besoins, lisez le guide <a href=\"https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files\">Comprendre les unités et les fichiers d'unité systemd</a>.<br></span></p>\n\n<p>Fermez et enregistrez le fichier <code>files/etcd.service</code> en appuyant sur <code>CTRL+X</code> suivi de <code>Y</code> .</p>\n\n<p>Ensuite, nous devons ajouter une tâche à l'intérieur de notre playbook qui copiera le fichier local <code>files/etcd.service</code> dans le répertoire <code>/etc/systemd/system/etcd.service</code> pour chaque noeud géré. Nous pouvons le faire en utilisant le module <a href=\"https://docs.ansible.com/ansible/latest/modules/copy_module.html\"><code>copy</code></a>.</p>\n\n<p>Ouvrez votre playbook :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ajoutez la tâche surlignée suivante à la fin de nos tâches existantes :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    ...\n    - name: \"Set the ETCDCTL_API environment variable to 3\"\n      lineinfile:\n        path: /etc/profile\n        line: export ETCDCTL_API=3\n        state: present\n        create: True\n        insertafter: EOF\n    <span class=\"highlight\">- name: \"Create a etcd service\"</span>\n      <span class=\"highlight\">copy:</span>\n        <span class=\"highlight\">src: files/etcd.service</span>\n        <span class=\"highlight\">remote_src: False</span>\n        <span class=\"highlight\">dest: /etc/systemd/system/etcd.service</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0644</span>\n</code></pre>\n<p>En copiant le fichier unitaire dans le fichier <code>/etc/systemd/system/etcd.service</code> , un service est maintenant défini.</p>\n\n<p>Sauvegardez et quittez le playbook.</p>\n\n<p>Exécutez à nouveau la même commande <code>ansible-playbook</code> pour appliquer les nouveaux changements :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Pour confirmer que les changements ont bien été appliqués, il faut d'abord faire entrer les SSH dans l'un des nœuds gérés :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd1_public_ip</span>\n</li></ul></code></pre>\n<p>Ensuite, lancez <code>systemctl status etcd</code> pour interroger systemd sur l'état du service <code>etcd</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">systemctl status etcd\n</li></ul></code></pre>\n<p>Vous trouverez la sortie suivante, qui indique que le service est chargé :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>● etcd.service - etcd distributed reliable key-value store\n   Loaded: loaded (/etc/systemd/system/etcd.service; static; vendor preset: enabled)\n   Active: inactive (dead)\n...\n</code></pre>\n<p><span class='note'><strong>Note :</strong> La dernière ligne ( <code>Active : inactive (dead)</code>) de la sortie indique que le service est inactif, ce qui signifie qu'il ne sera pas exécuté automatiquement au démarrage du système. Cela est prévu et n'est pas une erreur.<br></span></p>\n\n<p>Appuyez sur <code>q</code> pour revenir au shell, puis exécutez <code>exit</code> pour sortir du nœud géré et revenir à votre shell local :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">exit\n</li></ul></code></pre>\n<p>Dans cette étape, nous avons mis à jour notre playbook pour faire fonctionner le binaire <code>etcd</code> comme un service systemd. Dans la prochaine étape, nous continuerons à mettre en place etcd en lui fournissant un espace pour stocker ses données.</p>\n\n<h2 id=\"Étape-5-configurer-le-répertoire-de-données\">Étape 5 - Configurer le répertoire de données</h2>\n\n<p>etcd est un magasin de données à valeur clé, ce qui signifie que nous devons lui fournir de l'espace pour stocker ses données. Dans cette étape, nous allons mettre à jour notre playbook afin de définir un répertoire de données dédié à l'usage d'etcd.</p>\n\n<p>Ouvrez votre playbook :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ajoutez la tâche suivante à la fin de la liste des tâches :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    ...\n    - name: \"Create a etcd service\"\n      copy:\n        src: files/etcd.service\n        remote_src: False\n        dest: /etc/systemd/system/etcd.service\n        owner: root\n        group: root\n        mode: 0644\n    <span class=\"highlight\">- name: \"Create a data directory\"</span>\n      <span class=\"highlight\">file:</span>\n        <span class=\"highlight\">path: /var/lib/etcd/{{ inventory_hostname }}.etcd</span>\n        <span class=\"highlight\">state: directory</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0755</span>\n</code></pre>\n<p>Ici, nous utilisons <code>/var/lib/etcd/<span class=\"highlight\">hostname</span>.etcd</code> comme répertoire de données, où <code><span class=\"highlight\">hostname</span></code> est le nom d'hôte du nœud géré actuel. <code>inventory_hostname</code> est une variable qui représente le nom d'hôte du nœud géré actuel ; sa valeur est automatiquement alimentée par Ansible. La syntaxe des accolades (c'est-à-dire <code>{{ inventory_hostname }}</code> ) est utilisée pour la <em>substitution de variables</em>, supportée par le moteur de modèle <a href=\"https://palletsprojects.com/p/jinja/\">Jinja2</a>, qui est le moteur de modèle par défaut pour Ansible.</p>\n\n<p>Fermez l'éditeur de texte et enregistrez le fichier.</p>\n\n<p>Ensuite, nous devons demander à etcd d'utiliser ce répertoire de données. Nous le faisons en passant le point term<code>inal dat</code>a-dir à etcd. Pour définir les points terminaux etcd, nous pouvons utiliser une combinaison de variables d'environnement, de drapeaux de ligne de commande et de fichiers de configuration. Pour ce tutoriel, nous utiliserons un fichier de configuration, car il est beaucoup plus judicieux d'isoler toutes les configurations dans un fichier, plutôt que d'avoir la configuration éparpillée dans notre playbook.</p>\n\n<p>Dans le répertoire de votre projet, créez un nouveau répertoire nommé <code>templates/</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir templates\n</li></ul></code></pre>\n<p>Ensuite, à l'aide de votre éditeur, créez un nouveau fichier nommé <code>etcd.conf.yaml.j2</code> dans le répertoire :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano templates/etcd.conf.yaml.j2\n</li></ul></code></pre>\n<p>Ensuite, copiez la ligne suivante et collez-la dans le fichier :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/templates/etcd.conf.yaml.j2\">~/playground/etcd-ansible/templates/etcd.conf.yaml.j2</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">data-dir: /var/lib/etcd/{{ inventory_hostname }}.etcd\n</code></pre>\n<p>Ce fichier utilise la même syntaxe de substitution de variables Jinja2 que notre playbook. Pour substituer les variables et télécharger le résultat sur chaque hôte géré, nous pouvons utiliser le module <a href=\"https://docs.ansible.com/ansible/latest/modules/template_module.html\"><code>template</code></a>. Il fonctionne de la même manière que la <code>copie</code>, sauf qu'il effectue une substitution variable avant le téléchargement.</p>\n\n<p>Sortez d&rsquo;<code>etcd.conf.yaml.j2</code> , puis ouvrez votre playbook :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ajoutez les tâches suivantes à la liste des tâches pour créer un répertoire et y télécharger le fichier de configuration modèle :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    ...\n    - name: \"Create a data directory\"\n      file:\n        ...\n        mode: 0755\n    <span class=\"highlight\">- name: \"Create directory for etcd configuration\"</span>\n      <span class=\"highlight\">file:</span>\n        <span class=\"highlight\">path: /etc/etcd</span>\n        <span class=\"highlight\">state: directory</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0755</span>\n    <span class=\"highlight\">- name: \"Create configuration file for etcd\"</span>\n      <span class=\"highlight\">template:</span>\n        <span class=\"highlight\">src: templates/etcd.conf.yaml.j2</span>\n        <span class=\"highlight\">dest: /etc/etcd/etcd.conf.yaml</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0600</span>\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>Comme nous avons effectué ce changement, nous devons mettre à jour le fichier d'unité de notre service pour lui transmettre l'emplacement de notre fichier de configuration (c'est-à-dire <code>/etc/etcd/etcd.conf.yaml</code> ).</p>\n\n<p>Ouvrez le fichier de service etcd sur votre machine locale :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano files/etcd.service\n</li></ul></code></pre>\n<p>Mettez à jour le fichier <code>files/etcd.service</code> en ajoutant l'indicateur <code>--config-file</code> mis en évidence dans ce qui suit :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/files/etcd.service\">~/playground/etcd-ansible/files/etcd.service</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[Unit]\nDescription=etcd distributed reliable key-value store\n\n[Service]\nType=notify\nExecStart=/opt/etcd/bin/etcd <span class=\"highlight\">--config-file /etc/etcd/etcd.conf.yaml</span>\nRestart=always\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>Dans cette étape, nous avons utilisé notre playbook pour fournir un répertoire de données à etcd afin de stocker ses données. Dans l'étape suivante, nous ajouterons quelques tâches supplémentaires pour redémarrer le service <code>etcd</code> et le lancer au démarrage.</p>\n\n<h2 id=\"Étape-6-activation-et-démarrage-du-service-etcd\">Étape 6 - Activation et démarrage du service etcd</h2>\n\n<p>Chaque fois que nous apportons des modifications au fichier d'unité d'un service, nous devons redémarrer le service pour qu'elles prennent effet. Nous pouvons le faire en exécutant la commande <code>systemctl restart etcd</code>. En outre, pour que le service <code>etcd</code> démarre automatiquement au démarrage du système, nous devons exécuter <code>systemctl enable etcd</code> . Dans cette étape, nous allons exécuter ces deux commandes en utilisant le playbook.</p>\n\n<p>Pour exécuter les commandes, nous pouvons utiliser le module de <a href=\"https://docs.ansible.com/ansible/latest/modules/command_module.html\"><code>commande</code></a> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ajoutez les tâches suivantes à la fin de la liste des tâches :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    ...\n    - name: \"Create configuration file for etcd\"\n      template:\n        ...\n        mode: 0600\n    <span class=\"highlight\">- name: \"Enable the etcd service\"</span>\n      <span class=\"highlight\">command: systemctl enable etcd</span>\n    <span class=\"highlight\">- name: \"Start the etcd service\"</span>\n      <span class=\"highlight\">command: systemctl restart etcd</span>\n</code></pre>\n<p>Enregistrez et fermez le fichier.</p>\n\n<p>Exécutez <code>ansible-playbook -i hosts playbook.yaml</code> une fois de plus :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Pour vérifier que le service <code>etcd</code> est maintenant redémarré et activé, SSH dans l'un des nœuds gérés :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd1_public_ip</span>\n</li></ul></code></pre>\n<p>Ensuite, lancez <code>systemctl status etcd</code> pour vérifier l'état du service <code>etcd</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">systemctl status etcd\n</li></ul></code></pre>\n<p>Vous trouverez <code>enabled</code> and <code>active (en cours)</code> comme mis en surbrillance ci-dessous ; cela signifie que les modifications que nous avons apportées à notre playbook ont pris effet :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>● etcd.service - etcd distributed reliable key-value store\n   Loaded: loaded (/etc/systemd/system/etcd.service; static; vendor preset: <span class=\"highlight\">enabled</span>)\n   Active: <span class=\"highlight\">active (running)</span>\n Main PID: 19085 (etcd)\n    Tasks: 11 (limit: 2362)\n</code></pre>\n<p>Dans cette étape, nous avons utilisé le module <code>command</code> pour exécuter des commandes <code>systemctl</code> qui redémarrent et activent le service <code>etcd</code> sur nos nœuds gérés. Maintenant que nous avons mis en place une installation etcd, nous allons, dans la prochaine étape, tester sa fonctionnalité en effectuant quelques opérations de base de création, lecture, mise à jour et suppression (CRUD).</p>\n\n<h2 id=\"Étape-7-tester-etcd\">Étape 7 - Tester etcd</h2>\n\n<p>Bien que nous disposions d'une installation etcd en état de marche, elle n'est pas sûre et n'est pas encore prête à être utilisée pour la production. Mais avant de sécuriser notre installation etcd dans les étapes ultérieures, il faut d'abord comprendre ce qu'etcd peut faire en termes de fonctionnalités. Dans cette étape, nous allons envoyer manuellement des demandes à etcd pour ajouter, récupérer, mettre à jour et supprimer des données.</p>\n\n<p>Par défaut, etcd expose une API qui écoute sur le port <code>2379</code> pour la communication avec les clients. Cela signifie que nous pouvons envoyer des requêtes API brutes à etcd en utilisant un client HTTP. Cependant, il est plus rapide d'utiliser le client officiel etcd (<code>etcdctl</code>), qui permet de créer/mettre à jour, de récupérer et de supprimer des paires clé-valeur en utilisant respectivement les sous-commandes <code>put</code> , <code>get</code> et <code>del</code>.</p>\n\n<p>Assurez-vous que vous êtes toujours à l'intérieur du nœud géré par <strong>etcd1</strong>, et exécutez les commandes <code>etcdctl</code> suivantes pour confirmer que votre installation etcd fonctionne.</p>\n\n<p>D'abord, créez une nouvelle entrée en utilisant la sous-commande <code>put</code>.</p>\n\n<p>La sous-commande <code>put</code> a la syntaxe suivante :</p>\n<pre class=\"code-pre \"><code>etcdctl put <span class=\"highlight\">key</span> <span class=\"highlight\">value</span>\n</code></pre>\n<p>Sur <strong>etcd1</strong> , lancez la commande suivante :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl put foo \"bar\"\n</li></ul></code></pre>\n<p>La commande que nous venons d'exécuter demande à etcd d'écrire la valeur <code>« bar »</code> dans la clé <code>foo</code> du magasin.</p>\n\n<p>Vous trouverez alors <code>OK</code> imprimé dans la sortie, ce qui indique que les données ont persisté :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>OK\n</code></pre>\n<p>Nous pouvons ensuite récupérer cette entrée en utilisant la sous-commande <code>get</code>, qui a la syntaxe <code>etcdctl get <span class=\"highlight\">key</span></code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl get foo\n</li></ul></code></pre>\n<p>Vous trouverez ce résultat, qui indique la clé sur la première ligne et la valeur que vous avez insérée plus tôt sur la deuxième ligne :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>foo\nbar\n</code></pre>\n<p>Nous pouvons supprimer l'entrée en utilisant la sous-commande <code>del</code>, qui a la syntaxe <code>etcdctl del <span class=\"highlight\">key</span></code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl del foo\n</li></ul></code></pre>\n<p>Vous trouverez la sortie suivante, qui indique le nombre d'entrées supprimées :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>1\n</code></pre>\n<p>Maintenant, lançons à nouveau la sous-commande <code>get</code> pour tenter de récupérer une paire clé-valeur supprimée :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl get foo\n</li></ul></code></pre>\n<p>Vous ne recevrez pas de sortie, ce qui signifie qu&rsquo;<code>etcdctl</code> n'est pas en mesure de récupérer la paire clé-valeur. Cela confirme qu'une fois l'entrée supprimée, elle ne peut plus être récupérée.</p>\n\n<p>Maintenant que vous avez testé les opérations de base d'etcd et d&rsquo;<code>etcdctl</code>, sortons de notre nœud géré et retournons à votre environnement local :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">exit\n</li></ul></code></pre>\n<p>Dans cette étape, nous avons utilisé le client <code>etcdctl</code> pour envoyer des demandes à etcd. À ce stade, nous gérons trois instances distinctes d'etcd, chacune agissant indépendamment des autres. Cependant, etcd est conçu comme un magasin de valeurs clés distribué, ce qui signifie que plusieurs instances d'etcd peuvent se regrouper pour former un seul <em>groupe</em> ; chaque instance devient alors un <em>membre</em> du groupe. Après avoir formé un cluster, vous pourrez récupérer une paire clé-valeur insérée à partir d'un autre membre du cluster. Dans la prochaine étape, nous utiliserons notre playbook pour transformer nos trois clusters à un seul nœud en un seul cluster à trois nœuds.</p>\n\n<h2 id=\"Étape-8-formation-d-39-un-cluster-à-l-39-aide-de-la-découverte-statique\">Étape 8 - Formation d'un cluster à l'aide de la découverte statique</h2>\n\n<p>Pour créer un cluster à 3 nœuds au lieu de trois clusters à 1 nœud, nous devons configurer ces installations etcd pour qu'elles communiquent entre elles. Cela signifie que chacun doit connaître les adresses IP des autres. Ce processus est appelé <em>découverte</em>. La découverte peut se faire soit par <em>configuration statique</em>, soit par <em>découverte dynamique de services</em>. Dans cette étape, nous discuterons de la différence entre les deux, et nous mettrons à jour notre playbook pour créer un cluster etcd en utilisant la découverte statique.</p>\n\n<p>La découverte par configuration statique est la méthode qui nécessite le moins de configuration ; c'est là que les points terminaux de chaque membre sont passés dans la commande <code>etcd</code> avant qu'elle ne soit exécutée. Pour utiliser la configuration statique, les conditions suivantes doivent être remplies avant l'initialisation du cluster :</p>\n\n<ul>\n<li>le nombre de membres est connu</li>\n<li>les points terminaux de chaque membre sont connus</li>\n<li>les adresses IP de tous les points terminaux sont statiques</li>\n</ul>\n\n<p>Si ces conditions ne peuvent être remplies, vous pouvez alors utiliser un service de découverte dynamique. Avec le service de découverte dynamique, toutes les instances s'enregistreraient auprès du service de découverte, qui permet à chaque membre de récupérer des informations sur la localisation des autres membres.</p>\n\n<p>Comme nous savons que nous voulons un cluster à 3 nœuds etcd, et que tous nos serveurs ont des adresses IP statiques, nous utiliserons la découverte statique. Pour lancer notre cluster en utilisant la découverte statique, nous devons ajouter plusieurs points terminaux à notre fichier de configuration. Utilisez un éditeur pour ouvrir le fichier modèle <code>templates/etcd.conf.yaml.j2</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano templates/etcd.conf.yaml.j2\n</li></ul></code></pre>\n<p>Ajoutez les lignes en surbrillance suivantes :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/templates/etcd.conf.yaml.j2\">~/playground/etcd-ansible/templates/etcd.conf.yaml.j2</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">data-dir: /var/lib/etcd/{{ inventory_hostname }}.etcd\n<span class=\"highlight\">name: {{ inventory_hostname }}</span>\n<span class=\"highlight\">initial-advertise-peer-urls: http://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2380</span>\n<span class=\"highlight\">listen-peer-urls: http://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2380,http://127.0.0.1:2380</span>\n<span class=\"highlight\">advertise-client-urls: http://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2379</span>\n<span class=\"highlight\">listen-client-urls: http://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2379,http://127.0.0.1:2379</span>\n<span class=\"highlight\">initial-cluster-state: new</span>\n<span class=\"highlight\">initial-cluster: {% for host in groups['etcd'] %}{{ hostvars[host]['ansible_facts']['hostname'] }}=http://{{ hostvars[host]['ansible_facts']['eth1']['ipv4']['address'] }}:2380{% if not loop.last %},{% endif %}{% endfor %}</span>\n</code></pre>\n<p>Fermez et enregistrez le fichier <code>templates/etcd.conf.yaml.j2</code> en appuyant sur <code>CTRL+X</code> suivi de <code>Y</code> .</p>\n\n<p>Voici une brève explication de chaque point terminal :</p>\n\n<ul>\n<li><code>nom</code> - un nom lisible pour le membre. Par défaut, etcd utilise un identifiant unique, généré de manière aléatoire, pour identifier chaque membre ; cependant, un nom lisible par l'utilisateur nous permet de le référencer plus facilement à l'intérieur des fichiers de configuration et sur la ligne de commande. Ici, nous utiliserons les noms d'hôtes comme noms de membres (c'est-à-dire, <code>etcd1</code> , <code>etcd2</code> , et <code>etcd3</code> ).</li>\n<li><code>initial-advertise-peer-urls</code> - une liste d'adresses IP/combinaisons de ports que les autres membres peuvent utiliser pour communiquer avec ce membre. En plus du port API (<code>2379</code>), etcd expose également le port <code>2380</code> pour la communication entre les membres d'etcd, qui leur permet de s'envoyer des messages et d'échanger des données. Notez que ces URL doivent être accessibles par ses pairs (et ne pas être une adresse IP locale).</li>\n<li><code>listen-peer-urls</code> - une liste d'adresses IP/combinaisons de ports où le membre actuel écoutera les communications des autres membres. Cela doit inclure toutes les URL du drapeau <code>-initial-advertise-peer-urls</code>, mais aussi les URL locales comme <code>127.0.0.1:2380</code> . L'adresse IP de destination/le port des messages de pairs entrants doit correspondre à l'une des URL énumérées ici.</li>\n<li><code>advertise-client-urls</code> - une liste des combinaisons Adresse IP/port que les clients doivent utiliser pour communiquer avec ce membre. Ces URL doivent être accessibles par le client (et ne pas être une adresse locale). Si le client accède au cluster via l'Internet public, il doit s'agir d'une adresse IP publique.</li>\n<li><code>listen-client-urls</code> - une liste des combinaisons Adresses IP/ports où le membre actuel écoutera les communications des clients. Cela doit inclure toutes les URL du drapeau <code>--advertise-client-urls</code>, mais aussi les URL locales comme <code>127.0.0.1:2379</code> L'adresse IP de destination/le port des messages clients entrants doit correspondre à l'une des URL énumérées ici.</li>\n<li><code>groupe initial</code> - une liste de points terminaux pour chaque membre du groupe. Chaque point terminal doit correspondre aux URL <code>initial-advertise-peer-urls</code> du membre correspondant.</li>\n<li><code>initial-cluster-state</code> soi <code>new</code> ou <code>existing</code>.</li>\n</ul>\n\n<p>Pour assurer la cohérence, etcd ne peut prendre de décisions que lorsque la majorité des nœuds marche bien. C'est ce qu'on appelle établir le <em>quorum</em>. En d'autres termes, dans un groupe de trois membres, le quorum est atteint si deux ou plusieurs des membres fonctionnent bien.</p>\n\n<p>Si le paramètre <code>initial-cluster-state</code> est réglé sur <code>new</code>,<code>etcd</code> saura qu'il s'agit d'un nouveau cluster en cours de démarrage et permettra aux membres de commencer en parallèle, sans attendre que le quorum soit atteint. Plus concrètement, après l'entrée en fonction du premier membre, le quorum ne sera pas atteint car un tiers (33,33%) est inférieur ou égal à 50%. Normalement, etcd s'arrêtera et refusera d'engager d'autres actions et le cluster ne sera jamais formé. Cependant, comme <code>initial-cluster-state</code> a été fixé comme <code>new</code>, il ignorera le manque initial de quorum.</p>\n\n<p>S'il est fixé comme <code>existing</code>, le membre essaiera de rejoindre un groupe existant, et s'attend à ce que le quorum soit déjà établi.</p>\n\n<p><span class='note'><strong>Note :</strong> Vous pouvez trouver plus de détails sur tous les drapeaux de configuration pris en charge dans la section <a href=\"https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/configuration.md\">Configuration</a> de la documentation d'etcd.<br></span></p>\n\n<p>Dans le fichier modèle mis à jour <code>templates/etcd.conf.yaml.j2</code>, on trouve quelques exemples de <code>hostvars</code> .  Lorsque Ansible s'exécute , il recueillera des variables auprès d'une variété sources. Nous avons déjà utilisé la variable <code>inventory_hostname</code> auparavant, mais il y en a beaucoup d'autres disponibles. Ces variables sont disponibles sous <code>hostvars [inventory_hostname]['ansible_facts']</code> . Ici, nous extrayons les adresses IP privées de chaque nœud et les utilisons pour construire la valeur de notre point terminal.</p>\n\n<span class='note'><p>\n<strong>Note :</strong> Comme nous avons activé l'option <strong>Private Networking</strong> lors de la création de nos serveurs, chaque serveur serait associé à trois adresses IP :</p>\n\n<ul>\n<li>Une adresse IP  de<em>bouclage</em> - une adresse qui n'est valable qu'à l'intérieur de la même machine. Elle est utilisée pour que la machine se réfère à elle-même, par exemple, <code>127.0.0.1</code></li>\n<li>Une adresse IP <em>publique</em> - une adresse qui peut être acheminée sur l'Internet public, par exemple, <code>178.128.169.51</code> </li>\n<li>Une adresse IP <em>privée</em> - une adresse qui n'est routable qu'au sein du réseau privé ; dans le cas de DigitalOcean Droplets, il y a un réseau privé au sein de chaque centre de données, par exemple, <code>10.131.82.225</code></li>\n</ul>\n\n<p>Chacune de ces adresses IP est associée à une interface réseau différente : l'adresse de bouclage est associée à l'interface <code>lo</code>, l'adresse IP publique est associée à l'interface <code>eth0</code>, et l'adresse IP privée à l'interface <code>eth1</code>. Nous utilisons l'interface <code>eth1</code> pour que tout le trafic reste dans le réseau privé, sans jamais atteindre Internet.</p>\n\n<p>La compréhension des interfaces de réseau n'est pas nécessaire pour cet article, mais si vous souhaitez en savoir plus, <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-networking-terminology-interfaces-and-protocols\">Une introduction à la terminologie, aux interfaces et aux protocoles de réseau</a> est un excellent point de départ.<br></p></span>\n\n<p>La syntaxe <code>{% %}</code> Jinja2 définit la structure de la boucle <code>for</code> qui itére à travers chaque nœud du groupe <code>etcd</code> pour construire la chaîne du <code>cluster initial</code> dans un format requis par etcd.</p>\n\n<p>Pour former le nouveau cluster de trois membres, vous devez d'abord arrêter le service <code>etcd</code> et effacer le répertoire de données avant de lancer le cluster. Pour ce faire, utilisez un éditeur afin d'ouvrir le fichier <code>playbook.yaml</code> sur votre machine locale :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ensuite, avant la tâche <code>« Create a data directory »</code>, ajoutez une tâche pour arrêter le service <code>etcd</code> :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    ...\n        group: root\n        mode: 0644\n    <span class=\"highlight\">- name: \"Stop the etcd service\"</span>\n      <span class=\"highlight\">command: systemctl stop etcd</span>\n    - name: \"Create a data directory\"\n      file:\n    ...\n</code></pre>\n<p>Ensuite, mettez à jour la tâche <code>« Create a data directory »</code> pour d'abord supprimer le répertoire de données et le recréer :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  become: True\n  tasks:\n    ...\n    - name: \"Stop the etcd service\"\n      command: systemctl stop etcd\n    - name: \"Create a data directory\"\n      file:\n        path: /var/lib/etcd/{{ inventory_hostname }}.etcd\n        state: <span class=\"highlight\">\"{{ item }}\"</span>\n        owner: root\n        group: root\n        mode: 0755\n      <span class=\"highlight\">with_items:</span>\n        <span class=\"highlight\">- absent</span>\n        <span class=\"highlight\">- directory</span>\n    - name: \"Create directory for etcd configuration\"\n      file:\n    ...\n</code></pre>\n<p>La propriété <code>with_items</code> définit une liste de chaînes de caractères sur lesquelles cette tâche va itérer. Cela équivaut à répéter deux fois la même tâche, mais avec des valeurs différentes pour la propriété <code>state</code>. Dans ce cas, nous répétons la liste avec les éléments <code>absents</code> et <code>le répertoire</code>, ce qui garantit que le répertoire de données est d'abord supprimé et ensuite recréé.</p>\n\n<p>Fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code>, puis sur <code>Y</code>. Ensuite, lancez à nouveau <code>ansible-playbook</code>. Ansible va maintenant créer un cluster unique de 3 membres <code>etcd</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Vous pouvez vérifier cela en entrant en langage SSH dans n'importe quel nœud membre etcd :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd1_public_ip</span>\n</li></ul></code></pre>\n<p>Ensuite, lancez l'application <code>etcdctl endpoint health --cluster</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl endpoint health --cluster\n</li></ul></code></pre>\n<p>Le statut de chaque membre du groupe sera ainsi répertorié :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>http://<span class=\"highlight\">etcd2_private_ip</span>:2379 is healthy: successfully committed proposal: took = 2.517267ms\nhttp://<span class=\"highlight\">etcd1_private_ip</span>:2379 is healthy: successfully committed proposal: took = 2.153612ms\nhttp://<span class=\"highlight\">etcd3_private_ip</span>:2379 is healthy: successfully committed proposal: took = 2.639277ms\n</code></pre>\n<p>Nous avons maintenant réussi à créer un cluster de 3 nœuds etcd. Nous pouvons confirmer cela en ajoutant une entrée à etcd sur un nœud membre, et en la récupérant sur un autre nœud membre. Sur l'un des nœuds membres, lancez <code>etcdctl put</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl put foo \"bar\"\n</li></ul></code></pre>\n<p>Ensuite, utilisez un nouveau terminal pour SSH dans un autre nœud membre :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd2_public_ip</span>\n</li></ul></code></pre>\n<p>Ensuite, essayez de retrouver la même entrée en utilisant la clé :</p>\n<pre class=\"code-pre custom_prefix prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd2:~#\">etcdctl get foo\n</li></ul></code></pre>\n<p>Vous pourrez récupérer l'entrée, qui prouve que le cluster fonctionne :</p>\n<pre class=\"code-pre  third-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>foo\nbar\n</code></pre>\n<p>Enfin, sortez de chacun des nœuds gérés et revenez à votre machine locale :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">exit\n</li></ul></code></pre><pre class=\"code-pre custom_prefix prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd2:~#\">exit\n</li></ul></code></pre>\n<p>Dans cette étape, nous avons mis en place un nouveau cluster de 3 nœuds. À l'heure actuelle, la communication entre les membres d&rsquo;<code>etcd</code> et leurs pairs et clients se fait par HTTP. Cela signifie que la communication n'est pas cryptée et que toute partie qui peut intercepter le trafic peut lire les messages. Ce n'est pas un gros problème si le cluster <code>etcd</code> et les clients sont tous déployés dans un réseau privé ou un <em>réseau privé virtuel</em> (VPN) que vous contrôlez entièrement. Toutefois, si une partie du trafic doit passer par un réseau partagé (privé ou public), vous devez alors vous assurer que ce trafic est crypté. En outre, un mécanisme doit être mis en place pour qu'un client ou un pair puisse vérifier l'authenticité du serveur.</p>\n\n<p>Dans la prochaine étape, nous examinerons comment sécuriser la communication client-serveur et la communication entre pairs en utilisant le TLS.</p>\n\n<h2 id=\"Étape-9-obtenir-les-adresses-ip-privées-des-nœuds-gérés\">Étape 9 - Obtenir les adresses IP privées des nœuds gérés</h2>\n\n<p>Pour crypter les messages entre les nœuds membres, etcd utilise <em>Hypertext Transfer Protocol Secure</em> , ou <em>HTTPS</em> , qui est une couche au-dessus du protocole <em>TLS</em> , ou <em>Transport Layer Security</em> . TLS utilise un système de clés privées, de certificats et d'entités de confiance appelées <em>Certificate Authorities</em> (Autorités de certification) (CA) pour s'authentifier et s'envoyer des messages cryptés.</p>\n\n<p>Dans ce tutoriel, chaque nœud membre doit générer un certificat pour s'identifier, et faire signer ce certificat par une AC. Nous allons configurer tous les nœuds membres pour qu'ils fassent confiance à cette AC, et donc aussi à tous les certificats qu'elle signe. Cela permet aux nœuds membres de s'authentifier mutuellement.</p>\n\n<p>Le certificat qu'un nœud membre génère doit permettre aux autres nœuds membres de s'identifier. Tous les certificats comportent le <em>Common Name</em> (Nom Commun) (CN) de l'entité à laquelle il est associé. Cela est souvent utilisé comme identité de l'entité. Toutefois, lors de la vérification d'un certificat, les clients peuvent comparer si les informations qu'ils ont recueillies sur l'entité correspondent à celles qui figurent dans le certificat. Par exemple, lorsqu'un client télécharge le certificat TLS avec l'objet <code>CN=foo.bar.com</code>, mais qu'il se connecte en fait au serveur en utilisant une adresse IP (par exemple <code>167.71.129.110</code>), il y a alors un décalage et le client peut ne pas faire confiance au certificat. En spécifiant un <em>nom alternatif du sujet</em> (SAN) dans le certificat, il informe le vérificateur que les deux noms appartiennent à la même entité.</p>\n\n<p>Comme nos membres etcd s'échangent des informations en utilisant leurs adresses IP privées, lorsque nous définirons nos certificats, nous devrons fournir ces adresses IP privées comme noms alternatifs du sujet.</p>\n\n<p>Pour connaître l'adresse IP privée d'un nœud géré, il faut y entrer en SSH :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd1_public_ip</span>\n</li></ul></code></pre>\n<p>Exécutez ensuite la commande suivante :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">ip -f inet addr show eth1\n</li></ul></code></pre>\n<p>Vous trouverez des résultats similaires aux lignes suivantes :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    inet <span class=\"highlight\">10.131.255.176</span>/16 brd 10.131.255.255 scope global eth1\n       valid_lft forever preferred_lft forever\n</code></pre>\n<p>Dans notre exemple de sortie, <code><span class=\"highlight\">10.131.255.176</span></code> est l'adresse IP privée du nœud géré, et la seule information qui nous intéresse. Pour filtrer tout le reste, à l'exception de la propriété intellectuelle privée, nous pouvons transmettre la sortie de la commande <code>ip</code> à l&rsquo;<a href=\"https://www.digitalocean.com/community/tutorials/the-basics-of-using-the-sed-stream-editor-to-manipulate-text-in-linux\">utilitaire <code>sed</code></a>, qui est utilisé pour filtrer et transformer le texte.</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">ip -f inet addr show eth1 | sed -En -e 's/.*inet ([0-9.]+).*/\\1/p'\n</li></ul></code></pre>\n<p>Maintenant, la seule sortie est l'adresse IP privée elle-même :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div><span class=\"highlight\">10.131.255.176</span>\n</code></pre>\n<p>Une fois que vous êtes convaincu que la commande précédente fonctionne, quittez le nœud géré :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">exit\n</li></ul></code></pre>\n<p>Pour incorporer les commandes précédentes dans notre playbook, ouvrez d'abord le fichier <code>playbook.yaml</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ensuite, ajoutez une nouvelle pièce avec une seule tâche avant notre play existante :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n<span class=\"highlight\">- hosts: etcd</span>\n<span class=\"highlight\">  tasks:</span>\n<span class=\"highlight\">    - shell: ip -f inet addr show eth1 | sed -En -e 's/.*inet ([0-9.]+).*/\\1/p'</span>\n<span class=\"highlight\">      register: privateIP</span>\n- hosts: etcd\n  tasks:\n...\n</code></pre>\n<p>La tâche utilise le module <code>shell</code> pour exécuter les commandes <code>ip</code> et <code>sed</code>, qui récupère l'adresse IP privée du nœud géré. Elle <em>enregistre</em> ensuite la valeur de retour de la commande shell dans une variable appelée <code>privateIP</code> , que nous utiliserons plus tard.</p>\n\n<p>Dans cette étape, nous avons ajouté une tâche au playbook pour obtenir l'adresse IP privée des nœuds gérés. Dans l'étape suivante, nous allons utiliser ces informations pour générer des certificats pour chaque nœud membre, et faire signer ces certificats par une autorité de certification (CA).</p>\n\n<h2 id=\"Étape-10-générer-les-clés-privées-et-les-rse-des-membres-d-39-etcd\">Étape 10 - Générer les clés privées et les RSE des membres d'etcd</h2>\n\n<p>Pour qu'un nœud membre puisse recevoir un trafic crypté, l'expéditeur doit utiliser la clé publique du nœud membre pour crypter les données, et le nœud membre doit utiliser sa clé privée pour décrypter le texte chiffré et récupérer les données originales. La clé publique est emballée dans un certificat et signée par une AC pour garantir son authenticité.</p>\n\n<p>Par conséquent, nous devrons générer une clé privée et une demande de signature de certificat (CSR) pour chaque nœud membre etcd. Pour nous faciliter la tâche, nous allons générer toutes les paires de clés et signer tous les certificats localement, sur le nœud de contrôle, puis copier les fichiers pertinents vers les hôtes gérés.</p>\n\n<p>Tout d'abord, créez un répertoire appelé <code>artefacts/</code>, où nous placerons les fichiers (clés et certificats) générés au cours du processus. Ouvrez le fichier <code>playbook.yaml</code> avec un éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Dans celui-ci, utilisez le module <code>file</code> pour créer le répertoire <code>artefacts/</code> :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n    - shell: ip -f inet addr show eth1 | sed -En -e 's/.*inet ([0-9.]+).*/\\1/p'\n      register: privateIP\n<span class=\"highlight\">- hosts: localhost</span>\n<span class=\"highlight\">  gather_facts: False</span>\n<span class=\"highlight\">  become: False</span>\n<span class=\"highlight\">  tasks:</span>\n<span class=\"highlight\">    - name: \"Create ./artifacts directory to house keys and certificates\"</span>\n<span class=\"highlight\">      file:</span>\n<span class=\"highlight\">        path: ./artifacts</span>\n<span class=\"highlight\">        state: directory</span>\n- hosts: etcd\n  tasks:\n...\n</code></pre>\n<p>Ensuite, ajoutez une autre tâche à la fin du play pour générer la clé privée :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n- hosts: localhost\n  gather_facts: False\n  become: False\n  tasks:\n        ...\n<span class=\"highlight\">    - name: \"Generate private key for each member\"</span>\n<span class=\"highlight\">      openssl_privatekey:</span>\n<span class=\"highlight\">        path: ./artifacts/{{item}}.key</span>\n<span class=\"highlight\">        type: RSA</span>\n<span class=\"highlight\">        size: 4096</span>\n<span class=\"highlight\">        state: present</span>\n<span class=\"highlight\">        force: True</span>\n<span class=\"highlight\">      with_items: \"{{ groups['etcd'] }}\"</span>\n- hosts: etcd\n  tasks:\n...\n</code></pre>\n<p>La création de clés privées et de CSR peut se faire en utilisant respectivement les modules <a href=\"https://docs.ansible.com/ansible/latest/modules/openssl_privatekey_module.html\"><code>openssl_privatekey</code></a> et <a href=\"https://docs.ansible.com/ansible/latest/modules/openssl_csr_module.html\"><code>openssl_csr</code></a>.</p>\n\n<p>L'attribut <code>force : True</code> garantit que la clé privée est régénérée à chaque fois, même si elle existe déjà.</p>\n\n<p>De même, ajoutez la nouvelle tâche suivante au même play pour générer les RSE pour chaque membre, en utilisant le module <code>openssl_csr</code> :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">...\n- hosts: localhost\n  gather_facts: False\n  become: False\n  tasks:\n    ...\n    - name: \"Generate private key for each member\"\n      openssl_privatekey:\n        ...\n      with_items: \"{{ groups['etcd'] }}\"\n    <span class=\"highlight\">- name: \"Generate CSR for each member\"</span>\n      <span class=\"highlight\">openssl_csr:</span>\n        <span class=\"highlight\">path: ./artifacts/{{item}}.csr</span>\n        <span class=\"highlight\">privatekey_path: ./artifacts/{{item}}.key</span>\n        <span class=\"highlight\">common_name: \"{{item}}\"</span>\n        <span class=\"highlight\">key_usage:</span>\n          <span class=\"highlight\">- digitalSignature</span>\n        <span class=\"highlight\">extended_key_usage:</span>\n          <span class=\"highlight\">- serverAuth</span>\n        <span class=\"highlight\">subject_alt_name:</span>\n          <span class=\"highlight\">- IP:{{ hostvars[item]['privateIP']['stdout']}}</span>\n          <span class=\"highlight\">- IP:127.0.0.1</span>\n        <span class=\"highlight\">force: True</span>\n      <span class=\"highlight\">with_items: \"{{ groups['etcd'] }}\"</span>\n</code></pre>\n<p>Nous précisons que ce certificat peut être impliqué dans un mécanisme de signature numérique à des fins d'authentification du serveur. Ce certificat est associé au nom d'hôte (par exemple, <code>etcd1</code> ), mais le vérificateur doit également traiter les adresses IP privées et de boucle locale de chaque nœud comme des noms alternatifs.  Notez que nous utilisons la variable <code>privateIP</code> que nous avons enregistrée dans le play précédente.</p>\n\n<p>Fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code> suivi de <code>Y</code>. Ensuite, lancez à nouveau ansible-playbook.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Nous allons maintenant trouver un nouveau répertoire appelé <code>artefacts</code> dans notre répertoire de projets ; utilisez <code>ls</code> pour en énumérer le contenu :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ls artifacts\n</li></ul></code></pre>\n<p>Vous trouverez les clés privées et les RSE de chacun des membres d'etcd :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>etcd1.csr  etcd1.key  etcd2.csr  etcd2.key  etcd3.csr  etcd3.key\n</code></pre>\n<p>Dans cette étape, nous avons utilisé plusieurs modules Ansible pour générer des clés privées et des certificats de clé publique pour chacun des nœuds membres. Dans la prochaine étape, nous examinerons comment signer une demande de signature de certificat (CSR).</p>\n\n<h2 id=\"Étape-11-génération-des-certificats-ca\">Étape 11 - Génération des certificats CA</h2>\n\n<p>Au sein d'un cluster etcd, les nœuds membres cryptent les messages en utilisant la clé publique du destinataire. Pour garantir l'authenticité de la clé publique, le destinataire l'emballe dans une demande de signature de certificat (CSR) et la fait signer par une entité de confiance (c'est-à-dire l'AC). Comme nous contrôlons tous les nœuds membres et les AC auxquelles ils font confiance, nous n'avons pas besoin d'utiliser une AC externe et pouvons agir comme notre propre AC. Dans cette étape, nous allons agir comme notre propre AC, ce qui signifie que nous devrons générer une clé privée et un certificat auto-signé pour fonctionner etant qu'AC.</p>\n\n<p>Ouvrez le fichier <code>playbook.yaml</code> avec votre éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ensuite, comme pour l'étape précédente, ajoutez une tâche au play <code>localhost</code> pour générer une clé privée pour l'AC :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: localhost\n  ...\n  tasks:\n    ...\n  - name: \"Generate CSR for each member\"\n    ...\n    with_items: \"{{ groups['etcd'] }}\"\n    <span class=\"highlight\">- name: \"Generate private key for CA\"</span>\n      <span class=\"highlight\">openssl_privatekey:</span>\n        <span class=\"highlight\">path: ./artifacts/ca.key</span>\n        <span class=\"highlight\">type: RSA</span>\n        <span class=\"highlight\">size: 4096</span>\n        <span class=\"highlight\">state: present</span>\n        <span class=\"highlight\">force: True</span>\n- hosts: etcd\n  become: True\n  tasks:\n    - name: \"Create directory for etcd binaries\"\n...\n</code></pre>\n<p>Ensuite, utilisez le module <code>openssl_csr</code> pour générer un nouveau CSR. Cette étape est similaire à la précédente, mais dans ce CSR, nous ajoutons la contrainte de base et l'extension d'utilisation des clés pour indiquer que ce certificat peut être utilisé comme un certificat CA :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: localhost\n  ...\n  tasks:\n    ...\n    - name: \"Generate private key for CA\"\n      openssl_privatekey:\n        path: ./artifacts/ca.key\n        type: RSA\n        size: 4096\n        state: present\n        force: True\n    <span class=\"highlight\">- name: \"Generate CSR for CA\"</span>\n      <span class=\"highlight\">openssl_csr:</span>\n        <span class=\"highlight\">path: ./artifacts/ca.csr</span>\n        <span class=\"highlight\">privatekey_path: ./artifacts/ca.key</span>\n        <span class=\"highlight\">common_name: ca</span>\n        <span class=\"highlight\">organization_name: \"Etcd CA\"</span>\n        <span class=\"highlight\">basic_constraints:</span>\n          <span class=\"highlight\">- CA:TRUE</span>\n          <span class=\"highlight\">- pathlen:1</span>\n        <span class=\"highlight\">basic_constraints_critical: True</span>\n        <span class=\"highlight\">key_usage:</span>\n          <span class=\"highlight\">- keyCertSign</span>\n          <span class=\"highlight\">- digitalSignature</span>\n        <span class=\"highlight\">force: True</span>\n- hosts: etcd\n  become: True\n  tasks:\n    - name: \"Create directory for etcd binaries\"\n...\n</code></pre>\n<p>Enfin, utilisez le module <a href=\"https://docs.ansible.com/ansible/2.4/openssl_certificate_module.html\"><code>openssl_certificate</code></a> pour auto-signer le CSR :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: localhost\n  ...\n  tasks:\n    ...\n    - name: \"Generate CSR for CA\"\n      openssl_csr:\n        path: ./artifacts/ca.csr\n        privatekey_path: ./artifacts/ca.key\n        common_name: ca\n        organization_name: \"Etcd CA\"\n        basic_constraints:\n          - CA:TRUE\n          - pathlen:1\n        basic_constraints_critical: True\n        key_usage:\n          - keyCertSign\n          - digitalSignature\n        force: True\n    <span class=\"highlight\">- name: \"Generate self-signed CA certificate\"</span>\n      <span class=\"highlight\">openssl_certificate:</span>\n        <span class=\"highlight\">path: ./artifacts/ca.crt</span>\n        <span class=\"highlight\">privatekey_path: ./artifacts/ca.key</span>\n        <span class=\"highlight\">csr_path: ./artifacts/ca.csr</span>\n        <span class=\"highlight\">provider: selfsigned</span>\n        <span class=\"highlight\">force: True</span>\n- hosts: etcd\n  become: True\n  tasks:\n    - name: \"Create directory for etcd binaries\"\n...\n</code></pre>\n<p>Fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code> suivi de <code>Y</code>. Ensuite, relancez notre playbook pour appliquer les changements :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Vous pouvez également lancer <code>ls</code> pour vérifier le contenu du répertoire <code>artefacts/</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ls artifacts/\n</li></ul></code></pre>\n<p>Vous trouverez maintenant le certificat CA nouvellement généré ( <code>ca.crt</code> ) :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div><span class=\"highlight\">ca.crt  ca.csr  ca.key</span>  etcd1.csr  etcd1.key  etcd2.csr  etcd2.key  etcd3.csr  etcd3.key\n</code></pre>\n<p>Dans cette étape, nous avons généré une clé privée et un certificat auto-signé pour l'AC. Dans la prochaine étape, nous utiliserons le certificat de l'AC pour signer la RSE de chaque membre.</p>\n\n<h2 id=\"Étape-12-signature-des-rse-des-membres-d-39-etcd\">Étape 12 - Signature des RSE des membres d'etcd</h2>\n\n<p>Dans cette étape, nous allons signer la RSE de chaque nœud membre. Cela sera similaire à la manière dont nous avons utilisé le module <code>openssl_certificate</code> pour auto-signer le certificat CA, mais au lieu d'utiliser le fournisseur <code>auto-signé</code>, nous utiliserons le fournisseur <code>ownca</code>, qui nous permet de signer en utilisant notre propre certificat CA.</p>\n\n<p>Ouvrez votre playbook :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Ajoutez la tâche en surbrillance suivante à la tâche <code>« Generate self-signed CA certificate »</code> (Générer un certificat CA auto-signé) :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: localhost\n  ...\n  tasks:\n    ...\n    - name: \"Generate self-signed CA certificate\"\n      openssl_certificate:\n        path: ./artifacts/ca.crt\n        privatekey_path: ./artifacts/ca.key\n        csr_path: ./artifacts/ca.csr\n        provider: selfsigned\n        force: True\n    <span class=\"highlight\">- name: \"Generate an `etcd` member certificate signed with our own CA certificate\"</span>\n      <span class=\"highlight\">openssl_certificate:</span>\n        <span class=\"highlight\">path: ./artifacts/{{item}}.crt</span>\n        <span class=\"highlight\">csr_path: ./artifacts/{{item}}.csr</span>\n        <span class=\"highlight\">ownca_path: ./artifacts/ca.crt</span>\n        <span class=\"highlight\">ownca_privatekey_path: ./artifacts/ca.key</span>\n        <span class=\"highlight\">provider: ownca</span>\n        <span class=\"highlight\">force: True</span>\n      <span class=\"highlight\">with_items: \"{{ groups['etcd'] }}\"</span>\n- hosts: etcd\n  become: True\n  tasks:\n    - name: \"Create directory for etcd binaries\"\n...\n</code></pre>\n<p>Fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code> suivi de <code>Y</code> . Ensuite, relancez le playbook pour appliquer les modifications :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Maintenant, énumérez le contenu du répertoire <code>artefacts</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ls artifacts/\n</li></ul></code></pre>\n<p>Vous y trouverez la clé privée, le CSR et le certificat de chaque membre de l'etcd et de l'AC :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>ca.crt  ca.csr  ca.key  etcd1.crt  etcd1.csr  etcd1.key  etcd2.crt  etcd2.csr  etcd2.key  etcd3.crt  etcd3.csr  etcd3.key\n</code></pre>\n<p>Dans cette étape, nous avons signé les RSE de chaque nœud membre en utilisant la clé de l'AC. Dans l'étape suivante, nous allons copier les fichiers pertinents dans chaque nœud géré, de sorte qu'etcd ait accès aux clés et aux certificats pertinents pour établir les connexions TLS.</p>\n\n<h2 id=\"Étape-13-copie-de-clés-privées-et-de-certificats\">Étape 13 - Copie de clés privées et de certificats</h2>\n\n<p>Chaque nœud doit avoir une copie du certificat auto-signé de l'AC ( <code>ca.crt</code> ). Chaque nœud membre d&rsquo;<code>etcd</code> doit également avoir sa propre clé privée et son certificat. Dans cette étape, nous allons télécharger ces fichiers et les placer dans un nouveau répertoire <code>/etc/etcd/ssl/</code>.</p>\n\n<p>Pour commencer, ouvrez le fichier <code>playbook.yaml</code> avec votre éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/playbook.yaml\n</li></ul></code></pre>\n<p>Pour effectuer ces changements sur notre playbook Ansible, il faut d'abord mettre à jour la propriété <code>du chemin</code> de la tâche <code>Create directory for etcd configuration</code> pour créer le répertoire <code>/etc/etcd/ssl/</code> :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  ...\n  tasks:\n    ...\n      with_items:\n        - absent\n        - directory\n    - name: \"Create directory for etcd configuration\"\n      file:\n        path: <span class=\"highlight\">\"{{ item }}\"</span>\n        state: directory\n        owner: root\n        group: root\n        mode: 0755\n      <span class=\"highlight\">with_items:</span>\n        <span class=\"highlight\">- /etc/etcd</span>\n        <span class=\"highlight\">- /etc/etcd/ssl</span>\n    - name: \"Create configuration file for etcd\"\n      template:\n...\n</code></pre>\n<p>Ensuite, à la suite de la tâche modifiée, ajoutez trois autres tâches pour copier les fichiers par-dessus :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/playbook.yaml\">~/playground/etcd-ansible/playbook.yaml</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">- hosts: etcd\n  ...\n  tasks:\n    ...\n    <span class=\"highlight\">- name: \"Copy over the CA certificate\"</span>\n      <span class=\"highlight\">copy:</span>\n        <span class=\"highlight\">src: ./artifacts/ca.crt</span>\n        <span class=\"highlight\">remote_src: False</span>\n        <span class=\"highlight\">dest: /etc/etcd/ssl/ca.crt</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0644</span>\n    <span class=\"highlight\">- name: \"Copy over the `etcd` member certificate\"</span>\n      <span class=\"highlight\">copy:</span>\n        <span class=\"highlight\">src: ./artifacts/{{inventory_hostname}}.crt</span>\n        <span class=\"highlight\">remote_src: False</span>\n        <span class=\"highlight\">dest: /etc/etcd/ssl/server.crt</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0644</span>\n    <span class=\"highlight\">- name: \"Copy over the `etcd` member key\"</span>\n      <span class=\"highlight\">copy:</span>\n        <span class=\"highlight\">src: ./artifacts/{{inventory_hostname}}.key</span>\n        <span class=\"highlight\">remote_src: False</span>\n        <span class=\"highlight\">dest: /etc/etcd/ssl/server.key</span>\n        <span class=\"highlight\">owner: root</span>\n        <span class=\"highlight\">group: root</span>\n        <span class=\"highlight\">mode: 0600</span>\n    - name: \"Create configuration file for etcd\"\n      template:\n...\n</code></pre>\n<p>Fermez et enregistrez le fichier <code>playbook.yaml</code> en appuyant sur <code>CTRL+X</code>, puis sur <code>Y</code>.</p>\n\n<p>Lancez de nouveau <code>ansible-playbook</code> pour apporter ces changements :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Dans cette étape, nous avons réussi à télécharger les clés privées et les certificats vers les nœuds gérés. Après avoir copié les fichiers, nous devons maintenant mettre à jour notre fichier de configuration etcd pour pouvoir les utiliser.</p>\n\n<h2 id=\"Étape-14-activer-le-tls-sur-etcd\">Étape 14 - Activer le TLS sur etcd</h2>\n\n<p>Dans la dernière étape de ce tutoriel, nous allons mettre à jour certaines configurations Ansible pour activer TLS dans un cluster etcd.</p>\n\n<p>Tout d'abord, ouvrez le fichier modèle <code>templates/etcd.conf.yaml.j2</code> à l'aide de votre éditeur :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano $HOME/playground/etcd-ansible/templates/etcd.conf.yaml.j2\n</li></ul></code></pre>\n<p>Une fois à l'intérieur, modifiez toutes les URL pour utiliser le protocole <code>https</code> au lieu de <code>http</code>.  De plus, ajoutez une section à la fin du modèle pour spécifier l'emplacement du certificat de l'AC, du certificat du serveur et de la clé du serveur :</p>\n<div class=\"code-label \" title=\"~/playground/etcd-ansible/templates/etcd.conf.yaml.j2\">~/playground/etcd-ansible/templates/etcd.conf.yaml.j2</div><pre class=\"code-pre \"><code class=\"code-highlight language-yaml\">data-dir: /var/lib/etcd/{{ inventory_hostname }}.etcd\nname: {{ inventory_hostname }}\ninitial-advertise-peer-urls: http<span class=\"highlight\">s</span>://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2380\nlisten-peer-urls: http<span class=\"highlight\">s</span>://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2380,http<span class=\"highlight\">s</span>://127.0.0.1:2380\nadvertise-client-urls: http<span class=\"highlight\">s</span>://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2379\nlisten-client-urls: http<span class=\"highlight\">s</span>://{{ hostvars[inventory_hostname]['ansible_facts']['eth1']['ipv4']['address'] }}:2379,http<span class=\"highlight\">s</span>://127.0.0.1:2379\ninitial-cluster-state: new\ninitial-cluster: {% for host in groups['etcd'] %}{{ hostvars[host]['ansible_facts']['hostname'] }}=http<span class=\"highlight\">s</span>://{{ hostvars[host]['ansible_facts']['eth1']['ipv4']['address'] }}:2380{% if not loop.last %},{% endif %}{% endfor %}\n\n<span class=\"highlight\">client-transport-security:</span>\n<span class=\"highlight\">  cert-file: /etc/etcd/ssl/server.crt</span>\n<span class=\"highlight\">  key-file: /etc/etcd/ssl/server.key</span>\n<span class=\"highlight\">  trusted-ca-file: /etc/etcd/ssl/ca.crt</span>\n<span class=\"highlight\">peer-transport-security:</span>\n<span class=\"highlight\">  cert-file: /etc/etcd/ssl/server.crt</span>\n<span class=\"highlight\">  key-file: /etc/etcd/ssl/server.key</span>\n<span class=\"highlight\">  trusted-ca-file: /etc/etcd/ssl/ca.crt</span>\n</code></pre>\n<p>Fermez et enregistrez le fichier <code>templates/etcd.conf.yaml.j2</code></p>\n\n<p>Ensuite, lancez votre playbook Ansible :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ansible-playbook -i hosts playbook.yaml\n</li></ul></code></pre>\n<p>Puis, SSH dans l'un des nœuds gérés :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd1_public_ip</span>\n</li></ul></code></pre>\n<p>Une fois à l'intérieur, lancez la commande <code>etcdctl endpoint health</code> pour vérifier si les terminaux utilisent le HTTPS, et si tous les membres sont en bon état :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl --cacert /etc/etcd/ssl/ca.crt endpoint health --cluster\n</li></ul></code></pre>\n<p>Comme notre certificat CA n'est pas, par défaut, un certificat CA root de confiance installé dans le répertoire <code>/etc/ssl/certs/</code>, nous devons le passer à <code>etcdctl</code> en utilisant le drapeau <code>--cacert</code>.</p>\n\n<p>Cela donnera le résultat suivant :</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://<span class=\"highlight\">etcd3_private_ip</span>:2379 is healthy: successfully committed proposal: took = 19.237262ms\nhttps://<span class=\"highlight\">etcd1_private_ip</span>:2379 is healthy: successfully committed proposal: took = 4.769088ms\nhttps://<span class=\"highlight\">etcd2_private_ip</span>:2379 is healthy: successfully committed proposal: took = 5.953599ms\n</code></pre>\n<p>Pour confirmer que le cluster <code>etcd</code> fonctionne réellement, nous pouvons, une fois de plus, créer une entrée sur un nœud membre et la récupérer à partir d'un autre nœud membre :</p>\n<pre class=\"code-pre custom_prefix prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd1:~#\">etcdctl --cacert /etc/etcd/ssl/ca.crt put foo \"bar\"\n</li></ul></code></pre>\n<p>Ensuite, utilisez un nouveau terminal pour SSH dans un autre nœud membre :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ssh <span class=\"highlight\">root</span>@<span class=\"highlight\">etcd2_public_ip</span>\n</li></ul></code></pre>\n<p>Récupérez maintenant la même entrée en utilisant la clé <code>foo</code> :</p>\n<pre class=\"code-pre custom_prefix prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"root@etcd2:~#\">etcdctl --cacert /etc/etcd/ssl/ca.crt get foo\n</li></ul></code></pre>\n<p>Ceci renverra l'entrée, montrant la sortie ci-dessous :</p>\n<pre class=\"code-pre  third-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>foo\nbar\n</code></pre>\n<p>Vous pouvez faire la même chose sur le troisième nœud pour vous assurer que les trois membres sont opérationnels.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Vous avez maintenant approvisionné avec succès un cluster de 3 nœuds etcd, l'avez sécurisé avec TLS et avez confirmé qu'il fonctionne.</p>\n\n<p>etcd est un outil créé à l'origine par <a href=\"https://coreos.com/\">CoreOS</a> .  Pour comprendre l'utilisation d'etcd par rapport à CoreOS, vous pouvez lire <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-etcdctl-and-etcd-coreos-s-distributed-key-value-store\">Comment utiliser Etcdctl et Etcd, le Distributed Key-Value Store de CoreOS</a> .  L'article vous guide également dans la mise en place d'un modèle de découverte dynamique, ce qui a été discuté mais non démontré dans ce tutoriel.</p>\n\n<p>Comme mentionné au début de ce tutoriel, etcd est une partie importante de l'écosystème de Kubernetes. Pour en savoir plus sur Kubernetes et le rôle d'etcd en son sein, vous pouvez lire <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-kubernetes\">Une introduction à Kubernetes</a>. Si vous déployez etcd dans le cadre d'un cluster Kubernetes, sachez que d'autres outils sont disponibles, tels que <a href=\"https://github.com/kubernetes-sigs/kubespray\">kubespray</a> et <a href=\"https://kubernetes.io/docs/reference/setup-tools/kubeadm/\"><code>kubeadm</code></a> . Pour plus de détails sur ce dernier point, vous pouvez lire <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-cluster-using-kubeadm-on-ubuntu-18-04\">Comment créer un cluster Kubernetes en utilisant Kubeadm sur Ubuntu 18.04</a>.</p>\n\n<p>Enfin, ce tutoriel a fait appel à de nombreux outils, mais n'a pu se plonger dans chacun d'entre eux de manière trop détaillée. Vous trouverez ci-dessous des liens qui vous permettront d'examiner plus en détail chaque outil :</p>\n\n<ul>\n<li>Pour en savoir plus sur la syntaxe avancée des playbooks Ansible, vous pouvez lire <a href=\"https://www.digitalocean.com/community/tutorials/configuration-management-101-writing-ansible-playbooks\">Gestion de la configuration 101 : Écrire des playbooks Ansible</a>. La présentation officielle <a href=\"https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html\">d'Ansible sur les Playbooks</a> constitue également une excellente ressource.</li>\n<li>Pour en savoir plus sur OpenSSL, vous pouvez lire <a href=\"https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs\">Notions de base OpenSSL : travailler avec les certificats SSL, les clés privées et les CSR</a>.</li>\n</ul>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:31 +0000","feedId":8037,"bgimg":"","linkMd5":"780df2c0c82f37eebedffd98ce3615e0","bgimgJsdelivr":"","metaImg":"","author":"Daniel Li","publishedOrCreatedDate":1598860106967},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"How To Handle DOM and Window Events with React","link":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","description":"<p><em>The author selected <a href=\"https://creativecommons.org/\">Creative Commons</a> to receive a donation as part of the <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> program.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>In web development, <a href=\"https://www.digitalocean.com/community/tutorials/understanding-events-in-javascript\">events</a> represent actions that happen in the web browser. By responding to events with <a href=\"https://www.digitalocean.com/community/tutorials/understanding-events-in-javascript#event-handlers-and-event-listeners\">event handlers</a>, you can create dynamic <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-javascript\">JavaScript</a> applications that respond to any user action, including clicking with a mouse, scrolling along a webpage, touching a touch screen, and more.</p>\n\n<p>In <a href=\"https://reactjs.org/\">React</a> apps, you can use event handlers to update <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-on-react-class-components\">state data</a>, trigger <a href=\"https://www.digitalocean.com/community/tutorials/how-to-customize-react-components-with-props\">prop</a> changes, or prevent default browser actions. To do this, React uses a <code>SyntheticEvent</code> wrapper instead of the native <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Event\"><code>Event</code> interface</a>. <code>SyntheticEvent</code> closely emulates the standard browser event, but provides more consistent behavior for different web browsers. React also gives you tools to safely add and remove a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Window\"><code>Window</code></a> event listener when a component mounts and unmounts from the <a href=\"https://www.digitalocean.com/community/tutorials/introduction-to-the-dom\">Document Object Model (DOM)</a>, giving you control over <code>Window</code> events while preventing <a href=\"https://en.wikipedia.org/wiki/Memory_leak\">memory leaks</a> from improperly removed listeners.</p>\n\n<p>In this tutorial, you&rsquo;ll learn how to handle events in React. You&rsquo;ll build several sample components that handle user events, including a self-validating input component and an informative tooltip for the input form. Throughout the tutorial, you&rsquo;ll learn how to add event handlers to components, pull information from the <code>SyntheticEvent</code>, and add and remove <code>Window</code> event listeners. By the end of this tutorial, you&rsquo;ll be able to work with a variety of event handlers and apply the catalog of <a href=\"https://reactjs.org/docs/events.html#supported-events\">events supported by React</a>.</p>\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\n<ul>\n<li><p>You will need a development environment running <a href=\"https://nodejs.org/en/about/\">Node.js</a>; this tutorial was tested on Node.js version 10.22.0 and npm version 6.14.6. To install this on macOS or Ubuntu 18.04, follow the steps in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">How to Install Node.js and Create a Local Development Environment on macOS</a> or the <strong>Installing Using a PPA</strong> section of <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">How To Install Node.js on Ubuntu 18.04</a>.</p></li>\n<li><p>A React development environment set up with <a href=\"https://github.com/facebook/create-react-app\">Create React App</a>, with the non-essential boilerplate removed. To set this up, follow <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-on-react-class-components#step-1-%E2%80%94-creating-an-empty-project\"><strong>Step 1 — Creating an Empty Project</strong> of the How To Manage State on React Class Components tutorial</a>. This tutorial will use <code>events-tutorial</code> as the project name.</p></li>\n<li><p>You will also need a basic knowledge of JavaScript and HTML, which you can find in our <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-build-a-website-with-html\">How To Build a Website with HTML series</a> and in <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-javascript\">How To Code in JavaScript</a>. Basic knowledge of CSS would also be useful, which you can find at the <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS\">Mozilla Developer Network</a>.</p></li>\n<li><p>You will be using React components, the <code>useState</code> Hook, and the <code>useReducer</code> Hook, which you can learn about in our tutorials <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-custom-components-in-react\">How To Create Custom Components in React</a> and <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-with-hooks-on-react-components\">How To Manage State with Hooks on React Components</a>.</p></li>\n</ul>\n\n<h2 id=\"step-1-—-extracting-event-data-with-syntheticevent\">Step 1 — Extracting Event Data with <code>SyntheticEvent</code></h2>\n\n<p>In this step, you&rsquo;ll create a validating component using an <code>&lt;input&gt;</code> HTML element and the <code>onChange</code> event handler. This component will accept input and <em>validate</em> it, or make sure that the content adheres to a specific text pattern. You&rsquo;ll use the <code>SyntheticEvent</code> wrapper to pass event data into the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-asynchronous-code-in-node-js#asynchronous-programming-with-callbacks\">callback function</a> and update the component using the data from the <code>&lt;input&gt;</code>. You will also call <a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-javascript\">functions</a> from the <code>SyntheticEvent</code>, such as <code>preventDefault</code> to prevent standard browser actions.</p>\n\n<p>In React, you don&rsquo;t need to select elements before adding event listeners. Instead, you add event handlers directly to your <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-react-elements-with-jsx\">JSX</a> using props. There are a large number of <a href=\"https://reactjs.org/docs/events.html#supported-events\">supported events in React</a>, including common events such as <code>onClick</code> or <code>onChange</code> and less common events such as <code>onWheel</code>.</p>\n\n<p>Unlike native <a href=\"https://developer.mozilla.org/en-US/docs/Web/Guide/Events/Event_handlers\">DOM <code>onevent</code> handlers</a>, React passes a special wrapper called <code>SyntheticEvent</code> to the event handler rather than the native browser <code>Event</code>. The abstraction helps reduce cross-browser inconsistencies and gives your components a standard interface for working with events. The API for <code>SyntheticEvent</code> is similar to the native <code>Event</code>, so most tasks are accomplished in the same manner.</p>\n\n<p>To demonstrate this, you will start by making your validating input. First, you will create a component called <code>FileNamer</code>. This will be a <code>&lt;form&gt;</code> element with an input for naming a file. As you fill in the input, you&rsquo;ll see the information update a preview box above the component. The component will also include a submit button to run the validation, but for this example the form will not actually submit anything.</p>\n\n<p>First, create the directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir src/components/FileNamer\n</li></ul></code></pre>\n<p>Then open <code>FileNamer.js</code> in your text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/FileNamer/FileNamer.js\n</li></ul></code></pre>\n<p>Inside <code>FileNamer.js</code>, create a wrapper <code>&lt;div&gt;</code>, then add another <code>&lt;div&gt;</code> with a class name of <code>preview</code> and a <code>&lt;form&gt;</code> element inside the wrapper by writing the following lines of code:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React from 'react';\n\nexport default function FileNamer() {\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>Next, add an input element for the name to display in the preview box and a <strong>Save</strong> button. Add the following highlighted lines:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React from 'react';\n\nexport default function FileNamer() {\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        <span class=\"highlight\">&lt;h2&gt;Preview:&lt;/h2&gt;</span>\n      &lt;/div&gt;\n      &lt;form&gt;\n        <span class=\"highlight\">&lt;label&gt;</span>\n          <span class=\"highlight\">&lt;p&gt;Name:&lt;/p&gt;</span>\n          <span class=\"highlight\">&lt;input name=\"name\" /&gt;</span>\n        <span class=\"highlight\">&lt;/label&gt;</span>\n        <span class=\"highlight\">&lt;div&gt;</span>\n          <span class=\"highlight\">&lt;button&gt;Save&lt;/button&gt;</span>\n        <span class=\"highlight\">&lt;/div&gt;</span>\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>In the <code>preview</code> <code>&lt;div&gt;</code>, you added an <code>&lt;h2&gt;</code> element with the text <code>Preview</code>. This will be your preview box. Inside your form, you added an <code>&lt;input&gt;</code> surrounded by a <code>&lt;label&gt;</code> element with <code>Name:</code> as its text. Then you added a <code>button</code> called <strong>Save</strong> directly before the closing <code>&lt;form&gt;</code> tag.</p>\n\n<p>Save and close the file.</p>\n\n<p>Next, open <code>App.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/App/App.js\n</li></ul></code></pre>\n<p>Import <code>FileNamer</code>, then render inside the <code>App</code> function by adding the following highlighted lines:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/App/App.js\">events-tutorial/src/components/App/App.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React from 'react';\n<span class=\"highlight\">import FileNamer from '../FileNamer/FileNamer';</span>\n\nfunction App() {\n    return <span class=\"highlight\">&lt;FileNamer /&gt;</span>\n}\n\nexport default App;\n</code></pre>\n<p>Save and close the file. When you do the browser will refresh and you&rsquo;ll see your component.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/name_element.png\" alt=\"Name element\"></p>\n\n<p>Next, add some light styling to help define the sections and to add some padding and margins to the elements.</p>\n\n<p>Open <code>FileNamer.css</code> in your text editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/FileNamer/FileNamer.css\n</li></ul></code></pre>\n<p>Give the <code>.preview</code> class a gray border and padding, then give the <code>.wrapper</code> class a small amount of padding. Display the items in a column using <a href=\"https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Flexbox\"><code>flex</code></a> and <code>flex-direction</code>, and make all the text align left. Finally, remove the default button styles by removing the border and adding a black border:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.css\">events-tutorial/src/components/FileNamer/FileNamer.css</div><pre class=\"code-pre \"><code class=\"code-highlight language-css\">.preview {\n    border: 1px darkgray solid;\n    padding: 10px;\n}\n\n.wrapper {\n    display: flex;\n    flex-direction: column;\n    padding: 20px;\n    text-align: left;\n}\n\n.wrapper button {\n    background: none;\n    border: 1px black solid;\n    margin-top: 10px;\n}\n</code></pre>\n<p>Save and close the file. Then open <code>FileNamer.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/FileNamer/FileNamer.js\n</li></ul></code></pre>\n<p>Import the styles to apply them to your component:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React from 'react';\n<span class=\"highlight\">import './FileNamer.css';</span>\n\nexport default function FileNamer() {\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview:&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input name=\"name\" /&gt;\n        &lt;/label&gt;\n        &lt;div&gt;\n          &lt;button&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>Save the file. When you do, the browser will refresh and you&rsquo;ll find the component has the new styles.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/styled_component.png\" alt=\"Styled component\"></p>\n\n<p>Now that you have a basic component, you can add event handlers to the <code>&lt;input&gt;</code> element. But first, you&rsquo;ll need a place to store the data in the input field. Add the <a href=\"https://www.digitalocean.com/community/tutorials/how-to-manage-state-with-hooks-on-react-components#step-2-%E2%80%94-setting-state-with-usestate\"><code>useState</code> Hook</a> to hold the input:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React<span class=\"highlight\">, { useState }</span> from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  <span class=\"highlight\">const [name, setName] = useState('');</span>\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: <span class=\"highlight\">{name}.js</span>&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input name=\"name\" /&gt;\n        &lt;/label&gt;\n        &lt;div&gt;\n          &lt;button&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>In this code, you destructured <code>useState</code> into a variable <code>name</code> to hold the input and a function called <code>setName</code> to update the data. Then you displayed the <code>name</code> in the preview section followed by the <code>.js</code> extension, as if the user were naming a file.</p>\n\n<p>Now that you can store the input data, you can add an event handler to the <code>&lt;input&gt;</code> component. There are often several different event handlers you can use for a given task. In this case, your app needs to capture the data the user types into the element. The most common handler for this situation is <code>onChange</code>, which fires every time the component changes. However, you could also use <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent\">keyboard events</a>, such as <code>onKeyDown</code>, <code>onKeyPress</code>, and <code>onKeyUp</code>. The difference primarily has to do with when the event fires and the information passed to the <code>SyntheticEvent</code> object. For example, <code>onBlur</code>, an event for when an element becomes unfocused, fires before <code>onClick</code>. If you want to handle user information before another event fires, you can pick an earlier event. </p>\n\n<p>Your choice of event is also determined by the type of data you want to pass to the <code>SyntheticEvent</code>. The <code>onKeyPress</code> event, for example, will include the <code>charCode</code> of the key that the user pressed, while <code>onChange</code> will not include the specific character code, but will include the full input. This is important if you want to perform different actions depending on which key the user pressed.</p>\n\n<p>For this tutorial, use <code>onChange</code> to capture the entire input value and not just the most recent key. This will save you the effort of storing and concatenating the value on every change.</p>\n\n<p>Create a function that takes the <code>event</code> as an argument and pass it to the <code>&lt;input&gt;</code> element using the <code>onChange</code> prop:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input name=\"name\" <span class=\"highlight\">onChange={event =&gt; {}}</span>/&gt;\n        &lt;/label&gt;\n        &lt;div&gt;\n          &lt;button&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>As mentioned earlier, the <code>event</code> here is not the native browser event. It&rsquo;s the <code>SyntheticEvent</code> provided by React, which is often treated the same. In the rare case you need the native event, you can use the <code>nativeEvent</code> attribute on the <code>SyntheticEvent</code>.</p>\n\n<p>Now that you have the event, pull out the current value from the <code>target.value</code> property of the event. Pass the value to <code>setName</code> to update the preview:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n           <span class=\"highlight\">autoComplete=\"off\"</span>\n           name=\"name\"\n           onChange={event =&gt; <span class=\"highlight\">setName(event.target.value)</span> }\n         /&gt;\n        &lt;/label&gt;\n        &lt;div&gt;\n          &lt;button&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>In addition, you set the attribute <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/autocomplete\"><code>autoComplete</code></a> to <code>\"off\"</code> to turn off browser suggestions.</p>\n\n<p>Save the file. When you do, the page will reload, and when you type in the <code>&lt;input&gt;</code> you&rsquo;ll see an update in the preview.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/typing.gif\" alt=\"Typing into the input element\"></p>\n\n<p><span class='note'><strong>Note:</strong> You could also access the name of the input using <code>event.target.name</code>. This would be useful if you were using the same event handler across multiple inputs, since the <code>name</code> would automatically match the <code>name</code> attribute of the component. <br></span></p>\n\n<p>At this point, you have a working event handler. You are taking the user information, saving it to state, and updating another component with the data. But in addition to pulling information from an event, there are situations where you&rsquo;ll need to halt an event, such as if you wanted to prevent a form submission or prevent a keypress action. </p>\n\n<p>To stop an event, call the <code>preventDefault</code> action on the event. This will stop the browser from performing the default behavior.</p>\n\n<p>In the case of the <code>FileNamer</code> component, there are certain characters that could break the process of choosing a file that your app should forbid. For example, you wouldn&rsquo;t want a user to add a <code>*</code> to a filename since it conflicts with the wildcard character, which could be interpreted to refer to a different set of files. Before a user can submit the form, you&rsquo;ll want to check to make sure there are no invalid characters. If there is an invalid character, you&rsquo;ll stop the browser from submitting the form and display a message for the user.</p>\n\n<p>First, create a Hook that will generate an <code>alert</code> <a href=\"https://www.digitalocean.com/community/tutorials/understanding-data-types-in-javascript#booleans\">boolean</a> and a <code>setAlert</code> function. Then add a <code>&lt;div&gt;</code> to display the message if <code>alert</code> is true:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  <span class=\"highlight\">const [alert, setAlert] = useState(false);</span>\n\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n            autoComplete=\"off\"\n            name=\"name\"\n            onChange={event =&gt; setName(event.target.value) }\n          /&gt;\n        &lt;/label&gt;\n        <span class=\"highlight\">{alert &amp;&amp; &lt;div&gt; Forbidden Character: *&lt;/div&gt;}</span>\n        &lt;div&gt;\n          &lt;button&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>In this code, you used the <code>&amp;&amp;</code> operator to only show the new <code>&lt;div&gt;</code> if <code>alert</code> is set equal to <code>true</code> first. The message in the <code>&lt;div&gt;</code> will tell the user that the <code>*</code> character is not allowed in the input.</p>\n\n<p>Next, create a function called <code>validate</code>. Use the <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-regular-expressions\">regular expression</a> <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/test\"><code>.test</code> method</a> to find out if the string contains a <code>*</code>. If it does, you will prevent the form submission:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  const [alert, setAlert] = useState(false);\n  <span class=\"highlight\">const validate = event =&gt; {</span>\n    <span class=\"highlight\">if(/\\*/.test(name)) {</span>\n      <span class=\"highlight\">event.preventDefault();</span>\n      <span class=\"highlight\">setAlert(true);</span>\n      <span class=\"highlight\">return;</span>\n    <span class=\"highlight\">}</span>\n      <span class=\"highlight\">setAlert(false);</span>\n <span class=\"highlight\">};</span>\n\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n            autoComplete=\"off\"\n            name=\"name\"\n            onChange={event =&gt; setName(event.target.value) }\n          /&gt;\n        &lt;/label&gt;\n        {alert &amp;&amp; &lt;div&gt; Forbidden Character: *&lt;/div&gt;}\n        &lt;div&gt;\n          &lt;button <span class=\"highlight\">onClick={validate}</span>&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>When the <code>validate</code> function is called and the test returns <code>true</code>, it will use <code>event.preventDefault</code> then call <code>setAlert(true)</code>. Otherwise, it will call <code>setAlert(false)</code>. In the last part of the code, you added the event handler to the <code>&lt;button&gt;</code> element with <code>onClick</code>.</p>\n\n<p>Save the file. As before, you could have also used <code>onMouseDown</code>, but <code>onClick</code> is more common and thus allows you to avoid any unexpected side effects. This form doesn&rsquo;t have any submit actions, but by preventing the default action, you prevent the page from reloading:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/prevent_default.gif\" alt=\"Prevent Default and trigger a warning\"></p>\n\n<p>Now you have a form that uses two event handlers: <code>onChange</code> and <code>onClick</code>. You are using the event handlers to connect user actions to the component and the application, making it interactive. In doing so, you learned to add events to DOM elements, and how there are several events that fire on the same action, but that provide different information in the <code>SyntheticEvent</code>. You also learned how to extract information from the <code>SyntheticEvent</code>, update other components by saving that data to state, and halt an event using <code>preventDefault</code>.</p>\n\n<p>In the next step, you&rsquo;ll add multiple events to a single DOM element to handle a variety of user actions.</p>\n\n<h2 id=\"step-2-—-adding-multiple-event-handlers-to-the-same-element\">Step 2 — Adding Multiple Event Handlers to the Same Element</h2>\n\n<p>There are situations when a single component will fire multiple events, and you&rsquo;ll need to be able to connect to the different events on a single component. For example, in this step you&rsquo;ll use the <code>onFocus</code> and <code>onBlur</code> event handlers to give the user just-in-time information about the component. By the end of this step, you&rsquo;ll know more about the different supported events in React and how to add them to your components.</p>\n\n<p>The <code>validate</code> function is helpful for preventing your form from submitting bad data, but it&rsquo;s not very helpful for user experience: The user only receives information about the valid characters after they&rsquo;ve filled out the entire form. If there were multiple fields, it wouldn&rsquo;t give the user any feedback until the last step. To make this component more user friendly, display the allowed and disallowed characters when the user enters the field by adding an <code>onFocus</code> event handler.</p>\n\n<p>First, update the <code>alert</code> <code>&lt;div&gt;</code> to include information about what characters are allowed. Tell the user alphanumeric characters are allowed and the <code>*</code> is not allowed:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n...\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n            autocomplete=\"off\"\n            name=\"name\"\n            onChange={event =&gt; setName(event.target.value) }\n          /&gt;\n        &lt;/label&gt;\n        {alert &amp;&amp;\n         &lt;div&gt;\n           <span class=\"highlight\">&lt;span role=\"img\" aria-label=\"allowed\"&gt;✅&lt;/span&gt; Alphanumeric Characters</span>\n           <span class=\"highlight\">&lt;br /&gt;</span>\n           <span class=\"highlight\">&lt;span role=\"img\" aria-label=\"not allowed\"&gt;⛔️&lt;/span&gt; *</span>\n         &lt;/div&gt;\n       }\n        &lt;div&gt;\n          &lt;button onClick={validate}&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>In this code, you used <a href=\"https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA\">Accessible Rich Internet Applications (ARIA) standards</a> to make the component more accessible to screen readers.</p>\n\n<p>Next, add another event handler to the <code>&lt;input&gt;</code> element. You will alert the user about the allowed and disallowed characters when they activate the component by either clicking or tabbing into the input. Add in the following highlighted line:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n...\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n            autocomplete=\"off\"\n            name=\"name\"\n            onChange={event =&gt; setName(event.target.value) }\n            <span class=\"highlight\">onFocus={() =&gt; setAlert(true)}</span>\n          /&gt;\n        &lt;/label&gt;\n        {alert &amp;&amp;\n          &lt;div&gt;\n            &lt;span role=\"img\" aria-label=\"allowed\"&gt;✅&lt;/span&gt; Alphanumeric Characters\n            &lt;br /&gt;\n            &lt;span role=\"img\" aria-label=\"not allowed\"&gt;⛔️&lt;/span&gt; *\n          &lt;/div&gt;\n        }\n        &lt;div&gt;\n          &lt;button onClick={validate}&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>You added the <code>onFocus</code> event handler to the <code>&lt;input&gt;</code> element. This event triggers when the user selects the field. After adding the event handler, you passed an anonymous function to <code>onFocus</code> that will call <code>setAlert(true)</code> and display the data. In this case, you don&rsquo;t need any information from the <code>SyntheticEvent</code>; you only need to trigger an event when the user acts. React is still sending the <code>SyntheticEvent</code> to the function, but in the current situation you don&rsquo;t need to use the information in it.</p>\n\n<p><span class='note'><strong>Note:</strong> You could trigger the data display with <code>onClick</code> or even <code>onMouseDown</code>, but that wouldn&rsquo;t be accessible for users that use the keyboard to tab into the form fields. In this case, the <code>onFocus</code> event will handle both cases.<br></span></p>\n\n<p>Save the file. When you do, the browser will refresh and the information will remain hidden until the user clicks on the input.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/trigger_the_event.gif\" alt=\"Trigger the event when clicking on the input\"></p>\n\n<p>The user information now appears when the field is focused, but now the data is present for the duration of the component. There&rsquo;s no way to make it go away. Fortunately, there&rsquo;s another event called <code>onBlur</code> that fires when the user leaves an input. Add the <code>onBlur</code> event handler with an anonymous function that will set the <code>alert</code> to <code>false</code>. Like <code>onFocus</code>, this will work both when a user clicks away or when a user tabs away:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n...\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n            autocomplete=\"off\"\n            name=\"name\"\n            <span class=\"highlight\">onBlur={() =&gt; setAlert(false)}</span>\n            onChange={event =&gt; setName(event.target.value) }\n            onFocus={() =&gt; setAlert(true)}\n          /&gt;\n        &lt;/label&gt;\n        {alert &amp;&amp;\n          &lt;div&gt;\n            &lt;span role=\"img\" aria-label=\"allowed\"&gt;✅&lt;/span&gt; Alphanumeric Characters\n            &lt;br /&gt;\n            &lt;span role=\"img\" aria-label=\"not allowed\"&gt;⛔️&lt;/span&gt; *\n          &lt;/div&gt;\n        }\n        &lt;div&gt;\n          &lt;button onClick={validate}&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>Save the file. When you do, the browser will refresh and the information will display when the user clicks on the element and disappear when the user clicks away:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/show_information_on_focus.gif\" alt=\"Show information on focus and hide on blur\"></p>\n\n<p>You can add as many event handlers as you need to an element. If you have an idea of an event you need, but aren&rsquo;t sure of the name, scroll through the <a href=\"https://reactjs.org/docs/events.html#supported-events\">supported events</a> and you may find what you need.</p>\n\n<p>In this step you added multiple event handlers to a single DOM element. You learned how different event handlers can handle a broad range of events—such as both click and tab—or a narrow range of events.</p>\n\n<p>In the next step, you&rsquo;ll add global event listeners to the <code>Window</code> object to capture events that occur outside the immediate component.</p>\n\n<h2 id=\"step-3-—-adding-window-events\">Step 3 — Adding Window Events</h2>\n\n<p>In this step, you&rsquo;ll put the user information in a pop-up component that will activate when the user focuses an input and will close when the user clicks anywhere else on the page. To achieve this effect, you&rsquo;ll add a global event listener to the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Window/event\"><code>Window</code> object</a> using the <a href=\"https://reactjs.org/docs/hooks-reference.html#useeffect\"><code>useEffect</code> Hook</a>. You&rsquo;ll also remove the event listener when the component unmounts to prevent memory leaks, when your app take up more memory than it needs to.</p>\n\n<p>By the end of this step, you&rsquo;ll be able to safely add and remove event listeners on individual components. You&rsquo;ll also learn how to use the <code>useEffect</code> Hook to perform actions when a component mounts and unmounts.</p>\n\n<p>In most cases, you&rsquo;ll add event handlers directly to DOM elements in your JSX. This keeps your code focused and prevents confusing situations where a component is controlling another component&rsquo;s behavior through the <code>Window</code> object. But there are times in which you&rsquo;ll need to add global event listeners. For example, you may want a scroll listener to load new content, or you may want to capture click events outside of a component.</p>\n\n<p>In this tutorial, you only want to show the user the information about the input if they specifically ask for it. After you display the information, you&rsquo;ll want to hide it whenever the user clicks the page outside the component.</p>\n\n<p>To start, move the <code>alert</code> display into a new <code>&lt;div&gt;</code> with a <code>className</code> of <code>information-wrapper</code>. Then add a new button with a <code>className</code> of <code>information</code> and an <code>onClick</code> event that will call <code>setAlert(true)</code>:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n...\n  return(\n    &lt;div className=\"wrapper\"&gt;\n      &lt;div className=\"preview\"&gt;\n        &lt;h2&gt;Preview: {name}.js&lt;/h2&gt;\n      &lt;/div&gt;\n      &lt;form&gt;\n        &lt;label&gt;\n          &lt;p&gt;Name:&lt;/p&gt;\n          &lt;input\n            autocomplete=\"off\"\n            name=\"name\"\n            onChange={event =&gt; setName(event.target.value) }\n          /&gt;\n        &lt;/label&gt;\n        <span class=\"highlight\">&lt;div className=\"information-wrapper\"&gt;</span>\n          <span class=\"highlight\">&lt;button</span>\n            <span class=\"highlight\">className=\"information\"</span>\n            <span class=\"highlight\">onClick={() =&gt; setAlert(true)}</span>\n            <span class=\"highlight\">type=\"button\"</span>\n          <span class=\"highlight\">&gt;</span>\n            <span class=\"highlight\">more information</span>\n          <span class=\"highlight\">&lt;/button&gt;</span>\n         {alert &amp;&amp;\n           &lt;div <span class=\"highlight\">className=\"popup\"</span>&gt;\n             &lt;span role=\"img\" aria-label=\"allowed\"&gt;✅&lt;/span&gt; Alphanumeric Characters\n             &lt;br /&gt;\n             &lt;span role=\"img\" aria-label=\"not allowed\"&gt;⛔️&lt;/span&gt; *\n           &lt;/div&gt;\n         }\n        <span class=\"highlight\">&lt;/div&gt;</span>\n        &lt;div&gt;\n          &lt;button onClick={validate}&gt;Save&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/form&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>You also removed the <code>onFocus</code> and <code>onBlur</code> handlers from the <code>&lt;input&gt;</code> element to remove the behavior from the last step.</p>\n\n<p>Save and close the file. Then open <code>FileNamer.css</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/FileNamer/FileNamer.css\n</li></ul></code></pre>\n<p>Add some styling to absolutely position the <code>popup</code> information above the button. Then change the <code>&lt;button&gt;</code> with a class of <code>information</code> to be blue with no border.</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.css\">events-tutorial/src/components/FileNamer/FileNamer.css</div><pre class=\"code-pre \"><code class=\"code-highlight language-css\">\n<span class=\"highlight\">.information {</span>\n   <span class=\"highlight\">font-size: .75em;</span>\n   <span class=\"highlight\">color: blue;</span>\n   <span class=\"highlight\">cursor: pointer;</span>\n<span class=\"highlight\">}</span>\n<span class=\"highlight\"></span>\n<span class=\"highlight\">.wrapper button.information {</span>\n   <span class=\"highlight\"> border: none;</span>\n<span class=\"highlight\">}</span>\n<span class=\"highlight\"></span>\n<span class=\"highlight\">.information-wrapper {</span>\n   <span class=\"highlight\">position: relative;</span>\n<span class=\"highlight\">}</span>\n\n<span class=\"highlight\">.popup {</span>\n    <span class=\"highlight\">position: absolute;</span>\n    <span class=\"highlight\">background: white;</span>\n    <span class=\"highlight\">border: 1px darkgray solid;</span>\n    <span class=\"highlight\">padding: 10px;</span>\n    <span class=\"highlight\">top: -70px;</span>\n    <span class=\"highlight\">left: 0;</span>\n<span class=\"highlight\">}</span>\n\n.preview {\n    border: 1px darkgray solid;\n    padding: 10px;\n}\n\n.wrapper {\n    display: flex;\n    flex-direction: column;\n    padding: 20px;\n    text-align: left;\n}\n\n.wrapper button {\n    background: none;\n    border: 1px black solid;\n    margin-top: 10px;\n}\n</code></pre>\n<p>Save and close the file. When you do, the browser will reload, and when you click on <code>more information</code>, the information about the component will appear:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/trigger_info_popup.gif\" alt=\"Trigger information pop-up\"></p>\n\n<p>Now you can trigger the pop-up, but there&rsquo;s no way to clear it. To fix that problem, add a global event listener that calls <code>setAlert(false)</code> on any click outside of the pop-up.</p>\n\n<p>The event listener would look something like this:</p>\n<pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">window.addEventListener('click', () =&gt; setAlert(false))\n</code></pre>\n<p>However, you have to be mindful about when you set the event listener in your code. You can&rsquo;t, for example, add an event listener at the top of your component code, because then every time something changed, the component would re-render and add a new event listener. Since your component will likely re-render many times, that would create a lot of unused event listeners that take up memory.</p>\n\n<p>To solve this, React has a special Hook called <code>useEffect</code> that will run only when specific properties change. The basic structure is this:</p>\n<pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">useEffect(() =&gt; {\n // run code when anything in the array changes\n}, [<span class=\"highlight\">someProp</span>, <span class=\"highlight\">someOtherProp</span>])\n</code></pre>\n<p>In the simplified example, React will run the code in the anonymous function whenever <code>someProp</code> or <code>someOtherProp</code> changes. The items in the array are called <em>dependencies</em>. This Hook listens for changes to the dependencies and then runs the function after the change.</p>\n\n<p>Now you have the tools to add and remove a global event listener safely by using <code>useEffect</code> to add the event listener whenever <code>alert</code> is <code>true</code> and remove it whenever <code>alert</code> is <code>false</code>.</p>\n\n<p>There is one more step. When the component unmounts, it will run any function that you return from inside of your <code>useEffect</code> Hook. Because of this, you&rsquo;ll also need to return a function that removes the event listener when the component unmounts. </p>\n\n<p>The basic structure would be like this:</p>\n<pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">useEffect(() =&gt; {\n // run code when anything in the array changes\n  return () =&gt; {} // run code when the component unmounts\n}, [someProp, someOtherProp])\n</code></pre>\n<p>Now that you know the shape of your <code>useEffect</code> Hook, use it in your application. Open up <code>FileNamer.js</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano src/components/FileNamer/FileNamer.js\n</li></ul></code></pre>\n<p>Inside, import <code>useEffect</code>, then add an empty anonymous function with a dependency of <code>alert</code> and <code>setAlert</code> in the array after the function:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { <span class=\"highlight\">useEffect,</span> useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  const [alert, setAlert] = useState(false);\n\n  <span class=\"highlight\">useEffect(() =&gt; {</span>\n  <span class=\"highlight\">}, [alert, setAlert]);</span>\n...\n</code></pre>\n<p>In this code, you added both <code>alert</code> and <code>setAlert</code>. To be complete, React recommends you add all external dependencies to the <code>useEffect</code> function. Since you will be calling the <code>setAlert</code> function, it can be considered a dependency. <code>setAlert</code> will not change after the first render, but it&rsquo;s a good practice to include anything that could be considered a dependency.</p>\n\n<p>Next, inside the anonymous function, create a new function called <code>handleWindowClick</code> that calls <code>setAlert(false)</code>:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useEffect, useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  const [alert, setAlert] = useState(false);\n\n  useEffect(() =&gt; {\n    <span class=\"highlight\">const handleWindowClick = () =&gt; setAlert(false)</span>\n  }, [alert, setAlert]);\n  ...\n}\n</code></pre>\n<p>Then add a <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-conditional-statements-in-javascript\">conditional</a> that will call <code>window.addEventListener('click', handleWindowClick)</code> when <code>alert</code> is <code>true</code> and will call <code>window.removeEventListener('click', handleWindowClick)</code> when <code>alert</code> is <code>false</code>. This will add the event listener every time you trigger the pop-up and remove it everytime the pop-up is closed:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">import React, { useEffect, useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  const [alert, setAlert] = useState(false);\n\n  useEffect(() =&gt; {\n    const handleWindowClick = () =&gt; setAlert(false)\n    <span class=\"highlight\">if(alert) {</span>\n      <span class=\"highlight\">window.addEventListener('click', handleWindowClick);</span>\n    <span class=\"highlight\">} else {</span>\n      <span class=\"highlight\">window.removeEventListener('click', handleWindowClick);</span>\n    <span class=\"highlight\">}</span>\n  }, [alert, setAlert]);\n  ...\n}\n</code></pre>\n<p>Finally, return a function that will remove the event listener. Once again, this will run when the component unmounts. There may not be a live event listener, but it&rsquo;s still worth cleaning up in situations where the listener still exists:</p>\n<div class=\"code-label \" title=\"events-tutorial/src/components/FileNamer/FileNamer.js\">events-tutorial/src/components/FileNamer/FileNamer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">\nimport React, { useEffect, useState } from 'react';\nimport './FileNamer.css';\n\nexport default function FileNamer() {\n  const [name, setName] = useState('');\n  const [alert, setAlert] = useState(false);\n\n  useEffect(() =&gt; {\n    const handleWindowClick = () =&gt; setAlert(false)\n    if(alert) {\n      window.addEventListener('click', handleWindowClick);\n    } else {\n      window.removeEventListener('click', handleWindowClick)\n    }\n    <span class=\"highlight\">return () =&gt; window.removeEventListener('click', handleWindowClick);</span>\n  }, [alert, setAlert]);\n  ...\n}\n</code></pre>\n<p>Save the file. When you do, the browser will refresh. If you click on the <strong>more information</strong> button, the message will appear. If you look at the global event listeners in the developer tools, you&rsquo;ll see there is a <code>click</code> listener:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/click_event_listener.png\" alt=\"Click event listener\"></p>\n\n<p>Click anywhere outside the component. The message will disappear and you&rsquo;ll no longer see the global click event listener.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67407/no_click_event_listener.png\" alt=\"No click event listener\"></p>\n\n<p>Your <code>useEffect</code> Hook successfully added and removed a global event listener based on a user interaction. It wasn&rsquo;t tied to a specific DOM element, but was instead triggered by a change in the component state.</p>\n\n<p><span class='note'><strong>Note:</strong> From an accessibility standpoint, this component is not complete. If a user is not able to use the mouse, they will be stuck with an open pop-up because they would never be able to click outside the component. The solution would be to add another event listener for <code>keydown</code> that would also remove the message. The code would be nearly identical except the method would be <code>keydown</code> instead of <code>click</code>.<br></span></p>\n\n<p>In this step you added global event listeners inside a component. You also learned how to use the <code>useEffect</code> Hook to properly add and remove the event listener as the state changes and how to clean up event listeners when the component unmounts.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Event handlers give you the opportunity to align your components with user actions. These will give your applications a rich experience and will increase the interactive possibilities of your app. They will also give you the ability to capture and respond to user actions.</p>\n\n<p>React&rsquo;s event handlers let you keep your event callbacks integrated with the HTML so that you can share functionality and design across an application. In most cases, you should focus on adding event handlers directly to DOM elements, but in situations where you need to capture events outside of the component, you can add event listeners and clean them up when they are no longer in use to prevent memory leaks and create performative applications.</p>\n\n<p>If you would like to look at more React tutorials, check out our <a href=\"https://www.digitalocean.com/community/tags/react\">React Topic page</a>, or return to the <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-react-js\">How To Code in React.js series page</a>. To learn more about events in JavaScript, read our <a href=\"https://www.digitalocean.com/community/tutorials/understanding-events-in-javascript\">Understanding Events in JavaScript</a> and <a href=\"https://www.digitalocean.com/community/tutorials/using-event-emitters-in-node-js\">Using Event Emitters in Node.js</a> tutorials.</p>\n","descriptionType":"html","publishedDate":"Thu, 27 Aug 2020 23:01:13 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67407/name_element.png","linkMd5":"d9b542071ee442a9ad50485e5196f52a","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn85@2020_1/2020/08/31/07-48-27-286_a44b243efb8b534d.webp","destWidth":862,"destHeight":428,"sourceBytes":23209,"destBytes":5402,"author":"Joe Morgan","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67407/name_element.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn85@2020_1/2020/08/31/07-48-27-286_a44b243efb8b534d.webp","https://assets.digitalocean.com/articles/67407/styled_component.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn58@2020_6/2020/08/31/07-48-33-092_7a86c555b7663c66.webp","https://assets.digitalocean.com/articles/67407/typing.gif":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn85@2020_6/2020/08/31/07-48-36-762_f869a5c6c190ef77.webp","https://assets.digitalocean.com/articles/67407/prevent_default.gif":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn33@2020_3/2020/08/31/07-48-43-270_2265c36d42884432.webp","https://assets.digitalocean.com/articles/67407/trigger_the_event.gif":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn45@2020_4/2020/08/31/07-48-33-730_a399286aa823b53d.webp","https://assets.digitalocean.com/articles/67407/show_information_on_focus.gif":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn57@2020_1/2020/08/31/07-48-35-777_22862a208751346f.webp","https://assets.digitalocean.com/articles/67407/trigger_info_popup.gif":null,"https://assets.digitalocean.com/articles/67407/click_event_listener.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn42@2020_3/2020/08/31/07-48-31-951_f71b688deee2ac8b.webp","https://assets.digitalocean.com/articles/67407/no_click_event_listener.png":null},"publishedOrCreatedDate":1598860106961},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Zentralisieren von Protokollen mit Journald unter Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-journald-on-ubuntu-20-04-de","description":"<p><em>Der Autor wählte den <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a>, um eine Spende im Rahmen des Programms <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> zu erhalten.</em></p>\n\n<h3 id=\"einführung\">Einführung</h3>\n\n<p>Systemprotokolle sind ein äußerst wichtiger Bestandteil für die Verwaltung von Linux-Systemen. Sie bieten einen unschätzbaren Einblick in die Funktionsweise und Verwendung der Systeme, da sie neben Fehlern auch Betriebsinformationen wie Sicherheitsereignisse aufzeichnen. Die Standardkonfiguration für Linux-Systeme besteht darin, ihre Protokolle lokal auf demselben System zu speichern, auf dem sie aufgetreten sind. Dies funktioniert für eigenständige Systeme, wird jedoch mit zunehmender Anzahl von Systemen schnell zu einem Problem. Die Lösung für die Verwaltung all dieser Protokolle besteht darin, einen zentralen Protokollierungsserver zu erstellen, auf dem jeder Linux-Host seine Protokolle in Echtzeit an einen dedizierten Protokollverwaltungsserver sendet.</p>\n\n<p>Eine zentralisierte Protokollierungslösung bietet im Vergleich zum Speichern von Protokollen auf jedem Host mehrere Vorteile:</p>\n\n<ul>\n<li>Reduziert den Speicherplatz, der auf jedem Host zum Speichern von Protokolldateien benötigt wird.</li>\n<li>Protokolle können länger aufbewahrt werden, da der dedizierte Protokollserver mit mehr Speicherkapazität konfiguriert werden kann.</li>\n<li>Es kann eine erweiterte Protokollanalyse durchgeführt werden, die Protokolle von mehreren Systemen und mehr Rechenressourcen erfordert, als auf den Hosts verfügbar sind.</li>\n<li>Systemadministratoren können auf die Protokolle aller ihrer Systeme zugreifen, bei denen sie sich aus Sicherheitsgründen möglicherweise nicht direkt anmelden können.</li>\n</ul>\n\n<p>In diesem Leitfaden konfigurieren Sie eine Komponente der Tool-Suite <a href=\"https://systemd.io/\">systemd</a>, um Protokollnachrichten von Client-Systemen an einen zentralen Protokollsammlungsserver weiterzuleiten. Sie konfigurieren den Server und den Client so, dass TLS-Zertifikate verwendet werden, um die Protokollnachrichten zu verschlüsseln, wenn sie über unsichere Netzwerke wie das Internet übertragen werden, und um sich gegenseitig zu authentifizieren.</p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Bevor Sie diese Anleitung beginnen, benötigen Sie Folgendes:</p>\n\n<ul>\n<li>Zwei Ubuntu 20.04-Server.</li>\n<li>Einen Nicht-root-Benutzer mit Sudo-Berechtigungen auf beiden Servern. Anweisungen dazu finden Sie im Leitfaden zur <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Ersteinrichtung des Servers mit Ubuntu 20.04</a>. Sie sollten auch die UFW-Firewall auf beiden Servern konfigurieren, wie im Leitfaden erläutert.</li>\n<li>Zwei Hostnamen, die auf Ihre Server verweisen. Ein Hostname für das <strong>Client</strong>-System, das die Protokolle generiert, und ein anderer für den Protokollsammlungs<strong>server</strong>. In der <a href=\"https://www.digitalocean.com/docs/networking/dns/\">Domains- und DNS-Dokumentation</a> erfahren Sie, wie Sie Hostnamen auf DigitalOcean Droplets verweisen.</li>\n</ul>\n\n<p>In diesem Leitfaden werden die folgenden zwei Beispiel-Hostnamen verwendet:</p>\n\n<ul>\n<li><code><span class=\"highlight\">client.your_domain</span></code>: Das Client-System, das die Protokolle generiert.</li>\n<li><code><span class=\"highlight\">server.your_domain</span></code>: Der Protokollsammlungsserver.</li>\n</ul>\n\n<p>Melden Sie sich sowohl beim Client als auch beim Server in separaten Terminals über SSH als Nicht-root-sudo-Benutzer an, um dieses Tutorial zu starten.</p>\n\n<p><span class='note'><strong>Hinweis</strong>: Während des gesamten Tutorials werden Befehlsblöcke mit dem Namen des Servers (<strong>Client</strong> oder <strong>Server</strong>) gekennzeichnet, auf dem der Befehl ausgeführt werden soll.<br></span></p>\n\n<h2 id=\"schritt-1-—-installieren-von-systemd-journal-remote\">Schritt 1 — Installieren von <code>systemd-journal-remote</code></h2>\n\n<p>In diesem Schritt installieren Sie das Paket <code>systemd-journal-remote</code> auf dem <strong>Client</strong> und dem <strong>Server</strong>. Dieses Paket enthält die Komponenten, die der <strong>Client</strong> und der <strong>Server</strong> zum Weiterleiten von Protokollnachrichten verwenden.</p>\n\n<p>Führen Sie zunächst sowohl auf dem <strong>Client</strong> als auch auf dem <strong>Server</strong> ein Systemupdate aus, um sicherzustellen, dass die Paketdatenbank und das System aktuell sind:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li><li class=\"line\" data-prefix=\"$\">sudo apt upgrade\n</li></ul></code></pre>\n<p>Installieren Sie das Paket <code>systemd-journal-remote</code>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install systemd-journal-remote\n</li></ul></code></pre>\n<p>Aktivieren und starten Sie auf dem <strong>Server</strong> die beiden <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\"><code>systemd</code></a>-Komponenten, die zum Empfangen von Protokollnachrichten benötigt werden, mit dem folgenden Befehl:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable --now systemd-journal-remote.socket\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-remote.service\n</li></ul></code></pre>\n<p>Die Option <code>--now</code> im ersten Befehl startet die Dienste sofort. Sie haben es im zweiten Befehl nicht verwendet, da dieser Dienst erst gestartet wird, wenn er über TLS-Zertifikate verfügt, die Sie im nächsten Schritt erstellen.</p>\n\n<p>Aktivieren Sie auf dem <strong>Client</strong> die Komponente, mit der <code>systemd</code> die Protokollnachrichten an den Server sendet:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Öffnen Sie anschließend auf dem Server die Ports <code>19532</code> und <code>80</code> in der UFW-Firewall. Dadurch kann der Server die Protokollnachrichten vom Client empfangen. Port <code>80</code> ist der Port, über den <code>Certbot</code> das TLS-Zertifikat generiert. Die folgenden Befehle öffnen diese Ports:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 19532/tcp\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Auf dem Client müssen Sie Port <code>80</code> nur mit diesem Befehl öffnen:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Sie haben jetzt die erforderlichen Komponenten installiert und die Basissystemkonfiguration auf dem Client und dem Server abgeschlossen. Bevor Sie diese Komponenten so konfigurieren können, dass sie mit der Weiterleitung von Protokollnachrichten beginnen, registrieren Sie die <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> TLS-Zertifikate für den <strong>Client</strong> und den <strong>Server</strong> mithilfe des Dienstprogramms <a href=\"https://certbot.eff.org/\"><code>certbot</code></a>.</p>\n\n<h2 id=\"schritt-2-installieren-von-certbot-und-registrieren-von-zertifikaten\">Schritt 2 - Installieren von Certbot und Registrieren von Zertifikaten</h2>\n\n<p>Let&rsquo;s Encrypt ist eine <a href=\"https://en.wikipedia.org/wiki/Certificate_authority\">Zertifizierungsstelle</a>, die kostenlose TLS-Zertifikate ausstellt. Mit diesen Zertifikaten können Computer sowohl die zwischen ihnen gesendeten Daten verschlüsseln als auch die Identität des anderen überprüfen. Mit diesen Zertifikaten können Sie Ihr Surfen im Internet mit HTTPS sichern. Dieselben Zertifikate können von jeder anderen Anwendung verwendet werden, die dieselbe Sicherheitsstufe wünscht. Der Prozess der Registrierung des Zertifikats ist der gleiche, unabhängig davon, wofür Sie es verwenden.</p>\n\n<p>In diesem Schritt installieren Sie das Dienstprogramm <code>certbot</code> und registrieren damit die Zertifikate. Außerdem wird es automatisch darum kümmern, die Zertifikate zu erneuern, wenn sie ablaufen. Der Registrierungsvorgang ist hier der gleiche auf dem <strong>Client</strong> und dem <strong>Server</strong>. Sie müssen nur den Hostnamen ändern, um ihn an den Host anzupassen, auf dem Sie den Registrierungsbefehl ausführen.</p>\n\n<p>Aktivieren Sie zunächst das <code>universe</code>-Repository von Ubuntu, da sich das Dienstprogramm <code>certbot</code> im <code>universe</code>-Repository befindet. Wenn Sie das <code>universe</code>-Repository bereits aktiviert haben, wird eine Ausführung dieser Befehle in Ihrem System nichts verändern und ist somit sicher:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install software-properties-common\n</li><li class=\"line\" data-prefix=\"$\">sudo add-apt-repository universe\n</li><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Als Nächstes installieren Sie <code>certbot</code> auf beiden Hosts:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install certbot\n</li></ul></code></pre>\n<p>Nachdem Sie <code>certbot</code> installiert haben, führen Sie den folgenden Befehl aus, um die Zertifikate auf dem <strong>Client</strong> und <strong>Server</strong> zu registrieren:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot certonly --standalone --agree-tos --email <span class=\"highlight\">sammy@your_domain</span> -d <span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Die Optionen in diesem Befehl bedeuten Folgendes:</p>\n\n<ul>\n<li><code>certonly</code>: Registrieren Sie das Zertifikat und führen Sie keine anderen Änderungen am System vor.</li>\n<li><code>--standalone</code>: Verwenden Sie den integrierten Webserver von certbot zur Verifizierung der Zertifikatsanforderung.</li>\n<li>-<code>-agree-tos:</code> Stimmen Sie automatisch den Nutzungsbedingungen von Let&rsquo;s Encrypt zu.</li>\n<li><code>--email <span class=\"highlight\">your_email</span></code>: Dies ist die E-Mail-Adresse, mit der Let&rsquo;s Encrypt Sie über den Ablauf des Zertifikats und andere wichtige Informationen benachrichtigt.</li>\n<li><code>-d <span class=\"highlight\">your_domain</span></code>: Der Hostname, für den das Zertifikat registriert wird. Dies muss dem System entsprechen, in dem Sie es ausführen.</li>\n</ul>\n\n<p>Wenn Sie diesen Befehl ausführen, werden Sie gefragt, ob Sie die E-Mail-Adresse mit Let&rsquo;s Encrypt teilen möchten, damit diese Ihnen Nachrichten und andere Informationen zu ihrer Arbeit per E-Mail senden können. Dies ist optional. Wenn Sie Ihre E-Mail-Adresse nicht teilen, wird die Zertifikatsregistrierung weiterhin normal abgeschlossen.</p>\n\n<p>Wenn der Zertifikatregistrierungsprozess abgeschlossen ist, werden die Zertifikat- und Schlüsseldateien in <code>/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/</code> abgelegt, wobei <code>your_domain</code> der Hostname ist, für den Sie das Zertifikat registriert haben.</p>\n\n<p>Schließlich müssen Sie eine Kopie der Let&rsquo;s Encrypt-Zertifizierungsstelle und der Zwischenzertifikate herunterladen und in dieselbe Datei einfügen. <code>journald</code> verwendet diese Datei, um die Authentizität der Zertifikate auf dem <strong>Client</strong> und dem <strong>Server</strong> zu überprüfen, wenn diese miteinander kommunizieren.</p>\n\n<p>Mit dem folgenden Befehl werden die beiden Zertifikate von der Let&rsquo;s Encrypt-Website heruntergeladen und in einer einzigen Datei mit dem Namen <code>letsencrypt-combined-certs.pem</code> im Home-Verzeichnis Ihres Benutzers abgelegt.</p>\n\n<p>Führen Sie diesen Befehl auf dem <strong>Client</strong> und dem <strong>Server</strong> aus, um die Zertifikate herunterzuladen und die kombinierte Datei zu erstellen:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -s https://letsencrypt.org/certs/{isrgrootx1.pem.txt,letsencryptauthorityx3.pem.txt} &gt; ~/letsencrypt-combined-certs.pem\n</li></ul></code></pre>\n<p>Verschieben Sie als Nächstes diese Datei in das Verzeichnis Let&rsquo;s Encrypt, das die Zertifikate und Schlüssel enthält:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp ~/letsencrypt-combined-certs.pem /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/\n</li></ul></code></pre>\n<p>Sie haben nun die Zertifikate und Schlüssel registriert. Im nächsten Schritt konfigurieren Sie den Protokollsammlungs<strong>server</strong> so, dass er Protokollnachrichten vom <strong>Client</strong> abhört und speichert.</p>\n\n<h2 id=\"schritt-3-–-konfigurieren-des-servers\">Schritt 3 – Konfigurieren des Servers</h2>\n\n<p>In diesem Schritt konfigurieren Sie den <strong>Server</strong> so, dass er die im letzten Schritt generierten Zertifikat- und Schlüsseldateien verwendet, damit er Protokollnachrichten vom <strong>Client</strong> akzeptieren kann.</p>\n\n<p><code>systemd-journal-remote</code> ist die Komponente, die auf Protokollnachrichten wartet. Öffnen Sie ihre Konfigurationsdatei unter <code>/etc/systemd/journal-remote.conf</code> mit einem Texteditor, um die Konfiguration auf dem <strong>Server</strong> zu starten:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-remote.conf\n</li></ul></code></pre>\n<p>Entfernen Sie anschließend die Kommentare in allen Zeilen im Abschnitt <code>[Remote]</code> und legen Sie die Pfade so fest, dass sie auf die soeben erstellten TLS-Dateien verweisen:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-remote.conf\">/etc/systemd/journal-remote.conf</div><pre class=\"code-pre \"><code>[Remote]\nSeal=false\nSplitMode=host\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Hier sind die Optionen, die Sie hier verwendet haben:</p>\n\n<ul>\n<li><code>Seal=false</code>: Melden Sie die Protokolldaten im Journal an. Aktivieren Sie diese Option, wenn Sie maximale Sicherheit benötigen; andernfalls können Sie es als <code>false</code> belassen.</li>\n<li><code>SplitMode=host</code>: Die Protokolle der Remoteclients werden nach Host in <code>/var/log/journal/remote</code> geteilt. Wenn Sie möchten, dass alle Protokolle einer einzelnen Datei hinzugefügt werden, setzen Sie dies auf <code>SplitMode=false</code>.</li>\n<li><code>ServerKeyFile</code>: Die private Schlüsseldatei des Servers.</li>\n<li><code>ServerCertificateFile</code>: Die Zertifikatdatei des Servers.</li>\n<li><code>TrustedCertificateFile</code>: Die Datei mit den Let&rsquo;s Encrypt CA-Zertifikaten.</li>\n</ul>\n\n<p>Jetzt müssen Sie die Berechtigungen für die Let&rsquo;s Encrypt-Verzeichnisse ändern, die die Zertifikate und den Schlüssel enthalten, damit die <code>systemd-journal-remote</code> sie lesen und verwenden kann.</p>\n\n<p>Ändern Sie zunächst die <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-permissions\">Berechtigungen</a> so, dass das Zertifikat und der private Schlüssel lesbar sind:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Ändern Sie als Nächstes das Gruppeneigentum des privaten Schlüssels in die Gruppe von <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-remote /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Jetzt können Sie <code>systemd-journal-remote</code> starten:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start systemd-journal-remote.service\n</li></ul></code></pre>\n<p>Ihr Protokollsammlungs <strong>server</strong> wird jetzt ausgeführt und ist bereit, Protokollnachrichten von einem <strong>Client</strong> zu akzeptieren. Im nächsten Schritt konfigurieren Sie den <strong>Client</strong> so, dass die Protokolle an Ihren Sammlungs <strong>server</strong> weitergeleitet werden.</p>\n\n<h2 id=\"schritt-4-–-konfigurieren-des-clients\">Schritt 4 – Konfigurieren des Clients</h2>\n\n<p>In diesem Schritt konfigurieren Sie die Komponente, die die Protokollnachrichten an den Protokollsammlungsserver weiterleitet. Diese Komponente wird <code>systemd-journal-upload</code> genannt.</p>\n\n<p>Die Standardkonfiguration für <code>systemd-journal-upload</code> ist, dass ein temporärer Benutzer verwendet wird, der nur vorhanden ist, während der Prozess ausgeführt wird. Dies erschwert das Lesen der TLS-Zertifikate und -Schlüssel durch <code>systemd-journal-upload</code>. Um dies zu beheben, erstellen Sie einen neuen Systembenutzer mit demselben Namen wie der temporäre Benutzer, der an seiner Stelle verwendet wird.</p>\n\n<p>Erstellen Sie zunächst den neuen Benutzer mit dem Namen <code>systemd-journal-upload</code> auf dem <strong>Client</strong> mit dem folgenden <code>adduser</code>-Befehl:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo adduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload\n</li></ul></code></pre>\n<p>Diese Optionen für den Befehl lauten:</p>\n\n<ul>\n<li><code>--system:</code> Erstellen Sie den neuen Benutzer als Systembenutzer. Dadurch wird dem Benutzer eine UID-Nummer (Benutzerkennung) unter <code>1000</code> gegeben. UIDs über <code>1000</code> werden normalerweise an Benutzerkonten vergeben, mit denen sich ein Mensch anmeldet.</li>\n<li><code>--home/run/systemd</code>: Legen Sie <code>/run/systemd</code> als Home-Verzeichnis für diesen Benutzer fest.</li>\n<li><code>--no-create-home</code>: Erstellen Sie das Home-Verzeichnis nicht, da es bereits vorhanden ist.</li>\n<li><code>--disabled-login:</code> Der Benutzer kann sich beispielsweise nicht über SSH beim Server anmelden.</li>\n<li><code>--group</code>: Erstellen Sie eine Gruppe mit demselben Namen wie der Benutzer.</li>\n</ul>\n\n<p>Legen Sie als Nächstes die Berechtigungen und den Besitz der Let&rsquo;s Encrypt-Zertifikatdateien fest:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-upload /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Bearbeiten Sie nun die Konfiguration für <code>systemd-journal-upload</code> unter <code>/etc/systemd/journal-upload.conf</code>. Öffnen Sie diese Datei mit einem Texteditor:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-upload.conf\n</li></ul></code></pre>\n<p>Bearbeiten Sie diese Datei, damit sie wie folgt aussieht:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-upload.conf\">/etc/systemd/journal-upload.conf</div><pre class=\"code-pre \"><code>[Upload]\nURL=https://<span class=\"highlight\">server.your_domain</span>:19532\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Starten Sie abschließend den <code>systemd-journal-upload</code>-Dienst neu, damit er die neue Konfiguration verwendet:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Ihr <strong>Client</strong> ist jetzt eingerichtet und wird ausgeführt und sendet seine Protokollnachrichten an den Protokollsammlungsserver. Im nächsten Schritt überprüfen Sie, ob die Protokolle korrekt gesendet und aufgezeichnet werden.</p>\n\n<h2 id=\"schritt-5-–-testen-des-clients-und-des-servers\">Schritt 5 – Testen des Clients und des Servers</h2>\n\n<p>In diesem Schritt testen Sie, ob der <strong>Client</strong> Protokollnachrichten an den <strong>Server</strong> weiterleitet und ob der <strong>Server</strong> sie korrekt speichert.</p>\n\n<p>Der Protokollsammlungsserver speichert die Protokolle von den Clients in einem Verzeichnis unter <code>/var/log/journal/remote/</code>. Wenn Sie den <strong>Client</strong> am Ende des letzten Schritts neu gestartet haben, wurden Protokollnachrichten gesendet, sodass sich jetzt eine Protokolldatei in <code>/var/log/journal/remote/</code> befindet. Die Datei wird nach dem Hostnamen, den Sie für das TLS-Zertifikat verwenden, benannt.</p>\n\n<p>Verwenden Sie den Befehl <code>Is</code>, um zu überprüfen, ob die Protokolldatei des <strong>Clients</strong> auf dem <strong>Server</strong> vorhanden ist:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ls -la /var/log/journal/remote/\n</li></ul></code></pre>\n<p>Dadurch wird der Verzeichnisinhalt mit der Protokolldatei gedruckt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>total 16620\ndrwxr-xr-x  2 systemd-journal-remote systemd-journal-remote     4096 Jun 30 16:17  .\ndrwxr-sr-x+ 4 root                   systemd-journal            4096 Jun 30 15:55  ..\n-rw-r-----  1 systemd-journal-remote systemd-journal-remote 8388608 Jul  1 10:46 '<span class=\"highlight\">remote-CN=client.your_domain</span>'\n</code></pre>\n<p>Schreiben Sie als Nächstes eine Protokollnachricht auf den <strong>Client</strong>, um zu überprüfen, ob der <strong>Server</strong> die Nachrichten des <strong>Clients</strong> wie erwartet empfängt. Mit dem Dienstprogramm <a href=\"https://man7.org/linux/man-pages/man1/logger.1.html\">logger</a> erstellen Sie eine benutzerdefinierte Protokollnachricht auf dem <strong>Client</strong>. Wenn alles funktioniert, leitet <code>systemd-journal-upload</code> diese Nachricht an den <strong>Server</strong> weiter.</p>\n\n<p>Führen Sie auf dem <strong>Client</strong> den folgenden <code>logger</code>-Befehl aus:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo logger -p syslog.debug \"### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\"\n</li></ul></code></pre>\n<p><code>-p syslog.debug</code> in diesem Befehl legt <a href=\"https://en.wikipedia.org/wiki/Syslog#Message_components\">Funktion und Schweregrad</a> der Nachricht fest. Wenn man dies auf <code>syslog.debug</code> setzt, wird deutlich, dass es sich um eine Testnachricht handelt. Dieser Befehl zeichnet die Nachricht <code>### TEST MESSAGE from <span class=\"highlight\"> client.your_domain </span> ###</code> im Journal des Clients auf, das dann vom <code>systemd-journal-upload</code> an den** Server** weitergeleitet wird.</p>\n\n<p>Lesen Sie als Nächstes die Journaldatei des <strong>Clients</strong> auf dem <strong>Server</strong>, um zu überprüfen, ob die Protokollnachrichten vom <strong>Client</strong> eingehen. Diese Datei ist eine binäre Protokolldatei, sodass Sie sie mit Tools wie <code>less</code> nicht lesen können. Lesen Sie die Datei stattdessen mit <code>journalctl</code> mit der Option <code>--file =</code>, mit der Sie eine benutzerdefinierte Journaldatei angeben können:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo journalctl --file=/var/log/journal/remote/remote-CN=<span class=\"highlight\">client.your_domain.journal</span>\n</li></ul></code></pre>\n<p>Die Protokollnachricht wird wie folgt angezeigt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Test log message\">Test log message</div>. . .\nJun 29 13:10:09 client root[3576]: ### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\n</code></pre>\n<p>Ihr Protokollzentralisierungsserver sammelt jetzt erfolgreich Protokolle von Ihrem Client-System.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>In diesem Artikel haben Sie einen zentralen Protokollsammlungsserver eingerichtet und einen Client so konfiguriert, dass eine Kopie seiner Systemprotokolle an den Server weitergeleitet wird. Mit den hier verwendeten Client-Konfigurationsschritten können Sie so viele Clients konfigurieren, wie Sie zum Weiterleiten von Nachrichten an den Protokollsammlungsserver benötigen.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:44 +0000","feedId":8037,"bgimg":"","linkMd5":"08a3128c59c62ba548f6acdba7e5d52b","bgimgJsdelivr":"","metaImg":"","author":"Elliot Cooper","publishedOrCreatedDate":1598860106983},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo usar ThreadPoolExecutor en Python 3","link":"https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3-es","description":"<p><em>El autor seleccionó el <a href=\"https://www.brightfunds.org/funds/write-for-donations-covid-19-relief-fund\">COVID-19 Relief Fund</a> para que reciba una donación como parte del programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introducción\">Introducción</h3>\n\n<p>Los <em>subprocesos</em> de <a href=\"https://www.python.org/\">Python</a> son una especie de paralelismo que le permiten a su programa ejecutar varios procedimientos a la vez. Este paralelismo en Python también se puede lograr utilizando varios procesos, pero los subprocesos son particularmente adecuados para acelerar las aplicaciones que implican una cantidad considerable de E/S (entrada/salida).</p>\n\n<p>Algunos ejemplos de <a href=\"https://en.wikipedia.org/wiki/I/O_bound#:%7E:text=In%20computer%20science%2C%20I%2FO,a%20task%20being%20CPU%20bound.\">operaciones limitadas por las E/S</a> son la realización de solicitudes web y la lectura de datos de archivos. A diferencia de las operaciones limitadas por las E/S, <a href=\"https://en.wikipedia.org/wiki/CPU-bound\">las operaciones limitadas por la CPU</a> (como realizar cálculos matemáticos con la biblioteca estándar de Python) no se benefician mucho de los subprocesos de Python.</p>\n\n<p>Python 3 incluye la utilidad <code>ThreadPoolExecutor</code> para ejecutar código en subprocesos.</p>\n\n<p>En este tutorial, utilizaremos <code>ThreadPoolExecutor</code> para realizar solicitudes de red de forma rápida. Definiremos una función que se pueda invocar desde subprocesos, utilizaremos <code>ThreadPoolExecutor</code> para ejecutar esa función y procesaremos los resultados de esas ejecuciones.</p>\n\n<p>Para los fines de este tutorial, realizaremos solicitudes de red para verificar la existencia de páginas de <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipedia</a>.</p>\n\n<p><span class='note'><strong>Nota:</strong> El hecho de que las operaciones limitadas por las E/S se beneficien más de los subprocesos que las limitadas por la CPU se debe a una idiosincrasia de Python denominada <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\"><em>bloqueo global de intérpretes</em></a>. Si desea obtener más información sobre el bloqueo global de intérpretes de Python, puede consultar la <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">documentación oficial de Python</a>.<br></span></p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Para aprovechar este tutorial al máximo, es recomendable tener algunos conocimientos de programación en Python y un entorno de programación local de Python con <code>requests</code> instalado.</p>\n\n<p>Puede revisar estos tutoriales para encontrar la información básica necesaria:</p>\n\n<ul>\n<li><a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-python-3\">Cómo programar en Python 3</a></li>\n<li><p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">Cómo instalar Python 3 y configurar un entorno de programación local en Ubuntu 18.04</a></p></li>\n<li><p>Para instalar el paquete <code>requests</code> en su <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">entorno de programación local de Python</a>, puede ejecutar este comando:</p></li>\n</ul>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pip install --user requests==2.23.0\n</li></ul></code></pre>\n<h2 id=\"paso-1-definir-una-función-que-se-ejecute-en-subprocesos\">Paso 1: Definir una función que se ejecute en subprocesos</h2>\n\n<p>Vamos a comenzar por definir una función que nos gustaría ejecutar con la ayuda de subprocesos.</p>\n\n<p>Puede abrir este archivo usando <code>nano</code> o el editor de texto o entorno de desarrollo que prefiera:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano wiki_page_function.py\n</li></ul></code></pre>\n<p>Para los fines de este tutorial, vamos a escribir una función que determine si una página de Wikipedia existe o no:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n</code></pre>\n<p>La <a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-python-3\">función</a> <code>get_wiki_page_existence</code> acepta dos argumentos: una URL a una página de Wikipedia (<code>wiki_page_url</code>) y un <code>timeout</code> que indica la cantidad de segundos que se debe esperar una respuesta de esa URL.</p>\n\n<p><code>get_wiki_page_existence</code> utiliza el paquete <a href=\"https://requests.readthedocs.io/en/master/\"><code>requests</code></a> para realizar una solicitud web a esa URL. Se devuelve una cadena que indica si la página existe o no dependiendo del <a href=\"https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes\">código de estado</a> de <code>response</code>, la respuesta HTTP. Los diferentes códigos de estado representan los distintos resultados que puede tener una solicitud HTTP. En este procedimiento, se asume que un código de estado <code>200</code>, &ldquo;correcto&rdquo;, indica que la página de Wikipedia existe y un código de estado <code>404</code>, &ldquo;no encontrada&rdquo;, que la página de Wikipedia no existe.</p>\n\n<p>Como se describe en la sección Requisitos previos, deberá tener el paquete <code>requests</code> instalado para poder ejecutar esta función.</p>\n\n<p>Intentemos ejecutar la función añadiendo la <code>url</code> y la invocación a la función después de la función <code>get_wiki_page_existence</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">. . .\nurl = \"https://en.wikipedia.org/wiki/Ocean\"\nprint(get_wiki_page_existence(wiki_page_url=url))\n</code></pre>\n<p>Una vez que haya añadido el código, guarde y cierre el archivo.</p>\n\n<p>Si ejecutamos este código:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Veremos un resultado como el siguiente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Ocean - exists\n</code></pre>\n<p>La invocación de la función <code>get_wiki_page_existence</code> con una página de Wikipedia válida devuelve una cadena que confirma que la página efectivamente existe.</p>\n\n<p><span class='warning'><strong>Advertencia:</strong> En general, no es seguro compartir objetos o estados de Python entre subprocesos sin tener especial cuidado para evitar errores de simultaneidad. A la hora de definir una función que se ejecute en un subproceso, lo mejor es definir una que realice una sola tarea y no publique ni comparta su estado con otros subprocesos. La función <code>get_wiki_page_existence</code> es un ejemplo de una función con estas características.<br></span></p>\n\n<h2 id=\"paso-2-usar-threadpoolexecutor-para-ejecutar-una-función-en-subprocesos\">Paso 2: Usar ThreadPoolExecutor para ejecutar una función en subprocesos</h2>\n\n<p>Ahora que tenemos una función que se puede invocar con subprocesos, podemos usar <code>ThreadPoolExecutor</code> para invocar esa función varias veces de forma rápida.</p>\n\n<p>Agregue el siguiente código resaltado a su programa en <code>wiki_page_function.py</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n<span class=\"highlight\">import concurrent.futures</span>\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Ocean\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Island\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/this_page_does_not_exist\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Shark\",</span>\n<span class=\"highlight\">]</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n</code></pre>\n<p>Veamos cómo funciona este código:</p>\n\n<ul>\n<li><code>concurrent.futures</code> se importa para darnos acceso a <code>ThreadPoolExecutor</code>.</li>\n<li>Se utiliza una instrucción <code>with</code> para crear un <code>executor</code> de una instancia de  <code>ThreadPoolExecutor</code> que limpia de forma rápida los subprocesos al completarse.</li>\n<li>Se envían (<code>submit</code>) cuatro tareas al <code>executor</code> para cada una de las URL de la lista <code>wiki_page_urls</code>.</li>\n<li>Cada invocación a <code>submit</code> devuelve una <a href=\"https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future\">instancia <code>Future</code></a> que se almacena en la lista de <code>futures</code>.</li>\n<li>La función <code>as_completed</code> espera que se complete cada invocación a <code>get_wiki_page_existence</code> de <code>Future</code> para que podamos imprimir su resultado.</li>\n</ul>\n\n<p>Si volvemos a ejecutar este programa con el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Veremos un resultado como el siguiente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Island - exists\nhttps://en.wikipedia.org/wiki/Ocean - exists\nhttps://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\nhttps://en.wikipedia.org/wiki/Shark - exists\n</code></pre>\n<p>Este resultado es lógico: tres de las URL son páginas de Wikipedia válidas y una de ellas, <code>this_page_does_not_exist</code>, no lo es. Tenga en cuenta que su resultado puede tener un orden distinto a este. La función <code>concurrent.futures.as_completed</code> de este ejemplo devuelve resultados tan pronto estén disponibles, independientemente del orden en que se presentaron las tareas.</p>\n\n<h2 id=\"paso-3-procesar-excepciones-de-funciones-ejecutadas-en-subprocesos\">Paso 3: Procesar excepciones de funciones ejecutadas en subprocesos</h2>\n\n<p>En el paso anterior, <code>get_wiki_page_existence</code> devolvió correctamente un valor para todas nuestras invocaciones. En este paso, veremos que <code>ThreadPoolExecutor</code> también puede crear excepciones generadas en invocaciones de funciones con subprocesos.</p>\n\n<p>Consideremos el siguiente bloque de código de ejemplo:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n\nwiki_page_urls = [\n    \"https://en.wikipedia.org/wiki/Ocean\",\n    \"https://en.wikipedia.org/wiki/Island\",\n    \"https://en.wikipedia.org/wiki/this_page_does_not_exist\",\n    \"https://en.wikipedia.org/wiki/Shark\",\n]\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(</span>\n            <span class=\"highlight\">executor.submit(</span>\n                <span class=\"highlight\">get_wiki_page_existence, wiki_page_url=url, timeout=0.00001</span>\n            <span class=\"highlight\">)</span>\n        <span class=\"highlight\">)</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">try:</span>\n            <span class=\"highlight\">print(future.result())</span>\n        <span class=\"highlight\">except requests.ConnectTimeout:</span>\n            <span class=\"highlight\">print(\"ConnectTimeout.\")</span>\n</code></pre>\n<p>Este bloque de código es casi idéntico al que utilizamos en el paso 2, pero tiene dos diferencias clave:</p>\n\n<ul>\n<li>Ahora, pasamos <code>timeout=0.00001</code> a <code>get_wiki_page_existence</code>. Como el paquete <code>requests</code> no puede completar su solicitud web a Wikipedia en <code>0.00001</code> segundos, creará una excepción <code>ConnectTimeout</code>.</li>\n<li>Tomamos las excepciones <code>ConnectTimeout</code> que generó <code>future.result()</code> e imprimimos una cadena cada vez que lo hacemos.</li>\n</ul>\n\n<p>Si volvemos a ejecutar el programa, veremos el siguiente resultado:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>ConnectTimeout.\nConnectTimeout.\nConnectTimeout.\nConnectTimeout.\n</code></pre>\n<p>Se imprimen cuatro mensajes de <code>ConnectTimeout</code> (uno para cada una de nuestras cuatro <code>wiki_page_urls</code>), dado que no se pudo completar ninguna de ellas en <code>0.00001</code> segundos y cada una de las cuatro invocaciones a <code>get_wiki_page_existence</code> generó la excepción <code>ConnectTimeout</code>.</p>\n\n<p>Aprendió que si la invocación a una función enviada a <code>ThreadPoolExecutor</code> crea una excepción, esa excepción se puede generar normalmente al invocar <code>Future.result</code>. Invocar <code>Future.result</code> en todas sus invocaciones enviadas garantiza que su programa no omita ninguna excepción que se haya generado a partir de su función de subprocesos.</p>\n\n<h2 id=\"paso-4-comparar-el-tiempo-de-ejecución-con-y-sin-subprocesos\">Paso 4: Comparar el tiempo de ejecución con y sin subprocesos</h2>\n\n<p>Ahora, vamos a verificar que usar <code>ThreadPoolExecutor</code> efectivamente hace que su programa sea más rápido.</p>\n\n<p>Primero, vamos a medir el tiempo de ejecución de <code>get_wiki_page_existence</code> sin subprocesos:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\"><span class=\"highlight\">import time</span>\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]</span>\n\n<span class=\"highlight\">print(\"Running without threads:\")</span>\n<span class=\"highlight\">without_threads_start = time.time()</span>\n<span class=\"highlight\">for url in wiki_page_urls:</span>\n    <span class=\"highlight\">print(get_wiki_page_existence(wiki_page_url=url))</span>\n<span class=\"highlight\">print(\"Without threads time:\", time.time() - without_threads_start)</span>\n</code></pre>\n<p>En el código de ejemplo, invocamos nuestra función <code>get_wiki_page_existence</code> con cincuenta URL de páginas de Wikipedia distintas, una por una. Usamos la <a href=\"https://docs.python.org/3/library/time.html#time.time\">función <code>time.time()</code></a> para imprimir la cantidad de segundos que toma la ejecución de nuestro programa.</p>\n\n<p>Si volvemos a ejecutar este código como antes, veremos un resultado similar al siguiente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running without threads:\nhttps://en.wikipedia.org/wiki/0 - exists\nhttps://en.wikipedia.org/wiki/1 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nWithout threads time: 5.803015232086182\n</code></pre>\n<p>Se omitieron las entradas 2 a 47 de este resultado para mayor brevedad.</p>\n\n<p>La cantidad de segundos que se imprima después de <code>Without threads time</code> será distinta cuando lo ejecute en su máquina, lo que es normal, dado que solo está recibiendo un número de referencia para realizar una comparación con una solución que utiliza <code>ThreadPoolExecutor</code>. En este caso, tomó <code>~5.803</code> segundos.</p>\n\n<p>Ejecutemos las mismas cincuenta URL de Wikipedia a través de <code>get_wiki_page_existence</code>, pero, esta vez, utilizando <code>ThreadPoolExecutor</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import time\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\nwiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n\n<span class=\"highlight\">print(\"Running threaded:\")</span>\n<span class=\"highlight\">threaded_start = time.time()</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n<span class=\"highlight\">print(\"Threaded time:\", time.time() - threaded_start)</span>\n</code></pre>\n<p>El código es el mismo que el que creamos en el Paso 2, solo agregamos algunas instrucciones de impresión que nos muestran la cantidad de segundos que toma la ejecución de nuestro código.</p>\n\n<p>Si volvemos a ejecutar el programa, veremos lo siguiente:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running threaded:\nhttps://en.wikipedia.org/wiki/1 - exists\nhttps://en.wikipedia.org/wiki/0 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nThreaded time: 1.2201685905456543\n</code></pre>\n<p>Nuevamente, la cantidad de segundos que se imprime después de <code>Threaded time</code> será diferente en su computadora (al igual que el orden de su resultado).</p>\n\n<p>Ahora, puede comparar el tiempo de ejecución de la búsqueda de las cincuenta URL de páginas de Wikipedia con y sin subprocesos.</p>\n\n<p>En la máquina utilizada en este tutorial, la ejecución sin subprocesos llevó <code>~5.803</code> segundos y con subprocesos, <code>~1.220</code> segundos. Nuestro programa se ejecutó considerablemente más rápido con subprocesos.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>En este tutorial, aprendió a usar la utilidad <code>ThreadPoolExecutor</code> de Python 3 para ejecutar de forma eficiente código limitado por las E/S. Creó una función que se puede invocar desde subprocesos, aprendió a recuperar resultados y excepciones de ejecuciones de esa función y notó la mejora de desempeño que se obtiene al utilizar subprocesos.</p>\n\n<p>Ahora, puede obtener más información sobre otras funciones de simultaneidad que ofrece el <a href=\"https://docs.python.org/3/library/concurrent.futures.html\">módulo <code>concurrent.futures</code></a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:41 +0000","feedId":8037,"bgimg":"","linkMd5":"70be9d05b25c59f1cd213df1df371128","bgimgJsdelivr":"","metaImg":"","author":"DavidMuller","publishedOrCreatedDate":1598860106964},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como centralizar logs com o Journald no Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-journald-on-ubuntu-20-04-pt","description":"<p><em>O autor selecionou o <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> para receber uma doação como parte do programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introdução\">Introdução</h3>\n\n<p>Os logs de sistema são um componente extremamente importante no gerenciamento de sistemas Linux. Eles fornecem uma visão valiosa sobre como os sistemas estão funcionando e também como eles estão sendo usados, porque, além de erros, eles registram informações operacionais como eventos de segurança. A configuração padrão para sistemas Linux é para armazenar seus logs localmente no mesmo sistema onde eles ocorreram. Isso funciona para sistemas standalone, mas rapidamente torna-se um problema à medida que o número de sistemas aumenta. A solução para gerenciar todos esses logs é criar um servidor de logs centralizado onde cada host Linux envia seus logs, em tempo real, para um servidor de gerenciamento de logs dedicado.</p>\n\n<p>Uma solução de log centralizada oferece vários benefícios em comparação com o armazenamento de logs em cada host:</p>\n\n<ul>\n<li>Reduz a quantidade de espaço em disco necessária em cada host para armazenar arquivos de log.</li>\n<li>Os logs podem ser retidos por mais tempo, pois o servidor de log dedicado pode ser configurado com mais capacidade de armazenamento.</li>\n<li>Análise de log avançada pode ser realizada, o que requer logs a partir de vários sistemas e também mais recursos de computação do que podem estar disponíveis nos hosts.</li>\n<li>Os administradores de sistemas podem acessar os logs para todos os seus sistemas nos quais eles talvez não consigam efetuar login diretamente por questões de segurança.</li>\n</ul>\n\n<p>Neste guia, você irá configurar um componente do conjunto de ferramentas <a href=\"https://systemd.io/\">systemd</a> para retransmitir mensagens de log de sistemas cliente a um servidor de coleta de log centralizado. Você irá configurar o servidor e o cliente para usar certificados TLS para criptografar as mensagens de log à medida que elas são transmitidas por redes inseguras, como a internet e também para autenticar um ao outro.</p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Antes de iniciar este guia, será necessário o seguinte:</p>\n\n<ul>\n<li>Dois servidores Ubuntu 20.04.</li>\n<li>Um usuário não-root com privilégios sudo em ambos os servidores. Siga o guia <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Initial Server Setup with Ubuntu 20.04</a> para instruções sobre como fazer isso. Você também deve configurar o firewall UFW em ambos os servidores, conforme explicado no guia.</li>\n<li>Dois nomes de host que apontam para seus servidores. Um nome de host para o sistema <strong>client</strong> que gera os logs e outro para o <strong>server</strong> de coleta de log. Saiba como apontar nomes de host para os Droplets da DigitalOcean consultando a documentação de <a href=\"https://www.digitalocean.com/docs/networking/dns/\">Domínios e DNS</a>.</li>\n</ul>\n\n<p>Este guia irá usar os seguintes dois nomes de host de exemplo:</p>\n\n<ul>\n<li><code><span class=\"highlight\">client.your_domain</span></code>: O sistema cliente que gera os logs.</li>\n<li><code><span class=\"highlight\">server.your_domain</span></code>: O servidor de coleta de log.</li>\n</ul>\n\n<p>Faça login tanto no cliente quanto no servidor em terminais separados via SSH como o usuário sudo não-root para iniciar este tutorial.</p>\n\n<p><span class='note'><strong>Nota</strong>: ao longo do tutorial, os blocos de comando são rotulados com o nome do servidor (<strong>client</strong> ou <strong>server</strong>) em que o comando deve ser executado.<br></span></p>\n\n<h2 id=\"passo-1-—-instalando-o-systemd-journal-remote\">Passo 1 — Instalando o <code>systemd-journal-remote</code></h2>\n\n<p>Neste passo, você irá instalar o pacote <code>systemd-journal-remote</code> no <strong>client</strong> e no <strong>server</strong>. Este pacote contém os componentes que o <strong>client</strong> e o <strong>server</strong> usam para transmitir as mensagens de log.</p>\n\n<p>Primeiro, tanto no <strong>client</strong> quanto no <strong>server</strong>, execute uma atualização de sistema para garantir que o banco de dados de pacotes e o sistema estejam atualizados:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li><li class=\"line\" data-prefix=\"$\">sudo apt upgrade\n</li></ul></code></pre>\n<p>Em seguida, instale o pacote <code>systemd-journal-remote</code>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install systemd-journal-remote\n</li></ul></code></pre>\n<p>No <strong>server</strong>, habilite e inicie os dois componentes <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\"><code>systemd</code></a> que ele precisa para receber mensagens de log com o seguinte comando:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable --now systemd-journal-remote.socket\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-remote.service\n</li></ul></code></pre>\n<p>A opção <code>--now</code> no primeiro comando inicia os serviços imediatamente. Você não o usou no segundo comando, porque este serviço não irá iniciar até que ele tenha certificados TLS, que você irá criar no próximo passo.</p>\n\n<p>No <strong>client</strong>, habilite o componente que o <code>systemd</code> usa para enviar as mensagens de log para o servidor:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Em seguida, no servidor, abra as portas <code>19532</code> e <code>80</code> no firewall UFW. Isso permitirá ao servidor receber as mensagens de log do cliente. A porta <code>80</code> é a porta que o <code>certbot</code> irá usar para gerar o certificado TLS. Os seguintes comandos irão abrir essas portas:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 19532/tcp\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>No cliente, você só precisa abrir a porta <code>80</code> com este comando:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Agora, você instalou os componentes necessários e concluiu a configuração básica do sistema no cliente e no servidor. Antes de configurar esses componentes para começar a retransmitir mensagens de log, você registrará os certificados TLS <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> para o <strong>client</strong> e o <strong>server</strong> usando o utilitário <a href=\"https://certbot.eff.org/\"><code>certbot</code></a>.</p>\n\n<h2 id=\"passo-2-—-instalando-o-certbot-e-registrando-certificados\">Passo 2 — Instalando o Certbot e registrando certificados</h2>\n\n<p>O Let&rsquo;s Encrypt é uma <a href=\"https://en.wikipedia.org/wiki/Certificate_authority\">Autoridade de Certificação</a> que emite certificados TLS gratuitos. Esses certificados permitem que os computadores criptografem os dados que eles enviam entre eles e também verificam a identidade um do outro. Esses certificados são o que lhe permite proteger sua navegação na Internet com HTTPS. Os mesmos certificados podem ser usados por qualquer outra aplicação que queira o mesmo nível de segurança. O processo de registro do certificado é o mesmo, independentemente para o que você o utilize.</p>\n\n<p>Neste passo, você irá instalar o utilitário <code>certbot</code> e usá-lo para registrar os certificados. Ele também irá cuidar automaticamente de renovar os certificados quando eles expirarem. O processo de registro aqui é o mesmo no <strong>client</strong> e no <strong>server</strong>. Você só precisa alterar o nome do host para corresponder ao host onde você está executando o comando de registo.</p>\n\n<p>Primeiro, habilite o repositório <code>universe</code> do Ubuntu, pois o utilitário <code>certbot</code> reside no repositório <code>universe</code>. Se você já tiver o repositório <code>universe</code> habilitado, executar esses comandos não fará nada com seu sistema e é seguro executar:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install software-properties-common\n</li><li class=\"line\" data-prefix=\"$\">sudo add-apt-repository universe\n</li><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Em seguida, instale o <code>certbot</code> em ambos os hosts:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install certbot\n</li></ul></code></pre>\n<p>Agora que você instalou o <code>certbot</code>, execute o seguinte comando para registrar os certificados no <strong>client</strong> e no <strong>server</strong>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot certonly --standalone --agree-tos --email <span class=\"highlight\">sammy@your_domain</span> -d <span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>As opções neste comando significam o seguinte:</p>\n\n<ul>\n<li><code>certonly</code>: registrar o certificado e não fazer nenhuma outra alteração no sistema.</li>\n<li><code>--standalone</code>: usar o servidor Web embutido do certbot para verificar a solicitação de certificado.</li>\n<li><code>--agree-tos</code>: concordar automaticamente com os Termos de Serviço do Let&rsquo;s Encrypt.</li>\n<li><code>--email <span class=\"highlight\">your-email</span></code>: este é o endereço de e-mail que o Let&rsquo;s Encrypt irá usar para notificar você sobre a expiração do certificado e outras informações importantes.</li>\n<li><code>-d <span class=\"highlight\">your_domain</span></code>: o nome de host para o qual o certificado será registrado. Isso deve corresponder ao sistema em que você o executa.</li>\n</ul>\n\n<p>Ao executar este comando, você será perguntado se você deseja compartilhar o endereço de e-mail com o Let&rsquo;s Encrypt para que eles possam enviar a você notícias e outras informações sobre seu trabalho. Fazer isso é opcional, se você não compartilhar seu endereço de e-mail o registro de certificado ainda irá completar normalmente.</p>\n\n<p>Quando o processo de registro de certificado for concluído, ele irá colocar o certificado e os arquivos de chave em <code>/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/</code> onde <code>your_domain</code> é o nome de host para o qual você registrou o certificado.</p>\n\n<p>Por fim, você precisa baixar uma cópia do CA do Let&rsquo;s Encrypt e certificados intermediários e colocá-los no mesmo arquivo. O <code>journald</code> irá usar este arquivo para verificar a autenticidade dos certificados no <strong>client</strong> e no <strong>server</strong> quando eles se comunicam um com o outro.</p>\n\n<p>O comando a seguir irá baixar os dois certificados do site do Let&rsquo;s Encrypt e colocá-los em um único arquivo chamado <code>letsencrypt-combined-certs.pem</code> no diretório home do seu usuário.</p>\n\n<p>Execute este comando no <strong>client</strong> e no <strong>server</strong> para baixar os certificados e criar o arquivo combinado:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -s https://letsencrypt.org/certs/{isrgrootx1.pem.txt,letsencryptauthorityx3.pem.txt} &gt; ~/letsencrypt-combined-certs.pem\n</li></ul></code></pre>\n<p>Em seguida, mova este arquivo para o diretório do Let&rsquo;s Encrypt que contém os certificados e chaves:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp ~/letsencrypt-combined-certs.pem /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/\n</li></ul></code></pre>\n<p>Agora, você registrou os certificados e as chaves. No próximo passo, você irá configurar o <strong>server</strong> de coleta de logs para iniciar a escuta e armazenar mensagens de log do <strong>client</strong>.</p>\n\n<h2 id=\"passo-3-—-configurando-o-servidor\">Passo 3 — Configurando o servidor</h2>\n\n<p>Neste passo, você irá configurar o <strong>server</strong> para usar o certificado e os arquivos de chave que você gerou no último passo para que ele possa começar a aceitar mensagens de log do <strong>client</strong>.</p>\n\n<p>O <code>systemd-journal-remote</code> é o componente que faz a escuta para as mensagens de log. Abra seu arquivo de configuração em <code>/etc/systemd/journal-remote.conf</code> com um editor de texto para iniciar a configuração dele no <strong>server</strong>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-remote.conf\n</li></ul></code></pre>\n<p>Em seguida, descomente todas as linhas sob a seção <code>[Remote]</code> e defina os caminhos para apontar para os arquivos TLS que você acabou de criar:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-remote.conf\">/etc/systemd/journal-remote.conf</div><pre class=\"code-pre \"><code>[Remote]\nSeal=false\nSplitMode=host\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Aqui estão as opções que você usou aqui:</p>\n\n<ul>\n<li><code>Seal=false</code>: assine os dados de log no journal. Habilite isso se você precisar de segurança máxima; caso contrário, você pode deixá-lo como <code>falso</code>.</li>\n<li><code>SplitMode=host</code>: os logs dos clientes remotos serão divididos por host em <code>/var/log/journal/remote</code>. Se você preferir que todos os logs sejam adicionados a um único arquivo defina isso como <code>SplitMode=false</code>.</li>\n<li><code>ServerKeyFile</code>: o arquivo de chave privada do servidor.</li>\n<li><code>ServerCertificateFile</code>: o arquivo de certificado do servidor.</li>\n<li><code>TrustedCertificateFile</code>: o arquivo que contém os certificados Let&rsquo;s Encrypt CA.</li>\n</ul>\n\n<p>Agora, você precisa alterar as permissões nos diretórios do Let&rsquo;s Encrypt que contêm os certificados e a chave para que o <code>systemd-journal-remote</code> possa lê-los e usá-los.</p>\n\n<p>Primeiro, altere as <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-permissions\">permissões</a> para que o certificado e a chave privada sejam legíveis:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Em seguida, mude a propriedade do grupo da chave privada para o grupo <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-remote /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Agora, você pode iniciar o <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start systemd-journal-remote.service\n</li></ul></code></pre>\n<p>Seu <strong>server</strong> de coleta de log agora está em execução e pronto para começar a aceitar mensagens de log de um <strong>client</strong>. No próximo passo, você irá configurar o <strong>client</strong> para retransmitir os logs para seu <strong>server</strong> de coleta.</p>\n\n<h2 id=\"passo-4-—-configurando-o-cliente\">Passo 4 — Configurando o cliente</h2>\n\n<p>Neste passo, você irá configurar o componente que retransmite as mensagens de log para o servidor de coleta de log. Este componente é chamado <code>systemd-journal-upload</code>.</p>\n\n<p>A configuração padrão para o <code>systemd-journal-upload</code> é que ele usa um usuário temporário que só existe enquanto o processo está em execução. Isso torna mais complicada a permissão para o <code>systemd-journal-upload</code> ler os certificados TLS e as chaves. Para resolver isso, você irá criar um novo usuário de sistema com o mesmo nome que o usuário temporário que será usado em seu lugar.</p>\n\n<p>Primeiro, crie o novo usuário chamado <code>systemd-journal-upload</code> no <strong>client</strong> com o seguinte comando <code>adduser</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo adduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload\n</li></ul></code></pre>\n<p>Essas opções para o comando são:</p>\n\n<ul>\n<li><code>--system</code>: cria o novo usuário como um usuário do sistema. Isso dá ao usuário um número UID (User Identifier) abaixo de <code>1000</code>. UID&rsquo;s acima de <code>1000</code> são geralmente dados a contas de usuário que um humano irá usar para fazer login.</li>\n<li><code>--home /run/systemd</code>: define <code>/run/systemd</code> como o diretório home para este usuário.</li>\n<li><code>--no-create-home</code>: não cria o conjunto de diretório home, uma vez que ele já existe.</li>\n<li><code>--disabled-login</code>: o usuário não pode fazer login no servidor via SSH, por exemplo.</li>\n<li><code>--group</code>: cria um grupo com o mesmo nome que o usuário.</li>\n</ul>\n\n<p>Em seguida, defina as permissões e a propriedade dos arquivos de certificado Let&rsquo;s Encrypt:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-upload /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Agora, edite a configuração para o <code>systemd-journal-upload</code>, que está em <code>/etc/systemd/journal-upload.conf</code>. Abra este arquivo com um editor de texto:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-upload.conf\n</li></ul></code></pre>\n<p>Edite este arquivo para que ele fique como o seguinte:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-upload.conf\">/etc/systemd/journal-upload.conf</div><pre class=\"code-pre \"><code>[Upload]\nURL=https://<span class=\"highlight\">server.your_domain</span>:19532\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Por fim, reinicie o serviço <code>systemd-journal-upload</code> para que ele use a nova configuração:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Seu <strong>client</strong> agora está configurado e funcionando e está enviando suas mensagens de log para o servidor de coleta de log. No próximo passo, você irá verificar se os logs estão sendo enviados e gravados corretamente.</p>\n\n<h2 id=\"passo-5-—-testando-o-cliente-e-o-servidor\">Passo 5 — Testando o cliente e o servidor</h2>\n\n<p>Neste passo, você irá testar se o <strong>client</strong> está retransmitindo mensagens de log para o <strong>server</strong> e se o <strong>server</strong> está armazenando-as corretamente.</p>\n\n<p>O servidor de coleta de log armazena os logs dos clientes em um diretório em <code>/var/log/journal/remote/</code>. Quando você reiniciou o <strong>client</strong> no final do último passo, ele começou a enviar mensagens de log, dessa forma há agora um arquivo de log em <code>/var/log/journal/remote/</code>. O arquivo será nomeado após o nome do host usado para o certificado TLS.</p>\n\n<p>Use o comando <code>ls</code> para verificar se o arquivo de log do <strong>client</strong> está presente no <strong>server</strong>:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ls -la /var/log/journal/remote/\n</li></ul></code></pre>\n<p>Isso irá imprimir o conteúdo do diretório mostrando o arquivo de log:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>total 16620\ndrwxr-xr-x  2 systemd-journal-remote systemd-journal-remote     4096 Jun 30 16:17  .\ndrwxr-sr-x+ 4 root                   systemd-journal            4096 Jun 30 15:55  ..\n-rw-r-----  1 systemd-journal-remote systemd-journal-remote 8388608 Jul  1 10:46 '<span class=\"highlight\">remote-CN=client.your_domain</span>'\n</code></pre>\n<p>Em seguida, escreva uma mensagem de log no <strong>client</strong> para verificar se o <strong>server</strong> está recebendo as mensagens do <strong>client</strong> como você espera. Você irá usar o utilitário <a href=\"https://man7.org/linux/man-pages/man1/logger.1.html\">logger</a> para criar uma mensagem de log personalizada no <strong>client</strong>. Se tudo estiver funcionando, o <code>systemd-journal-upload</code> irá retransmitir esta mensagem ao <strong>server</strong>.</p>\n\n<p>No <strong>client</strong> execute o seguinte comando <code>logger</code>:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo logger -p syslog.debug \"### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\"\n</li></ul></code></pre>\n<p>O <code>-p syslog.debug</code> neste comando define a <a href=\"https://en.wikipedia.org/wiki/Syslog#Message_components\">facilidade e a severidade</a> da mensagem. Definir isso para <code>syslog.debug</code> irá tornar claro que ela é uma mensagem de teste. Este comando irá gravar a mensagem <code>### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###</code> no journal do cliente, que o <code>systemd-journal-upload</code> então retransmite para o <strong>server</strong>.</p>\n\n<p>Em seguida, leia o arquivo de journal do <strong>client</strong> no <strong>server</strong> para verificar se as mensagens de log estão chegando do <strong>client</strong>. Este arquivo é um arquivo de log binário, portanto você não será capaz de lê-lo com ferramentas como o <code>less</code>. Em vez disso, leia o arquivo usando o <code>journalctl</code> com a opção <code>--file=</code> que lhe permite especificar um arquivo de journal personalizado:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo journalctl --file=/var/log/journal/remote/remote-CN=<span class=\"highlight\">client.your_domain.journal</span>\n</li></ul></code></pre>\n<p>A mensagem de log irá aparecer da seguinte forma:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Test log message\">Test log message</div>. . .\nJun 29 13:10:09 client root[3576]: ### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\n</code></pre>\n<p>Seu servidor de centralização de log agora está coletando logs com sucesso a partir do seu sistema cliente.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Neste artigo, você configurou um servidor central de coleta de logs e configurou um cliente para retransmitir uma cópia dos logs de sistema ao servidor. Você pode configurar quantos clientes você precisar retransmitir mensagens ao servidor de coleta de log usando os passos de configuração do cliente que você usou aqui.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:58 +0000","feedId":8037,"bgimg":"","linkMd5":"86b94d9e37440330cacddc1e82379b61","bgimgJsdelivr":"","metaImg":"","author":"Elliot Cooper","publishedOrCreatedDate":1598860106986},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Skalieren und Sichern einer Django-Anwendung mit Docker, Nginx und Let’s Encrypt","link":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-de","description":"<h3 id=\"einführung\">Einführung</h3>\n\n<p>In cloudbasierten Umgebungen gibt es mehrere Möglichkeiten, eine <a href=\"https://www.djangoproject.com/\">Django</a>-Anwendung zu skalieren und zu sichern. Durch <em>horizontale Skalierung</em> und die Ausführung mehrerer Kopien Ihrer Anwendung können Sie ein fehlertolerantes und hochverfügbares System aufbauen und gleichzeitig <em>den Durch</em>satz erhöhen, sodass Anfragen gleichzeitig verarbeitet werden können. Eine Möglichkeit zur horizontalen Skalierung einer Django-Anwendung besteht darin, zusätzliche <em>App-Server</em> bereitzustellen, die Ihre Django-Anwendung und Ihren WSGI-HTTP-Server (wie <a href=\"https://gunicorn.org/\">Gunicorn</a> oder <a href=\"https://uwsgi-docs.readthedocs.io/en/latest/\">uWSGI</a>) ausführen. Um eingehende Anfragen über diesen Satz von App-Servern zu leiten und zu verteilen, können Sie einen <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#load-balancing\">Load Balancer</a> und <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">Reverse Proxy</a> wie <a href=\"https://www.nginx.com/\">Nginx</a> verwenden. Nginx kann auch statische Inhalte zwischenspeichern und <em>Transport Layer Security</em>-Verbindungen (TLS-Verbindungen) beenden, die zur Bereitstellung von HTTPS- und sicheren Verbindungen zu Ihrer Anwendung verwendet werden.</p>\n\n<p>Die Ausführung Ihrer Django-Anwendung und des Nginx-Proxys innerhalb von Docker-<a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#container\">Containern</a> stellt sicher, dass sich diese Komponenten unabhängig von der Umgebung, in der sie bereitgestellt werden, gleich verhalten. Darüber hinaus bieten Container viele Funktionen, die das Paketieren und Konfigurieren Ihrer Anwendung erleichtern.</p>\n\n<p>In diesem Tutorial skalieren Sie eine containerisierte Django- und Gunicorn-<a href=\"https://docs.djangoproject.com/en/3.0/intro/tutorial01/\">Umfrageanwendung</a> horizontal, indem Sie zwei App-Server bereitstellen, die jeweils eine Kopie eines Django- und Gunicorn-Anwendungscontainers ausführen.</p>\n\n<p>Des Weiteren aktivieren Sie HTTPS, indem Sie einen dritten Proxy-Server bereitstellen und konfigurieren, auf dem ein Nginx Reverse-Proxy-Container und ein <a href=\"https://certbot.eff.org/\">Certbot</a>-Client-Container ausgeführt werden. Certbot stellt TLS-Zertifikate für Nginx von der <a href=\"https://letsencrypt.org/\">Let’s Encrypt</a> Zertifizierungsstelle bereit. Dadurch wird sichergestellt, dass Ihre Website von <a href=\"https://www.ssllabs.com/\">SSL Labs</a> eine hohe Sicherheitsbewertung erhält. Dieser Proxy-Server empfängt alle externen Anfragen Ihrer Anwendung und sitzt vor den beiden <em>upstream</em> Django-App-Servern. Schließlich <em>härten</em> Sie dieses verteilte System ab, indem Sie den externen Zugriff auf nur den Proxy-Server beschränken.</p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Um dieser Anleitung zu folgen, benötigen Sie:</p>\n\n<ul>\n<li><p>Drei Ubuntu 18.04-Server:</p>\n\n<ul>\n<li>Zwei Server werden <strong>App-Server</strong> sein, die zum Ausführen Ihrer Django- und Gunicorn-Anwendung verwendet werden.</li>\n<li>Ein Server wird ein <strong>Proxy</strong>-Server sein, auf dem Nginx und Certbot ausgeführt werden.</li>\n<li>Alle Server sollten einen Nicht-Root-Benutzer mit <code>sudo</code>-Berechtigungen und eine aktive Firewall haben. Eine Anleitung für das Setup finden Sie im <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Leitfaden für die Ersteinrichtung des Servers</a>.</li>\n</ul></li>\n<li><p>Auf allen drei Servern installiertes Docker. Eine Anleitung zur Installation von Docker finden Sie in den Schritten 1 und 2 von <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04\">Installieren und Verwenden von Docker unter Ubuntu 18.04</a>.</p></li>\n<li><p>Einen registrierten Domänennamen.  In diesem Tutorial wird durchgängig <code><span class=\"highlight\">your_domain.com</span></code> verwendet. Einen Domänennamen können Sie kostenlos bei <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> erhalten oder Sie nutzen eine Domänenregistrierungsstelle Ihrer Wahl.</p></li>\n<li><p>Einen DNS-<code>A</code>-Eintrag mit <code><span class=\"highlight\">your-domain.com</span></code>, der auf die öffentliche IP-Adresse Ihres <strong>Proxy</strong>-Servers verweist. Falls Sie ein DigitalOcean-Konto nutzen, können Sie in <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">dieser Einführung in DigitalOcean-DNS</a> im Einzelnen nachlesen, wie Sie ihn hinzufügen.</p></li>\n<li><p>Einen S3-Objektspeicher-Bucket wie beispielsweise einen <a href=\"https://www.digitalocean.com/products/spaces/\">DigitalOcean Space</a> zur Speicherung der statischen Dateien Ihres Django-Projekts und einen Satz von Zugriffsschlüsseln für diesen Space. Um zu erfahren, wie Sie einen Space erstellen können, lesen Sie die Produktdokumentation <a href=\"https://www.digitalocean.com/docs/spaces/how-to/create/\">Erstellen von Spaces</a>. Um zu erfahren, wie Sie Zugriffsschlüssel für Spaces erstellen können, lesen Sie <a href=\"https://www.digitalocean.com/docs/spaces/how-to/administrative-access/#access-keys\">Zugriff auf Spaces mit Zugriffsschlüsseln gemeinsam nutzen</a>. Mit geringfügigen Änderungen können Sie jeden Objektspeicherdienst verwenden, der das Plugin <a href=\"https://django-storages.readthedocs.io/en/latest/\">django-storages</a> verwendet.</p></li>\n<li><p>Eine PostgreSQL-Server-Instanz, Datenbank und Benutzer für Ihre Django-Anwendung. Mit geringfügigen Änderungen können Sie jede Datenbank verwenden, die <a href=\"https://docs.djangoproject.com/en/2.2/ref/databases/\">Django unterstützt</a>.</p>\n\n<ul>\n<li>Die PostgreSQL-Datenbank sollte <strong>polls</strong> genannt werden (oder einen anderen einprägsamen Namen erhalten, den Sie unten in Ihre Konfigurations datei eingeben können) und in diesem Tutorial wird der Datenbankbenutzer <strong>sammy</strong> genannt. Führen Sie zum Erstellen dieser den Schritt 1 von <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Erstellen einer Django- und Gunicorn-Anwendung mit Docker</a> aus. Sie können diese Schritte von einem beliebigen der drei Server ausführen.</li>\n<li>In diesem Tutorial wird ein DigitalOcean <a href=\"https://www.digitalocean.com/products/managed-databases/\">Managed PostgreSQL-Cluster</a> verwendet. Um mehr über die Erstellung eines Clusters zu erfahren, lesen Sie die <a href=\"https://www.digitalocean.com/docs/databases/how-to/clusters/create/\">Produktdokumentation zu verwalteten Datenbanken</a> von DigitalOcean.</li>\n<li>Sie können auch Ihre eigene PostgreSQL-Instanz installieren und ausführen. Eine Anleitung zur Installation und Verwaltung von PostgreSQL auf einem Ubuntu-Server finden Sie unter <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04\">Installieren und Verwenden von PostgreSQL unter Ubuntu 18.04</a>.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"schritt-1-–-konfigurieren-des-ersten-django-app-servers\">Schritt 1 – Konfigurieren des ersten Django-App-Servers</h2>\n\n<p>Wir klonen zunächst das Django-Anwendungs-Repository auf den ersten App-Server. Dann konfigurieren und erstellen wir das Docker-Image und testen die Anwendung durch Ausführung des Django-Containers.</p>\n\n<p><span class='note'><strong>Anmerkung:</strong> Wenn Sie von <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Erstellen einer Django- und Gunicorn-Anwendung mit Docker</a> fortfahren, haben Sie Schritt 1 bereits abgeschlossen und können mit <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-2-%E2%80%94-configuring-the-second-django-application-server\">Schritt 2</a> fortfahren, um den <strong>zweiten</strong> App-Server zu konfigurieren.<br></span></p>\n\n<p>Beginnen Sie mit der Anmeldung beim ersten der beiden Django-App-Server und verwenden Sie <code>git</code>, um den Zweig <code>polls-docker</code> der Django Tutorial Umfrageanwendung <a href=\"https://github.com/do-community/django-polls\">GitHub-Repository</a> zu klonen. Dieses Repository enthält Code für die <a href=\"https://docs.djangoproject.com/en/3.0/intro/\">Umfrage-Beispielanwendung</a> der Django-Dokumentation. Der Zweig <code>polls-docker</code> enthält eine dockerisierte Version der Umfrageanwendung. Um zu erfahren, wie die Umfrageanwendung modifiziert wurde, um effektiv in einer containerisierten Umgebung zu arbeiten, lesen Sie bitte <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker\">Erstellen einer Django- und Gunicorn-Anwendung mit Docker</a>.</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Navigieren Sie in das Verzeichnis <code>django-polls</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cd django-polls\n</code></pre>\n<p>Dieses Verzeichnis enthält den Python-Code der Django-Anwendung, ein <code>Dockerfile</code>, das Docker zum Erstellen des Container-Images verwendet, sowie eine Datei <code>env</code>, die eine Liste von Umgebungsvariablen enthält, die an die laufende Umgebung des Containers übergeben werden müssen. Prüfen Sie das <code>Dockerfile</code> mit <code>cat</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cat Dockerfile\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>FROM python:3.7.4-alpine3.10\n\nADD django-polls/requirements.txt /app/requirements.txt\n\nRUN set -ex \\\n    &amp;&amp; apk add --no-cache --virtual .build-deps postgresql-dev build-base \\\n    &amp;&amp; python -m venv /env \\\n    &amp;&amp; /env/bin/pip install --upgrade pip \\\n    &amp;&amp; /env/bin/pip install --no-cache-dir -r /app/requirements.txt \\\n    &amp;&amp; runDeps=\"$(scanelf --needed --nobanner --recursive /env \\\n        | awk '{ gsub(/,/, \"\\nso:\", $2); print \"so:\" $2 }' \\\n        | sort -u \\\n        | xargs -r apk info --installed \\\n        | sort -u)\" \\\n    &amp;&amp; apk add --virtual rundeps $runDeps \\\n    &amp;&amp; apk del .build-deps\n\nADD django-polls /app\nWORKDIR /app\n\nENV VIRTUAL_ENV /env\nENV PATH /env/bin:$PATH\n\nEXPOSE 8000\n\nCMD [\"gunicorn\", \"--bind\", \":8000\", \"--workers\", \"3\", \"mysite.wsgi\"]\n</code></pre>\n<p>Dieses Dockerfile verwendet das offizielle Python 3.7.4 <a href=\"https://hub.docker.com/_/python\">Docker-Image</a> als Basis und installiert die Python-Paketanforderungen von Django und Gunicorn, wie sie in der Datei <code>django-polls/requirements.txt</code> definiert sind. Anschließend entfernt es einige unnötige Builddateien, kopiert den Anwendungscode in das Image und legt den Ausführungspfad <code>PATH</code> fest. Schließlich gibt es an, dass Port <code>8000</code> verwendet wird, um eingehende Container-Verbindungen zu akzeptieren und <code>gunicorn</code> mit 3 Workern ausgeführt wird, die Port <code>8000</code> abhören.</p>\n\n<p>Um mehr über die einzelnen Schritte in diesem Dockerfile zu erfahren, lesen Sie bitte Schritt 6 von <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-6-%E2%80%94-writing-the-application-dockerfile\">Erstellen einer Django- und Gunicorn-Anwendung mit Docker</a>.</p>\n\n<p>Erstellen Sie nun das Image mit <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Wir benennen das Image <code>polls</code> mit dem Flag <code>-t</code> und übergeben im aktuellen Verzeichnis als <em>Build-Kontext</em> den Satz von Daten, auf den beim Erstellen des Images verwiesen werden soll.</p>\n\n<p>Nachdem Docker das Image erstellt und mit Tags versehen hat, listen wir die verfügbaren Images mit <code>docker images</code> auf:</p>\n<pre class=\"code-pre  second-environment\"><code>docker images\n</code></pre>\n<p>Sie sollten die <code>polls</code>-Images aufgelistet sehen:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\npolls               latest              80ec4f33aae1        2 weeks ago         197MB\npython              3.7.4-alpine3.10    f309434dea3a        8 months ago        98.7MB\n</code></pre>\n<p>Bevor wir den Django-Container ausführen, müssen wir seine Betriebsumgebung mithilfe der im aktuellen Verzeichnis vorhandenen Datei <code>env</code> konfigurieren. Diese Datei wird an den Befehl <code>docker run</code> übergeben, der zum Ausführen des Containers verwendet wird, und Docker injiziert die konfigurierten Umgebungsvariablen in die Betriebsumgebung des Containers.</p>\n\n<p>Öffnen Sie die Datei <code>env</code> mit <code>nano</code> oder Ihrem bevorzugten Editor:</p>\n<pre class=\"code-pre  second-environment\"><code>nano env\n</code></pre>\n<p>Wir werden die Datei wie nachfolgend beschrieben konfigurieren und Sie müssen einige zusätzliche Werte hinzufügen.</p>\n<div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  second-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Geben Sie die fehlenden Werte für die folgenden Schlüssel ein:</p>\n\n<ul>\n<li><code>DJANGO_SECRET_KEY</code>: Setzen Sie diesen auf einen eindeutigen, nicht vorhersagbaren Wert, wie in den <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#secret-key\">Django-Dokumentationen</a> beschrieben. Eine Methode zur Generierung dieses Wertes wird in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Anpassen der Anwendungseinstellungen</a> in dem Tutorial <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Skalierbare Django-Anwendung</a> angeboten.</li>\n<li><code>DJANGO_ALLOWED_HOSTS</code>: Diese Variable sichert die Anwendung und verhindert HTTP-Host-Header-Angriffe. Setzen Sie diese Variable für Testzwecke auf <code>*</code>, einen Platzhalter, der auf alle Hosts zutrifft. In der Produktion sollten Sie diese Variable auf <code><span class=\"highlight\">your_domain.com</span></code> setzen. Um mehr über diese Django-Einstellungen zu erfahren, konsultieren Sie die <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#allowed-hosts\">Core-Einstellungen</a> der Django-Dokumentation.</li>\n<li><code>DATABASE_USERNAME</code>: Setzen Sie diesen auf den in den vorbereitenden Schritten erstellten PostgreSQL Datenbankbenutzer.</li>\n<li><code>DATABASE_NAME</code>: Setzen Sie diesen auf <code>polls</code> oder den in den vorbereitenden Schritten erstellten Namen der PostgreSQL-Datenbank.</li>\n<li><code>DATABASE_PASSWORD</code>: Setzen Sie dieses auf das in den vorbereitenden Schritten erstellte Passwort für den PostgreSQL Benutzer.</li>\n<li><code>DATABASE_HOST</code>: Setzen Sie diesen Wert auf den Hostnamen Ihrer Datenbank.</li>\n<li><code>DATABASE_PORT</code>: Setzen Sie diesen Wert auf den Port Ihrer Datenbank.</li>\n<li><code>STATIC_ACCESS_KEY_ID</code>: Setzen Sie diesen Wert auf den Zugriffsschlüssel Ihres S3-Buckets oder Space.</li>\n<li><code>STATIC_SECRET_KEY</code>: Setzen Sie diesen Wert auf das Zugriffsschlüsselgeheimnis Ihres S3-Bucket oder Space</li>\n<li><code>STATIC_BUCKET_NAME</code>: Setzen Sie diesen auf Ihren S3-Bucket- oder Space-Namen.</li>\n<li><code>STATIC_ENDPOINT_URL</code>: Setzen Sie diese auf die entsprechenden S3-Bucket- oder Space-Endpunkt-URL, z.B. <code>https://<span class=\"highlight\">space-name</span>.nyc3.digitaloceanspaces.com</code>, wenn sich Ihr Space in der Region <code>nyc3</code> befindet.</li>\n</ul>\n\n<p>Wenn Sie die Bearbeitung abgeschlossen haben, speichern und schließen Sie die Datei.</p>\n\n<p>Wir verwenden nun <code>docker run</code>, um den <code>CMD</code>-Satz in dem Dockerfile zu überschreiben und das Datenbankschema mit den Befehlen <code>manage.py makemigrations</code> und <code>manage.py migrate</code> zu erstellen:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"\n</code></pre>\n<p>Wir führen das Container-Image <code>polls:latest</code> aus, übergeben die von uns gerade modifizierte Umgebungsvariablendatei und überschreiben den Dockerfile-Befehl mit <code>sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"</code>, wodurch das durch den Anwendungscode definierte Datenbankschema erstellt wird. Wenn Sie dies zum ersten Mal ausführen, sollten Sie Folgendes sehen:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>No changes detected\nOperations to perform:\n  Apply all migrations: admin, auth, contenttypes, polls, sessions\nRunning migrations:\n  Applying contenttypes.0001_initial... OK\n  Applying auth.0001_initial... OK\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying contenttypes.0002_remove_content_type_name... OK\n  Applying auth.0002_alter_permission_name_max_length... OK\n  Applying auth.0003_alter_user_email_max_length... OK\n  Applying auth.0004_alter_user_username_opts... OK\n  Applying auth.0005_alter_user_last_login_null... OK\n  Applying auth.0006_require_contenttypes_0002... OK\n  Applying auth.0007_alter_validators_add_error_messages... OK\n  Applying auth.0008_alter_user_username_max_length... OK\n  Applying auth.0009_alter_user_last_name_max_length... OK\n  Applying auth.0010_alter_group_name_max_length... OK\n  Applying auth.0011_update_proxy_permissions... OK\n  Applying polls.0001_initial... OK\n  Applying sessions.0001_initial... OK\n</code></pre>\n<p>Dies zeigt an, dass das Datenbankschema erfolgreich erstellt wurde.</p>\n\n<p>Wenn Sie die <code>Migration</code> zu einem späteren Zeitpunkt ausführen, führt Django eine Nulloperation durch, es sei denn, das Datenbankschema wurde geändert.</p>\n\n<p>Als Nächstes führen wir eine weitere Instanz des Anwendungscontainers aus und verwenden darin eine interaktive Shell, um einen Administratorbenutzer für das Django-Projekt zu erstellen.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -i -t --env-file env polls sh\n</code></pre>\n<p>Dadurch erhalten Sie eine Shell-Eingabeaufforderung innerhalb des laufenden Containers, die Sie zum Erstellen des Django-Benutzers verwenden können:</p>\n<pre class=\"code-pre  second-environment\"><code>python manage.py createsuperuser\n</code></pre>\n<p>Geben Sie einen Benutzernamen, eine E-Mail-Adresse und ein Passwort für Ihren Benutzer ein. Drücken Sie nach dem Erstellen des Benutzers <code>STRG+D</code>, um den Container zu verlassen und zu beenden.</p>\n\n<p>Schließlich generieren wir die statischen Dateien für die Anwendung und laden sie mit <code>collectstatic</code> in den DigitalOcean Space hoch. Beachten Sie, dass dies möglicherweise einige Zeit dauern kann.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py collectstatic --noinput\"\n</code></pre>\n<p>Nachdem diese Dateien generiert und hochgeladen sind, erhalten Sie folgende Ausgabe.</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>121 static files copied.\n</code></pre>\n<p>Wir können die Anwendung nun ausführen:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env -p 80:8000 polls\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>[2019-10-17 21:23:36 +0000] [1] [INFO] Starting gunicorn 19.9.0\n[2019-10-17 21:23:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8000 (1)\n[2019-10-17 21:23:36 +0000] [1] [INFO] Using worker: sync\n[2019-10-17 21:23:36 +0000] [7] [INFO] Booting worker with pid: 7\n[2019-10-17 21:23:36 +0000] [8] [INFO] Booting worker with pid: 8\n[2019-10-17 21:23:36 +0000] [9] [INFO] Booting worker with pid: 9\n</code></pre>\n<p>Hier führen wir den in dem Dockerfile definierten Standardbefehl <code>gunicorn ---bind :8000 --workers 3 mysite.wsgi:application</code> aus und stellen den Container-Port <code>8000</code> frei, sodass Port <code>80</code> auf dem Ubuntu-Server dem Port <code>8000</code> des Containers <code>poll</code> zugeordnet wird.</p>\n\n<p>Sie sollten nun über Ihren Webbrowser zu der Anwendung <code>polls</code> navigieren können, indem Sie <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> in der URL-Leiste eingeben. Da für den Pfad <code>/</code> keine Route definiert ist, erhalten Sie wahrscheinlich einen <code>404 Page Not Found</code>-Fehler, der zu erwarten ist.</p>\n\n<p><span class='warning'><strong>Warnung:</strong> Wenn Sie die UFW-Firewall mit Docker verwenden, umgeht Docker alle konfigurierten UFW-Firewallregeln, wie in diesem <a href=\"https://github.com/docker/for-linux/issues/690\">GitHub-Problem</a> dokumentiert. Dies erklärt, warum Sie Zugriff auf Port <code>80</code> Ihres Servers haben, obwohl Sie in keinem vorbereitenden Schritt explizit eine UFW-Zugriffsregel erstellt haben. In <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-5-%E2%80%94-preventing-external-access-to-django-app-servers\">Schritt 5</a> werden wir diese Sicherheitslücke schließen, indem wir die UFW-Konfiguration patchen. Wenn Sie UFW nicht verwenden und die <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">Cloud Firewalls</a> von DigitalOcean einsetzen, können Sie diese Warnung getrost ignorieren.<br></span></p>\n\n<p>Navigieren Sie zu <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code>, um die Benutzeroberfläche der Umfrageanwendung zu sehen:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Oberfläche der Umfrageanwendung\"></p>\n\n<p>Um die administrative Oberfläche anzuzeigen, besuchen Sie <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/admin</code>. Sie sollten das Authentifizierungsfenster für den Administrator der Umfrageanwendung sehen:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin.png\" alt=\"Authentifizierungsseite für Polls-Administrator\"></p>\n\n<p>Geben Sie den administrativen Benutzernamen und das Passwort ein, das Sie mit dem Befehl <code>createsuperuser</code> erstellt haben.</p>\n\n<p>Nach der Authentifizierung können Sie auf die administrative Oberfläche der Umfrageanwendung zugreifen:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png\" alt=\"Administrative Hauptoberfläche von Polls\"></p>\n\n<p>Beachten Sie, dass statische Assets für die Anwendungen <code>admin</code> und <code>polls</code> direkt aus dem Objektspeicher bereitgestellt werden. Um dies zu bestätigen, konsultieren Sie <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#testing-spaces-static-file-delivery\">Prüfen der statischen Dateizustellung von Spaces</a>.</p>\n\n<p>Wenn Sie die Erkundung abgeschlossen haben, drücken Sie <code>Strg+C</code> im Terminalfenster, in dem der Docker-Container ausgeführt wird, um den Container zu beenden.</p>\n\n<p>Nachdem Sie nun bestätigt haben, dass der App-Container wie erwartet ausgeführt wird, können Sie ihn im getrennten (<em>detached</em>) Modus ausführen, wodurch er im Hintergrund ausgeführt wird und Ihnen ermöglicht, sich von Ihrer SSH-Sitzung abzumelden:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Das Flag <code>-d</code> weist Docker an, den Container im getrennten Modus auszuführen, das Flag <code>-rm</code> säubert das Dateisystem des Containers nach dem Verlassen des Containers und wir benennen den Container <code>polls</code>.</p>\n\n<p>Melden Sie sich von dem ersten Django App-Server ab und navigieren Sie zu <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code>, um zu bestätigen, dass der Container wie erwartet ausgeführt wird.</p>\n\n<p>Nachdem Ihr erster Django-App-Server ausgeführt wird, können Sie nun Ihren zweiten Django-App-Server einrichten.</p>\n\n<h2 id=\"schritt-2-–-konfigurieren-des-zweiten-django-app-servers\">Schritt 2 – Konfigurieren des zweiten Django-App-Servers</h2>\n\n<p>Da viele der Befehle zur Einrichtung dieses Servers die gleichen sind wie im vorherigen Schritt, werden sie hier in abgekürzter Form dargestellt. Bitte lesen Sie <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Schritt 1</a> für weitere Informationen zu einem bestimmten Befehl in diesem Schritt.</p>\n\n<p>Beginnen Sie damit, sich bei dem <strong>zweiten</strong> Django-App-Server anzumelden.</p>\n\n<p>Klonen Sie den Zweig <code>polls-docker</code> des GitHub-Repositorys von <code>django-polls</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Navigieren Sie in das Verzeichnis <code>django-polls</code>:</p>\n<pre class=\"code-pre  third-environment\"><code>cd django-polls\n</code></pre>\n<p>Erstellen Sie das Image mit <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Öffnen Sie die Datei <code>env</code> mit <code>nano</code> oder Ihrem bevorzugten Editor:</p>\n<pre class=\"code-pre  third-environment\"><code>nano env\n</code></pre><div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  third-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Geben Sie die fehlenden Werte wie in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Schritt 1</a> ein. Wenn Sie die Bearbeitung abgeschlossen haben, speichern und schließen Sie die Datei.</p>\n\n<p>Führen Sie den App-Container anschließend im getrennten Modus aus:</p>\n<pre class=\"code-pre  third-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Navigieren Sie zu <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span>/polls</code>, um zu bestätigen, dass der Container wie erwartet ausgeführt wird. Sie können sich sicher von dem zweiten App-Server anmelden, ohne Ihren laufenden Container zu beenden.</p>\n\n<p>Da beide Django App-Container ausgeführt werden, können Sie mit der Konfiguration des Reverse-Proxy-Containers von Nginx fortfahren.</p>\n\n<h2 id=\"schritt-3-–-konfigurieren-des-nginx-docker-containers\">Schritt 3 – Konfigurieren des Nginx Docker-Containers</h2>\n\n<p><a href=\"https://www.nginx.com/\">Nginx</a> ist ein vielseitiger Webserver, der eine Reihe von Funktionen wie <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\">Reverse-Proxying</a>, <a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\">Load Balancing</a> und <a href=\"https://en.wikipedia.org/wiki/Web_cache\">Caching</a> bietet. In diesem Tutorial haben wir die statischen Assets von Django in den Objektspeicher ausgelagert, sodass wir die Caching-Funktionen von Nginx nicht verwenden werden. Wir werden Nginx jedoch als Reverse-Proxy für unsere beiden Backend-Django-App-Server verwenden und eingehende Anfragen zwischen ihnen verteilen. Darüber hinaus wird Nginx <a href=\"https://en.wikipedia.org/wiki/TLS_termination_proxy\">TLS-Terminierung</a> und -Umleitung unter Verwendung eines von Certbot bereitgestellten TLS-Zertifikats durchführen. Das bedeutet, dass es die Clients zwingen wird, HTTPS zu verwenden, und eingehende HTTPS-Anfragen an Port 443 umzuleiten. Anschließend entschlüsselt Nginx HTTPS-Anfragen und leitet sie an die vorgelagerten Django-Server weiter.</p>\n\n<p>In diesem Tutorial haben wir die Designentscheidung getroffen, die Nginx-Container von den Backend-Servern zu entkoppeln. Abhängig von Ihrem Anwendungsfall können Sie sich dafür entscheiden, den Nginx-Container auf einem der Django-App-Server auszuführen, das Proxying von Anfragen sowohl lokal als auch auf dem anderen Django-Server auszuführen. Eine weitere mögliche Architektur wäre die Ausführung von zwei Nginx-Containern, einer auf jedem Backend-Server, mit einem Cloud <a href=\"https://www.digitalocean.com/products/load-balancer/\">Load Balancer</a> davor. Jede Architektur bietet andere Sicherheits- und Leistungsvorteile und Sie sollten Ihr System einem <a href=\"https://en.wikipedia.org/wiki/Load_testing\">Lasttest</a> unterziehen, um Engpässe aufzudecken. Die in diesem Tutorial beschriebene flexible Architektur ermöglicht es Ihnen, sowohl die Backend-Django-Anwendungsschicht als auch die Nginx-Proxying-Schicht zu skalieren. Sobald der einzelne Nginx-Container zum Engpass wird, können Sie auf mehrere Nginx-Proxys skalieren und einen Cloud Load Balancer oder schnellen L4 Load Balancer wie <a href=\"http://www.haproxy.org/\">HAProxy</a> hinzufügen.</p>\n\n<p>Da beide Django-App-Server ausgeführt werden, können wir mit dem Einrichten des Proxy-Servers beginnen. Melden Sie sich an Ihrem Proxy-Server an und erstellen Sie ein Verzeichnis namens <code>conf</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>mkdir conf\n</code></pre>\n<p>Erstellen Sie mit <code>nano</code> oder Ihrem bevorzugten Editor eine Konfigurationsdatei namens <code>nginx.conf</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>nano conf/nginx.conf\n</code></pre>\n<p>Fügen Sie die folgende Nginx-Konfiguration ein:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>\nupstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n\nserver {\n    listen 80 default_server;\n    return 444;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n\n    # SSL\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n\n    client_max_body_size 4G;\n    keepalive_timeout 5;\n\n        location / {\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header X-Forwarded-Proto $scheme;\n          proxy_set_header Host $http_host;\n          proxy_redirect off;\n          proxy_pass http://django;\n        }\n\n    location ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n    }\n\n}\n</code></pre>\n<p>Diese Blöcke <code>upstream</code>, <code>server</code> und <code>location</code> konfigurieren Nginx so, dass HTTP-Anfragen an HTTPS umgeleitet werden und sorgen für einen Lastausgleich zwischen den beiden in Schritt 1 und 2 konfigurierten Django-App-Servern. Um mehr über die Nginx-Konfigurationsdatei zu erfahren, lesen Sie bitte in diesem Artikel über das <a href=\"https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts#understanding-nginx-configuration-contexts\">Verstehen der Nginx-Konfigurationsdateistruktur und der Konfigurationskontexte</a>. Außerdem kann dieser Artikel zum <a href=\"https://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\">Verstehen von Nginx-Server und Location-Block-Auswahlalgorithmen</a> hilfreich sein.</p>\n\n<p>Diese Konfiguration wurde aus Beispielkonfigurationsdateien zusammengestellt, die von <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Gunicorn</a>, <a href=\"https://github.com/certbot/certbot/blob/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf\">Certbot</a> und <a href=\"https://hub.docker.com/_/nginx\">Nginx</a> bereitgestellt wurden, und ist als eine minimale Nginx-Konfiguration gedacht, um diese Architektur betriebsbereit zu machen. Die Feineinstellung dieser Nginx-Konfiguration geht über den Umfang dieses Artikels hinaus, Sie können jedoch ein Tool wie <a href=\"https://www.digitalocean.com/community/tools/nginx\">NGINXConfig</a> verwenden, um performante und sichere Nginx-Konfigurationsdateien für Ihre Architektur zu generieren.</p>\n\n<p>Der Block <code>upstream</code> definiert die Gruppe von Servern, die zum Proxying von Anfragen zur Verwendung der Anweisung <code>proxy_pass</code> verwendet werden:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>upstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n. . .\n</code></pre>\n<p>In diesem Block nennen wir den upstream <code>django</code> und schließen die IP-Adressen der beiden Django-App-Server ein. Wenn die App-Server auf DigitalOcean ausgeführt werden und VPC Networking aktiviert haben, sollten Sie hier ihre privaten IP-Adressen verwenden. Um zu erfahren, wie Sie VPC-Networking auf DigitalOcean aktivieren können, lesen Sie bitte <a href=\"https://www.digitalocean.com/docs/networking/vpc/how-to/enable/\">Aktivieren von VPC-Networking auf vorhandenen Droplets</a>.</p>\n\n<p>Der erste Block <code>server</code> erfasst Anfragen, die nicht Ihrer Domäne entsprechen und beendet die Verbindung. Beispielsweise würde eine direkte HTTP-Anfrage an die IP-Adresse Ihres Servers von diesem Block bearbeitet werden:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80 default_server;\n    return 444;\n}\n. . .\n</code></pre>\n<p>Der nächste Block <code>server</code> leitet HTTP-Anfragen an Ihre Domäne über eine <a href=\"https://en.wikipedia.org/wiki/HTTP_301\">HTTP 301-Umleitung</a> an HTTPS um. Diese Anfragen werden dann vom letzten Block <code>server</code> bearbeitet:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name your_domain.com;\n    return 301 https://$server_name$request_uri;\n}\n. . .\n</code></pre>\n<p>Diese zwei Anweisungen definieren die Pfade zum TLS-Zertifikat und geheimen Schlüssel. Diese werden mit Certbot bereitgestellt und im nächsten Schritt in den Nginx-Container eingebunden.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\nssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n. . .\n</code></pre>\n<p>Bei diesen Parametern handelt es sich um die von Certbot empfohlenen SSL-Sicherheitsstandards. Um mehr über sie zu erfahren, lesen Sie bitte das <a href=\"https://nginx.org/en/docs/http/ngx_http_ssl_module.html\">Modul ngx_http_ssl_module</a> der Nginx-Dokumentation. Mozillas <a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\">Sicherheits-/Serverseitiges TLS</a> ist ein weiterer hilfreicher Leitfaden, den Sie für die Feinabstimmung Ihrer SSL-Konfiguration verwenden können.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n. . .\n</code></pre>\n<p>Diese beiden Anweisungen aus Gunicorns <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Nginx-Beispielkonfiguration</a> legen die maximal zulässige Größe des Client-Anfragekörpers fest und weisen das Timeout für Keep-Alive-Verbindungen mit dem Client zu. Nginx schließt Verbindungen mit dem Client nach <code>keepalive_timeout</code>-Sekunden.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nclient_max_body_size 4G;\nkeepalive_timeout 5;\n. . .\n</code></pre>\n<p>Der erste Block <code>location</code> weist Nginx zum Proxying von Anfragen über HTTP an die <code>upstream django</code>-Server an. Er bewahrt zusätzlich Client HTTP-Header auf, die die Ursprungs-IP-Adresse, das zur Verbindung verwendete Protokoll und den Ziel-Host erfassen:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation / {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://django;\n}\n. . .\n</code></pre>\n<p>Um mehr über diese Anweisungen zu erfahren, lesen Sie bitte <a href=\"https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration\">Bereitstellen von Gunicorn</a> und <a href=\"http://nginx.org/en/docs/http/ngx_http_proxy_module.html\">das Modul ngx_http_proxy_module</a> der Nginx-Dokumentation.</p>\n\n<p>Der letzte Block <code>location</code> erfasst Anfragen an den Pfad <code>/well-known/acme-Challenge/</code>, der von Certbot für HTTP-01-Challenges verwendet wird, um Ihre Domäne mit Let&rsquo;s Encrypt zu verifizieren und TLS-Zertifikate bereitzustellen oder zu erneuern. Weitere Informationen über die von Certbot verwendete HTTP-01-Challenge finden Sie unter <a href=\"https://letsencrypt.org/docs/challenge-types/\">Challenge-Arten</a> in der Let’s Encrypt-Dokumentation.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n}\n</code></pre>\n<p>Wenn Sie die Bearbeitung abgeschlossen haben, speichern und schließen Sie die Datei.</p>\n\n<p>Sie können diese Konfigurationsdatei nun verwenden, um einen Nginx Docker-Container auszuführen. In diesem Tutorial verwenden wir das Image <code>nginx:1.19.0</code>, Version <code>1.19.0</code> des <a href=\"https://hub.docker.com/_/nginx\">offiziellen Docker-Images</a>, das von Nginx verwaltet wird.</p>\n\n<p>Wenn wir den Container zum ersten Mal ausführen, wird Nginx einen Fehler ausgeben und fehlschlagen, da wir die in der Konfigurationsdatei definierten Zertifikate noch nicht bereitgestellt haben. Wir werden jedoch trotzdem den Befehl zum Herunterladen des Nginx-Images lokal ausführen und testen, ob alles andere korrekt funktioniert:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Hier nennen wir den Container <code>nginx</code> und ordnen die Host-Ports <code>80</code> und <code>443</code> den jeweiligen Container-Ports zu. Das Flag <code>-v</code> bindet die Konfigurationsdatei unter <code>/etc/nginx/conf.d/nginx.conf</code> in den Nginx-Container ein, für dessen Laden das Nginx-Image vorkonfiguriert ist. Es wird im Modus <code>ro</code> oder „read-only“ eingebunden, sodass der Container die Datei nicht verändern kann. Das Web-Stammverzeichnis <code>/var/www/html</code> ist ebenfalls in den Container eingebunden. Schließlich weist <code>nginx:1.19.0</code> Docker an, das Image <code>nginx:1.19.0</code> aus Dockerhub zu ziehen und auszuführen.</p>\n\n<p>Docker wird das Image ziehen und ausführen, dann wird Nginx einen Fehler ausgeben, wenn es das konfigurierte TLS-Zertifikat und den geheimen Schlüssel nicht findet. Im nächsten Schritt stellen wir diese mithilfe eines dockerisierten Certbot-Clients und der Zertifizierungsstelle Let’s Encrypt bereit.</p>\n\n<h2 id=\"schritt-4-–-konfigurieren-von-certbot-und-let’s-encrypt-zertifikaterneuerung\">Schritt 4 – Konfigurieren von Certbot und Let’s Encrypt-Zertifikaterneuerung</h2>\n\n<p><a href=\"https://github.com/certbot/certbot\">Certbot</a> ist ein Let’s Encrypt-Client, der von der <a href=\"https://www.eff.org/\">Electronic Frontier Foundation</a> entwickelt wurde. Er stellt kostenlose TLS-Zertifikate von der <a href=\"https://letsencrypt.org/\">Let’s Encrypt</a>-Zertifizierungsstelle zur Verfügung, mit denen Browser die Identität Ihrer Webserver überprüfen können. Da wir auf unserem Nginx-Proxy-Server Docker installiert haben, verwenden wir das <a href=\"https://hub.docker.com/r/certbot/certbot/\">Certbot Docker-Image</a> zur Bereitstellung und Erneuerung der TLS-Zertifikate.</p>\n\n<p>Stellen Sie zunächst sicher, dass Sie über einen DNS-<code>A</code>-Eintrag verfügen, der der öffentlichen IP-Adresse des Proxy-Servers zugeordnet ist. Stellen Sie dann auf Ihrem Proxy-Server eine Staging-Version der Zertifikate unter Verwendung des Docker-Images <code>certbot</code> bereit:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone --staging -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Dieser Befehl führt das <code>certbot</code> Docker-Image im interaktiven Modus aus und leitet Port <code>80</code> auf dem Host an den Container-Port <code>80</code> weiter. Er erstellt zwei Host-Verzeichnisse und bindet sie in die Container ein: <code>/etc/letsencrypt/</code> und <code>/var/lib/letsencrypt/</code>. <code>certbot</code> wird im Modus <code>standalone</code> ohne Nginx ausgeführt und verwendet die <code>Staging</code>-Server von Let’s Encrypt, um die Domänenvalidierung durchzuführen.</p>\n\n<p>Geben Sie, wenn Sie dazu aufgefordert werden, Ihre E-Mail-Adresse ein und stimmen Sie den Nutzungsbedingungen zu. Wenn die Domänenvalidierung erfolgreich war, sollten Sie die folgende Ausgabe sehen:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Obtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for stubb.dev\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem\n   Your cert will expire on 2020-09-15. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - Your account credentials have been saved in your Certbot\n   configuration directory at /etc/letsencrypt. You should make a\n   secure backup of this folder now. This configuration directory will\n   also contain certificates and private keys obtained by Certbot so\n   making regular backups of this folder is ideal.\n</code></pre>\n<p>Sie können das Zertifikat mit <code>cat</code> inspizieren:</p>\n<pre class=\"code-pre  fourth-environment\"><code>sudo cat /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n</code></pre>\n<p>Mit dem bereitgestellten TLS-Zertifikat können wir die im vorherigen Schritt eingebundene Nginx-Konfiguration testen:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Dies ist derselbe Befehl, der in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Schritt 3</a> ausgeführt wurde, mit dem Hinzufügen der beiden kürzlich erstellten Let’s Encrypt-Verzeichnisse:</p>\n\n<p>Sobald Nginx ausgeführt wird, navigieren Sie zu <code>http://<span class=\"highlight\">your_domain.com</span></code>. Möglicherweise erhalten Sie in Ihrem Browser eine Warnung, dass die Zertifizierungsstelle ungültig ist. Dies ist zu erwarten, da wir Staging-Zertifikate und keine Produktions-Let’s Encrypt-Zertifikate bereitgestellt haben. Überprüfen Sie die URL-Leiste Ihres Browsers, um zu bestätigen, dass Ihre HTTP-Anfrage an HTTPS umgeleitet wurde.</p>\n\n<p>Drücken Sie zum Beenden von Nginx in Ihrem Terminal <code>Strg+C</code> und führen Sie den Client <code>certbot</code> erneut aus, diesmal ohne das Flag <code>--staging</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Wenn Sie dazu aufgefordert werden, entweder das vorhandene Zertifikat beizubehalten oder es zu erneuern und zu ersetzen, drücken Sie <code>2</code> zum Erneuern und dann <code>ENTER</code>, um Ihre Wahl zu bestätigen.</p>\n\n<p>Wenn das Produktions-TLS-Zertifikat bereitgestellt ist, führen Sie den Nginx-Server erneut aus:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Navigieren Sie in Ihrem Browser zu <code>http://<span class=\"highlight\">your_domain.com</span></code>. Bestätigen Sie in der URL-Leiste, dass die HTTP-Anfrage an HTTPS umgeleitet wurde. Da für die Umfrageanwendung keine Standardroute konfiguriert ist, sollten Sie den Django-Fehler <strong>Page not found</strong> (Seite nicht gefunden) sehen. Navigieren Sie zu <code>https://<span class=\"highlight\">your_domain.com</span>/polls</code> und Sie sehen die Standardoberfläche der Umfrageanwendung:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Oberfläche der Umfrageanwendung\"></p>\n\n<p>Zu diesem Zeitpunkt haben Sie mit dem Certbot Docker-Client ein Produktions-TLS-Zertifikat bereitgestellt und externe Anfragen an die beiden Django-App-Server durch Reverse Proxying und Lastausgleich umgeleitet.</p>\n\n<p>Die Let’s Encrypt-Zertifikate laufen alle 90 Tage ab. Um sicherzustellen, dass Ihr Zertifikat gültig bleibt, sollten Sie es regelmäßig vor dessen geplantem Ablauf erneuern. Wenn Nginx ausgeführt wird, sollten Sie den Certbot-Client im Modus <code>webroot</code> anstelle des Modus <code>standalone</code> verwenden. Das bedeutet, dass Certbot die Validierung durch die Erstellung einer Datei im Verzeichnis <code>/var/www/html/.well-known/acme-challenge/</code> durchführt, und die Validierungsanforderungen von Let’s Encrypt an diesen Pfad werden von der in der Nginx-Konfiguration in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Schritt 3</a> definierten Regel <code>location</code> erfasst. Certbot wird dann die Zertifikate rotieren, und Sie können Nginx neu laden, sodass es dieses neu bereitgestellte Zertifikat verwendet.</p>\n\n<p>Es gibt mehrere Möglichkeiten, um dieses Verfahren zu automatisieren und die automatische Erneuerung von TLS-Zertifikaten geht über den Umfang dieses Tutorials hinaus. Ein ähnliches Verfahren unter Verwendung des Scheduling-Dienstprogramms <code>cron</code> finden Sie in Schritt 6 von <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates%5D(https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates)\">Sichern einer containerisierten Node.js-Anwendung mit Nginx, Let’s Encrypt, und Docker Compose</a>.</p>\n\n<p>Drücken Sie zum Beenden des Nginx-Containers in Ihrem Terminal <code>Strg+C</code>. Führen Sie ihn erneut im getrennten Modus aus, indem Sie das Flag <code>-d</code> anhängen:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -d -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n  -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Verwenden Sie mit im Hintergrund ausgeführtem Nginx den folgenden Befehl, um einen Probelauf des Zertifikatserneuerungsverfahrens auszuführen:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm --name certbot \\\n    -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n  -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n  -v \"/var/www/html:/var/www/html\" \\\n  certbot/certbot renew --webroot -w /var/www/html --dry-run\n</code></pre>\n<p>Wir verwenden das Plugin <code>--webroot</code>, geben den Web-Stammpfad ein und verwenden das Flag <code>--dry-run</code> zum Überprüfen der ordnungsgemäßen Funktion, ohne die Zertifikatserneuerung tatsächlich durchzuführen.</p>\n\n<p>Wenn die Erneuerungssimulation erfolgreich ist, sollten Sie die folgende Ausgabe sehen:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Cert not due for renewal, but simulating renewal for dry run\nPlugins selected: Authenticator webroot, Installer None\nRenewing an existing certificate\nPerforming the following challenges:\nhttp-01 challenge for <span class=\"highlight\">your_domain.com</span>\nUsing the webroot path /var/www/html for all unmatched domains.\nWaiting for verification...\nCleaning up challenges\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nnew certificate deployed without reload, fullchain is\n/etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates below have not been saved.)\n\nCongratulations, all renewals succeeded. The following certs have been renewed:\n  /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem (success)\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates above have not been saved.)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n</code></pre>\n<p>In einer Produktionseinstellung sollten Sie nach der Erneuerung von Zertifikaten Nginx neu laden, damit die Änderungen wirksam werden. Führen Sie zum Neuladen von Nginx den folgenden Befehl aus:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker kill -s HUP nginx\n</code></pre>\n<p>Dieser Befehl sendet ein <a href=\"https://en.wikipedia.org/wiki/SIGHUP\">HUP</a> Unix-Signal an den Nginx-Prozess, der innerhalb des Docker-Containers <code>nginx</code> ausgeführt wird. Nach Empfang dieses Signals lädt Nginx seine Konfiguration und erneuerten Zertifikate neu.</p>\n\n<p>Wenn HTTPS aktiviert ist und alle Komponenten dieser Architektur ausgeführt werden, besteht der letzte Schritt darin, die Einrichtung zu sperren, indem der externe Zugriff auf die beiden Backend-App-Server verhindert wird; alle HTTP-Anfragen sollten über den Nginx-Proxy laufen.</p>\n\n<h2 id=\"schritt-5-–-verhindern-des-externen-zugriffs-auf-django-app-server\">Schritt 5 – Verhindern des externen Zugriffs auf Django-App-Server</h2>\n\n<p>In der in diesem Tutorial beschriebenen Architektur erfolgt die SSL-Terminierung am Nginx-Proxy. Das bedeutet, dass Nginx die SSL-Verbindung entschlüsselt und die Pakete unverschlüsselt an die Django-App-Server weitergeleitet werden. Für viele Anwendungsfälle ist diese Sicherheitsstufe ausreichend. Für Anwendungen mit Finanz- oder Gesundheitsdaten sollten Sie eventuell eine End-to-End-Verschlüsselung implementieren. Sie können dies tun, indem Sie verschlüsselte Pakete über den Load Balancer weiterleiten und auf den App-Servern entschlüsseln oder am Proxy neu verschlüsseln und auf den Django-App-Servern wieder entschlüsseln. Diese Techniken gehen über den Rahmen dieses Artikels hinaus. Um mehr zu erfahren, lesen Sie bitte <a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">End-to-End-Verschlüsselung</a>.</p>\n\n<p>Der Nginx-Proxy fungiert als Gateway zwischen externem Datenverkehr und dem internen Netzwerk. Theoretisch sollten keine externen Clients direkten Zugriff auf die internen App-Server haben, und alle Anfragen sollten über den Nginx-Server laufen. Der Hinweis in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Schritt 1</a> beschreibt kurz ein <a href=\"https://github.com/docker/for-linux/issues/690\">offenes Problem</a> mit Docker, bei dem Docker standardmäßig die <code>ufw</code>-Firewalleinstellungen umgeht und Ports extern öffnet, die möglicherweise unsicher sind. Um dieses Sicherheitsproblem zu beheben wird empfohlen, bei der Arbeit mit Docker-fähigen Servern <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">Cloud Firewalls</a> zu verwenden. Weitere Informationen zum Erstellen von Cloud Firewalls mit DigitalOcean finden Sie unter <a href=\"https://www.digitalocean.com/docs/networking/firewalls/how-to/create/\">Erstellen von Firewalls</a>. Sie können <code>iptables</code> auch direkt manipulieren, anstatt <code>ufw</code> zu verwenden. Um mehr über die Verwendung von <code>iptables</code> mit Docker zu erfahren, lesen Sie bitte <a href=\"https://docs.docker.com/network/iptables/\">Docker und iptables</a>.</p>\n\n<p>In diesem Schritt ändern wir die UFW-Konfiguration so, dass der externe Zugriff auf die von Docker geöffneten Host-Ports blockiert wird. Bei der Ausführung von Django auf den App-Servern haben wir das Flag <code>-p 80:8000</code> an <code>docker</code> übergeben, das Port <code>80</code> auf dem Host an den Container-Port <code>8000</code> weiterleitet. Dadurch wurde Port <code>80</code> auch für externe Clients geöffnet, was Sie unter <code>http://<span class=\"highlight\">your_app_server_1_IP</span></code> überprüfen können. Um den direkten Zugriff zu verhindern, ändern wir die UFW-Konfiguration mithilfe der im <a href=\"https://github.com/chaifeng/ufw-docker\">ufw-docker GitHub-Repository</a> beschriebenen Methode.</p>\n\n<p>Beginnen Sie damit, sich bei dem ersten Django-App-Server anzumelden. Öffnen Sie dann die Datei <code>/etc/ufw/after.rules</code> mit superuser-Berechtigungen, indem Sie <code>nano</code> oder Ihren bevorzugten Editor verwenden:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Geben Sie bei Aufforderung Ihr Passwort ein und drücken Sie zur Bestätigung <code>ENTER</code>.</p>\n\n<p>Sie sollten die folgenden <code>ufw</code>-Regeln sehen:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>#\n# rules.input-after\n#\n# Rules that should be run after the ufw command line added rules. Custom\n# rules should be added to one of these chains:\n#   ufw-after-input\n#   ufw-after-output\n#   ufw-after-forward\n#\n\n# Don't delete these required lines, otherwise there will be errors\n*filter\n:ufw-after-input - [0:0]\n:ufw-after-output - [0:0]\n:ufw-after-forward - [0:0]\n# End required lines\n\n# don't log noisy services by default\n-A ufw-after-input -p udp --dport 137 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 138 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 139 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 445 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 67 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 68 -j ufw-skip-to-policy-input\n\n# don't log noisy broadcast\n-A ufw-after-input -m addrtype --dst-type BROADCAST -j ufw-skip-to-policy-input\n\n# don't delete the 'COMMIT' line or these rules won't be processed\nCOMMIT\n</code></pre>\n<p>Scrollen Sie nach unten und fügen Sie den folgenden Block mit UFW-Konfigurationsregeln ein:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Diese Regeln schränken den öffentlichen Zugriff auf die von Docker geöffneten Ports ein und ermöglichen den Zugriff aus den privaten IP-Bereichen <code>10.0.0/8</code>, <code>172.16.0.0/12</code> und <code>192.168.0.0/16</code>. Wenn Sie VPC mit DigitalOcean verwenden, dann haben Droplets in Ihrem VPC-Netzwerk über die private Netzwerkschnittstelle Zugriff auf den offenen Port, externe Clients jedoch nicht. Weitere Informationen über VPC finden Sie in der <a href=\"https://www.digitalocean.com/docs/networking/vpc/\">offiziellen VPC-Dokumentation</a>. Um mehr über die in diesem Snippet implementierten Regeln zu erfahren, lesen Sie bitte <a href=\"https://github.com/chaifeng/ufw-docker#how-it-works\">Funktionsweise</a> in der <a href=\"https://github.com/chaifeng/ufw-docker\">ufw-docker README</a>.</p>\n\n<p>Wenn Sie VPC nicht mit DigitalOcean verwenden und die öffentlichen IP-Adressen der App-Server in den Block <code>upstream</code> Ihrer Nginx-Konfiguration eingegeben haben, müssen Sie die UFW-Firewall explizit ändern, um den Datenverkehr vom Nginx-Server über Port <code>80</code> auf den Django-App-Servern zuzulassen. Eine Anleitung zur Erstellung von <code>allow</code>-Regeln mit der UFW-Firewall finden Sie unter <a href=\"https://www.digitalocean.com/community/tutorials/ufw-essentials-common-firewall-rules-and-commands\">UFW Grundlagen: Allgemeine Firewallregeln und -befehle</a>.</p>\n\n<p>Wenn Sie die Bearbeitung abgeschlossen haben, speichern und schließen Sie die Datei.</p>\n\n<p>Starten Sie <code>ufw</code> neu, damit die neue Konfiguration übernommen wird:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Navigieren Sie in Ihrem Webbrowser zu <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code>, um zu bestätigen, dass Sie über Port <code>80</code> nicht mehr auf die App-Server zugreifen können.</p>\n\n<p>Wiederholen Sie diesen Vorgang auf dem zweiten Django-App-Server.</p>\n\n<p>Melden Sie sich bei dem ersten App-Server ab oder öffnen Sie ein anderes Terminalfenster und melden Sie sich bei dem zweiten Django-App-Server an. Öffnen Sie dann die Datei <code>/etc/ufw/after.rules</code> mit superuser-Berechtigungen, indem Sie <code>nano</code> oder Ihren bevorzugten Editor verwenden:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Geben Sie bei Aufforderung Ihr Passwort ein und drücken Sie zur Bestätigung <code>ENTER</code>.</p>\n\n<p>Scrollen Sie nach unten und fügen Sie den folgenden Block mit UFW-Konfigurationsregeln ein:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  third-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Wenn Sie die Bearbeitung abgeschlossen haben, speichern und schließen Sie die Datei.</p>\n\n<p>Starten Sie <code>ufw</code> neu, damit die neue Konfiguration übernommen wird:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Navigieren Sie in Ihrem Webbrowser zu <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span></code>, um zu bestätigen, dass Sie über Port <code>80</code> nicht mehr auf die App-Server zugreifen können.</p>\n\n<p>Navigieren Sie abschließend zu <code>https://<span class=\"highlight\">your_domain_here</span>/polls</code>, um zu bestätigen, dass der Nginx-Proxy weiterhin Zugriff auf die upstream Django-Server hat. Sie sollten die Standardoberfläche der Umfrageanwendung sehen.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>In diesem Tutorial haben Sie mit Docker-Containern eine skalierbare Django Umfrageanwendung eingerichtet. Wenn Ihr Datenverkehr steigt und die Last auf dem System zunimmt, können Sie jede Schicht separat skalieren: die Nginx-Proxying-Schicht, die Django-Backend-Anwendungsschicht und die PostgreSQL-Datenbankschicht.</p>\n\n<p>Beim Aufbau eines verteilten Systems müssen Sie oft mehrere Designentscheidungen treffen, und mehrere Architekturen können Ihrem Anwendungsfall gerecht werden. Die in diesem Tutorial beschriebene Architektur ist als flexible Blaupause für den Entwurf skalierbarer Anwendungen mit Django und Docker gedacht.</p>\n\n<p>Möglicherweise möchten Sie das Verhalten Ihrer Container steuern, wenn sie auf Fehler stoßen, oder Container automatisch ausführen, wenn Ihr System gestartet wird. Zu diesem Zweck können Sie einen Prozessmanager wie <a href=\"https://en.wikipedia.org/wiki/Systemd\">Systemd</a> verwenden oder Neustartrichtlinien implementieren. Weitere Informationen hierzu finden Sie unter <a href=\"https://docs.docker.com/config/containers/start-containers-automatically/\">Automatisches Starten von Containern</a> in der Docker-Dokumentation.</p>\n\n<p>Wenn Sie im großen Maßstab mit mehreren Hosts arbeiten, die dasselbe Docker-Image ausführen, kann es effizient sein, Schritte mit einem Konfigurations-Managementtool wie <a href=\"https://www.ansible.com/\">Ansible</a> oder <a href=\"https://www.chef.io/\">Chef</a> zu automatisieren. Um mehr über das Konfigurationsmanagement zu erfahren, lesen Sie bitte <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-configuration-management\">Eine Einführung in das Konfigurationsmanagement</a> und <a href=\"https://www.digitalocean.com/community/meetup_kits/automating-server-setup-with-ansible-a-digitalocean-workshop-kit\">Automatisieren der Servereinrichtung mit Ansible: Ein DigitalOcean-Workshop-Kit</a>.</p>\n\n<p>Anstatt auf jedem Host dasselbe Image zu erstellen, können Sie die Bereitstellung auch mithilfe einer Image-Registrierung wie <a href=\"https://hub.docker.com/\">Docker Hub</a> rationalisieren, bei der Docker-Images zentral erstellt, gespeichert und an mehrere Server verteilt werden. Zusammen mit einer Image-Registrierung kann Ihnen eine kontinuierliche Integrations- und Bereitstellungspipeline dabei helfen, Images zu erstellen, zu testen und auf Ihre App-Server zu verteilen. Weitere Informationen zu CI/CD finden Sie unter <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-ci-cd-best-practices\">Eine Einführung in die CI/CD Best Practices</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:38 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/scalable_django/polls_app.png","linkMd5":"bc1428647c5f6f1dbcc36cbd85ba0fe6","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","destWidth":474,"destHeight":473,"sourceBytes":43341,"destBytes":1896,"author":"Hanif Jetha","articleImgCdnMap":{"https://assets.digitalocean.com/articles/scalable_django/polls_app.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/31/07-48-31-305_44661f4fc2769a02.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn38@2020_6/2020/08/31/07-48-31-498_6d93c2bd68b66072.webp"},"publishedOrCreatedDate":1598860106974},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como instalar o Elasticsearch, Logstash e Kibana (Pilha Elastic) no Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-pt","description":"<h3 id=\"introdução\">Introdução</h3>\n\n<p>A Pilha Elastic — anteriormente conhecida como <em>ELK Stack</em> — é uma coleção de softwares de código aberto produzida pela <a href=\"https://www.elastic.co/\">Elastic</a> que permite pesquisar, analisar e visualizar logs gerados a partir de qualquer fonte em qualquer formato. Esta é uma prática conhecida como <em>centralização de logs</em>. A centralização de logs pode ser útil ao tentar identificar problemas com seus servidores ou aplicações, uma vez que ela permite que você pesquise todos os seus logs em um único lugar. Também é útil porque ele lhe permite identificar problemas que abrangem vários servidores correlacionando seus logs durante um período de tempo específico.</p>\n\n<p>A pilha Elastic tem quatro componentes principais:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/elasticsearch\"><strong>Elasticsearch</strong></a>: um mecanismo de busca <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\"><em>RESTful</em></a> distribuído que armazena todos os dados coletados.</li>\n<li><a href=\"https://www.elastic.co/products/logstash\"><strong>Logstash</strong></a>: o componente de processamento de dados da pilha Elastic que envia dados recebidos para o Elasticsearch.</li>\n<li><a href=\"https://www.elastic.co/products/kibana\"><strong>Kibana</strong></a>: uma interface Web para pesquisar e visualizar logs.</li>\n<li><a href=\"https://www.elastic.co/products/beats\"><strong>Beats</strong></a>: transportadores de dados leves e de propósito único que podem enviar dados de centenas ou milhares de máquinas para o Logstash ou para o Elasticsearch.</li>\n</ul>\n\n<p>Neste tutorial, você irá instalar a <a href=\"https://www.elastic.co/elk-stack\">pilha Elastic</a> em um servidor Ubuntu 20.04. Você irá aprender como instalar todos os componentes da pilha Elastic — incluindo o <a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>, um Beat usado para encaminhar e centralizar logs e arquivos — e configurá-los para coletar e visualizar logs de sistema. Além disso, como o Kibana normalmente está disponível apenas no <code>localhost</code>, usaremos o <a href=\"https://www.nginx.com/\">Nginx</a> para fazer proxy dele para que ele seja acessível via um navegador Web. Vamos instalar todos esses componentes em um único servidor, que vamos nos referir como nosso <em>servidor da pilha Elastic</em>.</p>\n\n<p><span class='note'><strong>Nota</strong>: ao instalar a pilha Elastic, você deve usar a mesma versão em toda a pilha. Neste tutorial, vamos instalar as versões mais recentes de toda a pilha que são, no momento da escrita deste artigo, o Elasticsearch 7.7.1, Kibana 7.7.1, Logstash 7.7.1 e Filebeat 7.7.1.<br></span></p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Para concluir este tutorial, você precisará do seguinte:</p>\n\n<ul>\n<li><p>Um servidor Ubuntu 20.04, com 4GB de RAM e 2 CPUs configuradas com um usuário sudo não root. Você pode conseguir isso seguindo o guia <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Initial Server Setup with Ubuntu 20.04</a>. Para este tutorial, vamos trabalhar com a quantidade mínima necessária de CPU e RAM para executar o Elasticsearch. Observe que a quantidade de CPU, RAM e armazenamento que seu servidor Elasticsearch exigirá depende do volume de logs que você espera.</p></li>\n<li><p>OpenJDK 11 instalado. Veja a seção <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04#installing-the-default-jrejdk\">Installing the Default JRE/JDK</a> <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04\">How To Install Java with Apt on Ubuntu 20.04</a> para configurar isto.</p></li>\n<li><p>Nginx instalado em seu servidor, que vamos configurar mais tarde neste guia como um proxy reverso para o Kibana. Siga nosso guia <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">How to Install Nginx on Ubuntu 20.04</a> para configurar isso.</p></li>\n</ul>\n\n<p>Além disso, como a pilha Elastic é usada para acessar informações valiosas sobre seu servidor, que você não deseja que usuários não autorizados acessem, é importante que você mantenha seu servidor seguro instalando um certificado TLS/SSL. Isso é opcional, mas <strong>altamente recomendado</strong>.</p>\n\n<p>No entanto, como você acabará por fazer alterações em seu bloco de servidor Nginx ao longo deste guia, provavelmente faria mais sentido para você completar o guia <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Let&rsquo;s Encrypt on Ubuntu 20.04</a> no final do segundo passo deste tutorial. Com isso em mente, se você planeja configurar o Let&rsquo;s Encrypt em seu servidor, você precisará ter o seguinte em mãos antes de fazer isso:</p>\n\n<ul>\n<li>Um nome de domínio totalmente qualificado (FQDN). Este tutorial utilizará o <code><span class=\"highlight\">your_domain</span></code> durante todo o processo. Você pode comprar um nome de domínio em <a href=\"https://namecheap.com\">Namecheap</a>, obter um gratuitamente em <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> ou usar o registrado de domínios de sua escolha.</li>\n<li><p>Ambos os registros de DNS a seguir serão configurados para o seu servidor. Você pode seguir <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">esta introdução para DNS DigitalOcean</a> para mais detalhes sobre como adicioná-los.</p>\n\n<ul>\n<li>Um registro A com <code><span class=\"highlight\">your_domain</span></code> apontando para o endereço IP público do seu servidor.</li>\n<li>Um registro A com o <code>www.<span class=\"highlight\">your_domain</span></code> apontando para o endereço de IP público do seu servidor.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"passo-1-—-instalando-e-configurando-o-elasticsearch\">Passo 1 — Instalando e Configurando o Elasticsearch</h2>\n\n<p>Os componentes do Elasticsearch não estão disponíveis nos repositórios de pacotes padrão do Ubuntu. No entanto, eles podem ser instalados com o APT após adicionar a lista de origem de pacotes do Elastic.</p>\n\n<p>Todos os pacotes são assinados com a chave de assinatura do Elasticsearch para proteger seu sistema de spoofing de pacotes. Os pacotes autenticados usando a chave serão considerados confiáveis pelo seu gerenciador de pacotes. Neste passo, você importará a chave GPG pública do Elasticsearch e adicionará a lista de origem de pacotes do Elastic para instalar o Elasticsearch.</p>\n\n<p>Para começar utilize o cURL, a ferramenta de linha de comando para transferir dados com URLs, para importar a chave GPG pública do Elasticsearch para o APT. Observe que estamos usando os argumentos -fsSL para silenciar todo o progresso e possíveis erros (exceto para uma falha de servidor) e permitir que o cURL faça uma solicitação em um novo local se for redirecionado. Faça o pipe da saída do comando cURL no programa apt-key, que adiciona a chave pública GPG para o APT.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n</li></ul></code></pre>\n<p>Em seguida, adicione a lista de origem do Elastic ao diretório <code>sources.list.d</code>, onde o APT irá procurar por novas origens:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n</li></ul></code></pre>\n<p>Em seguida, atualize suas listas de pacotes para que o APT leia a nova origem do Elastic:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Em seguida, instale o Elasticsearch com este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install elasticsearch\n</li></ul></code></pre>\n<p>Agora, o Elasticsearch está instalado e pronto para ser configurado. Use seu editor de texto preferido para editar o arquivo de configuração principal do Elasticsearch, <code>elasticsearch.yml</code>. Aqui, usaremos o <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/elasticsearch/elasticsearch.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Nota:</strong> o arquivo de configuração do Elasticsearch está no formato YAML, o que significa que precisamos manter o formato de indentação. Certifique-se de não adicionar nenhum espaço extra ao editar este arquivo.<br></span></p>\n\n<p>O arquivo <code>elasticsearch.yml</code> fornece opções de configuração para seu cluster, node, paths, memória, rede, descoberta e gateway. A maioria destas opções estão pré-configuradas no arquivo, mas você pode alterá-las de acordo com suas necessidades. Para os fins de nossa demonstração de uma configuração de um único servidor, vamos ajustar apenas as configurações para o host de rede.</p>\n\n<p>O Elasticsearch escuta o tráfego de todos os lugares na porta <code>9200</code>. Você vai querer restringir o acesso externo à sua instância Elasticsearch para evitar que agentes externos leiam seus dados ou encerrem seu cluster Elasticsearch por meio da sua <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">API REST</a>. Para restringir o acesso e, portanto, aumentar a segurança, encontre a linha que especifica o <code>network.host</code>, descomente-a e substitua seu valor por <code>localhost</code> dessa forma:</p>\n<div class=\"code-label \" title=\"/etc/elasticsearch/elasticsearch.yml\">/etc/elasticsearch/elasticsearch.yml</div><pre class=\"code-pre \"><code>. . .\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: <span class=\"highlight\">localhost</span>\n. . .\n</code></pre>\n<p>Nós especificamos <code>localhost</code> para que o Elasticsearch escute em todas as interfaces e IPs ligados. Se você quiser que ele escute apenas em uma interface específica, você pode especificar o IP dela no lugar de <code>localhost</code>. Salve e feche o <code>elasticsearch.yml</code>. Se você estiver usando o <code>nano</code>, você pode fazer isso pressionando <code>CTRL+X</code>, seguido de <code>Y</code> e, depois, <code>ENTER</code>.</p>\n\n<p>Essas são as configurações mínimas com as quais você começa para utilizar o Elasticsearch. Agora, inicie o Elasticsearch pela primeira vez.</p>\n\n<p>Inicie o serviço Elasticsearch com o <code>systemctl</code>. Dê ao Elasticsearch alguns momentos para iniciar. Caso contrário, poderá haver erros quanto à indisponibilidade de conexão.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start elasticsearch\n</li></ul></code></pre>\n<p>Em seguida, execute o seguinte comando para habilitar o Elasticsearch para iniciar sempre que seu servidor inicializar:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable elasticsearch\n</li></ul></code></pre>\n<p>Você pode testar se seu serviço Elasticsearch está em execução enviando uma requisição HTTP:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -X GET \"localhost:9200\"\n</li></ul></code></pre>\n<p>Você verá uma resposta mostrando algumas informações básicas sobre seu nó local, semelhantes a esta:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\n  \"name\" : \"Elasticsearch\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"qqhFHPigQ9e2lk-a7AvLNQ\",\n  \"version\" : {\n    \"number\" : \"7.7.1\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"deb\",\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\",\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.5.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n\n</code></pre>\n<p>Agora que o Elasticsearch está funcionando, vamos instalar o Kibana, o próximo componente da pilha Elastic.</p>\n\n<h2 id=\"passo-2-—-instalando-e-configurando-o-painel-do-kibana\">Passo 2 — Instalando e configurando o painel do Kibana</h2>\n\n<p>De acordo com a <a href=\"https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html\">documentação oficial</a>, você deve instalar o Kibana somente após instalar o Elasticsearch. A instalação nesta ordem garante que os componentes de que cada produto depende estejam corretamente instalados.</p>\n\n<p>Como você já adicionou a fonte de pacotes Elastic no passo anterior, você pode apenas instalar os componentes restantes da pilha Elastic usando o <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install kibana\n</li></ul></code></pre>\n<p>Em seguida, habilite e inicie o serviço Kibana:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable kibana\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl start kibana\n</li></ul></code></pre>\n<p>Como o Kibana está configurado para ouvir somente em <code>localhost</code>, devemos configurar um <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">proxy reverso</a> para permitir acesso externo a ele. Usaremos o Nginx para este fim, que já deve estar instalado em seu servidor.</p>\n\n<p>Primeiro, use o comando <code>openssl</code> para criar um usuário administrativo do Kibana que você usará para acessar a interface Web do Kibana. Como exemplo, vamos nomear esta conta como <code><span class=\"highlight\">kibanaadmin</span></code>, mas para garantir maior segurança, recomendamos que você escolha um nome não padrão para seu usuário que seria difícil de adivinhar.</p>\n\n<p>O comando a seguir irá criar o usuário administrativo e a senha do Kibana e armazená-los no arquivo <code>htpasswd.users</code>. Você irá configurar o Nginx para exigir esse nome de usuário e senha e ler este arquivo momentaneamente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"<span class=\"highlight\">kibanaadmin</span>:`openssl passwd -apr1`\" | sudo tee -a /etc/nginx/htpasswd.users\n</li></ul></code></pre>\n<p>Digite e confirme uma senha no prompt. Lembre-se ou tome nota deste login, pois você precisará dele para acessar a interface Web do Kibana.</p>\n\n<p>Em seguida, vamos criar um arquivo de bloco de servidor do Nginx. Como um exemplo, vamos nos referir a este arquivo como <code><span class=\"highlight\">your_domain</span></code>, embora você possa achar útil dar ao seu arquivo um nome mais descritivo. Por exemplo, se você tiver um registro FQDN e DNS configurado para este servidor, você pode nomear este arquivo após seu FQDN.</p>\n\n<p>Usando o nano ou seu editor de texto preferido, crie o arquivo de bloco de servidor do Nginx:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Adicione o seguinte bloco de código ao arquivo, garantindo atualizar <code><span class=\"highlight\">your_domain</span></code> para corresponder ao FQDN do seu servidor ou endereço IP público. Este código configura o Nginx para direcionar o tráfego HTTP do seu servidor para a aplicação do Kibana, que está escutando em <code>localhost:5601</code>. Além disso, ele configura o Nginx para ler o arquivo <code>htpasswd.users</code> e requerer autenticação básica.</p>\n\n<p>Observe que se você seguiu o <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">tutorial de pré-requisitos do Nginx</a> até o fim, você pode já ter criado este arquivo e o preenchido com algum conteúdo. Nesse caso, exclua todo o conteúdo existente no arquivo antes de adicionar o seguinte:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/your_domain\">/etc/nginx/sites-available/your_domain</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n\n    server_name <span class=\"highlight\">your_domain</span>;\n\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/htpasswd.users;\n\n    location / {\n        proxy_pass http://localhost:5601;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n</code></pre>\n<p>Quando você terminar, salve e feche o arquivo.</p>\n\n<p>Em seguida, habilite a nova configuração criando um link simbólico para o diretório <code>sites-enabled</code>. Se você já criou um arquivo de bloco de servidor com o mesmo nome nos pré-requisitos do Nginx, você não precisa executar este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Em seguida, verifique a configuração para erros de sintaxe:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Se quaisquer erros forem relatados em sua saída, retorne e verifique se o conteúdo que você colocou em seu arquivo de configuração foi adicionado corretamente. Depois que você vir <code>syntax is ok</code> na saída, reinicie o serviço do Nginx:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Se você seguiu o guia de configuração inicial do servidor, você deverá ter um firewall UFW ativado. Para permitir conexões ao Nginx, podemos ajustar as regras digitando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 'Nginx Full'\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota:</strong> se você seguiu o tutorial de pré-requisitos, do Nginx, você pode ter criado uma regra UFW permitindo o perfil <code>Nginx HTTP</code> através do firewall. Como o perfil <code>Nginx Full</code> permite tanto o tráfego HTTP quanto HTTPS através do firewall, você pode excluir com segurança a regra que você criou no tutorial de pré-requisitos. Faça isso com o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw delete allow 'Nginx HTTP'\n</li></ul></code></pre>\n<p></p></span>\n\n<p>O Kibana agora está acessível através do seu FQDN ou do endereço IP público do seu servidor de pilha Elastic. Você pode verificar a página de status do servidor do Kibana navegando para o seguinte endereço e digitando suas credenciais de login quando solicitado:</p>\n<pre class=\"code-pre \"><code>http://<span class=\"highlight\">your_domain</span>/status\n</code></pre>\n<p>Esta página de status exibe informações sobre o uso de recursos do servidor e lista os plugins instalados.</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png\" alt=\"|Kibana status page\"></p>\n\n<p><span class='note'><strong>Nota</strong>: conforme mencionado na seção de pré-requisitos, é recomendado que você habilite o SSL/TLS no seu servidor. Você pode seguir o guia <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">do Let’s Encrypt</a> agora para obter um certificado SSL gratuito para o Nginx no Ubuntu 20.04. Depois de obter seus certificados SSL/TLS, retorne para completar este tutorial.<br></span></p>\n\n<p>Agora que o painel do Kibana está configurado, vamos instalar o próximo componente: Logstash.</p>\n\n<h2 id=\"passo-3-—-instalando-e-configurando-o-logstash\">Passo 3 — Instalando e configurando o Logstash</h2>\n\n<p>Embora seja possível para o Beats enviar dados diretamente para o banco de dados do Elasticsearch, é comum usar o Logstash para processar os dados. Isso lhe permitirá mais flexibilidade para coletar dados de diferentes fontes, transformá-los em um formato comum e exportá-los para outro banco de dados.</p>\n\n<p>Instale o Logstash com este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install logstash\n</li></ul></code></pre>\n<p>Depois de instalar o Logstash, você pode seguir para configurá-lo. Os arquivos de configuração do Logstash residem no diretório <code>/etc/logstash/conf.d</code>. Para mais informações sobre a sintaxe de configuração, você pode conferir a <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\">referência de configuração</a> que o Elastic fornece. À medida que você configura o arquivo, é útil pensar no Logstash como um pipeline que leva dados de uma extremidade, os processa de uma maneira ou de outra e os envia para seu destino (neste caso, o destino sendo o Elasticsearch). Um pipeline do Logstash tem dois elementos necessários, <code>input</code> e <code>output</code>, e um elemento opcional, <code>filter</code>. Os plugins input consomem dados de uma fonte, os plugins filter processam os dados e os plugins output gravam os dados para um destino.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png\" alt=\"Logstash pipeline\"></p>\n\n<p>Crie um arquivo de configuração chamado <code>02-beats-input.conf</code> onde você irá configurar sua entrada do Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/02-beats-input.conf\n</li></ul></code></pre>\n<p>Insira a seguinte configuração de <code>input</code>. Isso especifica uma entrada para o <code>beats</code> que irá ouvir na porta TCP <code>5044</code>.</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/02-beats-input.conf\">/etc/logstash/conf.d/02-beats-input.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">input {\n  beats {\n    port =&gt; 5044\n  }\n}\n</code></pre>\n<p>Salve e feche o arquivo.</p>\n\n<p>Em seguida, crie um arquivo de configuração chamado <code>30-elasticsearch-output.conf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf\n</li></ul></code></pre>\n<p>Insira a seguinte configuração de <code>output</code>. Essencialmente, esta saída configura o Logstash para armazenar os dados do Beats no Elasticsearch, que está em execução em <code>localhost:9200</code>, em um índice com o nome do Beat usado. O Beat usado neste tutorial é o Filebeat:</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/30-elasticsearch-output.conf\">/etc/logstash/conf.d/30-elasticsearch-output.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">output {\n  if [@metadata][pipeline] {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    pipeline =&gt; \"%{[@metadata][pipeline]}\"\n    }\n  } else {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n\n\n</code></pre>\n<p>Salve e feche o arquivo.</p>\n\n<p>Teste sua configuração do Logstash com este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t\n</li></ul></code></pre>\n<p>Se não houver erros de sintaxe, a saída irá exibir <code>Config Validation Result: OK. Exiting Logstash</code> após alguns segundos. Se você não vir isso em sua saída, verifique quaisquer erros na saída e atualize a configuração para corrigi-los. Observe que você receberá avisos do OpenJDK, mas eles não devem causar nenhum problema e podem ser ignorados.</p>\n\n<p>Se seu teste de configuração for bem sucedido, inicie e habilite o Logstash para colocar as alterações de configuração em vigor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start logstash\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable logstash\n</li></ul></code></pre>\n<p>Agora que o Logstash está executando corretamente e está totalmente configurado, vamos instalar o Filebeat.</p>\n\n<h2 id=\"passo-4-—-instalando-e-configurando-o-filebeat\">Passo 4 — Instalando e configurando o Filebeat</h2>\n\n<p>O Elastic Stack usa vários transportadores de dados leves chamados Beats para coletar dados de várias fontes e transportá-los para o Logstash ou para o Elasticsearch. Aqui estão os Beats que estão atualmente disponíveis na Elastic:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>: coleta e despacha os arquivos de log.</li>\n<li><a href=\"https://www.elastic.co/products/beats/metricbeat\">Metricbeat</a>: coleta métricas de seus sistemas e serviços.</li>\n<li><a href=\"https://www.elastic.co/products/beats/packetbeat\">Packetbeat</a>: coleta e analisa dados de rede.</li>\n<li><a href=\"https://www.elastic.co/products/beats/winlogbeat\">Winlogbeat</a>: coleta log de eventos do Windows.</li>\n<li><a href=\"https://www.elastic.co/products/beats/auditbeat\">Auditbeat</a>: coleta dados do framework de auditoria do Linux e monitora a integridade do arquivo.</li>\n<li><a href=\"https://www.elastic.co/products/beats/heartbeat\">Heartbeat</a>: monitora serviços para verificar sua disponibilidade com sonda ativa.</li>\n</ul>\n\n<p>Neste tutorial, usaremos o Filebeat para encaminhar logs locais para nossa pilha Elastic.</p>\n\n<p>Instale o Filebeat usando o <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install filebeat\n</li></ul></code></pre>\n<p>Em seguida, configure o Filebeat para se conectar ao Logstash. Aqui, vamos modificar o arquivo de configuração de exemplo que vem com o Filebeat.</p>\n\n<p>Abra o arquivo de configuração do Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/filebeat/filebeat.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Nota:</strong> assim como no Elasticsearch, o arquivo de configuração do Filebeat está em formato YAML. Isso significa que a indentação adequada é crucial, então certifique-se de usar o mesmo número de espaços que são indicados nessas instruções.<br></span></p>\n\n<p>O Filebeat suporta inúmeras saídas, mas você geralmente apenas enviará eventos diretamente para o Elasticsearch ou para o Logstash para processamento adicional. Neste tutorial, usaremos o Logstash para realizar processamento adicional nos dados coletados pelo Filebeat. O Filebeat não precisará enviar quaisquer dados diretamente para o Elasticsearch, então vamos desativar essa saída. Para fazer isso, encontre a seção <code>output.elasticsearch</code> e comente as seguintes linhas precedendo-as com um <code>#</code>:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>...\n<span class=\"highlight\">#</span>output.elasticsearch:\n  # Array of hosts to connect to.\n  <span class=\"highlight\">#</span>hosts: [\"localhost:9200\"]\n...\n</code></pre>\n<p>Então, configure a seção <code>output.logstash</code>. Descomente as linhas <code>output.logstash:</code> e <code>hosts: [\"localhost:5044\"]</code> removendo o <code>#</code>. Isso irá configurar o Filebeat para se conectar ao Logstash em seu servidor de pilha Elastic na porta <code>5044</code>, a porta para a qual especificamos uma entrada do Logstash anteriormente:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>output.logstash:\n  # The Logstash hosts\n  hosts: [\"localhost:5044\"]\n</code></pre>\n<p>Salve e feche o arquivo.</p>\n\n<p>A funcionalidade do Filebeat pode ser estendida com <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-modules.html\">módulos do Filebeat</a>. Neste tutorial, usaremos o módulo <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-module-system.html\">system</a>, que coleta e analisa logs criados pelo serviço de log de sistema das distribuições comuns do Linux.</p>\n\n<p>Vamos habilitá-lo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules enable system\n</li></ul></code></pre>\n<p>Você pode ver uma lista de módulos habilitados e desabilitados executando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules list\n</li></ul></code></pre>\n<p>Você verá uma lista similar à seguinte:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enabled:\nsystem\n\nDisabled:\napache2\nauditd\nelasticsearch\nicinga\niis\nkafka\nkibana\nlogstash\nmongodb\nmysql\nnginx\nosquery\npostgresql\nredis\ntraefik\n...\n</code></pre>\n<p>Por padrão, o Filebeat está configurado para usar caminhos padrão para o syslog e os logs de autorização. No caso deste tutorial, você não precisa alterar nada na configuração. Você pode ver os parâmetros do módulo no arquivo de configuração <code>/etc/filebeat/modules.d/system.yml</code>.</p>\n\n<p>Em seguida, precisamos configurar os pipelines de ingestão do Filebeat, que analisa os dados de log antes de enviá-los através do logstash para o Elasticsearch. Para carregar o pipeline de ingestão para o módulo system, digite o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --pipelines --modules system\n</li></ul></code></pre>\n<p>Em seguida, carregue o modelo de índice no Elasticsearch. Um <a href=\"https://www.elastic.co/blog/what-is-an-elasticsearch-index\"><em>índice do Elasticsearch</em></a> é uma coleção de documentos que têm características semelhantes. Os índices são identificados com um nome, que é usado para se referir ao índice ao realizar várias operações dentro dele. O modelo de índice será aplicado automaticamente quando um novo índice for criado.</p>\n\n<p>Para carregar o modelo use o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=[\"localhost:9200\"]'\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Index setup finished.\n</code></pre>\n<p>O Filebeat vem empacotado com painéis de amostra do Kibana que lhe permitem visualizar dados do Filebeat no Kibana. Antes que você possa usar os painéis, você precisa criar o padrão de índice e carregar os painéis no Kibana.</p>\n\n<p>Conforme os painéis carregam, o Filebeat se conecta ao Elasticsearch para verificar as informações da versão. Para carregar painéis quando o Logstash estiver habilitado, você precisa desativar a saída do Logstash e habilitar a saída do Elasticsearch:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601\n</li></ul></code></pre>\n<p>Você deve receber um resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Overwriting ILM policy is disabled. Set `setup.ilm.overwrite:true` for enabling.\n\nIndex setup finished.\nLoading dashboards (Kibana must be running and reachable)\nLoaded dashboards\nSetting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.\nSee more: https://www.elastic.co/guide/en/elastic-stack-overview/current/xpack-ml.html\nLoaded machine learning job configurations\nLoaded Ingest pipelines\n</code></pre>\n<p>Agora, você pode iniciar e habilitar o Filebeat:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start filebeat\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable filebeat\n</li></ul></code></pre>\n<p>Se você configurou sua pilha Elastic corretamente, o Filebeat começará a enviar seu syslog e logs de autorização para o Logstash, que então irá carregar esses dados no Elasticsearch.</p>\n\n<p>Para verificar se o Elasticsearch está realmente recebendo esses dados, consulte o índice do Filebeat com este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'\n</li></ul></code></pre>\n<p>Você deve receber um resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\n{\n{\n  \"took\" : 4,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 2,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 4040,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"filebeat-7.7.1-2020.06.04\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"FiZLgXIB75I8Lxc9ewIH\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"cloud\" : {\n            \"provider\" : \"digitalocean\",\n            \"instance\" : {\n              \"id\" : \"194878454\"\n            },\n            \"region\" : \"nyc1\"\n          },\n          \"@timestamp\" : \"2020-06-04T21:45:03.995Z\",\n          \"agent\" : {\n            \"version\" : \"7.7.1\",\n            \"type\" : \"filebeat\",\n            \"ephemeral_id\" : \"cbcefb9a-8d15-4ce4-bad4-962a80371ec0\",\n            \"hostname\" : \"june-ubuntu-20-04-elasticstack\",\n            \"id\" : \"fbd5956f-12ab-4227-9782-f8f1a19b7f32\"\n          },\n\n\n...\n</code></pre>\n<p>Se sua saída mostrar 0 total hits, o Elasticsearch não está carregando nenhum log sob o índice que você pesquisou e você precisará revisar sua configuração por erros. Se você recebeu a saída esperada, continue até o próximo passo, no qual veremos como navegar por alguns painéis do Kibana.</p>\n\n<h2 id=\"passo-5-—-explorando-painéis-do-kibana\">Passo 5 — Explorando painéis do Kibana</h2>\n\n<p>Vamos retornar à interface Web do Kibana que instalamos anteriormente.</p>\n\n<p>Em um navegador Web, vá até o FQDN ou endereço IP público do seu servidor de pilha Elastic. Se a sessão tiver sido interrompida, você precisará inserir novamente as credenciais que definiu no Passo 2. Depois de fazer login, você deve receber a página inicial do Kibana:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg\" alt=\"Kibana Homepage\"></p>\n\n<p>Clique no link <strong>Discover</strong> na barra de navegação à esquerda (você pode ter que clicar no ícone <strong>Expand</strong> no canto inferior esquerdo para ver os itens do menu de navegação). Na página <strong>Discover</strong> selecione o padrão de índice pré-definido <strong>filebeat-*</strong> para ver dados do Filebeat. Por padrão, isso irá lhe mostrar todos os dados de log dos últimos 15 minutos. Você verá um histograma com eventos de log e algumas mensagens de log abaixo:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg\" alt=\"Discover page\"></p>\n\n<p>Aqui, você pode pesquisar e navegar pelos seus logs e também personalizar seu painel. Neste ponto, porém, não haverá muito lá porque você só está coletando syslogs do seu servidor de pilha Elastic.</p>\n\n<p>Use o painel esquerdo para navegar até a página <strong>Dashboard</strong> e pesquise pelos painéis <strong>Filebeat System</strong>. Uma vez lá, você pode selecionar os painéis de amostra que vêm com o módulo <code>system</code> do Filebeat.</p>\n\n<p>Por exemplo, você pode visualizar estatísticas detalhadas baseadas em suas mensagens syslog:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg\" alt=\"Syslog Dashboard\"></p>\n\n<p>Você também pode visualizar quais usuários usaram o comando <code>sudo</code> e quando:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg\" alt=\"Sudo Dashboard\"></p>\n\n<p>O Kibana tem muitos outros recursos, como gráficos e filtros, para você explorar.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Neste tutorial, você aprendeu como instalar e configurar a pilha Elastic para coletar e analisar logs de sistema. Lembre-se que você pode enviar praticamente qualquer tipo de log ou dados indexados para o Logstash usando o <a href=\"https://www.elastic.co/products/beats\">Beats</a>, mas os dados tornam-se ainda mais úteis se eles forem analisados e estruturados com um filtro do Logstash, pois isso transforma os dados em um formato consistente que pode ser lido facilmente pelo Elasticsearch.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:56 +0000","feedId":8037,"bgimg":"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png","linkMd5":"a712f5d4ec616e375b5a1a29b264dfdd","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","destWidth":1833,"destHeight":948,"sourceBytes":40417,"destBytes":48810,"author":"Erin Glass","articleImgCdnMap":{"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn82@2020_2/2020/08/31/07-48-31-557_41a6f5cccef041e1.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn1@2020_3/2020/08/31/07-48-32-396_0638f11900b9faf4.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn37@2020_3/2020/08/31/07-48-33-221_1dfbe5e28e76fefb.webp","http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn10@2020_4/2020/08/31/07-48-32-522_c0c2011e332e864d.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn5@2020_6/2020/08/31/07-48-32-458_2cfaecfed9ac513b.webp"},"publishedOrCreatedDate":1598860106987},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Использование ThreadPoolExecutor в Python 3","link":"https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3-ru","description":"<p><em>Автор выбрал <a href=\"https://www.brightfunds.org/funds/write-for-donations-covid-19-relief-fund\">COVID-19 Relief Fund</a> для получения пожертвования в рамках программы <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"Введение\">Введение</h3>\n\n<p><em>Потоки</em> в <a href=\"https://www.python.org/\">Python</a> представляют собой форму параллельного программирования, позволяющую программе выполнять несколько процедур одновременно. Параллелизм в Python также можно реализовать посредством использования нескольких процессов, однако потоки особенно хорошо подходят для ускорения приложений, использующих существенные объемы ввода/вывода.</p>\n\n<p>Например, <a href=\"https://en.wikipedia.org/wiki/I/O_bound#:%7E:text=In%20computer%20science%2C%20I%2FO,a%20task%20being%20CPU%20bound.\">операции ввода-вывода</a> включают отправку веб-запросов и чтение данных из файлов. В отличие от операций ввода вывода, <a href=\"https://en.wikipedia.org/wiki/CPU-bound\">операции процессора</a> (например, математические операции со стандартной библиотекой Python) не становятся намного эффективнее при использовании потоков Python.</p>\n\n<p>В состав Python 3 входит утилита <code>ThreadPoolExecutor</code> для выполнения кода в потоке.</p>\n\n<p>В этом обучающем модуле мы используем <code>ThreadPoolExecutor</code> для ускоренной отправки сетевых запросов. Мы определим функцию, хорошо подходящую для вызова в потоках, используем <code>ThreadPoolExecutor</code> для выполнения этой функции и обработаем результаты выполнения.</p>\n\n<p>В этом обучающем модуле мы будем составлять сетевые запросы для проверки существования страниц на портале <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipedia</a>.</p>\n\n<p><span class='note'><strong>Примечание.</strong> Тот факт, что операции ввода-вывода получают больше выгод от потоков, чем операции процессора, связан с использованием в Python <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\"><em>глобальной блокировки интерпретатора</em></a>, которая позволяет только одному потоку сохранять контроль над интерпретатором Python. Если хотите, вы можете узнать больше о глобальном блокировке интерпретатора <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">Python в официальной документации по Python</a>.<br></span></p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для наиболее эффективного прохождения этого обучающего модуля требуется знакомство с программированием на Python и локальной средой программирования Python с <code>requests</code>.</p>\n\n<p>Необходимую информацию можно получить, пройдя следующие обучающие модули:</p>\n\n<ul>\n<li><a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-python-3\">Программирование на Python 3</a></li>\n<li><p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">Установка Python 3 и настройка среды программирования в Ubuntu 18.04</a></p></li>\n<li><p>Чтобы установить пакет <code>requests</code> в <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">локальную среду программирования Python</a>, запустите следующую команду:</p></li>\n</ul>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pip install --user requests==2.23.0\n</li></ul></code></pre>\n<h2 id=\"Шаг-1-—-Определение-функции-для-выполнения-в-потоках\">Шаг 1 — Определение функции для выполнения в потоках</h2>\n\n<p>Для начала определим функцию, которую мы хотим выполнить с помощью потоков.</p>\n\n<p>Откройте этот файл, используя <code>nano</code> или предпочитаемый текстовый редактор или среду разработки:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano wiki_page_function.py\n</li></ul></code></pre>\n<p>Для этого обучающего модуля мы напишем функцию, проверяющую существование страницы на портале Wikipedia:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n</code></pre>\n<p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-python-3\">Функция</a> <code>get_wiki_page_existence</code> принимает два аргумента: URL страницы Wikipedia (<code>wiki_page_url</code>) и <code>timeout</code> — количество секунд ожидания ответа от этого URL.</p>\n\n<p><code>get_wiki_page_existence</code> использует пакет <a href=\"https://requests.readthedocs.io/en/master/\"><code>requests</code></a> для отправки веб-запроса на этот URL. В зависимости от <a href=\"https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes\">кода состояния</a> <code>ответа</code> HTTP функция возвращает строку, описывающую наличие или отсутствие страницы. Разные коды состояния соответствуют разным результатам выполнения запроса HTTP. Эта процедура предполагает, что код состояния <code>200</code> (успех) означает, что страница Wikipedia существует, а код состояния <code>404</code> (не найдено) означает, что страница Wikipedia не существует.</p>\n\n<p>Как указывалось в разделе «Предварительные требования», для запуска этой функции должен быть установлен пакет <code>requests</code>.</p>\n\n<p>Попробуем запустить функцию, добавив <code>url</code> и вызов функции после функции <code>get_wiki_page_existence</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">. . .\nurl = \"https://en.wikipedia.org/wiki/Ocean\"\nprint(get_wiki_page_existence(wiki_page_url=url))\n</code></pre>\n<p>После добавления кода сохраните и закройте файл.</p>\n\n<p>Если мы запустим этот код:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Результат будет выглядеть примерно следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Ocean - exists\n</code></pre>\n<p>Вызов функции <code>get_wiki_page_existence</code> для существующей страницы Wikipedia возвращает строку, подтверждающую фактическое существование страницы.</p>\n\n<p><span class='warning'><strong>Предупреждение.</strong> Обычно небезопасно делать объекты или состояния Python доступными для всех потоков, не приняв особых мер для предотвращения ошибок параллельной обработки. При определении функции для выполнения в потоке лучше всего определить функцию, которая выполняет одну задачу и не делится своим состоянием с другими потоками. <code>get_wiki_page_existence</code> — хороший пример такой функции.<br></span></p>\n\n<h2 id=\"Шаг-2-—-Использование-threadpoolexecutor-для-выполнения-функции-в-потоках\">Шаг 2 — Использование ThreadPoolExecutor для выполнения функции в потоках</h2>\n\n<p>Теперь у нас есть функция, подходящая для вызова в потоках, и мы можем использовать <code>ThreadPoolExecutor</code> для многократного ускоренного вызова этой функции.</p>\n\n<p>Добавьте следующий выделенный код в свою программу в файле <code>wiki_page_function.py</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n<span class=\"highlight\">import concurrent.futures</span>\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Ocean\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Island\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/this_page_does_not_exist\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Shark\",</span>\n<span class=\"highlight\">]</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n</code></pre>\n<p>Посмотрим, как работает этот код:</p>\n\n<ul>\n<li><code>concurrent.futures</code> импортируется, чтобы предоставить нам доступ к <code>ThreadPoolExecutor</code>.</li>\n<li>Выражение <code>with</code> используется для создания <code>исполнительного блока</code> экземпляра <code>ThreadPoolExecutor</code>, который будет быстро очищать потоки после выполнения.</li>\n<li>Четыре задания <code>отправляются</code> в <code>исполнительный блок</code>: по одному для каждого URL из списка <code>wiki_page_urls</code>.</li>\n<li>Каждый вызов <code>submit</code> возвращает <a href=\"https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future\">экземпляр <code>Future</code></a>, хранящийся в списке <code>futures</code>.</li>\n<li>Функция <code>as_completed</code> ожидает каждого вызова <code>Future</code> <code>get_wiki_page_existence</code> для выполнения, чтобы дать нам возможность распечатать результат.</li>\n</ul>\n\n<p>Если мы снова запустим эту программу с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Результат будет выглядеть примерно следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Island - exists\nhttps://en.wikipedia.org/wiki/Ocean - exists\nhttps://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\nhttps://en.wikipedia.org/wiki/Shark - exists\n</code></pre>\n<p>Этот вывод имеет смысл: 3 адреса URL указывают на существующие страницы Wikipedia, а один из них <code>this_page_does_not_exist</code> не существует. Обратите внимание. что вывод может иметь другой порядок, отличающийся от показанного здесь. Функция <code>concurrent.futures.as_completed</code> в этом примере возвращает результаты сразу же, как только они становятся доступными, вне зависимости от порядка отправки заданий.</p>\n\n<h2 id=\"Шаг-3-—-Обработка-исключений-функций-выполняемых-в-потоках\">Шаг 3 — Обработка исключений функций, выполняемых в потоках</h2>\n\n<p>На предыдущем шаге функция <code>get_wiki_page_existence</code> успешно вернула значения во всех случаях вызова. На этом шаге мы увидим, что <code>ThreadPoolExecutor</code> также может выводить исключения при вызове функций в потоках.</p>\n\n<p>Рассмотрим в качестве примера следующий блок кода:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n\nwiki_page_urls = [\n    \"https://en.wikipedia.org/wiki/Ocean\",\n    \"https://en.wikipedia.org/wiki/Island\",\n    \"https://en.wikipedia.org/wiki/this_page_does_not_exist\",\n    \"https://en.wikipedia.org/wiki/Shark\",\n]\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(</span>\n            <span class=\"highlight\">executor.submit(</span>\n                <span class=\"highlight\">get_wiki_page_existence, wiki_page_url=url, timeout=0.00001</span>\n            <span class=\"highlight\">)</span>\n        <span class=\"highlight\">)</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">try:</span>\n            <span class=\"highlight\">print(future.result())</span>\n        <span class=\"highlight\">except requests.ConnectTimeout:</span>\n            <span class=\"highlight\">print(\"ConnectTimeout.\")</span>\n</code></pre>\n<p>Этот блок кода практически идентичен использованному нами на шаге 2, но имеет два важных отличия:</p>\n\n<ul>\n<li>Теперь мы передаем аргумент <code>timeout=0.00001</code> для функции <code>get_wiki_page_existence</code>. Поскольку пакет <code>requests</code> не может выполнить веб-запрос сайта Wikipedia за <code>0,00001</code> секунды, он выдаст исключение <code>ConnectTimeout</code>.</li>\n<li>Мы собираем исключения <code>ConnectTimeout</code>, выдаваемые <code>future.result()</code>, и выводим строку в каждом таком случае.</li>\n</ul>\n\n<p>Если мы запустим программу снова, мы получим следующий результат:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>ConnectTimeout.\nConnectTimeout.\nConnectTimeout.\nConnectTimeout.\n</code></pre>\n<p>Выведено четыре сообщения <code>ConnectTimeout</code>, по одному для каждого из четырех значений <code>wiki_page_urls</code>, поскольку ни один запрос не мог быть выполнен за <code>0,00001</code> секунды, и каждый из четырех вызовов <code>get_wiki_page_existence</code> завершился исключением <code>ConnectTimeout</code>.</p>\n\n<p>Мы увидели, что если вызов функции, отправленный в <code>ThreadPoolExecutor</code>, завершается исключением, это исключение может быть выведено обычным образом посредством вызова <code>Future.result</code>. Вызов <code>Future.result</code> для всех вызванных функций гарантирует, что ваша программа не пропустит никаких исключений при выполнении функции в потоке.</p>\n\n<h2 id=\"Шаг-4-—-Сравнение-времени-исполнения-с-потоками-и-без-потоков\">Шаг 4 — Сравнение времени исполнения с потоками и без потоков</h2>\n\n<p>Убедимся, что использование <code>ThreadPoolExecutor</code> действительно ускоряет нашу программу.</p>\n\n<p>Вначале определим время выполнения функции <code>get_wiki_page_existence</code> при ее запуске без потоков:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\"><span class=\"highlight\">import time</span>\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]</span>\n\n<span class=\"highlight\">print(\"Running without threads:\")</span>\n<span class=\"highlight\">without_threads_start = time.time()</span>\n<span class=\"highlight\">for url in wiki_page_urls:</span>\n    <span class=\"highlight\">print(get_wiki_page_existence(wiki_page_url=url))</span>\n<span class=\"highlight\">print(\"Without threads time:\", time.time() - without_threads_start)</span>\n</code></pre>\n<p>В этом пример кода мы вызываем функцию <code>get_wiki_page_existence</code> с пятьюдесятью разными URL страниц Wikipedia по одной. Мы используем <a href=\"https://docs.python.org/3/library/time.html#time.time\">функцию <code>time.time()</code></a> для вывода количества секунд выполнения нашей программы.</p>\n\n<p>Если мы запустим этот код снова, как и раньше, мы увидим следующий результат:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running without threads:\nhttps://en.wikipedia.org/wiki/0 - exists\nhttps://en.wikipedia.org/wiki/1 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nWithout threads time: 5.803015232086182\n</code></pre>\n<p>Записи 2–47 в выводимых результатах пропущены для краткости.</p>\n\n<p>Количество секунд, выводимое после <code>Without threads time</code>, будет отличаться для вашего компьютера, и это нормально, ведь это просто базовое число для сравнения с получаемым при использовании <code>ThreadPoolExecutor</code>.  В данном случае мы получили <code>результат ~5,803 секунды</code>.</p>\n\n<p>Теперь снова пропустим те же пятьдесят URL страниц Wikipedia через функцию <code>get_wiki_page_existence</code>, но в этот раз с использованием <code>ThreadPoolExecutor</code>:</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import time\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\nwiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n\n<span class=\"highlight\">print(\"Running threaded:\")</span>\n<span class=\"highlight\">threaded_start = time.time()</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n<span class=\"highlight\">print(\"Threaded time:\", time.time() - threaded_start)</span>\n</code></pre>\n<p>Это тот же самый код, который мы создали на шаге 2, только в него добавлены выражения print, показывающие время выполнения нашего кода в секундах.</p>\n\n<p>Если мы снова запустим программу, мы увидим следующий результат:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running threaded:\nhttps://en.wikipedia.org/wiki/1 - exists\nhttps://en.wikipedia.org/wiki/0 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nThreaded time: 1.2201685905456543\n</code></pre>\n<p>Количество секунд после <code>Threaded time</code> на вашем компьютере будет отличаться (как и порядок вывода).</p>\n\n<p>Теперь вы можете сравнить время выполнения при доставке пятидесяти URL страниц Wikipedia с потоками и без потоков.</p>\n\n<p>На компьютере, использованном для этого обучающего модуля, выполнение операций без потоков заняло <code>~5,803</code> секунды, а с потоками — <code>~1,220</code> секунды. С потоками наша программа работала значительно быстрее.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>В этом обучающем модуле мы научились использовать утилиту <code>ThreadPoolExecutor</code> в Python 3 для эффективного выполнения кода, связанного с операциями ввода-вывода. Вы создали функцию, хорошо подходящую для вызова в потоках, научились получать результаты и исключения при выполнении этой фукнции в потоках и оценили прирост производительности, достигаемый за счет использования потоков.</p>\n\n<p>Далее вас могут заинтересовать другие функции параллельной обработки, доступные в <a href=\"https://docs.python.org/3/library/concurrent.futures.html\">модуле <code>concurrent.futures</code></a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:54 +0000","feedId":8037,"bgimg":"","linkMd5":"b560e10140241344d0411f6f3628f83f","bgimgJsdelivr":"","metaImg":"","author":"DavidMuller","publishedOrCreatedDate":1598860106962},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Installieren von Elasticsearch, Logstash und Kibana (Elastic Stack) unter Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","description":"<h3 id=\"einführung\">Einführung</h3>\n\n<p>Der Elastic Stack (früher <em>ELK Stack</em> genannt) ist eine Sammlung von Open-Source-Software, die von <a href=\"https://www.elastic.co/\">Elastic</a> produziert wird. Damit können Sie Protokolle, die aus beliebigen Quellen in beliebigen Formaten generiert werden, durchsuchen, analysieren und visualisieren – diese Praktik wird* zentrale Protokollierung* genannt. Zentrale Protokollierung kann dabei helfen, Probleme mit Ihren Servern oder Anwendungen zu identifizieren, da Sie so alle Protokolle an einem Ort durchsuchen können. Außerdem können Sie Probleme ermitteln, die mehrere Server umfassen, indem Sie ihre Protokolle für einen bestimmten Zeitraum miteinander korrelieren.</p>\n\n<p>Der Elastic Stack verfügt über vier Hauptkomponenten:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/elasticsearch\"><strong>Elasticsearch</strong></a>: eine verteilte <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\"><em>RESTful</em></a>-Suchmaschine, die alle erfassten Daten speichert.</li>\n<li><a href=\"https://www.elastic.co/products/logstash\"><strong>Logstash</strong></a>: die Datenverarbeitungskomponente von Elastic Stack, die eingehende Daten an Elasticsearch sendet.</li>\n<li><a href=\"https://www.elastic.co/products/kibana\"><strong>Kibana</strong></a>: eine Weboberfläche zum Durchsuchen und Visualisieren von Protokollen.</li>\n<li><a href=\"https://www.elastic.co/products/beats\"><strong>Beats</strong></a>: schlanke Datenversender mit einem Zweck, die Daten von Hunderten oder Tausenden von Geräten an Logstash oder Elasticsearch senden können.</li>\n</ul>\n\n<p>In diesem Tutorial installieren Sie den <a href=\"https://www.elastic.co/elk-stack\">Elastic Stack</a> auf einem Ubuntu 20.04-Server. Sie erfahren, wie Sie alle Komponenten des Elastic Stacks installieren – darunter <a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>, ein Beat, das zum Weiterleiten und Zentralisieren von Protokollen und Dateien dient – und so konfigurieren, dass Systemprotokolle gesammelt und visualisiert werden. Da Kibana in der Regel nur auf dem <code>localhost</code> verfügbar ist, verwenden wir außerdem <a href=\"https://www.nginx.com/\">Nginx</a> als Proxy, sodass es über einen Webbrowser aufrufbar ist. Wir installieren alle diese Komponenten auf einem einzigen Server, den wir als <em>Elastic Stack-Server</em> bezeichnen werden.</p>\n\n<p><span class='note'><strong>Hinweis</strong>: Bei der Installation des Elastic Stacks müssen Sie im gesamten Stack die gleiche Version verwenden. In diesem Tutorial installieren wir die neuesten Versionen des gesamten Stacks (zum Zeitpunkt der Verfassung dieses Textes Elasticsearch 7.7.1, Kibana 7.7.1, Logstash 7.7.1 und Filebeat 7.7.1).<br></span></p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Um dieses Tutorial zu absolvieren, benötigen Sie Folgendes:</p>\n\n<ul>\n<li><p>Einen Ubuntu 20.04-Server mit 4 GB RAM und 2 CPUs, eingerichtet mit einem non-root sudo user. Sie können hierzu der <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Ersteinrichtung eines Servers mit Ubuntu 20.04</a> folgen. In diesem Tutorial arbeiten wir mit der Mindestmenge von CPUs und RAM, die zur Ausführung von Elasticsearch benötigt werden.  Beachten Sie, dass die Menge von CPU, RAM und Speicher, die Ihr Elasticsearch-Server benötigt, von der Menge der Protokolle abhängt, die Sie erwarten.</p></li>\n<li><p>Installiertes OpenJDK 11. Siehe Abschnitt <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04#installing-the-default-jrejdk\">Installieren der standardmäßigen JRE/JDK</a> in our guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04\">Installieren von Java mit Apt unter Ubuntu 20.04</a>, um die Einrichtung vorzunehmen.</p></li>\n<li><p>Nginx, installiert auf Ihrem Server; Nginx werden wir in diesem Leitfaden später als Reverseproxy für Kibana konfigurieren. Folgen Sie unserem Leitfaden <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">Installieren von Nginx unter Ubuntu 20.04</a>, um die Einrichtung vorzunehmen.</p></li>\n</ul>\n\n<p>Da der Elastic Stack dazu dient, wertvolle Informationen über Ihren Server aufzurufen, auf die nicht autorisierte Benutzer nicht zugreifen sollen, sollten Sie Ihren Server unbedingt schützen, indem Sie ein TLS/SSL-Zertifikat installieren. Dieser Schutz ist optional, wird jedoch <strong>ausdrücklich empfohlen</strong>.</p>\n\n<p>Da Sie im Laufe des Leitfadens jedoch Änderungen an Ihrem Nginx-Serverblock vornehmen werden, ist es wahrscheinlich sinnvoller, dem Leitfaden <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Let&rsquo;s Encrypt unter Ubuntu 20.04</a> am Ende des zweiten Schritts dieses Tutorials zu folgen. Wenn Sie vor diesem Hintergrund planen, Let&rsquo;s Encrypt auf Ihrem Server zu konfigurieren, benötigen Sie dazu Folgendes:</p>\n\n<ul>\n<li>Einen vollständig qualifizierten Domänennamen (FQDN). In diesem Tutorial wird überall <code><span class=\"highlight\">your_domain</span></code> verwendet. Sie können einen Domänennamen unter <a href=\"https://namecheap.com\">Namecheap</a> günstig erwerben oder einen kostenlosen von <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> herunterladen oder einfach die Domänenregistrierungsstelle Ihrer Wahl verwenden.</li>\n<li><p>Die beiden folgenden DNS-Einträge wurden für Ihren Server eingerichtet. Sie finden in <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">dieser Einführung in DigitalOcean DNS</a> Details dazu, wie Sie sie hinzufügen können.</p>\n\n<ul>\n<li>Einen A-Datensatz mit <code><span class=\"highlight\">your-domain</span></code>, der auf die öffentliche IP-Adresse Ihres Servers verweist.</li>\n<li>Einen A-Eintrag mit <code>www.<span class=\"highlight\">your_domain</span></code>, der auf die öffentliche IP-Adresse Ihres Servers verweist.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"schritt-1-—-installieren-und-konfigurieren-von-elasticsearch\">Schritt 1 — Installieren und Konfigurieren von Elasticsearch</h2>\n\n<p>Die Elasticsearch-Komponenten sind in Standard-Paket-Repositorys von Ubuntu nicht verfügbar. Sie können jedoch mit APT installiert werden, nachdem Sie die Paketquellliste von Elastic hinzugefügt haben.</p>\n\n<p>Alle Pakete werden mit dem Signierschlüssel von Elasticsearch signiert, um das System vor Paket-Spoofing zu schützen. Pakete, die mit dem Schlüssel authentifiziert wurden, werden von Ihrem Paketmanager als vertrauenswürdig eingestuft. In diesem Schritt importieren Sie den öffentlichen GPG-Schlüssel von Elasticsearch und fügen die Paketquellliste von Elastic hinzu, um Elasticsearch zu installieren.</p>\n\n<p>Verwenden Sie zunächst cURL, das Befehlszeilentool zur Übertragung von Daten mit URLs, um den öffentlichen GPG-Schlüssel von Elasticsearch in APT zu importieren. Beachten Sie, dass wir die Argumente -fsSL nutzen, um alle Fortschritte und möglichen Fehler stumm zu schalten (ausgenommen Serverfehler) und um zuzulassen, dass cURL bei einer Umleitung eine Anfrage an einem neuen Ort stellt.  Leiten Sie die Ausgabe des cURL-Befehls in das APT-Schlüsselprogramm weiter, das den öffentlichen GPG-Schlüssel zu APT hinzufügt.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n</li></ul></code></pre>\n<p>Fügen Sie als Nächstes die Elastic-Quellliste in das Verzeichnis <code>sources.list.d</code> ein, in dem APT nach neuen Quellen sucht:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n</li></ul></code></pre>\n<p>Aktualisieren Sie als Nächstes Ihre Paketlisten, damit APT die neue Elastic-Quelle liest:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Installieren Sie dann Elasticsearch mit diesem Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install elasticsearch\n</li></ul></code></pre>\n<p>Elasticsearch ist nun installiert und bereit für die Konfiguration. Verwenden Sie zur Bearbeitung der Konfigurationsdatei von Elasticsearch (<code>elasticsearch.yml</code>) Ihren bevorzugten Texteditor. Wir verwenden hier <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/elasticsearch/elasticsearch.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Anmerkung:</strong> Die Konfigurationsdatei von Elasticsearch liegt im YAML-Format vor. Das bedeutet, dass wir das Einrückungsformat beibehalten müssen. Achten Sie darauf, dass Sie beim Bearbeiten der Datei keine zusätzlichen Leerzeichen hinzufügen.<br></span></p>\n\n<p>Die Datei <code>elasticsearch.yml</code> bietet Konfigurationsoptionen für Cluster, Knoten, Pfade, Arbeitsspeicher, Netzwerk, Suche und Gateway. Die meisten dieser Optionen sind in der Datei vorkonfiguriert, aber Sie können sie je nach Ihren Bedürfnissen ändern. Im Sinne unserer Demonstration einer Konfiguration mit einem Server werden wir nur die Einstellungen für den Netzwerkhost anpassen.</p>\n\n<p>Elasticsearch lauscht an Port <code>9200</code> auf Verkehr von überall. Sie werden externen Zugriff auf Ihre Elasticsearch-Instanz einschränken wollen, um zu verhindern, dass externe Personen Ihre Daten lesen oder Ihren Elasticsearch-Cluster mit der <a href=\"https://de.wikipedia.org/wiki/Representational_State_Transfer\">REST-API</a> herunterfahren. Um Zugriff zu beschränken und damit die Sicherheit zu erhöhen, suchen Sie nach der Zeile, die <code>network.host</code> angibt, heben Sie die Kommentierung auf und ersetzen den Wert durch <code>localhost</code>, sodass die Zeile wie folgt aussieht:</p>\n<div class=\"code-label \" title=\"/etc/elasticsearch/elasticsearch.yml\">/etc/elasticsearch/elasticsearch.yml</div><pre class=\"code-pre \"><code>. . .\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: <span class=\"highlight\">localhost</span>\n. . .\n</code></pre>\n<p>Wir haben <code>localhost</code> angegeben, damit Elasticsearch an allen Schnittstellen und gebundenen IPs lauscht. Wenn Sie möchten, dass nur an einer bestimmten Schnittstelle gelauscht werden soll, können Sie deren IP-Adresse an Stelle von <code>localhost</code> angeben. Speichern und schließen Sie <code>elasticsearch.yml</code>.  Wenn Sie <code>nano</code> verwenden, können Sie dazu <code>STRG+X</code> drücken, gefolgt von <code>Y</code> und dann <code>ENTER</code>.</p>\n\n<p>Das sind die Mindesteinstellungen, mit denen Sie anfangen können, um Elasticsearch zu nutzen. Sie können Elasticsearch jetzt zum ersten Mal starten.</p>\n\n<p>Starten Sie den Elasticsearch-Dienst mit <code>systemctl</code>. Geben Sie Elasticsearch einige Momente zum Starten. Andernfalls erhalten Sie möglicherweise Fehlermeldungen, dass Sie keine Verbindung herstellen können.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start elasticsearch\n</li></ul></code></pre>\n<p>Führen Sie als Nächstes den folgenden Befehl aus, damit Elasticsearch bei jedem Server-Boot gestartet wird:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable elasticsearch\n</li></ul></code></pre>\n<p>Sie können testen, ob Ihr Elasticsearch-Dienst ausgeführt wird, indem Sie eine HTTP-Anfrage senden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -X GET \"localhost:9200\"\n</li></ul></code></pre>\n<p>Sie erhalten eine Antwort, die einige grundlegende Informationen zu Ihrem lokalen Knoten enthält und in etwa wie folgt aussieht:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\n  \"name\" : \"Elasticsearch\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"qqhFHPigQ9e2lk-a7AvLNQ\",\n  \"version\" : {\n    \"number\" : \"7.7.1\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"deb\",\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\",\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.5.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n\n</code></pre>\n<p>Nachdem Elasticsearch ausgeführt wird, installieren wir nun Kibana, die nächste Komponente des Elastic Stacks.</p>\n\n<h2 id=\"schritt-2-—-installieren-und-konfigurieren-des-kibana-dashboards\">Schritt 2 — Installieren und Konfigurieren des Kibana-Dashboards</h2>\n\n<p>Laut der <a href=\"https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html\">offiziellen Dokumentation</a> sollten Sie Kibana erst nach der Installation von Elasticsearch installieren. Durch eine Installation in dieser Reihenfolge wird sichergestellt, dass die Komponenten, auf die die einzelnen Produkte angewiesen sind, korrekt eingerichtet werden.</p>\n\n<p>Da Sie die Elastic-Paketquelle bereits im vorherigen Schritt hinzugefügt haben, können Sie die verbleibenden Komponenten des Elastic Stacks einfach mit <code>apt</code> installieren:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install kibana\n</li></ul></code></pre>\n<p>Aktivieren und starten Sie dann den Kibana-Dienst:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable kibana\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl start kibana\n</li></ul></code></pre>\n<p>Da Kibana so konfiguriert ist, dass nur an <code>localhost</code> gelauscht wird, müssen wir einen <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">Reverseproxy</a> einrichten, um externen Zugriff darauf zu ermöglichen. Dazu verwenden wir Nginx, das bereits auf Ihrem Server installiert sein sollte.</p>\n\n<p>Verwenden Sie zunächst den Befehl <code>openssl</code>, um einen administrativen Kibana-Benutzer zu erstellen, den Sie für den Zugriff auf die Kibana-Weboberfläche verwenden werden. Als Beispiel nennen wir dieses Konto <code><span class=\"highlight\">kibanaadmin</span></code>; für mehr Sicherheit empfehlen wir aber, einen nicht standardmäßigen Namen für Ihren Benutzer zu wählen, der sich nur schwer erraten lässt.</p>\n\n<p>Mit dem folgenden Befehl werden der administrative Kibana-Benutzer und das Passwort erstellt und in der Datei <code>htpasswd.users</code> gespeichert. Sie werden Nginx so konfigurieren, dass dieser Benutzername und das Passwort erforderlich sind und die Datei vorübergehend gelesen wird:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"<span class=\"highlight\">kibanaadmin</span>:`openssl passwd -apr1`\" | sudo tee -a /etc/nginx/htpasswd.users\n</li></ul></code></pre>\n<p>Geben Sie in der Eingabeaufforderung ein Passwort ein und bestätigen Sie es. Merken oder notieren Sie sich die Anmeldedaten, da Sie sie benötigen werden, um auf die Kibana-Weboberfläche zuzugreifen.</p>\n\n<p>Als Nächstes erstellen wir eine Nginx-Serverblockdatei. Als Beispiel werden wir diese Datei als <code><span class=\"highlight\">your_domain</span></code> bezeichnen; vielleicht finden Sie es jedoch hilfreich, Ihrer Datei einen beschreibenden Namen zu geben. Wenn Sie für diesen Server beispielsweise einen FQDN und DNS-Einträge eingerichtet haben, könnten Sie diese Datei nach Ihrem FQDN benennen.</p>\n\n<p>Erstellen Sie mit nano oder Ihrem bevorzugten Texteditor die Nginx-Serverblockdatei:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Fügen Sie der Datei den folgenden Codeblock hinzu; vergessen Sie dabei nicht, <code><span class=\"highlight\">your_domain</span></code> durch den FQDN oder die öffentliche IP-Adresse Ihres Servers zu ersetzen. Dieser Code konfiguriert Nginx so, dass HTTP-Datenverkehr Ihres Servers an die Kibana-Anwendung geleitet wird, die an <code>localhost:5601</code> lauscht. Außerdem konfiguriert er Nginx so, dass die Datei <code>htpasswd.users</code> gelesen und eine grundlegende Authentifizierung vorgeschrieben wird.</p>\n\n<p>Hinweis: Wenn Sie das <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04\">Nginx-Voraussetzungstutorial</a> bis zum Ende befolgt haben, haben Sie diese Datei möglicherweise bereits erstellt und mit Inhalten ausgefüllt. Löschen Sie in diesem Fall alle vorhandenen Inhalte in der Datei, bevor Sie Folgendes hinzufügen:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/your_domain\">/etc/nginx/sites-available/your_domain</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n\n    server_name <span class=\"highlight\">your_domain</span>;\n\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/htpasswd.users;\n\n    location / {\n        proxy_pass http://localhost:5601;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n</code></pre>\n<p>Wenn Sie fertig sind, speichern und schließen Sie die Datei.</p>\n\n<p>Aktivieren Sie als Nächstes die neue Konfiguration, indem Sie eine symbolische Verknüpfung zum Verzeichnis <code>sites-enabled</code> erstellen. Wenn Sie bereits eine Serverblockdatei mit dem gleichen Namen in der Nginx-Voraussetzung erstellt haben, müssen Sie diesen Befehl nicht ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Prüfen Sie die Konfiguration dann auf Syntaxfehler:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Wenn in Ihrer Ausgabe Fehler angezeigt werden, vergewisserrn Sie sich noch einmal, dass die in Ihrer Konfigurationsdatei platzierten Inhalte richtig hinzugefügt wurden. Sobald Sie sehen, dass in der Ausgabe <code>syntax is ok</code> (Syntax in Ordnung) steht, fahren Sie fort und starten Sie den Nginx-Dienst neu:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Wenn Sie den Leitfaden zur Servereinrichtung befolgt haben, sollte Ihre UFW-Firewall aktiviert sein. Um Verbindungen zu Nginx zu ermöglichen, können wir die Regeln anpassen, indem wir Folgendes eingeben:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 'Nginx Full'\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Hinweis:</strong> Wenn Sie dem Nginx-Voraussetzungstutorial gefolgt sind, haben Sie ggf. eine UFW-Regel erstellt, um das Profil <code>Nginx HTTP</code> über die Firewall zuzulassen. Da das Profil <code>Nginx Full</code> sowohl HTTP- als auch HTTPS-Datenverkehr über die Firewall zulässt, können Sie die von Ihnen im Voraussetzungstutorial erstellte Regel problemlos löschen. Führen Sie dazu folgenden Befehl aus:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw delete allow 'Nginx HTTP'\n</li></ul></code></pre>\n<p></p></span>\n\n<p>Kibana ist nun über Ihren FQDN oder die öffentliche IP-Adresse des Elastic Stack-Servers zugänglich. Sie können die Statusseite des Kibana-Servers überprüfen, indem Sie zur folgenden Adresse navigieren und Ihre Anmeldedaten eingeben, wenn Sie dazu aufgefordert werden:</p>\n<pre class=\"code-pre \"><code>http://<span class=\"highlight\">your_domain</span>/status\n</code></pre>\n<p>Auf dieser Statusseite werden Informationen zur Ressourcennutzung des Servers angezeigt und die installierten Plugins aufgelistet.</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png\" alt=\"|Kibana-Statusseite\"></p>\n\n<p><span class='note'><strong>Hinweis</strong>: Wie im Voraussetzungsbereich erwähnt, sollten Sie auf Ihrem Server SSL/TLS aktivieren. Sie können dem <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04\">Leitfaden zu Let’s Encrypt</a> folgen, um unter Ubuntu 20.04 ein kostenloses SSL-Zertifikat für Nginx zu erhalten. Nach der Erlangung Ihrer SSL/TLS-Zertifikate können Sie zurückkehren und dieses Tutorial abschließen.<br></span></p>\n\n<p>Nach der Installation des Kibana-Dashboards installieren wir nun die nächste Komponente: Logstash.</p>\n\n<h2 id=\"schritt-3-—-installieren-und-konfigurieren-von-logstash\">Schritt 3 — Installieren und Konfigurieren von Logstash</h2>\n\n<p>Zwar kann Beats Daten direkt an die Elasticsearch-Datenbank senden, doch ist es üblich, Logstash zur Verarbeitung der Daten zu verwenden. So können Sie flexibler Daten aus verschiedenen Quellen erfassen, in ein einheitliches Format umwandeln und in eine andere Datenbank exportieren.</p>\n\n<p>Installieren Sie Logstash mit diesem Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install logstash\n</li></ul></code></pre>\n<p>Nach der Installation von Logstash können Sie mit der Konfiguration fortfahren. Die Konfigurationsdateien von Logstash befinden sich im Verzeichnis <code>/etc/logstash/conf.d</code>. Weitere Informationen zur Konfigurationssyntax finden Sie in der von Elastic bereitgestellten <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\">Konfigurationsreferenz</a>. Beim Konfigurieren der Datei ist es hilfreich, sich Logstash als Pipeline vorzustellen, die Daten an einem Ende annimmt, auf die eine oder andere Weise verarbeitet und dann an das Ziel sendet (in diesem Fall an Elasticsearch). Eine Logstash-Pipeline verfügt über zwei erforderliche Elemente (<code>input</code> und <code>output</code>) sowie ein optionales Element (<code>filter</code>). Die Input-Plugins konsumieren Daten aus einer Quelle, die Filter-Plugins verarbeiten die Daten und die Output-Plugins schreiben die Daten an ein Ziel.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png\" alt=\"Logstash-Pipeline\"></p>\n\n<p>Erstellen Sie eine Konfigurationsdatei namens <code>02-beats-input.conf</code>, in der Sie Ihren Filebeat-Input einrichten werden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/02-beats-input.conf\n</li></ul></code></pre>\n<p>Geben Sie die folgende <code>input</code>-Konfiguration ein. Dadurch wird ein <code>beats</code>-Input angegeben, der an TCP-Port <code>5044</code> lauschen wird.</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/02-beats-input.conf\">/etc/logstash/conf.d/02-beats-input.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">input {\n  beats {\n    port =&gt; 5044\n  }\n}\n</code></pre>\n<p>Speichern und schließen Sie die Datei.</p>\n\n<p>Erstellen Sie als Nächstes eine Konfigurationsdatei namens <code>30-elasticsearch-output.conf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf\n</li></ul></code></pre>\n<p>Fügen Sie die folgende <code>output</code>-Konfiguration ein. Im Wesentlichen konfiguriert dieser Output Logstash so, dass die Beats-Daten in Elasticsearch, das bei <code>localhost:9200</code> ausgeführt wird, gespeichert werden – und zwar in einem nach dem verwendeten Beat benannten Index. Der in diesem Tutorial verwendete Beat ist Filebeat:</p>\n<div class=\"code-label \" title=\"/etc/logstash/conf.d/30-elasticsearch-output.conf\">/etc/logstash/conf.d/30-elasticsearch-output.conf</div><pre class=\"code-pre \"><code class=\"code-highlight language-html\">output {\n  if [@metadata][pipeline] {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    pipeline =&gt; \"%{[@metadata][pipeline]}\"\n    }\n  } else {\n    elasticsearch {\n    hosts =&gt; [\"localhost:9200\"]\n    manage_template =&gt; false\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n\n\n</code></pre>\n<p>Speichern und schließen Sie die Datei.</p>\n\n<p>Testen Sie Ihre Logstash-Konfiguration mit diesem Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t\n</li></ul></code></pre>\n<p>Wenn keine Syntaxfehler vorhanden sind, wird Ihre Ausgabe nach ein paar Sekunden <code>Config Validation Result: OK. Exiting Logstash</code> anzeigen. Wenn Sie das nicht in Ihrer Ausgabe sehen, prüfen Sie auf Fehler, die in Ihrer Ausgabe aufgeführt sind, und aktualisieren Sie Ihre Konfiguration, um sie zu korrigieren. Beachten Sie, dass Sie Warnungen von OpenJDK erhalten werden; diese sollten jedoch keine Probleme verursachen und können ignoriert werden.</p>\n\n<p>Wenn Ihr Konfigurationstest erfolgreich war, starten und aktivieren Sie Logstash, um die Konfigurationsänderungen anzuwenden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start logstash\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable logstash\n</li></ul></code></pre>\n<p>Nachdem Logstash nun korrekt ausgeführt wird und vollständig konfiguriert ist, installieren wir Filebeat.</p>\n\n<h2 id=\"schritt-4-—-installieren-und-konfigurieren-von-filebeat\">Schritt 4 — Installieren und Konfigurieren von Filebeat</h2>\n\n<p>Der Elastic Stack verwendet verschiedene schlanke Datenversender namens Beats, um Daten aus verschiedenen Quellen zu erfassen und zu Logstash oder Elasticsearch zu transportieren. Hier sind die Beats, die derzeit bei Elastic verfügbar sind:</p>\n\n<ul>\n<li><a href=\"https://www.elastic.co/products/beats/filebeat\">Filebeat</a>: erfasst und versendet Protokolldateien.</li>\n<li><a href=\"https://www.elastic.co/products/beats/metricbeat\">Metricbeat</a>: erfasst Metriken aus Ihren Systemen und Diensten.</li>\n<li><a href=\"https://www.elastic.co/products/beats/packetbeat\">Packetbeat</a>: erfasst und analysiert Netzwerkdaten.</li>\n<li><a href=\"https://www.elastic.co/products/beats/winlogbeat\">Winlogbeat</a>: erfasst Windows-Ereignisprotokolle.</li>\n<li><a href=\"https://www.elastic.co/products/beats/auditbeat\">Auditbeat</a>: erfasst Linux-Audit-Frameworkdaten und überwacht die Dateiintegrität.</li>\n<li><a href=\"https://www.elastic.co/products/beats/heartbeat\">Heartbeat</a>: überwacht Dienste durch aktive Sondierung auf ihre Verfügbarkeit.</li>\n</ul>\n\n<p>In diesem Tutorial werden wir Filebeat verwenden, um lokale Protokolle an unseren Elastic Stack weiterzuleiten.</p>\n\n<p>Installieren Sie Filebeat mit <code>apt</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install filebeat\n</li></ul></code></pre>\n<p>Konfigurieren Sie als Nächstes Filebeat so, dass eine Verbindung zu Logstash hergestellt wird. Hier werden wir die Beispielkonfigurationsdatei ändern, die mit Filebeat geliefert wird.</p>\n\n<p>Öffnen Sie die Filebeat-Konfigurationsdatei:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/filebeat/filebeat.yml\n</li></ul></code></pre>\n<p><span class='note'><strong>Hinweis:</strong> Wie bei Elasticsearch liegt die Konfigurationsdatei von Filebeat im YAML-Format vor. Das bedeutet, dass eine richtige Einrückung von entscheidender Bedeutung ist; stellen Sie also sicher, dass Sie die gleiche Anzahl von Leerzeichen verwenden, die in diesen Anweisungen angegeben ist.<br></span></p>\n\n<p>Filebeat unterstützt verschiedene Ausgaben; Sie werden in der Regel Ereignisse jedoch nur zur weiteren Verarbeitung direkt an Elasticsearch oder Logstash senden. In diesem Tutorial verwenden wir Logstash, um eine weitere Verarbeitung der von Filebeat erfassten Daten vorzunehmen. Filebeat muss Daten nicht direkt an Elasticsearch senden; lassen Sie uns diese Ausgabe also deaktivieren. Suchen Sie dazu nach dem Abschnitt <code>output.elasticsearch</code> und kommentieren Sie die folgenden Zeilen aus, indem Sie ihnen ein <code>#</code> voranstellen:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>...\n<span class=\"highlight\">#</span>output.elasticsearch:\n  # Array of hosts to connect to.\n  <span class=\"highlight\">#</span>hosts: [\"localhost:9200\"]\n...\n</code></pre>\n<p>Konfigurieren Sie dann den Abschnitt <code>output.logstash</code>. Heben Sie die Kommentierung der Zeilen <code>output.logstash:</code> und <code>hosts: [\"localhost:5044\"]</code> auf, indem Sie das <code>#</code> entfernen. Dadurch wird Filebeat so konfiguriert, dass auf Ihrem Elastic Stack-Server an Port <code>5044</code> eine Verbindung hergestellt wird. Das ist der Port, für den wir zuvor ein Logstash-Input angegeben haben:</p>\n<div class=\"code-label \" title=\"/etc/filebeat/filebeat.yml\">/etc/filebeat/filebeat.yml</div><pre class=\"code-pre \"><code>output.logstash:\n  # The Logstash hosts\n  hosts: [\"localhost:5044\"]\n</code></pre>\n<p>Speichern und schließen Sie die Datei.</p>\n\n<p>Die Funktionalität von Filebeat kann mit <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-modules.html\">Filebeat-Modulen</a> erweitert werden. In diesem Tutorial werden wir das <a href=\"https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-module-system.html\">system</a>-Modul verwenden, das Protokolle erfasst und analysiert, die vom Systemprotokollierungsdienst gängiger Linux-Distributionen erstellt werden.</p>\n\n<p>Aktivieren wir es:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules enable system\n</li></ul></code></pre>\n<p>Sie können eine Liste aktivierter und deaktivierter Module anzeigen, indem Sie Folgendes ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat modules list\n</li></ul></code></pre>\n<p>Sie sehen eine Liste, die der folgenden ähnelt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Enabled:\nsystem\n\nDisabled:\napache2\nauditd\nelasticsearch\nicinga\niis\nkafka\nkibana\nlogstash\nmongodb\nmysql\nnginx\nosquery\npostgresql\nredis\ntraefik\n...\n</code></pre>\n<p>Standardmäßig ist Filebeat so konfiguriert, dass für die syslog- und authorization-Protokolle Standardpfade verwendet werden. Im Fall dieses Tutorials müssen Sie in der Konfiguration nichts ändern. Sie können die Parameter des Moduls in der Konfigurationsdatei <code>/etc/filebeat/modules.d/system.yml</code> anzeigen.</p>\n\n<p>Als Nächstes müssen wir die Filebeat-Aufnahme-Pipelines einrichten, die die Protokolldaten analysieren, bevor sie über Logstash an Elasticsearch gesendet werden. Um die Aufnahme-Pipeline für das system-Modul zu laden, geben Sie folgenden Befehl ein:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --pipelines --modules system\n</li></ul></code></pre>\n<p>Laden Sie als Nächstes die Indexvorlage in Elasticsearch. Ein <a href=\"https://www.elastic.co/blog/what-is-an-elasticsearch-index\"><em>Elasticsearch-Index</em></a> ist eine Sammlung von Dokumenten, die ähnliche Merkmale aufweisen. Indizes werden mit einem Namen identifiziert, der bei der Ausführung verschiedener Operationen darin zum Verweisen auf den Index verwendet wird. Die Indexvorlage wird bei Erstellung eines neuen Index automatisch angewendet.</p>\n\n<p>Um die Vorlage zu laden, verwenden Sie folgenden Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=[\"localhost:9200\"]'\n</li></ul></code></pre><pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Index setup finished.\n</code></pre>\n<p>Filebeat ist mit beispielhaften Kibana-Dashboards ausgestattet, mit denen Sie Filebeat-Daten in Kibana visualisieren können. Bevor Sie die Dashboards verwenden können, müssen Sie das Indexmuster erstellen und die Dashboards in Kibana laden.</p>\n\n<p>Während die Dashboards geladen werden, verbindet sich Filebeat mit Elasticsearch, um Versionsdaten zu überprüfen. Um Dashboards zu laden, wenn Logstash aktiviert ist, müssen Sie die Logstash-Ausgabe deaktivieren und die Elasticsearch-Ausgabe aktivieren:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601\n</li></ul></code></pre>\n<p>Sie sollten eine Ausgabe erhalten, die der folgenden ähnelt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Overwriting ILM policy is disabled. Set `setup.ilm.overwrite:true` for enabling.\n\nIndex setup finished.\nLoading dashboards (Kibana must be running and reachable)\nLoaded dashboards\nSetting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.\nSee more: https://www.elastic.co/guide/en/elastic-stack-overview/current/xpack-ml.html\nLoaded machine learning job configurations\nLoaded Ingest pipelines\n</code></pre>\n<p>Jetzt können Sie Filebeat starten und aktivieren:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start filebeat\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable filebeat\n</li></ul></code></pre>\n<p>Wenn Sie Ihren Elastic Stack richtig eingerichtet haben, wird Filebeat mit dem Versand Ihrer syslog- und authorization-Protokolle an Logstash beginnen, was die Daten dann in Elasticsearch laden wird.</p>\n\n<p>Um zu prüfen, ob Elasticsearch diese Daten tatsächlich erhält, fragen Sie den Filebeat-Index mit folgendem Befehl ab:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'\n</li></ul></code></pre>\n<p>Sie sollten eine Ausgabe erhalten, die der folgenden ähnelt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\n{\n{\n  \"took\" : 4,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 2,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 4040,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"filebeat-7.7.1-2020.06.04\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"FiZLgXIB75I8Lxc9ewIH\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"cloud\" : {\n            \"provider\" : \"digitalocean\",\n            \"instance\" : {\n              \"id\" : \"194878454\"\n            },\n            \"region\" : \"nyc1\"\n          },\n          \"@timestamp\" : \"2020-06-04T21:45:03.995Z\",\n          \"agent\" : {\n            \"version\" : \"7.7.1\",\n            \"type\" : \"filebeat\",\n            \"ephemeral_id\" : \"cbcefb9a-8d15-4ce4-bad4-962a80371ec0\",\n            \"hostname\" : \"june-ubuntu-20-04-elasticstack\",\n            \"id\" : \"fbd5956f-12ab-4227-9782-f8f1a19b7f32\"\n          },\n\n\n...\n</code></pre>\n<p>Wenn Ihre Ausgabe insgesamt 0 Treffer anzeigt, lädt Elasticsearch keine Protokolle unter dem Index, den Sie angefragt haben; in diesem Fall müssen Sie Ihre Einrichtung auf Fehler prüfen. Wenn Sie die erwartete Ausgabe erhalten haben, fahren Sie mit dem nächsten Schritt fort, in dem Sie erfahren werden, wie Sie durch einige Kibana-Dashboards navigieren können.</p>\n\n<h2 id=\"schritt-5-—-erkunden-von-kibana-dashboards\">Schritt 5 — Erkunden von Kibana-Dashboards</h2>\n\n<p>Kehren wir zurück zur Kibana-Weboberfläche, die wir zuvor installiert haben.</p>\n\n<p>Rufen Sie in einem Webbrowser den FQDN oder die öffentliche IP-Adresse Ihres Elastic Stack-Servers auf. Wenn Ihre Sitzung unterbrochen wurde, müssen Sie die in Schritt 2 festgelegten Anmeldedaten erneut eingeben. Sobald Sie sich angemeldet haben, sollten Sie die Homepage von Kibana angezeigt werden:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg\" alt=\"Kibana-Homepage\"></p>\n\n<p>Klicken Sie in der linken Navigationsleiste auf den Link <strong>Discover</strong> (Erkunden) (Sie müssen möglicherweise links unten auf das Symbol zum <strong>Erweitern</strong> klicken, um die Elemente des Navigationsmenüs anzuzeigen). Wählen Sie auf der Seite <strong>Discover</strong> das vordefinierte <strong>filebeat-</strong>*-Indexmuster aus, um Filebeat-Daten anzuzeigen. Standardmäßig werden Ihnen die Protokolldaten der letzten 15 Minuten angezeigt. Im Folgenden sehen Sie ein Histogramm mit Protokollereignissen und einige Protokollnachrichten:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg\" alt=\"Seite „Discover“ (Erkunden)\"></p>\n\n<p>Hier können Sie Ihre Protokolle durchsuchen sowie Ihr Dashboard anpassen. An diesem Punkt wird es hier jedoch nicht viel geben, da Sie nur Syslogs von Ihrem Elastic Stack-Server erfassen.</p>\n\n<p>Verwenden Sie den linken Bereich, um zur <strong>Dashboard</strong>-Seite zu navigieren und nach den <strong>Filebeat System</strong>-Dashboards zu suchen. Nun können Sie die Beispiel-Dashboards auswählen, die mit dem <code>system</code>-Modul von Filebeat geliefert werden.</p>\n\n<p>Beispielsweise können Sie anhand Ihrer syslog-Nachrichten genaue Statistiken anzeigen:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg\" alt=\"Syslog-Dashboard\"></p>\n\n<p>Außerdem können Sie sehen, welche Benutzer den <code>sudo</code>-Befehl verwendet haben und wann:</p>\n\n<p><img src=\"http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg\" alt=\"Sudo-Dashboard\"></p>\n\n<p>Kibana verfügt über viele andere Funktionen wie Diagrammerstellung und Filter; sehen Sie sich diese Funktionen bei Interesse genauer an.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>In diesem Tutorial haben Sie gelernt, wie Sie den Elastic Stack installieren und so konfigurieren können, dass er Systemprotokolle erfasst und analysiert. Denken Sie daran, dass Sie mit <a href=\"https://www.elastic.co/products/beats\">Beats</a> fast jede Art von Protokoll oder indizierten Daten an Logstash senden können. Die Daten werden jedoch noch nützlicher, wenn sie mit einem Logstash-Filter analysiert und strukturiert werden; dabei werden die Daten in ein konsistentes Format umgewandelt, das von Elasticsearch leicht gelesen werden kann.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:42 +0000","feedId":8037,"bgimg":"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png","linkMd5":"fa59649059a7daf018f9d911d686df4f","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","destWidth":1833,"destHeight":948,"sourceBytes":40417,"destBytes":48810,"author":"Erin Glass","articleImgCdnMap":{"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn82@2020_2/2020/08/31/07-48-31-557_41a6f5cccef041e1.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn1@2020_3/2020/08/31/07-48-32-396_0638f11900b9faf4.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn37@2020_3/2020/08/31/07-48-33-221_1dfbe5e28e76fefb.webp","http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn10@2020_4/2020/08/31/07-48-32-522_c0c2011e332e864d.webp","http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn5@2020_6/2020/08/31/07-48-32-458_2cfaecfed9ac513b.webp"},"publishedOrCreatedDate":1598860106978},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Información sobre las bases de datos relacionales","link":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-es","description":"<h3 id=\"introducción\">Introducción</h3>\n\n<p><em>Los sistemas de administración de bases de datos</em> (DBMS) son programas que permiten a los usuarios interactuar con una base de datos. Les permiten controlar el acceso a una base de datos, escribir datos, ejecutar consultas y realizar otras tareas relacionadas con la administración de bases de datos.</p>\n\n<p>Sin embargo, para realizar cualquiera de estas tareas, los DBMS deben tener algún tipo de modelo subyacente que defina la organización de los datos. El <em>modelo relacional</em> es un enfoque para la organización de datos que se ha utilizado ampliamente en programas de software de bases de datos desde su concepción a fines de la década de 1960; a tal grado que, a la fecha de redacción de este artículo, <a href=\"https://db-engines.com/en/ranking\">cuatro de los cinco DBMS más popular</a>es son relacionales.</p>\n\n<p>Este artículo conceptual describe la historia del modelo relacional, la manera en que se organizan los datos en las bases de datos relacionales y cómo se utilizan hoy en día.</p>\n\n<h2 id=\"historia-del-modelo-relacional\">Historia del modelo relacional</h2>\n\n<p>Las <em>bases de datos</em> son conjuntos de información, o <em>datos</em>, modelados de forma lógica. Cualquier recopilación de datos es una base de datos, independientemente de cómo o dónde se almacene. Incluso un gabinete de archivos con información sobre nómina es una base de datos, al igual que una pila de formularios de pacientes hospitalizados o la recopilación de información sobre clientes de una empresa repartida en varias ubicaciones. Antes de que almacenar y administrar datos con computadoras se convirtiera en una práctica común, las bases de datos físicas como estas eran lo único con lo que contaban las organizaciones gubernamentales y empresariales que necesitaban almacenar información.</p>\n\n<p>A mediados del siglo XX, los desarrollos en las ciencias de la computación dieron lugar a máquinas con mayor capacidad de procesamiento y almacenamiento, tanto local como externo. Estos avances hicieron que los especialistas en ciencias de la computación comenzaran a reconocer el potencial que tenían estas máquinas para almacenar y administrar cantidades de datos cada vez más grandes.</p>\n\n<p>Sin embargo, no había teorías sobre cómo las computadoras podían organizar datos de manera significativa y lógica. Una cosa es almacenar datos no ordenados en una máquina, pero es mucho más complicado diseñar sistemas que permitan agregar, recuperar, clasificar y administrar esos datos de forma sistemática y práctica. La necesidad de contar con un marco de trabajo lógico para almacenar y organizar datos dio lugar a varias propuestas sobre cómo utilizar las computadoras para administrar datos.</p>\n\n<p>Uno de los primeros modelos de bases de datos fue el <a href=\"https://en.wikipedia.org/wiki/Hierarchical_database_model\"><em>modelo jerárquico</em></a>, en el que los datos se organizan con una estructura de árbol similar a la de los sistemas de archivos modernos. El siguiente ejemplo muestra el aspecto que podría tener el diseño de una parte de una base de datos jerárquica utilizada para categorizar animales:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png\" alt=\"Ejemplo de base de datos jerárquica: categorización de animales\"></p>\n\n<p>El modelo jerárquico se implementó ampliamente en los primeros sistemas de administración de bases de datos, pero resultaba poco flexible. En este modelo, a pesar de que los registros individuales pueden tener varios &ldquo;elementos secundarios&rdquo;, cada uno puede tener un solo &ldquo;elemento primario&rdquo; en la jerarquía. Es por eso que estas primeras bases de datos jerárquicas se limitaban a representar relaciones &ldquo;uno a uno&rdquo; y &ldquo;uno a varios&rdquo;. Esta carencia de relaciones &ldquo;varios a varios&rdquo; podía provocar problemas al trabajar con puntos de datos que se deseaba asociar a más de un elemento primario.</p>\n\n<p>A fines de los años 60, Edgar F. Codd, un especialista en ciencias de la computación que trabajaba en IBM, diseñó el modelo relacional de administración de bases de datos. El modelo relacional de Codd permitía que los registros individuales se relacionaran con más de una tabla y, de esta manera, posibilitaba las relaciones &ldquo;varios a varios&rdquo; entre los puntos de datos además de las relaciones &ldquo;uno a varios&rdquo;. Esto proporcionó más flexibilidad que los demás modelos existentes a la hora de diseñar estructuras de base de datos y permitió que los sistemas de gestión de bases de datos relacionales (RDBMS) pudieran satisfacer una gama mucho más amplia de necesidades empresariales.</p>\n\n<p>Codd propuso un lenguaje para la administración de datos relacionales, conocido como <a href=\"https://dl.acm.org/doi/pdf/10.1145/1734714.1734718\">Alfa</a>, que influyó en el desarrollo de los lenguajes de bases de datos posteriores. Dos colegas de Codd en IBM, Donald Chamberlin y Raymond Boyce, crearon un lenguaje similar inspirado en Alpha. Lo llamaron <em>SEQUEL</em>, abreviatura de <strong>S</strong>tructured <strong>E</strong>nglish <strong>Que</strong>ry <strong>L</strong>anguage (Lenguaje de consulta estructurado en inglés), pero debido a una marca comercial existente, lo abreviaron a <em>SQL</em> (conocido formalmente como* Lenguaje de consulta estructurado*).</p>\n\n<p>Debido a las limitaciones de hardware, las primeras bases de datos relacionales eran prohibitivamente lentas y el uso de la tecnología tardó un tiempo en generalizarse. Pero a mediados de los años ochenta, el modelo relacional de Codd se había implementado en varios productos comerciales de administración de bases de datos, tanto de IBM como de sus competidores. Estos proveedores también siguieron el liderazgo de IBM al desarrollar e implementar sus propios dialectos de SQL. Para 1987, tanto el Instituto Nacional Estadounidense de Estándares (American National Standards Institute) como la Organización Internacional de Normalización (International Organization for Standardization) habían ratificado y publicado normas para SQL, lo que consolidó su estado como el lenguaje aceptado para la administración de RDBMS.</p>\n\n<p>Gracias al uso extendido del modelo relacional en varias industrias, se lo comenzó a reconocer como el modelo estándar para la administración de datos. Incluso con el surgimiento de varias <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">bases de datos NoSQL</a> en los últimos años, las bases de datos relacionales siguen siendo las herramientas predominantes para almacenar y organizar datos.</p>\n\n<h2 id=\"cómo-organizan-los-datos-las-bases-de-datos-relacionales\">Cómo organizan los datos las bases de datos relacionales</h2>\n\n<p>Ahora que tiene una idea general de la historia del modelo relacional, vamos a analizar en detalle cómo organiza los datos.</p>\n\n<p>Los elementos más fundamentales del modelo relacional son las <em>relaciones</em>, que los usuarios y los RDBMS modernos reconocen como <em>tablas</em>. Una relación es un conjunto de <em>tuplas</em>, o filas de una tabla, en el que cada una de ellas comparte un conjunto de <em>atributos</em> o columnas:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png\" alt=\"Diagrama de ejemplo de la asociación entre las relaciones, las tuplas y los atributos\"></p>\n\n<p>Una columna es la estructura de organización más pequeña de una base de datos relacional y representa las distintas facetas que definen los registros en la tabla. De ahí proviene su nombre más formal: atributos. Se puede pensar que cada tupla es como una instancia única de cualquier tipo de personas, objetos, eventos o asociaciones que contenga la tabla.  Estas instancias pueden ser desde empleados de una empresa y ventas de un negocio en línea hasta resultados de pruebas de laboratorio. Por ejemplo, en una tabla que contiene registros de los maestros de una escuela, las tuplas pueden tener atributos como <code>name</code>, <code>subjects</code>, <code>start_date</code>, etc.</p>\n\n<p>Al crear una columna, especificamos un* tipo de datos *que determina el tipo de entradas que se permiten en esa columna. Los sistemas de administración de bases de datos relacionales (RDBMS) suelen implementar sus propios tipos de datos únicos, que pueden no ser directamente intercambiables con tipos de datos similares de otros sistemas. Algunos tipos de datos frecuentes son fechas, cadenas, enteros y booleanos.</p>\n\n<p>En el modelo relacional, cada tabla contiene, por lo menos, una columna que puede utilizarse para identificar de forma única cada fila, lo que se denomina <em>clave primaria</em>. Esto es importante, dado que significa que los usuarios no necesitan saber dónde se almacenan físicamente los datos en una máquina; en su lugar, sus DBMS pueden realizar un seguimiento de cada registro y devolverlo según corresponda. A su vez, significa que los registros no tienen un orden lógico definido y que los usuarios tienen la capacidad de devolver sus datos en cualquier orden y a través de los filtros que deseen.</p>\n\n<p>Si tiene dos tablas que desea asociar, una manera de hacerlo es con una <em>clave externa</em>. Una clave externa es, básicamente, una copia de la clave primaria de una tabla (la tabla &ldquo;primaria&rdquo;) insertada en una columna de otra tabla (la &ldquo;secundaria&rdquo;). El siguiente ejemplo destaca la relación entre dos tablas: una se utiliza para registrar información sobre los empleados de una empresa y la otra, para realizar un seguimiento de las ventas de la empresa. En este ejemplo, la clave primaria de la tabla <code>EMPLOYEES</code> se utiliza como clave externa de la tabla <code>SALES</code>:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png\" alt=\"Diagrama de ejemplo de cómo la clave primaria de la tabla EMPLOYEE actúa como la clave externa de la tabla SALES\"></p>\n\n<p>Si intenta agregar un registro a la tabla secundaria y el valor ingresado en la columna de la clave externa no existe en la clave primaria de la tabla primaria, la instrucción de inserción no será válida. Esto ayuda a mantener la integridad del nivel de las relaciones, dado que las filas de ambas tablas siempre se relacionarán correctamente.</p>\n\n<p>Los elementos estructurales del modelo relacional ayudan a mantener los datos almacenados de forma organizada, pero el almacenamiento de datos solo es útil si se pueden recuperar. Para obtener información de un RDBMS, puede emitir una <em>consulta</em> o una solicitud estructurada de un conjunto de información. Como se mencionó anteriormente, la mayoría de las bases de datos relacionales utilizan SQL para administrar y consultar datos. SQL permite filtrar y manipular los resultados de las consultas con una variedad de cláusulas, predicados y expresiones, lo que, a su vez, permite controlar correctamente qué datos se mostrarán en el conjunto de resultados.</p>\n\n<h2 id=\"ventajas-y-limitaciones-de-las-bases-de-datos-relacionales\">Ventajas y limitaciones de las bases de datos relacionales</h2>\n\n<p>Teniendo en cuenta la estructura organizativa subyacente de las bases de datos relacionales, consideremos algunas de sus ventajas y desventajas.</p>\n\n<p>Hoy en día, tanto SQL como las bases de datos que lo implementan se desvían del modelo relacional de Codd de diversas maneras. Por ejemplo, el modelo de Codd determina que cada fila de una tabla debe ser única, mientras que, por cuestiones de practicidad, la mayoría de las bases de datos relacionales modernas permiten la duplicación de filas. Algunas personas no consideran que las bases de datos SQL sean verdaderas bases de datos relacionales a menos que cumplan con las especificaciones de Codd del modelo relacional. Sin embargo, en términos prácticos, es probable que cualquier DBMS que utilice SQL y, por lo menos, se adhiera en cierta medida al modelo relacional se denomine &ldquo;sistema de administración de bases de datos relacionales&rdquo;.</p>\n\n<p>A pesar de que las bases de datos relacionales ganaron popularidad rápidamente, algunas de las deficiencias del modelo relacional comenzaron a hacerse evidentes a medida que los datos se volvieron más valiosos y las empresas comenzaron a almacenar más de ellos. Entre otras cosas, puede ser difícil escalar una base de datos relacional de forma horizontal.  Los términos <em>escalado horizontal</em> o <em>escala horizontal</em> se refieren a la práctica de agregar más máquinas a una pila existente para extender la carga y permitir un mayor tráfico y un procesamiento más rápido. Se suele contrastar con el <em>escalado vertical</em>, que implica la actualización del hardware de un servidor existente, generalmente, añadiendo más RAM o CPU.</p>\n\n<p>El motivo por el cual es difícil escalar una base de datos relacional de forma horizontal está relacionado con el hecho de que el modelo relacional se diseñó para garantizar <em>coherencia</em>, lo que significa que los clientes que realizan consultas en la misma base de datos siempre obtendrán los mismos datos. Al querer escalar una base de datos relacional de forma horizontal en varias máquinas, resulta difícil asegurar la coherencia, dado que los clientes pueden escribir datos en un nodo pero no en otros.  Es probable que haya un retraso entre la escritura inicial y el momento en que se actualicen los demás nodos para reflejar los cambios, lo que daría lugar a inconsistencias entre ellos.</p>\n\n<p>Otra limitación que presentan los RDBMS es que el modelo relacional se diseñó para administrar <em>datos estructurados</em> o alineados con un tipo de datos predeterminado o, por lo menos, organizado de una manera predeterminada para que se puedan ordenar o buscar de forma más sencilla. Sin embargo, con la difusión de los equipos informáticos personales y el auge de Internet a principios de la década de 1990, los <em>datos no estructurados</em>, como los mensajes de correo electrónico, las fotos, los videos, etc., se volvieron más comunes.</p>\n\n<p>Nada de esto significa que las bases de datos relacionales no sean útiles. Al contrario, después de más de 40 años, el modelo relacional sigue siendo el marco dominante para la administración de datos. Su prevalencia y longevidad indican que las bases de datos relacionales son una tecnología madura, lo que constituye una de sus principales ventajas. Hay muchas aplicaciones diseñadas para trabajar con el modelo relacional, así como muchos administradores de bases de datos profesionales expertos en bases de datos relacionales. También hay una amplia variedad de recursos disponibles en formato impreso y digital para quienes desean comenzar a utilizar bases de datos relacionales.</p>\n\n<p>Otra ventaja de las bases de datos relacionales es que casi todos los RDBMS admiten <em>transacciones</em>. Las transacciones constan de una o más instrucciones SQL individuales que se ejecutan en secuencia como una unidad de trabajo única. Las transacciones tienen un enfoque de todo o nada, lo que significa que todas las instrucciones SQL de una transacción deben ser válidas; de lo contrario, falla en su totalidad. Esto es muy útil para garantizar la integridad de los datos al realizar cambios en varias filas o tablas.</p>\n\n<p>Por último, las bases de datos relacionales son sumamente flexibles. Se han utilizado para crear una amplia variedad de aplicaciones distintas y siguen funcionando de forma eficiente incluso con grandes cantidades de datos. SQL también es sumamente potente y permite agregar y cambiar datos sobre la marcha, así como alterar la estructura de los esquemas y las tablas de las bases de datos sin afectar a los datos existentes.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>Gracias a su flexibilidad y diseño para la integridad de los datos, más de cincuenta años después de su concepción inicial, las bases de datos relacionales siguen siendo la principal forma de administrar y almacenar datos.  A pesar del surgimiento de diversas bases de datos NoSQL en los últimos años, la comprensión del modelo relacional y la manera de trabajar con RDBMS es fundamental para cualquier persona que desee crear aplicaciones que aprovechen el poder de los datos.</p>\n\n<p>Para obtener más información sobre RDBMS populares de código abierto, le recomendamos consultar <a href=\"https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\">nuestra comparación de diversas bases de datos relacionales SQL de código abierto</a>. Si desea obtener más información sobre las bases de datos en general, le recomendamos consultar <a href=\"https://www.digitalocean.com/community/tags/databases\">nuestra biblioteca completa de contenidos relacionados con bases de datos</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:47:03 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png","linkMd5":"a771760dc9be0f1b6da3957374a8752c","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","destWidth":1440,"destHeight":820,"sourceBytes":26442,"destBytes":57080,"author":"Mark Drake","articleImgCdnMap":{"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn42@2020_2/2020/08/31/07-48-32-526_c309571f1ca0d468.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png":null},"publishedOrCreatedDate":1598860106962},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como configurar um servidor VPN IKEv2 com o StrongSwan no Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-an-ikev2-vpn-server-with-strongswan-on-ubuntu-20-04-pt","description":"<p><em>Uma versão anterior deste tutorial foi escrita por <a href=\"https://www.digitalocean.com/community/users/jellingwood\">Justin Ellingwood</a> e <a href=\"https://www.digitalocean.com/community/users/namo\">Namo</a></em></p>\n\n<h3 id=\"introdução\">Introdução</h3>\n\n<p>Uma rede virtual privada, ou VPN, permite que você criptografe com segurança o tráfego enquanto ele viaja através de redes não confiáveis, como aquelas em uma cafeteria, uma sala de conferências ou um aeroporto.</p>\n\n<p>O <a href=\"https://en.wikipedia.org/wiki/Internet_Key_Exchange\">Internet Key Exchange v2</a>, ou IKEv2, é um protocolo que permite o tunelamento IPSec direto entre o servidor e o cliente. Em implementações de VPNs com IKEv2, o IPSec fornece criptografia para o tráfego de rede. O IKEv2 é nativamente suportado em algumas plataformas (OS X 10.11+, iOS 9.1+ e Windows 10) sem a necessidade de aplicativos adicionais, e ele cuida de engasgos de clientes muito bem.</p>\n\n<p>Neste tutorial, você irá configurar um servidor VPN IKEv2 usando o <a href=\"https://www.strongswan.org/\">StrongSwan</a> em um servidor Ubuntu 20.04. Em seguida, você irá aprender como se conectar a ele com os clientes do Windows, macOS, Ubuntu, iOS e Android.</p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Para completar este tutorial, você precisará de:</p>\n\n<ul>\n<li>Um servidor Ubuntu 20.04 configurado conforme <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">o guia de configuração inicial de servidor com o Ubuntu 20.04</a>, incluindo um usuário <code>sudo</code> não root e um firewall.</li>\n</ul>\n\n<h2 id=\"passo-1-—-instalando-o-strongswan\">Passo 1 — Instalando o StrongSwan</h2>\n\n<p>Primeiramente, vamos instalar o StrongSwan, um daemon IPSec de código aberto que vamos configurar como nosso servidor VPN. Também vamos instalar o componente de infraestrutura de chave pública (PKI) para que possamos criar uma autoridade de certificação (CA) para fornecer credenciais para nossa infraestrutura.</p>\n\n<p>Comece atualizando o cache de pacotes local:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Em seguida, instale o software digitando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan strongswan-pki libcharon-extra-plugins libcharon-extauth-plugins\n</li></ul></code></pre>\n<p>O pacote <code>libcharon-extauth-plugins</code> adicional é usado para garantir que vários clientes possam se autenticar em seu servidor usando um nome de usuário e uma frase secreta compartilhados.</p>\n\n<p>Agora que tudo está instalado, vamos seguir em frente para criar nossos certificados.</p>\n\n<h2 id=\"passo-2-—-criando-uma-autoridade-de-certificação\">Passo 2 — Criando uma Autoridade de Certificação</h2>\n\n<p>Um servidor com IKEv2 exige que um certificado se identifique para os clientes. Para ajudar a criar o certificado exigido, o pacote <code>strongswan-pki</code> vem com um utilitário chamado <code>pki</code> para gerar uma autoridade de certificação e certificados de servidor.</p>\n\n<p>Para começar, vamos criar alguns diretórios para armazenar todos os ativos em que iremos trabalhar. A estrutura do diretório corresponde a alguns dos diretórios em <code>/etc/ipsec.d</code>, para onde vamos mover todos os itens que eventualmente criarmos:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir -p ~/pki/{cacerts,certs,private}\n</li></ul></code></pre>\n<p>Em seguida, vamos bloquear as permissões para que nossos arquivos privados não possam ser vistos por outros usuários:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod 700 ~/pki\n</li></ul></code></pre>\n<p>Agora que temos uma estrutura de diretório para armazenar tudo, podemos gerar uma chave raiz. Esta é uma chave RSA 4096-bit que será usada para assinar nossa autoridade de certificação raiz.</p>\n\n<p>Execute estes comandos para gerar a chave:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/ca-key.pem\n</li></ul></code></pre>\n<p>Depois disso, podemos seguir em frente para criar nossa autoridade de certificação root usando a chave que acabamos de gerar para assinar o certificado root:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --self --ca --lifetime 3650 --in ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">    --type rsa --dn \"CN=VPN root CA\" --outform pem &gt; ~/pki/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>O sinalizador <code>--lifetime 3650</code> é usado para garantir que o certificado root da autoridade de certificação seja válido por 10 anos. O certificado root para uma autoridade não muda de maneira típica, uma vez que ele teria que ser redistribuído para todos os servidores e clientes que dependem dele. Sendo assim, 10 anos é um valor de validade padrão seguro.</p>\n\n<p>É possível alterar o valor de <em>nome diferenciado</em> (DN) para outra coisa se você preferir. O nome comum (campo CN) aqui é apenas o indicador, então ele não precisa corresponder a nada em sua infraestrutura.</p>\n\n<p>Agora que temos nossa autoridade de certificação root em funcionamento, podemos criar um certificado que o servidor VPN usará.</p>\n\n<h2 id=\"passo-3-—-gerando-um-certificado-para-o-servidor-vpn\">Passo 3 — Gerando um certificado para o Servidor VPN</h2>\n\n<p>Agora vamos criar um certificado e chave para o servidor VPN. Este certificado permitirá que o cliente verifique a autenticidade do servidor utilizando o certificado CA que acabamos de gerar.</p>\n\n<p>Primeiramente, crie uma chave privada para o servidor VPN com o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/server-key.pem\n</li></ul></code></pre>\n<p>Agora, crie e assine o certificado do servidor VPN com a chave de autoridade de certificação que você criou no passo anterior. Execute o comando a seguir, mas altere o campo Common Name (CN) e o campo Subject Alternate Name (SAN) para o nome DNS do seu servidor VPN ou endereço IP:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --pub --in ~/pki/private/server-key.pem --type rsa \\\n</li><li class=\"line\" data-prefix=\"$\">    | pki --issue --lifetime 1825 \\\n</li><li class=\"line\" data-prefix=\"$\">        --cacert ~/pki/cacerts/ca-cert.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --cakey ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --dn \"CN=<span class=\"highlight\">server_domain_or_IP</span>\" --san <span class=\"highlight\">server_domain_or_IP</span> \\\n</li><li class=\"line\" data-prefix=\"$\">        --flag serverAuth --flag ikeIntermediate --outform pem \\\n</li><li class=\"line\" data-prefix=\"$\">    &gt;  ~/pki/certs/server-cert.pem\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: se estiver usando um endereço IP em vez de um nome DNS, será necessário especificar várias entradas <code>--san</code>. A linha no bloco de comando anterior onde você especifica o nome diferenciado (<code>--dn ...</code>) precisará ser modificada com a entrada extra, assim como na seguinte linha extraída:</p>\n<pre class=\"code-pre \"><code>--dn \"CN=<span class=\"highlight\">IP address</span> --san @<span class=\"highlight\">IP_address</span> --san <span class=\"highlight\">IP_address</span> \\\n</code></pre>\n<p>A razão pela qual essa entrada extra <code>--san @<span class=\"highlight\">IP_address</span></code> é necessária é que alguns clientes irão verificar se o certificado TLS possui tanto uma entrada DNS quanto uma entrada de endereço IP para um servidor ao verificar sua identidade.<br></p></span>\n\n<p>A opção <code>--flag serverAuth</code> é usada para indicar que o certificado será usado explicitamente para a autenticação de servidor, antes de o túnel criptografado ser estabelecido. A opção <code>--flag ikeIntermediate</code> é usada para dar suporte a clientes macOS mais antigos.</p>\n\n<p>Agora que geramos todos os arquivos TLS/SSL que o StrongSwan necessita, podemos mover os arquivos para seus lugares no diretório <code>/etc/ipsec.d</code> digitando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp -r ~/pki/* /etc/ipsec.d/\n</li></ul></code></pre>\n<p>Neste passo, criamos um par de certificados que será usado para proteger as comunicações entre o cliente e o servidor. Também assinamos os certificados com a chave CA, para que o cliente possa verificar a autenticidade do servidor VPN utilizando o certificado CA. Com todos esses certificados prontos, vamos seguir para a configuração do software.</p>\n\n<h2 id=\"passo-4-—-configurando-o-strongswan\">Passo 4 — Configurando o StrongSwan</h2>\n\n<p>O StrongSwan tem um arquivo de configuração padrão com alguns exemplos, mas a maior parte da configuração terá que ser feita por nossa conta. Vamos fazer um backup do arquivo para referência antes de começar do zero:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/ipsec.conf{,.original}\n</li></ul></code></pre>\n<p>Crie e abra um novo arquivo de configuração em branco usando seu editor de texto preferido. Aqui, usaremos o <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: conforme for trabalhando nessa seção para configurar a porção do servidor da sua VPN, você encontrará configurações que se referem a lados <em>left</em> (esquerdo) e <em>right</em> (direito) de uma conexão. Quando se trabalha com VPNs IPSec, o lado <em>esquerdo</em> por convenção refere-se ao sistema local que você está configurando, neste caso o servidor. As diretivas laterais direita nessas configurações se referirão a clientes remotos, como telefones e outros computadores.</p>\n\n<p>Quando você for configurar clientes mais adiante neste tutorial, os arquivos de configuração do cliente se referirão a si mesmos usando várias diretivas <em>left</em>, e o servidor será referido usando a terminologia <em>right</em>.<br></p></span>\n\n<p>Primeiramente, vamos dizer ao StrongSwan para registrar os status do daemon para correção de erros e permitir conexões duplicadas. Adicione estas linhas ao arquivo:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n</code></pre>\n<p>Depois, vamos criar uma seção de configuração para nossa VPN. Também vamos dizer ao StrongSwan para criar os Túneis da VPN com IKEv2 e para carregar automaticamente essa seção de configuração quando for iniciado. Adicione as linhas a seguir ao arquivo:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n</code></pre>\n<p>Também vamos configurar a detecção de ponto morto para limpar conexões pendentes, caso o cliente se desconecte de maneira inesperada. Adicione estas linhas:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n</code></pre>\n<p>Em seguida, vamos configurar os parâmetros IPSec do lado &ldquo;esquerdo&rdquo; do servidor. Cada um dos seguintes parâmetros garante que o servidor esteja configurado para aceitar conexões de clientes e se identificar corretamente. Você irá adicionar cada uma dessas configurações ao arquivo <code>/etc/ipsec.conf</code> assim que estiver familiarizado com o que eles são e por que são usados:</p>\n\n<ul>\n<li><code>left=%any</code> O valor <code>%any</code> garante que o servidor usará a interface de rede onde ele recebe conexões de entrada para posterior comunicação com clientes. Por exemplo, se você estiver conectando um cliente por uma rede privada, o servidor usará o endereço IP privado onde ele recebe tráfego para o resto da conexão.</li>\n<li><code>leftid=<span class=\"highlight\">@server_domain_or_IP</span></code> Essa opção controla o nome que o servidor apresenta aos clientes. Quando combinada com a próxima opção <code>leftcert</code>, a opção <code>leftid</code> garante que o nome configurado do servidor e o nome diferenciado (DN) que está contido no certificado público correspondam.</li>\n<li><code>leftcert=server-cert.pem</code> Essa opção indica o caminho para o certificado público do servidor que você configurou no Passo 3. Sem ele, o servidor não será capaz de autenticar-se com clientes ou terminar de negociar a configuração do IKEv2.</li>\n<li><code>leftsendcert=always</code> O valor <code>always</code> (sempre) garante que qualquer cliente que se conecte ao servidor receba sempre uma cópia do certificado público do servidor como parte da configuração de conexão inicial.</li>\n<li><code>leftsubnet=0.0.0.0/0</code> A última opção do lado “esquerdo” que você adicionará informa aos clientes sobre as sub-redes que são alcançáveis por trás do servidor. Neste caso, <code>0.0.0.0/0</code> é usado para representar todo o conjunto de endereços IPv4, o que significa que o servidor irá pedir aos clientes para enviar todo o seu tráfego pela VPN por padrão.</li>\n</ul>\n\n<p>Agora que você está familiarizado com cada uma das opções relevantes do lado “esquerdo”, adicione todas elas ao arquivo desta forma:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n</code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: quando configurar o ID do servidor (<code>leftid</code>), inclua apenas o caractere <code>@</code> se o seu servidor de VPN for identificado por um nome de domínio:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .    leftid=<span class=\"highlight\">@vpn.example.com</span>\n    . . .\n</code></pre>\n<p>Se o servidor for identificado pelo seu endereço IP, apenas coloque o endereço IP em:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .\n    leftid=<span class=\"highlight\">your_server_ip</span>\n    . . .\n</code></pre>\n<p></p></span>\n\n<p>Em seguida, podemos configurar os parâmetros IPSec do lado &ldquo;direito&rdquo; do cliente. Cada um dos parâmetros a seguir informa ao servidor como aceitar conexões de clientes, como os clientes devem se autenticar no servidor e os intervalos de endereços IP privados e servidores DNS que os clientes usarão. Adicione cada uma dessas configurações ao arquivo <code>/etc/ipsec.conf</code> assim que estiver familiarizado com o que elas são e por que são usadas:</p>\n\n<ul>\n<li><code>right=%any</code> A opção <code>%any</code> para o lado <code>right</code> da conexão instrui o servidor a aceitar conexões recebidas de qualquer cliente remoto.</li>\n<li><code>rightid=%any</code> Essa opção garante que o servidor não irá rejeitar conexões de clientes que fornecem uma identidade antes que o túnel criptografado seja estabelecido.</li>\n<li><code>rightauth=eap-mschapv2</code> Essa opção configura o método de autenticação que os clientes usarão para se autenticar no servidor. O <code>eap-mschapv2</code> é usado aqui para garantir ampla compatibilidade para suportar clientes como Windows, macOS e dispositivos Android.</li>\n<li><code>rightsourceip=10.10.10.0/24</code> Essa opção instrui o servidor a atribuir endereços IP privados aos clientes a partir da pool de IPs <code>10.10.10.0/24</code> especificada.</li>\n<li><code>rightdns=8.8.8.8,8.8.4.4</code> Esses endereços IP são resolvedores de DNS públicos do Google. Eles podem ser alterados para outros resolvedores públicos, resolvedores do servidor VPN ou qualquer outro resolvedor que os clientes consigam acessar.</li>\n<li><code>rightsendcert=never</code> Essa opção instrui o servidor que os clientes não precisam enviar por conta própria um certificado para se autenticar.</li>\n</ul>\n\n<p>Agora que você está familiarizado com as opções do lado “direito” necessárias para a VPN, adicione as seguintes linhas ao <code>/etc/ipsec.conf</code>:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n</code></pre>\n<p>Agora, vamos dizer ao StrongSwan para pedir ao cliente as credenciais de usuário ao se conectarem:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    eap_identity=%identity\n</code></pre>\n<p>Por fim, adicione as seguintes linhas para dar suporte a clientes Linux, Windows, macOS, iOS e Android. Estas linhas especificam os vários algoritmos de intercâmbio de chave, hash, autenticação e criptografia (comumente conhecidos como <em>Pacotes de codificação</em>) que o StrongSwan permitirá que diferentes clientes usem:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Cada pacote de codificação suportado é separado dos outros por uma vírgula. Por exemplo, <code>chacha20poly1305-sha512-curve25519-prfsha512</code> é um pacote, e <code>aes256gcm16-sha384-prfsha384-ecp384</code> é outro. Os pacotes de codificação listados aqui são selecionados para garantir a mais ampla compatibilidade entre os clientes Windows, macOS, iOS, Android e Linux.</p>\n\n<p>O arquivo de configuração completo deve se parecer com este:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n    eap_identity=%identity\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Salve e feche o arquivo assim que verificar se adicionou cada linha corretamente. Se usou o <code>nano</code>, faça isso pressionando as teclas <code>CTRL+X</code>, <code>Y</code> e depois <code>ENTER</code>.</p>\n\n<p>Agora que configuramos os parâmetros VPN, vamos seguir em frente para criar uma conta que permita que nossos usuários se conectem ao servidor.</p>\n\n<h2 id=\"passo-5-—-configurando-a-autenticação-da-vpn\">Passo 5 — Configurando a autenticação da VPN</h2>\n\n<p>Nosso servidor VPN agora está configurado para aceitar conexões de clientes, mas ainda não temos nenhuma credencial configurada. Vamos ter que configurar algumas coisas em um arquivo de configuração especial chamado <code>ipsec.secrets:</code></p>\n\n<ul>\n<li>Precisamos dizer ao StrongSwan onde encontrar a chave privada do certificado do nosso servidor, de modo que o servidor consiga autenticar os clientes.</li>\n<li>Também precisamos configurar uma lista de usuários que serão autorizados a se conectar à VPN.</li>\n</ul>\n\n<p>Vamos abrir o arquivo secrets para edição:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.secrets\n</li></ul></code></pre>\n<p>Primeiramente, vamos dizer ao StrongSwan onde encontrar nossa chave privada:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code>: RSA \"server-key.pem\"\n</code></pre>\n<p>Então, vamos definir as credenciais do usuário. Você pode inventar qualquer nome de usuário ou senha que você queira:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Salve e feche o arquivo. Agora que terminamos de trabalhar com os parâmetros VPN, vamos reiniciar o serviço VPN para que nossas configurações seja aplicada:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart strongswan-starter\n</li></ul></code></pre>\n<p>Agora que o servidor VPN foi configurado completamente com ambas as opções de servidor e credenciais de usuário, é hora de seguir em frente para configurar a parte mais importante: o firewall.</p>\n\n<h2 id=\"passo-6-—-configurando-o-encaminhamento-de-ip-do-firewall-e-do-kernel\">Passo 6 — Configurando o encaminhamento de IP do Firewall e do Kernel</h2>\n\n<p>Com a configuração do StrongSwan concluída, precisamos configurar o firewall para permitir o tráfego VPN e encaminhá-lo.</p>\n\n<p>Se você seguiu o tutorial pré-requisito de configuração inicial do servidor, deve ter um firewall UFW habilitado. Se ainda não tiver o UFW configurado, comece adicionando uma regra para permitir conexões SSH através do firewall. Isso é feito para que sua sessão atual não feche quando o UFW for habilitado:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow OpenSSH\n</li></ul></code></pre>\n<p>Em seguida, habilite o firewall digitando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Após isso, adicione uma regra para permitir o tráfego UDP nas portas IPSec padrão, <code>500</code> e <code>4500</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 500,4500/udp\n</li></ul></code></pre>\n<p>Em seguida, vamos abrir um dos arquivos de configuração do UFW para adicionar algumas políticas de baixo nível para roteamento e encaminhamento de pacotes IPSec. No entanto, antes que possamos fazer isso, precisamos encontrar qual interface de rede em nosso servidor é usada para o acesso à internet. Encontre essa interface consultando o dispositivo associado à rota padrão:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ip route show default\n</li></ul></code></pre>\n<p>Sua interface pública deve vir após a palavra &ldquo;dev&rdquo;. Por exemplo, este resultado mostra a interface chamada <code>eth0</code>, que está destacada no exemplo a seguir:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>default via <span class=\"highlight\">your_server_ip</span> dev <span class=\"highlight\">eth0</span> proto static\n</code></pre>\n<p>Quando tiver sua interface de rede pública, abra o arquivo <code>/etc/ufw/before.rules</code> no seu editor de texto. As regras nesse arquivo são adicionadas ao firewall antes do resto das regras habituais de entrada e saída. Elas são usadas para configurar a conversão de endereços de rede (NAT) para que o servidor possa encaminhar corretamente as conexões de entrada e saída para clientes e a internet.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/before.rules\n</li></ul></code></pre>\n<p>Perto do topo do arquivo (antes da linha <code>*filter</code>), adicione o seguinte bloco de configuração. Altere cada instância de <code>eth0</code> na configuração acima para corresponder ao nome de interface que você encontrou com <code>ip route</code>. As linhas <code>*nat</code> criam regras para que o firewall possa rotear e manipular corretamente o tráfego entre os clientes VPN e a internet. A linha <code>*mangle</code> ajusta o tamanho máximo do segmento de pacotes para evitar possíveis problemas com certos clientes VPN:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code><span class=\"highlight\">*nat</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -m policy --pol ipsec --dir out -j ACCEPT</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -j MASQUERADE</span>\n<span class=\"highlight\">COMMIT</span>\n\n<span class=\"highlight\">*mangle</span>\n<span class=\"highlight\">-A FORWARD --match policy --pol ipsec --dir in -s 10.10.10.0/24 -o eth0 -p tcp -m tcp --tcp-flags SYN,RST SYN -m tcpmss --mss 1361:1536 -j TCPMSS --set-mss 1360</span>\n<span class=\"highlight\">COMMIT</span>\n\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n. . .\n</code></pre>\n<p>Em seguida, após as linhas de definição <code>*filter</code> e de cadeia, adicione mais um bloco de configuração:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code>. . .\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir in --proto esp -s 10.10.10.0/24 -j ACCEPT</span>\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir out --proto esp -d 10.10.10.0/24 -j ACCEPT</span>\n</code></pre>\n<p>Essas linhas dizem ao firewall para encaminhar o tráfego <a href=\"https://wiki.wireshark.org/ESP\">ESP</a> (Encapsulating Security Payload) para que os clientes VPN possam se conectar. O ESP proporciona segurança adicional para nossos pacotes VPN, enquanto eles estiverem passando por redes não confiáveis.</p>\n\n<p>Quando tiver terminado, salve e feche o arquivo após ter verificado se adicionou cada linha corretamente. Se usou o <code>nano</code>, faça isso pressionando as teclas <code>CTRL+X</code>, <code>Y</code> e depois <code>ENTER</code>.</p>\n\n<p>Antes de reiniciarmos o firewall, vamos alterar alguns parâmetros do kernel de rede para permitir o roteamento de uma interface para outra. O arquivo que controla essas configurações é chamado <code>/etc/ufw/sysctl.conf</code>. Precisaremos configurar algumas coisas no arquivo.</p>\n\n<p>Primeiro, o encaminhamento de pacotes IPv4 precisa ser ligado para que o tráfego possa se mover entre a VPN e as interfaces de rede voltadas ao público no servidor. Em seguida, vamos desabilitar a Path MTU Discovery (PMTUD), ou Descoberta da unidade máxima de transmissão do caminho, para evitar problemas de fragmentação de pacotes. Por fim, não vamos aceitar redirecionamentos ICMP nem enviar redirecionamentos ICMP para evitar ataques <a href=\"https://en.wikipedia.org/wiki/Man-in-the-middle_attack\">man-in-the-middle</a>.</p>\n\n<p>Abra o arquivo de configuração do kernel do UFW usando o <code>nano</code> ou seu editor de texto preferido:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/sysctl.conf\n</li></ul></code></pre>\n<p>Agora, adicione a definição <code>net/ipv4/ip_forward=1</code> no final do arquivo para habilitar o encaminhamento de pacotes entre interfaces:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_forward=1</span>\n</code></pre>\n<p>Depois disso, bloqueie o envio e recebimento de pacotes de redirecionamento ICMP adicionando as seguintes linhas no final do arquivo:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/conf/all/accept_redirects=0</span>\n<span class=\"highlight\">net/ipv4/conf/all/send_redirects=0</span>\n</code></pre>\n<p>Por fim, desative a descoberta MTU do caminho adicionando esta linha no fim do arquivo:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_no_pmtu_disc=1</span>\n</code></pre>\n<p>Salve o arquivo quando terminar. Agora, podemos habilitar todas as nossas alterações desativando e reativando o firewall, já que o UFW aplica essas configurações sempre que ele é reiniciado:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw disable\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Será solicitado que você confirme o processo. Digite <code>Y</code> para habilitar o UFW novamente com as novas configurações.</p>\n\n<h2 id=\"passo-7-—-testando-a-conexão-vpn-no-windows-macos-ubuntu-ios-e-android\">Passo 7 — Testando a conexão VPN no Windows, macOS, Ubuntu, iOS e Android</h2>\n\n<p>Agora que você tem tudo configurado, é hora do teste. Primeiro, você precisará copiar o certificado CA que você criou e instalá-lo no(s) seu(s) dispositivo(s) cliente que serão conectados à VPN. A maneira mais simples de fazer isso é fazendo login no seu servidor e gerando o conteúdo do arquivo de certificação:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cat /etc/ipsec.d/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Você verá um resultado similar a este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>-----BEGIN CERTIFICATE-----\nMIIFNDCCAxygAwIBAgIIHCsidG5mXzgwDQYJKoZIhvcNAQEMBQAwODELMAkGA1UE\n\n. . .\n\nH2YUdz8XNHrJHvMQKWFpi0rlEcMs+MSXPFWE3Q7UbaZJ/h8wpSldSUbQRUlphExJ\ndJ4PX+MUJO/vjG1/ie6Kh25xbBAc3qNq8siiJZDwrg6vjEK7eiZ1rA==\n-----END CERTIFICATE-----\n</code></pre>\n<p>Copie este resultado para o seu computador, incluindo as linhas <code>-----BEGIN CERTIFICATE----- e -----END</code><code>CERTIFICATE----- e</code> salve-o em um arquivo com um nome reconhecível, como <code>ca-cert.pem</code>. Certifique-se de que o arquivo que você criar tenha a extensão <code>.pem.</code></p>\n\n<p>De forma alternativa, <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server\">utilize o SFTP para transferir o arquivo para seu computador</a>.</p>\n\n<p>Assim que tiver o arquivo <code>ca-cert.pem</code> baixado no seu computador, você pode configurar a conexão com a VPN.</p>\n\n<h3 id=\"conectando-se-com-o-windows\">Conectando-se com o Windows</h3>\n\n<p>Existem várias maneiras de importar o certificado root e configurar o Windows para se conectar a uma VPN. O primeiro método usa ferramentas gráficas para cada passo. O segundo método usa comandos do PowerShell, que podem ser controlados e modificados para se adequar à configuração de sua VPN.</p>\n\n<p><span class='note'><strong>Nota:</strong> essas instruções foram testadas em instalações do Windows 10 executando as versões 1903 e 1909.<br></span></p>\n\n<h4 id=\"configurando-o-windows-com-ferramentas-gráficas\">Configurando o Windows com ferramentas gráficas</h4>\n\n<p>Primeiramente, importe o certificado raiz, seguindo estes passos:</p>\n\n<ol>\n<li><code>Pressione WINDOWS+R para trazer a janela Executar e digite mmc.exe</code>&ldquo;**** para iniciar o Console de Gerenciamento do Windows.</li>\n<li>Do menu <strong>Arquivo,</strong> navegue até <strong>Adicionar ou Remover Snap-in,</strong> selecione <strong>Certificados</strong> da lista de snap-ins disponíveis, e clique <strong>em Adicionar</strong>.</li>\n<li>Queremos que a VPN funcione com qualquer usuário, logo selecione <strong>Conta de Computador</strong> e clique <strong>em Avançar</strong>.</li>\n<li>Estamos configurando coisas no computador local, então selecione <strong>Computador Local e, depois, clique em Concluir.</strong></li>\n<li>Sob o nó <strong>Raiz do Console, expanda a entrada Certificados (Computador Local), expanda Autoridades</strong> de Certificação de Raíz Confiáveis** e, em seguida, selecione a entrada <strong>Certificados:</strong> <img src=\"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png\" alt=\"de Certificados Exibição\"> </li>\n<li>A partir do menu <strong>Ação,</strong> selecione <strong>Todas as Tarefas</strong> e clique <strong>Importar</strong> para exibir o Assistente de Importação de Certificados. Clique <strong>em Avançar</strong> para passar da introdução.</li>\n<li>Na tela <strong>Arquivo a ser importado</strong>, pressione o botão <strong>Pesquisar</strong>. Certifique-se de alterar o tipo de arquivo de “X.509 Certificate (<em>.cer;</em>.crt)” para “Todos os arquivos (<em>.</em> )”, e selecione o arquivo <code>ca-cert.pem</code> que você salvou. <strong>Então, clique em Avançar</strong>.</li>\n<li>Certifique-se <strong>de que Armazenagem de Certificados foi configurada em Autoridades Confiáveis para Certificação Raiz, e clique em</strong> Avançar.</li>\n<li>Clique em <strong>Concluir</strong> para importar o certificado.</li>\n</ol>\n\n<p>Então, configure a VPN com estes passos:</p>\n\n<ol>\n<li><strong>Abra o Painel de Controle,</strong> navegue até o <strong>Centro de Redes e Compartilhamento</strong>.</li>\n<li>Clique em <strong>Configurar uma nova conexão ou rede,</strong> depois selecione <strong>Conectar a um local de trabalho</strong>.</li>\n<li>Selecione <strong>Usar minha conexão com a Internet (VPN)</strong>.</li>\n<li>Digite os detalhes do servidor VPN. Digite o nome de domínio ou endereço IP do servidor no campo <strong>Endereço de internet,</strong> depois, preencha <strong>o Nome do destino</strong> com algo que descreva sua conexão VPN. Então,clique <strong>em Feito</strong>.</li>\n</ol>\n\n<h4 id=\"configurando-o-windows-usando-o-powershell\">Configurando o Windows usando o PowerShell</h4>\n\n<p>Para importar o certificado de CA root usando o PowerShell, abra primeiro um prompt PowerShell com privilégios de administrador. Para fazer isso, clique com o botão direito no ícone do menu Start e selecione o <code>Windows PowerShell (Admin)</code>. Você também pode abrir um prompt de comando como administrador e digitar <code>powershell</code>.</p>\n\n<p>Em seguida, importaremos o certificado usando o cmdlet <code>Import-Certificate</code> do PowerShell. No comando a seguir, o primeiro argumento <code>-CertStoreLocation</code> irá garantir que o certificado seja importado no armazenamento <strong>Autoridades de Certificação Raiz Confiáveis</strong> de modo que todos os programas e usuários consigam verificar o certificado do servidor VPN. O argumento <code>-FilePath</code> deve apontar para a localização onde você copiou o certificado. No exemplo a seguir, o caminho é <code>C:\\Users\\sammy\\Documents\\ca-cert.pem</code>. Certifique-se de editar o comando para que corresponda à localização que você usou.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Import-Certificate `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CertStoreLocation cert:\\LocalMachine\\Root\\ `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -FilePath <span class=\"highlight\">C:\\users\\sammy\\Documents\\ca-cert.pem</span>\n</li></ul></code></pre>\n<p>O comando gerará algo parecido com o seguinte:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>   PSParentPath: Microsoft.PowerShell.Security\\Certificate::LocalMachine\\Root\n\nThumbprint                                Subject\n----------                                -------\nDB00813B4087E9367861E8463A60CEA0ADC5F002  CN=VPN root CA\n</code></pre>\n<p>Agora, para configurar a VPN usando o PowerShell, execute o comando a seguir. Coloque o nome DNS ou endereço IP do seu servidor na linha <code>-ServerAddress</code>. Os diversos sinalizadores garantirão que o Windows seja configurado corretamente com os parâmetros de segurança apropriados que correspondam às opções que você definiu em <code>/etc/ipsec.conf</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Add-VpnConnection -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -ServerAddress \"<span class=\"highlight\">server_domain_or_IP</span>\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -TunnelType \"IKEv2\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationMethod \"EAP\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionLevel \"Maximum\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -RememberCredential `\n</li></ul></code></pre>\n<p>Se o comando for bem sucedido, não haverá nenhum resultado. Para confirmar que a VPN está configurada corretamente, use o cmdlet <code>Get-VPNConnection</code>:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Get-VpnConnection -Name \"VPN Connection\"\n</li></ul></code></pre>\n<p>Você receberá um resultado como o seguinte:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Name                  : VPN Connection\nServerAddress         : <span class=\"highlight\">your_server_ip</span>\nAllUserConnection     : False\nGuid                  : {B055A1AB-175C-4028-B4A8-D34309A2B20E}\nTunnelType            : Ikev2\nAuthenticationMethod  : {Eap}\nEncryptionLevel       : Maximum\nL2tpIPsecAuth         :\nUseWinlogonCredential : False\nEapConfigXmlStream    : #document\nConnectionStatus      : Disconnected\nRememberCredential    : True\nSplitTunneling        : False\nDnsSuffix             :\nIdleDisconnectSeconds : 0\n</code></pre>\n<p>Por padrão, o Windows escolhe algoritmos mais antigos e mais lentos. Execute o cmdlet <code>Set-VpnConnectionIPsecConfiguration</code> para atualizar os parâmetros de criptografia que o Windows usará para a troca de chaves do IKEv2 e para criptografar pacotes:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Set-VpnConnectionIPsecConfiguration -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CipherTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -DHGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -IntegrityCheckMethod SHA384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -PfsGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionMethod GCMAES256\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Nota</strong>: se você quiser excluir a conexão VPN e reconfigurá-la com opções diferentes, pode executar o cmdlet <code>Remove-VpnConnection</code>.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Remove-VpnConnection -Name \"VPN Connection\" -Force\n</li></ul></code></pre>\n<p>O sinalizador <code>-Force</code> irá ignorar o prompt que pediria que você confirmasse a remoção. Você deve estar desconectado da VPN se for tentar removê-la usando esse comando.<br></p></span>\n\n<h4 id=\"conectando-se-à-vpn\">Conectando-se à VPN</h4>\n\n<p>Depois de ter importado o certificado e configurado a VPN usando qualquer um dos dois métodos, sua nova conexão VPN será visível na lista de redes. Selecione a VPN e clique <strong>em Conectar</strong>. Você será solicitado a colocar seu nome de usuário e senha. Digite-os, clique em <strong>OK</strong> e você estará conectado.</p>\n\n<h3 id=\"conectando-se-com-o-macos\">Conectando-se com o macOS</h3>\n\n<p>Siga estes passos para importar o certificado:</p>\n\n<ol>\n<li>Clique duas vezes no arquivo de certificados. <strong>Acesso ao Chaveiro irá aparecer com uma janela que diz &quot;Acesso ao</strong> Chaveiro está tentando modificar o chaveiro do sistema. Digite sua senha para permitir.&rdquo;</li>\n<li>Digite sua senha, então clique em <strong>Modificar o Chaveiro</strong></li>\n<li>Clique duas vezes no certificado VPN recém-importado. Isso traz uma pequena janela de propriedades onde você pode especificar os níveis de confiança. Defina <strong>Segurança IP (IPSec)</strong> para <strong>Sempre Confiar</strong> e você será solicitado a inserir sua senha novamente. Esta configuração é salva automaticamente após colocar a senha.</li>\n</ol>\n\n<p>Agora que o certificado foi importado e é confiável, configure a conexão VPN com estes passos:</p>\n\n<ol>\n<li>Vá até as <strong>Preferências do Sistema</strong> e escolha <strong>Rede</strong>.</li>\n<li>Clique no pequeno botão &ldquo;mais&rdquo; no canto inferior esquerdo da lista de redes.</li>\n<li>Na notificação que aparece, Defina <strong>a Interface</strong> como <strong>VPN, defina o Tipo</strong>** de VPN** como <strong>IKEv2</strong> e nomeie a conexão.</li>\n<li>No campo <strong>Servidor</strong> e <strong>ID Remoto</strong>, digite o nome do domínio ou endereço IP do servidor. Deixe o <strong>ID Local</strong> em branco.</li>\n<li>Clique em <strong>Configurações de Autenticação,</strong> selecione <strong>Nome de usuário,</strong> e digite seu nome de usuário e senha que você configurou para seu usuário VPN. Então clique <strong>em OK</strong>.</li>\n</ol>\n\n<p>Por fim, clique em <strong>Conectar</strong> para se conectar à VPN. Agora, você deve estar conectado à VPN.</p>\n\n<h3 id=\"conectando-se-com-o-ubuntu\">Conectando-se com o Ubuntu</h3>\n\n<p>Para se conectar a partir de uma máquina com Ubuntu, você pode configurar e gerenciar o StrongSwan como um serviço ou usar um comando único cada vez que desejar se conectar. São fornecidas instruções para ambos.</p>\n\n<h4 id=\"gerenciando-o-strongswan-como-um-serviço\">Gerenciando o StrongSwan como um Serviço</h4>\n\n<p>Para gerenciar o StrongSwan como um serviço, você precisará executar os seguintes passos de configuração.</p>\n\n<p>Primeiro, atualize seu cache de pacotes local usando o <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo apt update\n</li></ul></code></pre>\n<p>Em seguida, instale o StrongSwan e os plug-ins necessários para a autenticação:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Agora, você precisará de uma cópia do certificado CA no diretório <code>/etc/ipsec.d/cacerts</code> para que seu cliente possa verificar a identidade do servidor. Execute o comando a seguir para criar uma cópia do arquivo <code>ca-cert.pem</code> nesse local:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Para garantir que a VPN seja executada apenas sob demanda, use o <code>systemctl</code> para impedir que o StrongSwan seja executado automaticamente:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl disable --now strongswan-starter\n</li></ul></code></pre>\n<p>Em seguida, configure o nome de usuário e a senha que você usará para se autenticar no servidor VPN. Edite <code>/etc/ipsec.secrets</code> usando o nano ou seu editor preferido:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<p>Adicione a linha a seguir, editando os valores de nome de usuário e senha destacados para que correspondam àqueles que você configurou no servidor:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Por fim, edite o arquivo <code>/etc/ipsec.conf</code> para configurar seu cliente de forma que corresponda à configuração do servidor:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code>config setup\n\nconn ikev2-rw\n    right=<span class=\"highlight\">server_domain_or_IP</span>\n    # This should match the `leftid` value on your server's configuration\n    rightid=<span class=\"highlight\">server_domain_or_IP</span>\n    rightsubnet=0.0.0.0/0\n    rightauth=pubkey\n    leftsourceip=%config\n    leftid=<span class=\"highlight\">username</span>\n    leftauth=eap-mschapv2\n    eap_identity=%identity\n    auto=start\n</code></pre>\n<p>Para se conectar ao VPN, digite:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start strongswan-starter\n</li></ul></code></pre>\n<p>Para se desconectar novamente, digite:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop strongswan-starter\n</li></ul></code></pre>\n<h4 id=\"usando-o-cliente-charon-cmd-para-conexões-únicas\">Usando o cliente <code>charon-cmd</code> para conexões únicas</h4>\n\n<p>Para gerenciar o StrongSwan como um serviço, você precisará executar os seguintes passos de configuração.</p>\n\n<p>Primeiro, atualize seu cache de pacotes local usando o <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Em seguida, instale o StrongSwan e os plug-ins necessários para a autenticação:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Agora, você precisará de uma cópia do certificado CA no diretório <code>/etc/ipsec.d/cacerts</code> para que seu cliente possa verificar a identidade do servidor. Execute o comando a seguir para criar uma cópia do arquivo <code>ca-cert.pem</code> nesse local:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Neste ponto, você pode se conectar ao servidor VPN com o <code>charon-cmd</code> usando o certificado CA do servidor, o endereço IP do servidor VPN e o nome de usuário que você configurou.</p>\n\n<p>Execute o comando a seguir sempre que quiser se conectar à VPN:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo charon-cmd --cert ca-cert.pem --host <span class=\"highlight\">vpn_domain_or_IP</span> --identity <span class=\"highlight\">your_username</span>\n</li></ul></code></pre>\n<p>Quando solicitado, forneça a senha do usuário VPN e você será conectado à VPN. Para desconectar-se, pressione <code>CTRL+C</code> no terminal e espere que a conexão feche.</p>\n\n<h3 id=\"conectando-se-com-o-ios\">Conectando-se com o iOS</h3>\n\n<p>Para configurar a conexão VPN em um dispositivo iOS, siga estes passos:</p>\n\n<ol>\n<li>Envie para si mesmo um e-mail com o certificado root anexado.</li>\n<li>Abra o e-mail no seu dispositivo iOS e toque no arquivo do certificado anexado; depois, toque <strong>em Instalar</strong> e digite a sua senha. Assim que instalar, toque <strong>em Feito</strong>.</li>\n<li>Vá até <strong>Configurações, Geral, VPN e toque em</strong> Adicionar** Configuração de VPN. Isso irá trazer a tela de configuração de conexão VPN.</li>\n<li>Toque em <strong>Tipo</strong> e selecione <strong>IKEv2</strong>.</li>\n<li>No campo <strong>Descrição,</strong> escreva um nome curto para a conexão VPN. Isso pode ser o que você quiser.</li>\n<li>No campo <strong>Servidor e ID Remoto,</strong>**** digite o nome do domínio ou endereço IP do servidor. O campo <strong>ID Local</strong> pode ser deixado em branco.</li>\n<li>Digite seu nome <strong>de usuário e senha na seção Autenticação e, em seguida toque em</strong>**** Feito.</li>\n<li>Selecione a conexão VPN que você acabou de criar, toque no botão no alto da página e você estará conectado.</li>\n</ol>\n\n<h3 id=\"conectando-se-com-o-android\">Conectando-se com o Android</h3>\n\n<p>Siga estes passos para importar o certificado:</p>\n\n<ol>\n<li>Envie um e-mail para si mesmo com o certificado CA anexado. Salve o certificado CA na sua pasta de downloads.</li>\n<li>Faça download do <a href=\"https://play.google.com/store/apps/details?id=org.strongswan.android&amp;hl=en_US\">StrongSwan VPN</a> client da Play Store.</li>\n<li>Abra o aplicativo. Toque no ícone &ldquo;more&rdquo; (<strong>&hellip;</strong>) no canto superior direito e selecione <strong>CA certificates</strong>.</li>\n<li>Toque no ícone &ldquo;more&rdquo;(<strong>&hellip;</strong>), no canto superior direito novamente. Selecione <strong>Importar certificado</strong>.</li>\n<li>Navegue até o arquivo do certificado CA, em sua pasta de downloads e selecione-o para importá-lo para o aplicativo.</li>\n</ol>\n\n<p>Agora que o certificado foi importado no aplicativo StrongSwan, você pode configurar a conexão VPN com esses passos:</p>\n\n<ol>\n<li>No aplicativo, clique em <strong>ADICIONAR PERFIL VPN,</strong> no topo.</li>\n<li>Preencha o <strong>Servidor</strong> com o nome de domínio ou endereço IP público do seu servidor VPN.</li>\n<li>Certifique-se de que <strong>IKEv2 EAP (Usuário/Senha)</strong> está selecionado como o Tipo VPN.</li>\n<li>Preencha o <strong>Nome de usuário</strong> e <strong>Senha</strong> com as credenciais que você definiu no servidor.</li>\n<li>Desmarque <strong>Selecionar automaticamente</strong> na seção <strong>certificado CA</strong> e clique <strong>em Selecionar o certificado CA</strong>.</li>\n<li>Toque na aba <strong>IMPORTADO,</strong> no alto da tela e escolha o CA que você importou (ele será chamado &ldquo;VPN raiz CA&rdquo; se você não tiver mudado o &ldquo;DN&rdquo; anteriormente).</li>\n<li>Se você quiser, preencha <strong>o Nome de perfil (opcional)</strong> com um nome mais descritivo.</li>\n</ol>\n\n<p>Quando quiser se conectar à VPN, clique no perfil que você acabou de criar no aplicativo StrongSwan.</p>\n\n<h3 id=\"solucionando-problemas-de-conexão\">Solucionando problemas de conexão</h3>\n\n<p>Se você não conseguir importar o certificado, <code>certifique-se de que o arquivo tenha a extensão .pem, e não .pem.txt</code>&ldquo;.</p>\n\n<p>Se você não conseguir conectar-se à VPN, verifique o nome do servidor ou endereço IP que você usou. O nome de domínio ou endereço IP do servidor deve corresponder ao que você havia configurado como o nome comum (CN) ao criar o certificado. Se eles não corresponderem, a conexão VPN não funcionará. Por exemplo, se for configurar um certificado com o CN de <code>vpn.example.com, você</code> <em>deve</em> usar <code>vpn.example.com</code> ao digitar os detalhes do servidor VPN. Verifique novamente o comando que você usou para gerar o certificado e os valores que você usou ao criar sua conexão VPN.</p>\n\n<p>Por fim, verifique novamente a configuração da VPN para garantir que o valor <code>leftid</code> tenha sido configurado com o símbolo <code>@</code> se você estiver usando um nome de domínio:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    leftid=<span class=\"highlight\">@</span>vpn.example.com\n</code></pre>\n<p>E, caso esteja usando um endereço IP, certifique-se de que o símbolo <code>@</code> seja omitido. Além disso, certifique-se de que ao gerar o arquivo <code>server-cert.pem</code> você tenha incluído ambas os sinalizadores <code>--san @<span class=\"highlight\">IP_address</span></code> e <code>--san <span class=\"highlight\">IP_address</span></code>.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Neste tutorial, você construiu um servidor VPN que usa o protocolo IKEv2. Você aprendeu sobre as diretrizes que controlam os lados <code>left</code> e <code>right</code> de uma conexão tanto no servidor quanto nos clientes. Você também configurou um cliente Windows, macOS, iOS, Android ou Linux para se conectar à VPN.</p>\n\n<p>Para adicionar ou remover usuários, volte para o Passo 5 novamente. Cada linha em <code>/etc/ipsec.secrets</code> é para um usuário. Dessa forma, adicionar,remover usuários ou alterar senhas depende apenas da edição do arquivo.</p>\n\n<p>Agora, você pode ter certeza de que suas atividades online permanecerão seguras onde quer que você vá e com qualquer dispositivo que use para acessar a internet.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:20 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png","linkMd5":"0a29085f0e1bdf03de8399661bf1c074","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp","destWidth":1436,"destHeight":754,"sourceBytes":109775,"destBytes":168410,"author":"Jamon Camisso","articleImgCdnMap":{"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp"},"publishedOrCreatedDate":1598860106968},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"How To Configure Nginx as a Web Server and Reverse Proxy for Apache on One Ubuntu 20.04 Server","link":"https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server","description":"<p><em>The author selected the <a href=\"https://www.brightfunds.org/organizations/electronic-frontier-foundation-inc\">Electronic Frontier Foundation</a> to receive a donation as part of the <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> program.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Apache and Nginx are two popular open-source web servers often used with PHP. It can be useful to run both of them on the same virtual machine when hosting multiple websites that have varied requirements. The general solution for running two web servers on a single system is to either use multiple IP addresses or different port numbers.</p>\n\n<p>Servers that have both IPv4 and IPv6 addresses can be configured to serve Apache sites on one protocol and Nginx sites on the other, but this isn&rsquo;t currently practical, as IPv6 adoption by ISPs is still not widespread. Having a different port number like <code>81</code> or <code>8080</code> for the second web server is another solution, but sharing URLs with port numbers (such as <code>http://<span class=\"highlight\">your_domain</span>:81</code>) isn&rsquo;t always reasonable or ideal.</p>\n\n<p>In this tutorial you&rsquo;ll configure Nginx as both a web server and as a reverse proxy for Apache – all on a single server. </p>\n\n<p>Depending on the web application, code changes might be required to keep Apache reverse-proxy-aware, especially when SSL sites are configured. To avoid this, you will install an Apache module called <code>mod_rpaf</code> which rewrites certain environment variables so it appears that Apache is directly handling requests from web clients.</p>\n\n<p>We will host four domain names on one server. Two will be served by Nginx: <code>nginx1.<span class=\"highlight\">your_domain</span></code> (the default virtual host) and <code>nginx2.<span class=\"highlight\">your_domain</span></code>. The remaining two, <code>apache1.<span class=\"highlight\">your_domain</span></code> and <code>apache2.<span class=\"highlight\">your_domain</span></code>, will be served by Apache. We&rsquo;ll also configure Apache to serve PHP applications using PHP-FPM, which offers better performance over <code>mod_php</code>.</p>\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\n<p>To complete this tutorial, you&rsquo;ll need the following:</p>\n\n<ul>\n<li>A new Ubuntu 20.04 server configured by following the <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Initial Server Setup with Ubuntu 20.04</a>, with a sudo non-root user and a firewall.</li>\n<li>Four fully-qualified domain names configured to point to your server&rsquo;s IP address. See Step 3 of <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-host-name-with-digitalocean\">How To Set Up a Host Name with DigitalOcean</a> for an example of how to do this. If you host your domains&rsquo; DNS elsewhere, you should create appropriate A records there instead.</li>\n</ul>\n\n<h2 id=\"step-1-—-installing-apache-and-php-fpm\">Step 1 — Installing Apache and PHP-FPM</h2>\n\n<p>Let&rsquo;s start by installing Apache and PHP-FPM.</p>\n\n<p>In addition to Apache and PHP-FPM, we will also install the PHP FastCGI Apache module, <code>libapache2-mod-fastcgi</code>, to support FastCGI web applications.</p>\n\n<p>First, update your package list to ensure you have the latest packages.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Next, install the Apache and PHP-FPM packages:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install apache2 php-fpm\n</li></ul></code></pre>\n<p>The FastCGI Apache module isn&rsquo;t available in Ubuntu&rsquo;s repository so download it from <a href=\"https://kernel.org\">kernel.org</a> and install it using the <code>dpkg</code> command.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://mirrors.edge.kernel.org/ubuntu/pool/multiverse/liba/libapache-mod-fastcgi/libapache2-mod-fastcgi_2.4.7~0910052141-1.2_amd64.deb\n</li><li class=\"line\" data-prefix=\"$\">sudo dpkg -i libapache2-mod-fastcgi_2.4.7~0910052141-1.2_amd64.deb\n</li></ul></code></pre>\n<p>Next, let&rsquo;s change Apache&rsquo;s default configuration to use PHP-FPM.</p>\n\n<h2 id=\"step-2-—-configuring-apache-and-php-fpm\">Step 2 — Configuring Apache and PHP-FPM</h2>\n\n<p>In this step we will change Apache&rsquo;s port number to <code>8080</code> and configure it to work with PHP-FPM using the <code>mod_fastcgi</code> module. Rename Apache&rsquo;s <code>ports.conf</code> configuration file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/apache2/ports.conf /etc/apache2/ports.conf.default\n</li></ul></code></pre>\n<p>Create a new <code>ports.conf</code> file with the port set to <code>8080</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"Listen <span class=\"highlight\">8080</span>\" | sudo tee /etc/apache2/ports.conf\n</li></ul></code></pre>\n<p><span class='note'><strong>Note:</strong> Web servers are generally set to listen on <code>127.0.0.1:8080</code> when configuring a reverse proxy but doing so would set the value of PHP&rsquo;s environment variable <strong>SERVER_ADDR</strong> to the loopback IP address instead of the server&rsquo;s public IP. Our aim is to set up Apache in such a way that its websites do not see a reverse proxy in front of it. So, we will configure it to listen on <code>8080</code> on all IP addresses.<br></span></p>\n\n<p>Next we&rsquo;ll create a virtual host file for Apache. The <code>&lt;VirtualHost&gt;</code> directive in this file will be set to serve sites only on port <code>8080</code>.</p>\n\n<p>Disable the default virtual host:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo a2dissite 000-default\n</li></ul></code></pre>\n<p>Then create a new virtual host file, using the existing default site:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /etc/apache2/sites-available/000-default.conf /etc/apache2/sites-available/001-default.conf\n</li></ul></code></pre>\n<p>Now open the new configuration file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/apache2/sites-available/001-default.conf\n</li></ul></code></pre>\n<p>Change the listening port to <code>8080</code>:</p>\n<div class=\"code-label \" title=\"/etc/apache2/sites-available/000-default.conf\">/etc/apache2/sites-available/000-default.conf</div><pre class=\"code-pre apache\"><code>&lt;VirtualHost *:<span class=\"highlight\">8080</span>&gt;\n    ServerAdmin webmaster@localhost\n    DocumentRoot /var/www/html\n    ErrorLog ${APACHE_LOG_DIR}/error.log\n    CustomLog ${APACHE_LOG_DIR}/access.log combined\n&lt;/VirtualHost&gt;\n</code></pre>\n<p>Save the file and activate the new configuration file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo a2ensite 001-default\n</li></ul></code></pre>\n<p>Then reload Apache:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload apache2\n</li></ul></code></pre>\n<p>Install the <code>net-tools</code> package which contains the <code>netstat</code> command:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install net-tools\n</li></ul></code></pre>\n<p>Verify that Apache is now listening on <code>8080</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo netstat -tlpn\n</li></ul></code></pre>\n<p>The output should look like the following example, with <code>apache2</code> listening on <code>8080</code>:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Active Internet connections (only servers)\nProto Recv-Q Send-Q Local Address     Foreign Address      State    PID/Program name\ntcp        0      0 0.0.0.0:22        0.0.0.0:*            LISTEN   1086/sshd\n<span class=\"highlight\">tcp6       0      0 :::8080           :::*                 LISTEN   4678/apache2</span>\ntcp6       0      0 :::22             :::*                 LISTEN   1086/sshd\n</code></pre>\n<p>Once you verify that Apache is listening on the correct port, you can configure support for PHP and FastCGI.</p>\n\n<h2 id=\"step-3-—-configuring-apache-to-use-mod_fastcgi\">Step 3 — Configuring Apache to Use <code>mod_fastcgi</code></h2>\n\n<p>Apache serves PHP pages using <code>mod_php</code> by default, but it requires additional configuration to work with PHP-FPM.</p>\n\n<p><span class='note'><strong>Note:</strong> If you are trying this tutorial on an existing installation of LAMP with <code>mod_php</code>, disable it first with <code>sudo a2dismod php7.4</code>.<br></span></p>\n\n<p>We will be adding a configuration block for <code>mod_fastcgi</code>, which depends on <code>mod_action</code>. <code>mod_action</code> is disabled by default, so we first need to enable it:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo a2enmod actions\n</li></ul></code></pre>\n<p>Rename the existing FastCGI configuration file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/apache2/mods-enabled/fastcgi.conf /etc/apache2/mods-enabled/fastcgi.conf.default\n</li></ul></code></pre>\n<p>Create a new configuration file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/apache2/mods-enabled/fastcgi.conf\n</li></ul></code></pre>\n<p>Add the following directives to the file to pass requests for <code>.php</code> files to the PHP-FPM UNIX socket:</p>\n<div class=\"code-label \" title=\"/etc/apache2/mods-enabled/fastcgi.conf\">/etc/apache2/mods-enabled/fastcgi.conf</div><pre class=\"code-pre apache\"><code>&lt;IfModule mod_fastcgi.c&gt;\n  AddHandler fastcgi-script .fcgi\n  FastCgiIpcDir /var/lib/apache2/fastcgi\n  AddType application/x-httpd-fastphp .php\n  Action application/x-httpd-fastphp /php-fcgi\n  Alias /php-fcgi /usr/lib/cgi-bin/php-fcgi\n  FastCgiExternalServer /usr/lib/cgi-bin/php-fcgi -socket /run/php/php7.4-fpm.sock -pass-header Authorization\n  &lt;Directory /usr/lib/cgi-bin&gt;\n    Require all granted\n  &lt;/Directory&gt;\n&lt;/IfModule&gt;\n</code></pre>\n<p>Save the changes and perform a configuration test:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apachectl -t\n</li></ul></code></pre>\n<p><span class='note'><strong>Note:</strong> If you see the warning <code>Could not reliably determine the server's fully /<br>\nqualified domain name, using 127.0.1.1. Set the /'ServerName' directive globally/<br>\nto suppress this message.</code>, you can safely ignore it for now. We&rsquo;ll configure server names later.<br></span></p>\n\n<p>Reload Apache as long as <code>Syntax OK</code> is displayed:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload apache2\n</li></ul></code></pre>\n<p>Now let&rsquo;s make sure we can serve PHP from Apache.</p>\n\n<h2 id=\"step-4-—-verifying-php-functionality\">Step 4 — Verifying PHP Functionality</h2>\n\n<p>Let&rsquo;s make sure that PHP works by creating a <code>phpinfo()</code> file and accessing it from a web browser.</p>\n\n<p>Create the file <code>/var/www/html/info.php</code>, which contains a call to the <code>phpinfo</code> function:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"&lt;?php phpinfo(); ?&gt;\" | sudo tee /var/www/html/info.php\n</li></ul></code></pre>\n<p>Note that if you followed the initial server setup in the <strong>Prerequisites</strong> section, then you likely enabled the Apache firewall. Let&rsquo;s go ahead and make sure that we can access our IP on port <code>8080</code>, which is not currently accessible. We&rsquo;ll restrict public access to this port in <strong>Step 10</strong>.</p>\n\n<p>First allow port <code>8080</code> through the firewall:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 8080\n</li></ul></code></pre>\n<p>Since we are going to secure our Apache domains, let&rsquo;s go ahead and make sure TLS traffic on port <code>443</code> can enter.</p>\n\n<p>Allow <code>Apache Full</code> to permit traffic on ports <code>80</code> and <code>443</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow \"Apache Full\"\n</li></ul></code></pre>\n<p>Now check your firewall status:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>If you followed the prerequisites, then the output will look like this:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>To                         Action      From\n--                         ------      ----\nOpenSSH                    ALLOW       Anywhere\n<span class=\"highlight\">Apache Full</span>                ALLOW       Anywhere\n<span class=\"highlight\">8080</span>                       ALLOW       Anywhere\nOpenSSH (v6)               ALLOW       Anywhere (v6)\n<span class=\"highlight\">Apache Full (v6)</span>           ALLOW       Anywhere (v6)\n<span class=\"highlight\">8080 (v6)</span>                  ALLOW       Anywhere (v6)\n</code></pre>\n<p>You will see that port <code>8080</code> and <code>Apache Full</code> are allowed alongside any other firewall rules. Now let&rsquo;s view our <code>info.php</code> page.</p>\n\n<p>To see the <code>info.php</code> in a browser, go to <code>http://<span class=\"highlight\">your_server_ip</span>:8080/info.php</code>. This will give you a list of the configuration settings PHP is using. You&rsquo;ll see output similar to this:</p>\n\n<p><img src=\"https://i.imgur.com/zLWcC3K.png\" alt=\"phpinfo Server API\"></p>\n\n<p><img src=\"https://i.imgur.com/JuyXP5S.png\" alt=\"phpinfo PHP Variables\"></p>\n\n<p>At the top of the page, check that <strong>Server API</strong> says <strong>FPM/FastCGI</strong>. About two-thirds of the way down the page, the <strong>PHP Variables</strong> section will tell you the <strong>SERVER_SOFTWARE</strong> is Apache on Ubuntu. These confirm that <code>mod_fastcgi</code> is active and Apache is using PHP-FPM to process PHP files.</p>\n\n<h2 id=\"step-5-—-creating-virtual-hosts-for-apache\">Step 5 — Creating Virtual Hosts for Apache</h2>\n\n<p>Let&rsquo;s create Apache virtual host files for the domains <code>apache1.<span class=\"highlight\">your_domain</span></code> and <code>apache2.<span class=\"highlight\">your_domain</span></code>. To do that, we&rsquo;ll first create document root directories for both sites and place some default files in those directories so we can easily test our configuration.</p>\n\n<p>First, create the document root directories:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mkdir -v /var/www/apache1.<span class=\"highlight\">your_domain</span> /var/www/apache2.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Then create an <code>index</code> file for each site:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"&lt;h1 style='color: green;'&gt;Apache 1&lt;/h1&gt;\" | sudo tee /var/www/apache1.<span class=\"highlight\">your_domain</span>/index.html\n</li><li class=\"line\" data-prefix=\"$\">echo \"&lt;h1 style='color: red;'&gt;Apache 2&lt;/h1&gt;\" | sudo tee /var/www/apache2.<span class=\"highlight\">your_domain</span>/index.html\n</li></ul></code></pre>\n<p>Then create a <code>phpinfo()</code> file for each site so we can test that PHP is configured properly.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"&lt;?php phpinfo(); ?&gt;\" | sudo tee /var/www/apache1.<span class=\"highlight\">your_domain</span>/info.php\n</li><li class=\"line\" data-prefix=\"$\">echo \"&lt;?php phpinfo(); ?&gt;\" | sudo tee /var/www/apache2.<span class=\"highlight\">your_domain</span>/info.php\n</li></ul></code></pre>\n<p>Now create the virtual host file for <code>apache1.<span class=\"highlight\">your_domain</span></code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/apache2/sites-available/apache1.<span class=\"highlight\">your_domain</span>.conf\n</li></ul></code></pre>\n<p>Add the following code to the file to define the host:</p>\n<div class=\"code-label \" title=\"/etc/apache2/sites-available/apache1.your_domain.conf\">/etc/apache2/sites-available/apache1.your_domain.conf</div><pre class=\"code-pre apache\"><code>    &lt;VirtualHost *:8080&gt;\n        ServerName apache1.<span class=\"highlight\">your_domain</span>\n        ServerAlias www.apache1.<span class=\"highlight\">your_domain</span>\n        DocumentRoot /var/www/apache1.<span class=\"highlight\">your_domain</span>\n        &lt;Directory /var/www/apache1.<span class=\"highlight\">your_domain</span>&gt;\n            AllowOverride All\n        &lt;/Directory&gt;\n    &lt;/VirtualHost&gt;\n</code></pre>\n<p>The line <code>AllowOverride All</code> enables <code>.htaccess</code> support.</p>\n\n<p>These are only the most basic directives. For a complete guide on setting up virtual hosts in Apache, see <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-apache-virtual-hosts-on-ubuntu-18-04\">How To Set Up Apache Virtual Hosts on Ubuntu 18.04</a>.</p>\n\n<p>Save and close the file. Then create a similar configuration for <code>apache2.<span class=\"highlight\">your_domain</span></code>. First create the file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/apache2/sites-available/apache2.your_domain.conf\n</li></ul></code></pre>\n<p>Then add the configuration to the file:</p>\n<div class=\"code-label \" title=\"/etc/apache2/sites-available/apache2.&lt;span class=\" highlight>your_domain.conf&rsquo;&gt;/etc/apache2/sites-available/apache2.<span class=\"highlight\">your_domain</span>.conf</div><pre class=\"code-pre apache\"><code>    &lt;VirtualHost *:8080&gt;\n        ServerName apache2.<span class=\"highlight\">your_domain</span>\n        ServerAlias www.apache2.<span class=\"highlight\">your_domain</span>\n        DocumentRoot /var/www/apache2.<span class=\"highlight\">your_domain</span>\n        &lt;Directory /var/www/apache2.<span class=\"highlight\">your_domain</span>\n            AllowOverride All\n        &lt;/Directory&gt;\n    &lt;/VirtualHost&gt;\n</code></pre>\n<p>Save the file and exit the editor.</p>\n\n<p>Now that both Apache virtual hosts are set up, enable the sites using the <code>a2ensite</code> command. This creates a symbolic link to the virtual host file in the <code>sites-enabled</code> directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo a2ensite apache1.<span class=\"highlight\">your_domain</span>\n</li><li class=\"line\" data-prefix=\"$\">sudo a2ensite apache2.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Check Apache for configuration errors again:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apachectl -t\n</li></ul></code></pre>\n<p>You&rsquo;ll see <code>Syntax OK</code> displayed if there are no errors. If you see anything else, review the configuration and try again.</p>\n\n<p>Reload Apache to apply the changes once your configuration is error-free:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload apache2\n</li></ul></code></pre>\n<p>To confirm the sites are working, open <code>http://apache1.<span class=\"highlight\">your_domain</span>:8080</code> and <code>http://apache2.<span class=\"highlight\">your_domain</span>:8080</code> in your browser and verify that each site displays its <code>index.html</code> file.</p>\n\n<p>You&rsquo;ll see the following results:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67458/apache1.png\" alt=\"apache1 index page\"></p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67458/apache2.png\" alt=\"apache2 index page\"></p>\n\n<p>Also, ensure that PHP is working by accessing the <code>info.php</code> files for each site. Visit <code>http://apache1.<span class=\"highlight\">your_domain</span>:8080/info.php</code> and <code>http://apache2.<span class=\"highlight\">your_domain</span>:8080/info.php</code> in your browser.</p>\n\n<p>You&rsquo;ll see the same PHP configuration spec list on each site as you saw in <strong>Step 4</strong>.</p>\n\n<p>We now have two websites hosted on Apache at port <code>8080</code>. Let&rsquo;s configure Nginx next.</p>\n\n<h2 id=\"step-6-—-installing-and-configuring-nginx\">Step 6 — Installing and Configuring Nginx</h2>\n\n<p>In this step we&rsquo;ll install Nginx and configure the domains <code>nginx1.<span class=\"highlight\">your_domain</span></code> and <code>nginx2.<span class=\"highlight\">your_domain</span></code> as Nginx&rsquo;s virtual hosts. For a complete guide on setting up virtual hosts in Nginx, see <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04#step-5-%E2%80%93-setting-up-server-blocks-(recommended)\">How To Set Up Nginx Server Blocks (Virtual Hosts) on Ubuntu 20.04</a>.</p>\n\n<p>Install Nginx using the <code>apt</code> package manager:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install nginx\n</li></ul></code></pre>\n<p>Then remove the default virtual host&rsquo;s symlink since we won&rsquo;t be using it any more:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo rm /etc/nginx/sites-enabled/default\n</li></ul></code></pre>\n<p>We&rsquo;ll create our own default site later (<code>nginx1.<span class=\"highlight\">your_domain</span></code>).</p>\n\n<p>Now we&rsquo;ll create virtual hosts for Nginx using the same procedure we used for Apache. First create document root directories for both the websites:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mkdir -v /usr/share/nginx/nginx1.<span class=\"highlight\">your_domain</span> /usr/share/nginx/nginx2.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>We&rsquo;ll keep the Nginx web sites in <code>/usr/share/nginx</code>, which is where Nginx wants them by default. You could put them under <code>/var/www/html</code> with the Apache sites, but this separation may help you associate sites with Nginx.</p>\n\n<p>As you did with Apache&rsquo;s virtual hosts, create <code>index</code> and <code>phpinfo()</code> files for testing after setup is complete:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"&lt;h1 style='color: green;'&gt;Nginx 1&lt;/h1&gt;\" | sudo tee /usr/share/nginx/nginx1.<span class=\"highlight\">your_domain</span>/index.html\n</li><li class=\"line\" data-prefix=\"$\">echo \"&lt;h1 style='color: red;'&gt;Nginx 2&lt;/h1&gt;\" | sudo tee /usr/share/nginx/nginx2.<span class=\"highlight\">your_domain</span>/index.html\n</li><li class=\"line\" data-prefix=\"$\">echo \"&lt;?php phpinfo(); ?&gt;\" | sudo tee /usr/share/nginx/nginx1.<span class=\"highlight\">your_domain</span>/info.php\n</li><li class=\"line\" data-prefix=\"$\">echo \"&lt;?php phpinfo(); ?&gt;\" | sudo tee /usr/share/nginx/nginx2.<span class=\"highlight\">your_domain</span>/info.php\n</li></ul></code></pre>\n<p>Now create a virtual host file for the domain <code>nginx1.<span class=\"highlight\">your_domain</span></code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/nginx1.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Nginx calls <code>server {. . .}</code> areas of a configuration file <strong>server blocks</strong>. Create a server block for the primary virtual host, <code>nginx1.<span class=\"highlight\">your_domain</span></code>. The <code>default_server</code> configuration directive makes this the default virtual host which processes HTTP requests which do not match any other virtual host.</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/nginx1.&lt;span class=\" highlight>your_domain&rsquo;&gt;/etc/nginx/sites-available/nginx1.<span class=\"highlight\">your_domain</span></div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80 default_server;\n\n    root /usr/share/nginx/nginx1.<span class=\"highlight\">your_domain</span>;\n    index index.php index.html index.htm;\n\n    server_name nginx1.<span class=\"highlight\">your_domain</span> www.nginx1.<span class=\"highlight\">your_domain</span>;\n    location / {\n        try_files $uri $uri/ /index.php;\n    }\n\n    location ~ \\.php$ {\n        fastcgi_pass unix:/run/php/php7.4-fpm.sock;\n        include snippets/fastcgi-php.conf;\n    }\n}\n</code></pre>\n<p>Save and close the file. Now create a virtual host file for Nginx&rsquo;s second domain, <code>nginx2.<span class=\"highlight\">your_domain</span></code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/nginx2.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Add the following to the file:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/nginx2.&lt;span class=\" highlight>your_domain&rsquo;&gt;/etc/nginx/sites-available/nginx2.<span class=\"highlight\">your_domain</span></div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    root /usr/share/nginx/nginx2.<span class=\"highlight\">your_domain</span>;\n    index index.php index.html index.htm;\n\n    server_name nginx2.<span class=\"highlight\">your_domain</span> www.nginx2.<span class=\"highlight\">your_domain</span>;\n    location / {\n        try_files $uri $uri/ /index.php;\n    }\n\n    location ~ \\.php$ {\n        fastcgi_pass unix:/run/php/php7.4-fpm.sock;\n        include snippets/fastcgi-php.conf;\n    }\n}\n</code></pre>\n<p>Save and close the file.</p>\n\n<p>Enable both sites by creating symbolic links to the <code>sites-enabled</code> directory:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/nginx1.<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/nginx1.<span class=\"highlight\">your_domain</span>\n</li><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/nginx2.<span class=\"highlight\">your_domain</span> /etc/nginx/sites-enabled/nginx2.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Test the Nginx configuration to ensure there are no configuration issues:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Then reload Nginx if there are no errors:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Now access the <code>phpinfo()</code> file for both Nginx virtual hosts in a web browser by visiting <a href=\"http://nginx1\">http://nginx1</a>.<span class=\"highlight\">your<em>domain</em></span>/info.php and <a href=\"http://nginx2\">http://nginx2</a>.<span class=\"highlight\">yourdomain</span>/info.php. Look under the PHP Variables sections again.</p>\n\n<p><strong>[&ldquo;SERVER_SOFTWARE&rdquo;]</strong> should say <code>nginx</code>, indicating that the files were directly served by Nginx. <strong>[&ldquo;DOCUMENT_ROOT&rdquo;]</strong> should point to the directory you created earlier in this step for each Nginx site.</p>\n\n<p>At this point, we have installed Nginx and created two virtual hosts. Next we will configure Nginx to proxy requests meant for domains hosted on Apache.</p>\n\n<h2 id=\"step-7-—-configuring-nginx-for-apache-39-s-virtual-hosts\">Step 7 — Configuring Nginx for Apache&rsquo;s Virtual Hosts</h2>\n\n<p>Let&rsquo;s create an additional Nginx virtual host with multiple domain names in the <code>server_name</code> directives. Requests for these domain names will be proxied to Apache.</p>\n\n<p>Create a new Nginx virtual host file to forward requests to Apache:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/apache\n</li></ul></code></pre>\n<p>Add the following code block; it specifies the names of both Apache virtual host domains and proxies their requests to Apache. Remember to use the public IP address in <code>proxy_pass</code>:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/apache\">/etc/nginx/sites-available/apache</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n    server_name apache1.<span class=\"highlight\">your_domain</span> www.apache1.<span class=\"highlight\">your_domain</span> apache2.<span class=\"highlight\">your_domain</span> www.apache2.<span class=\"highlight\">your_domain</span>;\n\n    location / {\n        proxy_pass http://<span class=\"highlight\">your_server_ip</span>:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>\n<p>Save the file and enable this new virtual host by creating a symbolic link:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ln -s /etc/nginx/sites-available/apache /etc/nginx/sites-enabled/apache\n</li></ul></code></pre>\n<p>Test the configuration to ensure there are no errors:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>If there are no errors, reload Nginx:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload nginx\n</li></ul></code></pre>\n<p>Open the browser and access the URL <code>http://apache1.<span class=\"highlight\">your_domain</span>/info.php</code> in your browser. Scroll down to the <strong>PHP Variables</strong> section and check the values displayed.</p>\n\n<p>The variables <strong>SERVER_SOFTWARE</strong> and <strong>DOCUMENT_ROOT</strong> confirm that this request was handled by Apache. The variables <strong>HTTP<em>X</em>REAL_IP</strong> and <strong>HTTP<em>X</em>FORWARDED_FOR</strong> were added by Nginx and should show the public IP address of the computer you&rsquo;re using to access the URL (if you accessed Apache directly on port <code>8080</code> you would not see these variables).</p>\n\n<p>We have successfully set up Nginx to proxy requests for specific domains to Apache. Next, let&rsquo;s configure Apache to set the <code>REMOTE_ADDR</code> variable as if it were handling these requests directly.</p>\n\n<h2 id=\"step-8-—-installing-and-configuring-mod_rpaf\">Step 8 — Installing and Configuring <code>mod_rpaf</code></h2>\n\n<p>In this step you&rsquo;ll install an Apache module called <code>mod_rpaf</code> which rewrites the values of <strong>REMOTE_ADDR</strong>, <strong>HTTPS</strong> and <strong>HTTP_PORT</strong> based on the values provided by a reverse proxy. Without this module, some PHP applications would require code changes to work seamlessly from behind a proxy. This module is present in Ubuntu&rsquo;s repository as <code>libapache2-mod-rpaf</code> but it is outdated and doesn&rsquo;t support certain configuration directives. Instead, we will install it from source.</p>\n\n<p>Move to your home directory and install the packages needed to build the module:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install unzip build-essential apache2-dev\n</li></ul></code></pre>\n<p>Download the latest stable release from GitHub:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://github.com/gnif/mod_rpaf/archive/stable.zip\n</li></ul></code></pre>\n<p>Extract the downloaded file:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">unzip stable.zip\n</li></ul></code></pre>\n<p>Change into the new directory containing the files:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd mod_rpaf-stable\n</li></ul></code></pre>\n<p>Compile and install the module:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">make\n</li><li class=\"line\" data-prefix=\"$\">sudo make install\n</li></ul></code></pre>\n<p>Next, create a file in the <code>mods-available</code> directory that will load the <code>rpaf</code> module:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/apache2/mods-available/rpaf.load\n</li></ul></code></pre>\n<p>Add the following code to the file to load the module:</p>\n<div class=\"code-label \" title=\"/etc/apache2/mods-available/rpaf.load\">/etc/apache2/mods-available/rpaf.load</div><pre class=\"code-pre apache\"><code>LoadModule rpaf_module /usr/lib/apache2/modules/mod_rpaf.so\n</code></pre>\n<p>Save the file and exit the editor.</p>\n\n<p>Create another file in this directory called <code>rpaf.conf</code> that will contain the configuration directives for <code>mod_rpaf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/apache2/mods-available/rpaf.conf\n</li></ul></code></pre>\n<p>Add the following code block to configure <code>mod_rpaf</code>, making sure to specify the IP address of your server:</p>\n<div class=\"code-label \" title=\"/etc/apache2/mods-available/rpaf.conf\">/etc/apache2/mods-available/rpaf.conf</div><pre class=\"code-pre apache\"><code>    &lt;IfModule mod_rpaf.c&gt;\n        RPAF_Enable             On\n        RPAF_Header             X-Real-Ip\n        RPAF_ProxyIPs           <span class=\"highlight\">your_server_ip</span> \n        RPAF_SetHostName        On\n        RPAF_SetHTTPS           On\n        RPAF_SetPort            On\n    &lt;/IfModule&gt;\n</code></pre>\n<p>Here&rsquo;s a brief description of each directive. See the <code>mod_rpaf</code> <a href=\"https://github.com/gnif/mod_rpaf/blob/stable/README.md#configuration-directives\">README</a> file for more information.</p>\n\n<ul>\n<li><strong>RPAF_Header</strong> - The header to use for the client&rsquo;s real IP address.</li>\n<li><strong>RPAF_ProxyIPs</strong> - The proxy IP to adjust HTTP requests for.</li>\n<li><strong>RPAF_SetHostName</strong> - Updates the vhost name so <code>ServerName</code> and <code>ServerAlias</code> work.</li>\n<li><strong>RPAF_SetHTTPS</strong> - Sets the <code>HTTPS</code> environment variable based on the value contained in <code>X-Forwarded-Proto</code>.</li>\n<li><strong>RPAF_SetPort</strong> - Sets the <code>SERVER_PORT</code> environment variable. Useful for when Apache is behind a SSL proxy.</li>\n</ul>\n\n<p>Save <code>rpaf.conf</code> and enable the module:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo a2enmod rpaf\n</li></ul></code></pre>\n<p>This creates symbolic links of the files <code>rpaf.load</code> and <code>rpaf.conf</code> in the <code>mods-enabled</code> directory. Now do a configuration test:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apachectl -t\n</li></ul></code></pre>\n<p>Reload Apache if there are no errors:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl reload apache2\n</li></ul></code></pre>\n<p>Access the <code>phpinfo()</code> pages <code>http://apache1.<span class=\"highlight\">your_domain</span>/info.php</code> and <code>http://apache2.<span class=\"highlight\">your_domain</span>/info.php</code> in your browser and check the <strong>PHP Variables</strong> section. The <strong>REMOTE_ADDR</strong> variable will now also be that of your local computer&rsquo;s public IP address.</p>\n\n<p>Now let&rsquo;s set up TLS/SSL encryption for each site.</p>\n\n<h2 id=\"step-9-—-setting-up-https-websites-with-let-39-s-encrypt-optional\">Step 9 — Setting Up HTTPS Websites with Let&rsquo;s Encrypt (Optional)</h2>\n\n<p>In this step we will configure TLS/SSL certificates for both the domains hosted on Apache.  We&rsquo;ll obtain the certificates through [Let&rsquo;s Encrypt](<a href=\"https://letsencrypt.org\">https://letsencrypt.org</a>]. Nginx supports SSL termination so we can set up SSL without modifying Apache&rsquo;s configuration files. The <code>mod_rpaf</code> module ensures that the required environment variables are set on Apache to make applications work seamlessly behind a SSL reverse proxy.</p>\n\n<p>First we will separate the <code>server {...}</code> blocks of both the domains so that each of them can have their own SSL certificates.  Open the file <code>/etc/nginx/sites-available/apache</code> in your editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/apache\n</li></ul></code></pre>\n<p>Modify the file so that it looks like this, with <code>apache1.<span class=\"highlight\">your_domain</span></code> and <code>apache2.<span class=\"highlight\">your_domain</span></code> in their own <code>server</code> blocks:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/apache\">/etc/nginx/sites-available/apache</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">    server {\n        listen 80;\n        server_name apache1.<span class=\"highlight\">your_domain</span> www.apache1.<span class=\"highlight\">your_domain</span>;\n\n        location / {\n            proxy_pass http://<span class=\"highlight\">your_server_ip</span>:8080;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n    server {\n        listen 80;\n        server_name apache2.<span class=\"highlight\">your_domain</span> www.apache2.<span class=\"highlight\">your_domain</span>;\n\n        location / {\n            proxy_pass http://<span class=\"highlight\">your_server_ip</span>:8080;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n</code></pre>\n<p>We&rsquo;ll use <a href=\"https://certbot.eff.org\">Certbot</a> to generate our TLS/SSL certificates. Its Nginx plugin will take care of reconfiguring Nginx and reloading the config whenever necessary. </p>\n\n<p>Install <code>certbot</code> using snapd</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo snap install --classic certbot\n</li></ul></code></pre>\n<p>Once it&rsquo;s installed, use the  <code>certbot</code> command to generate the certificates for <code>apache1.<span class=\"highlight\">your_domain</span></code> and <code>www.apache1.<span class=\"highlight\">your_domain</span></code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot --agree-tos --no-eff-email --email <span class=\"highlight\">your-email</span> --nginx -d apache1.<span class=\"highlight\">your_domain</span> -d www.apache1.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>This command tells Certbot to use the <code>nginx</code> plugin, using <code>-d</code> to specify the names we&rsquo;d like the certificate to be valid for.</p>\n\n<p>Now execute the command for the second domain:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot --agree-tos --no-eff-email --email <span class=\"highlight\">your-email</span> --nginx -d <span class=\"highlight\">your_domain</span> -d www.apache2.<span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Access one of Apache&rsquo;s domains in your browser using the <code>https://</code> prefix; visit <code>https://apache1.<span class=\"highlight\">your_domain</span>/info.php</code> or <code>https://apache2.<span class=\"highlight\">your_domain</span>/info.php</code>.</p>\n\n<p>Look in the <strong>PHP Variables</strong> section. The variable <strong>SERVER_PORT</strong> has been set to <strong>443</strong> and <strong>HTTPS</strong> set to <strong>on</strong>, as though Apache was directly accessed over HTTPS. With these variables set, PHP applications do not have to be specially configured to work behind a reverse proxy.</p>\n\n<p>Now let&rsquo;s disable direct access to Apache.</p>\n\n<h2 id=\"step-10-—-blocking-direct-access-to-apache-optional\">Step 10 — Blocking Direct Access to Apache (Optional)</h2>\n\n<p>Since Apache is listening on port <code>8080</code> on the public IP address, it is accessible by everyone. It can be blocked by working the following IPtables command into your firewall rule set.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo iptables -I INPUT -p tcp --dport 8080 ! -s <span class=\"highlight\">your_server_ip</span> -j REJECT --reject-with tcp-reset\n</li></ul></code></pre>\n<p>Be sure to use your server&rsquo;s IP address in place of the highlighted example. Once port <code>8080</code> is blocked in your firewall, test that Apache is unreachable on it. Open your web browser and try accessing one of Apache&rsquo;s domain names on port <code>8080</code>. For example: <a href=\"http://apache1\">http://apache1</a>.<span class=\"highlight\">your_domain</span>:8080</p>\n\n<p>The browser should display an &ldquo;Unable to connect&rdquo; or &ldquo;Webpage is not available&rdquo; error message. With the IPtables <code>tcp-reset</code> option in place, an outsider would see no difference between port <code>8080</code> and a port that doesn&rsquo;t have any service on it.</p>\n\n<p><span class='note'><strong>Note:</strong> IPtables rules do not survive a system reboot by default. There are multiple ways to preserve IPtables rules, but the easiest is to use <code>iptables-persistent</code> in Ubuntu&rsquo;s repository. Explore <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04\">this article</a> to learn more about how to configure IPTables.<br></span></p>\n\n<p>Now let&rsquo;s configure Nginx to serve static files for the Apache sites.</p>\n\n<h2 id=\"step-11-—-serving-static-files-using-nginx-optional\">Step 11 — Serving Static Files Using Nginx (Optional)</h2>\n\n<p>When Nginx proxies requests for Apache&rsquo;s domains, it sends every file request for that domain to Apache. Nginx is faster than Apache at serving static files like images, JavaScript and style sheets. So let&rsquo;s configure Nginx&rsquo;s <code>apache</code> virtual host file to directly serve static files but send PHP requests on to Apache.</p>\n\n<p>Open the file <code>/etc/nginx/sites-available/apache</code> in your editor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/nginx/sites-available/apache\n</li></ul></code></pre>\n<p>You&rsquo;ll need to add two additional <code>location</code> blocks to each server block, as well as modify the existing <code>location</code> sections.  Additionally, you&rsquo;ll need to tell Nginx where to find the static files for each site.  </p>\n\n<p>If you&rsquo;ve decided not to use SSL and TLS certificates, modify your file so it looks like this:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/apache\">/etc/nginx/sites-available/apache</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n    server_name apache2.<span class=\"highlight\">your_domain</span> www.apache2.<span class=\"highlight\">your_domain</span>;\n    <span class=\"highlight\">root /var/www/your_domain;</span>\n    <span class=\"highlight\">index index.php index.htm index.html;</span>\n\n    <span class=\"highlight\">location / {</span>\n        <span class=\"highlight\">try_files $uri $uri/ /index.php;</span>\n    <span class=\"highlight\">}</span>\n\n    <span class=\"highlight\">location ~ \\.php$ {</span>\n        proxy_pass http://<span class=\"highlight\">your_server_ip</span>:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    <span class=\"highlight\">location ~ /\\.ht {</span>\n        <span class=\"highlight\">deny all;</span>\n    <span class=\"highlight\">}</span>\n}\n\nserver {\n    listen 80;\n    server_name apache1.<span class=\"highlight\">your_domain</span> www.apache1.<span class=\"highlight\">your_domain</span>;\n    <span class=\"highlight\">root /var/www/your_domain;</span>\n    <span class=\"highlight\">index index.php index.htm index.html;</span>\n\n    <span class=\"highlight\">location / {</span>\n        <span class=\"highlight\">try_files $uri $uri/ /index.php;</span>\n    <span class=\"highlight\">}</span>\n\n    <span class=\"highlight\">location ~ \\.php$ {</span>\n        proxy_pass http://<span class=\"highlight\">your_ip_address</span>:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    <span class=\"highlight\">location ~ /\\.ht {</span>\n        <span class=\"highlight\">deny all;</span>\n    <span class=\"highlight\">}</span>\n}\n</code></pre>\n<p>If you also want HTTPS to be available, use the following configuration instead:</p>\n<div class=\"code-label \" title=\"/etc/nginx/sites-available/apache\">/etc/nginx/sites-available/apache</div><pre class=\"code-pre \"><code class=\"code-highlight language-nginx\">server {\n    listen 80;\n    server_name apache2.<span class=\"highlight\">your_domain</span> www.apache2.<span class=\"highlight\">your_domain</span>;\n    <span class=\"highlight\">root /var/www/your_domain;</span>\n    <span class=\"highlight\">index index.php index.htm index.html;</span>\n\n    <span class=\"highlight\">location / {</span>\n        <span class=\"highlight\">try_files $uri $uri/ /index.php;</span>\n    <span class=\"highlight\">}</span>\n\n    <span class=\"highlight\">location ~ \\.php$ {</span>\n        proxy_pass http://<span class=\"highlight\">your_server_ip</span>:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    <span class=\"highlight\">location ~ /\\.ht {</span>\n        <span class=\"highlight\">deny all;</span>\n    <span class=\"highlight\">}</span>\n\n    listen 443 ssl;\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n}\n\nserver {\n    listen 80;\n    server_name apache1.<span class=\"highlight\">your_domain</span> www.apache1.<span class=\"highlight\">your_domain</span>;\n    <span class=\"highlight\">root /var/www/your_domain;</span>\n    <span class=\"highlight\">index index.php index.htm index.html;</span>\n\n    <span class=\"highlight\">location / {</span>\n        <span class=\"highlight\">try_files $uri $uri/ /index.php;</span>\n    <span class=\"highlight\">}</span>\n\n    <span class=\"highlight\">location ~ \\.php$ {</span>\n        proxy_pass http://<span class=\"highlight\">your_ip_address</span>:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    <span class=\"highlight\">location ~ /\\.ht {</span>\n        <span class=\"highlight\">deny all;</span>\n    <span class=\"highlight\">}</span>\n\n    listen 443 ssl;\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n}\n</code></pre>\n<p>The <code>try_files</code> directive makes Nginx look for files in the document root and directly serve them. If the file has a <code>.php</code> extension, the request is passed to Apache. Even if the file is not found in the document root, the request is passed on to Apache so that application features like permalinks work without problems.</p>\n\n<p><span class='warning'><strong>Warning:</strong> The <code>location ~ /\\.ht</code> directive is very important; this prevents Nginx from serving the contents of Apache configuration files like <code>.htaccess</code> and <code>.htpasswd</code>, which contain sensitive information.<br></span></p>\n\n<p>Save the file and perform a configuration test:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nginx -t\n</li></ul></code></pre>\n<p>Reload Nginx if the test succeeds:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo service nginx reload\n</li></ul></code></pre>\n<p>To verify things are working, you can examine Apache&rsquo;s log files in <code>/var/log/apache2</code> and see the <code>GET</code> requests for the <code>info.php</code> files of <code>apache2.<span class=\"highlight\">your_domain</span></code> and <code>apache1.<span class=\"highlight\">your_domain</span></code>. Use the <code>tail</code> command to see the last few lines of the file, and use the <code>-f</code> switch to watch the file for changes:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo tail -f /var/log/apache2/other_vhosts_access.log\n</li></ul></code></pre>\n<p>Now visit <code>apache1.<span class=\"highlight\">your_domain</span>/info.php</code> or <code>apache2.<span class=\"highlight\">your_domain</span>/info.php</code> in your browser and then look at the output from the log. You&rsquo;ll see that Apache is indeed replying (your port will be <code>80</code> or <code>443</code> depending on whether or not you secured the instance):</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>    apache2.<span class=\"highlight\">your_domain</span>:<span class=\"highlight\">80</span> <span class=\"highlight\">your_server_ip</span> - - [27/Aug/2020:18:18:34 -0400] \"GET /info.php HTTP/1.0\" 200 20414 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\"\n</code></pre>\n<p>Then visit the <code>index.html</code> page for each site and you won&rsquo;t see any log entries from Apache. Nginx is serving them.</p>\n\n<p>When you&rsquo;re done observing the log file, press <code>CTRL+C</code> to stop tailing it.</p>\n\n<p>With this setup, Apache will not be able to restrict access to static files. Access control for static files would need to be configured in Nginx&rsquo;s <code>apache</code> virtual host file, but that&rsquo;s beyond the scope of this tutorial.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>You now have one Ubuntu server with Nginx serving <code>nginx1.<span class=\"highlight\">your_domain</span></code> and <code>nginx2.<span class=\"highlight\">your_domain</span></code>, along with Apache serving <code>apache1.<span class=\"highlight\">your_domain</span></code> and <code>apache2.<span class=\"highlight\">your_domain</span></code>. Though Nginx is acting as a reverse-proxy for Apache, Nginx&rsquo;s proxy service is transparent and connections to Apache&rsquo;s domains appear be served directly from Apache itself. You can use this method to serve secure and static sites.</p>\n","descriptionType":"html","publishedDate":"Thu, 27 Aug 2020 21:08:59 +0000","feedId":8037,"bgimg":"https://i.imgur.com/zLWcC3K.png","linkMd5":"dc56a320945f49e3f91d7c24367ad646","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn73@2020_1/2020/08/31/07-48-27-261_a8d55c22a165f6e1.webp","destWidth":933,"destHeight":164,"sourceBytes":14270,"destBytes":12666,"author":"Jesin A","articleImgCdnMap":{"https://i.imgur.com/zLWcC3K.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn73@2020_1/2020/08/31/07-48-27-261_a8d55c22a165f6e1.webp","https://i.imgur.com/JuyXP5S.png":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn17@2020_5/2020/08/31/07-48-32-251_ef112f77d043b8e8.webp","https://assets.digitalocean.com/articles/67458/apache1.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn90@2020_2/2020/08/31/07-48-31-893_31961f9420ae2ad2.webp","https://assets.digitalocean.com/articles/67458/apache2.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn21@2020_1/2020/08/31/07-48-32-339_5a289d8d38244e27.webp"},"publishedOrCreatedDate":1598860106963},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Einrichten eines IKEv2-VPN-Servers mit StrongSwan unter Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-set-up-an-ikev2-vpn-server-with-strongswan-on-ubuntu-20-04-de","description":"<p><em>Eine frühere Version dieses Tutorials wurde von <a href=\"https://www.digitalocean.com/community/users/jellingwood\">Justin Ellingwood</a> und <a href=\"https://www.digitalocean.com/community/users/namo\">Namo</a> verfasst</em></p>\n\n<h3 id=\"einführung\">Einführung</h3>\n\n<p>Ein virtuelles privates Netzwerk oder VPN ermöglicht Ihnen die sichere Verschlüsselung des Datenverkehrs auf dem Weg durch nicht vertrauenswürdige Netzwerke, wie z. B. im Café, bei einer Konferenz oder auf einem Flughafen.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Internet_Key_Exchange\">Internet Key Exchange v2</a> oder IKEv2 ist ein Protokoll, das ein direktes IPSec-Tunneling zwischen Server und Client ermöglicht. In IKEv2-VPN-Implementierungen bietet IPSec eine Verschlüsselung für den Netzwerkverkehr. IKEv2 wird auf einigen Plattformen (OS X 10.11+, iOS 9.1+ und Windows 10) nativ unterstützt, ohne dass zusätzliche Anwendungen erforderlich sind und Client-Hickups werden reibungslos verwaltet.</p>\n\n<p>In diesem Tutorial richten Sie einen IKEv2-VPN-Server mit <a href=\"https://www.strongswan.org/\">StrongSwan</a> auf einem Ubuntu-20.04-Server ein. Anschließend lernen Sie, wie mit Windows-, macOS-, Ubuntu-, iOS- und Android-Clients eine Verbindung zu diesem Server herstellen können.</p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Um diesem Tutorial zu folgen, benötigen Sie:</p>\n\n<ul>\n<li>Einen Ubuntu 20.04-Server, der gemäß des <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Leitfadens zur Ersteinrichtung des Servers für Ubuntu 20.04</a> konfiguriert wurde, einschließlich eines Nicht-Root-Benutzer mit <code>sudo</code>-Berechtigungen und einer Firewall.</li>\n</ul>\n\n<h2 id=\"schritt-1-—-installieren-von-strongswan\">Schritt 1 — Installieren von StrongSwan</h2>\n\n<p>Zuerst installieren wir StrongSwan, einen Open-Source-IPSec-Daemon, den wir als unseren VPN-Server konfigurieren werden. Außerdem installieren wir die Komponente „Public Key Infrastructure“ (PKI), sodass wir eine Zertifizierungsstelle (Certificate Authority, CA) erstellen können, die die Anmeldedaten für unsere Infrastruktur bereitstellt.</p>\n\n<p>Beginnen Sie mit der Aktualisierung des lokalen Paket-Caches:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Installieren Sie dann die Software durch folgende Eingabe:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan strongswan-pki libcharon-extra-plugins libcharon-extauth-plugins\n</li></ul></code></pre>\n<p>Das zusätzliche Paket <code>libcharon-extauth-plugins</code> wird verwendet, um sicherzustellen, dass verschiedene Clients sich bei Ihrem Server mit einem gemeinsamen Benutzernamen und einer gemeinsamen Passphrase authentifizieren können.</p>\n\n<p>Nachdem nun alles installiert ist, fahren wir mit der Erstellung unserer Zertifikate fort.</p>\n\n<h2 id=\"schritt-2-—-erstellen-einer-zertifizierungsstelle\">Schritt 2 — Erstellen einer Zertifizierungsstelle</h2>\n\n<p>Ein IKEv2-Server erfordert ein Zertifikat, um sich gegenüber Clients zu identifizieren. Um bei der Erstellung des erforderlichen Zertifikats zu helfen, enthält das Paket <code>strongswan-pki</code> ein Dienstprogramm namens <code>pki</code> zur Generierung einer Zertifizierungsstelle und von Serverzertifikaten.</p>\n\n<p>Zu Beginn erstellen wir einige Verzeichnisse zum Speichern aller Assets, an denen wir arbeiten möchten. Die Verzeichnisstruktur entspricht einigen der Verzeichnisse in <code>/etc/ipsec.d</code>, wohin wir schließlich alle von uns erstellten Objekte verschieben werden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir -p ~/pki/{cacerts,certs,private}\n</li></ul></code></pre>\n<p>Dann sperren wir die Berechtigungen, sodass unsere privaten Dateien von anderen Benutzern nicht gesehen werden können:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod 700 ~/pki\n</li></ul></code></pre>\n<p>Nachdem wir nun über eine Verzeichnisstruktur verfügen, um alles zu speichern, können wir einen Stammschlüssel generieren. Dies wird ein 4096-Bit-RSA-Schlüssel sein, der zum Signieren unserer Stammzertifizierungsstelle verwendet wird.</p>\n\n<p>Führen Sie diese Befehle zur Generierung des Schlüssels aus:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/ca-key.pem\n</li></ul></code></pre>\n<p>Danach können wir zur Erstellung unserer Stammzertifizierungsstelle übergehen und den gerade generierten Schlüssel zum Signieren des Stammzertifikats verwenden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --self --ca --lifetime 3650 --in ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">    --type rsa --dn \"CN=VPN root CA\" --outform pem &gt; ~/pki/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Das Flag <code>--lifetime 3650</code> wird verwendet, um sicherzustellen, dass das Stammzertifikat der Zertifizierungsstelle für 10 Jahre gültig ist. Das Stammzertifikat einer Stelle ändert sich in der Regel nicht, da es an alle Server und Clients, die darauf angewiesen sind, neu verteilt werden müsste. 10 Jahre ist als ein sicherer Standardwert für die Gültigkeitsdauer.</p>\n\n<p>Sie können den Wert für den <em>unterscheidenden Namen</em> (Distinguished name, DN) in etwas anderes ändern, wenn Sie möchten. Der gewöhnliche Name (Common Name) (CN-Feld) ist hier nur der Indikator, sodass er mit nichts in Ihrer Infrastruktur übereinstimmen muss.</p>\n\n<p>Nachdem wir nun unsere Stammzertifizierungsstelle eingerichtet haben, können wir ein Zertifikat erstellen, das der VPN-Server verwenden wird.</p>\n\n<h2 id=\"schritt-3-—-erstellen-eines-zertifikats-für-den-vpn-server\">Schritt 3 — Erstellen eines Zertifikats für den VPN-Server</h2>\n\n<p>Wir erstellen nun ein Zertifikat und einen Schlüssel für den VPN-Server. Dieses Zertifikat ermöglicht es dem Client, die Authentifizierung des Servers mit dem gerade generierten CA-Zertifikat zu überprüfen.</p>\n\n<p>Erstellen Sie zunächst einen privaten Schlüssel für den VPN-Server mit dem folgenden Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --gen --type rsa --size 4096 --outform pem &gt; ~/pki/private/server-key.pem\n</li></ul></code></pre>\n<p>Erstellen und signieren Sie nun das VPN-Serverzertifikat mit dem Schlüssel der Zertifizierungsstelle, den Sie im vorherigen Schritt erstellt haben. Führen Sie den folgenden Befehl aus, ändern Sie jedoch den Common Name (CN) und das Feld Subject Alternate Name (SAN) in den DNS-Namen oder die IP-Adresse Ihres VPN-Servers:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pki --pub --in ~/pki/private/server-key.pem --type rsa \\\n</li><li class=\"line\" data-prefix=\"$\">    | pki --issue --lifetime 1825 \\\n</li><li class=\"line\" data-prefix=\"$\">        --cacert ~/pki/cacerts/ca-cert.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --cakey ~/pki/private/ca-key.pem \\\n</li><li class=\"line\" data-prefix=\"$\">        --dn \"CN=<span class=\"highlight\">server_domain_or_IP</span>\" --san <span class=\"highlight\">server_domain_or_IP</span> \\\n</li><li class=\"line\" data-prefix=\"$\">        --flag serverAuth --flag ikeIntermediate --outform pem \\\n</li><li class=\"line\" data-prefix=\"$\">    &gt;  ~/pki/certs/server-cert.pem\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Anmerkung</strong>: Wenn Sie anstelle eines DNS-Namens eine IP-Adresse verwenden, müssen mehrere <code>--san</code> Einträge angegeben werden. Die Zeile im vorherigen Befehlsblock, in dem Sie den Distinguished Name (<code>--dn ...</code>) angeben, muss mit dem zusätzlichen Eintrag wie die folgende Auszugszeile modifiziert werden:</p>\n<pre class=\"code-pre \"><code>--dn \"CN=<span class=\"highlight\">IP address</span> --san @<span class=\"highlight\">IP_address</span> --san <span class=\"highlight\">IP_address</span> \\\n</code></pre>\n<p>Der Grund für diesen zusätzlichen Eintrag <code>--san @<span class=\"highlight\">IP_address</span></code> ist, dass einige Clients prüfen, ob das TLS-Zertifikat sowohl über einen DNS-Eintrag als auch einen IP-Adressen-Eintrag für einen Server verfügt, wenn sie seine Identität überprüfen.<br></p></span>\n\n<p>Die Option -<code>--flag serverAuth</code> wird verwendet, um anzugeben, dass das Zertifikat explizit für die Serverauthentifizierung verwendet wird, bevor der verschlüsselte Tunnel hergestellt wird. Die Option <code>--flag ikeIntermediate</code> wird zur Unterstützung älterere MacOS-Clients verwendet.</p>\n\n<p>Nachdem wir nun alle TLS/SSL-Dateien erzeugt haben, die StrongSwan benötigt, können wir die Dateien in das Verzeichnis <code>/etc/ipsec.d</code> verschieben, indem wir Folgendes eingeben:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp -r ~/pki/* /etc/ipsec.d/\n</li></ul></code></pre>\n<p>In diesem Schritt haben wir ein Zertifikatpaar erstellt, das zur Sicherung der Kommunikation zwischen dem Client und dem Server verwendet wird. Wir haben die Zertifikate auch mit dem CA-Schlüssel signiert, sodass der Client die Authentifizierung des VPN-Servers mit dem CA-Zertifikat überprüfen kann. Nachdem nun alle diese Zertifikate fertig sind, gehen wir zur Konfiguration der Software über.</p>\n\n<h2 id=\"schritt-4-—-konfigurieren-von-strongswan\">Schritt 4 — Konfigurieren von StrongSwan</h2>\n\n<p>StrongSwan hat eine Standardkonfigurationsdatei mit einigen Beispielen, aber wir werden die Konfiguration größtenteils selbst vornehmen müssen. Lassen Sie uns die Datei als Referenz sichern, bevor wir von Grund auf starten:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mv /etc/ipsec.conf{,.original}\n</li></ul></code></pre>\n<p>Erstellen und öffnen Sie eine neue leere Konfigurationsdatei mit Ihrem bevorzugten Texteditor. Wir verwenden hier <code>nano</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Anmerkung</strong>: Während Sie diesen Abschnitt zur Konfiguration des Serverteils Ihres VPNs durcharbeiten, werden Sie auf Einstellungen stoßen, die sich auf die <em>linke</em> und die <em>rechte</em> Seite einer Verbindung beziehen. Bei der Arbeit mit IPSec bezieht sich die <em>linke</em> Seite per Konvention auf das lokale System, das Sie konfigurieren, in diesem Fall den Server. Die Anweisungen der rechten Seite in diesen Einstellungen beziehen sich auf entfernte Clients wie Telefone und andere Computer.</p>\n\n<p>Wenn Sie später in diesem Tutorial mit der Konfiguration von Clients fortfahren, beziehen sich die Client-Konfigurationsdateien mit verschiedenen <em>linken</em> Anweisungen auf sich selbst, und der Server wird mit der Terminologie der <em>rechten</em> Seite bezeichnet.<br></p></span>\n\n<p>Zuerst weisen wir StrongSwan an, den Daemon-Status zur Fehlersuche zu protokollieren und doppelte Verbindungen zulassen. Fügen Sie der Datei diese Zeilen hinzu:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n</code></pre>\n<p>Dann erstellen wir einen Konfigurationsabschnitt für unser VPN. Außerdem weisen wir StrongSwan an, IKEv2 VPN-Tunnel zu erstellen und diesen Konfigurationsabschnitt automatisch beim Starten zu laden. Fügen Sie der Datei folgende Zeilen an:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n</code></pre>\n<p>Wir konfigurieren ebenfalls die Dead-Peer-Erkennung, um alle „unreferenzierten“ Verbindungen zu löschen, falls der Client die Verbindung unerwartet trennt. Fügen Sie diese Zeilen hinzu:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n</code></pre>\n<p>Als Nächstes konfigurieren wir die IPSec-Parameter der „linken“ Seite des Servers. Jede der folgenden Parameter stellt sicher, dass der Server für die Annahme von Verbindungen von Clients und für seine korrekte Identifizierung konfiguriert ist. Sie fügen jede dieser Einstellungen der Datei <code>/etc/ipsec.conf</code> hinzu, sobald Sie sich damit vertraut gemacht haben, was sie sind und warum sie verwendet werden:</p>\n\n<ul>\n<li><code>left =%any</code> Der Wert <code>%any</code> stellt sicher, dass der Server die Netzwerkschnittstelle, an der er eingehende Verbindungen empfängt, für die nachfolgende Kommunikation mit Clients verwendet. Wenn Sie beispielsweise einen Client über ein privates Netzwerk verbinden, verwendet der Server für den Rest der Verbindung die private IP-Adresse, an der er den Datenverkehr empfängt.</li>\n<li><code>leftid=<span class=\"highlight\">@server_domain_or_IP</span></code> Diese Option steuert den Namen, den der Server den Clients präsentiert. In Kombination mit der nächsten Option <code>leftcert</code>, stellt die Option <code>leftid</code> sicher, dass der konfigurierte Name des Servers und der im öffentlichen Zertifikat enthaltene Dinstinguished Name (DN) übereinstimmen.</li>\n<li><code>leftcert=server-cert.pem</code> Diese Option ist der Pfad zum öffentlichen Zertifikat für den Server, den Sie in Schritt 3 konfiguriert haben. Ohne ihn kann sich der Server nicht bei Clients authentifizieren und die Aushandlung der IKEv2-Einrichtung nicht beenden.</li>\n<li><code>leftsendcert=always</code> Der <code>Wert</code> always stellt sicher, dass jeder Client, der sich mit dem Server verbindet, als Teil des anfänglichen Verbindungsaufbaus immer eine Kopie des öffentlichen Zertifikats des Servers erhält.</li>\n<li><code>leftsubnet=0.0.0.0/0</code> Die letzte Option der „linken“ Seite, die Sie hinzufügen werden, informiert Clients über die Subnetze, die hinter dem Server erreichbar sind. In diesem Fall wird <code>0.0.0.0/0</code> verwendet, um den gesamten Satz der IPv4-Adressen zu repräsentieren, was bedeutet, dass der Server Clients standardmäßig anweist, ihren gesamten Datenverkehr über das VPN zu senden.</li>\n</ul>\n\n<p>Nachdem Sie nun mit jeder der entsprechenden Optionen der „linken“ Seite vertraut sind, fügen Sie sie alle wie folgt zur Datei hinzu:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n</code></pre>\n<span class='note'><p>\n<strong>Anmerkung</strong>: Geben Sie bei der Konfiguration der Server-ID (<code>leftid</code>) das <code>@</code>-Zeichen nur dann an, wenn Ihr VPN-Server durch einen Domänennamen identifiziert werden soll:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .    leftid=<span class=\"highlight\">@vpn.example.com</span>\n    . . .\n</code></pre>\n<p>Wenn der Server durch seine IP-Adresse identifiziert werden soll, geben Sie einfach die IP-Adresse ein:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    . . .\n    leftid=<span class=\"highlight\">your_server_ip</span>\n    . . .\n</code></pre>\n<p></p></span>\n\n<p>Als Nächstes können wir die IPSec-Parameter der „rechten“ Seite des Clients konfigurieren. Jede der folgenden Parameter teilt dem Server mit, wie Verbindungen von Clients akzeptiert werden sollen, wie sich Clients beim Server authentifizieren sollen und welche privaten IP-Adressbereiche und DNS-Server diese Clients verwenden werden. Fügen Sie jede dieser Einstellungen der Datei <code>/etc/ipsec.conf</code> hinzu, sobald Sie sich damit vertraut gemacht haben, was sie sind und warum sie verwendet werden:</p>\n\n<ul>\n<li><code>right=%any</code> Die Option <code>%any</code> für die <code>rechte</code> Seite der Verbindung weist den Server an, eingehende Verbindungen von jedem Remote-Client anzunehmen.</li>\n<li><code>rightid=%any</code> Diese Option stellt sicher, dass der Server keine Verbindungen von Clients ablehnt, die eine Identität angeben, bevor der verschlüsselte Tunnel hergestellt ist.</li>\n<li><code>rightauth=eap-mschapv2</code> Diese Option konfiguriert die Authentifizierungsmethode, die Clients zur Authentifizierung gegenüber dem Server verwenden werden. <code>eap-mschapv2</code> wird hier für eine breite Kompatibilität verwendet, um Clients wie Windows-, MacOS- und Android-Geräte zu unterstützen.</li>\n<li><code>rightsourceip=10.10.10.0/24</code> Diese Option weist den Server an, Clients private IP-Adressen aus dem angegebenen IP-Pool <code>10.10.10.0/24</code> zuzuweisen.</li>\n<li><code>rightdns=8.8.8.8,8.8.4.4</code> Diese IP-Adressen sind die öffentlichen DNS-Auflöser von Google. Sie können geändert werden, um andere öffentliche Auflöser, die Auflösung des VPN-Servers oder einen anderen Auflöser zu verwenden, den die Clients erreichen können.</li>\n<li><code>rightsendcert=never</code> Diese Option weist den Server an, dass Clients kein Zertifikat senden müssen, um sich selbst zu authentifizieren.</li>\n</ul>\n\n<p>Nachdem Sie nun mit den erforderlichen Optionen der „rechten“ Seite vertraut sind, fügen Sie die folgenden Zeilen in <code>/etc/ipsec.conf</code> ein:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n</code></pre>\n<p>Nun werden wir StrongSwan anweisen, den Client beim Verbindungsaufbau nach den Anmeldedaten der Benutzer zu fragen:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    eap_identity=%identity\n</code></pre>\n<p>Zum Schluss fügen Sie die folgenden Zeilen hinzu, um Linux-, Windows-, macOS-, iOS- und Android-Clients zu unterstützen. Diese Zeilen spezifizieren die verschiedenen Schlüsselaustausch-, Hashing-, Authentifizierungs- und Verschlüsselungsalgorithmen (allgemein als <em>Cipher Suites</em> bezeichnet), die StrongSwan den verschiedenen Clients zur Verfügung stellt:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>. . .\nconn ikev2-vpn\n    . . .\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Jede unterstützte Cipher Suite wird durch ein Komma von den anderen abgegrenzt. Beispielsweise ist <code>chacha20poly1305-sha512-curve25519-prfsha512</code> eine Suite, und <code>aes256gcm16-sha384-prfsha384-ecp384</code> ist eine andere. Die hier aufgelisteten Cipher Suits sind so ausgewählt, dass sie die größtmögliche Kompatibilität zwischen Windows-, macOS-, iOS-, Android- und Linux-Clients gewährleisten.</p>\n\n<p>Die vollständige Konfigurationsdatei sollte wie folgt aussehen:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>config setup\n    charondebug=\"ike 1, knl 1, cfg 0\"\n    uniqueids=no\n\nconn ikev2-vpn\n    auto=add\n    compress=no\n    type=tunnel\n    keyexchange=ikev2\n    fragmentation=yes\n    forceencaps=yes\n    dpdaction=clear\n    dpddelay=300s\n    rekey=no\n    left=%any\n    leftid=<span class=\"highlight\">@server_domain_or_IP</span>\n    leftcert=server-cert.pem\n    leftsendcert=always\n    leftsubnet=0.0.0.0/0\n    right=%any\n    rightid=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.10.10.0/24\n    rightdns=8.8.8.8,8.8.4.4\n    rightsendcert=never\n    eap_identity=%identity\n    ike=chacha20poly1305-sha512-curve25519-prfsha512,aes256gcm16-sha384-prfsha384-ecp384,aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024!\n    esp=chacha20poly1305-sha512,aes256gcm16-ecp384,aes256-sha256,aes256-sha1,3des-sha1!\n</code></pre>\n<p>Speichern und schließen Sie die Datei, nachdem Sie überprüft haben, dass Sie jede Zeile korrekt hinzugefügt haben. Wenn Sie <code>nano</code> verwendet haben, drücken Sie <code>STRG+X</code>, <code>Y</code>, dann die <code>EINGABETASTE</code>.</p>\n\n<p>Nachdem wir nun die VPN-Parameter konfiguriert haben, gehen wir zur Erstellung eines Kontos über, damit unsere Benutzer eine Verbindung zum Server herstellen können.</p>\n\n<h2 id=\"schritt-5-—-konfigurieren-der-vpn-authentifizierung\">Schritt 5 — Konfigurieren der VPN-Authentifizierung</h2>\n\n<p>Unser VPN-Server ist nun so konfiguriert, dass er Client-Verbindungen akzeptiert, aber wir haben noch keine Anmeldedaten konfiguriert. Wir müssen einige Dinge in einer speziellen Konfigurationsdatei namens <code>ipsec.secrets</code> konfigurieren:</p>\n\n<ul>\n<li>Wir müssen StrongSwan mitteilen, wo der private Schlüssel für unser Serverzertifikat zu finden ist, damit sich der Server gegenüber den Clients authentifizieren kann.</li>\n<li>Außerdem müssen wir eine Liste von Benutzern erstellen, die eine Verbindung mit dem VPN herstellen dürfen.</li>\n</ul>\n\n<p>Öffnen wie die Datei „Secrets“ zum Bearbeiten:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.secrets\n</li></ul></code></pre>\n<p>Zuerst teilen wir StrongSwan mit, wo unser privater Schlüssel zu finden ist:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code>: RSA \"server-key.pem\"\n</code></pre>\n<p>Dann definieren wir die Anmeldedaten des Benutzers. Sie können jede beliebige Kombination von Benutzername und Passwort zusammenstellen, die Ihnen gefällt:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.secrets\">/etc/ipsec.secrets</div><pre class=\"code-pre \"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Speichern und schließen Sie die Datei. Nachdem wir die Arbeit mit den VPN-Parametern beendet haben, starten wir den VPN-Dienst neu, damit unsere Konfiguration übernommen wird:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart strongswan-starter\n</li></ul></code></pre>\n<p>Nachdem der VPN-Server nun sowohl mit den Serveroptionen als auch mit den Anmeldedaten der Benutzer vollständig konfiguriert ist, ist es an der Zeit, mit der Konfiguration des wichtigsten Teils fortzufahren: der Firewall.</p>\n\n<h2 id=\"schritt-6-—-konfigurieren-der-firewall-amp-kernel-ip-weiterleitung\">Schritt 6 — Konfigurieren der Firewall &amp; Kernel-IP-Weiterleitung</h2>\n\n<p>Nachdem die Konfiguration von StrongSwan abgeschlossen ist, müssen wir die Firewall so konfigurieren, dass sie VPN-Verkehr durchlässt und weiterleitet.</p>\n\n<p>Wenn Sie dem Tutorial zur Ersteinrichtung des Servers gefolgt sind, sollten Sie eine UFW-Firewall aktiviert haben. Wenn Sie UFW noch nicht konfiguriert haben, sollten Sie zunächst mit dem Hinzufügen einer Regel beginnen, um SSH-Verbindungen durch die Firewall zuzulassen, damit Ihre aktuelle nicht geschlossen wird, wenn Sie UFW aktivieren:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow OpenSSH\n</li></ul></code></pre>\n<p>Aktivieren Sie dann die Firewall durch folgende Eingabe:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Fügen Sie dann eine Regel hinzu, um den UDP-Verkehr zu den IPSec-Standardports <code>500</code> und <code>4500</code> zulassen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 500,4500/udp\n</li></ul></code></pre>\n<p>Als Nächstes öffnen wir eine der Konfigurationsdateien von UFW, um einige niedrigstufige Richtlinien für das Routing und die Weiterleitung von IPSec-Paketen hinzuzufügen. Zuvor müssen wir jedoch herausfinden, welche Netzwerkschnittstelle auf unserem Server für den Internetzugang verwendet wird. Finden Sie diese Schnittstelle, indem Sie das mit der Standardroute verknüpfte Gerät abfragen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">ip route show default\n</li></ul></code></pre>\n<p>Ihre öffentliche Schnittstelle sollte dem Wort „dev“ folgen. Dieses Ergebnis zeigt beispielsweise die im folgenden Beispiel hervorgehobene Schnittstelle <code>eth0</code> an:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>default via <span class=\"highlight\">your_server_ip</span> dev <span class=\"highlight\">eth0</span> proto static\n</code></pre>\n<p>Wenn Sie Ihre öffentliche Netzwerkschnittstelle haben, öffnen Sie die Datei <code>/etc/ufw/before.rules</code> in Ihrem Texteditor. Die Regeln in dieser Datei werden der Firewall vor den übrigen üblichen Eingabe- und Ausgaberegeln hinzugefügt. Sie werden verwendet, um die Netzwerkadressübersetzung (Network Address Translation, NAT) zu konfigurieren, damit der Server Verbindungen zu und von Clients und dem Internet korrekt weiterleiten kann.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/before.rules\n</li></ul></code></pre>\n<p>Fügen Sie am Anfang der Datei (vor der Zeile <code>*filter</code>) den folgenden Konfigurationsblock hinzu. Ändern Sie jede Instanz von <code>eth0</code> in der obigen Konfiguration so, dass sie mit dem Schnittstellennamen übereinstimmt, den Sie mit <code>ip route</code> gefunden haben. Die Zeilen <code>*nat</code> erstellen Regeln, damit die Firewall den Datenverkehr zwischen den VPN-Clients und dem Internet korrekt weiterleiten und manipulieren kann. Die Zeile <code>*mangle</code> passt die maximale Paketsegmentgröße an, um potenzielle Probleme mit bestimmten VPN-Clients zu verhindern:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code><span class=\"highlight\">*nat</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -m policy --pol ipsec --dir out -j ACCEPT</span>\n<span class=\"highlight\">-A POSTROUTING -s 10.10.10.0/24 -o eth0 -j MASQUERADE</span>\n<span class=\"highlight\">COMMIT</span>\n\n<span class=\"highlight\">*mangle</span>\n<span class=\"highlight\">-A FORWARD --match policy --pol ipsec --dir in -s 10.10.10.0/24 -o eth0 -p tcp -m tcp --tcp-flags SYN,RST SYN -m tcpmss --mss 1361:1536 -j TCPMSS --set-mss 1360</span>\n<span class=\"highlight\">COMMIT</span>\n\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n. . .\n</code></pre>\n<p>Fügen Sie als Nächstes nach den Zeilen <code>*filter</code> und Kettendefinitionen einen weiteren Konfigurationsblock hinzu:</p>\n<div class=\"code-label \" title=\"/etc/ufw/before.rules\">/etc/ufw/before.rules</div><pre class=\"code-pre \"><code>. . .\n*filter\n:ufw-before-input - [0:0]\n:ufw-before-output - [0:0]\n:ufw-before-forward - [0:0]\n:ufw-not-local - [0:0]\n\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir in --proto esp -s 10.10.10.0/24 -j ACCEPT</span>\n<span class=\"highlight\">-A ufw-before-forward --match policy --pol ipsec --dir out --proto esp -d 10.10.10.0/24 -j ACCEPT</span>\n</code></pre>\n<p>Diese Zeilen weisen die Firewall an, den <a href=\"https://wiki.wireshark.org/ESP\">ESP</a>-Datenverkehr (Encapsulating Security Payload-Datenverkehr) weiterzuleiten, sodass die VPN-Clients eine Verbindung herstellen können. ESP bietet für unsere VPN-Pakete zusätzliche Sicherheit, da sie nicht vertrauenswürdige Netzwerke durchqueren.</p>\n\n<p>Wenn Sie fertig sind, speichern und schließen Sie die Datei, nachdem Sie überprüft haben, dass Sie jede Zeile korrekt hinzugefügt haben. Wenn Sie <code>nano</code> verwendet haben, drücken Sie <code>STRG+X</code>, <code>Y</code>, dann die <code>EINGABETASTE</code>.</p>\n\n<p>Vor dem Neustart der Firewall werden wir einige Netzwerk-Kernel-Parameter ändern, um die Weiterleitung von einer Schnittstelle zu einer anderen zu ermöglichen. Die Datei, die diese Einstellungen steuert, heißt <code>/etc/ufw/sysctl.conf</code>. In dieser Datei müssen wir einige Dinge konfigurieren.</p>\n\n<p>Zuerst muss die IPv4-Paketweiterleitung eingeschaltet werden, damit der Datenverkehr zwischen dem VPN und den öffentlich zugänglichen Netzwerkschnittstellen auf dem Server ausgetauscht werden kann. Als Nächstes deaktivieren wir die Path-MTU-Erkennung, um Probleme mit der Paketfragmentierung zu verhindern. Abschließend werden wir weder ICMP-Weiterleitungen akzeptieren noch ICMP-Weierleitungen senden, um <a href=\"https://en.wikipedia.org/wiki/Man-in-the-middle_attack\">Man-in-the-Middle</a>-Angriffe zu verhindern.</p>\n\n<p>Öffnen Sie die Konfigurationsdatei der UFW-Kernel-Parameter in <code>nano</code> oder Ihrem bevorzugten Texteditor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ufw/sysctl.conf\n</li></ul></code></pre>\n<p>Fügen Sie nun am Ende der Datei die folgende Einstellung <code>net/ipv4/ip_forward=1</code> hinzu, um die Weiterleitung von Paketen zwischen Schnittstellen zu ermöglichen:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_forward=1</span>\n</code></pre>\n<p>Blockieren Sie als Nächstes das Senden und Empfangen von ICMP-Umleitungspaketen, indem Sie die folgenden Zeilen am Ende der Datei hinzufügen:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/conf/all/accept_redirects=0</span>\n<span class=\"highlight\">net/ipv4/conf/all/send_redirects=0</span>\n</code></pre>\n<p>Deaktivieren Sie abschließend die Path-MTU-Erkennung, indem Sie diese Zeile am Ende der Datei hinzufügen:</p>\n<div class=\"code-label \" title=\"/etc/ufw/sysctl.conf\">/etc/ufw/sysctl.conf</div><pre class=\"code-pre \"><code>. . .\n<span class=\"highlight\">net/ipv4/ip_no_pmtu_disc=1</span>\n</code></pre>\n<p>Speichern Sie die Datei, wenn Sie fertig sind. Jetzt können wir alle unsere Änderungen durch Deaktivieren und erneutes Aktivieren der Firewall aktivieren, da UFW diese Einstellungen bei jedem Neustart anwendet:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw disable\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Sie werden dazu aufgefordert, den Vorgang zu bestätigen. Geben Sie <code>Y</code> ein, um UFW mit den neuen Einstellungen erneut zu aktivieren.</p>\n\n<h2 id=\"schritt-7-—-testen-der-vpn-verbindung-unter-windows-macos-ubuntu-ios-und-android\">Schritt 7 — Testen der VPN-Verbindung unter Windows, macOS, Ubuntu, iOS und Android</h2>\n\n<p>Nachdem nun alles eingerichtet ist, ist es Zeit, es auszuprobieren. Zuerst müssen Sie das von Ihnen erstellte CA-Zertifikat kopieren und auf Ihrem/Ihren Client-Gerät(en) installieren, das/die sich mit Ihrem Server verbindet/verbinden. Am einfachsten geht das, indem Sie sich bei Ihrem Server anmelden und den Inhalt der Zertifikatsdatei ausgeben:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cat /etc/ipsec.d/cacerts/ca-cert.pem\n</li></ul></code></pre>\n<p>Sie sehen eine Ausgabe, die dieser ähnelt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>-----BEGIN CERTIFICATE-----\nMIIFNDCCAxygAwIBAgIIHCsidG5mXzgwDQYJKoZIhvcNAQEMBQAwODELMAkGA1UE\n\n. . .\n\nH2YUdz8XNHrJHvMQKWFpi0rlEcMs+MSXPFWE3Q7UbaZJ/h8wpSldSUbQRUlphExJ\ndJ4PX+MUJO/vjG1/ie6Kh25xbBAc3qNq8siiJZDwrg6vjEK7eiZ1rA==\n-----END CERTIFICATE-----\n</code></pre>\n<p>Kopieren Sie diese Ausgabe auf Ihren Computer, einschließlich der Zeilen <code>--BEGIN CERTIFICATE----</code> und <code>--END CERTIFICATE--</code>, und speichern Sie sie in einer Datei mit einem erkennbaren Namen wie <code>ca-cert.pem</code>. Stellen Sie sicher, dass die von Ihnen erstellte Datei die Erweiterung <code>.pem</code> hat.</p>\n\n<p>Alternativ <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server\">können Sie SFTP verwenden, um die Datei auf Ihren Computer zu übertragen</a>.</p>\n\n<p>Sobald die Datei <code>ca-cert.pem</code> auf Ihren Computer heruntergeladen haben, können Sie die Verbindung zum VPN einrichten.</p>\n\n<h3 id=\"herstellen-der-verbindung-von-windows\">Herstellen der Verbindung von Windows</h3>\n\n<p>Es gibt mehrere Möglichkeiten, das Stammzertifikat zu importieren und Windows für die Verbindung mit einem VPN zu konfigurieren. Die erste Methode verwendet grafische Tools für jeden Schritt. Die zweite Methode verwendet PowerShell-Befehle, die in Skripts geschrieben und an Ihre VPN-Konfiguration angepasst werden können.</p>\n\n<p><span class='note'><strong>Anmerkung:</strong> Diese Anweisungen wurden in Windows 10-Installationen getestet, die die Versionen 1903 und 1909 ausführen.<br></span></p>\n\n<h4 id=\"konfigurieren-von-windows-mit-grafischen-tools\">Konfigurieren von Windows mit grafischen Tools</h4>\n\n<p>Importieren Sie zunächst das Stammzertifikat, indem Sie die folgenden Schritte ausführen:</p>\n\n<ol>\n<li>Drücken Sie <code>WINDOWS+R</code>, um das Dialogfeld <strong>Ausführen</strong> aufzurufen, und geben Sie <code>mmc.exe</code> zum Starten der Windows Managementkonsole ein.</li>\n<li>Navigieren Sie im Menü <strong>Datei</strong> zu <strong>Snap-In hinzufügen oder entfernen</strong>, wählen Sie aus der Liste der verfügbaren Snap-Ins <strong>Zertifikate</strong> aus und klicken Sie auf <strong>Hinzufügen</strong>.</li>\n<li>Wir wollen, dass das VPN mit jedem Benutzer funktioniert, daher wählen wir <strong>Computerkonto</strong> und klicken auf <strong>Weiter</strong>.</li>\n<li>Wir konfigurieren Dinge auf dem lokalen Computer, daher wählen wir <strong>Lokaler Computer</strong> und klicken auf <strong>Fertigstellen</strong>.</li>\n<li><p>Erweitern Sie unter dem Knoten <strong>Konsolenstamm</strong> den Eintrag <strong>Zertifikate (Lokaler Computer)</strong>, erweitern Sie <strong>Vertrauenswürdige Stammzertifizierungsstellen und wählen Sie dann den Eintra</strong>g** Zertifikate**: <img src=\"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png\" alt=\"Zertifikatsans\">icht.</p></li>\n<li><p>Wählen Sie im Menü <strong>Aktion</strong> <strong>Alle Aufgaben</strong> aus und klicken Sie auf <strong>Improtieren</strong>, um den Assistenten für den Zertifikatimport anzuzeigen. Klicken Sie auf <strong>Weiter</strong>, um die Einführung zu überspringen.</p></li>\n<li><p>Klicken Sie auf dem Bildschirm <strong>Zu importierende Datei</strong> die Schaltfläche <strong>Durchsuchen</strong>, stellen Sie sicher, dass Sie den Dateityp von „X.509-Zertifikat (<em>.cer;</em>.crt)“ in „Alle Dateien (<em>.</em>)“ ändern und wählen Sie die Datei <code>ca-cert.pem</code>, die Sie gespeichert haben. Klicken Sie dann auf <strong>Weiter</strong>.</p></li>\n<li><p>Stellen Sie sicher, dass der <strong>Zertifikatspeicher</strong> auf <strong>Vertrauenswürdige Stammzertifizierungsstellen</strong> eingestellt ist und klicken Sie auf <strong>Weiter</strong>.</p></li>\n<li><p>Klicken Sie auf <strong>Fertigstellen</strong>, um das Zertifikat zu importieren.</p></li>\n</ol>\n\n<p>Konfigurieren Sie das VPN dann mit diesen Schritten:</p>\n\n<ol>\n<li>Starten Sie die <strong>Systemsteuerung</strong>, navigieren Sie dann zum <strong>Netzwerk- und Freigabecenter</strong>.</li>\n<li>Klicken Sie auf <strong>Einrichten einer neuen Verbindung oder eines neuen Netzwerks</strong> und wählen Sie <strong>Mit einem Arbeitsplatz verbinden</strong>.</li>\n<li>Wählen Sie <strong>Meine Internetverbindung (VPN) verwenden</strong>.</li>\n<li>Geben Sie die Details des VPN-Servers ein. Geben Sie den Domänennamen oder die IP-Adresse des Servers in das Feld <strong>Internetadresse</strong> ein und geben Sie dann den <strong>Zielnamen</strong> mit einer Beschreibung Ihrer VPN-Verbindung ein. Klicken Sie dann auf <strong>Fertig</strong>.</li>\n</ol>\n\n<h4 id=\"konfigurieren-von-windows-mit-powershell\">Konfigurieren von Windows mit PowerShell</h4>\n\n<p>Um das Stamm-CA-Zertifikat mit PowerShell zu importieren, öffnen Sie zunächst eine PowerShell-Eingabeaufforderung mit Administratorberechtigungen. Klicken Sie dazu mit der rechten Maustaste auf das Symbol im Startmenü und wählen Sie <code>Windows PowerShell (Admin)</code>. Sie können auch eine Eingabeaufforderung als Administrator öffnen und <code>powershell</code> eingeben.</p>\n\n<p>Als Nächstes importieren wir das Zertifikat mit dem Powershell cmdlet <code>Import-Certificate</code>. Im folgenden Befehl wird mit dem ersten Argument <code>-CertStoreLocation</code> sichergestellt, dass das Zertifikat in dem Speicher der <strong>Vertrauenswürdigen Stammzertifizierungsstelle</strong> des Computers importiert wird, damit alle Programme und Benutzer das Zertifikat des VPN-Servers überprüfen können. Das Argument <code>-FilePath</code> sollte auf den Speicherort verweisen, in den Sie das Zertifikat kopiert haben. Im folgenden Beispiel lautet der Pfad <code>C:\\Users\\sammy\\Documents\\ca-cert.pem</code>. Stellen Sie sicher, dass Sie den Befehl so bearbeiten, dass er mit dem von Ihnen verwendeten Speicherort übereinstimmt.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Import-Certificate `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CertStoreLocation cert:\\LocalMachine\\Root\\ `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -FilePath <span class=\"highlight\">C:\\users\\sammy\\Documents\\ca-cert.pem</span>\n</li></ul></code></pre>\n<p>Der Befehl gibt etwas wie das Folgende aus:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>   PSParentPath: Microsoft.PowerShell.Security\\Certificate::LocalMachine\\Root\n\nThumbprint                                Subject\n----------                                -------\nDB00813B4087E9367861E8463A60CEA0ADC5F002  CN=VPN root CA\n</code></pre>\n<p>Um nun das VPN mit PowerShell zu konfigurieren, führen Sie den folgenden Befehl aus. Ersetzen Sie den DNS-Namen oder die IP-Adresse Ihres Servers in der Zeile <code>-Serveraddress</code>. Die verschiedenen Flags stellen sicher, dass Windows korrekt mit den entsprechenden Sicherheitsparametern konfiguriert wird, die den Optionen entsprechen, die Sie in <code>/etc/ipsec.conf</code> festgelegt haben.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Add-VpnConnection -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -ServerAddress \"<span class=\"highlight\">server_domain_or_IP</span>\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -TunnelType \"IKEv2\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationMethod \"EAP\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionLevel \"Maximum\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -RememberCredential `\n</li></ul></code></pre>\n<p>Wenn der Befehl erfolgreich ist, gibt es keine Ausgabe. Um zu bestätigen, dass das VPN richtig konfiguriert ist, verwenden Sie das cmdlet <code>Get-VPNConnection</code>:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Get-VpnConnection -Name \"VPN Connection\"\n</li></ul></code></pre>\n<p>Sie erhalten eine Ausgabe wie die folgende:</p>\n<pre class=\"code-pre  local-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Name                  : VPN Connection\nServerAddress         : <span class=\"highlight\">your_server_ip</span>\nAllUserConnection     : False\nGuid                  : {B055A1AB-175C-4028-B4A8-D34309A2B20E}\nTunnelType            : Ikev2\nAuthenticationMethod  : {Eap}\nEncryptionLevel       : Maximum\nL2tpIPsecAuth         :\nUseWinlogonCredential : False\nEapConfigXmlStream    : #document\nConnectionStatus      : Disconnected\nRememberCredential    : True\nSplitTunneling        : False\nDnsSuffix             :\nIdleDisconnectSeconds : 0\n</code></pre>\n<p>Standardmäßig wählt Windows ältere und langsamere Algorithmen. Führen Sie das cmdlet <code>Set-VpnConnectionIPsecConfiguration</code> aus, um die Verschlüsselungsparameter zu aktualisieren, die Windows für den IKEv2-Schlüsselaustausch verwendet und um Pakete zu verschlüsseln:</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Set-VpnConnectionIPsecConfiguration -Name \"VPN Connection\" `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -AuthenticationTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -CipherTransformConstants GCMAES256 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -DHGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -IntegrityCheckMethod SHA384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -PfsGroup ECP384 `\n</li><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">    -EncryptionMethod GCMAES256\n</li></ul></code></pre>\n<span class='note'><p>\n<strong>Anmerkung</strong>: Wenn Sie die VPN-Verbindung löschen und mit verschiedenen Optionen neu konfigurieren möchten, können Sie das cmdlet <code>Remove-VpnConnection</code> ausführen.</p>\n<pre class=\"code-pre custom_prefix prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"PS C:\\windows\\system32&gt;\">Remove-VpnConnection -Name \"VPN Connection\" -Force\n</li></ul></code></pre>\n<p>Das Flag <code>-Force</code> wird übersprungen und Sie werden aufgefordert, das Entfernen zu bestätigen. Wenn Sie versuchen, die VPN-Verbindung mit diesem Befehl zu entfernen, müssen Sie vom VPN getrennt sein.<br></p></span>\n\n<h4 id=\"herstellen-einer-verbindung-mit-dem-vpn\">Herstellen einer Verbindung mit dem VPN</h4>\n\n<p>Sobald Sie das Zertifikat importiert und das VPN mit einer der beiden Methoden konfiguriert haben, wird Ihre neue VPN-Verbindung unter der Liste der Netzwerke sichtbar. Wählen Sie das VPN und klicken Sie auf <strong>Verbinden</strong>. Sie werden zur Eingabe Ihres Benutzernamens und Ihres Passworts aufgefordert. Geben Sie sie ein, klicken Sie auf <strong>OK</strong>, und Sie werden verbunden.</p>\n\n<h3 id=\"herstellen-einer-verbindung-von-macos\">Herstellen einer Verbindung von macOS</h3>\n\n<p>Folgen Sie diesen Schritten, um das Zertifikat zu importieren:</p>\n\n<ol>\n<li>Doppelklicken Sie auf die Zertifikatsdatei. <strong>Keychain Access</strong> wird mit einem Dialogfeld eingeblendet, in dem es heißt „Keychain Access is trying to modify the system keychain. Enter your password to allow this.“ (Keychain Access versucht die System-Keychain zu ändern. Geben Sie Ihr Passwort ein, um dies zuzulassen).</li>\n<li>Geben Sie Ihr Passwort ein, klicken Sie dann auf <strong>Modify Keychain</strong> (Keychain ändern)</li>\n<li>Doppelklicken Sie auf das neu importierte VPN-Zertifikat. Dadurch wird ein kleines Eigenschaftenfenster eingeblendet, in dem Sie die Vertrauensstufen angeben können. Setzen Sie <strong>IP Security (IPSec)</strong> auf <strong>Always Trust</strong> (Immer vertrauen) und Sie werden erneut zur Eingabe Ihres Passworts aufgefordert. Diese Einstellung wird nach der Eingabe des Passworts automatisch gespeichert.</li>\n</ol>\n\n<p>Nachdem das Zertifikat importiert und vertrauenswürdig ist, konfigurieren Sie die VPN-Verbindung nun mit diesen Schritten:</p>\n\n<ol>\n<li>Gehen Sie zu <strong>Systemeinstellungen</strong> und wählen Sie <strong>Netzwerk</strong>.</li>\n<li>Klicken Sie auf die kleine „Plus“-Schaltfläche unten links in der Liste der Netzwerke.</li>\n<li>Stellen Sie in dem angezeigten Popup-Fenster <strong>Schnittstelle</strong> auf <strong>VPN</strong>, setzen Sie den <strong>VPN-Typ</strong> auf <strong>IKEv2</strong> und geben Sie der Verbindung einen Namen.</li>\n<li>Geben Sie im Feld <strong>Server</strong> und <strong>Remote ID</strong> den Domänennamen oder die IP-Adresse des Servers ein. Lassen Sie <strong>Lokale ID</strong> leer.</li>\n<li>Klicken Sie auf <strong>Authentifizierungseinstellungen</strong>, wählen Sie <strong>Bentuzername</strong> und geben Sie Ihren Benutzernamen und Ihr Passwort ein, das Sie für Ihren VPN-Benutzer konfiguriert haben. Klicken Sie dann auf <strong>OK</strong>.</li>\n</ol>\n\n<p>Klicken Sie abschließend auf <strong>Verbinden</strong>, um sich mit dem VPN zu verbinden. Sie sollten nun mit dem VPN verbunden sein.</p>\n\n<h3 id=\"herstellen-einer-verbindung-von-ubuntu\">Herstellen einer Verbindung von Ubuntu</h3>\n\n<p>Um eine Verbindung von einem Ubuntu-Rechner herzustellen, können Sie StrongSwan als Dienst einrichten und verwalten oder bei jeder gewünschten Verbindung einen einmaligen Befehl verwenden. Für beides stehen Anweisungen zur Verfügung.</p>\n\n<h4 id=\"verwalten-von-strongswan-als-dienst\">Verwalten von StrongSwan als Dienst</h4>\n\n<p>Um StrongSwan als Dienst zu verwalten, müssen Sie die folgenden Konfigurationsschritte durchführen.</p>\n\n<p>Aktualisieren Sie zunächst Ihren lokalen Paket-Cache mit <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo apt update\n</li></ul></code></pre>\n<p>Installieren Sie als Nächstes StrongSwan und die erforderlichen Plugins für die Authentifizierung:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Jetzt benötigen Sie im Verzeichnis <code>/etc/ipsec.d/cacerts</code> eine Kopie des CA-Zertifikats, damit Ihr Client die Identität des Servers überprüfen kann. Führen Sie den folgenden Befehl aus, um die Datei <code>ca-cert.pem</code> in den richtigen Speicherort zu kopieren:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Um sicherzustellen, dass das VPN nur bei Bedarf ausgeführt wird, deaktivieren Sie mit <code>systemctl</code> die automatische Ausführung von StrongSwan:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl disable --now strongswan-starter\n</li></ul></code></pre>\n<p>Konfigurieren Sie als Nächstes den Benutzernamen und das Passwort, das Sie zur Authentifizierung auf dem VPN-Server verwenden werden. Bearbeiten Sie <code>/etc/ipsec.secrets</code> mit nano oder Ihrem bevorzugten Editor:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/ipsec.conf\n</li></ul></code></pre>\n<p>Fügen Sie die folgende Zeile hinzu und bearbeiten Sie die hervorgehobenen Werte für Benutzername und Passwort, damit sie mit denen übereinstimmen, die Sie auf dem Server konfiguriert haben:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code><span class=\"highlight\">your_username</span> : EAP <span class=\"highlight\">\"your_password\"</span>\n</code></pre>\n<p>Bearbeiten Sie abschließend die Datei <code>/etc/ipsec.conf</code>, um Ihren Client so zu konfigurieren, dass er mit der Konfiguration des Servers übereinstimmt:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre  local-environment\"><code>config setup\n\nconn ikev2-rw\n    right=<span class=\"highlight\">server_domain_or_IP</span>\n    # This should match the `leftid` value on your server's configuration\n    rightid=<span class=\"highlight\">server_domain_or_IP</span>\n    rightsubnet=0.0.0.0/0\n    rightauth=pubkey\n    leftsourceip=%config\n    leftid=<span class=\"highlight\">username</span>\n    leftauth=eap-mschapv2\n    eap_identity=%identity\n    auto=start\n</code></pre>\n<p>Um sich mit dem VPN zu verbinden, geben Sie Folgendes ein:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start strongswan-starter\n</li></ul></code></pre>\n<p>Um sich wieder zu trennen, geben Sie Folgendes ein:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop strongswan-starter\n</li></ul></code></pre>\n<h4 id=\"verwenden-des-clients-charon-cmd-für-einmalige-verbindungen\">Verwenden des Clients <code>charon-cmd</code> für einmalige Verbindungen</h4>\n\n<p>Um StrongSwan als Dienst zu verwalten, müssen Sie die folgenden Konfigurationsschritte durchführen.</p>\n\n<p>Aktualisieren Sie zunächst Ihren lokalen Paket-Cache mit <code>apt</code></p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Installieren Sie als Nächstes StrongSwan und die erforderlichen Plugins für die Authentifizierung:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install strongswan libcharon-extra-plugins\n</li></ul></code></pre>\n<p>Jetzt benötigen Sie im Verzeichnis <code>/etc/ipsec.d/cacerts</code> eine Kopie des CA-Zertifikats, damit Ihr Client die Identität des Servers überprüfen kann. Führen Sie den folgenden Befehl aus, um die Datei <code>ca-cert.pem</code> in den richtigen Speicherort zu kopieren:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp <span class=\"highlight\">/tmp/ca-cert.pem</span> /etc/ipsec.d/cacerts\n</li></ul></code></pre>\n<p>Zu diesem Zeitpunkt können Sie sich mit <code>charon-cmd</code> unter Verwendung des CA-Zertifikats des Servers, der IP-Adresse des VPN-Servers und des von Ihnen konfigurierten Benutzernamens mit dem VPN-Server verbinden.</p>\n\n<p>Führen Sie den folgenden Befehl aus, wann immer Sie eine Verbindung mit dem VPN herstellen möchten:</p>\n<pre class=\"code-pre command prefixed local-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo charon-cmd --cert ca-cert.pem --host <span class=\"highlight\">vpn_domain_or_IP</span> --identity <span class=\"highlight\">your_username</span>\n</li></ul></code></pre>\n<p>Geben Sie, wenn Sie dazu aufgefordert werden, das Passwort des VPN-Benutzers ein und Sie werden mit dem VPN verbunden. Um die Verbindung zu trennen, drücken Sie im Terminal <code>Strg+C</code> und warten Sie, bis die Verbindung geschlossen wird.</p>\n\n<h3 id=\"herstellen-einer-verbindung-von-ios\">Herstellen einer Verbindung von iOS</h3>\n\n<p>Führen Sie die folgenden Schritte aus, um die VPN-Verbindung auf einem iOS-Gerät zu konfigurieren:</p>\n\n<ol>\n<li>Senden Sie sich selbst eine E-Mail mit dem Stammzertifikat im Anhang.</li>\n<li>Öffnen Sie die E-Mail auf Ihrem iOS-Gerät und tippen Sie auf die angehängte Zertifikatdatei, tippen Sie dann auf <strong>Installieren</strong> und geben Sie Ihren Passcode ein. Sobald diese installiert ist, tippen Sie <strong>auf Fertig</strong>.</li>\n<li>Gehen Sie zu <strong>Einstellungen</strong>, <strong>Allgemein</strong>, <strong>VPN</strong> und tippen Sie auf <strong>VPN-Konfiguration hinzufügen</strong>. Daraufhin wird der Bildschirm zur Konfiguration der VPN-Verbindung angezeigt.</li>\n<li>Tippen Sie auf <strong>Typ</strong> und wählen Sie <strong>IKEv2</strong>.</li>\n<li>Geben Sie im Feld <strong>Beschreibung</strong> einen kurzen Namen für die VPN-Verbindung ein. Dieser Name kann beliebig sein.</li>\n<li>Geben Sie im Feld <strong>Server</strong> und <strong>Remote ID</strong> den Domänennamen oder die IP-Adresse des Servers ein. Das Feld <strong>Lokale ID</strong> kann leer gelassen werden.</li>\n<li>Geben Sie Ihren Benutzernamen und Ihr Passwort in den Abschnitt <strong>Authentifizierung</strong> ein, und tippen Sie dann auf <strong>Fertig</strong>.</li>\n<li>Wählen Sie die gerade erstellte VPN-Verbindung, tippen Sie auf die Schaltfläche oben auf der Seite und schon sind Sie verbunden.</li>\n</ol>\n\n<h3 id=\"herstellen-einer-verbindung-von-android\">Herstellen einer Verbindung von Android</h3>\n\n<p>Folgen Sie diesen Schritten, um das Zertifikat zu importieren:</p>\n\n<ol>\n<li>Senden Sie sich selbst eine E-Mail mit dem CA-Zertifikat im Anhang. Speichern Sie das CA-Zertifikat in Ihrem Download-Ordner.</li>\n<li>Laden Sie den <a href=\"https://play.google.com/store/apps/details?id=org.strongswan.android&amp;hl=en_US\">StrongSwan VPN-Client</a> aus dem Play-Store herunter.</li>\n<li>Öffnen Sie die App. Tippen Sie auf das Symbol &ldquo;Mehr&rdquo; (<strong>&hellip;</strong>) in der rechten oberen Ecke und wählen Sie <strong>CA-Zertifikate</strong>.</li>\n<li>Tippen Sie erneut auf das Symbol &ldquo;Mehr&rdquo; (<strong>&hellip;</strong>) in der rechten oberen Ecke. Wählen Sie <strong>Zertifikat importieren</strong>.</li>\n<li>Navigieren Sie zu der CA-Zertifikatsdatei in Ihrem Donwload-Ordner und wählen Sie sie aus, um sie in die Anwendung zu importieren.</li>\n</ol>\n\n<p>Nachdem das Zertifikat nun in die StrongSwan-Anwendung importiert wurde, können Sie die VPN-Verbindung mit diesen Schritten konfigurieren:</p>\n\n<ol>\n<li>Tippen Sie oben in der App auf <strong>VPN-PROFIL HINZUFÜGEN</strong>.</li>\n<li>Geben Sie bei <strong>Server</strong> den Domänennamen oder die öffentliche IP-Adresse Ihres VPN-Servers ein.</li>\n<li>Stellen Sie sicher, dass <strong>IKEv2 EAP (Benutzername/Passwort)</strong> als VPN-Typ ausgewählt ist.</li>\n<li>Geben Sie bei <strong>Benutzername</strong> und <strong>Passwort</strong> die Anmeldedaten ein, die Sie auf dem Server definiert haben.</li>\n<li>Deaktivieren Sie <strong>Automatisch auswählen</strong> im Abschnitt <strong>CA-Zertifikat</strong> und klicken Sie auf <strong>CA-Zertifikat auswählen</strong>.</li>\n<li>Tippen Sie auf die Registerkarte <strong>IMPORTIERT</strong> oben auf dem Bildschirm und wählen Sie die von Ihnen importierte CA (sie heißt „VPN root CA“ wenn Sie den „DN“ nicht zuvor geändert haben).</li>\n<li>Wenn Sie möchten, können Sie den <strong>Profilnamen (optional)</strong> mit einem aussagekräftigeren Namen ausfüllen.</li>\n</ol>\n\n<p>Wenn Sie eine Verbindung mit dem VPN herstellen möchten, klicken Sie auf das Profil, das Sie gerade in der Anwendung StrongSwan erstellt haben.</p>\n\n<h3 id=\"fehlerbehebung-bei-verbindungen\">Fehlerbehebung bei Verbindungen</h3>\n\n<p>Wenn Sie das Zertifikat nicht importieren können, stellen Sie sicher, dass die Datei die Erweiterung <code>.pem</code> und nicht <code>.pem.txt</code> hat.</p>\n\n<p>Wenn Sie keine Verbindung mit dem VPN herstellen können, überprüfen Sie den von Ihnen verwendeten Servernamen oder die IP-Adresse. Der Domänenname oder die IP-Adresse des Servers muss mit dem übereinstimmen, was Sie bei der Erstellung des Zertifikats als Common Name (CN) konfiguriert haben. Wenn sie nicht übereinstimmen, funktioniert die VPN-Verbindung nicht. Wenn Sie beispielsweise ein Zertifikat mit dem CN von <code>vpn.example.com</code> einrichten, <em>müssen</em> Sie <code>vpn.example.com</code> verwenden, wenn Sie die VPN-Serverdetails eingeben. Überprüfen Sie den Befehl, den Sie zum Generieren des Zertifikats verwendet haben, und die Werte, die Sie bei der Erstellung Ihrer VPN-Verbindung verwendet haben.</p>\n\n<p>Abschließend überprüfen Sie die VPN-Konfiguration, um sicherzustellen, dass der Wert <code>leftid</code> mit dem Symbol <code>@</code> konfiguriert ist, wenn Sie einen Domänennamen verwenden:</p>\n<div class=\"code-label \" title=\"/etc/ipsec.conf\">/etc/ipsec.conf</div><pre class=\"code-pre \"><code>    leftid=<span class=\"highlight\">@</span>vpn.example.com\n</code></pre>\n<p>Wenn Sie eine IP-Adresse verwenden, stellen Sie sicher, dass das Symbol <code>@</code> ausgelassen ist. Stellen Sie außerdem sicher, dass Sie beim Generieren der Datei <code>server-cert.pem</code> die beiden Flags <code>--san @<span class=\"highlight\">IP_address</span></code> und <code>--san <span class=\"highlight\">IP_address</span></code> eingefügt haben.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>In diesem Tutorial haben Sie einen VPN-Server erstellt, der das IKEv2-Protokoll verwendet. Sie haben sich mit den Anweisungen vertraut gemacht, die die <code>linke</code> und die <code>rechte</code> Seite einer Verbindung sowohl auf dem Server als auch auf den Clients steuern. Außerdem haben Sie einen Windows-, macOS-, iOS-, Android- oder Linux-Client für die Verbindung mit dem VPN konfiguriert.</p>\n\n<p>Um Benutzer hinzuzufügen oder zu entfernen, führen Sie erneut Schritt 5 aus. Jede Zeile in <code>/etc/ipsec.secrets</code> ist für einen Benutzer, sodass das Hinzufügen oder Entfernen von Benutzern oder das Ändern von Passwörtern nur die Bearbeitung der Datei erfordert.</p>\n\n<p>Jetzt können Sie sicher sein, dass Ihre Online-Aktivitäten überall und mit jedem Gerät, das Sie für den Zugang zum Internet benutzen, geschützt bleiben.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:06 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png","linkMd5":"355a2635997cb4fb8442dea37b78a4ad","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp","destWidth":1436,"destHeight":754,"sourceBytes":109775,"destBytes":168410,"author":"Jamon Camisso","articleImgCdnMap":{"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp"},"publishedOrCreatedDate":1598860106972},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment installer MongoDB sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-mongodb-on-ubuntu-20-04-fr","description":"<p><em>Une version antérieure de ce tutoriel a été écrite par <a href=\"https://www.digitalocean.com/community/users/melissaanderson\">Brennan Bearnes</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://www.mongodb.com/\">MongoDB</a>, également connu sous le nom de <em>Mongo</em>, est une base de données de documents open-source utilisée dans de nombreuses applications web modernes. Elle est classée comme une <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">base de données NoSQL</a> car elle ne repose pas sur une structure de base de données relationnelle traditionnelle basée sur des tableaux.</p>\n\n<p>Elle utilise plutôt des documents de type JSON avec des schémas dynamiques, ce qui signifie que, à la différence des bases de données relationnelles, MongoDB ne nécessite pas de schéma prédéfini avant d'ajouter des données à une base de données. Vous pouvez modifier le schéma à tout moment et aussi souvent que nécessaire sans avoir à créer une nouvelle base de données avec un schéma mis à jour.</p>\n\n<p>Dans ce tutoriel, vous allez installer MongoDB sur un serveur Ubuntu 20.04, tester, et apprendre à le gérer en tant que service <code>systemd</code>.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour suivre ce tutoriel, vous aurez besoin de :</p>\n\n<ul>\n<li>Un serveur Ubuntu 20.04. Ce serveur doit avoir un utilisateur administratif non root et un pare-feu configuré avec UFW. Pour cela, suivez notre <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">guide de configuration initiale du serveur pour Ubuntu 20.04</a>.</li>\n</ul>\n\n<h2 id=\"Étape-1-—-installation-de-mongodb\">Étape 1 — Installation de MongoDB</h2>\n\n<p>Les référentiels de paquets officiels d'Ubuntu comprennent une version stable de MongoDB. Cependant, au moment d'écrire ces lignes, la version de MongoDB disponible dans les référentiels Ubuntu par défaut est la <span class=\"highlight\">3.6</span>, alors que la dernière version stable est la <span class=\"highlight\">4.4</span>.</p>\n\n<p>Pour obtenir la version la plus récente de ce logiciel, vous devez inclure le référentiel de paquets dédié de MongoDB à vos sources APT. Ensuite, vous pourrez installer <code>mongodb-org</code>, un méta-paquet qui pointe toujours vers la dernière version de MongoDB.</p>\n\n<p>Pour commencer, importez la clé GPG publique pour la dernière version stable de MongoDB. Vous pouvez trouver le fichier clé approprié en naviguant vers le <a href=\"https://www.mongodb.org/static/pgp/\">serveur de clé MongoDB</a> et en trouvant le fichier qui comprend le numéro de la dernière version stable et se termine par <code>.asc</code>. Par exemple, si vous voulez installer la version 4.4 de MongoDB, vous devez chercher le fichier nommé <strong>server-4.4.asc</strong>.</p>\n\n<p>Cliquez avec le bouton droit sur le fichier, et sélectionnez <strong>Copy link address</strong>. Ensuite, collez ce lien dans la commande <code>curl</code> suivante, en remplaçant l'URL mise en surbrillance :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -fsSL <span class=\"highlight\">https://www.mongodb.org/static/pgp/server-4.4.asc</span> | sudo apt-key add -\n</li></ul></code></pre>\n<p>cURL est un outil en ligne de commande disponible sur de nombreux systèmes d'exploitation utilisés pour transférer des données. Il lit toute donnée stockée à l'URL qui lui est transmise et imprime le contenu à la sortie du système. Dans l'exemple suivant, cURL imprime le contenu du fichier clé GPG et l'envoie ensuite dans la commande <code>sudo apt-key add qui</code> suit, ajoutant ainsi la clé GPG à votre liste de clés de confiance.</p>\n\n<p>Notez également que cette commande <code>curl</code> utilise les options <code>-fsSL</code> qui, ensemble, disent essentiellement à cURL d'échouer silencieusement. Cela signifie que si, pour une raison quelconque, cURL ne peut pas contacter le serveur GPG ou si le serveur GPG est en panne, il n'ajoutera pas accidentellement le code d'erreur résultant à votre liste de clés de confiance.</p>\n\n<p>Cette commande renverra <code>OK</code> si la clé a été ajoutée avec succès :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>OK\n</code></pre>\n<p>Si vous souhaitez vérifier si la clé a été correctement ajoutée, vous pouvez le faire avec la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">apt-key list\n</li></ul></code></pre>\n<p>Cela retournera la clé MongoDB quelque part dans la sortie :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>/etc/apt/trusted.gpg\n--------------------\npub   rsa4096 2019-05-28 [SC] [expires: 2024-05-26]\n      2069 1EEC 3521 6C63 CAF6  6CE1 6564 08E3 90CF B1F5\nuid           [ unknown] MongoDB 4.4 Release Signing Key &lt;packaging@mongodb.com&gt;\n. . .\n</code></pre>\n<p>À ce stade, votre installation APT ne sait toujours pas où trouver le paquet <code>mongodb-org</code> dont vous avez besoin pour installer la dernière version de MongoDB.</p>\n\n<p>Il existe deux endroits sur votre serveur où APT cherche les sources en ligne des paquets à télécharger et à installer : le fichier <code>sources.list</code> et le répertoire <code>sources.list.d</code>. <code>sources.list</code> est un fichier qui liste les sources actives des données APT, avec une source par ligne et les sources les plus appréciées en premier. Le répertoire <code>sources.list.d</code> vous permet d'ajouter ces entrées <code>sources.list</code> en tant que fichiers distincts.</p>\n\n<p>Exécutez la commande suivante, qui crée dans le répertoire <code>sources.list.d</code> un fichier nommé <code>mongodb-org-4.4.list</code>. Le seul contenu de ce fichier est une ligne unique : <code>deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/4.4 multiverse </code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/4.4 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.4.list\n</li></ul></code></pre>\n<p>Cette ligne unique indique à APT tout ce qu'il doit savoir sur la source et où la trouver :</p>\n\n<ul>\n<li><code>deb</code> : cela signifie que l'entrée source fait référence à une architecture Debian normale. Dans d'autres cas, cette partie de la ligne peut être <code>deb-src</code>, ce qui signifie que l'entrée source représente le code source d'une distribution Debian.</li>\n<li><code>[ arch=amd64,arm64 ]</code> : ceci spécifie sur quelles architectures les données APT devraient être téléchargées. Dans ce cas, il spécifie les architectures <code>amd64</code> et <code>arm64</code>.</li>\n<li><code>https://repo.mongodb.org/apt/ubuntu</code> : il s'agit d'une URI de l'emplacement où les données APT se trouvent. Dans ce cas, l'URI pointe vers l'adresse HTTPS où se trouve le référentiel MongoDB officiel.</li>\n<li><code>focal/mongodb-org/4.4</code> : les référentiels Ubuntu peuvent contenir plusieurs versions différentes. Ceci spécifie que vous ne voulez que la version <code>4.4</code> du paquet <code>mongodb-org</code> disponible pour la version <code>focal</code> d'Ubuntu (&ldquo;Focal Fossa&rdquo; étant le nom du code d'Ubuntu 20.04).</li>\n<li><code>multiverse</code> : cette partie dirige APT vers l'un des quatre principaux référentiels d'Ubuntu. Dans ce cas, il pointe vers le <a href=\"https://help.ubuntu.com/community/Repositories#Multiverse\">référentiel <code>multiverse</code></a>.</li>\n</ul>\n\n<p>Après avoir exécuté cette commande, mettez à jour l'index local de votre serveur afin qu'APT sache où trouver le paquet <code>mongodb-org</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Après cela, vous pouvez installer MongoDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install mongodb-org\n</li></ul></code></pre>\n<p>Lorsque vous y êtes invité, appuyez sur <code>Y</code> et ensuite <code>ENTER</code> pour confirmer que vous voulez installer le paquet.</p>\n\n<p>Lorsque la commande se termine, MongoDB sera installé sur votre système. Cependant, il n'est pas encore prêt à être utilisé. Ensuite, vous allez lancer MongoDB et confirmer qu'il fonctionne correctement.</p>\n\n<h2 id=\"Étape-2-—-démarrage-du-service-mongodb-et-test-de-la-base-de-données\">Étape 2 — Démarrage du service MongoDB et test de la base de données</h2>\n\n<p>Le processus d'installation décrit dans l'étape précédente configure automatiquement MongoDB pour qu'il s'exécute en tant que démon contrôlé par <code>systemd</code>, ce qui signifie que vous pouvez gérer MongoDB en utilisant les différentes commandes <code>systemctl</code>. Toutefois, cette procédure d'installation ne démarre pas automatiquement le service.</p>\n\n<p>Exécutez la commande <code>systemctl</code> suivante pour lancer le service MongoDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mongod.service\n</li></ul></code></pre>\n<p>Ensuite, vérifiez l'état du service. Notez que cette commande n'inclut pas <code>.service</code> dans la définition de fichier service. <code>systemctl</code> ajoutera automatiquement ce suffixe à n'importe quel argument que vous passerez s'il n'est pas déjà présent, il n'est donc pas nécessaire de l'inclure :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl status mongod\n</li></ul></code></pre>\n<p>Cette commande retournera une sortie semblable à celle-ci, indiquant que le service est opérationnel :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>● mongod.service - MongoDB Database Server\n     Loaded: loaded (/lib/systemd/system/mongod.service; disabled; vendor preset: enabled)\n     Active: <span class=\"highlight\">active (running)</span> since Tue 2020-06-09 12:57:06 UTC; 2s ago\n       Docs: https://docs.mongodb.org/manual\n   Main PID: 37128 (mongod)\n     Memory: 64.8M\n     CGroup: /system.slice/mongod.service\n             └─37128 /usr/bin/mongod --config /etc/mongod.conf\n</code></pre>\n<p>Après avoir confirmé que le service fonctionnait comme prévu, activez le service MongoDB pour qu'il se lance au démarrage :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mongod\n</li></ul></code></pre>\n<p>Vous pouvez également vérifier que la base de données est opérationnelle en vous connectant au serveur de base de données et en exécutant une commande de diagnostic. La commande suivante se connectera à la base de données et sortira sa version actuelle, son adresse serveur et son port. Elle retournera également le résultat de la commande interne <code>connectionStatus</code> de MongoDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mongo --eval 'db.runCommand({ connectionStatus: 1 })'\n</li></ul></code></pre>\n<p><code>connectionStatus</code> vérifiera et retournera l'état de la connexion à la base de données. Une valeur de <code>1</code> pour le champ <code>ok</code> dans la réponse indique que le serveur fonctionne comme prévu :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>MongoDB shell version v4.4.0\nconnecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodb\nImplicit session: session { \"id\" : UUID(\"1dc7d67a-0af5-4394-b9c4-8a6db3ff7e64\") }\nMongoDB server version: 4.4.0\n{\n    \"authInfo\" : {\n        \"authenticatedUsers\" : [ ],\n        \"authenticatedUserRoles\" : [ ]\n    },\n    \"ok\" : <span class=\"highlight\">1</span>\n}\n</code></pre>\n<p>Notez également que la base de données est en cours d'exécution sur le port <code>27017</code> sur <code>127.0.0.1</code>, l'adresse locale de rebouclage représentant <strong>localhost</strong>. Il s'agit du numéro de port par défaut de MongoDB.</p>\n\n<p>Ensuite, nous allons examiner comment gérer l'instance serveur MongoDB avec <code>systemd</code>.</p>\n\n<h2 id=\"Étape-3-—-gestion-du-service-mongodb\">Étape 3 — Gestion du service MongoDB</h2>\n\n<p>Comme mentionné précédemment, le processus d'installation décrit à l'Étape 1 configure MongoDB pour qu'il s'exécute en tant que service <code>systemd</code>. Cela signifie que vous pouvez le gérer en utilisant des commandes standard <code>systemctl</code> comme vous le feriez avec d'autres services système Ubuntu.</p>\n\n<p>Comme mentionné précédemment, la commande <code>systemctl status</code> vérifie l'état du service MongoDB :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl status mongod\n</li></ul></code></pre>\n<p>Vous pouvez arrêter le service à tout moment en tapant :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop mongod\n</li></ul></code></pre>\n<p>Pour lancer le service lorsque celui-ci est arrêté, exécutez :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mongod\n</li></ul></code></pre>\n<p>Vous pouvez également redémarrer le serveur lorsque celui-ci est déjà en cours d'exécution :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mongod\n</li></ul></code></pre>\n<p>Dans l'Étape 2, vous avez permis à MongoDB de démarrer automatiquement avec le serveur. Si jamais vous souhaitez désactiver ce démarrage automatique, tapez :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl disable mongod\n</li></ul></code></pre>\n<p>Ensuite, pour le réactiver au démarrage, exécutez à nouveau la commande <code>enable</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mongod\n</li></ul></code></pre>\n<p>Pour plus d'informations sur la gestion des services <code>systemd</code>, consultez <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\">les Essentiels de Systemd : Travailler avec les services, les unités et le journal</a>.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans ce tutoriel, vous avez ajouté le référentiel officiel de MongoDB à votre instance APT, et installé la dernière version de MongoDB. Vous avez ensuite testé les fonctionnalités de Mongo et avez pratiqué certaines commandes <code>systemctl</code>.</p>\n\n<p>Comme prochaine étape immédiate, nous vous recommandons <strong>fortement</strong> de durcir la sécurité de votre installation MongoDB en suivant notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-mongodb-on-ubuntu-20-04\">Comment sécuriser MongoDB sur Ubuntu 20.04</a>. Une fois sécurisé, vous pouvez alors <a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-remote-access-for-mongodb-on-ubuntu-20-04\">configurer MongoDB pour accepter des connexions distantes</a>.</p>\n\n<p>Vous pouvez trouver d'autres tutoriels sur la façon de configurer et d'utiliser MongoDB dans <a href=\"https://www.digitalocean.com/community/search?q=mongodb\">ces articles publiés par la communauté DigitalOcean.</a> Nous vous encourageons également à consulter la <a href=\"https://docs.mongodb.com/manual/\">documentation officielle de MongoDB</a>, car il s'agit là d'une excellente ressource sur les possibilités offertes par MongoDB.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:06 +0000","feedId":8037,"bgimg":"","linkMd5":"49c13880ef27a36120780ba841930fe8","bgimgJsdelivr":"","metaImg":"","author":"Mark Drake","publishedOrCreatedDate":1598860106976},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo crear un bot de Discord con Node.js","link":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-es","description":"<p><em>El autor seleccionó <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> para recibir una donación como parte del programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introducción\">Introducción</h3>\n\n<p><a href=\"https://discord.com/\">Discord</a> es una aplicación de chat que permite a millones de usuarios de todo el mundo transmitir mensajes y voz en línea en comunidades llamadas <a href=\"https://discord.com/developers/docs/resources/guild\">gremios</a> o servidores. Discord también proporciona una amplia API que los desarrolladores pueden usar para crear potentes bots de Discord. Los bots pueden realizar diversas acciones, como enviar mensajes a servidores, mensajes directos a usuarios, moderar servidores y reproducir audio en los chats de voz. Esto permite a los desarrolladores crear bots potentes que incluyen funciones avanzadas y complejas como herramientas de moderación o, incluso, juegos. Por ejemplo, el bot de utilidad <a href=\"https://dyno.gg/bot\">Dyno</a> sirve a millones de gremios y contiene características útiles como la protección contra spam, un reproductor de música y otras funciones útiles. Aprender a crear bots de Discord le permite implementar muchas posibilidades, con las que miles de personas podrían interactuar cada día.</p>\n\n<p>En este tutorial, creará un bot de Discord desde cero, usando <a href=\"https://nodejs.org/en/\">Node.js</a> y la biblioteca de <a href=\"https://discord.js.org/#/\">Discord.js</a>, que permite a los usuarios interactuar directamente con la API de Discord. Configurará un perfil para un bot de Discord, obtendrá tokens de autenticación para el bot y lo programará con la capacidad de procesar comandos con argumentos, desde los usuarios.</p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Para comenzar, necesitará lo siguiente:</p>\n\n<ul>\n<li><p>Node.js instalado en su equipo de desarrollo. Para instalarlo en macOS o Ubuntu 18.04, siga los pasos de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">Cómo instalar Node.js y crear un entorno de desarrollo local en macOS</a> o las indicaciones de la sección <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">Instalación con un PPA</a>, de <strong>Cómo instalar Node.js en Ubuntu 18.04</strong>.</p></li>\n<li><p>Cualquier editor de texto que elija, como <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>, <a href=\"https://atom.io\">Atom</a>, <a href=\"https://www.sublimetext.com/\">Sublime</a> o <a href=\"https://www.nano-editor.org/\">Nano</a>.</p></li>\n<li><p>Una <a href=\"https://discord.com/register\">cuenta de Discord gratuita</a> con una cuenta de correo electrónico verificada y un <a href=\"https://support.discord.com/hc/en-us/articles/204849977-How-do-I-create-a-server-\">servidor de Discord gratuito</a> que utilizará para probar su bot de Discord.</p></li>\n</ul>\n\n<h2 id=\"paso-1-configurar-un-bot-de-discord\">Paso 1: Configurar un bot de Discord</h2>\n\n<p>En este paso, utilizará la GUI de desarrolladores de Discord para configurar un bot de Discord y obtener el token de bot, que pasará a su programa.</p>\n\n<p>Para registrar un bot en la plataforma Discord, utilice el <a href=\"https://discord.com/developers/applications/\">panel de aplicación de Discord</a>. Aquí los desarrolladores pueden crear aplicaciones de Discord incluyendo bots de Discord.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png\" alt=\"Imagen del panel de aplicación de Discord después de visitar https://discord.com/developers/applications primero\"></p>\n\n<p>Para comenzar, haga clic en <strong>Nueva aplicación</strong>. Discord le solicitará que introduzca un nombre para su nueva aplicación. A continuación, haga clic en <strong>Crear</strong> para crear la aplicación.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1b.png\" alt='Imagen del mensaje para crear una aplicación, con \"Test Node.js Bot\" como el nombre de la aplicación'></p>\n\n<p><span class='note'><strong>Nota:</strong> El nombre de su aplicación es independiente del nombre del bot, y el bot no tiene el mismo nombre que la aplicación.<br></span></p>\n\n<p>Ahora, abra el panel de su aplicación. Para agregar un bot a la aplicación, diríjase a la pestaña <strong>Bot</strong> en la barra de navegación a la izquierda.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1c.png\" alt=\"Imagen de la pestaña bot del panel de aplicación\"></p>\n\n<p>Haga clic en el botón <strong>Añadir bot</strong> para agregar un bot a la aplicación. Haga clic en el botón <strong>Sí, ¡hazlo!</strong> cuando le pida la confirmación. A continuación, estará en un panel que contiene detalles sobre el nombre de su bot, el token de autenticación y la imagen de perfil.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1d.png\" alt=\"Panel que contiene detalles de su bot\"></p>\n\n<p>Puede modificar el nombre o la imagen de su bot, aquí, en el panel. También necesita copiar el token de autenticación del bot haciendo clic en <strong>Haga clic para mostrar Token</strong> y copiando el token que aparece.</p>\n\n<p><span class='warning'><strong>Advertencia:</strong> Nunca comparta ni suba su token de bot, ya que permite a cualquier persona iniciar sesión en su bot.<br></span></p>\n\n<p>Ahora, necesita crear una invitación que le permita agregar los gremios de Discord del bot donde puede probar el bot. Primero, vaya a la pestaña <strong>OAuth2</strong> del panel de aplicación. Para crear una invitación, desplácese hacia abajo y seleccione <strong>bot</strong> en <strong>alcances</strong>. También debe establecer permisos para controlar las acciones que puede realizar su bot en los gremios. A los efectos de este tutorial, seleccione <strong>Administrador</strong>, que le dará a su bot permiso para realizar casi todas las acciones en los gremios. Copie el enlace con el botón <strong>Copiar</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1e.png\" alt='Pestaña OAuth2, con el alcance configurado en \"bot\" y permisos establecidos en \"administrador\"'></p>\n\n<p>A continuación, añada el bot a un servidor. Siga el enlace de invitación que acaba de crear. Puede agregar el bot a cualquier servidor que posea, o en el que tenga permisos de administrador, desde el menú desplegable.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1f.png\" alt=\"Página desde el siguiente enlace de invitación, que permite a los usuarios agregar el bot a los servidores\"></p>\n\n<p>Ahora haga clic en <strong>Continuar</strong>. Asegúrese de tener marcada la casilla junto a <strong>Administrador</strong>: esto concederá los permisos de administrador de bot. A continuación, haga clic en <strong>Autorizar</strong>. Discord le solicitará que resuelva un <a href=\"https://en.wikipedia.org/wiki/CAPTCHA\">CAPTCHA</a> antes de que el bot se una al servidor. Ahora, tendrá el bot de Discord en la lista de miembros en el servidor al que añadió el bot debajo de <strong>sin conexión</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1g.png\" alt='Lista de miembros de un servidor de Discord con el bot recientemente creado en la sección \"sin conexión\" de la lista de miembros'></p>\n\n<p>Ha creado correctamente un bot de Discord y lo ha añadido a un servidor. A continuación, escribirá un programa para iniciar sesión en el bot.</p>\n\n<h2 id=\"paso-2-crear-su-proyecto\">Paso 2: Crear su proyecto</h2>\n\n<p>En este paso, configurará el entorno de codificación básico donde creará su bot e iniciará sesión en el bot de forma programática.</p>\n\n<p>Primero, debe configurar una carpeta de proyecto y los archivos de proyecto necesarios para el bot.</p>\n\n<p>Cree su carpeta de proyecto:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Vaya a la carpeta de proyecto que acaba de crear:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>A continuación, utilice su editor de texto para crear un archivo llamado <code>config.json</code> para almacenar el token de autenticación de su bot:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano config.json\n</li></ul></code></pre>\n<p>A continuación, añada el siguiente código al archivo config, sustituyendo el texto resaltado por el token de autenticación de su bot:</p>\n<div class=\"code-label \" title=\"config.json\">config.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">{\n    \"BOT_TOKEN\": \"<span class=\"highlight\">YOUR BOT TOKEN</span>\"\n}\n</code></pre>\n<p>Guarde el archivo y ciérrelo.</p>\n\n<p>A continuación, creará un archivo <code>package.json</code> que almacenará los detalles de su proyecto e información sobre las dependencias que utilizará para el proyecto. Creará un archivo <code>package.json</code> ejecutando el siguiente comando <code>npm</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm init\n</li></ul></code></pre>\n<p><code>npm</code> le solicitará varios datos sobre su proyecto. Si desea obtener información sobre cómo completar las preguntas, puede leer sobre ellos en <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-node-js-modules-with-npm-and-package-json#step-1-%E2%80%94-creating-a-packagejson-file\">Cómo usar módulos Node.js con npm y package.json</a>.</p>\n\n<p>Ahora, instalará el paquete <code>discord.js</code> que utilizará para interactuar con la API de Discord. Puede instalar <code>discord.js</code> a través de npm con el siguiente comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm install discord.js\n</li></ul></code></pre>\n<p>Ahora ha configurado el archivo de configuración y ha instalado la dependencia necesaria, está listo para comenzar a crear su bot. En una aplicación en el mundo real, un bot grande se dividiría en muchos archivos, pero a efectos de este tutorial, el código para su bot estará en un solo archivo.</p>\n\n<p>Primero, cree un archivo llamado <code>index.js</code> en la carpeta <code><span class=\"highlight\">discord-bot</span></code> para el código:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Comience a codificar el bot pidiendo la dependencia de <code>discord.js</code> y el archivo config con el token de bot:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n</code></pre>\n<p>A continuación, añada las siguientes dos líneas de código:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Guarde y cierre su archivo.</p>\n\n<p>La primera línea de código crea un nuevo <code>Discord.Client</code> y lo asigna a la constante <code>client</code>. Este cliente es en parte cómo interactúa con la API de Discord y cómo le notificará eventos como mensajes nuevos. El cliente, en efecto, representa el bot de Discord.</p>\n\n<p>La segunda línea de código utiliza el método <code>login</code> en <code>client</code> para iniciar sesión en el bot de Discord que creó, usando el token en el archivo <code>config.json</code> como contraseña. El token permite a la API de Discord saber para qué bot es el programa y que está autenticado para usar el bot.</p>\n\n<p>Ahora, ejecute el archivo <code>index.js</code> usando Node:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>El estado de su bot cambiará a &ldquo;en línea&rdquo; en el servidor de Discord al que lo añadió.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step2a.png\" alt=\"Imagen del bot en línea\"></p>\n\n<p>Ha configurado correctamente un entorno de codificación y ha creado el código básico para iniciar sesión en un bot de Discord. En el siguiente paso, manejará los comandos de usuario y hará que su bot realice acciones, como enviar mensajes.</p>\n\n<h2 id=\"paso-3-cómo-manejar-su-primer-comando-de-usuario\">Paso 3: Cómo manejar su primer comando de usuario</h2>\n\n<p>En este paso, creará un bot que puede manejar los comandos de usuario. Implementará su primer comando de <code>ping</code>, que responderá con <code>\"pong\"</code> y el tiempo que toma para responder al comando.</p>\n\n<p>Primero, necesita detectar y recibir cualquier mensaje que los usuarios envíen, para que pueda procesar cualquier comando. Con el método <code>on</code> en el cliente de Discord, Discord le enviará una notificación sobre eventos nuevos. El método <code>on</code> toma dos argumentos: el nombre de un evento a esperar y una función a ejecutar cada vez que se produce ese evento. Con este método, puede esperar el evento <code>message</code>: se producirá cada vez que se envía un mensaje a un gremio donde el bot tiene permiso para ver mensajes. Por tanto, vamos a crear una función, que se ejecuta cada vez que se envía un mensaje, para procesar comandos.</p>\n\n<p>Primero, abra su archivo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Añada el siguiente código a su archivo:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\n\n<span class=\"highlight\">client.on(\"message\", function(message) { </span>\n<span class=\"highlight\">                                         </span>\n<span class=\"highlight\">});                                      </span>\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Esta función, que se ejecuta en el evento <code>message</code>, toma <code>message</code> como un parámetro. <code>message</code> tendrá el valor de una instancia de <a href=\"https://discord.js.org/#/docs/main/stable/class/Message\">mensaje de Discord.js</a>, que contiene información sobre el mensaje enviado y los métodos para ayudar a responder al bot.</p>\n\n<p>Ahora, añada la siguiente línea de código a su función de manejo de comandos:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  <span class=\"highlight\">if (message.author.bot) return;</span>\n});\n...\n</code></pre>\n<p>Esta línea comprueba si el autor del mensaje es un bot y, si es así, deja de procesar el comando. Esto es importante, ya que generalmente no quiere procesar o responder a los mensajes de bots. Por lo general, los bots no necesitan o no quieren usar nuestro bot, por lo que ignorar sus mensajes ahorra potencia de procesamiento y ayuda a evitar respuestas accidentales.</p>\n\n<p>Ahora, escribirá un controlador de comandos. Para ello, es bueno entender el formato habitual de un comando de Discord. Normalmente, la estructura de un comando de Discord contiene tres partes en el siguiente orden: un prefijo, un nombre de comando y (a veces) argumentos de comandos.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png\" alt='Una imagen de un comando típico de Discord que se lee \"! add 1 2\"'></p>\n\n<ul>\n<li><p>Prefijo: el prefijo puede ser cualquier cosa, pero, por lo general, es un signo de puntuación o una frase abstracta que normalmente no estaría al principio de un mensaje. Esto significa que, cuando incluya el prefijo al inicio del mensaje, el bot sabrá que la intención de este comando es para que un bot lo procese.</p></li>\n<li><p>Nombre de comando: el nombre del comando que el usuario quiere usar. Esto significa que el bot puede soportar múltiples comandos con diferentes funciones y permitir a los usuarios elegir entre ellos al proporcionar un nombre de comando diferente.</p></li>\n<li><p>Argumentos: a veces, si el comando requiere o utiliza información adicional del usuario, este puede proporcionar argumentos después del nombre de comando, con cada argumento separado por un espacio.</p></li>\n</ul>\n\n<p><span class='note'><strong>Nota:</strong> No hay estructura de comandos forzada, y los bots pueden procesar los comandos como quieran, pero la estructura que se presenta aquí es una estructura eficiente que la gran mayoría de bots utilizan.<br></span></p>\n\n<p>Para comenzar a crear un analizador sintáctico de comandos que maneje este formato, añada las siguientes líneas de código a la función de manejo de mensajes:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n<span class=\"highlight\">const prefix = \"!\";</span>\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  <span class=\"highlight\">if (!message.content.startsWith(prefix)) return;</span>\n});\n...\n</code></pre>\n<p>Añada la primera línea de código para asignar el valor <code>\"!\"</code> a la constante <code>prefix</code>, que utilizará como prefijo del bot.</p>\n\n<p>La segunda línea de código que añade comprueba si el contenido del mensaje que el bot está procesando comienza con el prefijo que configuró y, si no lo hace, deja de procesarlo.</p>\n\n<p>Ahora, debe convertir el resto del mensaje en un nombre de comando y cualquier argumento que pueda existir en el mensaje. Añada las siguientes líneas resaltadas:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  <span class=\"highlight\">const commandBody = message.content.slice(prefix.length);</span>\n  <span class=\"highlight\">const args = commandBody.split(' ');</span>\n  <span class=\"highlight\">const command = args.shift().toLowerCase();</span>\n});\n...\n</code></pre>\n<p>Utilice la primera línea aquí para eliminar el prefijo del contenido de mensaje y asignar el resultado a la constante <code>commandBody</code>. Esto es necesario, ya que no quiere incluir el prefijo en el nombre de comando analizado.</p>\n\n<p>La segunda línea toma el mensaje con el prefijo eliminado y utiliza el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-index-split-and-manipulate-strings-in-javascript#splitting-strings\">método <code>split</code></a> en él, con un espacio como separador. Esto lo divide en una matriz de subcadenas y hace una división dondequiera que haya un espacio. Esto crea una matriz que contiene el nombre de comando y, por tanto, si se incluye en el mensaje, cualquier argumento. Asigna esta matriz a la constante <code>args</code>.</p>\n\n<p>La tercera línea elimina el primer elemento de la matriz de <code>args</code> (que será el nombre de comando que se proporciona), lo convierte en minúscula y, luego, lo asigna a la constante <code>command</code>. Esto le permite aislar el nombre de comando y dejar solo argumentos en la matriz. También utiliza el método <code>toLowerCase</code>, ya que los comandos no suelen distinguir entre minúsculas y mayúsculas en bots de Discord.</p>\n\n<p>Completó la construcción de un analizador de comandos, implementó un prefijo requerido y obtuvo el nombre de comando y cualquier argumento de los mensajes. Ahora, implementará y creará el código para los comandos específicos.</p>\n\n<p>Añada el siguiente código para comenzar a implementar el comando <code>ping</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  <span class=\"highlight\">if (command === \"ping\") {</span>\n  <span class=\"highlight\">                         </span>\n  <span class=\"highlight\">}                        </span>\n});\n...\n</code></pre>\n<p>Esta <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-conditional-statements-in-javascript\">instrucción <code>if</code></a> comprueba si el nombre de comando que analizó (asignado a la constante <code>command</code>) coincide con <code>\"ping\"</code>. Si lo hace, indica que el usuario quiere usar el comando <code>\"ping\"</code>. Anidará el código para el comando específico dentro del bloque de instrucción <code>if</code>. Repetirá este patrón para otros comandos que desee implementar.</p>\n\n<p>Ahora, puede implementar el código para el comando <code>\"ping\"</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    <span class=\"highlight\">const timeTaken = Date.now() - message.createdTimestamp;</span>\n    <span class=\"highlight\">message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);</span>\n  }\n...\n</code></pre>\n<p>Guarde y cierre su archivo.</p>\n\n<p>Añada el bloque de comandos <code>\"ping\"</code> que calcula la diferencia entre el tiempo actual, que se encuentra usando el <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now\">método <code>now</code></a> en el objeto <code>Date</code> y la marca de tiempo cuando el mensaje se creó en milisegundos. Esto calcula cuánto tiempo tardó el mensaje en procesarse y el <code>\"ping\"</code> del bot.</p>\n\n<p>La segunda línea responde al comando del usuario usando el método <code>reply</code> en la constante <code>message</code>. El <a href=\"https://discord.js.org/#/docs/main/stable/class/Message?scrollTo=reply\">método <code>reply</code></a> avisa (que notifica al usuario e indica el mensaje para el usuario especificado) al usuario que invocó el comando, seguido por el contenido proporcionado como el primer argumento al método. Proporciona una <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">plantilla literal</a> que contiene un mensaje y el ping calculado como la respuesta que el método <code>reply</code> utilizará.</p>\n\n<p>Esto concluye la implementación del comando <code>\"ping\"</code>.</p>\n\n<p>Ejecute su bot usando el siguiente comando (en la misma carpeta que <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Ahora puede usar el comando <code>\"! ping\"</code> en cualquier canal que el bot pueda ver y enviar un mensaje, lo que resulta en una respuesta.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png\" alt='Imagen de bot replicando en Discord a \"! ping\" con \"@T0M, Pong! This message had a latency of 1128ms.\" '></p>\n\n<p>Ha creado correctamente un bot que puede manejar los comandos de usuario y ha implementado su primer comando. En el siguiente paso, continuará desarrollando su bot implementando un comando sum.</p>\n\n<h2 id=\"paso-4-cómo-implementar-el-comando-sum\">Paso 4: Cómo implementar el comando sum</h2>\n\n<p>Ahora, extenderá su programa implementando el comando <code>\"! sum\"</code>. El comando tomará cualquier número de argumentos y los agregará juntos, antes de devolver la suma de todos los argumentos al usuario.</p>\n\n<p>Si su bot de Discord aún se está ejecutando, puede detener su proceso con <code>CTRL + C</code>.</p>\n\n<p>Abra su archivo <code>index.js</code> de nuevo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Para comenzar a implementar el comando <code>\"! sum\"</code>, usará un bloque <code>else-if</code>. Después de comprobar el nombre de comando ping, comprobará si el nombre de comando es igual a <code>\"sum\"</code>. Usamos un bloque <code>else-if</code>, ya que solo un comando se procesará a la vez, de forma que si el programa coincide con el nombre de comando <code>\"ping\"</code>, no tiene que verificar el comando <code>\"sum\"</code>. Añada las siguientes líneas resaltadas a su archivo:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Ping! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  <span class=\"highlight\">else if (command === \"sum\") {</span>\n  <span class=\"highlight\">                             </span>\n  <span class=\"highlight\">}                            </span>\n});\n...\n</code></pre>\n<p>Puede comenzar a implementar el código para el comando <code>\"sum\"</code>. El código para el comando <code>\"sum\"</code> entrará en el bloque <code>else-if</code> que acaba de crear. Ahora, añada el siguiente código:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  else if (command === \"sum\") {\n    <span class=\"highlight\">const numArgs = args.map(x =&gt; parseFloat(x));</span>\n    <span class=\"highlight\">const sum = numArgs.reduce((counter, x) =&gt; counter += x);</span>\n    <span class=\"highlight\">message.reply(`The sum of all the arguments you provided is ${sum}!`);</span>\n  }\n...\n</code></pre>\n<p>Utilice el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#map()\">método <code>map</code></a> de la lista de argumentos para crear una nueva lista usando la función <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseFloat\"><code>parseFloat</code></a> en cada elemento de la matriz de <code>args</code>. Esto crea una nueva matriz (asignada a la constante <code>numArgs</code>) en la que todos los elementos son números en vez de cadenas. Esto significa que más tarde puede encontrar correctamente la suma de los números sumándolos.</p>\n\n<p>La segunda línea utiliza el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#reduce()\">método <code>reduce</code></a> en la constante <code>numArgs</code> que proporcionan una función que suma todos los elementos de la lista. Asignó la suma de todos los elementos en <code>numArgs</code> a la constante <code>sum</code>.</p>\n\n<p>A continuación, utilice el método <code>reply</code> en el objeto de mensaje para responder al comando del usuario con una <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">plantilla literal</a>, que contiene la suma de todos los argumentos que el usuario envía al bot.</p>\n\n<p>Esto concluye la implementación del comando <code>\"sum\"</code>. Ahora, ejecute su bot usando el siguiente comando (en la misma carpeta que <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Ahora, puede usar el comando <code>\"! sum\"</code> en cualquier canal que pueda ver el bot y enviar mensajes.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step4a.png\" alt='Imagen del bot respondiendo \"The sum of all the arguments you provided is 6!\" a \"! sum 12 3\" y, luego, respondiendo \"The sum of all the arguments you provided is 13! a \"! sum 1.5 1.5 10\"'></p>\n\n<p>A continuación, se muestra una versión completa de la secuencia de comandos del bot <code>index.js</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n\nconst client = new Discord.Client();\n\nconst prefix = \"!\";\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  const commandBody = message.content.slice(prefix.length);\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  else if (command === \"sum\") {\n    const numArgs = args.map(x =&gt; parseFloat(x));\n    const sum = numArgs.reduce((counter, x) =&gt; counter += x);\n    message.reply(`The sum of all the arguments you provided is ${sum}!`);\n  }\n});\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>En este paso, ha desarrollado aún más su bot de Discord implementando el comando <code>sum</code>.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>Ha implementado correctamente un bot de Discord que puede manejar varios comandos de usuario y argumentos de comandos. Si desea ampliar su bot, posiblemente pueda implementar más comandos o probar más partes de la API de Discord para crear un bot de Discord potente. Puede revisar la <a href=\"https://discord.js.org/#/docs/main/stable/general/welcome\">documentación de Discord.js</a> o la <a href=\"https://discord.com/developers/docs/intro\">documentación de la API de Discord</a> para ampliar sus conocimiento de la API de Discord.</p>\n\n<p>Al crear bots de Discord, siempre debe tener en cuenta los <a href=\"https://discord.com/developers/docs/legal\">términos de servicio de la API de Discord</a>, que describe cómo los desarrolladores deben usarla. También puede leer <a href=\"https://github.com/meew0/discord-bot-best-practices/blob/master/README.md\">este conjunto de directrices</a> sobre cómo implementar mejor un bot de Discord y proporciona consejos sobre cómo diseñar bots de Discord. Si desea obtener más información sobre Node.js consulte nuestra <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">serie Cómo crear códigos en Node.js</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:24 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png","linkMd5":"ab8fbde9c723d68d66c86e37d72bf25d","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","destWidth":1920,"destHeight":973,"sourceBytes":66395,"destBytes":26384,"author":"Tom","articleImgCdnMap":{"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1b.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn9@2020_3/2020/08/31/07-48-31-275_690c64ccbc0c5170.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1c.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn30@2020_4/2020/08/31/07-48-31-778_f5a474e22c90438c.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1d.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_6/2020/08/31/07-48-31-392_d550c10707834d3f.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1e.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/31/07-48-31-921_817dcbabd0b27a3d.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1f.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn89@2020_2/2020/08/31/07-48-31-288_1d3824d3640df0a3.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1g.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn77@2020_3/2020/08/31/07-48-31-225_5aca524b04a26500.webp","https://assets.digitalocean.com/articles/node_discord_bot/step2a.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn74@2020_2/2020/08/31/07-48-31-293_81968c3f6c9ff261.webp","https://assets.digitalocean.com/articles/node_discord_bot/step3a.png":null,"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn98@2020_5/2020/08/31/07-48-33-506_74310bb53d7bafb2.webp","https://assets.digitalocean.com/articles/node_discord_bot/step4a.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn70@2020_4/2020/08/31/07-48-31-272_5589082ccebd5fbf.webp"},"publishedOrCreatedDate":1598860106986},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment utiliser ThreadPoolExecutor en Python 3","link":"https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3-fr","description":"<p><em>L'auteur a choisi le <a href=\"https://www.brightfunds.org/funds/write-for-donations-covid-19-relief-fund\">COVID-19 Relief Fund</a> pour recevoir un don dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Les <em>threads</em> <a href=\"https://www.python.org/\">Python</a> sont une forme de parallélisme qui permet à votre programme d'exécuter plusieurs procédures à la fois. Le parallélisme en Python peut également être réalisé en utilisant des processus multiples, mais les threads sont particulièrement bien adaptés pour accélérer les applications qui impliquent des quantités importantes d'entrées/sorties (input/output).</p>\n\n<p>Les <a href=\"https://en.wikipedia.org/wiki/I/O_bound#:%7E:text=In%20computer%20science%2C%20I%2FO,a%20task%20being%20CPU%20bound.\">opérations liées aux entrées/sorties</a> comprennent, par exemple, les requêtes web et la lecture des données des fichiers. Contrairement aux opérations liées aux entrées/sorties, <a href=\"https://en.wikipedia.org/wiki/CPU-bound\">les opérations liées au CPU</a> (comme l'exécution de calculs mathématiques avec la bibliothèque standard Python) ne bénéficieront pas beaucoup des threads Python.</p>\n\n<p>Python 3 inclut l'utilitaire <code>ThreadPoolExecutor</code> pour exécuter du code dans un thread.</p>\n\n<p>Au cours de ce tutoriel, nous utiliserons <code>ThreadPoolExecutor</code> pour effectuer rapidement des requêtes réseau. Nous allons définir une fonction bien adaptée à l'invocation dans les threads, utiliser <code>ThreadPoolExecutor</code> pour exécuter cette fonction, et traiter les résultats de ces exécutions.</p>\n\n<p>Pour ce tutoriel, nous allons faire des requêtes réseau pour vérifier l'existence de pages <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipédia</a>.</p>\n\n<p><span class='note'><strong>Note :</strong> le fait que les opérations liées aux entrées/sorties bénéficient davantage des threads que les opérations liées au CPU est causé par une idiosyncrasie en Python appelée <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\"><em>verrouillage global de l'interpréteur</em></a>. Si vous le souhaitez, vous pouvez en apprendre davantage sur le verrouillage global de l'interpréteur de Python <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">dans la documentation officielle de Python</a>.<br></span></p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Pour tirer le meilleur parti de ce tutoriel, il est recommandé de se familiariser avec la programmation en Python et d'avoir un environnement de programmation Python local avec des <code>requêtes</code> installé.</p>\n\n<p>Vous pouvez consulter ces tutoriels pour obtenir les informations de base nécessaires :</p>\n\n<ul>\n<li><a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-python-3\">Comment coder en Python 3</a></li>\n<li><p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">Comment installer Python 3 et configurer un environnement de programmation local sur Ubuntu 18.04</a></p></li>\n<li><p>Pour installer le paquet <code>requests</code> dans votre <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-18-04\">environnement de programmation Python local</a>, vous pouvez exécuter cette commande :</p></li>\n</ul>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">pip install --user requests==2.23.0\n</li></ul></code></pre>\n<h2 id=\"Étape-1-—-définition-d-39-une-fonction-à-exécuter-en-threads\">Étape 1 — Définition d'une fonction à exécuter en threads</h2>\n\n<p>Commençons par définir une fonction que nous aimerions exécuter à l'aide de threads.</p>\n\n<p>En utilisant <code>nano</code> ou votre éditeur de texte/environnement de développement préféré, vous pouvez ouvrir ce fichier :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano wiki_page_function.py\n</li></ul></code></pre>\n<p>Pour ce tutoriel, nous allons écrire une fonction qui détermine si une page Wikipédia existe ou non :</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n</code></pre>\n<p>La <a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-python-3\">fonction</a> <code>get_wiki_page_existence</code> accepte deux arguments : une URL vers une page Wikipédia (<code>wiki_page_url</code>), et un <code>timeout</code>  de quelques secondes pour obtenir une réponse de cette URL.</p>\n\n<p><code>get_wiki_page_existence</code> utilise le paquet <a href=\"https://requests.readthedocs.io/en/master/\"><code>requests</code></a> pour faire une requête web à cette URL. En fonction du <a href=\"https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes\">code d'état</a> de la <code>response</code> HTTP, une chaîne de caractères qui décrit si la page existe ou non est renvoyée. Les différents codes d'état représentent les différents résultats d'une requête HTTP. Cette procédure suppose qu'un code d'état <code>200</code> &ldquo;réussi&rdquo; signifie que la page Wikipédia existe, et qu'un code d'état <code>404</code> &ldquo;non trouvé&rdquo; signifie que la page Wikipédia n'existe pas.</p>\n\n<p>Comme décrit dans la section Prérequis, vous aurez besoin du paquet <code>requests</code> installé pour exécuter cette fonction.</p>\n\n<p>Essayons d'exécuter la fonction en ajoutant l&rsquo;<code>url</code> et l'appel de fonction après la fonction <code>get_wiki_page_existence</code> :</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">. . .\nurl = \"https://en.wikipedia.org/wiki/Ocean\"\nprint(get_wiki_page_existence(wiki_page_url=url))\n</code></pre>\n<p>Une fois que vous avez ajouté le code, enregistrez et fermez le fichier.</p>\n\n<p>Si nous exécutons ce code :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Nous verrons une sortie comme celle-ci :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Ocean - exists\n</code></pre>\n<p>L'appel de la fonction <code>get_wiki_page_existence</code> avec une page Wikipédia valide renvoie une chaîne de caractères qui confirme que la page existe bel et bien.</p>\n\n<p><span class='warning'><strong>Avertissement :</strong> en général, il n'est pas sûr de partager des objets ou des états Python entre les threads sans prendre un soin particulier pour éviter les bogues de concurrence. Lors de la définition d'une fonction à exécuter dans un thread, il est préférable de définir une fonction qui effectue un seul travail et qui ne partage ni ne publie l'état à d'autres threads. <code>get_wiki_page_existence</code> est un exemple d'une telle fonction.<br></span></p>\n\n<h2 id=\"Étape-2-—-utilisation-de-threadpoolexecutor-pour-exécuter-une-fonction-dans-threads\">Étape 2 — Utilisation de ThreadPoolExecutor pour exécuter une fonction dans Threads</h2>\n\n<p>Maintenant que nous disposons d'une fonction bien adaptée à l'invocation avec des threads, nous pouvons utiliser <code>ThreadPoolExecutor</code> pour effectuer de multiples invocations de cette fonction de manière opportune.</p>\n\n<p>Ajoutons le code surligné suivant à votre programme dans <code>wiki_page_function.py</code> :</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\n<span class=\"highlight\">import concurrent.futures</span>\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Ocean\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Island\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/this_page_does_not_exist\",</span>\n    <span class=\"highlight\">\"https://en.wikipedia.org/wiki/Shark\",</span>\n<span class=\"highlight\">]</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n</code></pre>\n<p>Voyons comment ce code fonctionne :</p>\n\n<ul>\n<li><code>concurrent.futures</code> est importé pour nous donner accès à <code>ThreadPoolExecutor</code>.</li>\n<li>Un énoncé <code>with</code> est utilisé pour créer un <code>executor</code>d'instance <code>ThreadPoolExecutor</code> qui nettoiera rapidement les threads dès leur achèvement.</li>\n<li>Quatre emplois sont <code>submitted</code> à l&rsquo;<code>executor</code> : un pour chacune des URL de la liste <code>wiki_page_urls</code>.</li>\n<li>Chaque appel à <code>submit</code> renvoie une <a href=\"https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future\">instance <code>Future</code></a> qui est stockée dans la liste <code>futures</code>.</li>\n<li>La fonction <code>as_completed</code> attend que chaque appel <code>Future</code> <code>get_wiki_page_existence</code> soit terminé pour que nous puissions imprimer son résultat.</li>\n</ul>\n\n<p>Si nous exécutons à nouveau ce programme, avec la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python wiki_page_function.py\n</li></ul></code></pre>\n<p>Nous verrons une sortie comme celle-ci :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>https://en.wikipedia.org/wiki/Island - exists\nhttps://en.wikipedia.org/wiki/Ocean - exists\nhttps://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\nhttps://en.wikipedia.org/wiki/Shark - exists\n</code></pre>\n<p>Cette sortie est logique : 3 des URLs sont des pages Wikipédia valides, et l'une d'entre elles, <code>this_page_does_not_exist</code>, ne l'est pas. Notez que votre sortie peut être ordonnée différemment de cette sortie. Dans cet exemple, la fonction <code>concurrent.futures.as_completed</code> renvoie les résultats dès qu'ils sont disponibles, quel que soit l'ordre dans lequel les emplois ont été soumis.</p>\n\n<h2 id=\"Étape-3-—-traitement-des-exceptions-aux-fonctions-exécutées-dans-threads\">Étape 3 — Traitement des exceptions aux fonctions exécutées dans Threads</h2>\n\n<p>Au cours de l'étape précédente, <code>get_wiki_page_existence</code> a réussi à retourner une valeur pour toutes nos invocations. Dans cette étape, nous verrons que <code>ThreadPoolExecutor</code> peut également lever les exceptions générées dans les invocations de fonctions threadées.</p>\n\n<p>Considérons l'exemple de bloc de code suivant :</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n\nwiki_page_urls = [\n    \"https://en.wikipedia.org/wiki/Ocean\",\n    \"https://en.wikipedia.org/wiki/Island\",\n    \"https://en.wikipedia.org/wiki/this_page_does_not_exist\",\n    \"https://en.wikipedia.org/wiki/Shark\",\n]\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(</span>\n            <span class=\"highlight\">executor.submit(</span>\n                <span class=\"highlight\">get_wiki_page_existence, wiki_page_url=url, timeout=0.00001</span>\n            <span class=\"highlight\">)</span>\n        <span class=\"highlight\">)</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">try:</span>\n            <span class=\"highlight\">print(future.result())</span>\n        <span class=\"highlight\">except requests.ConnectTimeout:</span>\n            <span class=\"highlight\">print(\"ConnectTimeout.\")</span>\n</code></pre>\n<p>Ce bloc de code est presque identique à celui que nous avons utilisé à l'étape 2, mais il présente deux différences essentielles :</p>\n\n<ul>\n<li>Nous passons maintenant <code>timeout=0.00001</code> à <code>get_wiki_page_existence</code>. Comme le paquet <code>requests</code> ne pourra pas terminer sa requête web à Wikipedia en <code>0,0000</code>1 seconde, cela entraînera une exc<code>eption Connect</code>Timeout.</li>\n<li>Nous attrapons les exceptions <code>ConnectTimeout</code> soulevées par <code>future.result()</code> et imprimons une chaîne de caractères à chaque fois que nous le faisons.</li>\n</ul>\n\n<p>Si nous relançons le programme, nous obtiendrons la sortie suivante :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>ConnectTimeout.\nConnectTimeout.\nConnectTimeout.\nConnectTimeout.\n</code></pre>\n<p>Quatre messages <code>ConnectTimeout</code> sont imprimés - un pour chacun de nos quatre <code>wiki_page_urls</code>, car aucun d'entre eux n'a pu être terminé en <code>0.00001</code> seconde et chacun des quatre appels <code>get_wiki_page_existence</code> a soulevé l'exception <code>ConnectTimeout</code>.</p>\n\n<p>Vous avez maintenant vu que si un appel de fonction soumis à un <code>ThreadPoolExecutor</code> soulève une exception, cette exception peut être soulevée normalement en appelant <code>Future.result</code>. Appeler <code>Future.result</code> sur toutes vos invocations soumises garantit que votre programme ne manquera aucune exception soulevée par votre fonction threadée.</p>\n\n<h2 id=\"Étape-4-—-comparaison-du-temps-d-39-exécution-avec-et-sans-threads\">Étape 4 — Comparaison du temps d'exécution avec et sans threads</h2>\n\n<p>Maintenant, vérifions que l'utilisation de <code>ThreadPoolExecutor</code> rend réellement votre programme plus rapide.</p>\n\n<p>Tout d'abord, chronométrons <code>get_wiki_page_existence</code> si nous le faisons fonctionner sans threads :</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\"><span class=\"highlight\">import time</span>\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\n\n<span class=\"highlight\">wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]</span>\n\n<span class=\"highlight\">print(\"Running without threads:\")</span>\n<span class=\"highlight\">without_threads_start = time.time()</span>\n<span class=\"highlight\">for url in wiki_page_urls:</span>\n    <span class=\"highlight\">print(get_wiki_page_existence(wiki_page_url=url))</span>\n<span class=\"highlight\">print(\"Without threads time:\", time.time() - without_threads_start)</span>\n</code></pre>\n<p>Dans l'exemple de code, nous appelons notre fonction <code>get_wiki_page_existence</code> avec cinquante URL de pages Wikipédia différentes, une par une. Nous utilisons la fonction <a href=\"https://docs.python.org/3/library/time.html#time.time\"><code>time.time()</code></a> pour imprimer le nombre de secondes qu'il faut pour exécuter notre programme.</p>\n\n<p>Si nous exécutons à nouveau ce code comme auparavant, nous obtiendrons la sortie suivante :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running without threads:\nhttps://en.wikipedia.org/wiki/0 - exists\nhttps://en.wikipedia.org/wiki/1 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nWithout threads time: 5.803015232086182\n</code></pre>\n<p>Les entrées 2–47 dans cette sortie ont été omises par concision.</p>\n\n<p>Le nombre de secondes affiché après <code>Without threads time</code> (Temps écoulé sans threads) sera différent lorsque vous l'exécuterez sur votre machine - ce n'est pas grave, vous obtenez juste un nombre de base à comparer avec une solution qui utilise <code>ThreadPoolExecutor</code>. Dans ce cas, il était de <code>~5.803</code> secondes.</p>\n\n<p>Exécutons les mêmes cinquante URLs de Wikipédia dans <code>get_wiki_page_existence</code>, mais cette fois en utilisant <code>ThreadPoolExecutor</code> :</p>\n<div class=\"code-label \" title=\"wiki_page_function.py\">wiki_page_function.py</div><pre class=\"code-pre \"><code class=\"code-highlight language-python\">import time\nimport requests\nimport concurrent.futures\n\n\ndef get_wiki_page_existence(wiki_page_url, timeout=10):\n    response = requests.get(url=wiki_page_url, timeout=timeout)\n\n    page_status = \"unknown\"\n    if response.status_code == 200:\n        page_status = \"exists\"\n    elif response.status_code == 404:\n        page_status = \"does not exist\"\n\n    return wiki_page_url + \" - \" + page_status\nwiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n\n<span class=\"highlight\">print(\"Running threaded:\")</span>\n<span class=\"highlight\">threaded_start = time.time()</span>\n<span class=\"highlight\">with concurrent.futures.ThreadPoolExecutor() as executor:</span>\n    <span class=\"highlight\">futures = []</span>\n    <span class=\"highlight\">for url in wiki_page_urls:</span>\n        <span class=\"highlight\">futures.append(executor.submit(get_wiki_page_existence, wiki_page_url=url))</span>\n    <span class=\"highlight\">for future in concurrent.futures.as_completed(futures):</span>\n        <span class=\"highlight\">print(future.result())</span>\n<span class=\"highlight\">print(\"Threaded time:\", time.time() - threaded_start)</span>\n</code></pre>\n<p>Le code est le même que celui que nous avons créé à l'étape 2, mais avec l'ajout de quelques énoncés imprimés qui nous indiquent le nombre de secondes qu'il faut pour exécuter notre code.</p>\n\n<p>Si nous relançons le programme, nous obtiendrons la sortie suivante :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Running threaded:\nhttps://en.wikipedia.org/wiki/1 - exists\nhttps://en.wikipedia.org/wiki/0 - exists\n. . .\nhttps://en.wikipedia.org/wiki/48 - exists\nhttps://en.wikipedia.org/wiki/49 - exists\nThreaded time: 1.2201685905456543\n</code></pre>\n<p>Là encore, le nombre de secondes imprimées après <code>Threaded time</code> (temps threadé écoulé) sera différent sur votre ordinateur (ainsi que l'ordre de votre sortie).</p>\n\n<p>Vous pouvez maintenant comparer le temps d'exécution pour récupérer les cinquante URLs des pages Wikipédia avec et sans threads.</p>\n\n<p>Sur la machine utilisée dans ce tutoriel, l'exécution sans threads a pris <code>~5.803</code> secondes, et celle avec threads a pris <code>~1.220</code> secondes. Notre programme a fonctionné beaucoup plus rapidement avec les threads.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans ce tutoriel, vous avez appris à utiliser l'utilitaire <code>ThreadPoolExecutor</code> en Python 3 pour exécuter efficacement du code lié aux entrées/sorties. Vous avez créé une fonction bien adaptée à l'invocation dans les threads, appris comment récupérer à la fois la sortie et les exceptions des exécutions threadées de cette fonction, et observé l'augmentation des performances obtenue en utilisant les threads.</p>\n\n<p>De là, vous pouvez en savoir plus sur les autres fonctions de concurrence offertes par le <a href=\"https://docs.python.org/3/library/concurrent.futures.html\">module <code>concurrent.futures</code></a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:46:45 +0000","feedId":8037,"bgimg":"","linkMd5":"90a979418042f60871af2f23901a2b13","bgimgJsdelivr":"","metaImg":"","author":"DavidMuller","publishedOrCreatedDate":1598860106963},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como escalar e proteger um aplicativo Django com o Docker, Nginx e Let's Encrypt","link":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-pt","description":"<h3 id=\"introdução\">Introdução</h3>\n\n<p>Em ambientes baseados em nuvem, existem várias maneiras de dimensionar e proteger um aplicativo <a href=\"https://www.djangoproject.com/\">Django</a>. Ao <em>escalar horizontalmente</em> e executar várias cópias de seu aplicativo, você pode construir um sistema mais tolerante e altamente disponível, ao mesmo tempo em que também aumenta seu <em>rendimento</em> de modo que as solicitações possam ser processadas simultaneamente. Uma maneira de escalar horizontalmente um aplicativo Django é fornecendo <em>servidores de aplicativos</em> adicionais que executem seu aplicativo Django e seu servidor HTTP WSGI (como o <a href=\"https://gunicorn.org/\">Gunicorn</a> ou o <a href=\"https://uwsgi-docs.readthedocs.io/en/latest/\">uWSGI</a>). Para encaminhar e distribuir pedidos recebidos neste conjunto de servidores de aplicativos, você pode usar um <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#load-balancing\">balanceador de carga</a> e um <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">proxy reverso</a> como o <a href=\"https://www.nginx.com/\">Nginx</a>. O Nginx também é capaz de colocar em cache conteúdo estático e encerrar as conexões via <em>protocolo TLS</em>, usadas para providenciar o HTTPS e conexões seguras ao seu aplicativo.</p>\n\n<p>Executar seu aplicativo Django e o proxy Nginx dentro dos <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#container\">contêineres</a> Docker garante que esses componentes se comportem da mesma maneira, independentemente do ambiente em que estão implantados. Além disso, os contêineres proporcionam muitos recursos que facilitam o empacotamento e a configuração do seu aplicativo.</p>\n\n<p>Neste tutorial, você irá escalar horizontalmente um Django e um aplicativo Gunicorn <a href=\"https://docs.djangoproject.com/en/3.0/intro/tutorial01/\">Polls</a> em contêiner fornecendo dois servidores de aplicativos que irão cada um executar uma cópia de um contêiner de aplicativos Django e Gunicorn.</p>\n\n<p>Você também habilitará o HTTPS fornecendo e configurando um terceiro servidor proxy que irá executar um contêiner de proxy reverso Nginx e um contêiner do cliente <a href=\"https://certbot.eff.org/\">Certbot</a>. O Certbot irá fornecer certificados TLS para o Nginx a partir da autoridade de certificação <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>. Isso irá garantir que seu site receba uma alta classificação de segurança do <a href=\"https://www.ssllabs.com/\">SSL Labs</a>. Este servidor proxy receberá todos os pedidos externos do seu aplicativo e se colocará em frente aos dois servidores <em>upstream</em> do aplicativo Django. Por fim, você irá <em>fortalecer</em> esse sistema distribuído restringindo o acesso externo apenas ao servidor de proxy.</p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Para seguir este tutorial, será necessário:</p>\n\n<ul>\n<li><p>Três servidores Ubuntu 18.04:</p>\n\n<ul>\n<li>Dois serão os servidores de <strong>aplicativo</strong>, usados para executar os aplicativos Django e Gunicorn.</li>\n<li>Um servidor será um servidor <strong>proxy</strong>, usado para executar o Nginx e o Certbot.</li>\n<li>Todos devem possuir um usuário não root com privilégios <code>sudo</code> e um firewall ativo. Para saber como configurar isso, consulte este <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">guia de Configuração inicial do servidor</a>.</li>\n</ul></li>\n<li><p>Docker instalado em todos os três servidores. Como orientação na instalação do Docker, siga os Passos 1 e 2 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04\">Como instalar e usar o Docker no Ubuntu 18.04</a>.</p></li>\n<li><p>Um nome de domínio registrado. Este tutorial utilizará o <code><span class=\"highlight\">your_domain.com</span></code> durante todo o processo. Você pode obter um domínio gratuitamente através do <a href=\"http://www.freenom.com/en/index.html\">Freenom</a>, ou usar o registrador de domínios de sua escolha.</p></li>\n<li><p>Um registro de DNS de tipo <code>A</code> com o <code><span class=\"highlight\">your_domain.com</span></code> apontando para o endereço IP público do seu servidor <strong>proxy</strong>. Você pode seguir <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">esta introdução para o DNS da DigitalOcean</a> para obter mais detalhes sobre como adicioná-lo a uma conta da DigitalOcean, caso seja o que estiver usando:</p></li>\n<li><p>Um bucket de armazenamento de objetos S3, como um <a href=\"https://www.digitalocean.com/products/spaces/\">espaço da DigitalOcean</a> para armazenar os arquivos estáticos do seu projeto Django e um conjunto de chaves de acesso para esse espaço. Para aprender como criar um espaço, consulte a documentação de produto <a href=\"https://www.digitalocean.com/docs/spaces/how-to/create/\">Como criar espaços</a>. Para aprender como criar chaves de acesso para espaços, consulte <a href=\"https://www.digitalocean.com/docs/spaces/how-to/administrative-access/#access-keys\">Compartilhando acesso a espaços com chaves de acesso</a>. Com pequenas alterações, você pode usar qualquer serviço de armazenamento de objetos que o plug-in <a href=\"https://django-storages.readthedocs.io/en/latest/\">django-storages</a> suporte.</p></li>\n<li><p>Uma instância de servidor PostgreSQL, banco de dados e usuário para seu aplicativo Django. Com pequenas alterações, você pode usar qualquer banco de dados <a href=\"https://docs.djangoproject.com/en/2.2/ref/databases/\">compatível com o Django</a>.</p>\n\n<ul>\n<li>O banco de dados PostgreSQL deve ser chamado de <strong>polls</strong> (ou outro nome memorável para inserir em seus arquivos de configuração abaixo) e, neste tutorial, o usuário do banco de dados será chamado <strong>sammy</strong>. Para orientação sobre como criar esses elementos, siga o Passo 1 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Como construir um aplicativo Django e Gunicorn com o Docker</a>. Você pode executar esses passos a partir de qualquer um dos três servidores.</li>\n<li>Um <a href=\"https://www.digitalocean.com/products/managed-databases/\">cluster PostgreSQL gerenciado</a> pela DigitalOcean será usado neste tutorial. Para aprender como criar um cluster, consulte a <a href=\"https://www.digitalocean.com/docs/databases/how-to/clusters/create/\">Documentação de produto de banco de dados gerenciados</a> da DigitalOcean</li>\n<li>É possível instalar e executar sua própria instância do PostgreSQL. Para obter orientações sobre a instalação e administração do <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04\">PostgreSQL em um servidor Ubuntu, consulte Como instalar e usar o PostgreSQL no Ubuntu 18.04</a>.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"passo-1-—-configurando-o-primeiro-servidor-do-aplicativo-django\">Passo 1 — Configurando o primeiro servidor do aplicativo Django</h2>\n\n<p>Para começar, vamos clonar o repositório do aplicativo Django no primeiro servidor de aplicativo. Em seguida, vamos configurar e compilar a imagem do aplicativo Docker e então testar o aplicativo executando o contêiner do Django.</p>\n\n<p><span class='note'><strong>Nota:</strong> se estiver continuando a partir de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Como construir um aplicativo Django e Gunicorn com o Docker</a>, você já terá completado o Passo 1 e pode seguir direto ao <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-2-%E2%80%94-configuring-the-second-django-application-server\">Passo 2</a> para configurar o <strong>segundo</strong> servidor de aplicativo.<br></span></p>\n\n<p>Comece fazendo login no primeiro dos dois servidores do aplicativo Django e use o <code>git</code> para clonar a ramificação <code>polls-docker</code> a partir do <a href=\"https://github.com/do-community/django-polls\">repositório GitHub</a> do aplicativo Polls de tutorial do Django. Este repositório contém o código para o <a href=\"https://docs.djangoproject.com/en/3.0/intro/\">aplicativo de amostra Polls</a> da documentação do Django A ramificação <code>polls-docker</code> contém uma versão em Docker do aplicativo Polls. Para aprender como o aplicativo Polls foi modificado para funcionar efetivamente em um ambiente em contêiner, consulte <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker\">Como construir um aplicativo Django e Gunicorn com o Docker</a>.</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Navegue até o diretório <code>django-polls</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cd django-polls\n</code></pre>\n<p>Esse diretório contém o código Python do aplicativo Django, um <code>Dockerfile</code> que o Docker usará para compilar a imagem do contêiner, bem como um arquivo <code>env</code> que contém uma lista de variáveis de ambiente a serem passadas para o ambiente de execução do contêiner. Inspecione o <code>Dockerfile</code> usando o <code>cat</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cat Dockerfile\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>FROM python:3.7.4-alpine3.10\n\nADD django-polls/requirements.txt /app/requirements.txt\n\nRUN set -ex \\\n    &amp;&amp; apk add --no-cache --virtual .build-deps postgresql-dev build-base \\\n    &amp;&amp; python -m venv /env \\\n    &amp;&amp; /env/bin/pip install --upgrade pip \\\n    &amp;&amp; /env/bin/pip install --no-cache-dir -r /app/requirements.txt \\\n    &amp;&amp; runDeps=\"$(scanelf --needed --nobanner --recursive /env \\\n        | awk '{ gsub(/,/, \"\\nso:\", $2); print \"so:\" $2 }' \\\n        | sort -u \\\n        | xargs -r apk info --installed \\\n        | sort -u)\" \\\n    &amp;&amp; apk add --virtual rundeps $runDeps \\\n    &amp;&amp; apk del .build-deps\n\nADD django-polls /app\nWORKDIR /app\n\nENV VIRTUAL_ENV /env\nENV PATH /env/bin:$PATH\n\nEXPOSE 8000\n\nCMD [\"gunicorn\", \"--bind\", \":8000\", \"--workers\", \"3\", \"mysite.wsgi\"]\n</code></pre>\n<p>Esse Dockerfile usa a <a href=\"https://hub.docker.com/_/python\">imagem Docker</a> oficial do Python 3.7.4 como base e instala os requisitos de pacote Python do Django e do Gunicorn, conforme definido no arquivo <code>django-polls/requirements.txt</code>. Em seguida, ele remove alguns arquivos de compilação desnecessários, copia o código do aplicativo na imagem e define o <code>PATH</code> de execução. Por fim, ele declara que a porta <code>8000</code> será usada para aceitar conexões de contêiner recebidas e executa <code>gunicorn</code> com 3 trabalhadores, escutando na porta <code>8000</code>.</p>\n\n<p>Para aprender mais sobre cada um dos passos nesse Dockerfile, confira o Passo 6 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-6-%E2%80%94-writing-the-application-dockerfile\">Como construir um aplicativo Django e Gunicorn com o Docker</a>.</p>\n\n<p>Agora, crie a imagem usando o <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Nós demos o nome de <code>polls</code> para a imagem usando o sinalizador <code>-t</code> e passamos o diretório atual como um <em>contexto de compilação</em>, que é o conjunto de arquivos de referência ao compilar a imagem.</p>\n\n<p>Depois que o Docker compilar e marcar a imagem, liste as imagens disponíveis usando <code>docker images</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>docker images\n</code></pre>\n<p>Você deve ver a imagem <code>polls</code> listada:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\npolls               latest              80ec4f33aae1        2 weeks ago         197MB\npython              3.7.4-alpine3.10    f309434dea3a        8 months ago        98.7MB\n</code></pre>\n<p>Antes de executarmos o contêiner Django, precisamos configurar seu ambiente de execução usando o arquivo <code>env</code> presente no diretório atual. Esse arquivo será passado para o comando <code>docker run</code> usado para executar contêiner e o Docker irá injetar as variáveis de ambiente configuradas no ambiente de execução do contêiner.</p>\n\n<p>Abra o arquivo <code>env</code> com o <code>nano</code> ou com o seu editor favorito:</p>\n<pre class=\"code-pre  second-environment\"><code>nano env\n</code></pre>\n<p>Vamos configurar o arquivo dessa forma, e você precisará adicionar alguns valores adicionais, conforme descrito abaixo.</p>\n<div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  second-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Preencha os valores que estão faltando para as seguintes chaves:</p>\n\n<ul>\n<li><code>DJANGO_SECRET_KEY</code>: defina isso como um valor único e imprevisível, conforme detalhado na <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#secret-key\">documentação do Django</a>. Um método para gerar essa chave é fornecido em <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Ajustando as configurações do aplicativo</a> do tutorial sobre o <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Aplicativo Django escalável</a>.</li>\n<li><code>DJANGO_ALLOWED_HOSTS</code>: essa variável protege o aplicativo e impede ataques de cabeçalho de host HTTP. Para fins de teste, defina isso como <code>*</code>, um coringa que irá corresponder a todos os hosts. Na produção, você deve definir isso como <code><span class=\"highlight\">your_domain.com</span></code>. Para aprender mais sobre esse ajuste do Django, consulte as <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#allowed-hosts\">Core Settings</a> da documentação do Django.</li>\n<li><code>DATABASE_USERNAME</code>: defina isso como o usuário do banco de dados PostgreSQL criado nos passos pré-requisitos.</li>\n<li><code>DATABASE_NAME</code>: defina isso como <code>polls</code> ou o nome do banco de dados PostgreSQL criado nos passos pré-requisitos.</li>\n<li><code>DATABASE_PASSWORD</code>: defina isso como a senha do usuário do banco de dados PostgreSQL criada nos passos pré-requisitos.</li>\n<li><code>DATABASE_HOST</code>: defina isso como o nome do host do seu banco de dados.</li>\n<li><code>DATABASE_PORT</code>: defina isso como a porta do seu banco de dados.</li>\n<li><code>STATIC_ACCESS_KEY_ID</code>: defina isso como a chave de acesso do seu bucket S3 ou espaço.</li>\n<li><code>STATIC_SECRET_KEY</code>: defina isso como o segredo da chave de acesso do seu bucket S3 ou espaço.</li>\n<li><code>STATIC_BUCKET_NAME</code>: defina isso como o nome do seu bucket S3 ou espaço.</li>\n<li><code>STATIC_ENDPOINT_URL</code>: defina isso como o URL do ponto de extremidade do bucket S3 ou espaço apropriado, como por exemplo <code>https://<span class=\"highlight\">space-name</span>.nyc3.digitaloceanspaces.com</code> se seu espaço estiver localizado na região <code>nyc3</code>.</li>\n</ul>\n\n<p>Assim que terminar a edição, salve e feche o arquivo.</p>\n\n<p>Agora, usaremos o <code>docker run</code> para substituir o conjunto <code>CMD</code> no Dockerfile e criar o esquema de banco de dados usando os comandos <code>manage.py makemigrations</code> e <code>manage.py migrate</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"\n</code></pre>\n<p>Executamos a imagem de contêiner <code>polls:latest</code>, passamos o arquivo de variável de ambiente que acabamos de modificar e substituímos o comando do Dockerfile com <code>sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"</code>, o que irá criar o esquema de banco de dados definido pelo código do aplicativo. Se estiver executando isso pela primeira vez, você deve ver:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>No changes detected\nOperations to perform:\n  Apply all migrations: admin, auth, contenttypes, polls, sessions\nRunning migrations:\n  Applying contenttypes.0001_initial... OK\n  Applying auth.0001_initial... OK\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying contenttypes.0002_remove_content_type_name... OK\n  Applying auth.0002_alter_permission_name_max_length... OK\n  Applying auth.0003_alter_user_email_max_length... OK\n  Applying auth.0004_alter_user_username_opts... OK\n  Applying auth.0005_alter_user_last_login_null... OK\n  Applying auth.0006_require_contenttypes_0002... OK\n  Applying auth.0007_alter_validators_add_error_messages... OK\n  Applying auth.0008_alter_user_username_max_length... OK\n  Applying auth.0009_alter_user_last_name_max_length... OK\n  Applying auth.0010_alter_group_name_max_length... OK\n  Applying auth.0011_update_proxy_permissions... OK\n  Applying polls.0001_initial... OK\n  Applying sessions.0001_initial... OK\n</code></pre>\n<p>Isso indica que o esquema de banco de dados foi criado com sucesso.</p>\n\n<p>Se estiver executando <code>migrate</code> uma outra vez, o Django irá cancelar a operação a menos que o esquema de banco de dados tenha sido alterado.</p>\n\n<p>Em seguida, vamos executar outra instância do contêiner de aplicativo e usar um shell interativo dentro dela para criar um usuário administrativo para o projeto Django.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -i -t --env-file env polls sh\n</code></pre>\n<p>Isso lhe fornecerá um prompt do shell dentro do contêiner em execução que você pode usar para criar o usuário do Django:</p>\n<pre class=\"code-pre  second-environment\"><code>python manage.py createsuperuser\n</code></pre>\n<p>Digite um nome de usuário, endereço de e-mail e senha para o seu usuário e, depois de criá-lo, pressione <code>CTRL+D</code> para sair do contêiner e encerrá-lo.</p>\n\n<p>Por fim, vamos gerar os arquivos estáticos para o aplicativo e fazer o upload deles para o espaço da DigitalOcean usando o <code>collectstatic</code>. Observe que esse processo pode demorar um pouco de tempo para ser concluído.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py collectstatic --noinput\"\n</code></pre>\n<p>Depois que esses arquivos forem gerados e enviados, você receberá a seguinte saída.</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>121 static files copied.\n</code></pre>\n<p>Agora, podemos executar o aplicativo:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env -p 80:8000 polls\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>[2019-10-17 21:23:36 +0000] [1] [INFO] Starting gunicorn 19.9.0\n[2019-10-17 21:23:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8000 (1)\n[2019-10-17 21:23:36 +0000] [1] [INFO] Using worker: sync\n[2019-10-17 21:23:36 +0000] [7] [INFO] Booting worker with pid: 7\n[2019-10-17 21:23:36 +0000] [8] [INFO] Booting worker with pid: 8\n[2019-10-17 21:23:36 +0000] [9] [INFO] Booting worker with pid: 9\n</code></pre>\n<p>Aqui, executamos o comando padrão definido no Dockerfile, <code>gunicorn --bind :8000 --workers 3 mysite.wsgi:application</code> e expomos a porta do contêiner <code>8000</code> para que a porta <code>80</code> no servidor Ubuntu seja mapeada para a porta <code>8000</code> do contêiner <code>polls</code>.</p>\n\n<p>Agora, você deve ser capaz de navegar até o aplicativo <code>polls</code> usando seu navegador Web digitando <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> na barra de URL. Como não há nenhuma rota definida para o caminho <code>/</code>, você provavelmente receberá um erro <code>404 Page Not Found</code>, o que é esperado.</p>\n\n<p><span class='warning'><strong>Aviso:</strong> quando se usa o firewall UFW com o Docker, o Docker ignora quaisquer regras configuradas do firewall UFW, conforme documentado neste <a href=\"https://github.com/docker/for-linux/issues/690\">problema do GitHub</a>. Isso explica por que você tem acesso à porta <code>80</code> do seu servidor, mesmo que não tenha criado explicitamente uma regra de acesso no UFW em qualquer passo pré-requisito. No <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-5-%E2%80%94-preventing-external-access-to-django-app-servers\">Passo 5</a>, vamos tratar desse problema de segurança corrigindo a configuração do UFW. Se você não estiver usando o UFW e estiver usando os <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">Firewalls em Nuvem</a> da DigitalOcean, você pode ignorar com segurança esse aviso.<br></span></p>\n\n<p>Navegue até <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> para ver a interface do aplicativo Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Interface do aplicativo Polls\"></p>\n\n<p>Para visualizar a interface administrativa, visite <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/admin</code>. Você deve ver a janela de autenticação do administrador do aplicativo Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin.png\" alt=\"Página de autenticação de administrador do Polls\"></p>\n\n<p>Digite o nome e a senha do usuário administrativo que você criou com o comando <code>createsuperuser</code>.</p>\n\n<p>Depois de autenticar-se, você pode acessar a interface administrativa do aplicativo Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png\" alt=\"Interface administrativa principal do Polls\"></p>\n\n<p>Observe que os ativos estáticos para os aplicativos <code>admin</code> e <code>polls</code> estão sendo entregues diretamente do armazenamento de objetos. Para confirmar isso, consulte <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#testing-spaces-static-file-delivery\">Testando a entrega de arquivos estáticos de espaços</a>.</p>\n\n<p>Quando terminar de explorar, aperte <code>CTRL+C</code> na janela do terminal executando o contêiner Docker para encerrar o contêiner.</p>\n\n<p>Agora que confirmou que o contêiner de aplicativo funciona como esperado, você pode executá-lo em modo <em>separado</em>. Isso irá executá-lo em segundo plano e lhe permitirá fazer logoff da sua sessão SSH:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>O sinalizador <code>-d</code> instrui o Docker a executar o contêiner em modo separado, o sinalizador <code>-rm</code> limpa o sistema de arquivos do contêiner após a saída do contêiner e damos o nome de <code>polls</code> a ele.</p>\n\n<p>Faça logoff do primeiro servidor do aplicativo Django e navegue até <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> para confirmar se o contêiner está funcionando como esperado.</p>\n\n<p>Agora que seu primeiro servidor do aplicativo Django está em operação, você pode configurar seu segundo servidor do aplicativo Django.</p>\n\n<h2 id=\"passo-2-—-configurando-o-segundo-servidor-do-aplicativo-django\">Passo 2 — Configurando o segundo servidor do aplicativo Django</h2>\n\n<p>Como muitos dos comandos usados para configurar este servidor serão iguais àqueles do passo anterior, eles serão apresentados aqui de forma abreviada. Por favor, reveja o <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Passo 1</a> para obter mais informações sobre qualquer comando em particular neste passo.</p>\n\n<p>Comece fazendo login no <strong>segundo</strong> servidor do aplicativo Django.</p>\n\n<p>Clone a ramificação <code>polls-docker</code> do repositório GitHub <code>django-polls</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Navegue até o diretório <code>django-polls</code>:</p>\n<pre class=\"code-pre  third-environment\"><code>cd django-polls\n</code></pre>\n<p>Compile a imagem usando o <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Abra o arquivo <code>env</code> com o <code>nano</code> ou com o seu editor favorito:</p>\n<pre class=\"code-pre  third-environment\"><code>nano env\n</code></pre><div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  third-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Preencha os valores que estão faltando como no <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Passo 1</a>. Quando terminar a edição, salve e feche o arquivo.</p>\n\n<p>Por fim, execute o contêiner do aplicativo em modo separado:</p>\n<pre class=\"code-pre  third-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Navegue até <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span>/polls</code> para confirmar se o contêiner está funcionando como esperado. Você pode fazer logoff com segurança do segundo servidor de aplicativo sem precisar encerrar seu contêiner em execução.</p>\n\n<p>Com ambos os contêineres do aplicativo Django em operação, você pode seguir para a configuração do contêiner do proxy reverso do Nginx.</p>\n\n<h2 id=\"passo-3-—-configurando-o-contêiner-docker-do-nginx\">Passo 3 — Configurando o contêiner Docker do Nginx</h2>\n\n<p>O <a href=\"https://www.nginx.com/\">Nginx</a> é um servidor Web versátil que oferece vários recursos, incluindo <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\">proxy reverso</a>, <a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\">balanceamento de carga</a> e <a href=\"https://en.wikipedia.org/wiki/Web_cache\">cache</a>. Neste tutorial, nós descarregamos os ativos estáticos do Django para um armazenamento de objetos, então não usaremos as capacidades de cache do Nginx. No entanto, usaremos o Nginx como um proxy reverso para nossos dois servidores de backend do aplicativo Django e distribuiremos pedidos recebidos entre eles. Além disso, o Nginx irá realizar a <a href=\"https://en.wikipedia.org/wiki/TLS_termination_proxy\">terminação TLS</a> e redirecionamento utilizando um certificado TLS fornecido pelo Certbot. Isso significa que ele irá forçar os clientes a usar o HTTPS, redirecionando solicitações HTTP recebidas para a porta 443. Em seguida, irá descriptografar as solicitações HTTPS e enviá-las via proxy para os servidores upstream do Django.</p>\n\n<p>Neste tutorial, tomamos a decisão de projeto de dissociar os contêineres do Nginx dos servidores de backend. Dependendo do seu caso de uso, você pode optar por executar o contêiner do Nginx em um dos servidores do aplicativo Django, fazendo o proxy de pedidos localmente, bem como para o outro servidor Django. Outra arquitetura possível seria executar dois contêineres do Nginx, um em cada servidor de backend, com um <a href=\"https://www.digitalocean.com/products/load-balancer/\">balanceador de carga</a> em nuvem no frontend. Cada arquitetura apresenta diferentes vantagens de segurança e desempenho, e você deve fazer o <a href=\"https://en.wikipedia.org/wiki/Load_testing\">teste de carga</a> no seu sistema para descobrir gargalos. A arquitetura flexível descrita neste tutorial permite que você escale tanto a camada backend do aplicativo Django, quanto a camada de proxy do Nginx. Assim que o contêiner do Nginx único se tornar um gargalo, você pode escalar o processo para vários proxies do Nginx e adicionar um balanceador de carga em nuvem ou um balanceador de carga L4 rápido como o <a href=\"http://www.haproxy.org/\">HAProxy</a>.</p>\n\n<p>Com ambos os servidores do aplicativo Django em operação, podemos começar a configurar o servidor de proxy do Nginx. Faça login em seu servidor de proxy e crie um diretório chamado <code>conf</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>mkdir conf\n</code></pre>\n<p>Crie um arquivo de configuração chamado <code>nginx.conf</code> usando o <code>nano</code> ou seu editor favorito:</p>\n<pre class=\"code-pre  fourth-environment\"><code>nano conf/nginx.conf\n</code></pre>\n<p>Cole nele a seguinte configuração do Nginx:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>\nupstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n\nserver {\n    listen 80 default_server;\n    return 444;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n\n    # SSL\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n\n    client_max_body_size 4G;\n    keepalive_timeout 5;\n\n        location / {\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header X-Forwarded-Proto $scheme;\n          proxy_set_header Host $http_host;\n          proxy_redirect off;\n          proxy_pass http://django;\n        }\n\n    location ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n    }\n\n}\n</code></pre>\n<p>Esses blocos <code>upstream</code>, <code>server</code> e <code>location</code> configuram o Nginx para redirecionar solicitações HTTP para HTTPS, além do balanceamento de carga entre eles em dois servidores do aplicativo Django configurados nos Passos 1 e 2. Para aprender mais sobre a estrutura do arquivo de configuração do Nginx, consulte este artigo, <a href=\"https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts#understanding-nginx-configuration-contexts\">Compreendendo a estrutura do arquivo de configuração do Nginx e contextos de configuração</a>. Além dele, este artigo, <a href=\"https://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\">Compreendendo os algoritmos de seleção do servidor Nginx e do bloco de localização</a>, também pode ser útil.</p>\n\n<p>Essa configuração foi montada a partir de arquivos de configuração de amostra fornecidos pelo <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Gunicorn</a>, <a href=\"https://github.com/certbot/certbot/blob/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf\">Cerbot</a> e <a href=\"https://hub.docker.com/_/nginx\">Nginx</a> e serve como uma configuração mínima do Nginx para tornar essa arquitetura funcional. Ajustar essa configuração do Nginx vai além do escopo deste artigo, mas você pode usar uma ferramenta como o <a href=\"https://www.digitalocean.com/community/tools/nginx\">NGINXConfig</a> para gerar arquivos de configuração do Nginx com maior desempenho e segurança para sua arquitetura.</p>\n\n<p>O bloco <code>upstream</code> define o grupo de servidores usados para fazer proxy de solicitações usando a diretiva <code>proxy_pass</code>:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>upstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n. . .\n</code></pre>\n<p>Neste bloco, damos o nome de <code>django</code> ao upstream e incluímos os endereços IP de ambos os servidores do aplicativo Django. Se os servidores do aplicativo estiverem em execução na DigitalOcean e possuírem a rede VPC ativada, você deve usar aqui seus endereços IP privados. Para aprender como habilitar a rede VPC na DigitalOcean, consulte <a href=\"https://www.digitalocean.com/docs/networking/vpc/how-to/enable/\">Como habilitar a rede VPC em Droplets existentes</a>.</p>\n\n<p>O primeiro bloco <code>server</code> captura solicitações que não correspondam ao seu domínio e encerra a conexão. Por exemplo, uma solicitação HTTP direta para o endereço IP do seu servidor seria manipulada por este bloco:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80 default_server;\n    return 444;\n}\n. . .\n</code></pre>\n<p>O próximo bloco <code>server</code> redireciona as solicitações HTTP para seu domínio para HTTPS usando um <a href=\"https://en.wikipedia.org/wiki/HTTP_301\">redirecionamento HTTP 301</a>. Essas solicitações são então manipuladas pelo bloco <code>server</code> final:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name your_domain.com;\n    return 301 https://$server_name$request_uri;\n}\n. . .\n</code></pre>\n<p>Essas duas diretivas definem os caminhos para o certificado TLS e a chave secreta. Eles serão fornecidos usando o Certbot e montados no contêiner do Nginx no próximo passo.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\nssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n. . .\n</code></pre>\n<p>Esses parâmetros são os padrões de segurança SSL recomendados pelo Certbot. Para aprender mais sobre eles, consulte <a href=\"https://nginx.org/en/docs/http/ngx_http_ssl_module.html\">Module ngx_http_ssl_module</a> da documentação do Nginx. O <a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\">Security/Server Side TLS</a> do Mozilla é outro guia útil que você ajuste sua configuração SSL.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n. . .\n</code></pre>\n<p>Essas duas diretivas da <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">amostra de configuração do Nginx</a> do Gunicorn definem o tamanho máximo permitido do corpo da solicitação do cliente e atribuem o tempo limite para manutenção de conexão com o cliente. O Nginx irá interromper as conexões com o cliente após <code>keepalive_timeout</code> segundos.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nclient_max_body_size 4G;\nkeepalive_timeout 5;\n. . .\n</code></pre>\n<p>O primeiro bloco <code>location</code> instrui o Nginx a redirecionar solicitações via proxy para os servidores <code>upstream django</code> via HTTP. Ele também preserva os cabeçalhos HTTP do cliente que capturam o endereço IP originário, protocolo usado para conexão e host de destino:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation / {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://django;\n}\n. . .\n</code></pre>\n<p>Para aprender mais sobre essas diretivas, consulte <a href=\"https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration\">Deploying Gunicorn</a> e <a href=\"http://nginx.org/en/docs/http/ngx_http_proxy_module.html\">Module ngx_http_proxy_module</a> da documentação do Nginx.</p>\n\n<p>O bloco <code>location</code> final captura as solicitações para o caminho <code>/well-known/acme-challenge/</code> usado pelo Certbot para HTTP-01 challenges. Ele faz isso para verificar seu domínio com o Let&rsquo;s Encrypt e fornecer ou renovar os certificados TLS. Para maiores informações sobre o HTTP-01 challenge usado pelo Certbot, consulte <a href=\"https://letsencrypt.org/docs/challenge-types/\">Challenge Types</a> da documentação do Let&rsquo;s Encrypt.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n}\n</code></pre>\n<p>Assim que terminar a edição, salve e feche o arquivo.</p>\n\n<p>Agora, você pode usar esse arquivo de configuração para executar um contêiner Docker do Nginx. Neste tutorial, usaremos a imagem <code>nginx:1.19.0</code>, versão <code>1.19.0</code> da <a href=\"https://hub.docker.com/_/nginx\">imagem oficial do Docker</a> mantida pelo Nginx.</p>\n\n<p>Quando executamos o contêiner pela primeira vez, o Nginx irá gerar um erro e falhar, pois ainda não fornecemos os certificados definidos no arquivo de configuração. No entanto, ainda vamos executar o comando para baixar localmente a imagem do Nginx e testar se todo o resto está funcionando corretamente:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Aqui, chamamos o contêiner de <code>nginx</code> e mapeamos as portas de host <code>80</code> e <code>443</code> para as respectivas portas do contêiner. O sinalizador <code>-v</code> monta o arquivo de configuração no contêiner do Nginx em <code>/etc/nginx/conf.d/nginx.conf</code>, que é de onde a imagem do Nginx está configurada para carregar. Ele é montado em <code>ro</code>, ou modo &ldquo;apenas leitura&rdquo;, para que o contêiner não consiga modificar o arquivo. O diretório root Web <code>/var/www/html</code> também é montado no contêiner. Por fim, o <code>nginx:1.19.0</code> instrui o Docker a pegar e executar a imagem <code>nginx:1.19.0</code> do Dockerhub.</p>\n\n<p>O Docker irá pegar e executar a imagem, e então o Nginx irá gerar um erro quando não encontrar o certificado TLS e a chave secreta configurados. No próximo passo, vamos providenciá-los usando um cliente Certbot em Docker e a autoridade de certificação Let&rsquo;s Encrypt.</p>\n\n<h2 id=\"passo-4-—-configurando-o-certbot-e-a-renovação-de-certificados-do-lets-encrypt\">Passo 4 — Configurando o Certbot e a renovação de certificados do Lets Encrypt</h2>\n\n<p>O <a href=\"https://github.com/certbot/certbot\">Certbot</a> é um cliente do Let&rsquo;s Encrypt desenvolvido pela <a href=\"https://www.eff.org/\">Electronic Frontier Foundation</a>. Ele fornece certificados TLS gratuitos da autoridade de certificação <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>, que permite que navegadores verifiquem a identidade de seus servidores Web. Como temos o Docker instalado em nosso servidor de proxy do Nginx, usaremos a <a href=\"https://hub.docker.com/r/certbot/certbot/\">imagem Certbot do Docker</a> para fornecer e renovar os certificados TLS.</p>\n\n<p>Comece garantindo que você tenha um registro DNS do tipo <code>A</code> mapeado para o endereço IP público do servidor proxy. Em seguida, em seu servidor proxy, forneça uma versão de preparo dos certificados usando a imagem <code>certbot</code> do Docker:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone --staging -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Esse comando executa a imagem <code>certbot</code> do Docker em modo interativo, e encaminha a porta <code>80</code> no host para a porta <code>80</code> no contêiner. Ele cria e monta dois diretórios de host no contêiner: <code>/etc/letsencrypt/</code> e <code>/var/lib/letsencrypt/</code>. O <code>certbot</code> é executado no modo <code>standalone</code>, sem o Nginx, e usará os servidores <code>staging</code> — de preparo — do Let&rsquo;s Encrypt para realizar a validação de domínio.</p>\n\n<p>Quando solicitado, digite seu endereço de e-mail e concorde com os Termos de serviço. Se a validação de domínio for bem sucedida, você deve ver o seguinte resultado:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Obtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for stubb.dev\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem\n   Your cert will expire on 2020-09-15. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - Your account credentials have been saved in your Certbot\n   configuration directory at /etc/letsencrypt. You should make a\n   secure backup of this folder now. This configuration directory will\n   also contain certificates and private keys obtained by Certbot so\n   making regular backups of this folder is ideal.\n</code></pre>\n<p>Você pode inspecionar o certificado usando o <code>cat</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>sudo cat /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n</code></pre>\n<p>Com o certificado TLS fornecido, podemos testar a configuração do Nginx montada no passo anterior:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Esse é a mesma execução de comandos do <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Passo 3</a>, com a adição de ambos os diretórios recém-criados do Let&rsquo;s Encrypt.</p>\n\n<p>Assim que o Nginx estiver em funcionamento, navege até <code>http://<span class=\"highlight\">your_domain.com</span></code>. Você pode receber um aviso em seu navegador de que a autoridade de certificação é inválida. Isso é esperado, já que fornecemos os certificados de preparo e não os certificados do Let&rsquo;s Encrypt de produção. Verifique a barra de URL do seu navegador para confirmar se sua solicitação HTTP foi redirecionada para o HTTPS.</p>\n\n<p>Aperte <code>CTRL+C</code> em seu terminal para sair do Nginx e execute o cliente <code>certbot</code> novamente, mas, desta vez, omitindo o sinalizador <code>--staging</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Quando solicitado a manter o certificado existente ou renová-lo, aperte <code>2</code> para renová-lo e então <code>ENTER</code> para confirmar sua escolha.</p>\n\n<p>Com o certificado TLS de produção fornecido, execute o servidor Nginx novamente:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Em seu navegador, navegue até <code>http://<span class=\"highlight\">your_domain.com</span></code>. Na barra de URL, confirme se a solicitação HTTP foi redirecionada para o HTTPS. Como o aplicativo Polls não possui nenhum padrão de rota configurado, você deve ver um erro <strong>Page not found</strong> do Django. Navegue até <code>https://<span class=\"highlight\">your_domain.com</span>/polls</code> e você verá a interface padrão do aplicativo Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Interface do aplicativo Polls\"></p>\n\n<p>Neste ponto, você já forneceu um certificado TLS de produção usando o cliente Certbot do Docker, e está aplicando um proxy reverso e balanceamento de carga nas solicitações externas de carga para os dois servidores do aplicativo Django.</p>\n\n<p>Os certificados do Let&rsquo;s Encrypt expiram a cada 90 dias. Para garantir que seu certificado permaneça válido, você deve renová-lo regularmente antes de sua expiração programada. Com o Nginx em execução, você deve usar o cliente Certbot no modo <code>webroot</code> em vez do modo <code>standalone</code>. Isso significa que o Certbot irá realizar a validação criando um arquivo no diretório <code>/var/www/html/.well-known/acme-challenge/</code> e as solicitações de validação do Let&rsquo;s Encrypt para este caminho serão capturadas pela regra <code>location</code> definida na configuração do Nginx no <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Passo 3</a>. Então, o Certbot irá rotacionar os certificados e você pode recarregar o Nginx para que ele use esse certificado recém-fornecido.</p>\n\n<p>Existem várias maneiras de automatizar esse procedimento e a renovação automática de certificados TLS vai além do escopo deste tutorial. Para um processo semelhante usando o utilitário de planejamento <code>cron</code>, consulte o Passo 6 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates%5D(https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates)\">Como proteger um aplicativo Node.js em contêiner com Nginx, Let&rsquo;s Encrypt e Docker Compose</a>.</p>\n\n<p>Em seu terminal, aperte <code>CTRL+C</code> para encerrar o contêiner do Nginx. Execute-o novamente em modo separado adicionando o sinalizador <code>-d</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -d -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n  -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Com o Nginx em execução em segundo plano, use o comando a seguir para realizar simulação do procedimento de renovação de certificado:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm --name certbot \\\n    -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n  -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n  -v \"/var/www/html:/var/www/html\" \\\n  certbot/certbot renew --webroot -w /var/www/html --dry-run\n</code></pre>\n<p>Usamos o plug-in <code>--webroot</code>, especificamos o caminho do root Web e usamos o sinalizador <code>--dry-run</code> para verificar se tudo está funcionando corretamente sem realmente realizar a renovação de certificado.</p>\n\n<p>Se a simulação de renovação for bem sucedida, você deve ver o seguinte resultado:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Cert not due for renewal, but simulating renewal for dry run\nPlugins selected: Authenticator webroot, Installer None\nRenewing an existing certificate\nPerforming the following challenges:\nhttp-01 challenge for <span class=\"highlight\">your_domain.com</span>\nUsing the webroot path /var/www/html for all unmatched domains.\nWaiting for verification...\nCleaning up challenges\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nnew certificate deployed without reload, fullchain is\n/etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates below have not been saved.)\n\nCongratulations, all renewals succeeded. The following certs have been renewed:\n  /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem (success)\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates above have not been saved.)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n</code></pre>\n<p>Em uma configuração de produção, após renovar os certificados, é necessário recarregar o Nginx para que as alterações entrem em vigor. Para recarregar o Nginx, execute o seguinte comando:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker kill -s HUP nginx\n</code></pre>\n<p>Esse comando enviará um sinal <a href=\"https://en.wikipedia.org/wiki/SIGHUP\">HUP</a> do Unix para o processo do Nginx em execução dentro do contêiner <code>nginx</code> do Docker. Ao receber esse sinal, o Nginx irá recarregar suas configurações e os certificados renovados.</p>\n\n<p>Com o HTTPS habilitado e todos os componentes dessa arquitetura em operação, o passo final é bloquear a configuração impedindo o acesso externo aos dois servidores backend de aplicativo. Todas as solicitações HTTP devem fluir através do proxy do Nginx.</p>\n\n<h2 id=\"passo-5-—-prevenindo-o-acesso-externo-a-servidores-do-aplicativo-django\">Passo 5 — Prevenindo o acesso externo a servidores do aplicativo Django</h2>\n\n<p>Na arquitetura descrita neste tutorial, a terminação SSL ocorre no proxy do Nginx. Isso significa que o Nginx descriptografa a conexão SSL, e os pacotes, não criptografados, são enviados via proxy para os servidores do aplicativo Django. Para muitos casos de uso, esse nível de segurança é o suficiente. Para aplicações envolvendo dados financeiros ou de saúde, pode ser interessante implementar uma criptografia de ponta a ponta. Você pode fazer isso encaminhando pacotes criptografados através do balanceador de carga e descriptografando-os nos servidores do aplicativo, ou criptografando novamente no proxy e mais uma vez descriptografando nos servidores do aplicativo Django. Essas técnicas vão além do escopo deste artigo, mas para aprender mais sobre elas, consulte <a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">Criptografia de ponta a ponta</a>.</p>\n\n<p>O proxy do Nginx age como um gateway entre o tráfego externo e a rede interna. Teoricamente, nenhum cliente externo deve ter acesso direto aos servidores internos do aplicativo, e todas as solicitações devem fluir através do servidor Nginx. A nota no <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Passo 1</a> descreve brevemente um <a href=\"https://github.com/docker/for-linux/issues/690\">problema em aberto</a> com o Docker, onde ele ignora as configurações de firewall do <code>ufw</code> por padrão e abre portas externamente, o que pode não ser seguro. Para lidar com essa preocupação de segurança, é recomendado usar <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">firewalls em nuvem</a> ao trabalhar com servidores que possuam o Docker habilitado. Para obter mais informações sobre a criação de firewalls em nuvem com a DigitalOcean, consulte <a href=\"https://www.digitalocean.com/docs/networking/firewalls/how-to/create/\">Como criar firewalls</a>. Você também pode manipular o <code>iptables</code> diretamente em vez de usar o <code>ufw</code>. Para aprender mais sobre como usar o <code>iptables</code> com o Docker, consulte <a href=\"https://docs.docker.com/network/iptables/\">Docker e o iptables</a>.</p>\n\n<p>Neste passo, vamos modificar a configuração do UFW para bloquear o acesso externo a portas do host abertas pelo Docker. Ao executarmos o Django nos servidores do aplicativo, passamos o sinalizador <code>-p 80:8000</code> para o <code>docker</code>, que encaminha a porta <code>80</code> no host para a porta <code>8000</code> no contêiner. Isso também abriu a porta <code>80</code> para clientes externos, o que pode ser verificado visitando <code>http://<span class=\"highlight\">your_app_server_1_IP</span></code>. Para evitar o acesso direto, vamos modificar a configuração do UFW usando o método descrito no <a href=\"https://github.com/chaifeng/ufw-docker\">repositório ufw-docker do GitHub</a>.</p>\n\n<p>Comece fazendo login no primeiro servidor do aplicativo Django. Em seguida, abra o arquivo <code>/etc/ufw/after.rules</code> com privilégios de superusuário, usando o <code>nano</code> ou o seu editor favorito:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Digite sua senha quando solicitado, e aperte <code>ENTER</code> para confirmar.</p>\n\n<p>Você deve ver as seguintes regras do <code>ufw</code>:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>#\n# rules.input-after\n#\n# Rules that should be run after the ufw command line added rules. Custom\n# rules should be added to one of these chains:\n#   ufw-after-input\n#   ufw-after-output\n#   ufw-after-forward\n#\n\n# Don't delete these required lines, otherwise there will be errors\n*filter\n:ufw-after-input - [0:0]\n:ufw-after-output - [0:0]\n:ufw-after-forward - [0:0]\n# End required lines\n\n# don't log noisy services by default\n-A ufw-after-input -p udp --dport 137 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 138 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 139 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 445 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 67 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 68 -j ufw-skip-to-policy-input\n\n# don't log noisy broadcast\n-A ufw-after-input -m addrtype --dst-type BROADCAST -j ufw-skip-to-policy-input\n\n# don't delete the 'COMMIT' line or these rules won't be processed\nCOMMIT\n</code></pre>\n<p>Role até o final e cole o bloco a seguir de regras de configuração do UFW:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Essas regras restringem o acesso público às portas abertas pelo Docker e permitem o acesso dos intervalos de IP privativo <code>10.0.0.0/8</code>, <code>172.16.0.0/12</code> e <code>192.168.0.0/16</code>. Se estiver usando o VPC com a DigitalOcean, então os Droplets em sua rede VPC terão acesso à porta aberta através da interface de rede privada, mas os clientes externos não terão. Para maiores informações sobre o VPC, consulte a <a href=\"https://www.digitalocean.com/docs/networking/vpc/\">documentação oficial do VPC</a>. Para aprender mais sobre as regras implementadas nesse trecho de código, consulte <a href=\"https://github.com/chaifeng/ufw-docker#how-it-works\">Como isso funciona?</a> do <a href=\"https://github.com/chaifeng/ufw-docker\">LEIAME do ufw-docker</a>.</p>\n\n<p>Se você não estiver usando o VPC com a DigitalOcean, e digitou os endereços IP públicos dos servidores do aplicativo no bloco <code>upstream</code> de sua configuração do Nginx, será necessário modificar explicitamente o firewall UFW para permitir o tráfego do servidor Nginx através da porta <code>80</code> nos servidores do aplicativo Django. Para orientação sobre a criação de regras de <code>allow</code> (permissão) com o firewall UFW, consulte <a href=\"https://www.digitalocean.com/community/tutorials/ufw-essentials-common-firewall-rules-and-commands\">Fundamentos do UFW: Regras e comandos comuns do firewall</a>.</p>\n\n<p>Assim que terminar a edição, salve e feche o arquivo.</p>\n\n<p>Reinicie o <code>ufw</code> para que a nova configuração entre em vigor:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Navegue até <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> em seu navegador Web para confirmar se não é mais possível acessar o servidor do aplicativo pela porta <code>80</code>.</p>\n\n<p>Repita esse processo no segundo servidor do aplicativo Django.</p>\n\n<p>Faça logoff do primeiro servidor de aplicativo ou abra outra janela do terminal e faça login no segundo servidor do aplicativo Django. Em seguida, abra o arquivo <code>/etc/ufw/after.rules</code> com privilégios de superusuário, usando o <code>nano</code> ou o seu editor favorito:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Digite sua senha quando solicitado e aperte <code>ENTER</code> para confirmar.</p>\n\n<p>Role até o final e cole o bloco a seguir de regras de configuração do UFW:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  third-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Assim que terminar a edição, salve e feche o arquivo.</p>\n\n<p>Reinicie o <code>ufw</code> para que a nova configuração entre em vigor:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Navegue até <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span></code> em seu navegador Web para confirmar se não é mais possível acessar o servidor do aplicativo pela porta <code>80</code>.</p>\n\n<p>Por fim, navegue até <code>https://<span class=\"highlight\">your_domain_here</span>/polls</code> para confirmar se o proxy do Nginx ainda tem acesso aos servidores upstream do Django. Você deve ver a interface padrão do aplicativo Polls.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Neste tutorial, você configurou um aplicativo Polls do Django escalável usando contêineres Docker. À medida que seu tráfego cresce e a carga no sistema aumenta, é possível escalar cada camada separadamente: a camada de proxy do Nginx, a camada backend do aplicativo Django e a camada do banco de dados PostgreSQL.</p>\n\n<p>Ao construir um sistema distribuído, muitas vezes há várias decisões de projeto que você deve enfrentar, e várias arquiteturas podem satisfazer seu caso de uso. A arquitetura descrita neste tutorial tem o intuito de servir como um planejamento flexível para projetar aplicativos escaláveis com o Django e o Docker.</p>\n\n<p>Você pode desejar controlar o comportamento dos contêineres quando eles encontram erros, ou executar contêineres automaticamente quando o seu sistema for inicializado. Para fazer isso, você pode usar um gerenciador de processos como o <a href=\"https://en.wikipedia.org/wiki/Systemd\">Systemd</a> ou implementar políticas de reinicialização. Para mais informações sobre isso, consulte <a href=\"https://docs.docker.com/config/containers/start-containers-automatically/\">Iniciar contêineres automaticamente</a> da documentação do Docker.</p>\n\n<p>Ao trabalhar em escala com vários hosts executando a mesma imagem do Docker, pode ser mais eficiente automatizar passos usando uma ferramenta de gerenciamento de configuração como o <a href=\"https://www.ansible.com/\">Ansible</a> ou o <a href=\"https://www.chef.io/\">Chef</a>. Para aprender mais sobre o gerenciamento de configuração, consulte <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-configuration-management\">Uma introdução ao gerenciamento de configuração</a> e <a href=\"https://www.digitalocean.com/community/meetup_kits/automating-server-setup-with-ansible-a-digitalocean-workshop-kit\">Automatizando a configuração do servidor com o Ansible: um kit de oficina da DigitalOcean</a>.</p>\n\n<p>Em vez de compilar a mesma imagem em todos os hosts, você também pode simplificar a implantação usando um registro de imagem como o <a href=\"https://hub.docker.com/\">Docker Hub</a>, que compila, armazena e distribui centralmente as imagens do Docker em vários servidores. Junto com um registro de imagem, um pipeline de integração e implantação contínuas pode ajudá-lo a compilar, testar e implantar imagens em seus servidores de aplicativo. Para mais informações sobre CI/CD, consulte <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-ci-cd-best-practices\">Introdução a práticas recomendadas de CI/CD</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:52 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/scalable_django/polls_app.png","linkMd5":"5f4933306d16689cf1a957ecf36bdc6d","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","destWidth":474,"destHeight":473,"sourceBytes":43341,"destBytes":1896,"author":"Hanif Jetha","articleImgCdnMap":{"https://assets.digitalocean.com/articles/scalable_django/polls_app.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/31/07-48-31-305_44661f4fc2769a02.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn38@2020_6/2020/08/31/07-48-31-498_6d93c2bd68b66072.webp"},"publishedOrCreatedDate":1598860106989},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Знакомство с реляционными базами данных","link":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-ru","description":"<h3 id=\"Введение\">Введение</h3>\n\n<p><em>Системы управления базами данных</em> (СУБД) — это компьютерные программы, которые позволяют пользователям взаимодействовать с базой данных. СУБД позволяет пользователям контролировать доступ к базе данных, записывать данные, запускать запросы и выполнять любые другие задачи, связанные с управлением базами данных.</p>\n\n<p>Однако для выполнения любой из этих задач СУБД должна иметь в основе модель, определяющую организацию данных. <em>Реляционная модель</em> — это один из подходов к организации данных, который широко используется в программном обеспечении баз данных с момента своего появления в конце 60-х годов. Этот подход настолько распространен, что на момент написания данной статьи <a href=\"https://db-engines.com/en/ranking\">четыре из пяти самых популярных систем управления базами данных</a> являются реляционными.</p>\n\n<p>В этой концептуальной статье представлена история реляционной модели, порядок организации данных реляционными системами и примеры использования в настоящее время.</p>\n\n<h2 id=\"История-реляционной-модели\">История реляционной модели</h2>\n\n<p><em>Базы данных</em> — это логически сформированные кластеры информации, или <em>данных</em>. Любая коллекция данных является базой данных, независимо от того, как и где она хранится. Шкаф с платежными ведомостями, полка в регистратуре с карточками пациентов или хранящаяся в разных офисах клиентская картотека компании — все это базы данных. Прежде чем хранение данных и управление ими с помощью компьютеров стало общей практикой, правительственным организациям и коммерческим компаниям для хранения информации были доступны только физические базы данных такого рода.</p>\n\n<p>Примерно в середине XX века развитие компьютерной науки привело к созданию машин с большей вычислительной мощностью, а также с увеличенными возможностями встроенной и внешней памяти. Эти достижения позволили специалистам в области вычислительной техники осознать потенциал таких устройств в области хранения и управления большими массивами данных.</p>\n\n<p>Однако не существовало никаких теорий о том, как компьютеры могут организовывать данные осмысленным, логическим образом. Одно дело хранить несортированные данные на компьютере, но гораздо сложнее создать системы, которые позволяют последовательно добавлять, извлекать, сортировать и иным образом управлять этими данными на практике. Необходимость в логической конструкции для хранения и организации данных привела к появлению ряда предложений по использованию компьютеров для управления данными.</p>\n\n<p>Одной из ранних моделей базы данных была <a href=\"https://en.wikipedia.org/wiki/Hierarchical_database_model\"><em>иерархическая модель</em></a>, в которой данные были организованы в виде древовидной структуры, подобной современным файловым системам. Следующий пример показывает, как может выглядеть часть иерархической базы данных, используемой для классификации животных:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png\" alt=\"Пример иерархической базы данных: классификация животных\"></p>\n\n<p>Иерархическая модель была широко внедрена в ранние системы управления базами данных, но она отличалась отсутствием гибкости. В этой модели каждая запись может иметь только одного «предка», даже если отдельные записи могут иметь несколько «потомков». Из-за этого эти ранние иерархические базы данных могли представлять только отношения «один к одному» или «один ко многим». Отсутствие отношений «много ко многим» могло привести к возникновению проблем при работе с точками данных, которые требуют привязки к нескольким предкам.</p>\n\n<p>В конце 60-х годов Эдгар Ф. Кодд (Edgar F. Codd), программист из IBM, разработал реляционную модель управления базами данных. Реляционная модель Кодда позволила связать отдельные записи с несколькими таблицами, что дало возможность устанавливать между точками данных отношения «много ко многим» в дополнение к «один ко многим». Это обеспечило большую гибкость по сравнению с другими существующими моделями, если говорить о разработке структур баз данных, а значит реляционные системы управления базами данных (РСУБД) могли удовлетворить гораздо более широкий спектр бизнес-задач.</p>\n\n<p>Кодд предложил язык для управления реляционными данными, известный как <a href=\"https://dl.acm.org/doi/pdf/10.1145/1734714.1734718\">Alpha</a> , оказавший влияние на разработку более поздних языков баз данных. Коллеги Кодда из IBM, Дональд Чемберлен (Donald Chamberlin) и Рэймонд Бойс (Raymond Boyce), создали один из языков под влиянием языка Alpha. Они назвали свой язык <em>SEQUEL</em>, сокращенное название от <strong>S</strong>tructured <strong>E</strong>nglish <strong>Que</strong>ry <strong>L</strong>anguage (структурированный английский язык запросов), но из-за существующего товарного знака сократили название до <em>SQL</em> (более формальное название — <em>структурированный язык запросов</em>).</p>\n\n<p>Из-за ограниченных возможностей аппаратного обеспечения ранние реляционные базы данных были все еще непозволительно медленными, и потребовалось некоторое время, прежде чем технология получила широкое распространение. Но к середине 80-х годов реляционная модель Кодда была внедрена в ряд коммерческих продуктов по управлению базами данных от компании IBM и ее конкурентов. Вслед за IBM, эти поставщики также стали разрабатывать и применять свои собственные диалекты SQL. К 1987 году Американский национальный институт стандартов и Международная организация по стандартизации ратифицировали и опубликовали стандарты SQL, укрепив его статус признанного языка для управления РСУБД.</p>\n\n<p>Широкое использование реляционной модели во многих отраслях привело к тому, что она была признана стандартной моделью для управления данными. Даже с появлением в последнее время все большего числа различных <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">баз данных NoSQL</a> реляционные базы данных остаются доминирующим инструментом хранения и организации данных.</p>\n\n<h2 id=\"Как-реляционные-базы-данных-структурируют-данные\">Как реляционные базы данных структурируют данные</h2>\n\n<p>Теперь, когда у вас есть общее понимание истории реляционной модели, давайте более подробно рассмотрим, как данная модель структурирует данные.</p>\n\n<p>Наиболее значимыми элементами реляционной модели являются <em>отношения</em>, которые известны пользователям и современным РСУБД как <em>таблицы</em>. Отношения — это набор <em>кортежей</em>, или строк в таблице, где каждый кортеж имеет набор <em>атрибутов</em>, или столбцов:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png\" alt=\"Пример диаграммы, отражающей связь отношений, кортежей и атрибутов друг с другом\"></p>\n\n<p>Столбец — это наименьшая организационная структура реляционной базы данных, представляющая различные ячейки, которые определяют записи в таблице. Отсюда происходит более формальное название — атрибуты. Вы можете рассматривать каждый кортеж в качестве уникального экземпляра чего-либо, что может находиться в таблице: категории людей, предметов, событий или ассоциаций. Такими экземплярами могут быть сотрудники компаний, продажи в онлайн-бизнесе или результаты лабораторных тестов. Например, в таблице с трудовыми записями учителей в школе кортежи могут иметь такие атрибуты, как <code>name</code>, <code>subjects</code>, <code>start_date</code> и т. д.</p>\n\n<p>При создании столбцов вы указываете <em>тип данных</em>, определяющий, какие записи могут вноситься в данный столбец. РСУБД часто используют свои собственные уникальные типы данных, которые могут не быть напрямую взаимозаменяемы с аналогичными типами данных из других систем. Некоторые распространенные типы данных включают даты, строки, целые числа и логические значения.</p>\n\n<p>В реляционной модели каждая таблица содержит по крайней мере один столбец, который можно использовать для уникальной идентификации каждой строки. Он называется <em>первичным ключом</em>. Это важно, поскольку это означает, что пользователям не нужно знать, где физически хранятся данные на компьютере. Их СУБД может отслеживать каждую запись и возвращать ее в зависимости от конкретной цели. В свою очередь, это означает, что записи не имеют определенного логического порядка, и пользователи могут возвращать данные в любом порядке или с помощью любого фильтра по своему усмотрению.</p>\n\n<p>Если у вас есть две таблицы, которые вы хотите связать друг с другом, можно сделать это с помощью <em>внешнего ключа</em>. Внешний ключ — это, по сути, копия основного ключа одной таблицы (таблицы «предка»), вставленная в столбец другой таблицы («потомка»). Следующий пример показывает отношения между двумя таблицами: одна используется для записи информации о сотрудниках компании, а другая — для отслеживания продаж компании. В этом примере первичный ключ таблицы <code>EMPLOYEES</code> используется в качестве внешнего ключа таблицы <code>SALES</code>:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png\" alt=\"Пример диаграммы, показывающей, как первичный ключ таблицы EMPLOYEE действует в качестве внешнего ключа таблицы SALES\"></p>\n\n<p>Если вы попытаетесь добавить запись в таблицу «потомок», и при этом значение, вводимое в столбец внешнего ключа, не существует в первичном ключе таблицы «предок», вставка будет недействительной. Это помогает поддерживать целостность уровня отношений, поскольку ряды в обеих таблицах всегда будут связаны корректно.</p>\n\n<p>Структурные элементы реляционной модели помогают хранить данные в структурированном виде, но хранение имеет значение только в том случае, если вы можете извлечь эти данные. Для извлечения информации из РСУБД вы можете создать <em>запрос</em>, т. е. структурированный запрос на набор информации. Как уже упоминалось ранее, большинство реляционных баз данных используют язык SQL для управления данными и отправки запросов. SQL позволяет фильтровать результаты и обрабатывать их с помощью различных пунктов, предикатов и выражений, позволяя вам контролировать, какие данные появятся в результате.</p>\n\n<h2 id=\"Преимущества-и-ограничения-реляционных-баз-данных\">Преимущества и ограничения реляционных баз данных</h2>\n\n<p>Учитывая организационную структуру, положенную в основу реляционных баз данных, давайте рассмотрим их некоторые преимущества и недостатки.</p>\n\n<p>Сегодня как SQL, так и базы данных, которые ее используют, несколько отклоняются от реляционной модели Кодда. Например, модель Кодда предписывает, что каждая строка в таблице должна быть уникальной, а по соображениям практической целесообразности большинство современных реляционных баз данных допускают дублирование строк. Есть и те, кто не считает базы данных на основе SQL истинными реляционными базами данных, если они не соответствуют каждому критерию реляционной модели по версии Кодда. Но на практике любая СУБД, которая использует SQL и в какой-то мере соответствует реляционной модели, может быть отнесена к реляционным системам управления базами данных.</p>\n\n<p>Хотя популярность реляционных баз данных стремительно росла, некоторое недостатки реляционной модели стали проявляться по мере того, как увеличивались ценность и объемы хранящихся данных. К примеру, трудно масштабировать реляционную базу данных горизонтально. <em>Горизонтальное масштабирование или</em> <em>масштабирование по горизонтали</em> — это практика добавления большего количества машин к существующему стеку, что позволяет распределить нагрузку, увеличить трафик и ускорить обработку. Часто это контрастирует с <em>вертикальным масштабированием</em>, которое предполагает модернизацию аппаратного обеспечения существующего сервера, как правило, с помощью добавления оперативной памяти или центрального процессора.</p>\n\n<p>Реляционную базу данных сложно масштабировать горизонтально из-за того, что она разработана для обеспечения <em>целостности</em>, т.е. клиенты, отправляющие запросы в одну и ту же базу данных, всегда будут получать одинаковые данные. Если вы масштабируете реляционную базу данных горизонтально по всем машинам, будет трудно обеспечить целостность, т.к. клиенты могут вносить данные только в один узел, а не во все. Вероятно, между начальной записью и моментом обновления других узлов для отображения изменений возникнет задержка, что приведет к отсутствию целостности данных между узлами.</p>\n\n<p>Еще одно ограничение, существующее в РСУБД, заключается в том, что реляционная модель была разработана для управления <em>структурированными данными</em>, или данными, которые соответствуют заранее определенному типу данных, или, по крайней мере, каким-либо образом предварительно организованы. Однако с распространением персональных компьютеров и развитием сети Интернет в начале 90-х годов появились <em>неструктурированные данные</em>, такие как электронные сообщения, фотографии, видео и пр.</p>\n\n<p>Но все это не означает, что реляционные базы данных бесполезны. Напротив, спустя более 40 лет, реляционная модель все еще является доминирующей основой для управления данными. Распространенность и долголетие реляционных баз данных свидетельствуют о том, что это зрелая технология, которая сама по себе является главным преимуществом. Существует много приложений, предназначенных для работы с реляционной моделью, а также много карьерных администраторов баз данных, которые являются экспертами, когда дело доходит до реляционных баз данных. Также существует широкий спектр доступных печатных и онлайн-ресурсов для тех, кто хочет начать работу с реляционными базами данных.</p>\n\n<p>Еще одно преимущество реляционных баз данных заключается в том, что почти все РСУБД поддерживают <em>транзакции</em>. Транзакция состоит из одного или более индивидуального выражения SQL, выполняемого последовательно, как один блок работы. Транзакции представляют подход «все или ничего», означающий, что все операторы SQL в транзакции должны быть действительными. В противном случае вся транзакция не будет выполнена. Это очень полезно для обеспечения целостности данных при внесении изменений в несколько строк или в таблицы.</p>\n\n<p>Наконец, реляционные базы данных демонстрируют чрезвычайную гибкость. Они используются для построения широкого спектра различных приложений и продолжают эффективно работать даже с большими объемами данных. Язык SQL также обладает огромным потенциалом и позволяет вам добавлять или менять данные на лету, а также вносить изменения в структуру схем баз данных и таблиц, не влияя на существующие данные.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>Благодаря гибкости и проектному решению, направленному на сохранение целостности данных, спустя пятьдесят лет после появления такого замысла, реляционные базы данных все еще являются основным способом управления данными и их хранения. Даже с увеличением в последние годы числа разнообразных баз данных NoSQL понимание реляционной модели и принципов ее работы с РСУБД является ключевым моментом для всех, кто хочет создавать приложения, использующие возможности данных.</p>\n\n<p>Чтобы узнать больше о нескольких популярных РСУБД с открытым исходным кодом, мы рекомендуем вам ознакомиться с <a href=\"https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\">нашим сравнением различных реляционных баз данных с открытым исходным кодом</a>. Если вам интересно узнать больше о базах данных в целом, мы рекомендуем вам ознакомиться с <a href=\"https://www.digitalocean.com/community/tags/databases\">нашей полной библиотекой материалов о базах данных</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:47:17 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png","linkMd5":"bbd580a9f5932a12b8eee1a4fd9c573c","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","destWidth":1440,"destHeight":820,"sourceBytes":26442,"destBytes":57080,"author":"Mark Drake","articleImgCdnMap":{"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn42@2020_2/2020/08/31/07-48-32-526_c309571f1ca0d468.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png":null},"publishedOrCreatedDate":1598860106960},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como instalar uma pilha ERPNext no Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-pt","description":"<p><em>O autor selecionou a <a href=\"https://www.brightfunds.org/organizations/software-in-the-public-interest-inc\">Software in the Public Interest</a> para receber uma doação como parte do programa <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introdução\">Introdução</h3>\n\n<p>O <a href=\"https://erpnext.com//\">ERPNext</a> é uma suíte de Planejamento de Recursos Empresariais (ERP) que aproveita o poder e a flexibilidade das tecnologias de código aberto. Ele se destaca no gerenciamento de processos de negócio fundamentais, como finanças, vendas, recursos humanos, fabricação, compras, serviços, necessidades de assistência técnica e muito mais. Entre os benefícios da implementação de um sistema como o ERPNext estão:</p>\n\n<ul>\n<li>Melhor produtividade, automatizando processos de negócio repetitivos</li>\n<li>Melhoria da eficiência de TI através do compartilhamento de um banco de dados para todos os departamentos dentro da empresa</li>\n<li>Melhor tomada de decisão graças a uma visão integral de como as unidades de negócios se relacionam entre si</li>\n</ul>\n\n<p>O ERPNext é baseado no <a href=\"https://frappe.io/frappe\">Frappe</a>, um framework Web full-stack de aplicativos escrito em <a href=\"https://www.python.org/\">Python</a> que aproveita ao máximo o <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">ambiente de tempo de execução Node/JavaScript</a> e usa o <a href=\"https://mariadb.org/\">MariaDB</a> como seu banco de dados de back-end. Uma das muitas vantagens dos aplicativos baseados no Frappe, como o ERPNext, é o utilitário de linha de comando <a href=\"https://github.com/frappe/bench\">bench</a>. O CLI do bench economiza tempo dos administradores automatizando tarefas como instalar, atualizar, configurar e gerenciar vários sites do Frappe/ERPNext.</p>\n\n<p>Neste tutorial, você irá instalar e configurar uma pilha ERPNext em um servidor executando o Ubuntu 18.04. Isso permitirá que você configure sua pilha para vários ambientes de desenvolvimento ou produção dependendo das suas necessidades. Além disso, isso irá prepará-lo para construir uma arquitetura mais complexa e tolerante a falhas.</p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<ul>\n<li>Um servidor Ubuntu 18.04 com pelo menos 4 GB de RAM e um usuário <code>sudo</code> não-root. Você pode configurar seu servidor e seu usuário seguindo <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">nosso guia de configuração inicial do servidor com o Ubuntu 18.04</a>.</li>\n</ul>\n\n<p><span class='note'><strong>Nota:</strong> ao escolher as especificações do seu servidor, tenha em mente que os sistemas ERP consomem muitos recursos. Este guia exige um servidor com 4 GB de RAM, que será suficiente para casos de uso básicos. No entanto, os requisitos específicos de hardware podem variar dependendo do número de usuários e do tamanho do seu negócio.<br></span></p>\n\n<ul>\n<li>Um nome de domínio totalmente registrado com um registro A apontado para seu servidor. Se você estiver usando um Droplet da DigitalOcean, então você pode seguir <a href=\"https://www.digitalocean.com/community/tutorials/how-to-point-to-digitalocean-nameservers-from-common-domain-registrars\">este guia</a> para configurar corretamente seu DNS. Este tutorial utilizará o <code><span class=\"highlight\">your_domain</span></code> durante todo o processo.</li>\n</ul>\n\n<h2 id=\"passo-1-—-configurando-o-firewall\">Passo 1 — Configurando o firewall</h2>\n\n<p>Embora configurar um firewall para o desenvolvimento seja opcional, para a produção, isso é uma prática de segurança obrigatória.</p>\n\n<p>Você precisará abrir as seguintes portas em seu servidor ERPNext:</p>\n\n<ul>\n<li><code>80/tcp</code> e <code>443/tcp</code> para o HTTP e HTTPS respectivamente</li>\n<li><code>3306/tcp</code> para a conexão do MariaDB (recomendado apenas se precisar de acesso remoto ao banco de dados)</li>\n<li><code>143/tcp</code> e <code>25/tcp</code> para o IMAP e STMP respectivamente</li>\n<li><code>22/tcp</code> para o SSH (se você ainda não tiver ativado o <code>OpenSSH</code>)</li>\n<li><code>8000/tcp</code> para testes de desenvolvimento antes de implantar seu site</li>\n</ul>\n\n<p>Para abrir várias portas ao mesmo tempo, utilize o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 22,25,143,80,443,3306,8000/tcp\n</li></ul></code></pre>\n<p>De maneira alternativa, você pode permitir conexões vindas de endereços IP específicos em portas específicas usando este comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow from <span class=\"highlight\">server_IP</span> to any port <span class=\"highlight\">port_number</span>\n</li></ul></code></pre>\n<p>Depois de abrir todas as portas necessárias,o ative o firewall:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Depois de ativar o firewall, confirme o status de suas portas abertas:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>Para mais informações sobre a configuração do firewall, leia nosso guia <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-18-04\">How To Set Up a Firewall with UFW on Ubuntu 18.04</a>.</p>\n\n<p>Configurar um firewall adequado é o primeiro dos dois passos preliminares. Agora, você irá configurar o mapeamento de teclado e a codificação de caracteres no seu servidor.</p>\n\n<h2 id=\"passo-2-—-configurando-localidades\">Passo 2 — Configurando localidades</h2>\n\n<p>É altamente recomendado que você configure o mapeamento de teclado para o console, bem como a linguagem e a codificação de caracteres no seu host. Isso é necessário para evitar possíveis problemas durante o processo de instalação do ERPNext 12. Observe que essa configuração não tem nada a ver com a linguagem UI na sua plataforma ERPNext em si, mas com a configuração de localidades do sistema.</p>\n\n<p>Primeiro, atualize seu servidor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Agora, configure o keymap, a linguagem e a codificação de caracteres:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo localectl set-keymap us &amp;&amp; sudo localectl set-locale LANG=en_US.utf8\n</li></ul></code></pre>\n<p>O utilitário <code>localectl</code> é usado pelo Ubuntu 18.04 e outras distribuições Linux para controlar e alterar as configurações de localidade e de layout de teclado em todo o sistema antes do usuário fazer login, que é exatamente o que o ERPNext 12 necessita.</p>\n\n<p>Você também precisará adicionar as seguintes linhas ao seu arquivo <code>/etc/environment</code>. Use o <code>nano</code> ou seu editor de texto preferido para abrir o arquivo:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/environment\n</li></ul></code></pre>\n<p>Agora, adicione o conteúdo a seguir:</p>\n<div class=\"code-label \" title=\"/etc/environment\">/etc/environment</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">LC_ALL=en_US.UTF-8\nLC_CTYPE=en_US.UTF-8\nLANG=en_US.UTF-8\n</code></pre>\n<p>Salve e feche o arquivo.</p>\n\n<p>Reinicialize seu servidor para aplicar todas as alterações:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo reboot\n</li></ul></code></pre>\n<p>Dê ao seu servidor alguns minutos para reinicializar e então fazer um <code>ssh</code> nele. Agora, você está pronto para instalar seu banco de dados.</p>\n\n<h2 id=\"passo-3-—-instalando-o-mariadb-10-4\">Passo 3 — Instalando o MariaDB 10.4</h2>\n\n<p>Agora, você irá adicionar o MariaDB à sua pilha de servidor. O ERPNext 12 requer o MariaDB 10.2+, mas a versão incluída no repositório oficial do Ubuntu 18.04 é a 10.1, o que significa que você precisará instalar uma versão superior. Para os propósitos deste guia, você irá usar a versão mais recente do MariaDB, que no momento da escrita deste artigo é a versão 10.4.</p>\n\n<p>Para instalar o MariaDB 10.4 no Ubuntu 18.04, você precisará adicionar a chave de assinatura e o repositório apropriados. Você pode encontrar essas informações no <a href=\"https://downloads.mariadb.org/mariadb/repositories/#mirror=klaus\">assistente do repositório da Fundação MariaDB</a>. Visite esta URL em seu navegador Web. Agora, sob <strong>1. Choose a Distro</strong>, clique em <strong>Ubuntu</strong>. Uma segunda coluna intitulada <strong>2. Choose a Release</strong> irá aparecer. Abaixo deste título, clique em <strong>18.04 LTS &ldquo;bionic&rdquo;</strong>. Uma terceira coluna intitulada <strong>3.Choose a Version</strong> então aparecerá. Abaixo deste clique em <strong>10.4 stable</strong>. Uma terceira coluna intitulada <strong>4.Choose a Mirror</strong> então aparecerá. Escolha um espelho baseado em sua localização e então o MariaDB irá preencher os comandos adequados para sua instalação personalizada.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_0.png\" alt=\"MariaDB repo wizard\"></p>\n\n<p>Execute os três comandos preenchidos, que adicionarão corretamente o repositório e a chave do MariaDB. Seus próprios comandos serão parecidos com este:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt-get install software-properties-common &amp;&amp; sudo apt-key adv --fetch-keys <span class=\"highlight\">'https://mariadb.org/mariadb_release_signing_key.asc'</span> &amp;&amp; sudo add-apt-repository 'deb [arch=amd64,arm64,ppc64el] <span class=\"highlight\">http://mirror.klaus-uwe.me/mariadb/repo/10.4/ubuntu</span> bionic main'\n</li></ul></code></pre>\n<p>Depois de terminar de adicionar o repositório, instale o MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install mariadb-server\n</li></ul></code></pre>\n<p>Depois de instalar o <code>mariadb-server</code>, instale os seguintes pacotes:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install libmysqlclient-dev python3-mysqldb\n</li></ul></code></pre>\n<p>O ERPNext 12 é uma aplicação Python e, portanto, ele requer a biblioteca <code>python3-mysqldb</code> para o gerenciamento do banco de dados. Quanto ao <code>libmysqlclient-dev</code>, <code>mariadb-client</code>, e <code>libmariadbclient18</code>: esses pacotes permitem aos usuários se comunicar com o serviço MariaDB. O <code>ntpdate</code> e o <code>libdate-manip-perl</code> são usados pelo ERPNext para a sincronização de tempo do servidor.</p>\n\n<p>Em seguida, adicione uma camada básica de segurança ao servidor MariaDB executando o script <code>mysql_secure_installation</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql_secure_installation\n</li></ul></code></pre>\n<p>O script <code>mysql_secure_installation</code> solicitará que você responda a várias perguntas:</p>\n\n<ul>\n<li>O primeiro prompt irá perguntar-lhe sobre a senha do <strong>root</strong>. Como ainda não existe nenhuma senha configurada, pressione <code>ENTER</code>.</li>\n<li>Em seguida, você terá que decidir usar a autenticação do Unix ou não. Responda <code>Y</code> para aceitar este método de autenticação.</li>\n<li>Quando perguntado sobre a alteração da senha do <strong>root</strong> do MariaDB, responda <code>N</code>. Usar a senha padrão juntamente com a autenticação do Unix é a configuração recomendada para sistemas baseados no Ubuntu, pois a conta <strong>root</strong> está intimamente relacionada com tarefas de manutenção automatizadas do sistema.</li>\n<li>As perguntas restantes têm a ver com remover o usuário anônimo do banco de dados, restringir a conta <strong>root</strong> para fazer login remotamente no localhost, remover o banco de dados de teste e recarregar as tabelas de privilégio. É seguro responder <code>Y</code> a todas essas perguntas.</li>\n</ul>\n\n<p>Depois de completar o script <code>mysql_secure_installation</code>, o MariaDB será iniciado usando sua configuração padrão. A instalação padrão do ERPNext usa o usuário <strong>root</strong> do MariaDB&rsquo;s para todas as operações de banco de dados. Embora essa abordagem possa ser conveniente em configurações com um único servidor, ela não é considerada uma boa prática de segurança. Dessa forma,na próxima seção, você irá aprender como evitar este problema criando um novo usuário com privilégios especiais.</p>\n\n<h3 id=\"como-criar-um-usuário-super-administrador-do-mariadb\">Como criar um usuário super administrador do MariaDB</h3>\n\n<p>O ERPNext espera usar o usuário <strong>root</strong> do MariaDB para o gerenciamento de conexões de banco de dados, mas isso nem sempre é ideal. Para superar essa limitação e deixar um usuário não-root gerenciar o MariaDB, você terá que criar manualmente um banco de dados com o nome do usuário. Depois disso, será capaz de atribuir privilégios especiais ao novo usuário para que ele conduza as operações de banco de dados do ERPNext.</p>\n\n<p>Abra o prompt do MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql\n</li></ul></code></pre>\n<p>Agora, crie um novo banco de dados com o nome do usuário que você deseja atribuir para as conexões do MariaDB. Este tutorial irá usar <code><span class=\"highlight\">sammy</span></code>, mas você está livre para escolher seu próprio nome:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">CREATE DATABASE <span class=\"highlight\">sammy</span>;\n</li></ul></code></pre>\n<p>Confirme se o banco de dados foi criado usando esta declaração SQL:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SHOW DATABASES;\n</li></ul></code></pre>\n<p>Você verá um resultado parecido com este:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| <span class=\"highlight\">sammy</span>             |\n+--------------------+\n</code></pre>\n<p>Agora, crie o usuário <code><span class=\"highlight\">sammy</span></code> do MariaDB com privilégios semelhantes ao <strong>root</strong> e então dê a ele uma senha forte da sua escolha. Mantenha a senha em um lugar seguro; você precisará dela mais tarde:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">GRANT ALL PRIVILEGES ON *.* TO '<span class=\"highlight\">sammy</span>'@'%' IDENTIFIED BY '<span class=\"highlight\">mariadb_password</span>' WITH GRANT OPTION;\n</li></ul></code></pre>\n<p>Agora, confirme tanto a criação do usuário quanto dos privilégios do novo usuário:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SELECT host, user, Super_priv FROM mysql.user;\n</li></ul></code></pre>\n<p>Você verá uma saída como esta:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+-----------+-------+------------+\n| Host      | User  | Super_priv |\n+-----------+-------+------------+\n| localhost | root  | Y          |\n| localhost | mysql | Y          |\n| %         | <span class=\"highlight\">sammy</span> | <span class=\"highlight\">Y</span>          |\n+-----------+-------+------------+\n3 rows in set (0.001 sec)\n</code></pre>\n<p>Em seguida, libere os privilégios para aplicar todas as alterações:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">FLUSH PRIVILEGES;\n</li></ul></code></pre>\n<p>Depois de terminar, saia da sessão:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">exit\n</li></ul></code></pre>\n<p>Agora que você criou um usuário do banco de dados, precisa apenas ajustar o MariaDB para garantir uma operação adequada do ERPNext 12. Felizmente, a equipe do ERPNext fornece um excelente modelo de configuração que será usado como um ponto de partida para sua implementação. Na próxima seção, você irá aprender como configurar corretamente o banco de dados do MariaDB usando esse modelo.</p>\n\n<h2 id=\"passo-4-—-configurando-o-mariadb-para-o-erpnext\">Passo 4 — Configurando o MariaDB para o ERPNext</h2>\n\n<p>Com o MariaDB instalado e protegido, é hora de ajustá-lo para as conexões do ERPNext.</p>\n\n<p>Primeiro, interrompa o <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop mariadb\n</li></ul></code></pre>\n<p>Agora, use o <code>nano</code> ou seu editor de texto favorito para criar um arquivo de configuração do MariaDB chamado <code>settings.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/conf.d/settings.cnf\n</li></ul></code></pre>\n<p>Agora, adicione o modelo de configuração do ERPNext:</p>\n<div class=\"code-label \" title=\"/etc/mysql/conf.d/settings.cnf\">/etc/mysql/conf.d/settings.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\n\n# GENERAL #\nuser                           = mysql\ndefault-storage-engine         = InnoDB\nsocket                         = /var/lib/mysql/mysql.sock\npid-file                       = /var/lib/mysql/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n# SAFETY #\nmax-allowed-packet             = 256M\nmax-connect-errors             = 1000000\ninnodb                         = FORCE\n\n# DATA STORAGE #\ndatadir                        = /var/lib/mysql/\n\n# BINARY LOGGING #\nlog-bin                        = /var/lib/mysql/mysql-bin\nexpire-logs-days               = 14\nsync-binlog                    = 1\n\n# REPLICATION #\nserver-id                      = 1\n\n# CACHES AND LIMITS #\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\nquery-cache-type               = 0\nquery-cache-size               = 0\nmax-connections                = 500\nthread-cache-size              = 50\nopen-files-limit               = 65535\ntable-definition-cache         = 4096\ntable-open-cache               = 10240\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\ninnodb-log-file-size           = 512M\ninnodb-flush-log-at-trx-commit = 1\ninnodb-file-per-table          = 1\ninnodb-buffer-pool-size        = 5462M\ninnodb-file-format             = barracuda\ninnodb-large-prefix            = 1\ncollation-server               = utf8mb4_unicode_ci\ncharacter-set-server           = utf8mb4\ncharacter-set-client-handshake = FALSE\nmax_allowed_packet             = 256M\n\n# LOGGING #\nlog-error                      = /var/lib/mysql/mysql-error.log\nlog-queries-not-using-indexes  = 0\nslow-query-log                 = 1\nslow-query-log-file            = /var/lib/mysql/mysql-slow.log\n\n[mysql]\ndefault-character-set = utf8mb4\n\n[mysqldump]\nmax_allowed_packet=256M\n\n!includedir /etc/mysql/mariadb.conf.d/\n</code></pre>\n<p>Salve e feche o arquivo. Para obter informações mais detalhadas sobre essas configurações, <a href=\"https://github.com/frappe/erpnext/wiki/MySQL-configuration-file\">revise este arquivo modelo no repositório Github do ERPNext</a>. Ele é um ponto de partida útil para explorar essas opções.</p>\n\n<p>Em seguida, crie outro arquivo chamado <code>erpnext.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/mariadb.conf.d/erpnext.cnf\n</li></ul></code></pre>\n<p>Adicione o conteúdo a seguir ao arquivo:</p>\n<div class=\"code-label \" title=\"/etc/mysql/mariadb.conf.d/erpnext.cnf\">/etc/mysql/mariadb.conf.d/erpnext.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nbind-address    = 0.0.0.0\n</code></pre>\n<p>O primeiro arquivo, <code>/etc/mysql/conf.d/settings.cnf</code> complementa e também sobrepõe alguns valores incluídos na configuração padrão do MariaDB localizada em <code>/etc/mysql/my.cnf</code>. Este arquivo oferece um modelo curado que melhora muito o desempenho de banco de dados para o ERPNext. No entanto, tenha em mente que, embora esse modelo seja um ótimo ponto de partida, nada impede que você melhore o desempenho do MariaDB ainda mais ajustando esses parâmetros para atender às suas necessidades.</p>\n\n<p>O segundo arquivo, o <code>/etc/mysql/mariadb.conf.d/erpnext.cnf</code>, também sobrepõe alguns valores introduzindo informações específicas sobre a sua conexão de banco de dados.</p>\n\n<h3 id=\"testando-a-conexão-do-mariadb\">Testando a conexão do MariaDB</h3>\n\n<p>Como o ERPNext depende da conexão de banco de dados para quase todas as suas operações internas, é uma boa ideia testar a conexão antes de continuar.</p>\n\n<p>Inicie o <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mariadb\n</li></ul></code></pre>\n<p>Para testar a conexão, use o seguinte comando. Lembre-se de substituir <code><span class=\"highlight\">sammy</span></code> e <code><span class=\"highlight\">mariadb_password</span></code> por suas próprias credenciais:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mysql --user <span class=\"highlight\">sammy</span> --password <span class=\"highlight\">mariadb_password</span> --host=localhost --protocol=tcp --port=3306 test\n</li></ul></code></pre>\n<p>Você verá um resultado mostrando o conteúdo básico de ajuda do MariaDB, bem como diversos parâmetros. Isso significa que sua conexão foi bem sucedida:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>mysql  Ver 15.1 Distrib 10.4.13-MariaDB, for debian-linux-gnu (x86_64) using readline 5.2\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nUsage: mysql [OPTIONS] [database]\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\n\n...\n\n  --ssl-verify-server-cert\n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n\n...\n\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\nbinary-mode                       FALSE\nconnect-expired-password          FALSE\n</code></pre>\n<p>Se precisar fazer qualquer ajuste nas configurações do MariaDB, ou corrigir qualquer erro, lembre-se de recarregar o serviço usando o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mariadb\n</li></ul></code></pre>\n<p>Depois de terminar, ative o MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mariadb\n</li></ul></code></pre>\n<p>Agora que você testou a conexão do banco de dados, continue com a instalação do seu aplicativo ERPNext.</p>\n\n<h2 id=\"passo-5-—-configurando-o-erpnext-12\">Passo 5 — Configurando o ERPNext 12</h2>\n\n<p>Agora que o banco de dados está pronto, continue configurando seu aplicativo Web ERPNext. Nesta seção, você irá aprender como instalar e configurar todos os componentes necessários pelo ERPNext 12 e então instalar o próprio aplicativo.</p>\n\n<p>Comece preparando o servidor com todos os pacotes de sistema exigidos pelo ERPNext 12. Instale as dependências do sistema usando o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo DEBIAN_FRONTEND=noninteractive apt install -y curl build-essential mariadb-client python3-setuptools python3-dev libffi-dev python3-pip libcurl4 dnsmasq fontconfig git htop libcrypto++-dev libfreetype6-dev liblcms2-dev libwebp-dev libxext6 libxrender1 libxslt1-dev libxslt1.1 libffi-dev ntpdate postfix python3-dev python-tk screen vim xfonts-75dpi xfonts-base zlib1g-dev apt-transport-https libsasl2-dev libldap2-dev libcups2-dev pv libjpeg8-dev libtiff5-dev tcl8.6-dev tk8.6-dev libssl1.0-dev python3-mysqldb libdate-manip-perl logwatch\n</li></ul></code></pre>\n<p>A variável <code>DEBIAN_FRONTEND=noninteractive</code> foi passada para o comando de instalação para evitar os prompts do Postfix. Para informações detalhadas sobre a configuração do Postfix, leia nosso guia <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-postfix-on-ubuntu-18-04\">How To Install and Configure Postfix on Ubuntu 18.04</a>.</p>\n\n<p>Em seguida, atualize o <code>pip3</code> e então, instale as versões mais recentes de três módulos Python adicionais exigidos pelo ERPNext:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo -H python3 -m pip install --upgrade setuptools cryptography psutil\n</li></ul></code></pre>\n<p>Agora que você instalou todas as dependências globais necessárias, irá instalar todos os serviços e bibliotecas exigidos pelo ERPNext 12.</p>\n\n<h3 id=\"configurando-o-node-js-e-o-yarn\">Configurando o Node.js e o Yarn</h3>\n\n<p>O ERPNext 12 pode trabalhar com a versão 8+ do ambiente de servidor Node.js. Na verdade, no momento da escrita deste artigo, o script oficial <code>easy_install</code> do ERPNext usa o Node 8. No entanto, do ponto de vista da segurança, é aconselhável instalar uma versão mais recente porque o Node 8 atingiu seu End Of Life (EOL) em 2020 e, portanto, não receberá mais nenhum patch de segurança. Para os fins deste guia, o Node.js versão 12 LTS será instalado juntamente com os gerenciadores de pacotes correspondentes, <code>npm</code> e o <code>yarn</code>. Note que o framework Frappe usa o <code>yarn</code> para instalar dependências. Se você decidir usar um método alternativo de instalação, certifique-se de que você tenha a versão 1.12+ do <code>yarn</code> em execução no seu sistema.</p>\n\n<p>Adicione o repositório NodeSource ao seu sistema:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -sL https://deb.nodesource.com/setup_12.x -o nodesource_setup.sh\n</li></ul></code></pre>\n<p>Agora, você pode inspecionar o conteúdo do script baixado:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano nodesurce_setup.sh\n</li></ul></code></pre>\n<p>Quando estiver satisfeito, execute o script:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bash nodesource_setup.sh\n</li></ul></code></pre>\n<p>Esse script irá atualizar automaticamente a lista <code>apt</code>. Agora, instale o <code>nodejs</code> em seu servidor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install nodejs\n</li></ul></code></pre>\n<p>Em seguida, instale o <code>yarn</code> globalmente usando o pacote <code>npm</code> incluído:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo npm install -g yarn\n</li></ul></code></pre>\n<p>Agora que você instalou o Node, siga adiante para configurar o <code>wkhtmltopdf</code> para sua plataforma.</p>\n\n<p>O ERPNext usa a ferramenta <code>wkhtmltopdf</code> de código aberto para converter conteúdo HTML em PDF usando o mecanismo de renderização Qt WebKit. Esse recurso é usado principalmente para imprimir faturas, cotações e outros relatórios. No caso do ERPNext 12, uma versão específica do <code>wkhtmltopdf</code> é necessária, a <code>0.12.5</code> com o Qt implementado.</p>\n\n<p>Para instalar o <code>wkhtmltopdf</code>, comece indo para um diretório adequado para baixar o pacote. Neste caso, o <code>/tmp</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /tmp\n</li></ul></code></pre>\n<p>Baixe a versão e o pacote apropriados do <code>wkhtmltopdf</code> para o Ubuntu 18.04 da página do projeto:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.5/wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Agora, instale o pacote usando a ferramenta <code>dpkg</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo dpkg -i wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Em seguida, copie todos os executáveis relevantes para seu diretório <code>/usr/bin/</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /usr/local/bin/wkhtmlto* /usr/bin/\n</li></ul></code></pre>\n<p>Assim que os arquivos estiverem no lugar, mude suas permissões para torná-los executáveis:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod a+x /usr/bin/wk*\n</li></ul></code></pre>\n<p>Agora que o <code>wkhtmltopdf</code> está instalado corretamente, adicionaremos o Redis à pilha do nosso banco de dados.</p>\n\n<h3 id=\"instalando-o-redis\">Instalando o Redis</h3>\n\n<p>O ERPNext 12 usa o Redis para melhorar o desempenho do MariaDB. Especificamente, <a href=\"https://discuss.erpnext.com/t/why-erpnext-need-redis/6194\">ele ajuda com o cache</a>.</p>\n\n<p>Primeiro, instale o Redis a partir do repositório oficial do Ubuntu 18.04:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install redis-server\n</li></ul></code></pre>\n<p>Em seguida, ative o Redis na inicialização:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable redis-server\n</li></ul></code></pre>\n<p>Agora que você adicionou o Redis à sua pilha, vamos dedicar um momento para resumir o que você fez até agora. Até este ponto, você instalou todos os componentes principais necessários para o ERPNext 12, que incluem:</p>\n\n<ul>\n<li>Um backend de banco de dados MariaDB</li>\n<li>O ambiente de servidor JavaScript Node.js</li>\n<li>O gerenciador de pacotes Yarn</li>\n<li>Um cache banco de dados Redis</li>\n<li>O gerador de documentos PDF <code>wkhtmltopdf</code></li>\n</ul>\n\n<p>Se você estiver instalando o sistema ERP para o desenvolvimento ou para a produção, agora está pronto para o próximo passo, que é a instalação do framework full-stack Frappe e o aplicativo Web ERPNext 12 em si.</p>\n\n<h2 id=\"passo-6-—-instalando-o-bench-cli-do-frappe\">Passo 6 — Instalando o Bench CLI do Frappe</h2>\n\n<p>Agora que você instalou todos os requisitos de pilha do ERPNext, libere a flexibilidade do utilitário de linha de comando <code>bench</code> do Frappe. O <code>bench</code> CLI foi projetado com o propósito de ajudar os usuários no processo de instalar, configurar e gerenciar aplicativos como o ERPNext que são baseados no Frappe Framework. Nas próximas seções, você irá instalar o CLI <code>bench</code> e então usá-lo para completar o processo de configuração do ERPNext 12.</p>\n\n<p>Certifique-se de que o usuário do Frappe (neste caso <code><span class=\"highlight\">sammy</span></code>) tenha os direitos adequados em seu diretório <code>home</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chown <span class=\"highlight\">sammy</span> -R /home/<span class=\"highlight\">sammy</span>\n</li></ul></code></pre>\n<p>Agora, clone o repositório <code>frappe/bench</code> para seu diretório home. Lembre-se de substituir <code><span class=\"highlight\">sammy</span></code> pelo nome de usuário do seu sistema:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone https://github.com/frappe/bench /home/<span class=\"highlight\">sammy</span>/.bench --depth 1 --branch master\n</li></ul></code></pre>\n<p>Instale o <code>bench</code> CLI:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo pip3 install -e /home/<span class=\"highlight\">sammy</span>/.bench\n</li></ul></code></pre>\n<p>Este guia assume que você esteja instalando o ERPNext 12 para cenários de teste/produção e, consequentemente,que você esteja usando a ramificação <code>master</code>. Mas se a sua intenção for desenvolver aplicativos ou módulos do ERPNext personalizados, a ramificação <code>develop</code> pode ser uma opção mais adequada. Para ambos os casos, você está agora preparado para instalar o Frappe Framework. Esse será o passo final antes de instalar o próprio ERPNext.</p>\n\n<h3 id=\"configurando-o-ambiente-do-frappe-framework\">Configurando o ambiente do Frappe Framework</h3>\n\n<p>Nesta seção, você irá criar um <a href=\"https://frappe.io/docs/user/en/architecture\">ambiente do Frappe</a> usando o <code>bench</code> CLI.</p>\n\n<p>Durante a instalação do Frappe, você pode exceder o limite de inspeção de arquivos do Ubuntu, que por padrão é definido como 8192. Para evitar este problema, defina um limite superior usando o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p\n</li></ul></code></pre>\n<p>Em seguida, inicialize o Frappe Framework 12. Substitua Sammy pelo nome de usuário do seu sistema:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench init /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> --frappe-path https://github.com/frappe/frappe --frappe-branch version-12 --python python3\n</li></ul></code></pre>\n<p>Durante a execução, um erro sobre seu caminho pode aparecer, juntamente com vários avisos. Deixe o processo continuar até o fim. Depois que ele for finalizado, você verá um resultado semelhante ao seguinte, indicando que seu ambiente foi criado com sucesso:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nDone in 82.23s.\nINFO:bench.utils:setting up backups\nno crontab for <span class=\"highlight\">sammy</span>\nSUCCESS: Bench /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> initialized\n</code></pre>\n<p><span class='note'><strong>Nota:</strong> o processo <code>bench init</code> pode ser interrompido se um erro <code>spawn ENOMEM</code> for encontrado. Esse erro é causado quando seu sistema fica sem memória. Você deve corrigir o problema antes de continuar, seja instalando mais memória física ou alocando um espaço SWAP.<br></span></p>\n\n<p>Vamos dar uma olhada no comando usado para criar o ambiente:</p>\n\n<ul>\n<li><code>/home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span></code> é o caminho onde o Frappe Framework, os sites e aplicativos associados serão instalados. Um novo diretório, chamado <code><span class=\"highlight\">frappe-bench</span></code> neste exemplo, será criado para acomodar todos os arquivos necessários.</li>\n<li><code>--frappe-path</code> aponta para o repositório do Frappe, que neste caso é o repositório oficial do Github.</li>\n<li><code>--frappe-branch</code> é a versão do Frappe a ser instalada. Como você quer instalar o ERPNext 12, a versão escolhida é o Frappe 12.</li>\n<li><code>--python</code> é a versão do Python que será usada. O ERPNext 12 requer o Python 3.6+. No entanto, as versões anteriores ainda usam o Python 2.7.</li>\n</ul>\n\n<p>Para obter mais informações sobre comandos <code>bench</code> CLI, consulte o <a href=\"https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html\">Manual dos comandos bench</a>.</p>\n\n<p>A flexibilidade oferecida pelo Frappe Framework vai muito além do uso de ambientes isolados. Você também pode criar sites diferentes e instalar aplicativos neles.</p>\n\n<h2 id=\"passo-7-—-instalando-o-aplicativo-web-erpnext-12\">Passo 7 — Instalando o aplicativo Web ERPNext 12</h2>\n\n<p>Nesta seção, você irá construir um site baseado no Frappe, e então instalar o aplicativo ERPNext 12 nele.</p>\n\n<p>Vá para o diretório onde o Frappe foi inicializado.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Agora, faça o download do ERPNext 12 a partir do seu repositório usando o <code>bench</code> CLI:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench get-app erpnext https://github.com/frappe/erpnext --branch version-12\n</li></ul></code></pre>\n<p>Em seguida, crie o novo site, substituindo <code><span class=\"highlight\">your_domain</span></code> pelo domínio que você associou ao IP deste servidor:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench new-site <span class=\"highlight\">your_domain</span> --admin-password '<span class=\"highlight\">erpnext_admin_password</span>' --mariadb-root-username <span class=\"highlight\">sammy</span> --mariadb-root-password '<span class=\"highlight\">mariadb_password</span>'\n</li></ul></code></pre>\n<p>Vamos reservar um momento para revisar as opções usadas no comando acima:</p>\n\n<ul>\n<li><code>bench new-site</code> cria um novo site baseado no Frappe Framework.</li>\n<li><code><span class=\"highlight\">your_domain</span></code> é o nome para o novo site. Certifique-se de que o DNS do seu domínio tenha um registro A apontando para o IP do seu servidor.</li>\n<li><code><span class=\"highlight\">erpnext_admin_password</span></code> é a senha desejada para o usuário <strong>Administrator</strong> do ERPNext. Mantenha essa senha em um lugar seguro — você precisará dela em breve.</li>\n<li><code><span class=\"highlight\">mariadb_password</span></code> é a senha que você criou no início do guia para o usuário <code><span class=\"highlight\">sammy</span></code> do MariaDB.</li>\n</ul>\n\n<p>Depois disso, instale o aplicativo ERPNext no site:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench --site <span class=\"highlight\">your_domain</span> install-app erpnext\n</li></ul></code></pre>\n<p>Assim que a instalação for concluída, você terá uma aplicação ERPNext 12 funcionando. Agora, vamos testá-lo usando um comando <code>bench</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench start\n</li></ul></code></pre>\n<p>O comando acima irá iniciar um console de monitoramento em tempo real mostrando várias mensagens sobre o servidor Web e outros serviços. Abra um navegador Web e vá até <code>localhost:8000</code> (para instalações locais) ou <code><span class=\"highlight\">your_domain</span>:8000</code> (se você estiver usando um servidor remoto). Você verá a tela de login do ERPNext (abordaremos o login e a configuração em um passo posterior, assim que fizermos nosso site ficar pronto para a produção).</p>\n\n<p>Depois de visitar sua implantação teste, retorne ao seu terminal e pressione <code>CTRL+C</code>. Isso irá parar o ERPNext e sair do console de monitoramento.</p>\n\n<p>Se seu objetivo principal for criar módulos ou modificar o ERPNext 12, então pode parar aqui. Não há mais componentes necessários para fins de desenvolvimento. No entanto, se o que você precisa é um sistema pronto para a produção que não requer uma inicialização manual, então será necessário instalar e configurar alguns componentes adicionais. Esse é o seu próximo passo.</p>\n\n<h2 id=\"passo-8-—-configurando-o-erpnext-12-para-a-produção\">Passo 8 — Configurando o ERPNext 12 para a produção</h2>\n\n<p>Embora a aplicação ERPNext 12 esteja pronta, o sistema como um todo ainda não está completamente preparado para a produção. Para garantir a confiabilidade e a segurança do ERPNext, será necessário habilitar alguns serviços adicionais:</p>\n\n<ul>\n<li>O <strong>Fail2ban</strong> fornece uma camada extra de proteção contra tentativas de força bruta de usuários e bots maliciosos.</li>\n<li>O <strong>Nginx</strong> será usado principalmente como um proxy Web, redirecionando todo o tráfego da porta <code>8000</code> para a porta <code>80</code> (HTTP) ou porta <code>443</code> (HTTPS)</li>\n<li><strong>Supervisor</strong> este serviço garante que os processos chave do ERPNext estejam em funcionamento constante, reiniciando-os conforme necessário.</li>\n</ul>\n\n<p>Até este ponto, você instalou e configurou o ERPNext 12 manualmente, o que lhe permitiu personalizar o processo para funcionar em qualquer caso de uso particular. No entanto, para o resto da configuração de produção, aproveite a conveniência do <code>bench</code> CLI e deixe-o automatizar a instalação e configuração desses serviços restantes.</p>\n\n<p>Certifique-se de estar no diretório de trabalho do Frappe:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Agora, use o seguinte comando para terminar a configuração do ERPNext 12 para produção:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bench setup production <span class=\"highlight\">sammy</span> --yes\n</li></ul></code></pre>\n<p>O comando acima irá instalar e configurar o Nginx, Supervisor e Fail2Ban e definir <code><span class=\"highlight\">sammy</span></code> como proprietário do ambiente de produção.</p>\n\n<p>Os arquivos de configuração criados pelo comando <code>bench</code> são:</p>\n\n<ul>\n<li>Dois arquivos de configuração do Nginx localizados em <code>/etc/nginx/nginx.conf</code> e <code>/etc/nginx/conf.d/<span class=\"highlight\">frappe-bench</span>.conf</code></li>\n<li>Uma prisão de proxy do Fail2Ban localizada em <code>/etc/fail2ban/jail.d/nginx-proxy.conf</code> e um filtro localizado em <code>/etc/fail2ban/filter.d/nginx-proxy.conf</code></li>\n</ul>\n\n<p>Essas configurações padrão serão suficientes para este tutorial, mas é possível explorar e ajustar esses arquivos para atender às suas necessidades. Pare todos os serviços executando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl stop all\n</li></ul></code></pre>\n<p>Assim que tudo estiver pronto, reinicie seus serviços:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl start all\n</li></ul></code></pre>\n<p>Agora, você está pronto para testar sua instalação.</p>\n\n<h3 id=\"testando-sua-instalação-do-erpnext-12\">Testando sua instalação do ERPNext 12</h3>\n\n<p>Em primeiro lugar, verifique se os principais serviços de produção estão em execução usando o seguinte comando <code>systemctl</code> e então fazendo pipe dele para o <code>grep</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">systemctl list-unit-files | grep 'fail2ban\\|nginx\\|supervisor'\n</li></ul></code></pre>\n<p>Você verá uma saída como esta:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>fail2ban.service                       enabled\nnginx.service                          enabled\nsupervisor.service                     enabled\n</code></pre>\n<p>Depois de confirmar que tudo está funcionando como esperado, você pode testar o ERPNext 12 ao vivo em seu servidor. Abra seu navegador favorito e navegue até o domínio onde você está hospedando sua aplicação ERPNext 12.</p>\n\n<p>Depois de alguns segundos, a tela de login do ERPNext 12 deve aparecer. Use <strong>Administrator</strong> para o nome de usuário e <code><span class=\"highlight\">erpnext_admin_password</span></code> que você criou anteriormente para a senha.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_1.png\" alt=\"Tela de login do ERPNext\"></p>\n\n<p>Na próxima tela, você verá um menu suspenso onde pode selecionar o idioma da interface do usuário para o aplicativo:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_2.png\" alt=\"Seleção de idiomas\"></p>\n\n<p>Após a seleção de idiomas, o ERPNext irá questioná-lo sobre seu país, fuso horário e moeda:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_3.png\" alt=\"Selecione sua região\"></p>\n\n<p>Depois de completar as informações sobre a sua região, você será capaz de criar o primeiro usuário do ERPNext. As informações que você fornecer serão usadas como as credenciais de login do usuário.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_4.png\" alt=\"Primeiro usuário do ERPNext\"></p>\n\n<p>Na próxima tela, você será questionado sobre o que o ERPNext chama de <strong>Domains</strong> (domínios). Se não tiver certeza sobre qual é o seu domínio, selecione <strong>Distribution</strong> e clique no botão <strong>Next</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_5.png\" alt=\"Selecionar seus domínios\"></p>\n\n<p>Em seguida, será necessário fornecer um nome e abreviação da empresa.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_6.png\" alt=\"Nome da empresa\"></p>\n\n<p>Na última tela, o ERPNext irá perguntar o que sua empresa faz, o nome do seu banco, o tipo de gráficos de contas e o período do ano fiscal. Você será capaz de inserir bancos adicionais mais tarde. Por enquanto, preencha todos os campos como quiser e clique no botão <strong>Complete Setup</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_7.png\" alt=\"Informações financeiras\"></p>\n\n<p>Em seguida, você verá uma barra de progresso.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_8.png\" alt=\"Configurando o ERPNext\"></p>\n\n<p>Assim que o processo de configuração for concluído, o painel principal do ERPNext 12 será exibido.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_9.png\" alt=\"Painel do ERPNext 12\"></p>\n\n<p>Agora, você terminou de instalar e configurar totalmente um aplicativo ERPNext 12.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Agora que você instalou corretamente seu aplicativo ERPNext 12, pode ser desejável iniciar a implementação do sistema para as necessidades do seu negócio. Um bom ponto de partida é clicando no botão <strong>Getting Started</strong> no painel do ERPNext. O ERPNext irá então ajudá-lo a configurar a plataforma para todas as suas necessidades de negócios e e-commerce.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_10.png\" alt=\"Getting Started\"></p>\n\n<p>Pode ser que você também queira aumentar a velocidade do ERPNext. Se for esse o caso, então você pode ler sobre <a href=\"https://github.com/frappe/erpnext/wiki/ERPNext-Performance-Tuning\">Ajuste de Desempenho do ERPNext</a>, que irá guiá-lo pelas práticas recomendadas e em como depurar problemas relacionados ao desempenho.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:32 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67031/erpnext_0.png","linkMd5":"510cd117433b5adf34d215a010c834bd","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","destWidth":3584,"destHeight":2022,"sourceBytes":966173,"destBytes":375664,"author":"Damaso Sanoja","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67031/erpnext_0.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","https://assets.digitalocean.com/articles/67031/erpnext_1.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_3/2020/08/31/07-48-32-714_e6b982f1d7fe90cd.webp","https://assets.digitalocean.com/articles/67031/erpnext_2.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn94@2020_6/2020/08/31/07-48-32-235_5dfe5b1d282ec7f1.webp","https://assets.digitalocean.com/articles/67031/erpnext_3.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_3/2020/08/31/07-48-31-862_07721efc54737d85.webp","https://assets.digitalocean.com/articles/67031/erpnext_4.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn45@2020_1/2020/08/31/07-48-32-664_c2f620996c337847.webp","https://assets.digitalocean.com/articles/67031/erpnext_5.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn13@2020_2/2020/08/31/07-48-33-137_5b1867188f4eb783.webp","https://assets.digitalocean.com/articles/67031/erpnext_6.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn25@2020_3/2020/08/31/07-48-31-288_1f4bd367e3868d6d.webp","https://assets.digitalocean.com/articles/67031/erpnext_7.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn14@2020_2/2020/08/31/07-48-31-596_2e4f2cf158e027fc.webp","https://assets.digitalocean.com/articles/67031/erpnext_8.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn65@2020_2/2020/08/31/07-48-31-323_2f22aaf79a58e762.webp","https://assets.digitalocean.com/articles/67031/erpnext_9.png":null,"https://assets.digitalocean.com/articles/67031/erpnext_10.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn97@2020_3/2020/08/31/07-48-32-254_dccc24f52c8f5d64.webp"},"publishedOrCreatedDate":1598860106986},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Создание бота Discord Bot с помощью Node.js","link":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-ru","description":"<p><em>Автор выбрал фонд <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> для получения пожертвования в рамках программы <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"Введение\">Введение</h3>\n\n<p><a href=\"https://discord.com/\">Discord</a> — это приложение чата, позволяющее миллионам пользователей со всего мира обмениваться сообщениями и общаться в голосовом чате в сообществах, называемых <a href=\"https://discord.com/developers/docs/resources/guild\">«гильдии»</a> или «серверы». Discord также включает функциональный API, который разработчики смогут использовать для построения мощных ботов Discord. Боты могут выполнять разнообразные действия, в том числе отправлять сообщения на серверы, отправлять пользователям сообщения DM, модерировать серверы и воспроизводить звук в голосовых чатах. Это позволяет разработчикам создавать мощных ботов со сложными и продвинутыми функциями, включая инструменты модерирования и даже игры. Например, служебный бот <a href=\"https://dyno.gg/bot\">Dyno</a> обслуживает миллионы гильдий и содержит множество полезных функций, включая защиту от спама, музыкальный проигрыватель и другие служебные функции. Научившись создавать боты Discord, вы получите множество возможностей, с которыми тысячи людей смогут взаимодействовать каждый день.</p>\n\n<p>В этом обучающем модуле мы создадим бот Discord с нуля, используя <a href=\"https://nodejs.org/en/\">Node.js</a> и библиотеку <a href=\"https://discord.js.org/#/\">Discord.js</a>, позволяющую пользователям взаимодействовать с Discord API напрямую. Мы настроим профиль бота Discord, получим токены аутентификации для бота и запрограммируем бот для обработки отправляемых пользователями команд с аргументами.</p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для начала вам потребуется следующее:</p>\n\n<ul>\n<li><p>Node.js, установленный на вашем компьютере для разработки. Чтобы установить его в macOS или Ubuntu 18.04, следуйте указаниям руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">Установка Node.js и создание локальной среды разработки в macOS</a> или раздела <strong>Установка с помощью PPA</strong> руководства <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">Установка Node.js в Ubuntu 18.04</a>.</p></li>\n<li><p>Любой текстовый редактор по вашему усмотрению, например, <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>, <a href=\"https://atom.io\">Atom</a>, <a href=\"https://www.sublimetext.com/\">Sublime</a> или <a href=\"https://www.nano-editor.org/\">Nano</a>.</p></li>\n<li><p><a href=\"https://discord.com/register\">Бесплатная учетная запись Discord</a> с подтвержденной учетной записью электронной почты и <a href=\"https://support.discord.com/hc/en-us/articles/204849977-How-do-I-create-a-server-\">бесплатный сервер Discord</a>, который вы будете использовать для тестирования вашего бота Discord.</p></li>\n</ul>\n\n<h2 id=\"Шаг-1-—-Настройка-бота-discord\">Шаг 1 — Настройка бота Discord</h2>\n\n<p>На этом шаге вы будете использовать графический интерфейс разработчиков Discord для настройки бота Discord и получения токена бота, который вы передадите в свою программу.</p>\n\n<p>Чтобы зарегистрировать бота на платформе Discord, используйте <a href=\"https://discord.com/developers/applications/\">панель приложений Discord</a>. Здесь разработчики могут создавать приложения Discord, включая ботов Discord.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png\" alt=\"Изображение панели приложений Discord после первого посещения сайта https://discord.com/developers/applications\"></p>\n\n<p>Для начала нажмите <strong>New Application</strong> (Новое приложение). Discord предложит вам ввести имя нового приложения. Затем нажмите <strong>Create</strong> (Создать) для создания приложения.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1b.png\" alt='Изображение командной строки для создания приложения с введенным именем приложения \"Test Node.js Bot\"'></p>\n\n<p><span class='note'><strong>Примечание.</strong> Имя приложения не связано с именем бота, и эти имена могут не совпадать.<br></span></p>\n\n<p>Теперь откройте свою панель приложения. Чтобы добавить бота в приложение, откройте вкладку <strong>Bot</strong> (Бот) на панели навигации слева.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1c.png\" alt=\"Изображение вкладки Bot на панели приложений\"></p>\n\n<p>Нажмите кнопку <strong>Add Bot</strong> (Добавить бота), чтобы добавить бота в приложение. Нажмите кнопку <strong>Yes, do it!</strong> (Да, сделать это!) в диалоге запроса подтверждения. Откроется панель с подробными сведениями об имени вашего бота, токене аутентификации и изображении в профиле.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1d.png\" alt=\"Панель с подробными сведениями о боте\"></p>\n\n<p>На этой панели вы можете изменить имя бота или изображение профиля. Также необходимо скопировать токен аутентификации бота, нажав <strong>Click to Reveal Token</strong> (Нажмите для показа токена) и скопировав отображаемый токен.</p>\n\n<p><span class='warning'><strong>Предупреждение.</strong> Никогда не публикуйте и не выгружайте в сеть свой токен бота, поскольку это позволит любому пользователю выполнить вход в бот.<br></span></p>\n\n<p>Теперь нужно создать приглашение, которое позволяет добавить гильдии ботов Discord, где вы можете протестировать бот. Вначале перейдите на вкладку <strong>OAuth2</strong> на панели приложения. Чтобы создать приглашения, прокрутите страницу и выберите <strong>бота</strong> в разделе <strong>scopes</strong>. Также необходимо установить разрешения, чтобы определить, какие действия бот может выполнять в гильдиях. Для целей этого обучающего модуля выберите пункт <strong>Administrator</strong> (Администратор), которые дадут вашему боту разрешения для выполнения в гильдиях практически любых действий. Скопируйте ссылку с помощью кнопки <strong>Copy</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1e.png\" alt=\"Вкладка OAuth2 с установленной сферой действия bot и уровнем разрешений administator\"></p>\n\n<p>Затем добавьте бот на сервер. Перейдите по созданной ссылке с приглашением. Вы можете добавить бот на любой сервер, который вам принадлежит или на котором у вас есть права администратора, используя выпадающее меню.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1f.png\" alt=\"Страница после перехода по ссылке с приглашением, что позволяет пользователям добавлять бот на серверы\"></p>\n\n<p>Теперь нажмите кнопку <strong>Continue</strong> (Продолжить). Обязательно установите отметку рядом с полем <strong>Administrator</strong>, чтобы предоставить боту разрешения администратора. Затем нажмите <strong>Authorize</strong> (Авторизация). Discord предложит вам решить головоломку <a href=\"https://en.wikipedia.org/wiki/CAPTCHA\">CAPTCHA</a>, прежде чем бот сможет подключиться к серверу. Теперь наш бот Discord отображается в списке пользователей сервера, на который вы добавили бота, со статусом <strong>offline</strong> (не в сети).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1g.png\" alt=\"Список пользователей сервера Discord с новым ботом в разделе offline списка пользователей\"></p>\n\n<p>Вы успешно создали бота Discord и добавили его на сервер. Далее мы напишем программу для входа в бот.</p>\n\n<h2 id=\"Шаг-2-—-Создание-проекта\">Шаг 2 — Создание проекта</h2>\n\n<p>На этом шаге мы настроим базовую среду программирования, где выполним сборку бота и войдем в него программным путем.</p>\n\n<p>Вначале необходимо настроить папку проекта и необходимые файлы проекта для бота.</p>\n\n<p>Создайте папку проекта:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Перейдите в только что созданную папку проекта:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Далее используйте текстовый редактор для создания файла с именем <code>config.json</code> для сохранения токена аутентификации вашего бота:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano config.json\n</li></ul></code></pre>\n<p>Затем добавьте в файл конфигурации следующий код, заменяя выделенный текст токеном аутентификации вашего бота:</p>\n<div class=\"code-label \" title=\"config.json\">config.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">{\n    \"BOT_TOKEN\": \"<span class=\"highlight\">YOUR BOT TOKEN</span>\"\n}\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Затем мы создадим файл <code>package.json</code>, где будут храниться детали нашего проекта и информация о зависимостях, используемых в проекте. Для создания файла <code>package.json</code> запустите следующую команду <code>npm</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm init\n</li></ul></code></pre>\n<p><code>npm</code> запросит различные детали вашего проекта. Если вам нужны указания по <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-node-js-modules-with-npm-and-package-json#step-1-%E2%80%94-creating-a-packagejson-file\">ответам на эти запросы, воспользуйтесь руководством «Использование модулей Node.js с npm и package.json</a>».</p>\n\n<p>Сейчас мы установим пакет <code>discord.js</code>, который будем использовать для взаимодействия с Discord API. Вы можете установить <code>discord.js</code> через npm с помощью следующей команды:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm install discord.js\n</li></ul></code></pre>\n<p>Мы настроили файл конфигурации, установили необходимую зависимость и теперь можем начать сборку бота. В реальном приложении мы бы разделили код большого бота на несколько файлов, но в этом обучающем модуле мы поместим весь код бота в один файл.</p>\n\n<p>Вначале создайте файл с именем <code>index.js</code> в папке <code><span class=\"highlight\">discord-bot</span></code> для кода:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Начните программирование бота, запросив зависимость <code>discord.js</code> и файл конфигурации с токеном бота:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n</code></pre>\n<p>После этого добавьте следующие две строки кода:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Первая строка кода создает новый клиент <code>Discord.Client</code> и назначает его как значение константы <code>client</code>. Этот клиент частично обеспечивает взаимодействие с Discord API и получает уведомления Discord о событиях, например, о новых сообщениях. Фактически клиент представляет бот Discord.</p>\n\n<p>Во второй строке кода метод <code>login</code> используется на <code>клиенте</code> для входа в созданный бот Discord с использованием токена в файле <code>config.json</code> в качестве пароля. Токен сообщает Discord API, для какого бота предназначена программа, а также подтверждает вашу аутентификацию для использования бота.</p>\n\n<p>Теперь запустите файл <code>index.js</code> с помощью Node:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Теперь статус вашего бота на сервере Discord, куда вы его добавили, изменится на online (в сети).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step2a.png\" alt=\"Изображение бота со статусом online\"></p>\n\n<p>Мы успешно настроили среду программирования и создали базовый код для входа в бот Discord. На следующем шаге мы займемся пользовательскими командами и заставим бота выполнить определенные действия, например, отправить сообщения.</p>\n\n<h2 id=\"Шаг-3-—-Обработка-первой-команды-пользователя\">Шаг 3 — Обработка первой команды пользователя</h2>\n\n<p>На этом шаге мы создадим бот, который может обрабатывать команды пользователя. Вы запустите свою первую команду <code>ping</code>, на которую будет отправлен ответ <code>pong</code> с указанием времени ответа на команду.</p>\n\n<p>Сначала необходимо обеспечить обнаружение и получение любых отправляемых пользователями сообщений, чтобы бот мог обрабатывать любые команды. Используя метод <code>on</code> клиента Discord, Discord будет отправлять вам уведомления о новых событиях. Метод <code>on</code> принимает два аргумента: название ожидаемого события и функцию, которая будет запускаться каждый раз, когда будет возникать это событие. С этим методом вы можете ожидать события <code>message</code>, которое будет возникать каждый раз при отправке сообщения в гильдию, где у бота имеется разрешение на просмотр сообщений. Поэтому мы создадим функцию, которая будет запускаться для обработки команд каждый раз при отправке сообщения.</p>\n\n<p>Вначале откройте свой файл:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Добавьте в файл следующий код:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\n\n<span class=\"highlight\">client.on(\"message\", function(message) { </span>\n<span class=\"highlight\">                                         </span>\n<span class=\"highlight\">});                                      </span>\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Эта функция, выполняемая для события <code>message</code>, принимает параметр <code>message</code>. Параметр <code>message</code> имеет значение экземпляра <a href=\"https://discord.js.org/#/docs/main/stable/class/Message\">Discord.js message</a>, содержащее информацию об отправленном сообщении и методах, которые помогут боту ответить на него.</p>\n\n<p>Добавьте следующую строку кода в функцию обработки команд:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  <span class=\"highlight\">if (message.author.bot) return;</span>\n});\n...\n</code></pre>\n<p>Эта строка проверяет, является ли автор сообщения ботом, и если это так, останавливает обработку команды. Это важно, поскольку обычно нам не нужно обрабатывать сообщения ботов или отвечать на них. Другим ботам обычно не требуется использовать наш бот, и поэтому игнорирование их сообщений позволит нам сэкономить вычислительную мощность и предотвратить случайные ответы.</p>\n\n<p>Теперь мы напишем обработчик команд. Для этого важно понимать обычный формат команды Discord. Обычно структура команды Discord содержит три части в следующем порядке: префикс, имя команды и (иногда) аргументы команды.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png\" alt='Изображение типичной команды Discord \"! add 1 2\"'></p>\n\n<ul>\n<li><p>Префикс: префикс может быть любым, но обычно это знак пунктуации или абстрактная фраза, которая обычно не может располагаться в начале сообщения. Это означает, что при добавлении префикса в начало сообщения бот будет знать, что это команда, которую ему необходимо обработать.</p></li>\n<li><p>Имя команды: имя команды, которое пользователь хочет использовать. Это означает, что бот может поддерживать несколько команд с разными функциями и разрешать пользователям выбирать между ними, используя разные имена команд.</p></li>\n<li><p>Аргументы: иногда команда запрашивает или использует дополнительную информацию от пользователя, и пользователь может указывать аргументы после имени команды, разделяя их пробелами.</p></li>\n</ul>\n\n<p><span class='note'><strong>Примечание.</strong> Принудительно устанавливаемой структуры команд нет, и боты могут обрабатывать команды как угодно, однако здесь мы описываем эффективную структуру, которую использует большинство ботов.<br></span></p>\n\n<p>Чтобы начать создание синтаксического анализатора команд, поддерживающего этот формат, добавьте следующие строки кода в функцию обработки сообщений:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n<span class=\"highlight\">const prefix = \"!\";</span>\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  <span class=\"highlight\">if (!message.content.startsWith(prefix)) return;</span>\n});\n...\n</code></pre>\n<p>Первая строка кода добавляется, чтобы присвоить значение <code>\"!\"</code> константе <code>prefix</code>, которую мы будем использовать в качестве префикса бота.</p>\n\n<p>Вторая строка кода проверяет, начинается ли содержание обрабатываемого ботом сообщения с заданного префикса, и останавливает дальнейшую обработку сообщения, если префикса нет.</p>\n\n<p>Теперь необходимо конвертировать остальную часть сообщения в название команды и любые аргументы, которые могут присутствовать в сообщении. Добавьте следующие выделенные строки:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  <span class=\"highlight\">const commandBody = message.content.slice(prefix.length);</span>\n  <span class=\"highlight\">const args = commandBody.split(' ');</span>\n  <span class=\"highlight\">const command = args.shift().toLowerCase();</span>\n});\n...\n</code></pre>\n<p>Первая строка используется для удаления префикса из содержания сообщения и назначения результата константе <code>commandBody</code>. Это необходимо, поскольку нам не нужно, чтобы префикс входил в обработанное имя команды.</p>\n\n<p>Вторая строка принимает сообщение с удаленным префиксом и использует на нем <a href=\"https://www.digitalocean.com/community/tutorials/how-to-index-split-and-manipulate-strings-in-javascript#splitting-strings\">метод <code>split</code></a> с пробелом в качестве разделителя. Он разделяет команду на массив субстрок, проводя разделение после каждого пробела. В результате получается массив, содержащий имя команды, за которым идут аргументы (если они содержатся в сообщении). Мы назначаем этот массив константе <code>args</code>.</p>\n\n<p>Третья строка удаляет первый элемент из массива <code>args</code> (это будет имя команды), конвертирует его в нижний регистр и назначает константе <code>command</code>. Это позволяет изолировать имя команды и оставить в массиве только аргументы. Также мы используем метод <code>toLowerCase</code>, поскольку команды в ботах Discord обычно не учитывают регистр.</p>\n\n<p>Мы завершили построение синтаксического анализатора команд с реализацией обязательного префикса и получением имени команды и всех аргументов из сообщений. Теперь мы реализуем и создадим код для определенных команд.</p>\n\n<p>Добавьте следующий код, чтобы начать реализацию команды <code>ping</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  <span class=\"highlight\">if (command === \"ping\") {</span>\n  <span class=\"highlight\">                         </span>\n  <span class=\"highlight\">}                        </span>\n});\n...\n</code></pre>\n<p>Это <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-conditional-statements-in-javascript\">выражение <code>if</code></a> проверяет соответствие обработанного имени команды (назначенного константе <code>command</code>) значению <code>\"ping\"</code>. Такое соответствие означает, что пользователь хочет использовать команду <code>\"ping\"</code>. Мы вложим код определенной команды в блок выражения <code>if</code>. Впоследствии вы сможете использовать этот шаблон для других команд.</p>\n\n<p>Теперь вы можете реализовать код для команды <code>\"ping\"</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    <span class=\"highlight\">const timeTaken = Date.now() - message.createdTimestamp;</span>\n    <span class=\"highlight\">message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);</span>\n  }\n...\n</code></pre>\n<p>Сохраните и закройте файл.</p>\n\n<p>Мы добавляем блок команды <code>\"ping\"</code>, который рассчитывает разницу между текущим временем, определяемым с помощью <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now\">метода <code>now</code></a> объекта <code>Date</code>, и временной меткой создания сообщения, выражаемую в миллисекундах. Таким образом рассчитывается время обработки сообщения и ответа бота на команду <code>\"ping\"</code>.</p>\n\n<p>Вторая строка отвечает на команду пользователя, используя метод <code>reply</code> с константой <code>message</code>. <a href=\"https://discord.js.org/#/docs/main/stable/class/Message?scrollTo=reply\">Метод <code>reply</code></a> отправляет запрос ping (уведомляющий пользователя и выделяющий сообщение для указанного пользователя) пользователю, который отправил команду, добавляя после запроса содержание, указанное в качестве первого аргумента метода. Мы указали <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">литераль шаблона</a>, содержащую сообщение и рассчитанное значение ping, в качестве ответа, который будет использоваться методом <code>reply</code>.</p>\n\n<p>На этом мы завершаем реализацию команды <code>\"ping\"</code>.</p>\n\n<p>Запустите свой бот с помощью следующей команды (в той же папке, что и <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Теперь вы можете использовать команду <code>\"! ping\"</code> на любом канале, где бот может просматривать и принимать сообщения, а также отправлять ответы.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png\" alt='Изображение бота, отвечающего в Discord на запрос \"! ping\" ответом \"@T0M, Pong! This message had a latency of 1128ms.\"'></p>\n\n<p>Вы успешно создали бот, который может обрабатывать команды пользователей, и реализовали свою первую команду. На следующем шаге мы продолжим разработку бота, реализовав команду sum.</p>\n\n<h2 id=\"Шаг-4-—-Реализация-команды-sum\">Шаг 4 — Реализация команды Sum</h2>\n\n<p>Теперь мы расширим нашу программу, реализовав команду <code>\"! sum\"</code>. Эта команда принимает любое количество аргументов, складывает их и возвращает пользователю сумму всех аргументов.</p>\n\n<p>Если ваш бот Discord еще работает, вы можете остановить его процессы, нажав <code>CTRL + C</code>.</p>\n\n<p>Откройте файл <code>index.js</code> снова:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Чтобы начать реализацию команды <code>\"! sum\"</code>, мы используем блок <code>else-if</code>. После проверки имени команды ping бот будет проверять, имеет ли имя команды значение <code>\"sum\"</code>. Мы используем блок <code>else-if</code>, потому что одновременно будет обрабатываться только одна команда, и если программа определит совпадение с именем команды <code>\"ping\"</code>, ей не нужно будет проводить проверку на совпадение с именем команды <code>\"sum\"</code>. Добавьте в файл следующие выделенные строки:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Ping! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  <span class=\"highlight\">else if (command === \"sum\") {</span>\n  <span class=\"highlight\">                             </span>\n  <span class=\"highlight\">}                            </span>\n});\n...\n</code></pre>\n<p>Теперь вы можете начать реализацию кода для команды <code>\"sum\"</code>. Код команды <code>\"sum\"</code> будет размещен в только что созданном нами блоке <code>else-if</code>. Теперь добавьте следующий код:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  else if (command === \"sum\") {\n    <span class=\"highlight\">const numArgs = args.map(x =&gt; parseFloat(x));</span>\n    <span class=\"highlight\">const sum = numArgs.reduce((counter, x) =&gt; counter += x);</span>\n    <span class=\"highlight\">message.reply(`The sum of all the arguments you provided is ${sum}!`);</span>\n  }\n...\n</code></pre>\n<p>Мы используем <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#map()\">метод <code>map</code></a> для списка аргументов, чтобы создать новый список, используя функцию <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseFloat\"><code>parseFloat</code></a> для каждого элемента в массиве <code>args</code>. При этом создается новый массив (назначенный константе <code>numArgs</code>), где все элементы являются числами, а не строками. Это означает, что в дальнейшем вы можете определить сумму чисел, выполнив операцию сложения.</p>\n\n<p>Вторая строка использует <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#reduce()\">метод <code>reduce</code></a> на константе <code>numArgs</code>, предоставляя функцию, суммирующую все элементы в списке. Мы назначаем сумму всех элементов в <code>numArgs</code> как значение константы <code>sum</code>.</p>\n\n<p>Затем мы используем метод <code>reply</code> на объекте сообщений, чтобы ответить на команду пользователя, отправив <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">литераль шаблона</a>, содержащую сумму всех аргументов, отправленных пользователем боту.</p>\n\n<p>Это завершает реализацию команды <code>\"sum\"</code>. Теперь запустите бот, используя следующую команду (в той же папке, что и <code>index.js</code>):</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Теперь вы можете использовать команду <code>\"! sum\"</code> на любом канале, где бот может просматривать и отправлять сообщения.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step4a.png\" alt='Изображение бота, отвечающего \"The sum of all the arguments you provided is 6!\" на \"! sum 1 2 3\", а затем отвечающего \"The sum of all the arguments you provided is 13! на \"! sum 1.5 1.5 10\"'></p>\n\n<p>Далее приведена законченная версия скрипта бота <code>index.js</code>:</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n\nconst client = new Discord.Client();\n\nconst prefix = \"!\";\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  const commandBody = message.content.slice(prefix.length);\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  else if (command === \"sum\") {\n    const numArgs = args.map(x =&gt; parseFloat(x));\n    const sum = numArgs.reduce((counter, x) =&gt; counter += x);\n    message.reply(`The sum of all the arguments you provided is ${sum}!`);\n  }\n});\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>На этом шаге мы дополнили наш бот Discord, реализовав в нем команду <code>sum</code>.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>Мы успешно создали бот Discord, который может обрабатывать разные команды пользователей и аргументы команд. Если вы хотите расширить возможности вашего бота, вы можете реализовать дополнительные команды или использовать другие части Discord API для построения мощного бота Discord. Вы можете ознакомиться с <a href=\"https://discord.js.org/#/docs/main/stable/general/welcome\">документацией по Discord.js</a> или <a href=\"https://discord.com/developers/docs/intro\">Discord API</a>, чтобы узнать больше о Discord API.</p>\n\n<p>При создании ботов Discord всегда помните об <a href=\"https://discord.com/developers/docs/legal\">условиях обслуживания Discord API</a>, определяющих требования к использованию Discord API разработчиками. Также вам может быть полезен <a href=\"https://github.com/meew0/discord-bot-best-practices/blob/master/README.md\">этот набор рекомендаций</a>, показывающий наилучшие способы построения бота Discord и содержащий советы по проектированию ботов Discord. Если вы хотите узнать больше о Node.js, ознакомьтесь с нашей <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">серией материалов «Программирование в Node.js»</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:39 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png","linkMd5":"53f7b8863b0e9dfc01055a304d0f4785","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","destWidth":1920,"destHeight":973,"sourceBytes":66395,"destBytes":26384,"author":"Tom","articleImgCdnMap":{"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1b.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn9@2020_3/2020/08/31/07-48-31-275_690c64ccbc0c5170.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1c.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn30@2020_4/2020/08/31/07-48-31-778_f5a474e22c90438c.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1d.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_6/2020/08/31/07-48-31-392_d550c10707834d3f.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1e.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/31/07-48-31-921_817dcbabd0b27a3d.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1f.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn89@2020_2/2020/08/31/07-48-31-288_1d3824d3640df0a3.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1g.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn77@2020_3/2020/08/31/07-48-31-225_5aca524b04a26500.webp","https://assets.digitalocean.com/articles/node_discord_bot/step2a.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn74@2020_2/2020/08/31/07-48-31-293_81968c3f6c9ff261.webp","https://assets.digitalocean.com/articles/node_discord_bot/step3a.png":null,"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn98@2020_5/2020/08/31/07-48-33-506_74310bb53d7bafb2.webp","https://assets.digitalocean.com/articles/node_discord_bot/step4a.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn70@2020_4/2020/08/31/07-48-31-272_5589082ccebd5fbf.webp"},"publishedOrCreatedDate":1598860106983},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Installieren eines ERPNext-Stacks unter Ubuntu 18.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","description":"<p><em>Der Autor hat <a href=\"https://www.brightfunds.org/organizations/software-in-the-public-interest-inc\">Software in the Public Interest</a> dazu ausgewählt, im Rahmen des Programms <a href=\"https://do.co/w4do-cta\">Write for DOnations</a> eine Spende zu erhalten.</em></p>\n\n<h3 id=\"einführung\">Einführung</h3>\n\n<p><a href=\"https://erpnext.com//\">ERPNext</a> ist eine Suite für Enterprise Resource Planning (ERP), die die Leistung und Flexibilität von Open-Source-Technologien nutzt. Sie eignet sich bestens zur Verwaltung von wichtigen Geschäftsprozessen wie Finanzen, Vertrieb, Personalverwaltung, Herstellung, Einkauf, Dienstleistungen, Helpdesk und vielem mehr. Zu den Vorteilen der Implementierung eines Systems wie ERPNext gehören:</p>\n\n<ul>\n<li>Höhere Produktivität durch Automatisieren wiederholter Geschäftsprozesse</li>\n<li>Verbesserte IT-Effizienz durch Freigabe einer Datenbank für alle Abteilungen innerhalb des Unternehmens</li>\n<li>Bessere Entscheidungsprozesse dank einer integrierten Übersicht darüber, wie Geschäftseinheiten miteinander verbunden sind</li>\n</ul>\n\n<p>ERPNext basiert auf <a href=\"https://frappe.io/frappe\">Frappe</a>, einem Full-Stack-Webanwendungsframework, das in <a href=\"https://www.python.org/\">Python</a> geschrieben wurde. Es nutzt umfassend die <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">Node-/JavaScript-Laufzeitumgebung</a> und verwendet <a href=\"https://mariadb.org/\">MariaDB</a> als Datenbank-Backend. Einer der vielen Vorteile von Frappe-basierten Anwendungen wie ERPNext ist das Befehlszeilentool <a href=\"https://github.com/frappe/bench\">bench</a>. Die bench-CLI speichert Administratoren Zeit, indem sie Aufgaben wie Installation, Aktualisierung, Konfiguration und Verwaltung verschiedener Frappe-/ERPNext-Sites automatisiert.</p>\n\n<p>In diesem Tutorial installieren und konfigurieren Sie einen ERPNext-Stack auf einem Server, auf dem Ubuntu 18.04 ausgeführt wird. Dadurch können Sie Ihren Stack je nach Bedarf für verschiedene Entwicklungs- oder Produktionsumgebungen konfigurieren. So erhalten Sie die Möglichkeit, eine komplexere und fehlertolerantere Architektur einzurichten.</p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<ul>\n<li>Ein Ubuntu 18.04-Server mit mindestens 4 GB RAM und einem Nicht-root-Benutzer mit <code>sudo</code>-Berechtigungen. Sie können Ihren Server und Benutzer einrichten, indem Sie unserem <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">Leitfaden zur Ersteinrichtung des Servers unter Ubuntu 18.04</a> folgen.</li>\n</ul>\n\n<p><span class='note'><strong>Anmerkung:</strong> Bei der Auswahl der Spezifikationen Ihres Servers sollten Sie daran denken, dass ERP-Systeme ressourcenintensiv sind. Dieser Leitfaden erfordert einen Server mit 4 GB RAM, was für grundlegende Anwendungsfälle ausreicht. Die spezifischen Hardwareanforderungen können jedoch je nach Anzahl der Benutzer sowie der Unternehmensgröße variieren.<br></span></p>\n\n<ul>\n<li>Ein vollständig registrierter Domänenname mit einem A-Eintrag, der auf Ihren Server verweist. Wenn Sie ein DigitalOcean-Droplet verwenden, können Sie <a href=\"https://www.digitalocean.com/community/tutorials/how-to-point-to-digitalocean-nameservers-from-common-domain-registrars\">diesem Leitfaden</a> folgen, um Ihr DNS richtig einzurichten. In diesem Tutorial wird überall <code><span class=\"highlight\">your_domain</span></code> verwendet.</li>\n</ul>\n\n<h2 id=\"schritt-1-mdash-konfigurieren-der-firewall\">Schritt 1 — Konfigurieren der Firewall</h2>\n\n<p>Zwar ist die Konfiguration einer Firewall für Entwicklungsumgebungen optional, für die Produktion ist sie jedoch eine obligatorische Sicherheitsmaßnahme.</p>\n\n<p>Sie müssen auf Ihrem ERPNext-Server die folgenden Ports öffnen:</p>\n\n<ul>\n<li><code>80/tcp</code> und <code>443/tcp</code> für HTTP bzw. HTTPS</li>\n<li><code>3306/tcp</code> für die MariaDB-Verbindung (nur empfohlen, wenn Sie Remotezugriff auf die Datenbank benötigen)</li>\n<li><code>143/tcp</code> und <code>25/tcp</code> für IMAP bzw. STMP</li>\n<li><code>22/tcp</code> für SSH (wenn Sie <code>OpenSSH</code> nicht bereits aktiviert haben)</li>\n<li><code>8000/tcp</code> für Entwicklungstests, bevor Sie Ihre Site bereitstellen</li>\n</ul>\n\n<p>Zum Öffnen verschiedener Ports auf einmal können Sie folgenden Befehl verwenden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow 22,25,143,80,443,3306,8000/tcp\n</li></ul></code></pre>\n<p>Alternativ können Sie Verbindungen von bestimmten IP-Adressen zu bestimmten Ports mit diesem Befehl zulassen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow from <span class=\"highlight\">server_IP</span> to any port <span class=\"highlight\">port_number</span>\n</li></ul></code></pre>\n<p>Nach dem Öffnen aller erforderlichen Ports aktivieren Sie die Firewall:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw enable\n</li></ul></code></pre>\n<p>Nach Aktivierung der Firewall prüfen Sie den Status Ihrer offenen Ports:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw status\n</li></ul></code></pre>\n<p>Weitere Informationen zum Firewall-Setup finden Sie in unserem Leitfaden <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-18-04\">Einrichten einer Firewall mit UFW unter Ubuntu 18.04</a>.</p>\n\n<p>Das Einrichten einer ordnungsgemäß funktionierenden Firewall ist der erste von zwei Vorbereitungsschritten. Jetzt konfigurieren Sie die Tastenbelegung und Zeichencodierung auf Ihrem Server.</p>\n\n<h2 id=\"schritt-2-mdash-konfigurieren-von-gebietsschemas\">Schritt 2 — Konfigurieren von Gebietsschemas</h2>\n\n<p>Es wird dringend empfohlen, die Tastenbelegung für die Konsole sowie die Sprache und die Zeichencodierung auf Ihrem Host zu konfigurieren. Dies ist notwendig, um mögliche Probleme bei der ERPNext 12-Installation zu verhindern. Beachten Sie, dass diese Konfiguration nichts mit der UI-Sprache in Ihrer eigentlichen ERPNext-Plattform zu tun hat, sondern mit der Systemkonfiguration des Gebietsschemas.</p>\n\n<p>Aktualisieren Sie zunächst Ihren Server:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Konfigurieren Sie nun die Tastenbelegung, Sprache und Zeichencodierung:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo localectl set-keymap us &amp;&amp; sudo localectl set-locale LANG=en_US.utf8\n</li></ul></code></pre>\n<p>Das Dienstprogramm <code>localectl</code> wird von Ubuntu 18.04 und anderen Linux-Distributionen verwendet, um systemweite Einstellungen für das Gebietsschema und die Tastaturbelegung zu steuern und zu ändern, bevor der Benutzer sich anmeldet. Das ist genau das, was ERPNext 12 benötigt.</p>\n\n<p>Sie müssen Ihrer Datei <code>/etc/environment</code> außerdem die folgenden Zeilen hinzufügen. Verwenden Sie <code>nano</code> oder Ihren bevorzugten Texteditor, um die Datei zu öffnen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/environment\n</li></ul></code></pre>\n<p>Fügen Sie jetzt den folgenden Inhalt hinzu.</p>\n<div class=\"code-label \" title=\"/etc/environment\">/etc/environment</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">LC_ALL=en_US.UTF-8\nLC_CTYPE=en_US.UTF-8\nLANG=en_US.UTF-8\n</code></pre>\n<p>Speichern und schließen Sie die Datei.</p>\n\n<p>Starten Sie Ihren Server neu, um alle Änderungen anzuwenden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo reboot\n</li></ul></code></pre>\n<p>Geben Sie Ihrem Server einige Minuten zum Neustart und stellen Sie dann erneut eine <code>SSH</code>-Verbindung her. Sie sind nun bereit, Ihre Datenbank zu installieren.</p>\n\n<h2 id=\"schritt-3-mdash-installieren-von-mariadb-10-04\">Schritt 3 — Installieren von MariaDB 10.04</h2>\n\n<p>Jetzt fügen Sie MariaDB Ihrem Server-Stack hinzu. ERPNext 12 erfordert MariaDB 10.2 oder höher; die im offiziellen Repository von Ubuntu 18.04 enthaltene Version lautet jedoch 10.1, was bedeutet, dass Sie eine höhere Version installieren müssen. Für die Zwecke dieses Leitfadens verwenden Sie die neueste stabile Version von MariaDB, zum Zeitpunkt der Verfassung dieses Textes Version 10.4.</p>\n\n<p>Um MariaDB 10.4 unter Ubuntu 18.04 zu installieren, müssen Sie den entsprechenden Signaturschlüssel und das Repository hinzufügen. Diese Informationen finden Sie im <a href=\"https://downloads.mariadb.org/mariadb/repositories/#mirror=klaus\">Repository-Assistenten der MariaDB Foundation</a>. Besuchen Sie diese URL in Ihrem Webbrowser. Klicken Sie nun unter <strong>1. Choose a Distro</strong> (1. Distro wählen) auf <strong>Ubuntu</strong>. Eine zweite Spalte mit dem Titel <strong>2. Choose a Release</strong> (2. Release wählen) wird angezeigt. Klicken Sie unter diesem Titel auf <strong>18.04 LTS &ldquo;bionic&rdquo;</strong>. Dann wird eine dritte Spalte mit dem Titel <strong>3. Choose a Version</strong> (3. Version wählen) angezeigt. Klicken Sie darunter auf <strong>10.4 stable</strong>. Eine dritte Spalte mit dem Titel <strong>4. Choose a Mirror</strong> (4. Spiegelung wählen) wird angezeigt. Wählen Sie eine auf Ihrem Standort basierende Spiegelung aus; dann wird MariaDB die entsprechenden Befehle für Ihre benutzerdefinierte Installation eingeben.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_0.png\" alt=\"Repository-Assistent von MariaDB\"></p>\n\n<p>Führen Sie die drei eingegebenen Befehle aus, wodurch das MariaDB-Repository und der Schlüssel ordnungsgemäß hinzugefügt werden. Ihre eigenen Befehle werden etwa wie folgt aussehen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt-get install software-properties-common &amp;&amp; sudo apt-key adv --fetch-keys <span class=\"highlight\">'https://mariadb.org/mariadb_release_signing_key.asc'</span> &amp;&amp; sudo add-apt-repository 'deb [arch=amd64,arm64,ppc64el] <span class=\"highlight\">http://mirror.klaus-uwe.me/mariadb/repo/10.4/ubuntu</span> bionic main'\n</li></ul></code></pre>\n<p>Sobald Sie das Repository hinzugefügt haben, installieren Sie MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install mariadb-server\n</li></ul></code></pre>\n<p>Installieren Sie nach der Installation von <code>mariadb-server</code> die folgenden Pakete:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install libmysqlclient-dev python3-mysqldb\n</li></ul></code></pre>\n<p>ERPNext 12 ist eine Python-Anwendung und benötigt daher die Bibliothek <code>python3-mysqldb</code> für das Datenbankmanagement. Bezüglich <code>libmysqlclient-dev</code>, <code>mariadb-client</code> und <code>libmariadbclient18</code>: Über diese Pakete können Benutzer mit dem MariaDB-Dienst kommunizieren. <code>ntpdate</code> und <code>libdate-manip-perl</code> werden von ERPNext zur Synchronisierung der Serverzeit verwendet.</p>\n\n<p>Fügen Sie dem MariaDB-Server als Nächstes eine grundlegende Sicherheitsschicht hinzu, indem Sie das Skript <code>mysql_secure_installation</code> ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql_secure_installation\n</li></ul></code></pre>\n<p>Das Skript <code>mysql_secure_installation</code> wird Ihnen mehrere Fragen stellen:</p>\n\n<ul>\n<li>Die erste Eingabeaufforderung wird Sie nach dem <strong>root</strong>-Passwort fragen. Da jedoch noch kein Passwort konfiguriert ist, drücken Sie die <code>Eingabetaste</code>.</li>\n<li>Als Nächstes müssen Sie entscheiden, ob Sie Unix-Authentifizierung verwenden möchten oder nicht. Antworten Sie mit <code>Y</code> (J), um diese Authentifizierungsmethode zu akzeptieren.</li>\n<li>Antworten Sie mit <code>N</code>, wenn Sie dazu aufgefordert werden, das<strong>root</strong>-Passwort für MariaDB zu ändern. Eine Verwendung des Standardpassworts zusammen mit Unix-Authentifizierung ist das empfohlene Verfahren für Ubuntu-basierte Systeme, da das <strong>root</strong>-Konto eng mit automatisierten Systemwartungsaufgaben verbunden ist.</li>\n<li>Die übrigen Fragen haben mit dem Entfernen des anonymen Datenbankbenutzers tun, wobei das <strong>root</strong>-Konto so beschränkt wird, dass es sich remote bei localhost anmeldet, die Testdatenbank entfernt wird und Berechtigungstabellen neu geladen werden. Sie können alle diese Fragen mit <code>Y</code> beantworten.</li>\n</ul>\n\n<p>Nach Abschluss des Skripts <code>mysql_secure_installation</code> wird MariaDB mit ihrer Standardkonfiguration gestartet. Die standardmäßige ERPNext-Installation verwendet für alle Datenbankoperationen den <strong>root</strong> user von MariaDB. Zwar mag dieser Ansatz für einzelne Serverkonfigurationen praktisch sein, doch gilt er nicht als besonders sicher. Im nächsten Abschnitt erfahren Sie daher, wie Sie das Problem vermeiden können, indem Sie einen neuen Benutzer mit speziellen Berechtigungen erstellen.</p>\n\n<h3 id=\"erstellen-eines-mariadb-super-admin-benutzers\">Erstellen eines MariaDB Super Admin-Benutzers</h3>\n\n<p>ERPNext erwartet, dass zur Verwaltung von Datenbankverbindungen der <strong>root</strong> user von MariaDB verwendet wird. Dies ist jedoch nicht immer ideal. Um diese Einschränkung zu umgehen und MariaDB von einem Nicht-root-Benutzer verwalten zu lassen, müssen Sie nun manuell eine Datenbank erstellen, die nach diesem Benutzer benannt ist. Dann können Sie dem neuen Benutzer spezielle Berechtigungen zuweisen, um ihm ERPNext-Datenbankoperationen zu ermöglichen.</p>\n\n<p>Öffnen Sie die Eingabeaufforderung von MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo mysql\n</li></ul></code></pre>\n<p>Erstellen Sie nun eine neue Datenbank, die nach dem Benutzer benannt ist, den Sie für MariaDB-Verbindungen zuweisen möchten. In diesem Tutorial wird <code><span class=\"highlight\">sammy</span></code> verwendet, Sie können jedoch einen Namen Ihrer Wahl nutzen:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">CREATE DATABASE <span class=\"highlight\">sammy</span>;\n</li></ul></code></pre>\n<p>Prüfen Sie mit dieser SQL-Anweisung, ob die Datenbank erstellt wurde:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SHOW DATABASES;\n</li></ul></code></pre>\n<p>Sie sehen eine Ausgabe, die dieser ähnelt:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| <span class=\"highlight\">sammy</span>             |\n+--------------------+\n</code></pre>\n<p>Erstellen Sie nun den MariaDB-Benutzer <code><span class=\"highlight\">sammy</span></code> mit Berechtigungen, die denen von <strong>root</strong> ähneln, und weisen Sie dem Benutzer ein starkes Passwort Ihrer Wahl zu. Bewahren Sie das Passwort an einem sicheren Ort auf; Sie werden es später benötigen:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">GRANT ALL PRIVILEGES ON *.* TO '<span class=\"highlight\">sammy</span>'@'%' IDENTIFIED BY '<span class=\"highlight\">mariadb_password</span>' WITH GRANT OPTION;\n</li></ul></code></pre>\n<p>Prüfen Sie nun sowohl die Erstellung des Benutzers als auch die Berechtigungen des neuen Benutzers:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">SELECT host, user, Super_priv FROM mysql.user;\n</li></ul></code></pre>\n<p>Sie werden eine Ausgabe wie diese sehen:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>+-----------+-------+------------+\n| Host      | User  | Super_priv |\n+-----------+-------+------------+\n| localhost | root  | Y          |\n| localhost | mysql | Y          |\n| %         | <span class=\"highlight\">sammy</span> | <span class=\"highlight\">Y</span>          |\n+-----------+-------+------------+\n3 rows in set (0.001 sec)\n</code></pre>\n<p>Bereinigen Sie nun Berechtigungen, um alle Änderungen anzuwenden:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">FLUSH PRIVILEGES;\n</li></ul></code></pre>\n<p>Abschließend beenden Sie die Sitzung:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"mysql&gt;\">exit\n</li></ul></code></pre>\n<p>Nachdem Sie einen Datenbankbenutzer erstellt haben, müssen Sie nun nur noch MariaDB optimieren, um einen ordnungsgemäßen Betrieb von ERPNext 12 sicherzustellen. Das ERPNext-Team verfügt zum Glück über eine ausgezeichnete Konfigurationsvorlage, die Sie als Ausgangspunkt für Ihre Implementierung verwenden werden. Im nächsten Abschnitt erfahren Sie, wie Sie die MariaDB-Datenbank mit dieser Vorlage richtig konfigurieren.</p>\n\n<h2 id=\"schritt-4-mdash-konfigurieren-von-mariadb-für-erpnext\">Schritt 4 — Konfigurieren von MariaDB für ERPNext</h2>\n\n<p>Nach dem Installieren und Schützen von MariaDB ist es nun an der Zeit für die Optimierung der ERPNext-Verbindungen.</p>\n\n<p>Halten Sie zunächst <code>mariadb.service</code> an:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl stop mariadb\n</li></ul></code></pre>\n<p>Verwenden Sie nun <code>nano</code> oder Ihren bevorzugten Texteditor, um eine MariaDB-Konfigurationsdatei namens <code>settings.cnf</code> zu erstellen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/conf.d/settings.cnf\n</li></ul></code></pre>\n<p>Fügen Sie nun die Konfigurationsvorlage von ERPNext hinzu:</p>\n<div class=\"code-label \" title=\"/etc/mysql/conf.d/settings.cnf\">/etc/mysql/conf.d/settings.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\n\n# GENERAL #\nuser                           = mysql\ndefault-storage-engine         = InnoDB\nsocket                         = /var/lib/mysql/mysql.sock\npid-file                       = /var/lib/mysql/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n# SAFETY #\nmax-allowed-packet             = 256M\nmax-connect-errors             = 1000000\ninnodb                         = FORCE\n\n# DATA STORAGE #\ndatadir                        = /var/lib/mysql/\n\n# BINARY LOGGING #\nlog-bin                        = /var/lib/mysql/mysql-bin\nexpire-logs-days               = 14\nsync-binlog                    = 1\n\n# REPLICATION #\nserver-id                      = 1\n\n# CACHES AND LIMITS #\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\nquery-cache-type               = 0\nquery-cache-size               = 0\nmax-connections                = 500\nthread-cache-size              = 50\nopen-files-limit               = 65535\ntable-definition-cache         = 4096\ntable-open-cache               = 10240\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\ninnodb-log-file-size           = 512M\ninnodb-flush-log-at-trx-commit = 1\ninnodb-file-per-table          = 1\ninnodb-buffer-pool-size        = 5462M\ninnodb-file-format             = barracuda\ninnodb-large-prefix            = 1\ncollation-server               = utf8mb4_unicode_ci\ncharacter-set-server           = utf8mb4\ncharacter-set-client-handshake = FALSE\nmax_allowed_packet             = 256M\n\n# LOGGING #\nlog-error                      = /var/lib/mysql/mysql-error.log\nlog-queries-not-using-indexes  = 0\nslow-query-log                 = 1\nslow-query-log-file            = /var/lib/mysql/mysql-slow.log\n\n[mysql]\ndefault-character-set = utf8mb4\n\n[mysqldump]\nmax_allowed_packet=256M\n\n!includedir /etc/mysql/mariadb.conf.d/\n</code></pre>\n<p>Speichern und schließen Sie die Datei. Weitere Informationen zu diesen Konfigurationen <a href=\"https://github.com/frappe/erpnext/wiki/MySQL-configuration-file\">finden Sie in dieser Vorlagendatei im Github-Repository von ERPNext</a>. Dies ist ein nützlicher Ausgangspunkt für die Erkundung der Optionen.</p>\n\n<p>Erstellen Sie als Nächstes eine weitere Datei namens <code>erpnext.cnf</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/mysql/mariadb.conf.d/erpnext.cnf\n</li></ul></code></pre>\n<p>Fügen Sie der Datei folgenden Inhalt hinzu:</p>\n<div class=\"code-label \" title=\"/etc/mysql/mariadb.conf.d/erpnext.cnf\">/etc/mysql/mariadb.conf.d/erpnext.cnf</div><pre class=\"code-pre \"><code class=\"code-highlight language-ini\">[mysqld]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nbind-address    = 0.0.0.0\n</code></pre>\n<p>Die erste Datei <code>/etc/mysql/conf.d/settings.cnf</code> ergänzt und überschreibt auch einige Werte, die in der Standardkonfiguration von MariaDB unter <code>/etc/mysql/my.cnf</code> enthalten sind. Diese Datei dient Ihnen als kuratierte Vorlage, die die Datenbankleistung für ERPNext erheblich verbessert. Beachten Sie, dass diese Vorlage zwar ein guter Ausgangspunkt ist, Sie die Leistung von MariaDB jedoch noch weiter verbessern können, indem Sie die Parameter an Ihre Bedürfnisse anpassen.</p>\n\n<p>Die zweite Datei <code>/etc/mysql/mariadb.conf.d/erpnext.cnf</code> überschreibt ebenfalls einige Werte, indem bestimmte Informationen zu Ihrer Datenbankverbindung hinzugefügt werden.</p>\n\n<h3 id=\"testen-der-mariadb-verbindung\">Testen der MariaDB-Verbindung</h3>\n\n<p>Da ERPNext bei fast allen internen Operationen auf die Datenbankverbindung angewiesen ist, ist es sinnvoll, die Verbindung vor dem Fortfahren zu testen.</p>\n\n<p>Starten Sie <code>mariadb.service</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start mariadb\n</li></ul></code></pre>\n<p>Zum Testen der Verbindung können Sie folgenden Befehl verwenden. Denken Sie daran, <code><span class=\"highlight\">sammy</span></code> und <code><span class=\"highlight\">mariadb_password</span></code> durch Ihre eigenen Anmeldedaten zu ersetzen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mysql --user <span class=\"highlight\">sammy</span> --password <span class=\"highlight\">mariadb_password</span> --host=localhost --protocol=tcp --port=3306 test\n</li></ul></code></pre>\n<p>Sie erhalten eine Ausgabe mit dem grundlegenden Hilfeinhalt von MariaDB und mehreren Parametern. Das bedeutet, dass Ihre Verbindung erfolgreich hergestellt wurde:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>mysql  Ver 15.1 Distrib 10.4.13-MariaDB, for debian-linux-gnu (x86_64) using readline 5.2\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nUsage: mysql [OPTIONS] [database]\n\nDefault options are read from the following files in the given order:\n/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\n\n...\n\n  --ssl-verify-server-cert\n                      Verify server's \"Common Name\" in its cert against\n                      hostname used when connecting. This option is disabled by\n                      default.\n  -t, --table         Output in table format.\n  --tee=name          Append everything into outfile. See interactive help (\\h)\n                      also. Does not work in batch mode. Disable with\n                      --disable-tee. This option is disabled by default.\n  -u, --user=name     User for login if not current user.\n  -U, --safe-updates  Only allow UPDATE and DELETE that uses keys.\n  -U, --i-am-a-dummy  Synonym for option --safe-updates, -U.\n  -v, --verbose       Write more. (-v -v -v gives the table output format).\n\n...\n\nmax-join-size                     1000000\nsecure-auth                       FALSE\nshow-warnings                     FALSE\nplugin-dir                        (No default value)\ndefault-auth                      (No default value)\nbinary-mode                       FALSE\nconnect-expired-password          FALSE\n</code></pre>\n<p>Wenn Sie Änderungen an den Einstellungen von MariaDB vornehmen oder Fehler beheben müssen, können Sie den Dienst mit dem folgenden Befehl neu laden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart mariadb\n</li></ul></code></pre>\n<p>Aktivieren Sie anschließend MariaDB:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable mariadb\n</li></ul></code></pre>\n<p>Nachdem Sie die Datenbankverbindung getestet haben, können Sie nun mit der Installation Ihrer ERPNext-Anwendung fortfahren.</p>\n\n<h2 id=\"schritt-5-mdash-einrichten-von-erpnext-12\">Schritt 5 — Einrichten von ERPNext 12</h2>\n\n<p>Nachdem Ihr Datenbank-Backend bereit ist, können Sie nun mit der Einrichtung Ihrer ERPNext-Webanwendung fortfahren. In diesem Abschnitt erfahren Sie, wie Sie alle von ERPNext 12 benötigten Komponenten installieren und konfigurieren und dann die Anwendung selbst installieren.</p>\n\n<p>Bereiten Sie zunächst mit allen Systempaketen, die ERPNext 12 benötigt, den Server vor. Installieren Sie systemweite Abhängigkeiten mit dem folgenden Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo DEBIAN_FRONTEND=noninteractive apt install -y curl build-essential mariadb-client python3-setuptools python3-dev libffi-dev python3-pip libcurl4 dnsmasq fontconfig git htop libcrypto++-dev libfreetype6-dev liblcms2-dev libwebp-dev libxext6 libxrender1 libxslt1-dev libxslt1.1 libffi-dev ntpdate postfix python3-dev python-tk screen vim xfonts-75dpi xfonts-base zlib1g-dev apt-transport-https libsasl2-dev libldap2-dev libcups2-dev pv libjpeg8-dev libtiff5-dev tcl8.6-dev tk8.6-dev libssl1.0-dev python3-mysqldb libdate-manip-perl logwatch\n</li></ul></code></pre>\n<p>Die Variable <code>DEBIAN_FRONTEND=noninteractive</code> wurde an den Installationsbefehl übergeben, um Postfix-Eingabeaufforderungen zu vermeiden. Detaillierte Informationen zur Postfix-Konfiguration finden Sie in unserem Leitfaden zum <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-postfix-on-ubuntu-18-04\">Installieren und Konfigurieren von Postfix unter Ubuntu 18.04.</a></p>\n\n<p>Aktualisieren Sie nun <code>pip3</code> und installieren Sie dann die neuesten Versionen von drei zusätzlichen Python-Modulen, die ERPNext benötigt:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\"> sudo -H python3 -m pip install --upgrade setuptools cryptography psutil\n</li></ul></code></pre>\n<p>Nachdem Sie alle erforderlichen globalen Abhängigkeiten installiert haben, installieren Sie nun sämtliche Dienste und Bibliotheken, die ERPNext 12 benötigt.</p>\n\n<h3 id=\"einrichten-von-node-js-und-yarn\">Einrichten von Node.js und Yarn</h3>\n\n<p>ERPNext 12 kann mit Version 8 der Node.js-Serverumgebung und höher zusammenarbeiten. Zum Zeitpunkt der Verfassung dieses Dokuments verwendet das offizielle ERPNext <code>easy_install</code>-Skript Node 8. Aus Sicherheitsgründen ist es jedoch ratsam, eine neuere Version zu installieren, da Node 8 2020 sein Lebensende (End of Life, EOL) erreicht hat und somit keine Sicherheitspatches mehr erhalten wird. Für die Zwecke dieses Leitfadens wird Node.js-Version 12 LTS zusammen mit den entsprechenden Paketmanagern <code>npm</code> und <code>yarn</code> installiert. Bitte beachten Sie, dass das Frappe-Framework <code>yarn</code> zum Installieren von Abhängigkeiten verwendet. Wenn Sie sich dazu entscheiden, eine alternative Installationsmethode zu nutzen, stellen Sie sicher, dass am Ende Version 1.12 von <code>yarn</code> oder höher in Ihrem System ausgeführt wird.</p>\n\n<p>Fügen Sie das NodeSource-Repository zu Ihrem System hinzu:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -sL https://deb.nodesource.com/setup_12.x -o nodesource_setup.sh\n</li></ul></code></pre>\n<p>Sie können nun den Inhalt des heruntergeladenen Skripts überprüfen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano nodesurce_setup.sh\n</li></ul></code></pre>\n<p>Sobald Sie zufrieden sind, können Sie das Skript ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bash nodesource_setup.sh\n</li></ul></code></pre>\n<p>Dieses Skript aktualisiert automatisch die Liste <code>apt</code>. Sie können <code>nodejs</code> nun auf Ihrem Server installieren:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install nodejs\n</li></ul></code></pre>\n<p>Installieren Sie als Nächstes <code>yarn</code> global mit dem enthaltenen <code>npm</code>-Paket:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo npm install -g yarn\n</li></ul></code></pre>\n<p>Nachdem Sie Node installiert haben, können Sie nun mit der Konfiguration von <code>wkhtmltopdf</code> für Ihre Plattform fortfahren.</p>\n\n<p>ERPNext verwendet das Open-Source-Tool <code>wkhtmltopdf</code>, um HTML-Inhalte mit der Qt WebKit-Rendering-Engine in PDF zu konvertieren. Diese Funktion dient hauptsächlich zum Drucken von Rechnungen, Angeboten und anderen Berichten. Für ERPNext 12 wird eine spezifische Version von <code>wkhtmltopdf</code> (<code>0.12.5</code>) mit gepatchtem Qt benötigt.</p>\n\n<p>Wechseln Sie zum Installieren von <code>wkhtmltopdf</code> zunächst in ein geeignetes Verzeichnis, in das Sie das Paket herunterladen möchten, in diesem Fall <code>/tmp</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /tmp\n</li></ul></code></pre>\n<p>Laden Sie die entsprechende <code>wkhtmltopdf</code>-Version und das Paket für Ubuntu 18.04 von der Projektseite herunter:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.5/wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Installieren Sie das Paket nun mit dem Tool <code>dpkg</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo dpkg -i wkhtmltox_0.12.5-1.bionic_amd64.deb\n</li></ul></code></pre>\n<p>Kopieren Sie als Nächstes alle relevanten ausführbaren Dateien in Ihr Verzeichnis <code>/usr/bin</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp /usr/local/bin/wkhtmlto* /usr/bin/\n</li></ul></code></pre>\n<p>Ändern Sie anschließend ihre Berechtigungen, um sie ausführbar zu machen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod a+x /usr/bin/wk*\n</li></ul></code></pre>\n<p>Nachdem <code>wkhtmltopdf</code> richtig installiert ist, fügen wir nun Redis unserem Datenbank-Stack hinzu.</p>\n\n<h3 id=\"installieren-von-redis\">Installieren von Redis</h3>\n\n<p>ERPNext 12 verwendet Redis, um die Leistung von MariaDB zu verbessern. Insbesondere <a href=\"https://discuss.erpnext.com/t/why-erpnext-need-redis/6194\">hilft Redis beim Caching</a>.</p>\n\n<p>Installieren Sie zunächst Redis aus dem offiziellen Ubuntu 18.04-Repository:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install redis-server\n</li></ul></code></pre>\n<p>Aktivieren Sie anschließend Redis beim Start:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable redis-server\n</li></ul></code></pre>\n<p>Nachdem Sie Redis Ihrem Stack hinzugefügt haben, können wir uns nun einen Moment Zeit nehmen, um zusammenzufassen, was Sie bisher erreicht haben. Bisher haben Sie alle wichtigen Komponenten installiert, die ERPNext 12 benötigt, darunter folgende Komponenten:</p>\n\n<ul>\n<li>Ein MariaDB-Datenbank-Backend</li>\n<li>Die Node.js-JavaScript-Serverumgebung</li>\n<li>Den Yarn-Paketmanager</li>\n<li>Einen Redis-Datenbankcache</li>\n<li>Den <code>wkhtmltopdf</code>-Generator für PDF-Dokumente</li>\n</ul>\n\n<p>Egal, ob Sie das ERP-System für die Entwicklung oder Produktion installieren, sind Sie nun bereit für den nächsten Schritt, bei dem das Frappe-Full-Stack-Framework und die eigentliche ERPNext-12-Webanwendung installiert werden.</p>\n\n<h2 id=\"schritt-6-mdash-installieren-der-frappe-bench-cli\">Schritt 6 — Installieren der Frappe Bench-CLI</h2>\n\n<p>Nachdem Sie alle Stack-Voraussetzungen für ERPNext installiert haben, können Sie nun die Flexibilität des Befehlzeilentools <code>bench</code> von Frappe nutzen. Die <code>bench</code>-CLI wurde mit dem Ziel entwickelt, Benutzer beim Installieren, Einrichten und Verwalten von Anwendungen wie ERPNext, die auf dem Frappe-Framework basieren, zu unterstützen. In den kommenden Abschnitten installieren Sie die <code>bench</code>-CLI und verwenden diese dann zum Abschließen der Einrichtung von ERPNext 12.</p>\n\n<p>Stellen Sie sicher, dass der Frappe-Benutzer (in diesem Fall <code><span class=\"highlight\">sammy</span></code>) über die richtigen Berechtigungen für das Verzeichnis <code>home</code> verfügt:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chown <span class=\"highlight\">sammy</span> -R /home/<span class=\"highlight\">sammy</span>\n</li></ul></code></pre>\n<p>Klonen Sie nun das <code>frappe/bench</code>-Repository in Ihr Stammverzeichnis. Denken Sie daran, <code><span class=\"highlight\">sammy</span></code> durch Ihren Systembenutzernamen zu ersetzen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone https://github.com/frappe/bench /home/<span class=\"highlight\">sammy</span>/.bench --depth 1 --branch master\n</li></ul></code></pre>\n<p>Installieren Sie die <code>bench</code>-CLI:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo pip3 install -e /home/<span class=\"highlight\">sammy</span>/.bench\n</li></ul></code></pre>\n<p>Dieser Leitfaden geht davon aus, dass Sie ERPNext 12 für Test- bzw. Produktionsszenarien installieren und daher die Verzweigung <code>master</code> verwenden. Wenn Sie jedoch Anwendungen oder benutzerdefinierte ERPNext-Module entwickeln möchten, kann die Verzweigung <code>develop</code> eine bessere Option sein. In jedem Fall sind Sie nun bereit, das Frappe-Framework zu installieren. Dies ist der letzte Schritt vor der Installation von ERPNext selbst.</p>\n\n<h3 id=\"einrichten-der-frappe-framework-umgebung\">Einrichten der Frappe-Framework-Umgebung</h3>\n\n<p>In diesem Abschnitt erstellen Sie eine <a href=\"https://frappe.io/docs/user/en/architecture\">Frappe-Umgebung</a> mithilfe der <code>bench</code>-CLI.</p>\n\n<p>Bei der Installation von Frappe überschreiten Sie ggf. das File-Watch-Limit von Ubuntu, das standardmäßig auf 8192 festgelegt ist. Legen Sie mit dem folgenden Befehl ein höheres Limit fest, um das zu verhindern:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;&amp; sudo sysctl -p\n</li></ul></code></pre>\n<p>Initialisieren Sie als Nächstes Frappe Framework 12. Ersetzen Sie Sammy durch Ihren Systembenutzernamen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench init /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> --frappe-path https://github.com/frappe/frappe --frappe-branch version-12 --python python3\n</li></ul></code></pre>\n<p>Bei der Ausführung werden möglicherweise ein Fehler zu Ihrem Pfad sowie mehrere Warnungen angezeigt. Lassen Sie den Prozess bis zum Ende fortlaufen. Nach seinem Abschluss sehen Sie eine Ausgabe, die der folgenden ähnelt; das bedeutet, dass Ihre Umgebung erfolgreich erstellt wurde:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nDone in 82.23s.\nINFO:bench.utils:setting up backups\nno crontab for <span class=\"highlight\">sammy</span>\nSUCCESS: Bench /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span> initialized\n</code></pre>\n<p><span class='note'><strong>Anmerkung:</strong> Der Prozess <code>bench init</code> kann angehalten werden, wenn ein Fehler vom Typ <code>spawn ENOMEM</code> auftritt. Dieser Fehler wird ausgelöst, wenn Ihr System nicht mehr genügend Arbeitsspeicher hat. Sie müssen das Problem vor dem Fortfahren beheben, entweder durch Installieren von mehr physischem Arbeitsspeicher oder durch Zuweisen eines Auslagerungsbereichs.<br></span></p>\n\n<p>Sehen wir uns den Befehl genauer an, mit dem die Umgebung erstellt wird:</p>\n\n<ul>\n<li><code>/home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span></code> ist der Pfad, in dem das Frappe-Framework, die Websites und zugehörige Anwendungen installiert werden. Es wird ein neues Verzeichnis (in diesem Beispiel namens <code><span class=\"highlight\">frappe-bench</span></code>) erstellt, um alle erforderlichen Dateien zu unterbringen.</li>\n<li><code>--frappe-path</code> verweist auf das Frappe-Repository, das in diesem Fall das offizielle Github-Repository ist.</li>\n<li><code>--frappe-branch</code> ist die zu installierende Frappe-Version. Da Sie ERPNext 12 installieren möchten, ist die gewählte Version Frappe 12.</li>\n<li><code>--python</code> ist die zu verwendende Python-Version. ERPNext 12 erfordert Python 3.6 oder höher. Frühere Versionen nutzen jedoch immer noch Python 2.7.</li>\n</ul>\n\n<p>Weitere Informationen zu <code>bench</code>-CLI-Befehlen finden Sie im <a href=\"https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html\">Spickzettel mit Bench-Befehlen</a>.</p>\n\n<p>Die Flexibilität, die das Frappe-Framework bietet, geht weit über die Verwendung isolierter Umgebungen hinaus. Sie können auch verschiedene Websites erstellen und Anwendungen in ihnen installieren.</p>\n\n<h2 id=\"schritt-7-mdash-installieren-der-erpnext-12-webanwendung\">Schritt 7 — Installieren der ERPNext 12-Webanwendung</h2>\n\n<p>In diesem Abschnitt richten Sie eine auf Frappe basierende Site ein und installieren dann darin die ERPNext 12-Anwendung.</p>\n\n<p>Wechseln Sie zu dem Verzeichnis, in dem Frappe initialisiert wurde.</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Laden Sie nun mit der <code>bench</code>-CLI ERPNext 12 aus dem Repository herunter:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench get-app erpnext https://github.com/frappe/erpnext --branch version-12\n</li></ul></code></pre>\n<p>Erstellen Sie als Nächstes die neue Site und ersetzen Sie <code><span class=\"highlight\">your_domain</span></code> durch die Domäne, die Sie mit der IP-Adresse dieses Servers verknüpft haben:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench new-site <span class=\"highlight\">your_domain</span> --admin-password '<span class=\"highlight\">erpnext_admin_password</span>' --mariadb-root-username <span class=\"highlight\">sammy</span> --mariadb-root-password '<span class=\"highlight\">mariadb_password</span>'\n</li></ul></code></pre>\n<p>Nehmen wir uns einen Moment Zeit, um die im obigen Befehl verwendeten Optionen zu betrachten:</p>\n\n<ul>\n<li><code>bench new-site</code> erstellt eine neue Site basierend auf dem Frappe-Framework.</li>\n<li><code><span class=\"highlight\">your_domain</span></code> ist der Name für die neue Site. Stellen Sie sicher, dass das DNS Ihrer Domäne über einen A-Eintrag verfügt, der auf die IP-Adresse Ihres Servers verweist.</li>\n<li><code><span class=\"highlight\">erpnext_admin_password</span></code> ist das gewünschte Passwort für den ERPNext-Benutzer <strong>Administrator</strong>. Bewahren Sie dieses Passwort an einem sicheren Ort auf; Sie werden es in Kürze benötigen.</li>\n<li><code><span class=\"highlight\">mariadb_password</span></code> ist das Passwort, das Sie am Anfang des Leitfadens für den MariaDB-Benutzer <code><span class=\"highlight\">sammy</span></code> erstellt haben.</li>\n</ul>\n\n<p>Installieren Sie anschließend die ERPNext-Anwendung in der Site:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench --site <span class=\"highlight\">your_domain</span> install-app erpnext\n</li></ul></code></pre>\n<p>Nach Abschluss der Installation verfügen Sie über eine funktionierende ERPNext 12-Anwendung. Testen wir dies nun mit einem <code>bench</code>-Befehl:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">bench start\n</li></ul></code></pre>\n<p>Mit dem oben genannten Schritt wird eine Konsole zur Echtzeitüberwachung gestartet, die Ihnen verschiedene Nachrichten zum Webserver und anderen Diensten anzeigt. Öffnen Sie einen Webbrowser und navigieren Sie zu <code>localhost:8000</code> (bei lokalen Installationen) oder <code><span class=\"highlight\">your_domain</span>:8000</code> (wenn Sie einen Remoteserver verwenden). Sie sehen den ERPNext-Anmeldebildschirm (wir werden in einem späteren Schritt mit der Anmeldung und Einrichtung fortfahren, wenn unsere Site produktionsfertig ist).</p>\n\n<p>Kehren Sie nach dem Besuch Ihrer Testbereitstellung zu Ihrem Terminal zurück und drücken Sie <code>Strg+C</code>. Dadurch wird ERPNext angehalten und die Überwachungskonsole beendet.</p>\n\n<p>Wenn Ihr Hauptziel darin besteht, Module zu erstellen oder ERPNext 12 zu modifizieren, können Sie an diesem Punkt aufhören. Für Entwicklungszwecke sind keine Komponenten mehr erforderlich. Wenn Sie jedoch ein produktionsfähiges System benötigen, das keine manuelle Initialisierung voraussetzt, müssen Sie noch einige zusätzliche Komponenten installieren und konfigurieren. Dies ist Ihr nächster Schritt.</p>\n\n<h2 id=\"schritt-8-mdash-einrichten-von-erpnext-12-für-die-produktion\">Schritt 8 — Einrichten von ERPNext 12 für die Produktion</h2>\n\n<p>Zwar ist die ERPNext 12-Anwendung bereit, doch ist das System insgesamt noch nicht ganz fertig für die Produktion. Um die Zuverlässigkeit und Sicherheit von ERPNext zu gewährleisten, müssen Sie einige zusätzliche Dienste aktivieren:</p>\n\n<ul>\n<li><strong>Fail2ban</strong> bietet eine zusätzliche Schutzschicht vor Brute-Force-Angriffen durch bösartige Benutzer und Bots.</li>\n<li><strong>Nginx</strong> dient hauptsächlich als Webproxy, der den gesamten Datenverkehr von Port <code>8000</code> an Port <code>80</code> (HTTP) oder Port <code>443</code> (HTTPS) weiterleitet.</li>\n<li><strong>Supervisor</strong>: Dieser Dienst sorgt dafür, dass die wichtigsten Prozesse von ERPNext kontinuierlich ausgeführt und bei Bedarf neu gestartet werden.</li>\n</ul>\n\n<p>Bisher haben Sie ERPNext 12 manuell installiert und konfiguriert, sodass Sie den Prozess an einem bestimmten Anwendungsfall anpassen konnten. Für den Rest der Produktionseinrichtung können Sie jedoch aus Gründen der Einfachheit die <code>bench</code>-CLI nutzen und die Installation und Konfiguration der verbleibenden Dienste automatisch erledigen lassen.</p>\n\n<p>Stellen Sie sicher, dass Sie sich im Arbeitsverzeichnis Frappe befinden:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd /home/<span class=\"highlight\">sammy</span>/<span class=\"highlight\">frappe-bench</span>\n</li></ul></code></pre>\n<p>Verwenden Sie nun folgenden Befehl, um die Einrichtung von ERPNext 12 für die Produktion abzuschließen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo bench setup production <span class=\"highlight\">sammy</span> --yes\n</li></ul></code></pre>\n<p>Dadurch werden Nginx, Supervisor und Fail2Ban installiert und konfiguriert und wird <code><span class=\"highlight\">sammy</span></code> als Eigentümer der Produktionsumgebung festgelegt.</p>\n\n<p>Die Konfigurationsdateien, die mit dem Befehl <code>created</code> werden, sind:</p>\n\n<ul>\n<li>Zwei Nginx-Konfigurationsdateien, die sich unter <code>/etc/nginx/nginx.conf</code> und <code>/etc/nginx/conf.d/<span class=\"highlight\">frappe-bench</span>.conf</code> befinden</li>\n<li>Ein Fail2Ban-Proxy-Jail unter <code>/etc/fail2ban/jail.d/nginx-proxy.conf</code> und ein Filter unter <code>/etc/fail2ban/filter.d/nginx-proxy.conf</code></li>\n</ul>\n\n<p>Diese Standardkonfigurationen reichen für dieses Tutorial aus; Sie sollten diese Dateien jedoch erkunden und an Ihre eigenen Anforderungen anpassen. Sie können alle Dienste anhalten, indem Sie Folgendes ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl stop all\n</li></ul></code></pre>\n<p>Und wenn Sie bereit dazu sind, können Sie Ihre Dienste neu starten:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo supervisorctl start all\n</li></ul></code></pre>\n<p>Sie sind nun in der Lage, Ihre Installation zu testen.</p>\n\n<h3 id=\"testen-ihrer-erpnext-12-installation\">Testen Ihrer ERPNext 12-Installation</h3>\n\n<p>Überprüfen Sie zunächst mit dem folgenden Befehl <code>systemctl</code>, ob die wichtigsten Produktionsdienste ausgeführt werden, und leiten Sie dann an <code>grep</code> weiter:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">systemctl list-unit-files | grep 'fail2ban\\|nginx\\|supervisor'\n</li></ul></code></pre>\n<p>Sie werden eine Ausgabe wie diese sehen:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>fail2ban.service                       enabled\nnginx.service                          enabled\nsupervisor.service                     enabled\n</code></pre>\n<p>Nachdem Sie sich vergewissert haben, dass alles wie erwartet funktioniert, können Sie ERPNext 12 auf Ihrem Server live testen. Öffnen Sie Ihren bevorzugten Browser und navigieren Sie zu der Domäne, wo Sie Ihre ERPNext 12-Anwendung hosten.</p>\n\n<p>Nach wenigen Sekunden sollten Sie den Anmeldebildschirm von ERPNext 12 sehen. Verwenden Sie <strong>Administrator</strong> als Benutzernamen und das zuvor für das Passwort erstellte <code><span class=\"highlight\">erpnext_admin_password</span></code>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_1.png\" alt=\"Anmeldefenster von ERPNext\"></p>\n\n<p>Im nächsten Bildschirm sehen Sie ein Dropdownmenü, in dem Sie die Sprache der Benutzeroberfläche für die Anwendung auswählen können:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_2.png\" alt=\"Sprachauswahl\"></p>\n\n<p>Nach der Sprachauswahl wird Sie ERPNext zur Eingabe Ihres Lands, Ihrer Zeitzone und der Währung auffordern:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_3.png\" alt=\"Wählen Sie Ihre Region aus\"></p>\n\n<p>Nachdem Sie die Regionsinformationen festgelegt haben, können Sie den ersten ERPNext-Benutzer erstellen. Die von Ihnen angegebenen Informationen werden als Anmeldedaten des Benutzers verwendet.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_4.png\" alt=\"Erster ERPNext-Benutzer\"></p>\n\n<p>Im nächsten Bildschirm werden Sie nach etwas gefragt, das ERPNext <strong>Domänen</strong> nennt. Wenn Sie sich nicht sicher sind, wie Ihre Domäne lautet, wählen Sie als Nächstes  <strong>Distribution</strong> und klicken Sie auf die Schaltfläche <strong>Weiter</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_5.png\" alt=\"Wählen Sie Ihre Domänen aus\"></p>\n\n<p>Als Nächstes müssen Sie einen Firmennamen und eine Abkürzung angeben.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_6.png\" alt=\"Firmenname\"></p>\n\n<p>Im letzten Bildschirm fragt Sie ERPNext nach dem, was Ihre Firma tut, nach dem Namen ihrer Bank, nach der Art der Kontenpläne und nach der Geschäftsjahresperiode. Sie können später weitere Banken eingeben. Füllen Sie vorerst alle Felder wie gewünscht aus und klicken Sie dann auf die Schaltfläche <strong>Complete Setup</strong> (Einrichtung abschließen).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_7.png\" alt=\"Finanzdaten\"></p>\n\n<p>Als Nächstes sehen Sie eine Fortschrittsleiste.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_8.png\" alt=\"Einrichten von ERPNext\"></p>\n\n<p>Nach Abschluss der Einrichtung wird das Haupt-Dashboard von ERPNext 12 angezeigt.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_9.png\" alt=\"ERPNext 12-Dashboard\"></p>\n\n<p>Sie haben nun eine ERPNext 12-Anwendung vollständig installiert und konfiguriert.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>Nachdem Sie Ihre ERPNext 12-Anwendung richtig installiert haben, können Sie nun mit der Anpassung des Systems an Ihre geschäftlichen Bedürfnisse beginnen. Ein guter Ausgangspunkt ist ein Klick auf die Schaltfläche <strong>Getting Started</strong> (Erste Schritte) im ERPNext-Dashboard. ERPNext hilft Ihnen dann bei der Konfiguration der Plattform für alle Ihre geschäftlichen und E-Commerce-Anforderungen.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/67031/erpnext_10.png\" alt=\"Erste Schritte\"></p>\n\n<p>Vielleicht möchten Sie auch die Geschwindigkeit von ERPNext erhöhen. In diesem Fall können Sie <a href=\"https://github.com/frappe/erpnext/wiki/ERPNext-Performance-Tuning\">Leistungsoptimierung bei ERPNext</a> lesen; hier erhalten Sie Informationen über bewährte Praktiken und die Behebung von Leistungsproblemen.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:18 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/67031/erpnext_0.png","linkMd5":"03d293a1903a5035b8dba89d5b4d0422","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","destWidth":3584,"destHeight":2022,"sourceBytes":966173,"destBytes":375664,"author":"Damaso Sanoja","articleImgCdnMap":{"https://assets.digitalocean.com/articles/67031/erpnext_0.png":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","https://assets.digitalocean.com/articles/67031/erpnext_1.png":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_3/2020/08/31/07-48-32-714_e6b982f1d7fe90cd.webp","https://assets.digitalocean.com/articles/67031/erpnext_2.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn94@2020_6/2020/08/31/07-48-32-235_5dfe5b1d282ec7f1.webp","https://assets.digitalocean.com/articles/67031/erpnext_3.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_3/2020/08/31/07-48-31-862_07721efc54737d85.webp","https://assets.digitalocean.com/articles/67031/erpnext_4.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn45@2020_1/2020/08/31/07-48-32-664_c2f620996c337847.webp","https://assets.digitalocean.com/articles/67031/erpnext_5.png":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn13@2020_2/2020/08/31/07-48-33-137_5b1867188f4eb783.webp","https://assets.digitalocean.com/articles/67031/erpnext_6.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn25@2020_3/2020/08/31/07-48-31-288_1f4bd367e3868d6d.webp","https://assets.digitalocean.com/articles/67031/erpnext_7.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn14@2020_2/2020/08/31/07-48-31-596_2e4f2cf158e027fc.webp","https://assets.digitalocean.com/articles/67031/erpnext_8.png":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn65@2020_2/2020/08/31/07-48-31-323_2f22aaf79a58e762.webp","https://assets.digitalocean.com/articles/67031/erpnext_9.png":null,"https://assets.digitalocean.com/articles/67031/erpnext_10.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn97@2020_3/2020/08/31/07-48-32-254_dccc24f52c8f5d64.webp"},"publishedOrCreatedDate":1598860106982},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Como instalar o TensorFlow no Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-tensorflow-on-ubuntu-20-04-pt","description":"<h3 id=\"introdução\">Introdução</h3>\n\n<p>O <a href=\"https://www.tensorflow.org/\">TensorFlow</a> é uma biblioteca de software de machine learning de código aberto que é usado para treinar redes neurais. Expresso na forma de <a href=\"https://www.tensorflow.org/programmers_guide/graphs\">gráficos de fluxo de dados com estado</a>, cada nó no gráfico representa as operações realizadas por redes neurais em arrays multidimensionais. Esses arrays multidimensionais são comumente conhecidos como “tensores”, daí o nome TensorFlow.</p>\n\n<p>Neste tutorial, você irá instalar o TensorFlow em um ambiente virtual Python com o <code>virtualenv</code>. Essa abordagem isola a instalação do TensorFlow e coloca tudo em funcionamento rapidamente. Depois de completar a instalação, você irá validá-la importando o Tensorflow para garantir que você não tenha erros.</p>\n\n<h2 id=\"pré-requisitos\">Pré-requisitos</h2>\n\n<p>Antes de iniciar este tutorial, você vai precisar do seguinte:</p>\n\n<ul>\n<li><p>Um servidor Ubuntu 20.04 com pelo menos <strong>4 GB de RAM</strong> configurado seguindo o guia de <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">configuração inicial do servidor Ubuntu 20.04</a>, incluindo um usuário sudo não root e um firewall.</p></li>\n<li><p>Python 3.8 ou superior e <code>virtualenv</code> instalado. Siga o tutorial <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-programming-environment-on-an-ubuntu-20-04-server\">How To Install Python 3 on Ubuntu 20.04</a> para configurar o Python e o <code>virtualenv</code>.</p></li>\n</ul>\n\n<h2 id=\"passo-1-—-criando-um-ambiente-de-programação\">Passo 1 — Criando um ambiente de programação</h2>\n\n<p>Neste passo, vamos criar um ambiente virtual para instalar o TensorFlow nele sem comprometer nossos outros projetos de programação. Se você já tiver um ambiente de programação limpo configurado, sinta-se livre para ignorar este passo.</p>\n\n<p>Primeiro, crie um diretório de projeto. Vamos chamá-lo de <code>tf-demo</code> para fins de demonstração, mas escolha um nome de diretório que seja significativo para você:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Navegue até seu diretório <code>tf-demo</code> recém-criado:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Em seguida, crie um novo ambiente virtual chamado <code>tensorflow-dev</code>, por exemplo. Execute o comando a seguir para criar o ambiente:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python3 -m venv <span class=\"highlight\">tensorflow-dev</span>\n</li></ul></code></pre>\n<p>Isso cria um novo diretório <code>tensorflow-dev</code> que conterá todos os pacotes que você instalar enquanto este ambiente estiver ativado. Ele também inclui o <code>pip</code> e uma versão standalone do Python.</p>\n\n<p>Agora, ative seu ambiente virtual:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">source <span class=\"highlight\">tensorflow-dev</span>/bin/activate\n</li></ul></code></pre>\n<p>Uma vez ativado, o prompt do terminal refletirá que você está no ambiente virtual:</p>\n<pre class=\"code-pre \"><code>(<span class=\"highlight\">tensorflow-dev</span>)username@hostname:~/tf-demo $\n</code></pre>\n<p>Neste ponto, você pode instalar o TensorFlow em seu ambiente virtual.</p>\n\n<h2 id=\"passo-2-—-como-instalar-o-tensorflow\">Passo 2 — Como instalar o TensorFlow</h2>\n\n<p>Ao instalar o TensorFlow, queremos garantir que estamos instalando e atualizando para a versão mais recente disponível em <a href=\"https://pypi.python.org/pypi\">PyPi</a>.</p>\n\n<p>Portanto, usaremos a seguinte sintaxe de comando com o pip:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">pip install --upgrade tensorflow\n</li></ul></code></pre>\n<p>Depois de pressionar <code>ENTER</code>, o TensorFlow será instalado, e você receberá um resultado que indica que a instalação, juntamente com qualquer pacote de dependência, foi bem sucedida.</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nSuccessfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 numpy-1.16.2 pbr-5.1.3 protobuf-3.7.0 setuptools-40.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.0 wheel-0.33.1\n...\n\nSuccessfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 markdown-2.6.9 numpy-1.13.3 protobuf-3.5.0.post1 setuptools-38.2.3 six-1.11.0 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0rc3 werkzeug-0.12.2 wheel-0.30.0\n</code></pre>\n<span class='note'><p>\nVocê pode desativar seu ambiente virtual a qualquer momento usando o seguinte comando:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">deactivate\n</li></ul></code></pre>\n<p>Para reativar o ambiente mais tarde, navegue até seu diretório de projeto e execute <code>source <span class=\"highlight\">tensorflow-dev</span>/bin/activate</code>.<br></p></span>\n\n<p>Agora que você instalou o TensorFlow, vamos garantir que a instalação do TensorFlow funcione.</p>\n\n<h2 id=\"passo-3-—-validando-a-instalação\">Passo 3 — Validando a instalação</h2>\n\n<p>Para validar a instalação do TensorFlow, vamos garantir que possamos importar o pacote TensorFlow.</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">python\n</li></ul></code></pre>\n<p>O prompt a seguir irá aparecer em seu terminal:</p>\n<pre class=\"code-pre \"><code>&gt;&gt;&gt;\n</code></pre>\n<p>Esse é o prompt para o interpretador do Python, e ele indica que ele está pronto para você começar a inserir algumas declarações do Python.</p>\n\n<p>Primeiro, digite esta linha para importar o pacote TensorFlow e torná-lo disponível como variável local <code>tf</code>. Pressione <code>ENTER</code> depois de digitar a linha de código:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;&gt;&gt;\">import tensorflow as tf\n</li></ul></code></pre>\n<p>Contanto que não tenha recebido erros, você instalou o TensorFlow com sucesso. Se você tiver recebido um erro, você deve garantir que seu servidor seja poderoso o suficiente para lidar com o TensorFlow. Você pode precisar redimensionar seu servidor, certificando-se de que ele tenha pelo menos 4GB de memória.</p>\n\n<h2 id=\"conclusão\">Conclusão</h2>\n\n<p>Neste tutorial, você instalou o TensorFlow em um ambiente virtual Python e validou que o TensorFlow funciona ao importá-lo.</p>\n\n<p>O <a href=\"https://www.tensorflow.org/programmers_guide/\">guia do programador</a> do TensorFlow, fornece um recurso e uma referência úteis para o desenvolvimento com o TensorFlow. Você também pode explorar o <a href=\"https://www.kaggle.com/\">Kaggle</a>, um ambiente competitivo para aplicação prática de conceitos de machine learning que o colocam para competir contra outros entusiastas de machine learning, ciência de dados e estatística.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:25 +0000","feedId":8037,"bgimg":"","linkMd5":"12b486fbd164741523794a896de2be1a","bgimgJsdelivr":"","metaImg":"","author":"Lisa Tagliaferri","publishedOrCreatedDate":1598860106974},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comprendre les bases de données relationnelles","link":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-fr","description":"<h3 id=\"introduction\">Introduction</h3>\n\n<p><em>Les systèmes de gestion des bases de données</em> (SGDB ou DBMS en anglais) sont des programmes informatiques qui permettent aux utilisateurs d'interagir avec une base de données. Un SGDB permet aux utilisateurs de contrôler l'accès à une base de données, d'écrire des données, d'exécuter des requêtes et d'effectuer toute autre tâche liée à la gestion de base de données.</p>\n\n<p>Pour effectuer l'une de ces tâches, cependant, le SGDB doit avoir une sorte de modèle sous-jacent qui définit la manière dont les données sont organisées. Le <em>modèle relationnel</em> est une approche d'organisation des données qui ont trouvé un large usage dans le logiciel de base de données depuis sa conception initiale à la fin des années 1960, à tel point que, à partir de ce texte, <a href=\"https://db-engines.com/en/ranking\">quatre des cinq SGDB les plus populaires</a> sont relationnels.</p>\n\n<p>Cet article conceptuel décrit l'historique du modèle relationnel, la manière dont les bases de données relationnelles organisent les données, et leur utilisation aujourd'hui.</p>\n\n<h2 id=\"histoire-du-modèle-relationnel\">Histoire du modèle relationnel</h2>\n\n<p>Les <em>bases</em> de données sont des groupes d'informations ou de données modélisés de manière logique**. Toute collecte de données est une base de données, quel que soit la manière dont elle est stockée ou l'endroit où elle est stockée. Même un classeur de fichiers contenant des informations sur les salaires est une base de données, tout comme une pile de formulaires de patients d'un hôpital ou la collecte d'informations sur les clients d'une entreprise répartis dans plusieurs endroits. Avant que le stockage et la gestion des données à l'aide d'ordinateurs ne soit une pratique courante, les bases de données physiques comme celles-ci étaient les seules dont disposaient les organisations gouvernementales et commerciales qui avaient besoin de stocker des informations.</p>\n\n<p>Vers le milieu du XXe siècle, les développements en informatique ont conduit à la mise au point de machines plus puissantes, ainsi qu'à une plus grande capacité de stockage local et externe. Ces progrès ont conduit les informaticiens à commencer à reconnaître le potentiel de ces machines pour stocker et gérer des quantités de données toujours plus importantes.</p>\n\n<p>Cependant, il n'existait pas de théories sur la manière dont les ordinateurs pouvaient organiser les données de manière logique et significative. C'est une chose de stocker des données non triées sur une machine, mais il est beaucoup plus compliqué de concevoir des systèmes qui vous permettent d'ajouter, récupérer, trier et gérer ces données d'une manière cohérente et pratique. La nécessité d'un cadre logique pour stocker et organiser les données a conduit à un certain nombre de propositions d'utilisation des ordinateurs pour la gestion des données.</p>\n\n<p>L'un des premiers modèles de base de données était le <a href=\"https://en.wikipedia.org/wiki/Hierarchical_database_model\"><em>modèle hiérarchique</em></a>, dans lequel les données sont organisées dans une structure arborescente ressemblant semblables aux systèmes de fichiers modernes. L'exemple suivant montre à quoi pourrait ressembler la disposition d'une partie d'une base de données hiérarchique utilisée pour classer les animaux : :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png\" alt=\"Exemple Base de données hiérarchiques : catégorisation des animaux\"></p>\n\n<p>Le modèle hiérarchique a été largement appliqué dans les systèmes de gestion de base de données, mais il s'est également avéré peu flexible. Dans ce modèle, même si les enregistrements individuels peuvent avoir plusieurs enregistrements &ldquo;enfant&rdquo;, chaque enregistrement ne peut avoir qu'un seul &ldquo;parent&rdquo; dans la hiérarchie. Pour cette raison, ces bases de données hiérarchiques antérieures se limitaient à représenter uniquement des relations &ldquo;&quot;un à un&rdquo; et &ldquo;un à plusieurs&rdquo; Cette absence de relations &ldquo;de plusieurs à plusieurs&quot;  pourrait entraîner des problèmes lorsque vous travaillez avec des points de données que vous souhaitez associer à plus d'un parent.</p>\n\n<p>À la fin des années 1960, Edgar F. Codd, un informaticien chez IBM, a mis au point le modèle relationnel de gestion de base de données. Le modèle relationnel de Codd a permis à des enregistrements individuels d'être associés à plus d'une table, permettant ainsi des relations &quot;de plusieurs à plusieurs&rdquo; entre les points de données en plus des relations &ldquo;d'un à plusieurs&rdquo;.  Cela a permis une plus grande flexibilité que d'autres modèles existants en ce qui concerne la conception des structures de base de données, ce qui signifie que les systèmes de gestion de bases de données relationnelles (SGBDR) pouvaient répondre à un éventail beaucoup plus large de besoins commerciaux.</p>\n\n<p>Codd a proposé un langage pour gérer les données relationnelles, connu sous le nom d&rsquo;<a href=\"https://dl.acm.org/doi/pdf/10.1145/1734714.1734718\">Alpha</a>, qui a influencé le développement de langages de base de données ultérieurs. Deux des collègues de Codd chez IBM, Donald Chamberlin et Raymond Boyce, ont créé un tel langage inspirée d'Alpha. Ils ont appelé leur langue <em>SEQUEL</em>, anagramme de   <strong>S</strong> tructured  <strong>E</strong> nglish  <strong>Que</strong> ry  <strong>L</strong> anguage, mais en raison d'une marque existante ils ont raccourci le nom de leur langage à <em>SQL</em> (appelé de manière plus formelle <em>Structured Query Language</em>).</p>\n\n<p>En raison de contraintes matérielles, les premières bases de données relationnelles étaient excessivement lentes, et il a fallu un certain temps avant que la technologie ne se généralise. Mais au milieu des années 1980, le modèle relationnel de Codd a été mis en œuvre dans un certain nombre de produits de gestion de base de données commerciales d'IBM et de ses concurrents. Ces entreprises ont également suivi l'initiative d'IBM en développant et en mettant en œuvre leurs propres dialectes de SQL. En 1987, l'American National Standards Institute et l'International Organization for Standardization avaient tous deux ratifié et publié des normes pour SQL, consolidant ainsi son statut de langage accepté pour la gestion des SGBDR.</p>\n\n<p>L'utilisation du modèle relationnel dans plusieurs industries a conduit à sa reconnaissance en tant que modèle standard de gestion des données. Même avec l'essor de différentes <a href=\"https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models\">bases de données NoSQL</a> ces dernières années, les bases de données relationnelles restent les outils dominants pour le stockage et l'organisation des données.</p>\n\n<h2 id=\"comment-les-bases-de-données-relationnelles-organisent-les-données\">Comment les bases de données relationnelles organisent les données</h2>\n\n<p>Maintenant que vous avez une compréhension générale de l'histoire du modèle relationnel, examinons de plus près la manière dont le modèle organise les données.</p>\n\n<p>Les éléments les plus fondamentaux du modèle relationnel sont les <em>relations</em> que les utilisateurs et les SGBDR modernes reconnaissent comme <em>tableaux</em>. Une relation est un ensemble de <em>tuples</em>, ou de lignes dans une table, avec chaque tuple partageant un ensemble d&rsquo;<em>attributs</em>, ou colonnes :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png\" alt=\"Exemple de diagramme indiquant comment les relations, les tuples et les attributs sont liés les uns aux autres\"></p>\n\n<p>Une colonne est la plus petite structure organisationnelle d'une base de données relationnelle, et représente les différentes facettes qui définissent les enregistrements de la table. D'où leur nom plus formel, les attributs. Vous pouvez penser à chaque tuple comme une instance unique de n'importe quel type de personnes, objets, événements ou associations que la table contient. Ces instances peuvent être des éléments comme les employés d'une entreprise, les ventes d'une entreprise en ligne ou les résultats de test en laboratoire. Par exemple, dans une table contenant les enregistrements des enseignants d'une école, les tuples peuvent avoir des attributs comme <code>name</code>, <code>subjects</code>, <code>start_date</code>, etc.</p>\n\n<p>Lorsque vous créez des colonnes, vous spécifiez un <em>type de données</em> qui dicte le type d'entrées autorisées dans cette colonne. Les SGBDR mettent souvent en œuvre leurs propres types de données uniques, qui peuvent ne pas être directement interchangeables avec des types de données similaires dans d'autres systèmes. Les types de données les plus courants comprennent les dates, les chaînes de caractères, les entiers et les Booléens.</p>\n\n<p>Dans le modèle relationnel, chaque table contient au moins une colonne qui peut être utilisée pour identifier de manière unique chaque ligne, appelée <em>clé primaire</em>. C'est important, car cela signifie que les utilisateurs n'ont pas à savoir où leurs données sont physiquement stockées sur une machine, au lieu de cela, leur SGBD peut suivre chaque enregistrement et les renvoyer sur une base ad hoc. Cela signifie que les enregistrements n'ont pas d'ordre logique défini, et que les utilisateurs ont la possibilité de renvoyer leurs données dans n'importe quel ordre ou par les filtres qu'ils souhaitent.</p>\n\n<p>Si vous souhaitez associer deux tables l'une à l'autre, vous pouvez le faire avec une <em>clé étrangère</em>. Une clé étrangère est essentiellement une copie de la clé primaire d'une table (la table &ldquo;parent&rdquo;) insérée dans une colonne d'une autre table (l&rsquo;&ldquo;enfant&rdquo;). L'exemple suivant met en évidence la relation entre deux tableaux, l'un utilisé pour enregistrer les informations relatives aux employés d'une entreprise et l'autre utilisée pour suivre les ventes de l'entreprise. Dans cet exemple, la clé principale du tableau <code>EMPLOYEES</code> est utilisée comme clé étrangère du tableau <code>SALES</code> :</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png\" alt=\"Diagramme illustrant comment la clé principale du tableau de EMPLOYEE agit en tant que clé étrangère du tableau SALES\"></p>\n\n<p>Si vous essayez d'ajouter un enregistrement au tableau enfant et que la valeur saisie dans la colonne de clé étrangère n'existe pas dans la clé primaire du tableau parent, l'instruction d'insertion sera invalide. Cela aide à maintenir l'intégrité au niveau des relations, car les lignes des deux tableaux seront toujours correctement reliées.</p>\n\n<p>Les éléments structurels du modèle relationnel aident à conserver les données stockées de manière organisée, mais la conservation des données n'est utile que si vous pouvez les récupérer. Pour récupérer des informations d'un SGBDR, vous pouvez émettre une <em>query</em> ou une requête structurée d'un ensemble d'informations. Comme mentionné précédemment, la plupart des bases de données relationnelles utilisent SQL pour gérer et interroger les données. SQL vous permet de filtrer et de manipuler les résultats de requête avec une variété de clauses, de prédicats et d'expressions, vous donnant un contrôle précis sur les données qui apparaîtront dans l'ensemble de résultats.</p>\n\n<h2 id=\"avantages-et-limitations-des-bases-de-données-relationnelles\">Avantages et limitations des bases de données relationnelles</h2>\n\n<p>En tenant compte de la structure organisationnelle sous-jacente des bases de données relationnelles, examinons quelques-uns de leurs avantages et de leurs inconvénients.</p>\n\n<p>Aujourd'hui, tant SQL que les bases de données qui l'implémentent s'écartent du modèle relationnel de Codd de plusieurs façons. Par exemple, le modèle de Codd dicte que chaque ligne d'une table doit être unique tandis que, pour des raisons pratiques, la plupart des bases de données relationnelles modernes permettent de dupliquer les lignes. Certaines personnes ne considèrent pas les bases de données SQL comme de véritables bases de données relationnelles si elles ne respectent pas chacune des spécifications du modèle relationnel de Codd. En termes pratiques, cependant, tout SGBD qui utilise SQL et qui adhère au moins en partie au modèle relationnel est susceptible d'être appelé un système de gestion de base de données relationnelles.</p>\n\n<p>Bien que les bases de données relationnelles aient rapidement gagné en popularité, certaines des lacunes du modèle relationnel ont commencé à apparaître lorsque les données prenaient de la valeur et que les entreprises ont commencé à en stocker davantage. <em>La scalabilité horizontale</em>, ou <em>scaling out</em>, est la pratique qui consiste à ajouter plus de machines à une pile existante afin de répartir la charge et de permettre un traffic plus important et un traitement plus rapide. Cette opération est souvent opposée à la mise à la <em>scalabilité verticale</em> qui implique la mise à niveau du matériel d'un serveur existant, généralement en ajoutant plus de RAM ou de CPU.</p>\n\n<p>La raison pour laquelle il est difficile de faire évoluer une base de données relationnelle horizontalement est liée au fait que le modèle relationnel est conçu pour assurer la <em>cohérence</em>, ce qui signifie que les clients qui interrogent la même base de données récupèrent toujours les mêmes données. Si vous devez faire évoluer une base de données relationnelle horizontalement sur plusieurs machines, il devient difficile d'en garantir la cohérence car les clients peuvent parfois écrire des données sur un nœud, sans le faire sur les autres. Il y aurait probablement un délai entre l'écriture initiale et le moment où les autres nœuds sont mis à jour pour refléter les changements, ce qui entraînerait des incohérences entre eux.</p>\n\n<p>Une autre limitation présentée par les SGDBR est que le modèle relationnel a été conçu pour gérer <em>des données structurées</em>, ou des données qui s'alignent avec un type de données prédéfini ou qui sont au moins organisées d'une manière prédéterminée, ce qui les rend facilement triables et consultables. Toutefois, avec le développement de l'informatique personnelle et l'essor d'Internet au début des années 1990, <em>les données non structurées</em> — telles que les messages électroniques, les photos, les vidéos, etc. — sont devenues plus fréquentes.</p>\n\n<p>Rien de cela ne veut dire que les bases de données relationnelles ne sont pas utiles. Au contraire, le modèle relationnel est toujours le cadre dominant de la gestion des données après plus de 40 ans. Leur prévalence et leur longévité signifient que les bases de données relationnelles sont une technologie mature, qui est en soi l'un de leurs avantages majeurs. Il existe de nombreuses applications conçues pour fonctionner avec le modèle relationnel, ainsi que de nombreux administrateurs de base de données de carrière qui sont des experts en matière de bases de données relationnelles. Il existe également un large éventail de ressources disponibles sur papier et en ligne pour ceux qui souhaitent se lancer dans les bases de données relationnelles.</p>\n\n<p>Un autre avantage des bases de données relationnelles est que presque tous les SGBDR prennent en charge les <em>transactions</em>. Une transaction consiste en une ou plusieurs des instructions SQL individuelles exécutées en séquence comme une seule unité de travail. Les transactions présentent une approche de type tout-ou rien, ce qui signifie que chaque instruction SQL de la transaction doit être valide ; sinon, la transaction entière échouera. Ceci est très utile pour garantir l'intégrité des données lors de modifications de plusieurs lignes ou tableaux.</p>\n\n<p>Enfin, les bases de données relationnelles sont extrêmement flexibles. Elles ont été utilisées pour construire une grande variété d'applications différentes, et continuent de fonctionner efficacement même avec de très grandes quantités de données. SQL est également extrêmement puissant, vous permettant d'ajouter et de modifier des données au vol, ainsi que de modifier la structure des schémas et des tableaux de base de données sans incidence sur les données existantes.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Grâce à leur flexibilité et à leur conception pour l'intégrité des données, les bases de données relationnelles sont toujours le principal moyen de gérer et de stocker les données plus de cinquante ans après leur conception. Même avec l'essor de diverses bases de données NoSQL ces dernières années, la compréhension du modèle relationnel et de la manière de travailler avec les SGBDR sont la clé pour tous ceux qui veulent construire des applications qui exploitent la puissance des données.</p>\n\n<p>Pour en savoir plus sur quelques SGBDR open source populaires, nous vous encourageons à consulter <a href=\"https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems\">notre comparaison de différentes bases de données SQL relationnelles open-source</a>. Si vous souhaitez en savoir plus sur les bases de données en général, nous vous encourageons à consulter <a href=\"https://www.digitalocean.com/community/tags/databases\">notre bibliothèque complète de contenus liés aux bases de données</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:47:08 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png","linkMd5":"a7be8f228fc23dda64da52edfaba0470","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","destWidth":1440,"destHeight":820,"sourceBytes":26442,"destBytes":57080,"author":"Mark Drake","articleImgCdnMap":{"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn42@2020_2/2020/08/31/07-48-32-526_c309571f1ca0d468.webp","https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png":null},"publishedOrCreatedDate":1598860106961},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Installieren von TensorFlow unter Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-install-tensorflow-on-ubuntu-20-04-de","description":"<h3 id=\"einführung\">Einführung</h3>\n\n<p><a href=\"https://www.tensorflow.org/\">TensorFlow</a> ist eine Open-Source-Softwarebibliothek für maschinelles Lernen, die dem Trainieren neuronaler Netze dient. Jeder Knoten im Graph (ausgedrückt in Form von <a href=\"https://www.tensorflow.org/programmers_guide/graphs\">stateful dataflow graphs</a>) stellt die Operationen dar, die von neuronalen Netzen in multidimensionalen Arrays ausgeführt werden. Diese multidimensionalen Arrays werden im Allgemeinen als „Tensoren“ bezeichnet (daher der Name TensorFlow).</p>\n\n<p>In diesem Tutorial installieren Sie TensorFlow mit <code>virtualenv</code> in einer virtuellen Python-Umgebung. Dieser Ansatz sorgt für eine Isolierung der TensorFlow-Installation und schnelle Inbetriebnahme. Nachdem Sie die Installation abgeschlossen haben, werden Sie sie durch Importieren von Tensorflow validieren, um sicherzustellen, dass keine Fehler vorliegen.</p>\n\n<h2 id=\"voraussetzungen\">Voraussetzungen</h2>\n\n<p>Bevor Sie mit diesem Tutorial beginnen, benötigen Sie Folgendes:</p>\n\n<ul>\n<li><p>Einen Ubuntu 20.04-Server mit mindestens <strong>4 GB RAM</strong>, der anhand des Leitfadens zur <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Ersteinrichtung des Servers für Ubuntu 20.04</a> eingerichtet wurde, einschließlich eines non-root user mit sudo-Berechtigungen und einer Firewall.</p></li>\n<li><p>Installiertes Python 3.8 oder höher und <code>virtualenv</code>. Folgen Sie <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-programming-environment-on-an-ubuntu-20-04-server\">Installieren von Python 3 unter Ubuntu 20.04</a>, um Python und <code>virtualenv</code> zu konfigurieren.</p></li>\n</ul>\n\n<h2 id=\"schritt-1-—-einrichten-einer-programmierumgebung\">Schritt 1 — Einrichten einer Programmierumgebung</h2>\n\n<p>In diesem Schritt richten wir eine virtuelle Umgebung ein, um TensorFlow darin zu installieren, ohne unsere anderen Programmierprojekte zu beeinträchtigen. Wenn Sie bereits über eine saubere Programmierumgebung verfügen, können Sie diesen Schritt überspringen.</p>\n\n<p>Erstellen Sie zunächst ein Projektverzeichnis. Wir werden es für Demonstrationszwecke <code>tf-demo</code> nennen; Sie können jedoch einen anderen Verzeichnisnamen wählen, der sinnvoll für Sie ist:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Navigieren Sie zu Ihrem neu erstellten Verzeichnis namens <code>tf-demo</code>:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd ~/<span class=\"highlight\">tf-demo</span>\n</li></ul></code></pre>\n<p>Erstellen Sie dann beispielsweise eine neue virtuelle Umgebung namens <code>tensorflow-dev</code>. Führen Sie den folgenden Befehl aus, um Ihre Umgebung zu erstellen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">python3 -m venv <span class=\"highlight\">tensorflow-dev</span>\n</li></ul></code></pre>\n<p>Dadurch wird ein neues Verzeichnis namens <code>tensorflow-dev</code> erstellt, das alle von Ihnen installierten Pakete enthalten wird, während diese Umgebung aktiviert wird. Dazu gehören auch <code>pip</code> und eine eigenständige Version von Python.</p>\n\n<p>Aktivieren Sie nun Ihre virtuelle Umgebung:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">source <span class=\"highlight\">tensorflow-dev</span>/bin/activate\n</li></ul></code></pre>\n<p>Nach der Aktivierung wird Ihre Terminal-Eingabeaufforderung widerspiegeln, dass Sie sich in der virtuellen Umgebung befinden:</p>\n<pre class=\"code-pre \"><code>(<span class=\"highlight\">tensorflow-dev</span>)username@hostname:~/tf-demo $\n</code></pre>\n<p>Nun können Sie TensorFlow in Ihrer virtuellen Umgebung installieren.</p>\n\n<h2 id=\"schritt-2-—-installieren-von-tensorflow\">Schritt 2 — Installieren von TensorFlow</h2>\n\n<p>Bei der Installation von TensorFlow wollen wir sicherstellen, dass wir die neueste in <a href=\"https://pypi.python.org/pypi\">PyPi</a> verfügbare Version installieren.</p>\n\n<p>Daher verwenden wir die folgende Befehlssyntax mit pip:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">pip install --upgrade tensorflow\n</li></ul></code></pre>\n<p>Sobald Sie die <code>Eingabetaste</code> drücken, wird TensorFlow installiert; Sie sollten eine Ausgabe erhalten, die meldet, dass die Installation zusammen mit allen abhängigen Paketen erfolgreich war.</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>...\nSuccessfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 numpy-1.16.2 pbr-5.1.3 protobuf-3.7.0 setuptools-40.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.0 wheel-0.33.1\n...\n\nSuccessfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 markdown-2.6.9 numpy-1.13.3 protobuf-3.5.0.post1 setuptools-38.2.3 six-1.11.0 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0rc3 werkzeug-0.12.2 wheel-0.30.0\n</code></pre>\n<span class='note'><p>\nAnmerkung: Sie können Ihre virtuelle Umgebung jederzeit deaktivieren, indem Sie folgenden Befehl ausführen:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">deactivate\n</li></ul></code></pre>\n<p>Um die Umgebung später zu reaktivieren, navigieren Sie zu Ihrem Projektverzeichnis und führen Sie <code>source <span class=\"highlight\">tensorflow-dev</span>/bin/activate</code> aus.<br></p></span>\n\n<p>Nachdem Sie TensorFlow installiert haben, vergewissern wir uns nun, dass die TensorFlow-Installation funktioniert.</p>\n\n<h2 id=\"schritt-3-—-validieren-der-installation\">Schritt 3 — Validieren der Installation</h2>\n\n<p>Um die Installation von TensorFlow zu validieren, stellen wir sicher, dass wir das TensorFlow-Paket importieren können.</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"(tensorflow-dev) $\">python\n</li></ul></code></pre>\n<p>In Ihrem Terminal wird die folgende Eingabeaufforderung angezeigt:</p>\n<pre class=\"code-pre \"><code>&gt;&gt;&gt;\n</code></pre>\n<p>Dies ist die Eingabeaufforderung des Python-Interpreters; sie gibt an, dass Sie mit der Eingabe von Python-Befehlen beginnen können.</p>\n\n<p>Geben Sie zunächst diese Zeile ein, um das TensorFlow-Paket zu importieren und als lokale Variable <code>tf</code> verfügbar zu machen. Drücken Sie nach Eingabe der Codezeile die <code>Eingabetaste</code>:</p>\n<pre class=\"code-pre custom_prefix prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"&gt;&gt;&gt;\">import tensorflow as tf\n</li></ul></code></pre>\n<p>Wenn Sie keine Fehler erhalten, haben Sie TensorFlow erfolgreich installiert. Wenn Sie einen Fehler erhalten, sollten Sie sicherstellen, dass Ihr Server genug Leistung für die Verwaltung von TensorFlow bietet. Möglicherweise müssen Sie Ihren Server neu bemessen und dafür sorgen, dass er mindestens 4 GB Arbeitsspeicher hat.</p>\n\n<h2 id=\"zusammenfassung\">Zusammenfassung</h2>\n\n<p>In diesem Tutorial haben Sie TensorFlow in einer virtuellen Python-Umgebung installiert und durch Importieren des TensorFlow-Pakets überprüft, ob TensorFlow funktioniert.</p>\n\n<p>Der <a href=\"https://www.tensorflow.org/programmers_guide/\">Leitfaden für Programmierer</a> von TensorFlow dient als nützliche Ressource und Referenz für die TensorFlow-Entwicklung. Außerdem können Sie sich <a href=\"https://www.kaggle.com/\">Kaggle</a>, eine kompetitive Umgebung zur praktischen Anwendung von maschinellen Lernkonzepten, ansehen, in der Sie gegen andere Fans von maschinellem Lernen, Datenwissenschaft und Statistik antreten können.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:11 +0000","feedId":8037,"bgimg":"","linkMd5":"d59754a34fb71127566bc41a7b3058e2","bgimgJsdelivr":"","metaImg":"","author":"Lisa Tagliaferri","publishedOrCreatedDate":1598860106975},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Cómo escalar y proteger una aplicación de Django con Docker, Nginx y Let's Encrypt","link":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-es","description":"<h3 id=\"introducción\">Introducción</h3>\n\n<p>En los entornos basados en la nube, hay diversas maneras de escalar y proteger aplicaciones de <a href=\"https://www.djangoproject.com/\">Django</a>. Al <em>escalar horizontalmente</em> y ejecutar varias copias de su aplicación, puede crear un sistema más tolerante a fallos y de alta disponibilidad, a la vez que aumenta su <em>rendimiento</em> para que se puedan procesar solicitudes de forma simultánea. Una manera de escalar horizontalmente una aplicación de Django es proporcionar <em>servidores de aplicaciones</em> adicionales que ejecuten su aplicación de Django y su servidor HTTP WSGI (como <a href=\"https://gunicorn.org/\">Gunicorn</a> o <a href=\"https://uwsgi-docs.readthedocs.io/en/latest/\">uWSGI</a>). Para dirigir y distribuir las solicitudes entrantes a través de este conjunto de servidores de aplicaciones, puede usar un <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#load-balancing\">equilibrador de carga</a> y un <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#reverse-proxy\">proxy inverso</a> como <a href=\"https://www.nginx.com/\">Nginx</a>. Nginx también puede almacenar en  caché contenido estático y detener las conexiones de <em>Seguridad de la capa de transporte</em> (TLS), que se utilizan para proporcionar conexiones HTTPS y seguras a su aplicación.</p>\n\n<p>Ejecutar su aplicación de Django y el proxy Nginx dentro de <a href=\"https://www.digitalocean.com/community/tutorials/digitalocean-community-glossary#container\">contenedores</a> de Docker garantiza que estos componentes se comporten de la misma manera independientemente del entorno en el que se implementen. Además, los contenedores proporcionan muchas características que facilitan la creación de paquetes y la configuración de su aplicación.</p>\n\n<p>En este tutorial, escalará horizontalmente una aplicación <a href=\"https://docs.djangoproject.com/en/3.0/intro/tutorial01/\">Polls</a> de Django y Gunicorn en un contenedor proporcionando dos servidores de aplicaciones que ejecutarán una copia de un contenedor de una aplicación de Django y Gunicorn.</p>\n\n<p>También habilitará HTTPS al proporcionar y configurar un tercer  servidor proxy que ejecutará un contenedor de un proxy inverso Nginx y otro de un cliente <a href=\"https://certbot.eff.org/\">Certbot</a>. Certbot proporcionará certificados TLS para Nginx de la entidad de certificación <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a>. Esto garantizará que su sitio reciba una calificación de seguridad alta de <a href=\"https://www.ssllabs.com/\">SSL Labs</a>. Este servidor proxy recibirá todas las solicitudes externas de su aplicación y se ubicará frente a los dos servidores de aplicaciones de Django <em>que preceden en la cadena</em>. Por último, <em>reforzará</em> este sistema distribuido al restringir el acceso externo solo al servidor proxy.</p>\n\n<h2 id=\"requisitos-previos\">Requisitos previos</h2>\n\n<p>Para seguir este tutorial, necesitará lo siguiente:</p>\n\n<ul>\n<li><p>Tres servidores con Ubuntu 18.04:</p>\n\n<ul>\n<li>Dos se utilizarán como servidores de <strong>aplicaciones</strong> y se utilizarán para ejecutar su aplicación de Django y Gunicorn.</li>\n<li>Uno se usará como servidor <strong>proxy</strong> y se utilizará para ejecutar Nginx y Certbot.</li>\n<li>Todos los usuarios deben tener un usuario no root con privilegios <code>sudo</code> y firewall activo. Para obtener información sobre cómo configurarlos, consulte esta <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\">guía de configuración inicial para servidores</a>.</li>\n</ul></li>\n<li><p>Docker instalado en los tres servidores. Para obtener orientación sobre la instalación de Docker, siga los pasos 1 y 2 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04\">Cómo instalar y usar Docker en Ubuntu 18.04</a>.</p></li>\n<li><p>Un nombre de dominio registrado. En este tutorial, utilizaremos <code><span class=\"highlight\">your_domain</span></code> en todo momento. Puede obtener un ejemplar gratis en <a href=\"http://www.freenom.com/en/index.html\">Freenom</a> o utilizar el registrador de dominios que desee.</p></li>\n<li><p>Un registro DNS <code>A</code> con <code><span class=\"highlight\">your_domain.com</span></code> orientado a la dirección IP pública de su servidor <strong>proxy</strong>. Puede seguir <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-digitalocean-dns\">esta introducción al DNS de DigitalOcean</a> para obtener información sobre cómo agregarlo a una cuenta de DigitalOcean, si usa una:</p></li>\n<li><p>Un depósito de almacenamiento de objetos S3, como un <a href=\"https://www.digitalocean.com/products/spaces/\">Space de DigitalOcean</a>, para almacenar los archivos estáticos de su proyecto de Django y un conjunto de claves de acceso para ese espacio. Para obtener información sobre cómo crear Spaces, consulte la documentación de <a href=\"https://www.digitalocean.com/docs/spaces/how-to/create/\">Cómo crear Spaces</a>. Para obtener información sobre cómo crear claves de acceso para Spaces, consulte <a href=\"https://www.digitalocean.com/docs/spaces/how-to/administrative-access/#access-keys\">Compartir el acceso a Spaces con claves de acceso</a>. Con cambios menores, puede usar cualquier servicio de almacenamiento de objetos que admita el complemento <a href=\"https://django-storages.readthedocs.io/en/latest/\">django-storages</a></p></li>\n<li><p>Una instancia de un servidor de PostgreSQL, una base de datos y un usuario para su aplicación de Django. Con cambios menores, puede usar cualquier base de datos que <a href=\"https://docs.djangoproject.com/en/2.2/ref/databases/\">admita Django</a>.</p>\n\n<ul>\n<li>La base de datos de PostgreSQL se debería llamar <strong>polls</strong> (o tener cualquier otro nombre fácil de recordar para ingresar en sus archivos de configuración a continuación). En este tutorial, el usuario de la base de datos se denominará <strong>sammy</strong>. Para obtener información sobre cómo crearlos, siga el Paso 1 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Cómo crear una aplicación de Django y Gunicorn con Docker</a>. Puede realizar estos pasos desde cualquiera de los tres servidores.</li>\n<li>En este tutorial, se utiliza un <a href=\"https://www.digitalocean.com/products/managed-databases/\">clúster de PostgreSQL administrado</a> de DigitalOcean. Para obtener información sobre cómo crear un clúster, consulte la <a href=\"https://www.digitalocean.com/docs/databases/how-to/clusters/create/\">documentación de Bases de datos administradas</a> de DigitalOcean.</li>\n<li>También puede instalar y ejecutar su propia instancia de PostgreSQL. Para obtener información sobre la instalación y administración de PostgreSQL en un servidor de Ubuntu, consulte <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04\">Cómo instalar y utilizar PostgreSQL en Ubuntu 18.04</a>.</li>\n</ul></li>\n</ul>\n\n<h2 id=\"paso-1-configurar-el-primer-servidor-de-aplicaciones-de-django\">Paso 1: Configurar el primer servidor de aplicaciones de Django</h2>\n\n<p>Para comenzar, vamos a clonar el repositorio de aplicaciones de Django en el primer servidor de aplicaciones. A continuación, configuraremos y compilaremos la imagen de Docker de la aplicación y probaremos la aplicación ejecutando el contenedor de Django.</p>\n\n<p><span class='note'><strong>Nota:</strong> Si continúa desde <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-1-%E2%80%94-creating-the-postgresql-database-and-user\">Cómo crear una aplicación de Django y Gunicorn con Docker</a>, ya habrá completado el Paso 1, por lo que puede pasar directamente al <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-2-%E2%80%94-configuring-the-second-django-application-server\">Paso 2</a> para configurar el <strong>segundo</strong> servidor de aplicaciones.<br></span></p>\n\n<p>Comience iniciando sesión en el primero de los dos servidores de aplicaciones de Django. Utilice <code>git</code> para clonar la rama <code>polls-docker</code> del <a href=\"https://github.com/do-community/django-polls\">repositorio de GitHub</a> de la aplicación Polls del tutorial de Django. Este repositorio contiene código para la <a href=\"https://docs.djangoproject.com/en/3.0/intro/\">aplicación Polls de muestra</a> de la documentación de Django. La rama <code>polls-docker</code> contiene una versión con Docker de la aplicación Polls. Para obtener información sobre cómo se modificó la aplicación Polls para que funcione de forma eficaz en un entorno con contenedor, consulte <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker\">Cómo crear una aplicación de Django y Gunicorn con Docker</a>.</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Diríjase al directorio <code>django-polls</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cd django-polls\n</code></pre>\n<p>Este directorio contiene el código de Python de la aplicación de Django, un <code>Dockerfile</code> que Docker utilizará para crear la imagen del contenedor, y un archivo <code>env</code> que contiene una lista de las variables de entorno que se van a pasar al entorno en ejecución del contenedor. Inspeccione el <code>Dockerfile</code> con <code>cat</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>cat Dockerfile\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>FROM python:3.7.4-alpine3.10\n\nADD django-polls/requirements.txt /app/requirements.txt\n\nRUN set -ex \\\n    &amp;&amp; apk add --no-cache --virtual .build-deps postgresql-dev build-base \\\n    &amp;&amp; python -m venv /env \\\n    &amp;&amp; /env/bin/pip install --upgrade pip \\\n    &amp;&amp; /env/bin/pip install --no-cache-dir -r /app/requirements.txt \\\n    &amp;&amp; runDeps=\"$(scanelf --needed --nobanner --recursive /env \\\n        | awk '{ gsub(/,/, \"\\nso:\", $2); print \"so:\" $2 }' \\\n        | sort -u \\\n        | xargs -r apk info --installed \\\n        | sort -u)\" \\\n    &amp;&amp; apk add --virtual rundeps $runDeps \\\n    &amp;&amp; apk del .build-deps\n\nADD django-polls /app\nWORKDIR /app\n\nENV VIRTUAL_ENV /env\nENV PATH /env/bin:$PATH\n\nEXPOSE 8000\n\nCMD [\"gunicorn\", \"--bind\", \":8000\", \"--workers\", \"3\", \"mysite.wsgi\"]\n</code></pre>\n<p>Este Dockerfile utiliza la <a href=\"https://hub.docker.com/_/python\">imagen de Docker</a> oficial de Python 3.7.4 como base e instala los requisitos del paquete de Python de Django y Gunicorn, tal como se define en el archivo <code>django-polls/requirements.txt</code>. A continuación, elimina algunos archivos de compilación innecesarios, copia el código de la aplicación en la imagen y establece el <code>PATH</code> de ejecución. Por último, declara que el puerto <code>8000</code> se utilizará para aceptar conexiones de contenedores entrantes y ejecuta <code>gunicorn</code> con 3 trabajadores, escuchando en el puerto <code>8000</code>.</p>\n\n<p>Para obtener más información sobre cada uno de los pasos de este Dockerfile, consulte el Paso 6 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-build-a-django-and-gunicorn-application-with-docker#step-6-%E2%80%94-writing-the-application-dockerfile\">Cómo crear una aplicación de Django y Gunicorn con Docker</a>.</p>\n\n<p>Ahora, compile la imagen con <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Nombramos la imagen <code>polls</code> con el indicador <code>-t</code> y pasamos el directorio actual como <em>contexto de compilación</em>, el conjunto de archivos a los que se debe hacer referencia al construir la imagen.</p>\n\n<p>Una vez que Docker haya compilado y etiquetado la imagen, enumere las imágenes disponibles utilizando <code>docker images</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>docker images\n</code></pre>\n<p>Debería ver la imagen <code>polls</code> enumerada:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\npolls               latest              80ec4f33aae1        2 weeks ago         197MB\npython              3.7.4-alpine3.10    f309434dea3a        8 months ago        98.7MB\n</code></pre>\n<p>Antes de ejecutar el contenedor de Django, debemos configurar su entorno de ejecución utilizando el archivo <code>env</code> presente en el directorio actual. Este archivo se pasará al comando <code>docker run</code> que se utiliza para ejecutar el contenedor y Docker insertará las variables de entorno configuradas en el entorno en ejecución del contenedor.</p>\n\n<p>Abra el archivo <code>env</code> con <code>nano</code> o su editor favorito:</p>\n<pre class=\"code-pre  second-environment\"><code>nano env\n</code></pre>\n<p>Configuraremos el archivo de esta manera y deberá agregar algunos valores adicionales como se indica a continuación.</p>\n<div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  second-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Complete los valores que faltan para las siguientes claves:</p>\n\n<ul>\n<li><code>DJANGO_SECRET_KEY</code>: establézcala en un valor único e impredecible, como se detalla en la <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#secret-key\">documentación de Django</a>. Se proporciona un método para generar esta clave en la sección <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Ajustar la configuración de la aplicación</a> del tutorial <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#step-5-%E2%80%94-adjusting-the-app-settings\">Aplicaciones escalables de Django</a>.</li>\n<li><code>DJANGO_ALLOWED_HOSTS</code>: esta variable asegura la aplicación y evita ataques a través del encabezado de host HTTP. Para propósitos de prueba, establézcala en <code>*</code>, un comodín que coincidirá con todos los hosts. En producción, debe establecerlo en <code><span class=\"highlight\">your_domain.com</span></code>. Para obtener más información sobre esta configuración de Django, consulte la sección <a href=\"https://docs.djangoproject.com/en/3.0/ref/settings/#allowed-hosts\">Configuración principal</a> en la documentación de Django.</li>\n<li><code>DATABASE_USERNAME</code>: establézcalo en el usuario de la base de datos de PostgreSQL creado en los pasos de requisitos previos.</li>\n<li><code>DATABASE_NAME</code>: establézcalo en <code>polls</code> o el nombre de la base de datos de PostgreSQL creado en los pasos de requisitos previos.</li>\n<li><code>DATABASE_PASSWORD</code>: establézcala en la contraseña de la base de datos de PostgreSQL creada en los pasos de requisitos previos.</li>\n<li><code>DATABASE_HOST</code>: establézcalo en el nombre de host de su base de datos.</li>\n<li><code>DATABASE_PORT</code>: Set establézcalo en el puerto de su base de datos.</li>\n<li><code>STATIC_ACCESS_KEY_ID</code>: establézcala en la clave de acceso de su cubo S3 o su Space.</li>\n<li><code>STATIC_SECRET_KEY</code>: establézcala en el secreto de la clave de acceso de su cubo S3 o su Space.</li>\n<li><code>STATIC_BUCKET_NAME</code>: establézcalo en el nombre de su cubo S3 o su Space.</li>\n<li><code>STATIC_ENDPOINT_URL</code>: establézcala en la URL de extremo correspondiente de su cubo S3 o su Space, por ejemplo, <code>https://<span class=\"highlight\">space-name</span>.nyc3.digitaloceanspaces.com</code>, si su Space está ubicado en la región <code>nyc3</code>.</li>\n</ul>\n\n<p>Una vez que haya finalizado la edición, guarde y cierre el archivo.</p>\n\n<p>Ahora, utilizaremos <code>docker run</code> para anular el <code>CMD</code> establecido en Dockerfile y crear el esquema de la base de datos utilizando los comandos <code>manage.py makemigrations</code> y <code>manage.py migrate</code>:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"\n</code></pre>\n<p>Ejecutamos la imagen del contenedor <code>polls:latest</code>, pasamos el archivo de variables de entorno que acabamos de modificar y anulamos el comando de Dockerfile con <code>sh -c \"python manage.py makemigrations &amp;&amp; python manage.py migrate\"</code>, lo que creará el esquema de la base de datos definido mediante el código de la aplicación. Si lo ejecuta por primera vez, debería ver lo siguiente:</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>No changes detected\nOperations to perform:\n  Apply all migrations: admin, auth, contenttypes, polls, sessions\nRunning migrations:\n  Applying contenttypes.0001_initial... OK\n  Applying auth.0001_initial... OK\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying contenttypes.0002_remove_content_type_name... OK\n  Applying auth.0002_alter_permission_name_max_length... OK\n  Applying auth.0003_alter_user_email_max_length... OK\n  Applying auth.0004_alter_user_username_opts... OK\n  Applying auth.0005_alter_user_last_login_null... OK\n  Applying auth.0006_require_contenttypes_0002... OK\n  Applying auth.0007_alter_validators_add_error_messages... OK\n  Applying auth.0008_alter_user_username_max_length... OK\n  Applying auth.0009_alter_user_last_name_max_length... OK\n  Applying auth.0010_alter_group_name_max_length... OK\n  Applying auth.0011_update_proxy_permissions... OK\n  Applying polls.0001_initial... OK\n  Applying sessions.0001_initial... OK\n</code></pre>\n<p>Esto indica que el esquema de la base de datos se ha creado correctamente.</p>\n\n<p>Si no está ejecutando <code>migrate</code> por primera vez, Django realizará un no-op a menos que el esquema de la base de datos haya cambiado.</p>\n\n<p>A continuación, ejecutaremos otra instancia del contenedor de la aplicación y utilizaremos una shell interactiva en su interior para crear un usuario administrativo para el proyecto de Django.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -i -t --env-file env polls sh\n</code></pre>\n<p>Esto le proporcionará una línea de comandos de shell dentro del contenedor en ejecución que puede usar para crear el usuario de Django:</p>\n<pre class=\"code-pre  second-environment\"><code>python manage.py createsuperuser\n</code></pre>\n<p>Ingrese un nombre de usuario, una dirección de correo electrónico y una contraseña para su usuario y, una vez que haya creado el usuario, presione <code>CTRL+D</code> para salir del contenedor y cerrarlo.</p>\n\n<p>Por último, generaremos los archivos estáticos de la aplicación y los subiremos al Space de DigitalOcean utilizando <code>collectstatic</code>. Tenga en cuenta que esta operación puede tardar un poco en completarse.</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env polls sh -c \"python manage.py collectstatic --noinput\"\n</code></pre>\n<p>Una vez que estos archivos se hayan generado y cargado, obtendrá el siguiente resultado.</p>\n<pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>121 static files copied.\n</code></pre>\n<p>Ahora, podemos ejecutar la aplicación:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run --env-file env -p 80:8000 polls\n</code></pre><pre class=\"code-pre  second-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>[2019-10-17 21:23:36 +0000] [1] [INFO] Starting gunicorn 19.9.0\n[2019-10-17 21:23:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8000 (1)\n[2019-10-17 21:23:36 +0000] [1] [INFO] Using worker: sync\n[2019-10-17 21:23:36 +0000] [7] [INFO] Booting worker with pid: 7\n[2019-10-17 21:23:36 +0000] [8] [INFO] Booting worker with pid: 8\n[2019-10-17 21:23:36 +0000] [9] [INFO] Booting worker with pid: 9\n</code></pre>\n<p>Aquí, ejecutamos el comando predeterminado definido en el Dockerfile, <code>gunicorn --bind :8000 --workers 3 mysite.wsgi:application</code> y exponemos el puerto del contenedor <code>8000</code> para que el puerto <code>80</code> del servidor de Ubuntu se asigne al puerto <code>8000</code> del contenedor <code>polls</code>.</p>\n\n<p>Ahora, debería poder navegar a la aplicación <code>polls</code> desde su navegador web al escribir <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> en la barra de direcciones URL. Dado que no hay una ruta definida para la ruta <code>/</code> , es probable que reciba un error de <code>404 Page Not Found</code> (Página no encontrada), lo que es de esperar.</p>\n\n<p><span class='warning'><strong>Advertencia:</strong> Al usar el firewall UFW con Docker, Docker omite cualquier regla de firewall configurada, tal como se documenta en este <a href=\"https://github.com/docker/for-linux/issues/690\">número de GitHub</a>. Esto explica por qué tiene acceso al puerto <code>80</code> de su servidor, a pesar de no haber creado explícitamente una regla de acceso de UFW en ningún paso de los requisitos previos. Abordaremos este problema de seguridad en el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-5-%E2%80%94-preventing-external-access-to-django-app-servers\">Paso 5</a>, al corregir la configuración de UFW. Si no usa UFW y está utilizando <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">firewalls de DigitalOcean para la nube</a>, puede ignorar de forma segura esta advertencia.<br></span></p>\n\n<p>Diríjase a <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> para ver la interfaz de la aplicación Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Interfaz de la aplicación Polls\"></p>\n\n<p>Para ver la interfaz administrativa, visite <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/admin</code>. Debería ver la ventana de autenticación de administración de la aplicación Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin.png\" alt=\"Página de autenticación de administración de Polls\"></p>\n\n<p>Ingrese el nombre de usuario administrativo y la contraseña que creó con el comando <code>createsuperuser</code>.</p>\n\n<p>Después de la autenticación, podrá acceder a la interfaz administrativa de la aplicación Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png\" alt=\"Interfaz principal de administración de Polls\"></p>\n\n<p>Tenga en cuenta que los que los recursos estáticos de las aplicaciones <code>admin</code> y <code>polls</code> se entregan directamente desde el almacenamiento de objetos. Para confirmar esto, consulte <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-scalable-django-app-with-digitalocean-managed-databases-and-spaces#testing-spaces-static-file-delivery\">Prueba de la entrega de archivos estáticos de Spaces</a>.</p>\n\n<p>Cuando haya terminado de explorar, presione <code>CTRL+C</code> en la ventana de terminal que está ejecutando el contenedor de Docker para cerrar el contenedor.</p>\n\n<p>Ahora que ha confirmado que el contenedor de la aplicación se ejecuta de la manera prevista, puede ejecutarlo en modo <em>separado</em>, lo que lo ejecutará en segundo plano y le permitirá salir de su sesión SSH:</p>\n<pre class=\"code-pre  second-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>El indicador <code>-d</code> le indica a Docker que ejecute el contenedor en modo separado y el indicador <code>-rm</code> limpia el sistema de archivos del contenedor una vez que se sale de él. Denominamos <code>polls</code> al contenedor.</p>\n\n<p>Desconéctese del primer servidor de aplicaciones de Django y diríjase a <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span>/polls</code> para confirmar que el contenedor se está ejecutando de la manera prevista.</p>\n\n<p>Ahora que su primer servidor de aplicaciones de Django está en ejecución, puede configurar el segundo.</p>\n\n<h2 id=\"paso-2-configurar-el-segundo-servidor-de-aplicaciones-de-django\">Paso 2: Configurar el segundo servidor de aplicaciones de Django</h2>\n\n<p>Como muchos de los comandos que se utilizan para configurar este servidor serán los mismos que los que utilizamos en el paso anterior, se presentarán aquí de forma abreviada. Revise el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Paso 1</a> para obtener más información sobre los comandos que se utilizan en este paso.</p>\n\n<p>Comience por iniciar sesión en el <strong>segundo</strong> servidor de aplicaciones de Django.</p>\n\n<p>Clone la rama <code>polls-docker</code> del repositorio de GitHub <code>django-polls</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">git clone --single-branch --branch polls-docker https://github.com/do-community/django-polls.git\n</li></ul></code></pre>\n<p>Diríjase al directorio <code>django-polls</code>:</p>\n<pre class=\"code-pre  third-environment\"><code>cd django-polls\n</code></pre>\n<p>Compile la imagen con <code>docker build</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">docker build -t <span class=\"highlight\">polls</span> .\n</li></ul></code></pre>\n<p>Abra el archivo <code>env</code> con <code>nano</code> o su editor favorito:</p>\n<pre class=\"code-pre  third-environment\"><code>nano env\n</code></pre><div class=\"code-label \" title=\"django-polls/env\">django-polls/env</div><pre class=\"code-pre  third-environment\"><code>DJANGO_SECRET_KEY=\nDEBUG=True\nDJANGO_ALLOWED_HOSTS=\nDATABASE_ENGINE=postgresql_psycopg2\nDATABASE_NAME=polls\nDATABASE_USERNAME=\nDATABASE_PASSWORD=\nDATABASE_HOST=\nDATABASE_PORT=\nSTATIC_ACCESS_KEY_ID=\nSTATIC_SECRET_KEY=\nSTATIC_BUCKET_NAME=\nSTATIC_ENDPOINT_URL=\nDJANGO_LOGLEVEL=info\n</code></pre>\n<p>Complete los valores que faltan como se indica en el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Paso 1</a>. Cuando haya terminado de editar, guarde y cierre el archivo.</p>\n\n<p>Por último, ejecute el contenedor de la aplicación en modo separado:</p>\n<pre class=\"code-pre  third-environment\"><code>docker run -d --rm --name <span class=\"highlight\">polls</span> --env-file env -p 80:8000 polls\n</code></pre>\n<p>Diríjase a <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span>/polls</code> para confirmar que el contenedor se está ejecutando de la manera prevista. Puede iniciar sesión de forma segura en el segundo servidor de aplicaciones sin cerrar el contenedor en ejecución.</p>\n\n<p>Con los dos contenedores de aplicaciones de Django en ejecución, puede configurar el contenedor del proxy inverso Nginx.</p>\n\n<h2 id=\"paso-3-configurar-el-contenedor-de-docker-de-nginx\">Paso 3: Configurar el contenedor de Docker de Nginx</h2>\n\n<p><a href=\"https://www.nginx.com/\">Nginx</a> es un servidor web versátil que ofrece varias características, como <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\">proxy inverso</a>, <a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\">equilibrio de carga</a> y <a href=\"https://en.wikipedia.org/wiki/Web_cache\">almacenamiento en caché</a>. En este tutorial, hemos descargado los recursos estáticos de Django al almacenamiento de objetos, por lo que no utilizaremos las capacidades de almacenamiento en caché de Nginx. Sin embargo, utilizaremos Nginx como proxy inverso para nuestros dos servidores de aplicaciones de Django de backend y distribuiremos las solicitudes entrantes entre ellos. Además, Nginx realizará la <a href=\"https://en.wikipedia.org/wiki/TLS_termination_proxy\">terminación de TLS</a> y el redireccionamiento utilizando un certificado TLS proporcionado por Certbot. Esto significa que obligará a los clientes a usar HTTPS, redireccionando las solicitudes HTTP entrantes al puerto 443. Luego, descifrará las solicitudes HTTPS y las redirigirá, a través del proxy, a los servidores de Django que preceden en la cadena.</p>\n\n<p>En este tutorial, hemos tomado la decisión de desacoplar los contenedores de Nginx de los servidores de backend. Dependiendo de su caso de uso, puede optar por ejecutar el contenedor de Nginx en cualquiera de los dos servidores de aplicaciones de Django, redirigiendo las solicitudes, a través del proxy, de forma local. Otra posible arquitectura sería ejecutar dos contenedores de Nginx, uno en cada servidor de backend, con un <a href=\"https://www.digitalocean.com/products/load-balancer/\">equilibrador de carga</a> en la nube al frente. Cada arquitectura presenta diferentes ventajas de seguridad y desempeño; debe realizar una <a href=\"https://en.wikipedia.org/wiki/Load_testing\">prueba de carga</a> de su sistema para descubrir los posibles cuellos de botella. La arquitectura flexible que se describe en este tutorial le permite escalar tanto la capa de la aplicación de Django de backend como la capa del proxy de Nginx. Cuando el contenedor único de Nginx se convierta en un cuello de botella, puede escalar varios proxy de Nginx y agregar un equilibrador de carga en la nube o uno L4 rápido, como <a href=\"http://www.haproxy.org/\">HAProxy</a>.</p>\n\n<p>Con los dos servidores de aplicaciones de Django en ejecución, podemos comenzar a configurar el servidor proxy de Nginx. Inicie sesión en su servidor proxy y cree un directorio llamado <code>conf</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>mkdir conf\n</code></pre>\n<p>Cree un archivo de configuración denominado <code>nginx.conf</code> con <code>nano</code> o su editor favorito:</p>\n<pre class=\"code-pre  fourth-environment\"><code>nano conf/nginx.conf\n</code></pre>\n<p>Pegue la siguiente configuración de Nginx:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>\nupstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n\nserver {\n    listen 80 default_server;\n    return 444;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name <span class=\"highlight\">your_domain.com</span>;\n\n    # SSL\n    ssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n\n    client_max_body_size 4G;\n    keepalive_timeout 5;\n\n        location / {\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header X-Forwarded-Proto $scheme;\n          proxy_set_header Host $http_host;\n          proxy_redirect off;\n          proxy_pass http://django;\n        }\n\n    location ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n    }\n\n}\n</code></pre>\n<p>Los bloques <code>upstream</code>, <code>server</code> y <code>location</code> configuran Nginx para que redirija las solicitudes HTTP a HTTPS y equilibre su carga entre los dos servidores de aplicaciones de Django configurados en los pasos 1 y 2. Para obtener más información sobre la estructura de los archivos de configuración de Nginx, consulte el artículo <a href=\"https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts#understanding-nginx-configuration-contexts\">Información sobre la estructura de los archivos y los contextos de configuración de Nginx</a>. El artículo <a href=\"https://www.digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms\">Información sobre algoritmos de selección de bloques de servidores y ubicación de Nginx</a> también puede resultarle útil.</p>\n\n<p>Esta configuración se realizó a partir de archivos de configuración de muestra proporcionados por <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Gunicorn</a>, <a href=\"https://github.com/certbot/certbot/blob/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf\">Cerbot</a> y <a href=\"https://hub.docker.com/_/nginx\">Nginx</a> y representa una configuración mínima de Nginx para poner en marcha esta arquitectura. Los ajustes de esta configuración de Nginx están fuera del alcance de este artículo, pero puede usar una herramienta como <a href=\"https://www.digitalocean.com/community/tools/nginx\">NGINXConfi</a>g para generar archivos de configuración de Nginx seguros y de buen rendimiento para su arquitectura.</p>\n\n<p>El bloque <code>upstream</code> define el grupo de servidores que se utiliza para redirigir las solicitudes mediante el proxy utilizando la directiva <code>proxy_pass</code>:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>upstream django {\n    server <span class=\"highlight\">APP_SERVER_1_IP</span>;\n    server <span class=\"highlight\">APP_SERVER_2_IP</span>;\n}\n. . .\n</code></pre>\n<p>En este bloque, lo denominamos <code>django</code> e incluimos las direcciones IP de los dos servidores de aplicaciones de Django. Si los servidores de aplicaciones se ejecutan en DigitalOcean y tienen habilitadas redes VPC, debe usar sus direcciones IP privadas aquí. Para obtener información sobre cómo habilitar las redes VPC en DigitalOcean, consulte <a href=\"https://www.digitalocean.com/docs/networking/vpc/how-to/enable/\">Cómo habilitar redes VPC en Droplets existentes</a>.</p>\n\n<p>El primer bloque <code>server</code> captura las solicitudes que no coinciden con su dominio y termina la conexión. Por ejemplo, este bloque manejaría una solicitud HTTP directa a la dirección IP de su servidor:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80 default_server;\n    return 444;\n}\n. . .\n</code></pre>\n<p>El siguiente bloque <code>server</code> redirige las solicitudes HTTP a su dominio a HTTPS utilizando un redireccionamiento <a href=\"https://en.wikipedia.org/wiki/HTTP_301\">HTTP 301</a>. Luego, el bloque <code>server</code> final se encarga de manejar estas solicitudes:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name your_domain.com;\n    return 301 https://$server_name$request_uri;\n}\n. . .\n</code></pre>\n<p>Estas dos directivas definen las rutas al certificado TLS y la clave secreta. Se proporcionarán utilizando Certbot y se instalarán en el contenedor de Nginx en el siguiente paso.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nssl_certificate /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem;\nssl_certificate_key /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem;\n. . .\n</code></pre>\n<p>Estos parámetros son los valores predeterminados de seguridad SSL recomendados por Certbot. Para obtener más información sobre ellos, consulte el <a href=\"https://nginx.org/en/docs/http/ngx_http_ssl_module.html\">Módulo ngx_http_ssl_module</a> en la documentación de Nginx. La guía <a href=\"https://wiki.mozilla.org/Security/Server_Side_TLS\">Seguridad/TLS del lado del servidor</a> de Mozilla es otro recurso útil que puede usar para ajustar su configuración de SSL.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\n    ssl_session_cache shared:le_nginx_SSL:10m;\n    ssl_session_timeout 1440m;\n    ssl_session_tickets off;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";\n. . .\n</code></pre>\n<p>Estas dos directivas de la <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">configuración de muestra de Nginx</a> de Gunicorn establecen el tamaño máximo permitido del cuerpo de la solicitud del cliente y asignan el tiempo de espera para las conexiones persistentes con el cliente. Nginx cerrará las conexiones con el cliente una vez transcurridos los segundos de <code>keepalive_timeout</code>.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nclient_max_body_size 4G;\nkeepalive_timeout 5;\n. . .\n</code></pre>\n<p>El primer bloque <code>location</code> le indica a Nginx que redirija, a través del proxy, las solicitudes a los servidores <code>upstream django</code> mediante HTTP. También preserva los encabezados HTTP del cliente que capturan la dirección IP de origen, el protocolo utilizado para la conexión y el host de destino:</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation / {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://django;\n}\n. . .\n</code></pre>\n<p>Para obtener más información sobre estas directivas, consulte <a href=\"https://docs.gunicorn.org/en/stable/deploy.html#nginx-configuration\">Implementación de Gunicorn</a> y <a href=\"http://nginx.org/en/docs/http/ngx_http_proxy_module.html\">Module ngx_http_proxy_module</a> en la documentación de Nginx.</p>\n\n<p>El bloque <code>location</code> final captura las solicitudes a la ruta <code>/well-known/acme-challenge/</code> que utiliza Certbot en los desafíos de HTTP-01 para verificar su dominio con Let&rsquo;s Encrypt y suministrar o renovar los certificados TLS.  Para obtener más información sobre el desafío HTTP-01 que utiliza Certbot, consulte <a href=\"https://letsencrypt.org/docs/challenge-types/\">Tipos de desafíos</a> en la documentación de Let&rsquo;s Encrypt.</p>\n<div class=\"code-label \" title=\"conf/nginx.conf\">conf/nginx.conf</div><pre class=\"code-pre  fourth-environment\"><code>. . .\nlocation ^~ /.well-known/acme-challenge/ {\n        root /var/www/html;\n}\n</code></pre>\n<p>Una vez que haya finalizado la edición, guarde y cierre el archivo.</p>\n\n<p>Ahora, puede usar este archivo de configuración para ejecutar un contenedor de Docker de Nginx. En este tutorial, utilizaremos la imagen <code>nginx:1.19.0</code>, versión <code>1.19.0</code>, de la <a href=\"https://hub.docker.com/_/nginx\">imagen de Docker oficial</a> que mantiene Nginx.</p>\n\n<p>Cuando ejecutemos el contenedor por primera vez, Nginx arrojará un error y fallará, dado que aún no hemos proporcionado los certificados definidos en el archivo de configuración. De todos modos, ejecutaremos el comando para descargar la imagen de Nginx de forma local y probar que todo lo demás funcione correctamente:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Aquí, denominamos <code>nginx</code> al contenedor y asignamos los puertos del host <code>80</code> y <code>443</code> a los puertos de los contenedores respectivos. El indicador <code>-v</code> ubica el archivo config en el contenedor de Nginx en <code>/etc/nginx/conf.d/nginx.conf</code>, que la imagen de Nginx está preconfigurada para cargar. Se coloca en modo <code>ro</code> o de &ldquo;solo lectura&rdquo;, por lo que el contenedor no puede modificar el archivo. El directorio web root <code>/var/www/html</code> también se instala en el contenedor. Por último, <code>nginx:1.19.0</code> le indica a Docker que extraiga y ejecute la imagen <code>nginx:1.19.0</code> de Dockerhub.</p>\n\n<p>Docker extraerá y ejecutará la imagen y, luego, Nginx arrojará un error cuando no encuentre el certificado TLS configurado y la clave secreta. Los suministraremos en el siguiente paso utilizando un cliente de Cerbot con Docker y la entidad de certificación Let&rsquo;s Encrypt.</p>\n\n<h2 id=\"paso-4-configurar-la-renovación-de-certificados-de-let’s-encrypt-y-certbot\">Paso 4: Configurar la renovación de certificados de Let’s Encrypt y Certbot</h2>\n\n<p><a href=\"https://github.com/certbot/certbot\">Certbot</a> es un cliente Let&rsquo;s Encrypt desarrollado por <a href=\"https://www.eff.org/\">Electronic Frontier Foundation</a>. Proporciona certificados TLS gratuitos de la entidad de certificación <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> que permiten a los navegadores verificar la identidad de sus servidores web. Como tenemos Docker instalado en nuestro servidor proxy de Nginx, utilizaremos la <a href=\"https://hub.docker.com/r/certbot/certbot/\">imagen de Docker de Certbot</a> para suministrar y renovar los certificados TLS.</p>\n\n<p>Comience por asegurarse de tener un registro DNS <code>A</code> asignado a la dirección IP pública del servidor proxy. A continuación, en su servidor proxy, proporcione una versión provisional de los certificados utilizando la imagen de Docker <code>certbot</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone --staging -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Este comando ejecuta la imagen de Docker <code>certbot</code> en modo interactivo y reenvía el puerto <code>80</code> del host al puerto <code>80</code> del contenedor. Crea y monta dos directorios de host en el contenedor: <code>/etc/letsencrypt/</code> y <code>/var/lib/letsencrypt/</code>. <code>certbot</code> se ejecuta en modo <code>standalone</code>, sin Nginx, y utilizará los servidores <code>staging</code> de Let&rsquo;s Encrypt para realizar la validación del dominio.</p>\n\n<p>Cuando se le solicite, ingrese su dirección de correo electrónico y acepte las Condiciones del servicio. Si la validación del dominio es correcta, debería ver el siguiente resultado:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Obtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for stubb.dev\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/privkey.pem\n   Your cert will expire on 2020-09-15. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - Your account credentials have been saved in your Certbot\n   configuration directory at /etc/letsencrypt. You should make a\n   secure backup of this folder now. This configuration directory will\n   also contain certificates and private keys obtained by Certbot so\n   making regular backups of this folder is ideal.\n</code></pre>\n<p>Puede inspeccionar el certificado utilizando <code>cat</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>sudo cat /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n</code></pre>\n<p>Con el certificado TLS suministrado, podemos probar la configuración de Nginx que establecimos en el paso anterior:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Este es el mismo comando que ejecutamos en el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Paso 3</a>, con la adición de los dos directorios de Let&rsquo;s Encrypt que acabamos de crear.</p>\n\n<p>Una vez que Nginx esté en ejecución, diríjase a <code>http://<span class=\"highlight\">your_domain.com</span></code>. Puede recibir una advertencia en su navegador indicando que la entidad de certificación no es válida. Esto es de esperar dado que suministramos certificados provisionales, no certificados de producción de Let&rsquo;s Encrypt. Compruebe la barra de direcciones URL de su navegador para confirmar que su solicitud HTTP se haya redireccionado a HTTPS.</p>\n\n<p>Presione <code>CTRL+C</code> en su terminal para salir de Nginx y volver a ejecutar el cliente <code>certbot</code>, omitiendo el indicador <code>--staging</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm -p 80:80 --name certbot \\\n         -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n         -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n         certbot/certbot certonly --standalone -d <span class=\"highlight\">your_domain.com</span>\n</code></pre>\n<p>Cuando se le solicite mantener el certificado existente o renovarlo y sustituirlo, presione <code>2</code> para renovarlo y, luego, presione <code>ENTER</code> para confirmar su elección.</p>\n\n<p>Con el certificado TLS de producción suministrado, vuelva a ejecutar el servidor Nginx:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n    -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>En su navegador, diríjase a <code>http://<span class=\"highlight\">your_domain.com</span></code>. En la barra de direcciones URL, confirme que la solicitud HTTP se haya redireccionado a HTTPS. Dado que la aplicación Polls no tiene una ruta predeterminada configurada, debería ver un error de Django de  *<em>Página no encontrada *</em>. Diríjase a <code>https://<span class=\"highlight\">your_domain.com</span>/polls</code> para ver la interfaz estándar de la aplicación Polls:</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/scalable_django/polls_app.png\" alt=\"Interfaz de la aplicación Polls\"></p>\n\n<p>En este punto, ha suministrado un certificado TLS de producción utilizando el cliente de Docker Certbot y está redirigiendo las solicitudes externas a través del proxy inverso y equilibrando la carga entre los dos servidores de aplicaciones de Django.</p>\n\n<p>Los certificados de Let&rsquo;s Encrypt caducan cada 90 días. Para asegurarse de que su certificado permanezca válido, debe renovarlo regularmente antes de su vencimiento programado. Con Nginx en ejecución, debe usar el cliente de Certbot en modo <code>webroot</code> en vez de <code>standalone</code>. Esto significa que Certbot realizará la validación creando un archivo en el directorio <code>/var/www/html/.well-known/acme-challenge/</code> y la regla <code>location</code> definida en la configuración de Nginx realizada en el <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-3-%E2%80%94-configuring-the-nginx-docker-container\">Paso 3</a> capturará las solicitudes de validación de Let&rsquo;s Encrypt a esta ruta. A continuación, Certbot rotará los certificados, y usted podrá volver a cargar Nginx para que utilice este certificado recién suministrado.</p>\n\n<p>Hay varias formas de automatizar este procedimiento, pero la renovación automática de certificados TLS está fuera del alcance de este tutorial. Para obtener un proceso similar usando la utilidad de programación <code>cron</code>, consulte el paso 6 de <a href=\"https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates%5D(https://www.digitalocean.com/community/tutorials/how-to-secure-a-containerized-node-js-application-with-nginx-let-s-encrypt-and-docker-compose#step-6-%E2%80%94-renewing-certificates)\">Cómo proteger una aplicación de Node.js en un contenedor con Nginx, Let&rsquo;s Encrypt y Docker Compose</a>.</p>\n\n<p>En su terminal, presione <code>CTRL+C</code> para cerrar el contenedor de Nginx. Vuelva a ejecutarlo en modo separado al agregar el indicador <code>-d</code>:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run --rm --name nginx -d -p 80:80 -p 443:443 \\\n    -v ~/conf/nginx.conf:/etc/nginx/conf.d/nginx.conf:ro \\\n    -v /etc/letsencrypt:/etc/letsencrypt \\\n    -v /var/lib/letsencrypt:/var/lib/letsencrypt \\\n  -v /var/www/html:/var/www/html \\\n    nginx:1.19.0\n</code></pre>\n<p>Con Nginx ejecutándose en segundo plano, utilice el siguiente comando para realizar una ejecución de prueba del procedimiento de renovación de certificados:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker run -it --rm --name certbot \\\n    -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n  -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n  -v \"/var/www/html:/var/www/html\" \\\n  certbot/certbot renew --webroot -w /var/www/html --dry-run\n</code></pre>\n<p>Utilizamos el complemento <code>--webroot</code>, especificamos la ruta web root y utilizamos el indicador <code>--dry-run</code> para verificar que todo funciona correctamente sin realizar la renovación de certificados real.</p>\n\n<p>Si la simulación de la renovación se realiza correctamente, debería ver el siguiente resultado:</p>\n<pre class=\"code-pre  fourth-environment\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Cert not due for renewal, but simulating renewal for dry run\nPlugins selected: Authenticator webroot, Installer None\nRenewing an existing certificate\nPerforming the following challenges:\nhttp-01 challenge for <span class=\"highlight\">your_domain.com</span>\nUsing the webroot path /var/www/html for all unmatched domains.\nWaiting for verification...\nCleaning up challenges\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nnew certificate deployed without reload, fullchain is\n/etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates below have not been saved.)\n\nCongratulations, all renewals succeeded. The following certs have been renewed:\n  /etc/letsencrypt/live/<span class=\"highlight\">your_domain.com</span>/fullchain.pem (success)\n** DRY RUN: simulating 'certbot renew' close to cert expiry\n**          (The test certificates above have not been saved.)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n</code></pre>\n<p>En un entorno de producción, después de renovar los certificados, debe volver a cargar Nginx para que los cambios surtan efecto. Para volver a cargar Nginx, ejecute el siguiente comando:</p>\n<pre class=\"code-pre  fourth-environment\"><code>docker kill -s HUP nginx\n</code></pre>\n<p>Este comando enviará una señal <a href=\"https://en.wikipedia.org/wiki/SIGHUP\">HUP</a> Unix al proceso de Nginx que se está ejecutando en el contenedor de Docker <code>nginx</code>. Al recibir esta señal, Nginx volverá a cargar su configuración y sus certificados renovados.</p>\n\n<p>Con HTTPS habilitado y todos los componentes de esta arquitectura en ejecución, el paso final es bloquear la configuración al evitar el acceso externo a los dos servidores de aplicaciones backend; todas las solicitudes HTTP deben pasar por el proxy de Nginx.</p>\n\n<h2 id=\"paso-5-prevención-de-acceso-externo-a-servidores-de-aplicaciones-de-django\">Paso 5: Prevención de acceso externo a servidores de aplicaciones de Django</h2>\n\n<p>En la arquitectura que se describe en este tutorial, la terminación de SSL se produce en el proxy de Nginx. Esto significa que Nginx descifra la conexión SSL y los paquetes se redirigen, a través del proxy, a los servidores de aplicaciones de Django no cifrados. Para muchos casos de uso, este nivel de seguridad es suficiente. Para las aplicaciones que incluyen datos financieros o de salud, es conveniente implementar cifrado de extremo a extremo. Puede hacerlo al reenviar paquetes cifrados a través del equilibrador de carga y descifrarlos en los servidores de aplicaciones o volver a cifrarlos en el proxy y descifrarlos nuevamente en los servidores de aplicaciones de Django. Estas técnicas están fuera del alcance de este artículo, pero puede consultar el documento <a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">Cifrado de extremo a extremo</a> para obtener más información.</p>\n\n<p>El proxy de Nginx actúa como una puerta de enlace entre el tráfico externo y la red interna. En teoría, ningún cliente externo debería tener acceso directo a los servidores de aplicaciones internos y todas las solicitudes deberían pasar a través del servidor de Nginx. La nota del <a href=\"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt#step-1-%E2%80%94-configuring-the-first-django-application-server\">Paso 1</a> describe brevemente un <a href=\"https://github.com/docker/for-linux/issues/690\">problema abierto</a> con Docker en el que Docker omite la configuración de firewall <code>ufw</code> de manera predeterminada y abre los puertos de forma externa, lo que puede ser peligroso. Para solucionar este problema de seguridad, se recomienda usar <a href=\"https://www.digitalocean.com/docs/networking/firewalls/\">firewalls para la nube</a> al trabajar con servidores con Docker. Para obtener más información sobre la creación de firewalls para la nube con DigitalOcean, consulte <a href=\"https://www.digitalocean.com/docs/networking/firewalls/how-to/create/\">Cómo crear firewalls</a>. También puede manipular <code>iptables</code> directamente en lugar de usar <code>ufw</code>. Para obtener más información sobre el uso de <code>iptables</code> con Docker, consulte <a href=\"https://docs.docker.com/network/iptables/\">Docker e iptables</a>.</p>\n\n<p>En este paso, modificaremos la configuración de UFW para bloquear el acceso externo a los puertos del host que abre Docker. Al ejecutar Django en los servidores de aplicaciones, pasamos el indicador <code>-p 80:8000</code> a <code>docker</code>, que reenvía el puerto <code>80</code> del host al puerto <code>8000</code> del contenedor. Esto también abrió el puerto <code>80</code> a clientes externos, lo que puede verificar al dirigirse a <code>http://<span class=\"highlight\">your_app_server_1_IP</span></code>. Para evitar el acceso directo, modificaremos la configuración de UFW utilizando el método que se describe en el <a href=\"https://github.com/chaifeng/ufw-docker\">repositorio de GitHub ufw-docker</a>.</p>\n\n<p>Comience por iniciar sesión en el primer servidor de aplicaciones de Django. A continuación, abra el archivo <code>/etc/ufw/after.rules</code> con privilegios de superusuario, utilizando <code>nano</code> o su editor favorito:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Cuando se le solicite, ingrese su contraseña y, luego, presione <code>ENTER</code> para confirmar.</p>\n\n<p>Debería ver las siguientes reglas <code>ufw</code>:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>#\n# rules.input-after\n#\n# Rules that should be run after the ufw command line added rules. Custom\n# rules should be added to one of these chains:\n#   ufw-after-input\n#   ufw-after-output\n#   ufw-after-forward\n#\n\n# Don't delete these required lines, otherwise there will be errors\n*filter\n:ufw-after-input - [0:0]\n:ufw-after-output - [0:0]\n:ufw-after-forward - [0:0]\n# End required lines\n\n# don't log noisy services by default\n-A ufw-after-input -p udp --dport 137 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 138 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 139 -j ufw-skip-to-policy-input\n-A ufw-after-input -p tcp --dport 445 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 67 -j ufw-skip-to-policy-input\n-A ufw-after-input -p udp --dport 68 -j ufw-skip-to-policy-input\n\n# don't log noisy broadcast\n-A ufw-after-input -m addrtype --dst-type BROADCAST -j ufw-skip-to-policy-input\n\n# don't delete the 'COMMIT' line or these rules won't be processed\nCOMMIT\n</code></pre>\n<p>Pegue el siguiente bloque de reglas de configuración de UFW en la parte inferior:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  second-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Estas reglas restringen el acceso público a los puertos que abre Docker y permiten el acceso a los intervalos de IP privadas <code>10.0.0.0/8</code>, <code>172.16.0.0/12</code> y <code>192.168.0.0/16</code>. Si usa VPC con DigitalOcean, entonces, las Droplets de su red VPC tendrán acceso al puerto abierto a través de la interfaz de red privada, pero los clientes externos no lo tendrán. Para obtener más información sobre las VPC, consulte la <a href=\"https://www.digitalocean.com/docs/networking/vpc/\">documentación oficial de las VPC</a>. Para obtener más información sobre las reglas implementadas en este fragmento de código, consulte <a href=\"https://github.com/chaifeng/ufw-docker#how-it-works\">¿Cómo funciona?</a> en el <a href=\"https://github.com/chaifeng/ufw-docker\">archivo README de ufw-docker</a>.</p>\n\n<p>Si no está utilizando VPC con DigitalOcean y ha introducido las direcciones IP públicas de los servidores de aplicaciones en el bloque <code>upstream</code> de su configuración de Nginx, deberá modificar explícitamente el firewall UFW para que permita tráfico del servidor de Nginx a través del puerto <code>80</code> de los servidores de aplicaciones de Django. Para obtener información sobre la creación de reglas <code>allow</code> con el firewall de UFW, consulte <a href=\"https://www.digitalocean.com/community/tutorials/ufw-essentials-common-firewall-rules-and-commands\">Aspectos básicos de UFW: reglas y comandos comunes de firewall</a>.</p>\n\n<p>Una vez que haya finalizado la edición, guarde y cierre el archivo.</p>\n\n<p>Reinicie <code>ufw</code> para que tome la nueva configuración:</p>\n<pre class=\"code-pre  second-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Diríjase a <code>http://<span class=\"highlight\">APP_SERVER_1_IP</span></code> en su navegador web para confirmar que ya no pueda acceder al servidor de aplicaciones a través del puerto <code>80</code>.</p>\n\n<p>Repita este proceso en el segundo servidor de aplicaciones de Django.</p>\n\n<p>Cierre sesión en el primer servidor de aplicaciones o abra otra ventana de terminal, e inicie sesión en el segundo servidor de aplicaciones de Django. A continuación, abra el archivo <code>/etc/ufw/after.rules</code> con privilegios de superusuario, utilizando <code>nano</code> o su editor favorito:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo nano /etc/ufw/after.rules\n</code></pre>\n<p>Cuando se le solicite, ingrese su contraseña y, luego, presione <code>ENTER</code> para confirmar.</p>\n\n<p>Pegue el siguiente bloque de reglas de configuración de UFW en la parte inferior:</p>\n<div class=\"code-label \" title=\"/etc/ufw/after.rules\">/etc/ufw/after.rules</div><pre class=\"code-pre  third-environment\"><code>. . .\n\n# BEGIN UFW AND DOCKER\n*filter\n:ufw-user-forward - [0:0]\n:DOCKER-USER - [0:0]\n-A DOCKER-USER -j RETURN -s 10.0.0.0/8\n-A DOCKER-USER -j RETURN -s 172.16.0.0/12\n-A DOCKER-USER -j RETURN -s 192.168.0.0/16\n\n-A DOCKER-USER -p udp -m udp --sport 53 --dport 1024:65535 -j RETURN\n\n-A DOCKER-USER -j ufw-user-forward\n\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -d 172.16.0.0/12\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 192.168.0.0/16\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 10.0.0.0/8\n-A DOCKER-USER -j DROP -p udp -m udp --dport 0:32767 -d 172.16.0.0/12\n\n-A DOCKER-USER -j RETURN\nCOMMIT\n# END UFW AND DOCKER\n</code></pre>\n<p>Una vez que haya finalizado la edición, guarde y cierre el archivo.</p>\n\n<p>Reinicie <code>ufw</code> para que tome la nueva configuración:</p>\n<pre class=\"code-pre  third-environment\"><code>sudo systemctl restart ufw\n</code></pre>\n<p>Diríjase a <code>http://<span class=\"highlight\">APP_SERVER_2_IP</span></code> en su navegador web para confirmar que ya no pueda acceder al servidor de aplicaciones a través del puerto <code>80</code>.</p>\n\n<p>Por último, diríjase a <code>https://<span class=\"highlight\">your_domain_here</span>/polls</code> para confirmar que el proxy de Nginx siga teniendo acceso a los servidores de Django que preceden en la cadena. Debería ver la interfaz predeterminada de la aplicación de Polls.</p>\n\n<h2 id=\"conclusión\">Conclusión</h2>\n\n<p>En este tutorial, configuró una aplicación Polls de Django escalable utilizando contenedores de Docker. A medida que su tráfico y la carga en el sistema aumenten, puede escalar cada capa de forma separada: la capa de redireccionamiento mediante proxy de Nginx, la capa de aplicaciones de backend de Django y la capa de la base de datos de PostgreSQL.</p>\n\n<p>Crear un sistema distribuido suele implicar tener que tomar varias decisiones de diseño, y encontrará varias arquitecturas disponibles para satisfacer su caso de uso. La arquitectura que se describe en este tutorial se presenta como un plan flexible para diseñar aplicaciones escalables con Django y Docker.</p>\n\n<p>Probablemente desee controlar el comportamiento de sus contenedores cuando detecten errores o ejecutar contenedores de forma automática al iniciar su sistema. Para hacerlo, puede usar un administrador de procesos como <a href=\"https://en.wikipedia.org/wiki/Systemd\">Systemd</a> o implementar directivas de reinicio. Para obtener más información al respecto, consulte <a href=\"https://docs.docker.com/config/containers/start-containers-automatically/\">Iniciar contenedores de forma automática</a> en la documentación de Docker.</p>\n\n<p>Al trabajar a gran escala con varios hosts ejecutando la misma imagen de Docker, puede resultar más eficaz automatizar los pasos utilizando una herramienta de administración de configuración como <a href=\"https://www.ansible.com/\">Ansible</a> o <a href=\"https://www.chef.io/\">Chef</a>. Para obtener más información sobre la administración de configuración, consulte <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-configuration-management\">Introducción a la administración de configuración</a> y  <a href=\"https://www.digitalocean.com/community/meetup_kits/automating-server-setup-with-ansible-a-digitalocean-workshop-kit\">Configuración de la automatización con Ansible: Un kit del taller de DigitalOcean</a>.</p>\n\n<p>En lugar de compilar la misma imagen en cada host, también puede simplificar la implementación utilizando un registro de imágenes como <a href=\"https://hub.docker.com/\">Docker Hub</a>, que compila, almacena y distribuye imágenes de Docker en varios servidores. Además de un registro de imágenes, una canalización de integración e implementación continua puede ayudarlo a compilar, probar e implementar imágenes en sus servidores de aplicaciones. Para obtener más información sobre CI/CD, consulte <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-ci-cd-best-practices\">Introducción a las prácticas recomendadas de CI/CD</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:43 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/scalable_django/polls_app.png","linkMd5":"5792aefc8110244761ef1e85fcf54ab2","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","destWidth":474,"destHeight":473,"sourceBytes":43341,"destBytes":1896,"author":"Hanif Jetha","articleImgCdnMap":{"https://assets.digitalocean.com/articles/scalable_django/polls_app.png":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/31/07-48-31-305_44661f4fc2769a02.webp","https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn38@2020_6/2020/08/31/07-48-31-498_6d93c2bd68b66072.webp"},"publishedOrCreatedDate":1598860106987},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment centraliser les journaux avec Journald sur Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-journald-on-ubuntu-20-04-fr","description":"<p><em>L'auteur a choisi le <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> comme récipiendaire d'un don dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Les journaux système sont un élément extrêmement important de la gestion des systèmes Linux. Ils fournissent un aperçu inestimable du fonctionnement des systèmes et de leur utilisation car, en plus des erreurs, ils enregistrent des informations opérationnelles telles que les événements de sécurité. La configuration standard des systèmes Linux consiste à stocker leurs journaux localement sur le même système que celui où ils ont été créés. Cela fonctionne pour les systèmes autonomes, mais devient rapidement un problème lorsque le nombre de systèmes augmente. La solution pour gérer tous ces journaux est de créer un serveur de journalisation centralisé où chaque hôte Linux envoie ses journaux, en temps réel, à un serveur de gestion de journaux dédié.</p>\n\n<p>Une solution de journalisation centralisée offre plusieurs avantages par rapport au stockage des journaux sur chaque hôte :</p>\n\n<ul>\n<li>Cela réduit la quantité d'espace disque nécessaire sur chaque hôte pour stocker les fichiers journaux.</li>\n<li>Les journaux peuvent être conservés plus longtemps, car le serveur de journaux dédié peut être configuré avec une plus grande capacité de stockage.</li>\n<li>Il est possible d'effectuer une analyse avancée des journaux qui nécessite des journaux provenant de plusieurs systèmes et également plus de ressources de calcul que celles qui peuvent être disponibles sur les hôtes.</li>\n<li>Les administrateurs de systèmes peuvent accéder aux journaux de tous leurs systèmes auxquels ils ne peuvent pas se connecter directement pour des raisons de sécurité.</li>\n</ul>\n\n<p>Dans ce guide, vous allez configurer un composant de la suite d'outils <a href=\"https://systemd.io/\">systemd</a> pour relayer les messages de journal des systèmes clients vers un serveur de collecte de journaux centralisé. Vous allez configurer le serveur et le client pour qu'ils utilisent des certificats TLS afin de crypter les messages du journal lorsqu'ils sont transmis sur des réseaux non sécurisés tels qu'Internet, et également pour qu'ils s'authentifient mutuellement.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Avant de commencer ce guide, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li>Deux serveurs Ubuntu 20.04.</li>\n<li>Un utilisateur non root avec des privilèges sudo sur les deux serveurs.  Suivez le guide <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">Configuration initiale du serveur avec Ubuntu 20.04</a> pour savoir comment procéder. Vous devez également configurer le pare-feu UFW sur les deux serveurs comme expliqué dans le guide.</li>\n<li>Deux noms d'hôtes qui pointent vers vos serveurs. Un nom d'hôte pour le système <strong>client</strong> qui génère les journaux et un autre pour le <strong>serveur</strong> de collecte des journaux. Apprenez comment faire pointer les noms d'hôtes vers DigitalOcean Droplets en consultant la documentation <a href=\"https://www.digitalocean.com/docs/networking/dns/\">Domaines et DNS</a>.</li>\n</ul>\n\n<p>Ce guide utilisera les deux exemples de noms d'hôtes suivants :</p>\n\n<ul>\n<li><code><span class=\"highlight\">client.your_domain</span></code> : Le système client qui génère les journaux.</li>\n<li><code><span class=\"highlight\">server.your_domain</span></code> : Le serveur de collecte des journaux.</li>\n</ul>\n\n<p>Connectez-vous au client et au serveur dans des terminaux séparés via SSH en tant qu'utilisateur non root sudo pour commencer ce tutoriel.</p>\n\n<p><span class='note'><strong>Note</strong> : tout au long du tutoriel, les blocs de commande sont étiquetés avec le nom du serveur (<strong>client</strong> ou <strong>server</strong>) sur lequel la commande doit être exécutée.<br></span></p>\n\n<h2 id=\"Étape-1-—-installation-de-systemd-journal-remote\">Étape 1 — Installation de <code>systemd-journal-remote</code></h2>\n\n<p>Au cours de cette étape, vous installerez le paquet <code>systemd-journal-remote</code> sur le <strong>client</strong> et le <strong>serveur</strong>. Ce paquet contient les composants que le <strong>client</strong> et le <strong>serveur</strong> utilisent pour relayer les messages du journal.</p>\n\n<p>Tout d'abord, sur le <strong>client</strong> et le <strong>serveur</strong>, lancez une mise à jour du système pour vous assurer que la base de données de paquets et le système sont à jour :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li><li class=\"line\" data-prefix=\"$\">sudo apt upgrade\n</li></ul></code></pre>\n<p>Ensuite, installez le paquet <code>systemd-journal-remote</code> :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install systemd-journal-remote\n</li></ul></code></pre>\n<p>Sur le <strong>serveur</strong>, activez et lancez les deux composants <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\"><code>systemd</code></a> dont il a besoin pour recevoir les messages de journal avec la commande suivante :</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable --now systemd-journal-remote.socket\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-remote.service\n</li></ul></code></pre>\n<p>L'option <code>--now</code> de la première commande permet de démarrer les services immédiatement. Vous ne l'avez pas utilisé dans la deuxième commande, car ce service ne démarrera pas tant qu'il ne disposera pas de certificats TLS, que vous créerez à l'étape suivante.</p>\n\n<p>Sur le <strong>client</strong>, activez le composant que <code>systemd</code> utilise pour envoyer les messages de journal au serveur :</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Ensuite, sur le serveur, ouvrez les ports <code>19532</code> et <code>80</code> dans le pare-feu UFW. Cela permettra au serveur de recevoir les messages de journal du client. Le port <code>80</code> est le port que <code>certbot</code> utilisera pour générer le certificat TLS. Les commandes suivantes permettent d'ouvrir ces ports :</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 19532/tcp\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Sur le client, il suffit d'ouvrir le port <code>80</code> avec cette commande :</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Vous avez maintenant installé les composants nécessaires et terminé la configuration du système de base sur le client et le serveur. Avant de pouvoir configurer ces composants pour commencer à relayer les messages du journal, vous devez enregistrer les certificats <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> TLS pour le <strong>client</strong> et le <strong>serveur</strong> à l'aide de l'utilitaire <a href=\"https://certbot.eff.org/\"><code>certbot</code></a>.</p>\n\n<h2 id=\"Étape-2-—-installation-de-certbot-et-enregistrement-de-certificats\">Étape 2 — Installation de Certbot et enregistrement de certificats</h2>\n\n<p>Let&rsquo;s Encrypt est une <a href=\"https://en.wikipedia.org/wiki/Certificate_authority\">autorité de certification</a> qui délivre des certificats TLS gratuits. Ces certificats permettent aux ordinateurs à la fois de crypter les données qu'ils s'envoient entre eux et de vérifier l'identité de chacun. Ce sont ces certificats qui vous permettent de sécuriser votre navigation sur Internet avec HTTPS. Les mêmes certificats peuvent être utilisés par toute autre application qui souhaite le même niveau de sécurité. La procédure d'enregistrement du certificat est la même, quelle que soit l'utilisation que vous en ferez.</p>\n\n<p>Au cours de cette étape, vous installerez l'utilitaire <code>certbot</code> et l'utiliserez pour enregistrer les certificats. Il se chargera également de renouveler automatiquement les certificats lorsqu'ils arriveront à expiration. La procédure d'enregistrement est ici la même sur le <strong>client</strong> et sur le <strong>serveur</strong>. Il vous suffit de changer le nom d'hôte pour qu'il corresponde à celui de l'hôte sur lequel vous exécutez la commande d'enregistrement.</p>\n\n<p>Tout d'abord, activez le référentiel <code>universe</code> d'Ubuntu car l'utilitaire <code>certbot</code> réside dans le référentiel <code>universe</code>. Si vous avez déjà activé le dépôt <code>universe</code>, l'exécution de ces commandes ne fera rien à votre système et vous pourrez les exécuter en toute sécurité :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install software-properties-common\n</li><li class=\"line\" data-prefix=\"$\">sudo add-apt-repository universe\n</li><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Ensuite, installez <code>certbot</code> sur les deux hôtes :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install certbot\n</li></ul></code></pre>\n<p>Maintenant que vous avez installé <code>certbot</code>, exécutez la commande suivante pour enregistrer les certificats sur le <strong>client</strong> et le <strong>serveur</strong> :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot certonly --standalone --agree-tos --email <span class=\"highlight\">sammy@your_domain</span> -d <span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Les options de cette commande signifient ce qui suit :</p>\n\n<ul>\n<li><code>certonly</code> : enregistrer le certificat et ne faire aucune autre modification dans le système.</li>\n<li>-<code>--standalone</code> : utiliser le serveur web intégré de certbot pour vérifier la demande de certificat.</li>\n<li><code>--agree-tos</code> : accepter automatiquement les conditions d'utilisation du service Let&rsquo;s Encrypt.</li>\n<li><code>--email <span class=\"highlight\">your_email</span></code> : il s'agit de l'adresse électronique que Let&rsquo;s Encrypt utilisera pour vous informer de l'expiration du certificat et d'autres informations importantes.</li>\n<li><code>-d <span class=\"highlight\">your_domain</span></code> : le nom d'hôte pour lequel le certificat sera enregistré. Il doit correspondre au système dans lequel vous l'exécutez.</li>\n</ul>\n\n<p>Lorsque vous exécutez cette commande, il vous sera demandé si vous souhaitez partager l'adresse électronique avec Let&rsquo;s Encrypt afin qu'ils puissent vous envoyer des bulletins d'actualités et d'autres informations sur leur travail. Cette opération est facultative. Si vous ne communiquez pas votre adresse électronique, l'enregistrement du certificat se déroulera quand même normalement.</p>\n\n<p>Lorsque le processus d'enregistrement du certificat sera terminé, il placera le certificat et les fichiers clés dans <code>/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/</code> où <code>your_domain</code> est le nom d'hôte pour lequel vous avez enregistré le certificat.</p>\n\n<p>Enfin, vous devez télécharger une copie de l'AC de Let&rsquo;s Encrypt et des certificats intermédiaires, puis les placer dans le même fichier. <code>journald</code> utilisera ce fichier pour vérifier l'authenticité des certificats sur le <strong>client</strong> et <strong>le serveur</strong> lorsqu'ils communiquent entre eux.</p>\n\n<p>La commande suivante permet de télécharger les deux certificats sur le site web Let&rsquo;s Encrypt et de les placer dans un seul fichier appelé <code>letsencrypt-combined-certs.pem</code> dans le répertoire personnel de votre utilisateur.</p>\n\n<p>Exécutez cette commande sur le <strong>client</strong> et le <strong>serveur</strong> pour télécharger les certificats et créer le fichier combiné :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -s https://letsencrypt.org/certs/{isrgrootx1.pem.txt,letsencryptauthorityx3.pem.txt} &gt; ~/letsencrypt-combined-certs.pem\n</li></ul></code></pre>\n<p>Ensuite, déplacez ce fichier dans le répertoire Let&rsquo;s Encrypt contenant les certificats et les clés :</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp ~/letsencrypt-combined-certs.pem /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/\n</li></ul></code></pre>\n<p>Vous avez maintenant enregistré les certificats et les clés. Dans l'étape suivante, vous configurerez le <strong>serveur</strong> de collecte de journaux pour qu'il commence à écouter et à stocker les messages des journaux du <strong>client</strong>.</p>\n\n<h2 id=\"Étape-3-—-configuration-du-serveur\">Étape 3 — Configuration du serveur</h2>\n\n<p>Au cours de cette étape, vous configurerez le <strong>serveur</strong> pour qu'il utilise les fichiers de certificats et de clés que vous avez générés à la dernière étape afin qu'il puisse commencer à accepter les messages de journal du <strong>client</strong>.</p>\n\n<p><code>systemd-journal-remote</code> est le composant qui écoute les messages de journal. Ouvrez son fichier de configuration à l'adresse <code>/etc/systemd/journal-remote.conf</code> avec un éditeur de texte pour commencer à le configurer sur le <strong>serveur</strong> :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-remote.conf\n</li></ul></code></pre>\n<p>Ensuite, décommentez toutes les lignes sous la section <code>[Remote]</code> et définissez les chemins d'accès aux fichiers TLS que vous venez de créer :</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-remote.conf\">/etc/systemd/journal-remote.conf</div><pre class=\"code-pre \"><code>[Remote]\nSeal=false\nSplitMode=host\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Voici les options que vous avez utilisées ici :</p>\n\n<ul>\n<li><code>Seal=false</code> : signer les données du journal dans le journal. Activez cette option si vous avez besoin d'une sécurité maximale ; sinon, vous pouvez la laisser comme <code>false</code>.</li>\n<li><code>SplitMode=host</code> : les journaux des clients distants seront répartis par hôte dans <code>/var/log/journal/remote</code>. Si vous préférez que tous les journaux soient ajoutés dans un seul fichier, réglez celui-ci sur <code>SplitMode=false</code>.</li>\n<li><code>ServerKeyFile</code> : le fichier de clé privée du serveur.</li>\n<li><code>ServerCertificateFile</code>: le fichier de certificat du serveur.</li>\n<li><code>TrustedCertificateFile</code>: le fichier contenant les certificats AC Let&rsquo;s Encrypt.</li>\n</ul>\n\n<p>Maintenant, vous devez modifier les autorisations sur les répertoires de Let&rsquo;s Encrypt qui contiennent les certificats et la clé afin que le <code>systemd-journal-remote</code> puisse les lire et les utiliser.</p>\n\n<p>Tout d'abord, modifiez les <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-permissions\">autorisations</a> afin que le certificat et la clé privée soient lisibles :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Ensuite, changez la propriété du groupe de la clé privée pour celle du groupe de <code>systemd-journal-remote</code> :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-remote /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Vous pouvez maintenant lancer <code>systemd-journal-remote</code> :</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start systemd-journal-remote.service\n</li></ul></code></pre>\n<p>Votre <strong>serveur</strong> de collecte de journaux est maintenant en cours d'exécution et prêt à commencer à accepter les messages de journaux d'un <strong>client</strong>. Dans l'étape suivante, vous configurerez le <strong>client</strong> pour qu'il transmette les journaux à votre <strong>serveur</strong> de collecte.</p>\n\n<h2 id=\"Étape-4-—-configuration-du-client\">Étape 4 — Configuration du client</h2>\n\n<p>Au cours de cette étape, vous configurerez le composant qui relaie les messages du journal au serveur de collecte des journaux. Ce composant s'appelle <code>systemd-journal-upload</code>.</p>\n\n<p>La configuration par défaut de <code>systemd-journal-upload</code> fait qu'il a recours à un utilisateur temporaire qui n'existe que pendant le déroulement du processus. Il est donc plus compliqué d'autoriser <code>systemd-journal-upload</code> à lire les certificats et les clés TLS. Pour résoudre ce problème, vous créerez un nouvel utilisateur système portant le même nom que l'utilisateur temporaire qui sera utilisé à sa place.</p>\n\n<p>Tout d'abord, créez le nouvel utilisateur appelé <code>systemd-journal-upload</code> sur le <strong>client</strong> avec la commande <code>adduser</code> suivante :</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo adduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload\n</li></ul></code></pre>\n<p>Ces options de commande sont :</p>\n\n<ul>\n<li><code>--system</code> : créer le nouvel utilisateur en tant qu'utilisateur système. Elle donne à l'utilisateur un numéro UID (User Identifier) inférieur à <code>1000</code>. Les UID de plus de <code>1 000</code> sont généralement attribués à des comptes utilisateurs avec lesquels un humain se connectera.</li>\n<li><code>--home /run/systemd</code> : définir <code>/run/systemd</code> comme le répertoire d'origine de cet utilisateur.</li>\n<li><code>--no-create-home</code> : ne pas créer le répertoire d'origine, car il existe déjà.</li>\n<li><code>--disabled-login</code> : l'utilisateur ne peut pas se connecter au serveur (via SSH, par exemple).</li>\n<li><code>--group</code> : créer un groupe portant le même nom que l'utilisateur.</li>\n</ul>\n\n<p>Ensuite, définissez les autorisations et la propriété des fichiers de certificat Let&rsquo;s Encrypt :</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-upload /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Maintenant, modifiez la configuration pour <code>systemd-journal-upload</code>, qui se trouve dans <code>/etc/systemd/journal-upload.conf</code>. Ouvrez ce fichier avec un éditeur de texte :</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-upload.conf\n</li></ul></code></pre>\n<p>Modifiez ce fichier de manière à ce qu'il ressemble à ce qui suit :</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-upload.conf\">/etc/systemd/journal-upload.conf</div><pre class=\"code-pre \"><code>[Upload]\nURL=https://<span class=\"highlight\">server.your_domain</span>:19532\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Enfin, redémarrez le service <code>systemd-journal-upload</code> afin qu'il utilise la nouvelle configuration :</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Votre <strong>client</strong> est maintenant configuré, en cours d'exécution et envoie ses messages au serveur de collecte de journaux. Dans l'étape suivante, vous vérifierez que les journaux sont correctement envoyés et enregistrés.</p>\n\n<h2 id=\"Étape-5-—-test-du-client-et-du-serveur\">Étape 5 — Test du client et du serveur</h2>\n\n<p>Au cours de cette étape, vous vérifierez que le <strong>client</strong> relaie les messages de journaux au <strong>serveur</strong> et que le <strong>serveur</strong> les stocke correctement.</p>\n\n<p>Le serveur de collecte des journaux stocke les journaux des clients dans le répertoire <code>/var/log/journal/remote/</code>. Lorsque vous avez redémarré le <strong>client</strong> à la fin de la dernière étape, il a commencé à envoyer des messages de journaux ; il y a donc maintenant un fichier journal dans <code>/var/log/journal/remote/</code>. Le fichier sera nommé d'après le nom d'hôte que vous avez utilisé pour le certificat TLS.</p>\n\n<p>Utilisez la commande <code>ls</code> pour vérifier que le fichier journal du <strong>client</strong> est présent sur le <strong>serveur</strong> :</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ls -la /var/log/journal/remote/\n</li></ul></code></pre>\n<p>Cela permet d'imprimer le contenu du répertoire contenant le fichier journal :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>total 16620\ndrwxr-xr-x  2 systemd-journal-remote systemd-journal-remote     4096 Jun 30 16:17  .\ndrwxr-sr-x+ 4 root                   systemd-journal            4096 Jun 30 15:55  ..\n-rw-r-----  1 systemd-journal-remote systemd-journal-remote 8388608 Jul  1 10:46 '<span class=\"highlight\">remote-CN=client.your_domain</span>'\n</code></pre>\n<p>Ensuite, écrivez un message de journal sur le <strong>client</strong> pour vérifier que le <strong>serveur</strong> reçoit les messages du <strong>client</strong> comme prévu. Vous utiliserez l'utilitaire <a href=\"https://man7.org/linux/man-pages/man1/logger.1.html\">logger</a> pour créer un message de journal personnalisé sur le <strong>client</strong>. Si tout fonctionne correctement, <code>systemd-journal-upload</code> transmettra ce message au <strong>serveur</strong>.</p>\n\n<p>Sur le <strong>client</strong>, exécutez la commande <code>logger</code> suivante :</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo logger -p syslog.debug \"### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\"\n</li></ul></code></pre>\n<p>Le <code>-p syslog.debug</code> de cette commande définit la <a href=\"https://en.wikipedia.org/wiki/Syslog#Message_components\">facilité et la gravité</a> du message. Si vous réglez ce paramètre sur <code>syslog.debug</code>, vous verrez qu'il s'agit d'un message de test. Cette commande enregistre le message <code>### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###</code> dans le journal du client, que <code>systemd-journal-upload</code> transfère au <strong>serveur</strong>.</p>\n\n<p>Ensuite, lisez le fichier journal du <strong>client</strong> sur le <strong>serveur</strong> pour vérifier que les messages du journaux arrivent bien en provenance du <strong>client</strong>. Ce fichier est un fichier journal binaire, vous ne pourrez donc pas le lire avec des outils comme <code>less</code>. Lisez plutôt le fichier en utilisant <code>journalctl</code> avec l'option <code>--file=</code> qui vous permet de spécifier un fichier journal personnalisé :</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo journalctl --file=/var/log/journal/remote/remote-CN=<span class=\"highlight\">client.your_domain.journal</span>\n</li></ul></code></pre>\n<p>Le message du journal apparaîtra comme suit :</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Test log message\">Test log message</div>. . .\nJun 29 13:10:09 client root[3576]: ### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\n</code></pre>\n<p>Votre serveur de centralisation des journaux recueille maintenant avec succès les journaux de votre système client.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans cet article, vous avez mis en place un serveur central de collecte de journaux et configuré un client pour qu'il transmette une copie de ses journaux système au serveur. Vous pouvez configurer autant de clients que nécessaire pour relayer les messages au serveur de collecte de journaux en exécutant les étapes de configuration des clients que vous avez réalisées ici.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:53 +0000","feedId":8037,"bgimg":"","linkMd5":"deca7f753741b842e06ca470752f88ca","bgimgJsdelivr":"","metaImg":"","author":"Elliot Cooper","publishedOrCreatedDate":1598860106983},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment construire un bot Discord avec Node.js","link":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","description":"<p><em>L'auteur a choisi le <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> comme récipiendaire d'un don dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p><a href=\"https://discord.com/\">Discord</a> est une application de chat qui permet à des millions d'utilisateurs à travers le monde d'échanger des messages et de s'appeler en ligne au sein de communautés appelées <a href=\"https://discord.com/developers/docs/resources/guild\">guildes</a> ou serveurs. Discord fournit également une API complète que les développeurs peuvent utiliser pour créer de puissants bots Discord. Les bots peuvent effectuer diverses actions telles que l'envoi de messages aux serveurs, le DM-ing des utilisateurs, la modération des serveurs et la lecture audio dans les chats vocaux. Cela permet aux développeurs de créer des bots puissants qui comprennent des fonctionnalités avancées et complexes comme des outils de modération ou même des jeux. Par exemple, le bot utilitaire <a href=\"https://dyno.gg/bot\">Dyno</a> sert des millions de guildes et contient des fonctions utiles telles que la protection contre le spam, un lecteur de musique et d'autres fonctions utilitaires. Apprendre à créer des bots Discord vous permet d'implémenter de nombreuses choses, avec lesquelles des milliers de personnes pourront interagir chaque jour.</p>\n\n<p>Dans ce tutoriel, vous allez construire un bot Discord à partir de zéro, en utilisant <a href=\"https://nodejs.org/en/\">Node.js</a> et la bibliothèque <a href=\"https://discord.js.org/#/\">Discord.js</a>, qui permet aux utilisateurs d'interagir directement avec l'API Discord. Vous allez créer un profil pour un bot Discord, obtenir des jetons d'authentification pour le bot, et programmer le bot pour lui donner la capacité de traiter les commandes des utilisateurs avec des arguments.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<p>Avant de commencer, vous aurez besoin des éléments suivants :</p>\n\n<ul>\n<li><p>Node.js installé sur votre machine de développement. Pour l'installer sur macOS ou Ubuntu 18.04, suivez les étapes du tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">Comment installer Node.js et créer un environnement de développement local sur macOS</a> ou la section <strong>Installation à l'aide d'un PPA</strong> du tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">Comment installer Node.js sur Ubuntu 18.04</a>.</p></li>\n<li><p>Tout éditeur de texte de votre choix, tel que <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>, <a href=\"https://atom.io\">Atom</a>, <a href=\"https://www.sublimetext.com/\">Sublime</a> ou <a href=\"https://www.nano-editor.org/\">Nano</a>.</p></li>\n<li><p>Un <a href=\"https://discord.com/register\">compte Discord gratuit</a> avec un compte de courrier électronique vérifié et un <a href=\"https://support.discord.com/hc/en-us/articles/204849977-How-do-I-create-a-server-\">serveur Discord gratuit</a> que vous utiliserez pour tester votre bot Discord.</p></li>\n</ul>\n\n<h2 id=\"Étape-1-—-configuration-d-39-un-bot-discord\">Étape 1 — Configuration d'un bot Discord</h2>\n\n<p>Au cours de cette étape, vous utiliserez l'interface graphique des développeurs Discord pour mettre en place un bot Discord et obtenir le jeton du bot, que vous passerez dans votre programme.</p>\n\n<p>Pour enregistrer un bot sur la plate-forme Discord, utilisez le <a href=\"https://discord.com/developers/applications/\">tableau de bord de l'application Discord</a>. Les développeurs peuvent y créer des applications Discord, y compris des bots Discord.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png\" alt=\"Image du tableau de bord de l'application Discord après une première visite sur https://discord.com/developers/applications\"></p>\n\n<p>Pour commencer, cliquez sur  <strong>New Application</strong> (Nouvelle Application). Discord vous demandera d'entrer un nom pour votre nouvelle application. Cliquez ensuite sur <strong>Create</strong> (Créer) pour créer l'application.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1b.png\" alt=\"Image de l'invite à créer une application, avec &quot;Test Node.js Bot&quot; saisi comme nom de l'application\"></p>\n\n<p><span class='note'><strong>Note :</strong> le nom de votre application est indépendant du nom du bot, et le bot n'a pas besoin d'avoir le même nom que l'application.<br></span></p>\n\n<p>Ouvrez maintenant le tableau de bord de votre application. Pour ajouter un bot à l'application, naviguez dans l'onglet <strong>Bot</strong> de la barre de navigation, à gauche.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1c.png\" alt=\"Image de l'onglet bot du tableau de bord de l'application\"></p>\n\n<p>Cliquez sur le bouton <strong>Add Bot</strong> (Ajouter un Bot) pour ajouter un bot à l'application. Cliquez sur le bouton <strong>Yes, do it!</strong> (C'est parti !) lorsqu'il vous demande une confirmation. Vous vous retrouverez alors sur un tableau de bord contenant les détails du nom de votre bot, son jeton d'authentification et sa photo de profil.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1d.png\" alt=\"Tableau de bord contenant les détails de votre bot\"></p>\n\n<p>Vous pouvez modifier le nom ou la photo de profil de votre bot ici, sur le tableau de bord. Vous devez également copier le jeton d'authentification du bot en cliquant sur <strong>Click to Reveal Token</strong> (Cliquer pour révéler le jeton) et en copiant le jeton qui apparaît.</p>\n\n<p><span class='warning'><strong>Warning :</strong> ne partagez pas, ne téléchargez pas votre jeton de bot, car il permet à n'importe qui de se connecter à votre bot.<br></span></p>\n\n<p>Vous devez maintenant créer une invitation qui vous permette d'ajouter les guildes Discord de bots où vous pouvez tester le robot. Tout d'abord, naviguez vers l'onglet <strong>OAuth2</strong> du tableau de bord de l'application. Pour créer une invitation, faites défiler l'écran vers le bas et sélectionnez <strong>bot</strong> sous <strong>scopes</strong>. Vous devez également définir des autorisations pour contrôler les actions que votre bot peut effectuer dans les guildes. Pour les besoins de ce tutoriel, sélectionnez <strong>Administrator</strong> (Administrateur), ce qui donnera à votre bot la permission d'effectuer presque toutes les actions dans les guildes. Copiez le lien à l'aide du bouton <strong>Copy</strong> (Copier).</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1e.png\" alt='Onglet OAuth2, avec scope définie sur \"bot\" et autorisations définies sur \"administator\".'></p>\n\n<p>Ensuite, ajoutez le bot à un serveur. Suivez le lien d'invitation que vous venez de créer. Vous pouvez ajouter le bot à n'importe lequel des serveurs que vous possédez, ou pour lequel vous avez des autorisations d'administrateur, à partir du menu déroulant.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1f.png\" alt=\"Page suivant le lien d'invitation, permettant aux utilisateurs d'ajouter le bot aux serveurs\"></p>\n\n<p>Cliquez maintenant sur** Continue** (Continuer). Vérifiez que vous avez coché la case située à côté de <strong>Administrator</strong> - cela donnera au bot des autorisations d'administrateur. Ensuite, cliquez sur <strong>Authorize</strong> (Autoriser). Discord vous demandera de résoudre un <a href=\"https://en.wikipedia.org/wiki/CAPTCHA\">CAPTCHA</a> avant que le bot ne rejoigne le serveur. Votre bot Discord se trouvera désormais sur la liste des membres du serveur à laquelle vous l'avez ajouté, sous <strong>offline</strong>.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step1g.png\" alt=\"Liste des membres d'un serveur Discord avec le bot nouvellement créé sous la section &quot;offline&quot; de la liste des membres\"></p>\n\n<p>Vous avez créé avec succès un robot Discord et l'avez ajouté à un serveur. Ensuite, vous allez écrire un programme pour vous connecter au bot.</p>\n\n<h2 id=\"Étape-2-—-création-de-votre-projet\">Étape 2 — Création de votre projet</h2>\n\n<p>Au cours de cette étape, vous allez configurer l'environnement de codage de base dans lequel vous allez construire votre bot et vous connecter au bot par programmation.</p>\n\n<p>Tout d'abord, vous devez créer un dossier de projet et les fichiers de projet nécessaires pour le bot.</p>\n\n<p>Créez votre dossier de projet :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Rendez-vous dans le dossier de projet que vous venez de créer :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd <span class=\"highlight\">discord-bot</span>\n</li></ul></code></pre>\n<p>Ensuite, utilisez votre éditeur de texte pour créer un fichier nommé <code>config.json</code>, afin de stocker le jeton d'authentification de votre bot :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano config.json\n</li></ul></code></pre>\n<p>Ajoutez ensuite le code suivant au fichier de configuration, en remplaçant le texte surligné par le jeton d'authentification de votre bot :</p>\n<div class=\"code-label \" title=\"config.json\">config.json</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">{\n    \"BOT_TOKEN\": \"<span class=\"highlight\">YOUR BOT TOKEN</span>\"\n}\n</code></pre>\n<p>Enregistrez et quittez le fichier.</p>\n\n<p>Ensuite, vous créerez un fichier <code>package.json</code>, qui stockera les détails de votre projet et des informations sur les dépendances que vous utiliserez pour le projet. Vous allez créer un fichier <code>package.json</code> en exécutant la commande <code>npm</code> suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm init\n</li></ul></code></pre>\n<p><code>npm</code> vous demandera différentes informations sur votre projet. Si vous souhaitez obtenir des conseils sur la manière de remplir ces invites, vous trouverez plus d'informations dans la section <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-node-js-modules-with-npm-and-package-json#step-1-%E2%80%94-creating-a-packagejson-file\">Comment utiliser les modules Node.js avec npm et package.json</a>.</p>\n\n<p>Vous allez maintenant installer le paquet <code>discord.js</code> que vous utiliserez pour interagir avec l'API Discord. Vous pouvez installer <code>discord.js</code> par le biais de npm avec la commande suivante :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">npm install discord.js\n</li></ul></code></pre>\n<p>Maintenant que vous avez configuré le fichier de configuration et installé la dépendance nécessaire, vous êtes prêt à commencer à construire votre bot. Dans une application réelle, un gros bot serait réparti sur plusieurs fichiers, mais pour les besoins de ce tutoriel, le code de votre bot se trouvera dans un seul fichier.</p>\n\n<p>Tout d'abord, créez un fichier nommé <code>index.js</code> dans le dossier <code><span class=\"highlight\">discord-bot</span></code> pour le code :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Commencez à coder le bot en demandant la dépendance <code>discord.js</code> et le fichier de configuration avec le jeton du bot :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n</code></pre>\n<p>Ensuite, ajoutez les deux lignes de code suivantes :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Enregistrez et fermez votre fichier</p>\n\n<p>La première ligne de code crée un nouveau <code>Discord.Client</code> et l'attribue au <code>client</code> constant. Ce client permet en partie d'interagir avec l'API Discord et de vous informer des événements tels que l'arrivée de nouveaux messages. Le client, en effet, représente le bot Discord.</p>\n\n<p>La deuxième ligne de code utilise la méthode <code>login</code> sur le <code>client</code> pour se connecter au bot Discord que vous avez créé, en utilisant le jeton du fichier <code>config.json</code> comme mot de passe. Le jeton permet à l'API Discord de savoir à quel bot le programme est destiné et que vous avez été authentifié pour utiliser le bot.</p>\n\n<p>Maintenant, exécutez le fichier <code>index.js</code> en utilisant Node :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Le statut de votre bot passera à online (en ligne) dans le serveur Discord auquel vous l'avez ajouté.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step2a.png\" alt=\"Image du bot en ligne\"></p>\n\n<p>Vous avez configuré avec succès un environnement de codage et créé le code de base pour vous connecter à un bot Discord. Dans l'étape suivante, vous allez gérer les commandes utilisateur et demander à votre bot d'effectuer des actions, comme l'envoi de messages.</p>\n\n<h2 id=\"Étape-3-—-traitement-de-votre-première-commande-utilisateur\">Étape 3 — Traitement de votre première commande utilisateur</h2>\n\n<p>Dans cette étape, vous allez créer un bot qui peut gérer les commandes de l'utilisateur. Vous commencerez par configurer votre première commande <code>ping</code>, qui répondra par <code>\"pong\"</code> et indiquera le temps nécessaire pour répondre à la commande.</p>\n\n<p>Tout d'abord, vous devez détecter et recevoir tout message envoyé par les utilisateurs afin de pouvoir traiter toute commande. En utilisant la méthode <code>on</code> sur le client Discord, Discord vous enverra une notification sur les nouveaux événements. La méthode <code>on</code> prend deux arguments : le nom d'un événement à attendre et une fonction à exécuter chaque fois que cet événement se produit. Avec cette méthode, vous pouvez attendre le <code>message</code> de l'événement - cela se produit chaque fois qu'un message est envoyé à une guilde où le bot a la permission de voir les messages. C'est pourquoi nous allons créer une fonction, qui s'exécute à chaque fois qu'un message est envoyé, pour traiter les commandes.</p>\n\n<p>Tout d'abord, ouvrez votre fichier :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Ajoutez le code suivant à votre fichier :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nconst client = new Discord.Client();\n\n\n<span class=\"highlight\">client.on(\"message\", function(message) { </span>\n<span class=\"highlight\">                                         </span>\n<span class=\"highlight\">});                                      </span>\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Cette fonction, qui s'exécute sur l'événement <code>message</code>, prend <code>message</code> comme paramètre. <code>message</code> aura la valeur d'une instance de <a href=\"https://discord.js.org/#/docs/main/stable/class/Message\">message Discord.js</a>, qui contient des informations sur le message envoyé et des méthodes pour aider le bot à répondre.</p>\n\n<p>Ajoutez maintenant la ligne de code suivante à votre fonction de traitement des commandes :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  <span class=\"highlight\">if (message.author.bot) return;</span>\n});\n...\n</code></pre>\n<p>Cette ligne vérifie si l'auteur du message est un bot, et si c'est le cas, arrête le traitement de la commande. C'est important car, en général, vous ne voulez pas traiter les messages des bots ou y répondre. Les bots n'ont généralement pas besoin ou ne veulent pas utiliser notre bot. Ignorer leurs messages permet donc d'économiser de la puissance de traitement et d'éviter les réponses accidentelles.</p>\n\n<p>Maintenant vous allez écrire un gestionnaire de commandes. Pour ce faire, il est bon de comprendre le format habituel d'une commande Discord. En général, la structure d'une commande Discord contient trois parties dans l'ordre suivant : un préfixe, un nom de commande et (parfois) des arguments de commande.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png\" alt=\"Une image d'une commande Discord indiquant &quot;! add12&quot;\"></p>\n\n<ul>\n<li><p>Préfixe : le préfixe peut être de toute nature, mais il s'agit généralement d'un morceau de ponctuation ou d'une phrase abstraite qui ne se trouverait normalement pas au début d'un message. Cela signifie que lorsque vous incluez le préfixe au début du message, le bot saura que l'intention de cette commande est qu'un bot la traite.</p></li>\n<li><p>Nom de la commande : le nom de la commande que l'utilisateur veut utiliser. Cela signifie que le bot peut prendre en charge plusieurs commandes avec des fonctionnalités différentes et permettre aux utilisateurs de choisir entre elles en fournissant un nom de commande différent.</p></li>\n<li><p>Arguments : parfois, si la commande nécessite ou utilise des informations supplémentaires de la part de l'utilisateur, celui-ci peut fournir des arguments après le nom de la commande, chaque argument étant séparé par un espace.</p></li>\n</ul>\n\n<p><span class='note'><strong>Note :</strong> ll n'y a pas de structure de commandes imposée et les bots peuvent traiter les commandes comme ils le souhaitent, mais la structure présentée ici est une structure efficace, que la grande majorité des bots utilise.<br></span></p>\n\n<p>Pour commencer à créer un analyseur de commandes qui gère ce format, ajoutez les lignes de code suivantes à la fonction de traitement des messages :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n<span class=\"highlight\">const prefix = \"!\";</span>\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  <span class=\"highlight\">if (!message.content.startsWith(prefix)) return;</span>\n});\n...\n</code></pre>\n<p>Vous ajoutez la première ligne de code pour attribuer la valeur <code>\"!\"</code> au <code>prefix</code> de la constante, que vous utiliserez comme préfixe du bot.</p>\n\n<p>La deuxième ligne de code que vous ajoutez vérifie si le contenu du message que le bot traite commence par le préfixe que vous avez défini, et si ce n'est pas le cas, elle empêche la poursuite du traitement du message.</p>\n\n<p>Vous devez maintenant convertir le reste du message en un nom de commande et en arguments qui peuvent exister dans le message. Ajoutez les lignes surlignées suivantes :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  <span class=\"highlight\">const commandBody = message.content.slice(prefix.length);</span>\n  <span class=\"highlight\">const args = commandBody.split(' ');</span>\n  <span class=\"highlight\">const command = args.shift().toLowerCase();</span>\n});\n...\n</code></pre>\n<p>Ici, vous utilisez la première ligne pour supprimer le préfixe du contenu du message et attribuer le résultat à la constante <code>commandBody</code>. Cette action est nécessaire, car vous ne voulez pas inclure le préfixe dans le nom de la commande analysée.</p>\n\n<p>La deuxième ligne prend le message dont le préfixe a été supprimé et utilise la <a href=\"https://www.digitalocean.com/community/tutorials/how-to-index-split-and-manipulate-strings-in-javascript#splitting-strings\">méthode <code>split</code></a>, avec une espace comme séparateur. Cette méthode entraîne la division du message en une série de sous-chaînes de caractères, ce qui fait qu'elle se divise partout où il y a un espace. Cela donne lieu à un tableau contenant le nom de la commande et les arguments, s'ils sont inclus dans le message. Vous assignez ce tableau à la constante <code>args</code>.</p>\n\n<p>La troisième ligne supprime le premier élément du tableau <code>args</code> (qui sera le nom de la commande fournie), le convertit en minuscules, puis l'affecte à la constante <code>command</code>. Cela vous permet d'isoler le nom de la commande et de ne laisser que les arguments dans le tableau. Vous utilisez également la méthode <code>toLowerCase</code> car les commandes sont généralement insensibles à la casse dans les bots Discord.</p>\n\n<p>Vous avez terminé la construction d'un analyseur de commandes, l'implémentation d'un préfixe requis et l'obtention du nom de la commande et des arguments des messages. Vous allez maintenant implémenter et créer le code pour les commandes spécifiques.</p>\n\n<p>Ajoutez le code suivant pour commencer à implémenter la commande <code>ping</code> :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  <span class=\"highlight\">if (command === \"ping\") {</span>\n  <span class=\"highlight\">                         </span>\n  <span class=\"highlight\">}                        </span>\n});\n...\n</code></pre>\n<p>Cet <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-conditional-statements-in-javascript\">énoncé <code>if</code></a> vérifie si le nom de commande que vous avez analysé (attribué à la constante <code>command</code>) correspond à <code>\"ping\"</code>. Si c'est le cas, cela indique que l'utilisateur veut utiliser la commande <code>\"ping\"</code>. Vous allez imbriquer le code de la commande spécifique à l'intérieur du bloc <code>if</code>. Vous allez répéter ce schéma pour les autres commandes que vous souhaitez implémenter.</p>\n\n<p>Maintenant, vous pouvez implémenter le code pour la commande <code>\"ping\"</code> :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    <span class=\"highlight\">const timeTaken = Date.now() - message.createdTimestamp;</span>\n    <span class=\"highlight\">message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);</span>\n  }\n...\n</code></pre>\n<p>Enregistrez et fermez votre fichier</p>\n\n<p>Vous ajoutez le bloc de commande <code>\"ping\"</code> qui calcule la différence entre l'heure actuelle - trouvée en utilisant la <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now\">méthode <code>now</code></a> sur l'objet <code>Date</code> - et l'heure de création du message en millisecondes. Cela permet de calculer le temps de traitement du message et le <code>\"ping\"</code> du bot.</p>\n\n<p>La deuxième ligne répond à la commande de l'utilisateur en utilisant la méthode <code>reply</code> sur la constante <code>message</code>. La <a href=\"https://discord.js.org/#/docs/main/stable/class/Message?scrollTo=reply\">méthode <code>reply</code></a> envoie un ping à l'utilisateur qui a invoqué la commande (ce qui avertit l'utilisateur et met en évidence le message pour l'utilisateur spécifié), suivi du contenu fourni comme premier argument de la méthode. Vous fournissez un <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">modèle littéral</a> contenant un message et le ping calculé comme réponse que la méthode <code>reply</code> utilisera.</p>\n\n<p>Ceci conclut l'implémentation de la commande <code>\"ping\"</code>.</p>\n\n<p>Exécutez votre bot en utilisant la commande suivante (dans le même dossier que <code>index.js</code>) :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Vous pouvez maintenant utiliser la commande <code>\"! ping\"</code> dans n'importe quel canal que le robot peut visualiser et dans lequel il peut envoyer un message, ce qui donne lieu à une réponse.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png\" alt='Image du bot répondant dans Discord à \"! ping\" avec \"@T0M, Pong! This message had a latency of 1128ms.\"'></p>\n\n<p>Vous avez créé avec succès un bot capable de gérer les commandes des utilisateurs et vous avez implémenté votre première commande. Dans l'étape suivante, vous continuerez à développer votre bot en implémentant une commande sum.</p>\n\n<h2 id=\"Étape-4-—-implémentation-de-la-commande-sum\">Étape 4 — Implémentation de la commande sum</h2>\n\n<p>Vous allez maintenant étendre votre programme en implémentant la commande <code>\"! sum\"</code>. La commande prendra un nombre quelconque d'arguments et les additionnera, avant de renvoyer la somme de tous les arguments à l'utilisateur.</p>\n\n<p>Si votre bot Discord fonctionne toujours, vous pouvez arrêter son processus avec <code>CTRL + C</code>.</p>\n\n<p>Ouvrez à nouveau votre fichier <code>index.js</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano index.js\n</li></ul></code></pre>\n<p>Pour commencer à implémenter la commande <code>\"!</code>sum&quot; vous utiliserez le bloc <code>else-if</code>. Après avoir vérifié le nom de la commande ping, il vérifiera si le nom de la commande est égal à <code>\"sum\"</code>. Nous utilisons un bloc &ldquo;<code>else-if</code>&rdquo; car une seule commande sera traitée à la fois, donc si le programme correspond au nom de commande <code>\"ping\"</code>, il n'a pas besoin de vérifier la commande <code>\"sum\"</code>. Ajoutez les lignes surlignées suivantes à votre fichier :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Ping! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  <span class=\"highlight\">else if (command === \"sum\") {</span>\n  <span class=\"highlight\">                             </span>\n  <span class=\"highlight\">}                            </span>\n});\n...\n</code></pre>\n<p>Vous pouvez commencer à implémenter le code pour la commande <code>\"sum\"</code>. Le code de la commande <code>\"sum\"</code> ira dans le bloc <code>else-if</code> que vous venez de créer. Maintenant, ajoutez le code suivant :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">...\n  else if (command === \"sum\") {\n    <span class=\"highlight\">const numArgs = args.map(x =&gt; parseFloat(x));</span>\n    <span class=\"highlight\">const sum = numArgs.reduce((counter, x) =&gt; counter += x);</span>\n    <span class=\"highlight\">message.reply(`The sum of all the arguments you provided is ${sum}!`);</span>\n  }\n...\n</code></pre>\n<p>Vous utilisez la <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#map()\">méthode <code>map</code></a> sur la liste des arguments pour créer une nouvelle liste en utilisant la fonction <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseFloat\"><code>parseFloat</code></a> sur chaque élément du tableau <code>args</code>. Cela crée un nouveau tableau (attribué à la constante <code>numArgs</code>) dans lequel tous les éléments sont des nombres au lieu de chaînes de caractères. Cela signifie que vous pouvez ensuite trouver la somme des nombres en les additionnant.</p>\n\n<p>La deuxième ligne utilise la <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-array-methods-in-javascript-iteration-methods#reduce()\">méthode <code>reduce</code></a> sur la constante <code>numArgs</code>, fournissant une fonction qui totalise tous les éléments de la liste. Vous attribuez la somme de tous les éléments de <code>numArgs</code> à la constante <code>sum</code>.</p>\n\n<p>Vous utilisez ensuite la méthode <code>reply</code> sur l'objet du message pour répondre à la commande de l'utilisateur avec un <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">modèle littéral</a>, qui contient la somme de tous les arguments que l'utilisateur envoie au bot.</p>\n\n<p>Ceci conclut l'implémentation de la commande <code>\"sum\"</code>. Maintenant, exécutez le bot en utilisant la commande suivante (dans le même dossier que <code>index.js</code>) :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node index.js\n</li></ul></code></pre>\n<p>Vous pouvez maintenant utiliser la commande <code>\"! sum\"</code> dans n'importe quel canal que le bot peut visualiser et dans lequel il peut envoyer des messages.</p>\n\n<p><img src=\"https://assets.digitalocean.com/articles/node_discord_bot/step4a.png\" alt='Image du bot répondant \"The sum of all the arguments you provided is 6!\" à \"! sum 1 2 3\", puis répondant \"The sum of all the arguments you provided is 13! à \"! sum 1.5 1.5 10\"'></p>\n\n<p>Ce qui suit est une version complète du script du bot <code>index.js</code> :</p>\n<div class=\"code-label \" title=\"index.js\">index.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-js\">const Discord = require(\"discord.js\");\nconst config = require(\"./config.json\");\n\nconst client = new Discord.Client();\n\nconst prefix = \"!\";\n\nclient.on(\"message\", function(message) {\n  if (message.author.bot) return;\n  if (!message.content.startsWith(prefix)) return;\n\n  const commandBody = message.content.slice(prefix.length);\n  const args = commandBody.split(' ');\n  const command = args.shift().toLowerCase();\n\n  if (command === \"ping\") {\n    const timeTaken = Date.now() - message.createdTimestamp;\n    message.reply(`Pong! This message had a latency of ${timeTaken}ms.`);\n  }\n\n  else if (command === \"sum\") {\n    const numArgs = args.map(x =&gt; parseFloat(x));\n    const sum = numArgs.reduce((counter, x) =&gt; counter += x);\n    message.reply(`The sum of all the arguments you provided is ${sum}!`);\n  }\n});\n\nclient.login(config.BOT_TOKEN);\n</code></pre>\n<p>Au cours de cette étape, vous avez développé votre bot Discord en implémentant la commande <code>sum</code>.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Vous avez implémenté avec succès un bot Discord qui peut gérer plusieurs commandes utilisateur et arguments différents. Si vous souhaitez développer votre bot, vous pouvez implémenter plus de commandes ou essayer d'autres parties de l'API Discord pour créer un puissant bot Discord. Vous pouvez consulter la <a href=\"https://discord.js.org/#/docs/main/stable/general/welcome\">documentation de Discord.js</a> ou <a href=\"https://discord.com/developers/docs/intro\">celle de l'API Discord</a> pour approfondir vos connaissances de l'API Discord.</p>\n\n<p>Lorsque vous créez des bots Discord, vous devez toujours garder à l'esprit les <a href=\"https://discord.com/developers/docs/legal\">conditions d'utilisation de l'API Discord</a>, qui décrivent comment les développeurs doivent utiliser l'API Discord. Vous pouvez également lire <a href=\"https://github.com/meew0/discord-bot-best-practices/blob/master/README.md\">cet ensemble de lignes directrices</a> qui indique la meilleure façon d'implémenter un bot Discord et fournit des conseils sur la façon de concevoir des bots Discord. Si vous souhaitez en savoir plus sur Node.js, consultez notre série <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">Comment coder en Node.js</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:43:28 +0000","feedId":8037,"bgimg":"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png","linkMd5":"c8d03d0d0deff79cc858db974957a275","bgimgJsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","destWidth":1920,"destHeight":973,"sourceBytes":66395,"destBytes":26384,"author":"Tom","articleImgCdnMap":{"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1b.png":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn9@2020_3/2020/08/31/07-48-31-275_690c64ccbc0c5170.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1c.png":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn30@2020_4/2020/08/31/07-48-31-778_f5a474e22c90438c.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1d.png":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_6/2020/08/31/07-48-31-392_d550c10707834d3f.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1e.png":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/31/07-48-31-921_817dcbabd0b27a3d.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1f.png":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn89@2020_2/2020/08/31/07-48-31-288_1d3824d3640df0a3.webp","https://assets.digitalocean.com/articles/node_discord_bot/step1g.png":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn77@2020_3/2020/08/31/07-48-31-225_5aca524b04a26500.webp","https://assets.digitalocean.com/articles/node_discord_bot/step2a.png":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn74@2020_2/2020/08/31/07-48-31-293_81968c3f6c9ff261.webp","https://assets.digitalocean.com/articles/node_discord_bot/step3a.png":null,"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png":"https://cdn.jsdelivr.net/gh/myreaderx/cdn98@2020_5/2020/08/31/07-48-33-506_74310bb53d7bafb2.webp","https://assets.digitalocean.com/articles/node_discord_bot/step4a.png":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn70@2020_4/2020/08/31/07-48-31-272_5589082ccebd5fbf.webp"},"publishedOrCreatedDate":1598860106985},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Comment lancer des processus enfants dans Node.js","link":"https://www.digitalocean.com/community/tutorials/how-to-launch-child-processes-in-node-js-fr","description":"<p><em>L'auteur a choisi le <a href=\"https://www.brightfunds.org/funds/write-for-donations-covid-19-relief-fund\">COVID-19 Relief Fund</a> pour recevoir un don dans le cadre du programme <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"introduction\">Introduction</h3>\n\n<p>Lorsqu'un utilisateur lance un programme <a href=\"https://nodejs.org/\">Node.js</a>, ce dernier s'exécute comme un seul système d'exploitation (OS) *<em>qui représente l'instance du programme en cours d'exécution. Dans le cadre de ce processus, Node.js exécute des programmes sur un seul thread. Comme mentionné plus haut dans cette série avec le tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-asynchronous-code-in-node-js#the-event-loop\">Comment écrire du code asynchrone dans Node.js</a>, car un seul thread peut fonctionner sur un seul processus, les opérations qui prennent du temps à s'exécuter dans <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-javascript\">JavaScript</a> peuvent bloquer le thread Node.js et retarder l'exécution d'un autre code. Une stratégie clé pour contourner ce problème consiste à lancer un *processus enfant</em>, ou un processus créé par un autre processus, lorsqu'il est confronté à des tâches de longue haleine. Lorsqu'un nouveau processus est lancé, le système d'exploitation peut utiliser des techniques de multitraitement pour s'assurer que le processus principal de Node.js et le processus enfant supplémentaire s'exécutent <em>simultanément</em> ou en même temps.</p>\n\n<p>Node.js comprend le <a href=\"https://nodejs.org/api/child_process.html#child_process_child_process\">module <code>child_process</code></a> qui dispose de fonctions pour créer de nouveaux processus. En plus de traiter les tâches de longue haleine, ce module peut également s'interfacer avec l'OS et exécuter des commandes <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-the-linux-terminal#the-shell\">shell</a>. Les administrateurs système peuvent utiliser Node.js pour exécuter les commandes shell pour structurer et maintenir leurs opérations en tant que <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-a-node-js-module\">module Node.js</a> au lieu de <a href=\"https://www.digitalocean.com/community/tutorial_series/an-introduction-to-shell-scripting\">scripts shell</a>.</p>\n\n<p>Dans ce tutoriel, vous allez créer des processus enfants tout en exécutant une série d'exemples d'applications Node.js. Vous allez créer des processus avec le module <code>child_process</code> en récupérant les résultats d'un processus enfant via un <a href=\"https://www.digitalocean.com/community/tutorials/using-buffers-in-node-js\">buffer</a> ou une chaîne avec la <a href=\"https://nodejs.org/api/child_process.html#child_process_child_process_exec_command_options_callback\">fonction <code>exec()</code></a>, puis à partir d'un flux de données avec la <a href=\"https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options\">fonction <code>spawn()</code></a>. Vous terminerez en utilisant <a href=\"https://nodejs.org/api/child_process.html#child_process_child_process_fork_modulepath_args_options\"><code>fork()</code></a> pour créer un processus enfant d'un autre programme Node.js avec lequel vous pouvez communiquer au moment où il s'exécute. Pour illustrer ces concepts, vous allez écrire un programme pour lister le contenu d'un répertoire, un programme pour trouver des fichiers et un serveur web avec plusieurs terminaux.</p>\n\n<h2 id=\"conditions-préalables\">Conditions préalables</h2>\n\n<ul>\n<li><p>Vous devez avoir installé Node.js pour que ces exemples puissent fonctionner. Ce tutoriel utilise la version 10.22.0. Pour l'installer sur macOS ou Ubuntu 18.04, suivez les étapes du tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-and-create-a-local-development-environment-on-macos\">Comment installer Node.js et créer un environnement de développement local sur macOS</a> ou la section <strong>Installation à l'aide d'un PPA</strong> du tutoriel <a href=\"https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04\">Comment installer Node.js sur Ubuntu 18.04</a>.</p></li>\n<li><p>Cet article utilise un exemple qui crée un serveur web afin d'expliquer comment fonctionne la fonction <code>fork()</code>. Pour vous familiariser avec la création de serveurs web, vous pouvez lire notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-a-web-server-in-node-js-with-the-http-module\">Comment créer un serveur web dans Node.js avec le module HTTP</a>.</p></li>\n</ul>\n\n<h2 id=\"Étape-1-création-d-39-un-processus-enfant-avec-exec\">Étape 1 - Création d'un processus enfant avec <code>exec()</code></h2>\n\n<p>Les développeurs créent généralement des processus enfants pour exécuter des commandes sur leur système d'exploitation lorsqu'ils ont besoin de manipuler la sortie de leurs programmes Node.js avec un shell, comme en utilisant le piping shell ou la redirection. La fonction <code>exec()</code> dans Node.js crée un nouveau processus shell et exécute une commande dans ce shell. La sortie de la commande est maintenue dans un buffer en mémoire, que vous pouvez accepter via une <a href=\"https://www.digitalocean.com/community/tutorials/how-to-write-asynchronous-code-in-node-js#asynchronous-programming-with-callbacks\">fonction de rappel</a> passée dans <code>exec()</code>.</p>\n\n<p>Commençons à créer nos premiers processus enfants dans Node.js. Tout d'abord, nous devons créer notre environnement de codage pour stocker les scripts que nous allons créer tout au long de ce tutoriel. Dans le terminal, créez un dossier appelé <code>child-processes</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">mkdir child-processes\n</li></ul></code></pre>\n<p>Entrez ce dossier dans le terminal avec la commande <code>cd</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">cd child-processes\n</li></ul></code></pre>\n<p>Créez un nouveau fichier appelé <code>listFiles.js</code> et ouvrez le fichier dans un éditeur de texte. Dans ce tutoriel, nous utiliserons <a href=\"https://www.nano-editor.org/\">nano</a>, un éditeur de texte de terminal :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano listFiles.js\n</li></ul></code></pre>\n<p>Nous allons écrire un module Node.js qui utilise la fonction <code>exec()</code> pour exécuter la commande <code>ls</code>. La commande <code>ls</code> liste les fichiers et les dossiers dans un répertoire. Ce programme prend la sortie de la commande <code>ls</code> et l'affiche à l'utilisateur.</p>\n\n<p>Dans l'éditeur de texte, ajoutez le code suivant :</p>\n<div class=\"code-label \" title=\"~/child-processes/listFiles.js\">~/child-processes/listFiles.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const { exec } = require('child_process');\n\nexec('ls -lh', (error, stdout, stderr) =&gt; {\n  if (error) {\n    console.error(`error: ${error.message}`);\n    return;\n  }\n\n  if (stderr) {\n    console.error(`stderr: ${stderr}`);\n    return;\n  }\n\n  console.log(`stdout:\\n${stdout}`);\n});\n</code></pre>\n<p>Nous importons d'abord la commande <code>exec()</code> du module <code>child_process</code>, en utilisant la <a href=\"https://www.digitalocean.com/community/tutorials/understanding-destructuring-rest-parameters-and-spread-syntax-in-javascript#destructuring\">déstructuration JavaScript</a>. Une fois importé, nous utilisons la fonction <code>exec()</code>. Le premier argument est la commande que nous aimerions exécuter. Dans ce cas, il s'agit de <code>ls -lh</code>, qui liste tous les fichiers et les dossiers dans le répertoire actuel en format long, avec une taille totale de fichier en unités lisibles par l'homme en tête de la sortie.</p>\n\n<p>Le deuxième argument est une fonction de rappel avec trois paramètres : <code>error</code>, <code>stdout</code>, et <code>stderr</code>. Si la commande ne s'exécute pas, <code>error</code> indiquera la raison de l'échec. Cela peut se produire si le shell ne peut pas trouver la commande que vous essayez d'exécuter. Si la commande est exécutée avec succès, toute donnée qu'elle écrit dans le <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-i-o-redirection#standard-output\">flux de sortie standard</a> est capturée dans <code>stdout</code>, et toute donnée qu'elle écrit dans le <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-i-o-redirection#standard-error\">flux d'erreurs standard</a> est capturée dans <code>stderr</code>.</p>\n\n<p><span class='note'><strong>Remarque :</strong> il est important de garder en tête la différence entre <code>error</code> et <code>stderr</code>. Si la commande elle-même ne s'exécute pas, <code>error</code> capturera l'erreur. Si la commande s'exécute mais renvoie la sortie dans le flux d'erreur, <code>stderr</code> la capturera. Les programmes Node.js les plus résilients traiteront toutes les sorties possibles d'un processus enfant.<br></span></p>\n\n<p>Dans notre fonction de rappel, nous vérifions d'abord si nous avons reçu une erreur. Si c'est le cas, nous affichons le <code>message</code> de l'erreur (une propriété de l'objet <code>Error</code>) avec <code>console.error()</code> et terminons la fonction avec <code>return</code>. Nous vérifions alors si la commande a imprimé un message d'erreur et <code>return</code> si c'est le cas. Si la commande s'exécute avec succès, nous enregistrons la sortie de la <a href=\"https://www.digitalocean.com/community/tutorials/how-to-use-the-javascript-developer-console\">console</a> avec <code>console.log()</code>.</p>\n\n<p>Exécutons ce fichier pour le voir en action. Tout d'abord, enregistrez et quittez <code>nano</code> en appuyant sur <code>CTRL+X</code>.</p>\n\n<p>De retour dans votre terminal, lancez votre application avec la commande <code>node</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node listFiles.js\n</li></ul></code></pre>\n<p>Votre terminal affichera la sortie suivante :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>stdout:\ntotal <span class=\"highlight\">4.0K</span>\n-rw-rw-r-- 1 <span class=\"highlight\">sammy</span> <span class=\"highlight\">sammy</span> 280 Jul 27 16:35 listFiles.js\n</code></pre>\n<p>Ceci liste le contenu du répertoire <code>child-processes</code> en format long, ainsi que la taille du contenu en haut. Vos résultats auront votre propre utilisateur et groupe à la place de <code>sammy</code>. Cela montre que le programme <code>listFiles.js</code> a exécuté avec succès la commande shell <code>ls -lh</code>.</p>\n\n<p>Voyons maintenant un autre moyen d'exécuter des processus concurrents. Le module <code>child_process</code> de Node.js peut également exécuter des fichiers exécutables avec la fonction <code>execFile()</code>. La différence essentielle entre les fonctions <code>execFile()</code> et <code>exec()</code> est que le premier argument <code>execFile()</code> est maintenant un chemin vers un fichier exécutable au lieu d'une commande. La sortie du fichier exécutable est stockée dans un buffer comme <code>exec()</code>, que nous accédons via une fonction de rappel avec les paramètres <code>error</code>, <code>stdout</code> et <code>stderr</code>.</p>\n\n<span class='note'><p>\n<strong>Remarque :</strong> les scripts dans Windows comme <code>.bat</code> et <code>.cmd</code> ne peuvent pas être exécutés avec <code>execFile()</code> car la fonction ne crée pas de shell lors de l'exécution du fichier. Sous Unix, Linux et macOS, les scripts exécutables n'ont pas toujours besoin d'un shell s'exécuter. Cependant, une machine Windows a besoin d'un shell pour exécuter des scripts. Pour exécuter des fichiers script sous Windows, utilisez <code>exec()</code>, puisqu'il crée un nouveau shell. Vous pouvez également utiliser <code>spawn()</code>, que vous utiliserez plus loin dans cette étape.</p>\n\n<p>Cependant, notez que vous pouvez exécuter avec succès des fichiers <code>.exe</code> dans Windows en utilisant <code>execFile()</code>. Cette limitation ne s'applique qu'aux fichiers script qui nécessitent un shell pour s'exécuter.<br></p></span>\n\n<p>Commençons par ajouter un script exécutable pour exécuter <code>execFile()</code>. Nous allons écrire un script <a href=\"https://www.gnu.org/software/bash/\">bash</a> qui téléchargera le <a href=\"https://nodejs.org/static/images/logos/nodejs-new-pantone-black.svg\">logo Node.js</a> du site Node.js et <a href=\"https://en.wikipedia.org/wiki/Base64\">Base64</a> l'encode pour convertir ses données en une chaîne de caractères <a href=\"https://en.wikipedia.org/wiki/ASCII\">ASCII</a>.</p>\n\n<p>Créez un nouveau fichier script shell appelé <code>processNodejsImage.sh</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano processNodejsImage.sh\n</li></ul></code></pre>\n<p>Écrivez maintenant un script pour télécharger l'image et base64 la convertit :</p>\n<div class=\"code-label \" title=\"~/child-processes/processNodejsImage.sh\">~/child-processes/processNodejsImage.sh</div><pre class=\"code-pre \"><code class=\"code-highlight language-bash\">#!/bin/bash\ncurl -s https://nodejs.org/static/images/logos/nodejs-new-pantone-black.svg &gt; nodejs-logo.svg\nbase64 nodejs-logo.svg\n</code></pre>\n<p>La première déclaration est une <em>déclaration shebang</em>. Elle est utilisée dans Unix, Linux et macOS lorsque nous voulons spécifier un shell pour exécuter notre script. La deuxième déclaration est une commande <code>curl</code>. L&rsquo;<a href=\"https://curl.haxx.se/\">utilitaire cURL</a>, dont la commande est <code>curl</code>, est un outil en ligne de commande qui peut transférer des données vers et en provenance d'un serveur. Nous utilisons cURL pour télécharger le logo Node.js du site web, et nous utilisons <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-i-o-redirection\">redirection</a> pour enregistrer les données téléchargées dans un nouveau fichier <code>nodejs-logo.svg</code>. La dernière déclaration utilise l'utilitaire <code>base64</code> pour encoder le fichier <code>nodejs-logo.svg</code> que nous avons téléchargé avec cURL. Le script envoie alors la chaîne encodée à la console.</p>\n\n<p>Enregistrez et quittez avant de continuer.</p>\n\n<p>Pour que notre programme Node exécute le script bash, nous devons le rendre exécutable. Pour ce faire, lancez ce qui suit :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">chmod u+x processNodejsImage.sh\n</li></ul></code></pre>\n<p>Cela donnera à votre utilisateur actuel la permission d'exécuter le fichier.</p>\n\n<p>Une fois notre script en place, nous pouvons écrire un nouveau module Node.js pour l'exécuter. Ce script utilisera <code>execFile()</code> pour exécuter le script dans un processus enfant, en détectant toute erreur et en affichant toute sortie sur la console.</p>\n\n<p>Sur votre terminal, créez un nouveau fichier JavaScript appelé <code>getNodejsImage.js</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano getNodejsImage.js\n</li></ul></code></pre>\n<p>Tapez le code suivant dans l'éditeur de texte :</p>\n<div class=\"code-label \" title=\"~/child-processes/getNodejsImage.js\">~/child-processes/getNodejsImage.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const { execFile } = require('child_process');\n\nexecFile(__dirname + '/processNodejsImage.sh', (error, stdout, stderr) =&gt; {\n  if (error) {\n    console.error(`error: ${error.message}`);\n    return;\n  }\n\n  if (stderr) {\n    console.error(`stderr: ${stderr}`);\n    return;\n  }\n\n  console.log(`stdout:\\n${stdout}`);\n});\n</code></pre>\n<p>Nous utilisons la déstructuration JavaScript pour importer la fonction <code>execFile()</code> du module <code>child_process</code>. Nous utilisons alors cette fonction, en passant le chemin du fichier comme prénom. <code>__dirname</code> contient le chemin du répertoire du module dans lequel il est écrit. Node.js fournit la variable <code>__dirname</code> à un module lorsque le module s'exécute. En utilisant <code>__dirname</code>, notre script trouvera toujours le fichier <code>processNodejsImage.sh</code> sur différents systèmes d'exploitation, quel que soit l'endroit où nous exécutons <code>getNodejsImage.js</code>. Notez que pour la configuration actuelle de notre projet, <code>getNodejsImage.js</code> et <code>processNodejsImage.sh</code> doivent se trouver dans le même dossier.</p>\n\n<p>Le deuxième argument est un rappel avec les paramètres <code>error</code>, <code>stdout</code>, et <code>stderr</code>. Comme avec notre exemple précédent qui a utilisé <code>exec()</code>, nous vérifions chaque sortie possible du fichier script et les enregistrons dans la console.</p>\n\n<p>Dans votre éditeur de texte, enregistrez ce fichier et quittez l'éditeur.</p>\n\n<p>Dans votre terminal, utilisez <code>node</code> pour exécuter le module:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node getNodejsImage.js\n</li></ul></code></pre>\n<p>L'exécution de ce script produira une sortie comme celle-ci :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>stdout:\nPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDQyLjQgMjcwLjkiPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYiIgeDE9IjE4MC43IiB5MT0iODAuNyIge\n...\n</code></pre>\n<p>Notez que nous avons tronqué la sortie dans cet article en raison de sa grande taille.</p>\n\n<p>Avant d'encoder l'image en base64, <code>processNodejsImage.sh</code> la télécharge. Vous pouvez également vérifier que vous avez téléchargé l'image en inspectant le répertoire actuel.</p>\n\n<p>Exécutez <code>listFiles.js</code> pour trouver la liste mise à jour des fichiers dans notre répertoire :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node listFiles.js\n</li></ul></code></pre>\n<p>Le script affichera un contenu similaire à celui qui suit sur le terminal :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>stdout:\ntotal <span class=\"highlight\">20</span>K\n-rw-rw-r-- 1 <span class=\"highlight\">sammy sammy</span>  316 Jul 27 17:56 getNodejsImage.js\n-rw-rw-r-- 1 <span class=\"highlight\">sammy sammy</span>  280 Jul 27 16:35 listFiles.js\n-rw-rw-r-- 1 <span class=\"highlight\">sammy sammy</span> 5.4K Jul 27 18:01 nodejs-logo.svg\n-rwxrw-r-- 1 <span class=\"highlight\">sammy sammy</span>  129 Jul 27 17:56 processNodejsImage.sh\n</code></pre>\n<p>Nous avons maintenant exécuté avec succès <code>processNodejsImage.sh</code> en tant que processus enfant dans Node.js en utilisant la fonction <code>execFile()</code>.</p>\n\n<p>Les fonctions <code>exec()</code> et <code>execFile()</code> peuvent exécuter des commandes sur le shell du système d'exploitation dans un processus enfant Node.js. Node.js fournit également une autre méthode avec une fonctionnalité similaire, <code>spawn()</code>. La différence est qu'au lieu d'obtenir la sortie des commandes shell en même temps, nous les recevons en morceaux via un flux. Dans la section suivante, nous utiliserons la commande <code>spawn()</code> pour créer un processus enfant.</p>\n\n<h2 id=\"Étape-2-—-création-d-39-un-processus-enfant-avec-spawn\">Étape 2 — Création d'un processus enfant avec <code>spawn()</code></h2>\n\n<p>La fonction <code>spawn()</code> exécute une commande dans un processus. Cette fonction renvoie des données via l&rsquo;<a href=\"https://nodejs.org/api/stream.html\">API stream</a>. Par conséquent, pour obtenir la sortie du processus enfant, nous devons écouter les <a href=\"https://www.digitalocean.com/community/tutorials/understanding-events-in-javascript\">événements</a> du flux.</p>\n\n<p>Les flux dans Node.js sont des instances d'émetteurs d'événements. Si vous souhaitez en savoir plus sur l'écoute des événements et les fondements de l'interaction avec les flux, vous pouvez lire notre guide sur <a href=\"https://www.digitalocean.com/community/tutorials/using-event-emitters-in-node-js\">Utiliser des émetteurs d'événements dans Node.js</a>.</p>\n\n<p>Il est souvent judicieux de choisir <code>spawn()</code> plutôt <code>exec()</code> ou <code>execFile()</code> lorsque la commande que vous voulez exécuter peut produire une grande quantité de données. Avec un buffer, tel qu'utilisé par <code>exec()</code> et <code>execFile()</code>, toutes les données traitées sont stockées dans la mémoire de l'ordinateur. Pour de grandes quantités de données, cela peut dégrader la performance du système. Avec un flux, les données sont traitées et transférées en petits groupes. Par conséquent, vous pouvez traiter une grande quantité de données sans utiliser trop de mémoire à la fois.</p>\n\n<p>Voyons comment nous pouvons utiliser <code>spawn()</code> pour créer un processus enfant. Nous allons écrire un nouveau module Node.js qui crée un processus enfant pour exécuter la commande <code>find</code>. Nous utiliserons la commande <code>find</code> pour lister tous les fichiers du répertoire actuel.</p>\n\n<p>Créez un nouveau fichier appelé <code>findFiles.js</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano findFiles.js\n</li></ul></code></pre>\n<p>Dans votre éditeur de texte, commencez par appeler la commande <code>spawn()</code> :</p>\n<div class=\"code-label \" title=\"~/child-processes/findFiles.js\">~/child-processes/findFiles.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const { spawn } = require('child_process');\n\nconst child = spawn('find', ['.']);\n</code></pre>\n<p>Nous avons d'abord importé la fonction <code>spawn()</code> du module <code>child_process</code>. Nous avons ensuite appelé la fonction <code>spawn()</code> pour créer un processus enfant qui exécute la commande <code>find</code>. Nous tenons la référence au processus dans la variable <code>child</code>, que nous utiliserons pour écouter ses événements en flux.</p>\n\n<p>Le premier argument en <code>spawn()</code> est la commande à exécuter, dans ce cas <code>find</code>. Le deuxième argument est un <a href=\"https://www.digitalocean.com/community/tutorials/understanding-arrays-in-javascript\">tableau</a> qui contient les arguments pour la commande exécutée. Dans ce cas, nous disons à Node.js d'exécuter la commande <code>find</code> avec l'argument <code>.</code>, ce qui fait que la commande trouve tous les fichiers du répertoire courant. La commande équivalente dans le terminal est <code>find .</code>.</p>\n\n<p>Avec les fonctions <code>exec()</code> et <code>execFile()</code>, nous avons écrit les arguments en même temps que la commande dans une seule chaîne. Cependant, avec <code>spawn()</code>, tous les arguments des commandes doivent être entrés dans le tableau. Ceci parce que <code>spawn()</code>, contrairement à  <code>exec()</code> et <code>execFile()</code>, ne crée pas de nouveau shell avant d'exécuter un processus. Pour avoir des commandes avec leurs arguments dans une seule chaîne, vous devez également créer un nouveau shell.</p>\n\n<p>Continuons notre module en ajoutant des auditeurs pour la sortie de la commande. Ajoutez les lignes surlignées suivantes :</p>\n<div class=\"code-label \" title=\"~/child-processes/findFiles.js\">~/child-processes/findFiles.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const { spawn } = require('child_process');\n\nconst child = spawn('find', ['.']);\n\n<span class=\"highlight\">child.stdout.on('data', data =&gt; {</span>\n  <span class=\"highlight\">console.log(`stdout:\\n${data}`);</span>\n<span class=\"highlight\">});</span>\n\n<span class=\"highlight\">child.stderr.on('data', data =&gt; {</span>\n  <span class=\"highlight\">console.error(`stderr: ${data}`);</span>\n<span class=\"highlight\">});</span>\n</code></pre>\n<p>Les commandes peuvent renvoyer des données dans le flux <code>stdout</code> ou dans le flux <code>stderr</code>, vous avez donc ajouté des auditeurs pour les deux. Vous pouvez ajouter des écouteurs en appelant la méthode <code>on()</code> des objets de chaque flux. L'événement <code>data</code> des flux nous donne la sortie de la commande vers ce flux. Chaque fois que nous obtenons des données sur l'un ou l'autre des flux, nous les enregistrons dans la console.</p>\n\n<p>Nous écoutons ensuite deux autres événements : l'événement <code>error</code> si la commande ne s'exécute pas ou est interrompue, et l'événement <code>close</code> lorsque la commande a fini d'exécuter, fermant ainsi le flux.</p>\n\n<p>Dans l'éditeur de texte, complétez le module Node.js en écrivant les lignes en surbrillance suivantes :</p>\n<div class=\"code-label \" title=\"~/child-processes/findFiles.js\">~/child-processes/findFiles.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const { spawn } = require('child_process');\n\nconst child = spawn('find', ['.']);\n\nchild.stdout.on('data', (data) =&gt; {\n  console.log(`stdout:\\n${data}`);\n});\n\nchild.stderr.on('data', (data) =&gt; {\n  console.error(`stderr: ${data}`);\n});\n\n<span class=\"highlight\">child.on('error', (error) =&gt; {</span>\n  <span class=\"highlight\">console.error(`error: ${error.message}`);</span>\n<span class=\"highlight\">});</span>\n\n<span class=\"highlight\">child.on('close', (code) =&gt; {</span>\n  <span class=\"highlight\">console.log(`child process exited with code ${code}`);</span>\n<span class=\"highlight\">});</span>\n</code></pre>\n<p>Pour les événements <code>error</code> et <code>close</code>, vous configurez un auditeur directement sur la variable <code>child</code>. Lors de l'écoute des événements <code>error</code>, si une erreur survient, Node.js fournit un objet <code>Error</code>. Dans ce cas, vous enregistrez la propriété <code>message</code> de l'erreur.</p>\n\n<p>Lorsqu'il écoute l'événement <code>close</code>, Node.js fournit le <em>code exit</em> de la commande. Un code exit indique si la commande s'est exécuté avec succès ou non. Lorsqu'une commande s'exécute sans erreurs, elle renvoie la valeur la plus basse possible pour un code exit : <code>0</code>. Lorsqu'elle s'exécute avec une erreur, elle renvoie un code différent de zéro.</p>\n\n<p>Le module est terminé. Enregistrez et quittez <code>nano</code> avec <code>CTRL+X</code>.</p>\n\n<p>Maintenant, lancez le code avec la commande <code>node</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node findFiles.js\n</li></ul></code></pre>\n<p>Une fois terminé, vous verrez la sortie suivante :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>stdout:\n.\n./findFiles.js\n./listFiles.js\n./nodejs-logo.svg\n./processNodejsImage.sh\n./getNodejsImage.js\n\nchild process exited with code 0\n</code></pre>\n<p>Nous trouvons une liste de tous les fichiers dans notre répertoire actuel et le code exit de la commande, qui est <code>0</code> car il s'est exécuté avec succès. Bien que notre répertoire actuel contienne un petit nombre de fichiers, si nous avions exécuté ce code dans notre répertoire d'origine, notre programme aurait énuméré chaque fichier dans chaque dossier accessible à notre utilisateur. Étant donné que la sortie peut être potentiellement très importante, l'utilisation de la fonction <code>spawn()</code> est la plus idéale car ses flux ne nécessitent pas autant de mémoire qu'un grand buffer.</p>\n\n<p>Jusqu'à présent, nous avons utilisé des fonctions pour créer des processus enfants afin d'exécuter des commandes externes dans notre système d'exploitation. Node.js fournit également un moyen de créer un processus enfant qui exécute d'autres programmes Node.js. Utilisons la fonction <code>fork()</code> pour créer un processus enfant pour un module Node.js dans la section suivante.</p>\n\n<h2 id=\"Étape-3-—-création-d-39-un-processus-enfant-avec-fork\">Étape 3 — Création d'un processus enfant avec <code>fork()</code></h2>\n\n<p>Node.js fournit la fonction <code>fork()</code>, une variation du <code>spawn()</code>, pour créer un processus enfant qui est également un processus Node.js. Le principal avantage d'utiliser <code>fork()</code> pour créer un processus Node.js par rapport à <code>spawn()</code> ou <code>exec()</code> est que <code>fork()</code> permet la communication entre le processus parent et le processus enfant.</p>\n\n<p>Avec <code>fork()</code>, en plus de récupérer des données du processus enfant, un processus parent peut envoyer des messages au processus enfant en cours d'exécution. De la même façon, le processus enfant peut envoyer des messages au processus parent.</p>\n\n<p>Voyons un exemple où l'utilisation de <code>fork()</code> pour créer un nouveau processus enfant Node.js peut améliorer les performances de notre application. Les programmes Node.js s'exécutent sur un seul processus. Par conséquent, les tâches gourmandes en CPU comme l'itération sur des grandes boucles ou l'analyse de gros <a href=\"https://www.digitalocean.com/community/tutorials/how-to-work-with-json-in-javascript\">fichiers JSON</a> empêchent l'exécution d'autres codes JavaScript. Pour certaines applications, ce n'est pas une option viable. Si un serveur web est bloqué, il ne peut pas traiter de nouvelles demandes entrantes tant que le code qui le bloque n'a pas fini son exécution.</p>\n\n<p>Voyons cela en pratique en créant un serveur web avec deux points terminaux. L'un d'eux effectuera un calcul lent qui bloquera le processus Node.js. L'autre point terminal renverra un objet JSON disant <code>hello</code>.</p>\n\n<p>Tout d'abord, créez un nouveau fichier appelé <code>httpServer.js</code>, qui contiendra le code de notre serveur HTTP :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano httpServer.js\n</li></ul></code></pre>\n<p>Nous commencerons par configurer le serveur HTTP. Cela implique l'importation du module <code>http</code>, la création d'une fonction d'écoute des requêtes, la création d'un objet serveur et l'écoute des requêtes sur l'objet serveur. Si vous souhaitez vous plonger plus profondément dans la création de serveurs HTTP dans Node.js ou si vous souhaitez vous rafraîchir la mémoire, vous pouvez lire notre guide <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-a-web-server-in-node-js-with-the-http-module\">Comment créer un serveur web en Node.js avec le module HTTP</a>.</p>\n\n<p>Entrez le code suivant dans votre éditeur de texte pour configurer un serveur HTTP :</p>\n<div class=\"code-label \" title=\"~/child-processes/httpServer.js\">~/child-processes/httpServer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const http = require('http');\n\nconst host = 'localhost';\nconst port = 8000;\n\nconst requestListener = function (req, res) {};\n\nconst server = http.createServer(requestListener);\nserver.listen(port, host, () =&gt; {\n  console.log(`Server is running on http://${host}:${port}`);\n});\n</code></pre>\n<p>Ce code met en place un serveur HTTP qui s'exécutera sur <code>http://localhost:8000</code>. Elle utilise <a href=\"https://www.digitalocean.com/community/tutorials/understanding-template-literals-in-javascript\">des littéraux de gabarits</a> pour générer dynamiquement cette URL.</p>\n\n<p>Ensuite, nous allons écrire une fonction intentionnellement lente qui compte 5 milliards de fois dans une boucle. Avant la fonction <code>requestListener()</code>, ajoutez le code suivant :</p>\n<div class=\"code-label \" title=\"~/child-processes/httpServer.js\">~/child-processes/httpServer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">...\nconst port = 8000;\n\n<span class=\"highlight\">const slowFunction = () =&gt; {</span>\n  <span class=\"highlight\">let counter = 0;</span>\n  <span class=\"highlight\">while (counter &lt; 5000000000) {</span>\n    <span class=\"highlight\">counter++;</span>\n  <span class=\"highlight\">}</span>\n\n  <span class=\"highlight\">return counter;</span>\n<span class=\"highlight\">}</span>\n\nconst requestListener = function (req, res) {};\n...\n</code></pre>\n<p>Cela utilise la <a href=\"https://www.digitalocean.com/community/tutorials/how-to-define-functions-in-javascript#arrow-functions\">syntaxe de fonction fléchée</a> pour créer une <a href=\"https://www.digitalocean.com/community/tutorials/using-while-and-do-while-loops-in-javascript#while-loop\">boucle <code>while</code></a> qui compte jusqu'à <code>5000000000</code>.</p>\n\n<p>Pour terminer ce module, nous devons ajouter du code à la fonction <code>requestListener()</code>. Notre fonction appellera la fonction <code>slowFunction()</code> sur le sous-chemin et renverra un petit message JSON pour l'autre. Ajoutez le code suivant au module :</p>\n<div class=\"code-label \" title=\"~/child-processes/httpServer.js\">~/child-processes/httpServer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">...\nconst requestListener = function (req, res) {\n  <span class=\"highlight\">if (req.url === '/total') {</span>\n    <span class=\"highlight\">let slowResult = slowFunction();</span>\n    <span class=\"highlight\">let message = `{\"totalCount\":${slowResult}}`;</span>\n\n    <span class=\"highlight\">console.log('Returning /total results');</span>\n    <span class=\"highlight\">res.setHeader('Content-Type', 'application/json');</span>\n    <span class=\"highlight\">res.writeHead(200);</span>\n    <span class=\"highlight\">res.end(message);</span>\n  <span class=\"highlight\">} else if (req.url === '/hello') {</span>\n    <span class=\"highlight\">console.log('Returning /hello results');</span>\n    <span class=\"highlight\">res.setHeader('Content-Type', 'application/json');</span>\n    <span class=\"highlight\">res.writeHead(200);</span>\n    <span class=\"highlight\">res.end(`{\"message\":\"hello\"}`);</span>\n  <span class=\"highlight\">}</span>\n};\n...\n</code></pre>\n<p>Si l'utilisateur atteint le serveur dans le sous-chemin <code>/total</code>, nous exécutons alors <code>slowFunction()</code>. Si nous atteignons le sous-chemin <code>/hello</code>, nous renvoyons ce message JSON : <code>{\"message\":\"hello\"}</code>.</p>\n\n<p>Enregistrez et quittez le fichier en appuyant sur <code>CTRL+X</code>.</p>\n\n<p>Pour tester, lancez ce module serveur avec <code>node</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node httpServer.js\n</li></ul></code></pre>\n<p>Lorsque notre serveur démarre, la console affiche ce qui suit :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Server is running on http://localhost:8000\n</code></pre>\n<p>Maintenant, pour tester les performances de notre module, ouvrez deux terminaux supplémentaires. Sur le premier terminal, utilisez la commande <code>curl</code> pour faire une requête vers le point terminal <code>/total</code>, qui devrait être lent:</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl http://localhost:8000/total\n</li></ul></code></pre>\n<p>Dans l'autre terminal, utilisez <code>curl</code> pour faire une requête au point terminal <code>/hello</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl http://localhost:8000/hello\n</li></ul></code></pre>\n<p>La première requête renverra le JSON suivant :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\"totalCount\":5000000000}\n</code></pre>\n<p>Alors que la deuxième requête renverra ce JSON :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\"message\":\"hello\"}\n</code></pre>\n<p>La requête à <code>/hello</code> est complétée qu'après la requête à <code>/total</code>. Le <code>slowFunction()</code> a bloqué l'exécution de tout autre code alors qu'il se trouvait toujours dans sa boucle. Vous pouvez vérifier cela en regardant la sortie du serveur Node.js qui a été enregistrée dans votre terminal original :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Returning /total results\nReturning /hello results\n</code></pre>\n<p>Pour traiter le code de blocage tout en acceptant les requêtes entrantes, nous pouvons déplacer le code de blocage vers un processus enfant avec <code>fork()</code>. Nous allons déplacer le code de blocage dans son propre module. Le serveur Node.js créera alors un processus enfant lorsque quelqu'un accède au point terminal <code>/total</code> et écoutera les résultats de ce processus enfant.</p>\n\n<p>Remaniez le serveur en créant d'abord un nouveau module appelé <code>getCount.js</code> qui contiendra <code>slowFunction()</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano getCount.js\n</li></ul></code></pre>\n<p>Entrez encore une fois le code pour <code>slowFunction()</code> :</p>\n<div class=\"code-label \" title=\"~/child-processes/getCount.js\">~/child-processes/getCount.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const slowFunction = () =&gt; {\n  let counter = 0;\n  while (counter &lt; 5000000000) {\n    counter++;\n  }\n\n  return counter;\n}\n</code></pre>\n<p>Comme ce module sera un processus enfant créé avec <code>fork()</code>, nous pouvons également ajouter du code pour communiquer avec le processus parent lorsque <code>slowFunction()</code> a terminé le traitement. Ajoutez le bloc de code suivant qui envoie un message au processus parent avec le JSON à retourner à l'utilisateur :</p>\n<div class=\"code-label \" title=\"~/child-processes/getCount.js\">~/child-processes/getCount.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const slowFunction = () =&gt; {\n  let counter = 0;\n  while (counter &lt; 5000000000) {\n    counter++;\n  }\n\n  return counter;\n}\n\n<span class=\"highlight\">process.on('message', (message) =&gt; {</span>\n  <span class=\"highlight\">if (message == 'START') {</span>\n    <span class=\"highlight\">console.log('Child process received START message');</span>\n    <span class=\"highlight\">let slowResult = slowFunction();</span>\n    <span class=\"highlight\">let message = `{\"totalCount\":${slowResult}}`;</span>\n    <span class=\"highlight\">process.send(message);</span>\n  <span class=\"highlight\">}</span>\n<span class=\"highlight\">});</span>\n</code></pre>\n<p>Décomposons ce bloc de code. Les messages entre un processus parent et un processus enfant créés par <code>fork()</code> sont accessibles via l&rsquo;<a href=\"https://nodejs.org/api/process.html#process_process\">objet <code>process</code></a> global Node.js. Nous ajoutons un auditeur à la variable <code>process</code> pour rechercher des événements <code>message</code>. Une fois que nous recevons un événement <code>message</code>, nous vérifions si c'est l'événement <code>START</code>. Notre code serveur enverra l'événement <code>START</code> lorsque quelqu'un accède au point terminal <code>/total</code>. À la réception de cet événement, nous exécutons <code>slowFunction()</code> et créons une chaîne JSON avec le résultat de la fonction. Nous utilisons <code>process.send()</code> pour envoyer un message au processus parent.</p>\n\n<p>Enregistrez et quittez <code>getCount.js</code> en entrant <code>CTRL+X</code> dans nano.</p>\n\n<p>Maintenant, modifions le fichier <code>httpServer.js</code> afin qu'au lieu d'appeler <code>slowFunction()</code>, il crée un processus enfant qui exécute <code>getCount.js</code>.</p>\n\n<p>Rouvrez <code>httpServer.js</code> avec <code>nano</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">nano httpServer.js\n</li></ul></code></pre>\n<p>Tout d'abord, importez la fonction <code>fork()</code> du module <code>child_process</code> :</p>\n<div class=\"code-label \" title=\"~/child-processes/httpServer.js\">~/child-processes/httpServer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">const http = require('http');\n<span class=\"highlight\">const { fork } = require('child_process');</span>\n...\n</code></pre>\n<p>Ensuite, nous allons supprimer la fonction <code>slowFunction()</code> de ce module et modifier la fonction <code>requestListener()</code> pour créer un processus enfant. Modifiez le code dans votre fichier afin qu'il ressemble à ceci :</p>\n<div class=\"code-label \" title=\"~/child-processes/httpServer.js\">~/child-processes/httpServer.js</div><pre class=\"code-pre \"><code class=\"code-highlight language-javascript\">...\nconst port = 8000;\n\nconst requestListener = function (req, res) {\n  if (req.url === '/total') {\n    <span class=\"highlight\">const child = fork(__dirname + '/getCount');</span>\n\n    <span class=\"highlight\">child.on('message', (message) =&gt; {</span>\n      <span class=\"highlight\">console.log('Returning /total results');</span>\n      <span class=\"highlight\">res.setHeader('Content-Type', 'application/json');</span>\n      <span class=\"highlight\">res.writeHead(200);</span>\n      <span class=\"highlight\">res.end(message);</span>\n    <span class=\"highlight\">});</span>\n\n    <span class=\"highlight\">child.send('START');</span>\n  } else if (req.url === '/hello') {\n    console.log('Returning /hello results');\n    res.setHeader('Content-Type', 'application/json');\n    res.writeHead(200);\n    res.end(`{\"message\":\"hello\"}`);\n  }\n};\n...\n</code></pre>\n<p>Lorsque quelqu'un passe au point terminal <code>/total</code>, nous créons maintenant un nouveau processus enfant avec <code>fork()</code>. L'argument de <code>fork()</code> est le chemin vers le module Node.js. Dans ce cas, il s'agit du fichier <code>getCount.js</code> dans notre répertoire actuel, que nous recevons de <code>__dirname</code>. La référence à ce processus enfant est stockée dans une variable <code>child</code>.</p>\n\n<p>Nous ajoutons alors un auditeur à l'objet <code>child</code>. Cet auditeur capture tous les messages que le processus enfant nous donne. Dans ce cas, <code>getCount.js</code> renverra une chaîne JSON avec le nombre total compté par la boucle <code>while</code>. Lorsque nous recevons ce message, nous envoyons le JSON à l'utilisateur.</p>\n\n<p>Nous utilisons la fonction <code>send()</code> de la variable <code>child</code> pour lui donner un message. Ce programme envoie le message <code>START</code>, qui commence l'exécution de <code>slowFunction()</code> dans le processus enfant.</p>\n\n<p>Enregistrez et quittez <code>nano</code> en entrant <code>CTRL+X</code>.</p>\n\n<p>Pour tester l'amélioration en utilisant <code>fork()</code> fait sur le serveur HTTP, commencez par exécuter le fichier <code>httpServer.js</code> avec <code>node</code> :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">node httpServer.js\n</li></ul></code></pre>\n<p>Comme auparavant, il sortira le message suivant lorsqu'il se lancera :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Server is running on http://localhost:8000\n</code></pre>\n<p>Pour tester le serveur, nous aurons besoin de deux terminaux supplémentaires, comme nous l'avons fait la première fois. Vous pouvez les réutiliser s'ils sont toujours ouverts.</p>\n\n<p>Dans le premier terminal, utilisez la commande <code>curl</code> pour faire une requête vers le point terminal <code>/total</code>, qui prend un certain temps à calculer :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl http://localhost:8000/total\n</li></ul></code></pre>\n<p>Dans l'autre terminal, utilisez <code>curl</code> pour faire une requête au point terminal <code>/hello</code>, qui répond en peu de temps :</p>\n<pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl http://localhost:8000/hello\n</li></ul></code></pre>\n<p>La première requête renverra le JSON suivant :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\"totalCount\":5000000000}\n</code></pre>\n<p>Alors que la deuxième requête renverra ce JSON :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>{\"message\":\"hello\"}\n</code></pre>\n<p>Contrairement à la première fois que nous avons essayé ceci, la deuxième requête vers <code>/hello</code> s'exécute immédiatement. Vous pouvez confirmer en examinant les journaux, qui ressembleront à ceci :</p>\n<pre class=\"code-pre plaintext\"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>Child process received START message\nReturning /hello results\nReturning /total results\n</code></pre>\n<p>Ces journaux montrent que la requête concernant le point terminal <code>/hello</code> s'est exécutée après la création du processus enfant, mais avant que celui-ci n'ait terminé sa tâche.</p>\n\n<p>Comme nous avons déplacé le code de blocage dans un processus enfant en utilisant <code>fork()</code>, le serveur a toujours pu répondre à d'autres requêtes et exécuter d'autres codes JavaScript. Grâce à la capacité de la fonction <code>fork()</code> à transmettre des messages, nous pouvons contrôler le moment où un processus enfant commence une activité et nous pouvons renvoyer des données d'un processus enfant à un processus parent.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Dans cet article, vous avez utilisé diverses fonctions pour créer un processus enfant dans Node.js. Vous avez d'abord créé des processus enfants avec <code>exec()</code> pour exécuter des commandes shell à partir du code Node.js. Vous avez ensuite exécuté un fichier exécutable avec la fonction <code>execFile()</code>. Vous avez examiné la fonction <code>spawn()</code>, qui peut également exécuter des commandes mais renvoie des données via un flux et ne démarre pas un shell comme <code>exec()</code> et <code>execFile()</code>. Enfin, vous avez utilisé la fonction <code>fork()</code> pour permettre une communication bidirectionnelle entre les processus parent et enfant.</p>\n\n<p>Pour en savoir plus sur le module <code>child_process</code>, vous pouvez lire la <a href=\"https://nodejs.org/api/child_process.html\">documentation Node.js</a>. Si vous souhaitez continuer à apprendre Node.js, vous pouvez revenir à la <a href=\"https://www.digitalocean.com/community/tutorial_series/how-to-code-in-node-js\">série Comment coder dans Node.js</a>, ou parcourir les projets de programmation et les configurations sur notre <a href=\"https://www.digitalocean.com/community/tags/node-js\">page thématique Node</a>.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:45:34 +0000","feedId":8037,"bgimg":"","linkMd5":"57f635bf3276d328100dfff40f2ff854","bgimgJsdelivr":"","metaImg":"","author":"Stack Abuse","publishedOrCreatedDate":1598860106975},{"createdTime":"2020-08-31 15:48:26","updatedTime":"2020-08-31 15:48:26","title":"Централизация журналов с помощью Journald в Ubuntu 20.04","link":"https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-journald-on-ubuntu-20-04-ru","description":"<p><em>Автор выбрал фонд <a href=\"https://www.brightfunds.org/funds/foss-nonprofits\">Free and Open Source Fund</a> для получения пожертвования в рамках программы <a href=\"https://do.co/w4do-cta\">Write for DOnations</a>.</em></p>\n\n<h3 id=\"Введение\">Введение</h3>\n\n<p>Системные журналы — чрезвычайно важный компонент управления системами Linux. Они позволяют получить ценную информацию о работе и использовании систем, поскольку регистрируют не только ошибки, но и информацию о текущей работе, в том числе события безопасности. Стандартная конфигурация систем Linux предусматривает локальное хранение журналов в той же системе, где они ведутся. Это хорошо работает для отдельных систем, но быстро превращается в проблему с увеличением числа систем. Создание централизованного сервера управления журналами, куда каждый хост Linux будет отправлять свои журналы в реальном времени позволит решить эту проблему.</p>\n\n<p>Централизованный сервер управления журналами дает ряд преимуществ по сравнению с хранением журналов на каждом хосте:</p>\n\n<ul>\n<li>Сокращаются требования к дисковому пространству на каждом хосте для хранения файлов журналов.</li>\n<li>Журналы можно хранить дольше, поскольку выделенный сервер журналов можно настроить с дополнительной емкостью для хранения.</li>\n<li>Можно провести расширенный анализ журнала, требующий использования журналов из разных систем и дополнительных вычислительных ресурсов, которые могут быть доступны на хостах.</li>\n<li>Системные администраторы могут получать доступ к журналам всех систем, в том числе тех, куда они не могут входить напрямую по причинам безопасности.</li>\n</ul>\n\n<p>В этом обучающем модуле мы настроим компонент набора инструментов <a href=\"https://systemd.io/\">systemd</a> для пересылки сообщений журналов клиентских систем на централизованный сервер хранения журналов. Мы использование сертификатов TLS на сервере и клиенте для шифрования сообщений журнала, передаваемых через интернет и другие незащищенные сети, а также для взаимной аутентификации.</p>\n\n<h2 id=\"Предварительные-требования\">Предварительные требования</h2>\n\n<p>Для прохождения этого обучающего руководства вам потребуется следующее:</p>\n\n<ul>\n<li>Два сервера Ubuntu 20.04.</li>\n<li>Пользователь без прав root с привилегиями sudo на обоих серверах. Указания можно найти в руководстве <a href=\"https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04\">«Начальная настройка сервера Ubuntu 20.04»</a>. Также вам следует настроить брандмауэр UFW на обоих серверах, как объясняется в этом руководстве.</li>\n<li>Два хоста, указывающие на ваши серверы. Одно имя хоста для <strong>клиентской</strong> системы, которая генерирует журналы, и другое — для <strong>сервера</strong> сбора журналов. Узнайте, как назначать имена хостов для дроплетов DigitalOcean, ознакомившись с документацией по <a href=\"https://www.digitalocean.com/docs/networking/dns/\">доменам и DNS</a>.</li>\n</ul>\n\n<p>В этом руководстве мы будем использовать два типовых имени хоста:</p>\n\n<ul>\n<li><code><span class=\"highlight\">client.your_domain</span></code>: клиентская система, генерирующая журналы.</li>\n<li><code><span class=\"highlight\">server.your_domain</span></code>: сервер хранения журналов.</li>\n</ul>\n\n<p>Для начала этого обучающего модуля выполните вход на клиент и на сервер в отдельных терминалах через SSH как пользователь без прав root с привилегиями sudo.</p>\n\n<p><span class='note'><strong>Примечание</strong>. В этом обучающем модуле блоки команд помечаются именем сервера (<strong>client</strong> или <strong>server</strong>), где должна запускаться команда.<br></span></p>\n\n<h2 id=\"Шаг-1-—-Установка-systemd-journal-remote\">Шаг 1 — Установка <code>systemd-journal-remote</code></h2>\n\n<p>На этом шаге мы установим пакет <code>systemd-journal-remote</code> на серверах <strong>client</strong> и <strong>server</strong>. Этот пакет содержит компоненты, которые <strong>client</strong> и <strong>server</strong> используют для пересылки сообщений журнала.</p>\n\n<p>Вначале проведите обновление системы на серверах <strong>client</strong> и <strong>server</strong>, чтобы гарантировать использование актуальных версий системы и базы данных пакетов:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li><li class=\"line\" data-prefix=\"$\">sudo apt upgrade\n</li></ul></code></pre>\n<p>Затем установите пакет <code>systemd-journal-remote</code>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install systemd-journal-remote\n</li></ul></code></pre>\n<p>На сервере <strong>server</strong> активируйте и запустите два компонента <a href=\"https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal\"><code>systemd</code></a>, необходимых для получения журнала, с помощью следующей команды:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable --now systemd-journal-remote.socket\n</li><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-remote.service\n</li></ul></code></pre>\n<p>Опция <code>--now</code> в первой команде сразу же запускает службы. Мы не использовали ее во второй команде, потому что эта служба не запускается, пока не получит сертификаты TLS, которые мы создадим на следующем шаге.</p>\n\n<p>Активируйте на сервере <strong>client</strong> компонент, используемый <code>systemd</code> для отправки сообщений журнала на сервер:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl enable systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Откройте на сервере порты <code>19532</code> и <code>80</code> в брандмауэре UFW. Это позволит серверу получать сообщения журнала от клиента. Порт <code>80</code> используется <code>certbot</code> для генерирования сертификата TLS. Эти порты открываются с помощью следующих команд:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 19532/tcp\n</li><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>На клиенте нужно открыть только порт <code>80</code> с помощью следующей команды:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ufw allow in 80/tcp\n</li></ul></code></pre>\n<p>Мы установили требуемые компоненты и настроили базовую конфигурацию системы на клиенте и сервере. Прежде чем настраивать эти компоненты для пересылки сообщений журнала, необходимо зарегистрировать сертификаты TLS от <a href=\"https://letsencrypt.org/\">Let&rsquo;s Encrypt</a> для серверов <strong>client</strong> и <strong>server</strong> с помощью утилиты <a href=\"https://certbot.eff.org/\"><code>certbot</code></a>.</p>\n\n<h2 id=\"Шаг-2-—-Установка-certbot-и-регистрация-сертификатов\">Шаг 2 — Установка Certbot и регистрация сертификатов</h2>\n\n<p>Let&rsquo;s Encrypt — это <a href=\"https://en.wikipedia.org/wiki/Certificate_authority\">центр сертификации</a>, выпускающий бесплатные сертификаты TLS. Эти сертификаты позволяют компьютерам шифровать данные, которыми они обмениваются, и выполнять взаимную аутентификацию. Эти сертификаты позволяют защитить компьютер с помощью протокола HTTPS в браузере. Эти же сертификаты могут использоваться любым другим приложением, для которого требуется такой же уровень безопасности. Процесс регистрации сертификата будет одинаковым вне зависимости от его предназначения.</p>\n\n<p>На этом шаге мы установим утилиту <code>certbot</code> и используем ее для регистрации сертификатов. Также она будет автоматически продлевать сертификаты, когда срок их действия будет истекать. Процесс регистрации на <strong>клиенте</strong> и на <strong>сервере</strong> будет одинаковым. Вам нужно будет только указать имя того хоста, где вы будете выполнять команду регистрации.</p>\n\n<p>Вначале активируйте репозиторий Ubuntu <code>universe</code>, поскольку утилита <code>certbot</code> находится в репозитории <code>universe</code>. Если у вас уже активирован репозиторий <code>universe</code>, при запуске этих команд ничего не произойдет, так что вы можете безопасно запустить их:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install software-properties-common\n</li><li class=\"line\" data-prefix=\"$\">sudo add-apt-repository universe\n</li><li class=\"line\" data-prefix=\"$\">sudo apt update\n</li></ul></code></pre>\n<p>Затем установите <code>certbot</code> на обоих хостах:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo apt install certbot\n</li></ul></code></pre>\n<p>После установки <code>certbot</code> запустите следующую команду для регистрации сертификатов на <strong>клиенте</strong> и на <strong>сервере</strong>:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo certbot certonly --standalone --agree-tos --email <span class=\"highlight\">sammy@your_domain</span> -d <span class=\"highlight\">your_domain</span>\n</li></ul></code></pre>\n<p>Опции этой команды имеют следующее значение:</p>\n\n<ul>\n<li><code>certonly</code>: зарегистрировать сертификат и не вносить в систему никаких других изменений.</li>\n<li><code>--standalone</code>: использовать встроенный веб-сервер certbot для проверки запроса сертификата.</li>\n<li><code>--agree-tos</code>: автоматически принять условия обслуживания Let&rsquo;s Encrypt.</li>\n<li><code>--email <span class=\"highlight\">your_email</span></code>: этот адрес электронной почты Let&rsquo;s Encrypt будет использовать для уведомлений об истечении срока действия сертификатов и отправки другой важной информации.</li>\n<li><code>-d <span class=\"highlight\">your_domain</span></code>: имя хоста, для которого будет регистрироваться сертификат. Это значение должно соответствовать имени хоста системы, где вы запускаете команду.</li>\n</ul>\n\n<p>При запуске этой команды вам будет предложено передать Let&rsquo;s Encrypt адрес электронной почты, чтобы они могли посылать вам новости и другую информацию об их работе. Это необязательно, и если вы не передадите свой адрес электронной почты, регистрация сертификата все равно пройдет нормально.</p>\n\n<p>После завершения процесса регистрации файлы ключа и сам сертификат будут размещены в каталоге <code>/etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/</code>, где <code>your_domain</code> — имя хоста, для которого вы зарегистрировали сертификат.</p>\n\n<p>В заключение вам нужно будет загрузить копию ЦС Let&rsquo;s Encrypt и промежуточные сертификаты и поместить их в этот же файл. <code>journald</code> будет использовать этот файл для проверки подлинности сертификатов <strong>клиента</strong> и <strong>сервера</strong> при их взаимодействии друг с другом.</p>\n\n<p>Следующая команда загрузит два сертификата с сайта Let&rsquo;s Encrypt и поместит их в один файл <code>letsencrypt-combined-certs.pem</code> в домашнем каталоге пользователя.</p>\n\n<p>Запустите эту команду на <strong>клиенте</strong> и на <strong>сервере</strong> для загрузки сертификатов и создания объединенного файла:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">curl -s https://letsencrypt.org/certs/{isrgrootx1.pem.txt,letsencryptauthorityx3.pem.txt} &gt; ~/letsencrypt-combined-certs.pem\n</li></ul></code></pre>\n<p>Затем переместите этот файл в каталог Let&rsquo;s Encrypt, содержащий ключи и сертификаты:</p>\n<div class=\"code-label \" title=\"Client and Server\">Client and Server</div><pre class=\"code-pre command prefixed\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo cp ~/letsencrypt-combined-certs.pem /etc/letsencrypt/live/<span class=\"highlight\">your_domain</span>/\n</li></ul></code></pre>\n<p>Вы зарегистрировали ключи и сертификаты. На следующем шаге мы настроим <strong>сервер</strong> хранения журналов, чтобы он отслеживал и сохранял сообщения журнала, поступающие от <strong>клиента</strong>.</p>\n\n<h2 id=\"Шаг-3-—-Настройка-сервера\">Шаг 3 — Настройка сервера</h2>\n\n<p>На этом шаге мы настроим <strong>сервер</strong> для использования сертификата и файлов ключа, сгенерированных на предыдущем шаге, для принятия сообщений журнала от <strong>клиента</strong>.</p>\n\n<p>Компонент <code>systemd-journal-remote</code> отслеживает сообщения журнала. Откройте его файл конфигурации <code>/etc/systemd/journal-remote.conf</code> в текстовом редакторе, чтобы начать его настройку на <strong>сервере</strong>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-remote.conf\n</li></ul></code></pre>\n<p>Затем разкомментируйте все строки в разделе <code>[Remote]</code> и установите пути к только что созданным файлам TLS:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-remote.conf\">/etc/systemd/journal-remote.conf</div><pre class=\"code-pre \"><code>[Remote]\nSeal=false\nSplitMode=host\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Здесь мы используем следующие опции:</p>\n\n<ul>\n<li><code>Seal=false</code>: Подписывать данные в журнале. Активируйте эту опцию, если вам требуется максимальный уровень безопасности, а в ином случае оставьте значение <code>false</code>.</li>\n<li><code>SplitMode=host</code>: журналы удаленных клиентов разделяются по хостам в каталоге <code>/var/log/journal/remote</code>. Если вы предпочитаете добавлять все журналы в один файл, установите значение <code>SplitMode=false</code>.</li>\n<li><code>ServerKeyFile</code>: файл закрытого ключа сервера.</li>\n<li><code>ServerCertificateFile</code>: файл сертификата сервера.</li>\n<li><code>TrustedCertificateFile</code>: файл, содержащий сертификаты ЦС Let&rsquo;s Encrypt.</li>\n</ul>\n\n<p>Теперь необходимо изменить разрешения для содержащих сертификаты и ключ каталогов Let&rsquo;s Encrypt, чтобы команда <code>systemd-journal-remote</code> могла считывать и использовать их.</p>\n\n<p>Вначале измените <a href=\"https://www.digitalocean.com/community/tutorials/an-introduction-to-linux-permissions\">разрешения</a> так, чтобы сертификат и закрытый ключ были доступны для чтения:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Затем измените группового владельца закрытого ключа на группу <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-remote /etc/letsencrypt/live/<span class=\"highlight\">server.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Теперь вы можете запустить <code>systemd-journal-remote</code>:</p>\n<pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl start systemd-journal-remote.service\n</li></ul></code></pre>\n<p><strong>Сервер</strong> хранения журналов запущен и готов начать принимать сообщения журнала от <strong>клиента</strong>. На следующем шаге мы настроим <strong>клиент</strong> для пересылки журналов на <strong>сервер</strong> хранения журналов.</p>\n\n<h2 id=\"Шаг-4-—-Настройка-клиента\">Шаг 4 — Настройка клиента</h2>\n\n<p>На этом шаге мы настроим компонент, пересылающий сообщения журнала на сервер хранения журналов. Этот компонент называется <code>systemd-journal-upload</code>.</p>\n\n<p>В конфигурации <code>systemd-journal-upload</code> по умолчанию используется временный пользователь, существующий только во время выполнения процесса. Это усложняет предоставление <code>systemd-journal-upload</code> разрешения на чтение сертификатов TLS и ключей. Для устранения этой проблемы необходимо создать нового пользователя системы с тем же именем, что и у временного пользователя, который будет использоваться вместо него.</p>\n\n<p>Вначале создайте нового пользователя <code>systemd-journal-upload</code> на <strong>клиенте</strong> с помощью следующей команды <code>adduser</code>:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo adduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload\n</li></ul></code></pre>\n<p>Опции этой команды:</p>\n\n<ul>\n<li><code>--system</code>: создать нового пользователя как системного. При этом пользователю присваивается числовой идентификатор UID ниже <code>1000</code>. Идентификаторы UID выше <code>1000</code> обычно присваиваются учетным записям, которые используют пользователи-люди.</li>\n<li><code>--home /run/systemd</code>: задать <code>/run/systemd</code> как домашний каталог пользователя.</li>\n<li><code>--no-create-home</code>: не создавать набор домашних каталогов, поскольку он уже существует.</li>\n<li><code>--disabled-login</code>: этот пользователь не может входить на сервер, например, через SSH.</li>\n<li><code>--group</code>: создать группу с тем же именем, что и у пользователя.</li>\n</ul>\n\n<p>Затем необходимо задать разрешения и владельца файлов сертификатов Let&rsquo;s Encrypt:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo chmod 0755 /etc/letsencrypt/{live,archive}\n</li><li class=\"line\" data-prefix=\"$\">sudo chmod 0640 /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li><li class=\"line\" data-prefix=\"$\">sudo chgrp systemd-journal-upload /etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\n</li></ul></code></pre>\n<p>Теперь отредактируйте конфигурацию <code>systemd-journal-upload</code> в файле <code>/etc/systemd/journal-upload.conf</code>. Откройте этот файл в текстовом редакторе:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo nano /etc/systemd/journal-upload.conf\n</li></ul></code></pre>\n<p>Отредактируйте файл следующим образом:</p>\n<div class=\"code-label \" title=\"/etc/systemd/journal-upload.conf\">/etc/systemd/journal-upload.conf</div><pre class=\"code-pre \"><code>[Upload]\nURL=https://<span class=\"highlight\">server.your_domain</span>:19532\nServerKeyFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/privkey.pem\nServerCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/fullchain.pem\nTrustedCertificateFile=/etc/letsencrypt/live/<span class=\"highlight\">client.your_domain</span>/letsencrypt-combined-certs.pem\n</code></pre>\n<p>Перезапустите службу <code>systemd-journal-upload</code>, чтобы она использовала новую конфигурацию:</p>\n<pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo systemctl restart systemd-journal-upload.service\n</li></ul></code></pre>\n<p>Теперь ваш <strong>клиент</strong> настроен, работает и отправляет сообщения журнала на сервер хранения журналов. На следующем шаге мы убедимся, что журналы отправляются и записываются надлежащим образом.</p>\n\n<h2 id=\"Шаг-5-—-Тестирование-клиента-и-сервера\">Шаг 5 — Тестирование клиента и сервера</h2>\n\n<p>На этом шаге мы проверим пересылку <strong>клиентом</strong> сообщений журнала на <strong>сервер</strong> и правильность их сохранения на <strong>сервере</strong>.</p>\n\n<p>Сервер хранения журналов сохраняет журналы клиентов в каталоге <code>/var/log/journal/remote/</code>. Когда мы перезапустили <strong>клиент</strong> в конце последнего шага, он начал отправлять сообщения журнала, и поэтому теперь в каталоге <code>/var/log/journal/remote/</code> содержится файл журнала. Имя файла будет соответствовать имени хоста, использованному для сертификата TLS.</p>\n\n<p>Используйте команду <code>ls</code>, чтобы проверить наличие файла журнала <strong>клиента</strong> на <strong>сервере</strong>:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo ls -la /var/log/journal/remote/\n</li></ul></code></pre>\n<p>Эта команда выводит содержимое каталога, показывая файл журнала:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Output\">Output</div>total 16620\ndrwxr-xr-x  2 systemd-journal-remote systemd-journal-remote     4096 Jun 30 16:17  .\ndrwxr-sr-x+ 4 root                   systemd-journal            4096 Jun 30 15:55  ..\n-rw-r-----  1 systemd-journal-remote systemd-journal-remote 8388608 Jul  1 10:46 '<span class=\"highlight\">remote-CN=client.your_domain</span>'\n</code></pre>\n<p>Затем запишите сообщение журнала на <strong>клиенте</strong>, чтобы проверить получение <strong>сервером</strong> сообщений от <strong>клиента</strong> ожидаемым образом. Мы используем утилиту <a href=\"https://man7.org/linux/man-pages/man1/logger.1.html\">logger</a> для создания сообщения журнала на <strong>клиенте</strong>. Если все работает нормально, <code>systemd-journal-upload</code> перешлет это сообщение на <strong>сервер</strong>.</p>\n\n<p>Запустите на <strong>клиенте</strong> следующую команду <code>logger</code>:</p>\n<div class=\"code-label \" title=\"Client\">Client</div><pre class=\"code-pre command prefixed third-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo logger -p syslog.debug \"### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\"\n</li></ul></code></pre>\n<p>Опция <code>-p syslog.debug</code> в этой команде указывает <a href=\"https://en.wikipedia.org/wiki/Syslog#Message_components\">принадлежность и серьезность</a> сообщения. Мы установим значение <code>syslog.debug</code>, чтобы показать, что это тестовое сообщение. Эта команда записывает сообщение <code>### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###</code> в журнал клиента, а <code>systemd-journal-upload</code> пересылает его на <strong>сервер</strong>.</p>\n\n<p>Откройте файл журнала <strong>клиента</strong> на <strong>сервере</strong> и проверьте поступление сообщений журнала от <strong>клиента</strong>. Это двоичный файл журнала, поэтому вы не сможете открыть его с помощью таких инструментов, как <code>less</code>. Вместо этого откройте файл с помощью команды <code>journalctl</code> с опцией <code>--file=</code>, позволяющей указать определенный файл журнала:</p>\n<div class=\"code-label \" title=\"Server\">Server</div><pre class=\"code-pre command prefixed second-environment\"><code><ul class=\"prefixed\"><li class=\"line\" data-prefix=\"$\">sudo journalctl --file=/var/log/journal/remote/remote-CN=<span class=\"highlight\">client.your_domain.journal</span>\n</li></ul></code></pre>\n<p>Сообщение журнала будет выглядеть следующим образом:</p>\n<pre class=\"code-pre \"><code><div class=\"secondary-code-label \" title=\"Test log message\">Test log message</div>. . .\nJun 29 13:10:09 client root[3576]: ### TEST MESSAGE from <span class=\"highlight\">client.your_domain</span> ###\n</code></pre>\n<p>Ваш сервер централизованного хранения журналов успешно получает журналы вашей клиентской системы.</p>\n\n<h2 id=\"Заключение\">Заключение</h2>\n\n<p>В этом обучающем модуле мы настроили централизованный сервер хранения журналов и настроили клиент для пересылки копии системных журналов на этот сервер. Используя описанные здесь шаги по настройке клиента, вы можете настроить любое необходимое количество клиентов, которые будут пересылать сообщения на сервер хранения журналов.</p>\n","descriptionType":"html","publishedDate":"Wed, 26 Aug 2020 19:44:03 +0000","feedId":8037,"bgimg":"","linkMd5":"cff95134917b22ad4e61fd17f803abfd","bgimgJsdelivr":"","metaImg":"","author":"Elliot Cooper","publishedOrCreatedDate":1598860106983}],"record":{"createdTime":"2020-08-31 15:48:27","updatedTime":"2020-08-31 15:48:27","feedId":8037,"fetchDate":"Mon, 31 Aug 2020 07:48:27 +0000","fetchMs":4791,"handleMs":212,"totalMs":27233,"newArticles":0,"totalArticles":100,"status":1,"type":0,"ip":"84e253ce38f288a60a012751fa1461fa","hostName":"europe-58*","requestId":"9a7d04ac1943406cb86a97a5bea07dd7_8037","contentType":"application/atom+xml; charset=utf-8","totalBytes":17940850,"bgimgsTotal":36,"bgimgsGithubTotal":36,"articlesImgsTotal":83,"articlesImgsGithubTotal":77,"successGithubMap":{"myreaderx8":3,"myreaderx15":3,"myreaderx7":2,"myreaderx16":3,"myreaderx6":3,"myreaderx4":3,"myreaderx32":3,"myreaderx10":3,"myreaderx33":3,"myreaderx3":3,"myreaderx11":2,"myreaderx12":2,"myreaderx2":3,"myreaderx13":3,"myreaderx1":3,"myreaderx30":3,"myreaderx31":3,"myreaderx18":2,"myreaderx19":3,"myreaderx":3,"myreaderx25":3,"myreaderx27":3,"myreaderx21":3,"myreaderx22":3,"myreaderx24":3,"myreaderx5oss":3,"myreaderx29":3},"failGithubMap":{"myreaderx14":3,"myreaderx23":3}},"feed":{"createdTime":"2020-08-25 04:34:05","updatedTime":"2020-08-25 07:50:42","id":8037,"name":"DigitalOcean Community Tutorials","url":"https://www.digitalocean.com/community/tutorials/feed","subscriber":null,"website":null,"icon":"https://www.digitalocean.com/favicon.ico","icon_jsdelivr":"https://cdn.jsdelivr.net/gh/myreaderx64/cdn24@2020_1/2020/08/24/23-49-01-986_bd35edbedb83c25e.png","description":"","weekly":null,"link":null},"noPictureArticleList":[{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"03d61cd2414a172d150bf26064b36b07"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"f47ccc598c59c8525a156701452c31ae"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"621722b6627b6f6ffc438eca502d5e4e"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"5735b63fd89047b3fcf525f7eac7a839"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"d3cc2a34945fb61874cc0335bc19dee6"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"f57bebdffa936870bdf9f361d318434c"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"447e70a1f3e8a777994877fd01b67679"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"0eab903a325a6b0b5cf420e264649d5b"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"d9b542071ee442a9ad50485e5196f52a"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"a771760dc9be0f1b6da3957374a8752c"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"ab8fbde9c723d68d66c86e37d72bf25d"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"bbd580a9f5932a12b8eee1a4fd9c573c"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"510cd117433b5adf34d215a010c834bd"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"53f7b8863b0e9dfc01055a304d0f4785"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"03d293a1903a5035b8dba89d5b4d0422"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"a7be8f228fc23dda64da52edfaba0470"},{"createdTime":"2020-08-31 15:48:48","updatedTime":"2020-08-31 15:48:48","id":null,"feedId":8037,"linkMd5":"c8d03d0d0deff79cc858db974957a275"}],"tmpCommonImgCdnBytes":1022236,"tmpBodyImgCdnBytes":16918614,"tmpBgImgCdnBytes":0,"extra4":{"start":1598860101243,"total":0,"statList":[{"spend":5534,"msg":"获取xml内容"},{"spend":212,"msg":"解释文章"},{"spend":1,"msg":"上传封面图到cdn"},{"spend":0,"msg":"修正封面图上传失败重新上传"},{"spend":17446,"msg":"正文链接上传到cdn"}]},"extra5":83,"extra6":83,"extra7ImgCdnFailResultVector":[{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png","sourceStatusCode":200,"destWidth":320,"destHeight":164,"sourceBytes":17191,"destBytes":6624,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":176,"convertSpendMs":5,"createdTime":"2020-08-31 15:48:31","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn38/contents/2020/08/31/07-48-31-281_bedbb7086c51767f.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E210:0AAF:1A63940:3E86AFA:5F4CAB4C"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860593"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn38/contents/2020/08/31/07-48-31-281_bedbb7086c51767f.webp","historyStatusCode":[],"spendMs":49},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16.8 KB","destSize":"6.5 KB","compressRate":"38.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png","sourceStatusCode":200,"destWidth":1160,"destHeight":840,"sourceBytes":21412,"destBytes":38652,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":170,"convertSpendMs":33,"createdTime":"2020-08-31 15:48:31","host":"us-036*","referer":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-fr","linkMd5ListStr":"621722b6627b6f6ffc438eca502d5e4e,d3cc2a34945fb61874cc0335bc19dee6,a771760dc9be0f1b6da3957374a8752c,bbd580a9f5932a12b8eee1a4fd9c573c,a7be8f228fc23dda64da52edfaba0470","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn60/contents/2020/08/31/07-48-31-327_2c485c5585c5ed4b.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E528:3EAB:1D50CF4:40496BE:5F4CAB45"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860592"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn60/contents/2020/08/31/07-48-31-327_2c485c5585c5ed4b.webp","historyStatusCode":[],"spendMs":45},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.9 KB","destSize":"37.7 KB","compressRate":"180.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_9.png","sourceStatusCode":200,"destWidth":1199,"destHeight":862,"sourceBytes":65345,"destBytes":26090,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":218,"convertSpendMs":63,"createdTime":"2020-08-31 15:48:31","host":"us-029*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn50/contents/2020/08/31/07-48-31-370_a631023d252f1c2a.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["8F9C:088A:E8B960:2456BE3:5F4CAB39"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860593"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn50/contents/2020/08/31/07-48-31-370_a631023d252f1c2a.webp","historyStatusCode":[],"spendMs":44},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"63.8 KB","destSize":"25.5 KB","compressRate":"39.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step3a.png","sourceStatusCode":200,"destWidth":320,"destHeight":164,"sourceBytes":17191,"destBytes":6624,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":93,"convertSpendMs":5,"createdTime":"2020-08-31 15:48:31","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn38/contents/2020/08/31/07-48-31-459_bedbb7086c51767f.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E210:0AAF:1A6394C:3E86CD8:5F4CAB4F"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860593"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn38/contents/2020/08/31/07-48-31-459_bedbb7086c51767f.webp","historyStatusCode":[],"spendMs":39},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16.8 KB","destSize":"6.5 KB","compressRate":"38.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/components_for_DO.png","sourceStatusCode":200,"destWidth":2396,"destHeight":1458,"sourceBytes":447880,"destBytes":95552,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":341,"convertSpendMs":132,"createdTime":"2020-08-31 15:48:31","host":"us-021*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn74/contents/2020/08/31/07-48-31-455_f609ba01388ff766.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["9C2C:3505:37A7C70:5CB7A7F:5F4CAB1C"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860592"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn74/contents/2020/08/31/07-48-31-455_f609ba01388ff766.webp","historyStatusCode":[],"spendMs":61},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"437.4 KB","destSize":"93.3 KB","compressRate":"21.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/understanding_relational_dbs/foreign_key_example_final.png","sourceStatusCode":200,"destWidth":1160,"destHeight":840,"sourceBytes":21412,"destBytes":38652,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":145,"convertSpendMs":39,"createdTime":"2020-08-31 15:48:31","host":"us-036*","referer":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-fr","linkMd5ListStr":"621722b6627b6f6ffc438eca502d5e4e,d3cc2a34945fb61874cc0335bc19dee6,a771760dc9be0f1b6da3957374a8752c,bbd580a9f5932a12b8eee1a4fd9c573c,a7be8f228fc23dda64da52edfaba0470","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn60/contents/2020/08/31/07-48-31-544_2c485c5585c5ed4b.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E528:3EAB:1D50D04:4049C0A:5F4CAB4F"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860592"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn60/contents/2020/08/31/07-48-31-544_2c485c5585c5ed4b.webp","historyStatusCode":[],"spendMs":50},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.9 KB","destSize":"37.7 KB","compressRate":"180.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_9.png","sourceStatusCode":200,"destWidth":1199,"destHeight":862,"sourceBytes":65345,"destBytes":26090,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":190,"convertSpendMs":47,"createdTime":"2020-08-31 15:48:31","host":"us-029*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn50/contents/2020/08/31/07-48-31-595_a631023d252f1c2a.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["EB98:788E:3179959:53A139A:5F4CAB4F"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860593"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn50/contents/2020/08/31/07-48-31-595_a631023d252f1c2a.webp","historyStatusCode":[],"spendMs":93},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"63.8 KB","destSize":"25.5 KB","compressRate":"39.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/components_for_DO.png","sourceStatusCode":200,"destWidth":2396,"destHeight":1458,"sourceBytes":447880,"destBytes":95552,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":258,"convertSpendMs":140,"createdTime":"2020-08-31 15:48:31","host":"us-036*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn74/contents/2020/08/31/07-48-31-901_f609ba01388ff766.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:31 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E528:3EAB:1D50D19:4049C27:5F4CAB4F"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860592"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn74/contents/2020/08/31/07-48-31-901_f609ba01388ff766.webp","historyStatusCode":[],"spendMs":48},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"437.4 KB","destSize":"93.3 KB","compressRate":"21.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/no_click_event_listener.png","sourceStatusCode":200,"destWidth":2444,"destHeight":1392,"sourceBytes":266081,"destBytes":83608,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":341,"convertSpendMs":136,"createdTime":"2020-08-31 15:48:32","host":"us-009*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn94/contents/2020/08/31/07-48-33-266_4c872535a450a786.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:33 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E6B6:44DF:395C121:5E0F828:5F4CAB2A"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860592"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn94/contents/2020/08/31/07-48-33-266_4c872535a450a786.webp","historyStatusCode":[],"spendMs":70},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"259.8 KB","destSize":"81.6 KB","compressRate":"31.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/no_click_event_listener.png","sourceStatusCode":200,"destWidth":2444,"destHeight":1392,"sourceBytes":266081,"destBytes":83608,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":399,"convertSpendMs":218,"createdTime":"2020-08-31 15:48:33","host":"us-013*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx14/cdn94/contents/2020/08/31/07-48-33-795_4c872535a450a786.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 68584859.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:33 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["D1C0:0ABF:1A1DD0B:3777906:5F4CAB51"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860592"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx14/cdn94/contents/2020/08/31/07-48-33-795_4c872535a450a786.webp","historyStatusCode":[],"spendMs":103},"base64UserPassword":null,"token":"6b67d******************************91b08"},"githubUser":"myreaderx14","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"259.8 KB","destSize":"81.6 KB","compressRate":"31.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/trigger_info_popup.gif","sourceStatusCode":200,"destWidth":1188,"destHeight":640,"sourceBytes":327817,"destBytes":77168,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2442,"convertSpendMs":2244,"createdTime":"2020-08-31 15:48:32","host":"us-017*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn70/contents/2020/08/31/07-48-35-137_ae7d9a50cc213f2c.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:35 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["D3DA:6159:E7F226:2428499:5F4CAB51"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860593"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn70/contents/2020/08/31/07-48-35-137_ae7d9a50cc213f2c.webp","historyStatusCode":[],"spendMs":68},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"320.1 KB","destSize":"75.4 KB","compressRate":"23.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/trigger_info_popup.gif","sourceStatusCode":200,"destWidth":1188,"destHeight":640,"sourceBytes":327817,"destBytes":77168,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":3272,"convertSpendMs":2156,"createdTime":"2020-08-31 15:48:35","host":"europe-59*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","rawMap":{"githubUrl":"https://api.github.com/repos/myreaderx23/cdn70/contents/2020/08/31/07-48-38-225_ae7d9a50cc213f2c.webp","resp":{"code":403,"msg":"Forbidden","body":"{\n  \"message\": \"API rate limit exceeded for user ID 69189253.\",\n  \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"\n}\n","headerMap":{"access-control-allow-origin":["*"],"access-control-expose-headers":["ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset"],"content-security-policy":["default-src 'none'"],"content-type":["application/json; charset=utf-8"],"date":["Mon, 31 Aug 2020 07:48:38 GMT"],"referrer-policy":["origin-when-cross-origin, strict-origin-when-cross-origin"],"server":["GitHub.com"],"status":["403 Forbidden"],"strict-transport-security":["max-age=31536000; includeSubdomains; preload"],"transfer-encoding":["chunked"],"vary":["Accept-Encoding, Accept, X-Requested-With"],"x-accepted-oauth-scopes":["repo"],"x-content-type-options":["nosniff"],"x-frame-options":["deny"],"x-github-media-type":["github.v3; format=json"],"x-github-request-id":["E5D2:BAC2:7493AED:8CAFB2F:5F4CAB50"],"x-oauth-scopes":["admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete:packages, delete_repo, gist, notifications, read:packages, repo, user, workflow, write:discussion, write:packages"],"x-ratelimit-limit":["60"],"x-ratelimit-remaining":["0"],"x-ratelimit-reset":["1598860593"],"x-xss-protection":["1; mode=block"]},"exceptionMsg":"Unexpected code 403,url is : https://api.github.com/repos/myreaderx23/cdn70/contents/2020/08/31/07-48-38-225_ae7d9a50cc213f2c.webp","historyStatusCode":[],"spendMs":300},"base64UserPassword":null,"token":"df0b9******************************93a6e"},"githubUser":"myreaderx23","githubHttpCode":403,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"320.1 KB","destSize":"75.4 KB","compressRate":"23.5%"}],"extra10_invalidATagHrefValue":{},"extra111_proxyServerAndStatMap":{"http://us-013.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-037.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-55.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://europe68.herokuapp.com/":{"failCount":0,"successCount":5,"resultList":[200,200,200,200,200]},"http://us-021.herokuapp.com/":{"failCount":0,"successCount":5,"resultList":[200,200,200,200,200]},"http://us-005.herokuapp.com/":{"failCount":0,"successCount":5,"resultList":[200,200,200,200,200]},"http://us-009.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://europe-60.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-025.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-001.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://us-017.herokuapp.com/":{"failCount":0,"successCount":5,"resultList":[200,200,200,200,200]},"http://us-036.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://europe21.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-033.herokuapp.com/":{"failCount":0,"successCount":5,"resultList":[200,200,200,200,200]},"http://europe64.herokuapp.com/":{"failCount":0,"successCount":4,"resultList":[200,200,200,200]},"http://europe-59.herokuapp.com/":{"failCount":0,"successCount":2,"resultList":[200,200]},"http://us-51.herokuapp.com/":{"failCount":0,"successCount":5,"resultList":[200,200,200,200,200]},"http://europe-22.herokuapp.com/":{"failCount":0,"successCount":3,"resultList":[200,200,200]},"http://us-029.herokuapp.com/":{"failCount":0,"successCount":6,"resultList":[200,200,200,200,200,200]},"http://us-012.herokuapp.com/":{"failCount":0,"successCount":1,"resultList":[200]}},"extra12ImgCdnSuccessResultVector":[{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/name_element.png","sourceStatusCode":200,"destWidth":862,"destHeight":428,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn85@2020_1/2020/08/31/07-48-27-286_a44b243efb8b534d.webp","sourceBytes":23209,"destBytes":5402,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":880,"convertSpendMs":13,"createdTime":"2020-08-31 15:48:27","host":"us-009*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a,d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"22.7 KB","destSize":"5.3 KB","compressRate":"23.3%"},{"code":1,"isDone":false,"source":"https://i.imgur.com/zLWcC3K.png","sourceStatusCode":200,"destWidth":933,"destHeight":164,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn73@2020_1/2020/08/31/07-48-27-261_a8d55c22a165f6e1.webp","sourceBytes":14270,"destBytes":12666,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":954,"convertSpendMs":10,"createdTime":"2020-08-31 15:48:27","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server","linkMd5ListStr":"dc56a320945f49e3f91d7c24367ad646,dc56a320945f49e3f91d7c24367ad646","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"13.9 KB","destSize":"12.4 KB","compressRate":"88.8%"},{"code":1,"isDone":false,"source":"http://assets.digitalocean.com/articles/elastic_1804/KibanaDashboard.png","sourceStatusCode":200,"destWidth":1833,"destHeight":948,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn82@2020_5/2020/08/31/07-48-27-288_3c8d2301c2e4c24f.webp","sourceBytes":40417,"destBytes":48810,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":970,"convertSpendMs":41,"createdTime":"2020-08-31 15:48:27","host":"us-021*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","linkMd5ListStr":"14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f,14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"39.5 KB","destSize":"47.7 KB","compressRate":"120.8%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/scalable_django/polls_app.png","sourceStatusCode":200,"destWidth":474,"destHeight":473,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn2@2020_1/2020/08/31/07-48-27-471_79375aca53558399.webp","sourceBytes":43341,"destBytes":1896,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1011,"convertSpendMs":15,"createdTime":"2020-08-31 15:48:27","host":"us-025*","referer":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-es","linkMd5ListStr":"3907b9e1835be8bac72033ab91b97c78,3907b9e1835be8bac72033ab91b97c78,a4defe178e448cd4f5967fe95415435a,a4defe178e448cd4f5967fe95415435a,bc1428647c5f6f1dbcc36cbd85ba0fe6,bc1428647c5f6f1dbcc36cbd85ba0fe6,5f4933306d16689cf1a957ecf36bdc6d,5f4933306d16689cf1a957ecf36bdc6d,5792aefc8110244761ef1e85fcf54ab2,5792aefc8110244761ef1e85fcf54ab2,3907b9e1835be8bac72033ab91b97c78,a4defe178e448cd4f5967fe95415435a,bc1428647c5f6f1dbcc36cbd85ba0fe6,5f4933306d16689cf1a957ecf36bdc6d,5792aefc8110244761ef1e85fcf54ab2","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"42.3 KB","destSize":"1.9 KB","compressRate":"4.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1a.png","sourceStatusCode":200,"destWidth":1920,"destHeight":973,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn98@2020_5/2020/08/31/07-48-27-374_8ff068e0b58f057b.webp","sourceBytes":66395,"destBytes":26384,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1028,"convertSpendMs":50,"createdTime":"2020-08-31 15:48:27","host":"us-037*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275,f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"64.8 KB","destSize":"25.8 KB","compressRate":"39.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/jupyterlab_1804/step5.png","sourceStatusCode":200,"destWidth":1600,"destHeight":900,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn8@2020_5/2020/08/31/07-48-27-446_cbd8056c70131692.webp","sourceBytes":53522,"destBytes":30628,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1130,"convertSpendMs":120,"createdTime":"2020-08-31 15:48:27","host":"us-001*","referer":"https://www.digitalocean.com/community/tutorials/how-to-set-up-a-jupyterlab-environment-on-ubuntu-18-04","linkMd5ListStr":"fc30ef8432ef45436603870128d4654b,fc30ef8432ef45436603870128d4654b","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"52.3 KB","destSize":"29.9 KB","compressRate":"57.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/electron_macos/step3.png","sourceStatusCode":200,"destWidth":817,"destHeight":618,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn89@2020_1/2020/08/31/07-48-27-736_e3f96fdcf5b98dca.webp","sourceBytes":76356,"destBytes":6366,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1564,"convertSpendMs":21,"createdTime":"2020-08-31 15:48:27","host":"europe-22*","referer":"https://www.digitalocean.com/community/tutorials/how-to-create-your-first-cross-platform-desktop-application-with-electron-on-macos","linkMd5ListStr":"4adc87fa81c0f6a7965e53d80b41d035,4adc87fa81c0f6a7965e53d80b41d035","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"74.6 KB","destSize":"6.2 KB","compressRate":"8.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/understanding_relational_dbs/hierarchical_diagram_final.png","sourceStatusCode":200,"destWidth":1440,"destHeight":820,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn13@2020_2/2020/08/31/07-48-27-615_3f0946b646ca75a2.webp","sourceBytes":26442,"destBytes":57080,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1728,"convertSpendMs":34,"createdTime":"2020-08-31 15:48:27","host":"europe64*","referer":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-fr","linkMd5ListStr":"621722b6627b6f6ffc438eca502d5e4e,d3cc2a34945fb61874cc0335bc19dee6,a771760dc9be0f1b6da3957374a8752c,bbd580a9f5932a12b8eee1a4fd9c573c,a7be8f228fc23dda64da52edfaba0470,621722b6627b6f6ffc438eca502d5e4e,d3cc2a34945fb61874cc0335bc19dee6,a771760dc9be0f1b6da3957374a8752c,bbd580a9f5932a12b8eee1a4fd9c573c,a7be8f228fc23dda64da52edfaba0470","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"25.8 KB","destSize":"55.7 KB","compressRate":"215.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/ikevpn_ubuntu_1604/4PN0vT6.png","sourceStatusCode":200,"destWidth":1436,"destHeight":754,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn5@2020_6/2020/08/31/07-48-27-748_8e722bd570d025e4.webp","sourceBytes":109775,"destBytes":168410,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2106,"convertSpendMs":47,"createdTime":"2020-08-31 15:48:27","host":"europe-25*","referer":"https://www.digitalocean.com/community/tutorials/how-to-set-up-an-ikev2-vpn-server-with-strongswan-on-ubuntu-20-04-de","linkMd5ListStr":"ad3d959e24463022254533efb50ad457,dc95098eb17cd270464f91d93da4490c,5399aa66b310a4c3f70321f24d372a50,0a29085f0e1bdf03de8399661bf1c074,355a2635997cb4fb8442dea37b78a4ad,ad3d959e24463022254533efb50ad457,dc95098eb17cd270464f91d93da4490c,5399aa66b310a4c3f70321f24d372a50,0a29085f0e1bdf03de8399661bf1c074,355a2635997cb4fb8442dea37b78a4ad","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"107.2 KB","destSize":"164.5 KB","compressRate":"153.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/63957_Traefik/Empty_Traefik_dashboard.png","sourceStatusCode":200,"destWidth":3364,"destHeight":1912,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn77@2020_5/2020/08/31/07-48-28-644_6e7305f4eb849e2d.webp","sourceBytes":129856,"destBytes":237258,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2459,"convertSpendMs":1269,"createdTime":"2020-08-31 15:48:27","host":"us-033*","referer":"https://www.digitalocean.com/community/tutorials/how-to-use-traefik-as-a-reverse-proxy-for-docker-containers-on-ubuntu-20-04","linkMd5ListStr":"93379a64582b399474d7baec9251891d,93379a64582b399474d7baec9251891d","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"126.8 KB","destSize":"231.7 KB","compressRate":"182.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_0.png","sourceStatusCode":200,"destWidth":3584,"destHeight":2022,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn93@2020_1/2020/08/31/07-48-28-202_77ed0d2d2167d201.webp","sourceBytes":966173,"destBytes":375664,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2985,"convertSpendMs":243,"createdTime":"2020-08-31 15:48:27","host":"europe-60*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422,03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"943.5 KB","destSize":"366.9 KB","compressRate":"38.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/add_extension_button.png","sourceStatusCode":200,"destWidth":2192,"destHeight":738,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn70@2020_5/2020/08/31/07-48-29-881_2620fdc0eb454c8f.webp","sourceBytes":171415,"destBytes":51672,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1957,"convertSpendMs":59,"createdTime":"2020-08-31 15:48:29","host":"europe68*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839,5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"167.4 KB","destSize":"50.5 KB","compressRate":"30.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_6.png","sourceStatusCode":200,"destWidth":862,"destHeight":688,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn25@2020_3/2020/08/31/07-48-31-288_1f4bd367e3868d6d.webp","sourceBytes":17181,"destBytes":6744,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":872,"convertSpendMs":21,"createdTime":"2020-08-31 15:48:31","host":"us-037*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"16.8 KB","destSize":"6.6 KB","compressRate":"39.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step2a.png","sourceStatusCode":200,"destWidth":205,"destHeight":52,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn74@2020_2/2020/08/31/07-48-31-293_81968c3f6c9ff261.webp","sourceBytes":3165,"destBytes":1556,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":869,"convertSpendMs":12,"createdTime":"2020-08-31 15:48:31","host":"us-001*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"3.1 KB","destSize":"1.5 KB","compressRate":"49.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_8.png","sourceStatusCode":200,"destWidth":882,"destHeight":408,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn65@2020_2/2020/08/31/07-48-31-323_2f22aaf79a58e762.webp","sourceBytes":11034,"destBytes":4374,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":893,"convertSpendMs":14,"createdTime":"2020-08-31 15:48:31","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"10.8 KB","destSize":"4.3 KB","compressRate":"39.6%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/scalable_django/polls_admin.png","sourceStatusCode":200,"destWidth":532,"destHeight":415,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn66@2020_5/2020/08/31/07-48-31-305_44661f4fc2769a02.webp","sourceBytes":30535,"destBytes":4868,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":908,"convertSpendMs":13,"createdTime":"2020-08-31 15:48:31","host":"us-025*","referer":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-es","linkMd5ListStr":"3907b9e1835be8bac72033ab91b97c78,a4defe178e448cd4f5967fe95415435a,bc1428647c5f6f1dbcc36cbd85ba0fe6,5f4933306d16689cf1a957ecf36bdc6d,5792aefc8110244761ef1e85fcf54ab2","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"29.8 KB","destSize":"4.8 KB","compressRate":"15.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1b.png","sourceStatusCode":200,"destWidth":477,"destHeight":409,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn9@2020_3/2020/08/31/07-48-31-275_690c64ccbc0c5170.webp","sourceBytes":24511,"destBytes":15228,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":921,"convertSpendMs":9,"createdTime":"2020-08-31 15:48:31","host":"us-021*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"23.9 KB","destSize":"14.9 KB","compressRate":"62.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1f.png","sourceStatusCode":200,"destWidth":397,"destHeight":470,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn89@2020_2/2020/08/31/07-48-31-288_1d3824d3640df0a3.webp","sourceBytes":59784,"destBytes":13256,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":931,"convertSpendMs":9,"createdTime":"2020-08-31 15:48:31","host":"us-017*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"58.4 KB","destSize":"12.9 KB","compressRate":"22.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step4a.png","sourceStatusCode":200,"destWidth":436,"destHeight":243,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn70@2020_4/2020/08/31/07-48-31-272_5589082ccebd5fbf.webp","sourceBytes":30868,"destBytes":13238,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":917,"convertSpendMs":7,"createdTime":"2020-08-31 15:48:31","host":"us-013*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"30.1 KB","destSize":"12.9 KB","compressRate":"42.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/Text_area.png","sourceStatusCode":200,"destWidth":2342,"destHeight":902,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn18@2020_3/2020/08/31/07-48-31-493_e0304d6882cba836.webp","sourceBytes":50883,"destBytes":8986,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1056,"convertSpendMs":91,"createdTime":"2020-08-31 15:48:31","host":"us-51*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"49.7 KB","destSize":"8.8 KB","compressRate":"17.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1g.png","sourceStatusCode":200,"destWidth":238,"destHeight":157,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn77@2020_3/2020/08/31/07-48-31-225_5aca524b04a26500.webp","sourceBytes":8071,"destBytes":2416,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1277,"convertSpendMs":4,"createdTime":"2020-08-31 15:48:31","host":"europe64*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"7.9 KB","destSize":"2.4 KB","compressRate":"29.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1d.png","sourceStatusCode":200,"destWidth":1920,"destHeight":973,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn85@2020_6/2020/08/31/07-48-31-392_d550c10707834d3f.webp","sourceBytes":199677,"destBytes":56402,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1101,"convertSpendMs":91,"createdTime":"2020-08-31 15:48:31","host":"us-029*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"195 KB","destSize":"55.1 KB","compressRate":"28.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67478/Adminer_MySQL_database.png","sourceStatusCode":200,"destWidth":1618,"destHeight":919,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn50@2020_5/2020/08/31/07-48-31-357_2f4a7140be0210fe.webp","sourceBytes":178015,"destBytes":84624,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1169,"convertSpendMs":59,"createdTime":"2020-08-31 15:48:31","host":"us-037*","referer":"https://www.digitalocean.com/community/tutorials/how-to-use-traefik-as-a-reverse-proxy-for-docker-containers-on-ubuntu-20-04","linkMd5ListStr":"93379a64582b399474d7baec9251891d","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"173.8 KB","destSize":"82.6 KB","compressRate":"47.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/start_profiling.png","sourceStatusCode":200,"destWidth":2342,"destHeight":1482,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn30@2020_6/2020/08/31/07-48-31-451_f8f1f7e02bbedf9c.webp","sourceBytes":160176,"destBytes":54042,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1194,"convertSpendMs":150,"createdTime":"2020-08-31 15:48:31","host":"us-005*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"156.4 KB","destSize":"52.8 KB","compressRate":"33.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/highlight_changes.png","sourceStatusCode":200,"destWidth":2386,"destHeight":1414,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn70@2020_3/2020/08/31/07-48-31-491_7ea4448be3c833ea.webp","sourceBytes":203404,"destBytes":69682,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1194,"convertSpendMs":175,"createdTime":"2020-08-31 15:48:31","host":"us-033*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"198.6 KB","destSize":"68 KB","compressRate":"34.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/record_why_option.png","sourceStatusCode":200,"destWidth":2436,"destHeight":1384,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn42@2020_4/2020/08/31/07-48-31-378_18e5d11ff8450e5d.webp","sourceBytes":316380,"destBytes":145938,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1333,"convertSpendMs":185,"createdTime":"2020-08-31 15:48:31","host":"us-033*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"309 KB","destSize":"142.5 KB","compressRate":"46.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/update_value_devtools.png","sourceStatusCode":200,"destWidth":2344,"destHeight":1456,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn21@2020_6/2020/08/31/07-48-31-471_8b0584a2ee24e0ec.webp","sourceBytes":149696,"destBytes":43220,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1211,"convertSpendMs":131,"createdTime":"2020-08-31 15:48:31","host":"us-029*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"146.2 KB","destSize":"42.2 KB","compressRate":"28.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/scalable_django/polls_admin_main.png","sourceStatusCode":200,"destWidth":1882,"destHeight":656,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn38@2020_6/2020/08/31/07-48-31-498_6d93c2bd68b66072.webp","sourceBytes":92117,"destBytes":30118,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1257,"convertSpendMs":126,"createdTime":"2020-08-31 15:48:31","host":"us-001*","referer":"https://www.digitalocean.com/community/tutorials/how-to-scale-and-secure-a-django-application-with-docker-nginx-and-let-s-encrypt-es","linkMd5ListStr":"3907b9e1835be8bac72033ab91b97c78,a4defe178e448cd4f5967fe95415435a,bc1428647c5f6f1dbcc36cbd85ba0fe6,5f4933306d16689cf1a957ecf36bdc6d,5792aefc8110244761ef1e85fcf54ab2","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"90 KB","destSize":"29.4 KB","compressRate":"32.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/base_component.png","sourceStatusCode":200,"destWidth":2200,"destHeight":1408,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn45@2020_1/2020/08/31/07-48-31-570_c1fa2febe8442927.webp","sourceBytes":126029,"destBytes":33550,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1326,"convertSpendMs":137,"createdTime":"2020-08-31 15:48:31","host":"us-51*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"123.1 KB","destSize":"32.8 KB","compressRate":"26.6%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png","sourceStatusCode":200,"destWidth":1920,"destHeight":1080,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx12/cdn82@2020_2/2020/08/31/07-48-31-557_41a6f5cccef041e1.webp","sourceBytes":165753,"destBytes":58206,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1397,"convertSpendMs":149,"createdTime":"2020-08-31 15:48:31","host":"us-51*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","linkMd5ListStr":"14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f","githubUser":"myreaderx12","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"161.9 KB","destSize":"56.8 KB","compressRate":"35.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_7.png","sourceStatusCode":200,"destWidth":850,"destHeight":684,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn14@2020_2/2020/08/31/07-48-31-596_2e4f2cf158e027fc.webp","sourceBytes":31960,"destBytes":14452,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1570,"convertSpendMs":24,"createdTime":"2020-08-31 15:48:31","host":"europe21*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"31.2 KB","destSize":"14.1 KB","compressRate":"45.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/electron_macos/step4.png","sourceStatusCode":200,"destWidth":824,"destHeight":621,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn97@2020_5/2020/08/31/07-48-31-723_e31fa8af578f086e.webp","sourceBytes":91531,"destBytes":7550,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1602,"convertSpendMs":28,"createdTime":"2020-08-31 15:48:31","host":"europe68*","referer":"https://www.digitalocean.com/community/tutorials/how-to-create-your-first-cross-platform-desktop-application-with-electron-on-macos","linkMd5ListStr":"4adc87fa81c0f6a7965e53d80b41d035","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"89.4 KB","destSize":"7.4 KB","compressRate":"8.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_3.png","sourceStatusCode":200,"destWidth":845,"destHeight":476,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn84@2020_3/2020/08/31/07-48-31-862_07721efc54737d85.webp","sourceBytes":21182,"destBytes":10966,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":965,"convertSpendMs":28,"createdTime":"2020-08-31 15:48:31","host":"us-012*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"20.7 KB","destSize":"10.7 KB","compressRate":"51.8%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1c.png","sourceStatusCode":200,"destWidth":1920,"destHeight":973,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn30@2020_4/2020/08/31/07-48-31-778_f5a474e22c90438c.webp","sourceBytes":127520,"destBytes":30790,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1197,"convertSpendMs":96,"createdTime":"2020-08-31 15:48:31","host":"us-025*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"124.5 KB","destSize":"30.1 KB","compressRate":"24.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67458/apache1.png","sourceStatusCode":200,"destWidth":746,"destHeight":274,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx7/cdn90@2020_2/2020/08/31/07-48-31-893_31961f9420ae2ad2.webp","sourceBytes":27141,"destBytes":11154,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1011,"convertSpendMs":39,"createdTime":"2020-08-31 15:48:31","host":"us-001*","referer":"https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server","linkMd5ListStr":"dc56a320945f49e3f91d7c24367ad646","githubUser":"myreaderx7","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"26.5 KB","destSize":"10.9 KB","compressRate":"41.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/console_open.png","sourceStatusCode":200,"destWidth":2396,"destHeight":1414,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn94@2020_1/2020/08/31/07-48-31-785_f220c17a487f9e84.webp","sourceBytes":423170,"destBytes":88698,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1247,"convertSpendMs":151,"createdTime":"2020-08-31 15:48:31","host":"us-005*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"413.3 KB","destSize":"86.6 KB","compressRate":"21%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/settings_icon.png","sourceStatusCode":200,"destWidth":1400,"destHeight":825,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn56@2020_4/2020/08/31/07-48-31-772_1d95d8a85e858555.webp","sourceBytes":77782,"destBytes":34618,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1860,"convertSpendMs":45,"createdTime":"2020-08-31 15:48:31","host":"europe-59*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"76 KB","destSize":"33.8 KB","compressRate":"44.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step1e.png","sourceStatusCode":200,"destWidth":1920,"destHeight":973,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn26@2020_3/2020/08/31/07-48-31-921_817dcbabd0b27a3d.webp","sourceBytes":216944,"destBytes":56770,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1258,"convertSpendMs":88,"createdTime":"2020-08-31 15:48:31","host":"us-017*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"211.9 KB","destSize":"55.4 KB","compressRate":"26.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/pin_extension.png","sourceStatusCode":200,"destWidth":2390,"destHeight":832,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn15@2020_6/2020/08/31/07-48-31-906_426ea33d3b9056e4.webp","sourceBytes":211469,"destBytes":71482,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2081,"convertSpendMs":64,"createdTime":"2020-08-31 15:48:31","host":"europe-22*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"206.5 KB","destSize":"69.8 KB","compressRate":"33.8%"},{"code":1,"isDone":false,"source":"https://i.imgur.com/JuyXP5S.png","sourceStatusCode":200,"destWidth":934,"destHeight":669,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx11/cdn17@2020_5/2020/08/31/07-48-32-251_ef112f77d043b8e8.webp","sourceBytes":52177,"destBytes":53874,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":960,"convertSpendMs":31,"createdTime":"2020-08-31 15:48:32","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server","linkMd5ListStr":"dc56a320945f49e3f91d7c24367ad646","githubUser":"myreaderx11","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"51 KB","destSize":"52.6 KB","compressRate":"103.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67458/apache2.png","sourceStatusCode":200,"destWidth":746,"destHeight":274,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn21@2020_1/2020/08/31/07-48-32-339_5a289d8d38244e27.webp","sourceBytes":25122,"destBytes":12982,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":892,"convertSpendMs":10,"createdTime":"2020-08-31 15:48:32","host":"us-033*","referer":"https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server","linkMd5ListStr":"dc56a320945f49e3f91d7c24367ad646","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.5 KB","destSize":"12.7 KB","compressRate":"51.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_10.png","sourceStatusCode":200,"destWidth":1193,"destHeight":564,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn97@2020_3/2020/08/31/07-48-32-254_dccc24f52c8f5d64.webp","sourceBytes":55648,"destBytes":24778,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1039,"convertSpendMs":34,"createdTime":"2020-08-31 15:48:32","host":"us-51*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"54.3 KB","destSize":"24.2 KB","compressRate":"44.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/click_event_listener.png","sourceStatusCode":200,"destWidth":2454,"destHeight":1376,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn42@2020_3/2020/08/31/07-48-31-951_f71b688deee2ac8b.webp","sourceBytes":264250,"destBytes":81814,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2169,"convertSpendMs":102,"createdTime":"2020-08-31 15:48:31","host":"europe64*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"258.1 KB","destSize":"79.9 KB","compressRate":"31%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_2.png","sourceStatusCode":200,"destWidth":848,"destHeight":454,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn94@2020_6/2020/08/31/07-48-32-235_5dfe5b1d282ec7f1.webp","sourceBytes":9217,"destBytes":4442,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1540,"convertSpendMs":14,"createdTime":"2020-08-31 15:48:31","host":"europe64*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"9 KB","destSize":"4.3 KB","compressRate":"48.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/understanding_relational_dbs/tuples_chart_final.png","sourceStatusCode":200,"destWidth":880,"destHeight":580,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn42@2020_2/2020/08/31/07-48-32-526_c309571f1ca0d468.webp","sourceBytes":5833,"destBytes":11250,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":950,"convertSpendMs":15,"createdTime":"2020-08-31 15:48:32","host":"us-037*","referer":"https://www.digitalocean.com/community/tutorials/understanding-relational-databases-fr","linkMd5ListStr":"621722b6627b6f6ffc438eca502d5e4e,d3cc2a34945fb61874cc0335bc19dee6,a771760dc9be0f1b6da3957374a8752c,bbd580a9f5932a12b8eee1a4fd9c573c,a7be8f228fc23dda64da52edfaba0470","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.7 KB","destSize":"11 KB","compressRate":"192.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/characterMap_component_devtools.png","sourceStatusCode":200,"destWidth":2358,"destHeight":1490,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn33@2020_5/2020/08/31/07-48-32-030_dfcffe5803c02691.webp","sourceBytes":234842,"destBytes":90176,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2428,"convertSpendMs":238,"createdTime":"2020-08-31 15:48:31","host":"europe68*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"229.3 KB","destSize":"88.1 KB","compressRate":"38.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_1.png","sourceStatusCode":200,"destWidth":1153,"destHeight":746,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx6/cdn62@2020_3/2020/08/31/07-48-32-714_e6b982f1d7fe90cd.webp","sourceBytes":28229,"destBytes":11828,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":890,"convertSpendMs":48,"createdTime":"2020-08-31 15:48:32","host":"us-51*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx6","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"27.6 KB","destSize":"11.6 KB","compressRate":"41.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_4.png","sourceStatusCode":200,"destWidth":865,"destHeight":774,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx33/cdn45@2020_1/2020/08/31/07-48-32-664_c2f620996c337847.webp","sourceBytes":22354,"destBytes":9506,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":940,"convertSpendMs":28,"createdTime":"2020-08-31 15:48:32","host":"us-025*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx33","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"21.8 KB","destSize":"9.3 KB","compressRate":"42.5%"},{"code":1,"isDone":false,"source":"http://assets.digitalocean.com/articles/elastic_2004/kibana-home2004.jpg","sourceStatusCode":200,"destWidth":2716,"destHeight":1392,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx19/cdn1@2020_3/2020/08/31/07-48-32-396_0638f11900b9faf4.webp","sourceBytes":395844,"destBytes":149718,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1362,"convertSpendMs":184,"createdTime":"2020-08-31 15:48:32","host":"us-029*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","linkMd5ListStr":"14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f","githubUser":"myreaderx19","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"386.6 KB","destSize":"146.2 KB","compressRate":"37.8%"},{"code":1,"isDone":false,"source":"http://assets.digitalocean.com/articles/elastic_2004/kibana-sudo-2004.jpg","sourceStatusCode":200,"destWidth":2638,"destHeight":1294,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx24/cdn5@2020_6/2020/08/31/07-48-32-458_2cfaecfed9ac513b.webp","sourceBytes":207805,"destBytes":65224,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1311,"convertSpendMs":162,"createdTime":"2020-08-31 15:48:32","host":"us-017*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","linkMd5ListStr":"14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f","githubUser":"myreaderx24","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"202.9 KB","destSize":"63.7 KB","compressRate":"31.4%"},{"code":1,"isDone":false,"source":"http://assets.digitalocean.com/articles/elastic_2004/syslogfilebeat2004.jpg","sourceStatusCode":200,"destWidth":2848,"destHeight":1300,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx32/cdn10@2020_4/2020/08/31/07-48-32-522_c0c2011e332e864d.webp","sourceBytes":511178,"destBytes":224102,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1431,"convertSpendMs":166,"createdTime":"2020-08-31 15:48:32","host":"us-005*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","linkMd5ListStr":"14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f","githubUser":"myreaderx32","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"499.2 KB","destSize":"218.8 KB","compressRate":"43.8%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/DO_React_production_build.png","sourceStatusCode":200,"destWidth":2392,"destHeight":1384,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx18/cdn29@2020_2/2020/08/31/07-48-32-645_acc4b2ab3b9664b0.webp","sourceBytes":726888,"destBytes":134588,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1299,"convertSpendMs":109,"createdTime":"2020-08-31 15:48:32","host":"us-009*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx18","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"709.9 KB","destSize":"131.4 KB","compressRate":"18.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/chrome_success_message.png","sourceStatusCode":200,"destWidth":2384,"destHeight":920,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn53@2020_5/2020/08/31/07-48-32-881_a329d5d0c52d08b3.webp","sourceBytes":265259,"destBytes":83072,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1277,"convertSpendMs":159,"createdTime":"2020-08-31 15:48:32","host":"us-001*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"259 KB","destSize":"81.1 KB","compressRate":"31.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/ranked_view_memoized_app.png","sourceStatusCode":200,"destWidth":2268,"destHeight":1286,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx10/cdn65@2020_3/2020/08/31/07-48-32-854_858ed0abd37ea2d3.webp","sourceBytes":263332,"destBytes":128862,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1261,"convertSpendMs":134,"createdTime":"2020-08-31 15:48:32","host":"us-029*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx10","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"257.2 KB","destSize":"125.8 KB","compressRate":"48.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/ranked_tab.png","sourceStatusCode":200,"destWidth":2446,"destHeight":1372,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx1/cdn50@2020_3/2020/08/31/07-48-32-854_1d927d9ab39a7465.webp","sourceBytes":268723,"destBytes":129844,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1297,"convertSpendMs":144,"createdTime":"2020-08-31 15:48:32","host":"us-013*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx1","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"262.4 KB","destSize":"126.8 KB","compressRate":"48.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/electron_macos/step4b.png","sourceStatusCode":200,"destWidth":829,"destHeight":626,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx15/cdn90@2020_2/2020/08/31/07-48-33-135_566d0efe78411139.webp","sourceBytes":192226,"destBytes":32014,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":994,"convertSpendMs":46,"createdTime":"2020-08-31 15:48:32","host":"us-021*","referer":"https://www.digitalocean.com/community/tutorials/how-to-create-your-first-cross-platform-desktop-application-with-electron-on-macos","linkMd5ListStr":"4adc87fa81c0f6a7965e53d80b41d035","githubUser":"myreaderx15","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"187.7 KB","destSize":"31.3 KB","compressRate":"16.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/styled_component.png","sourceStatusCode":200,"destWidth":2376,"destHeight":852,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx25/cdn58@2020_6/2020/08/31/07-48-33-092_7a86c555b7663c66.webp","sourceBytes":52819,"destBytes":10298,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1598,"convertSpendMs":49,"createdTime":"2020-08-31 15:48:32","host":"europe64*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx25","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"51.6 KB","destSize":"10.1 KB","compressRate":"19.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67031/erpnext_5.png","sourceStatusCode":200,"destWidth":869,"destHeight":616,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx31/cdn13@2020_2/2020/08/31/07-48-33-137_5b1867188f4eb783.webp","sourceBytes":25005,"destBytes":9860,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2072,"convertSpendMs":468,"createdTime":"2020-08-31 15:48:32","host":"europe68*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-an-erpnext-stack-on-ubuntu-18-04-de","linkMd5ListStr":"03d61cd2414a172d150bf26064b36b07,f57bebdffa936870bdf9f361d318434c,0eab903a325a6b0b5cf420e264649d5b,510cd117433b5adf34d215a010c834bd,03d293a1903a5035b8dba89d5b4d0422","githubUser":"myreaderx31","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"24.4 KB","destSize":"9.6 KB","compressRate":"39.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/component_context.png","sourceStatusCode":200,"destWidth":2388,"destHeight":1456,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx13/cdn34@2020_2/2020/08/31/07-48-33-141_0a6c5080c6230b93.webp","sourceBytes":151807,"destBytes":45926,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1951,"convertSpendMs":88,"createdTime":"2020-08-31 15:48:32","host":"europe-22*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx13","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"148.2 KB","destSize":"44.8 KB","compressRate":"30.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/node_discord_bot/step3b.png","sourceStatusCode":200,"destWidth":458,"destHeight":132,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx/cdn98@2020_5/2020/08/31/07-48-33-506_74310bb53d7bafb2.webp","sourceBytes":15817,"destBytes":6250,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1452,"convertSpendMs":4,"createdTime":"2020-08-31 15:48:32","host":"europe-22*","referer":"https://www.digitalocean.com/community/tutorials/how-to-build-a-discord-bot-with-node-js-fr","linkMd5ListStr":"f47ccc598c59c8525a156701452c31ae,447e70a1f3e8a777994877fd01b67679,ab8fbde9c723d68d66c86e37d72bf25d,53f7b8863b0e9dfc01055a304d0f4785,c8d03d0d0deff79cc858db974957a275","githubUser":"myreaderx","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"15.4 KB","destSize":"6.1 KB","compressRate":"39.5%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/trigger_the_event.gif","sourceStatusCode":200,"destWidth":1196,"destHeight":648,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn45@2020_4/2020/08/31/07-48-33-730_a399286aa823b53d.webp","sourceBytes":282086,"destBytes":66716,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":3509,"convertSpendMs":2428,"createdTime":"2020-08-31 15:48:31","host":"us-021*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"275.5 KB","destSize":"65.2 KB","compressRate":"23.7%"},{"code":1,"isDone":false,"source":"http://assets.digitalocean.com/articles/elastic_2004/kibana-syslog-filebeat2004.jpg","sourceStatusCode":200,"destWidth":2872,"destHeight":1350,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx8/cdn37@2020_3/2020/08/31/07-48-33-221_1dfbe5e28e76fefb.webp","sourceBytes":458852,"destBytes":172732,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2495,"convertSpendMs":122,"createdTime":"2020-08-31 15:48:32","host":"europe-60*","referer":"https://www.digitalocean.com/community/tutorials/how-to-install-elasticsearch-logstash-and-kibana-elastic-stack-on-ubuntu-20-04-de","linkMd5ListStr":"14350bffdb7155c0aadbf754426bd819,f08085fc11977cbc11eeebd61646b9af,4aaa22fe5dfc497540cc577f2eea64f3,a712f5d4ec616e375b5a1a29b264dfdd,fa59649059a7daf018f9d911d686df4f","githubUser":"myreaderx8","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"448.1 KB","destSize":"168.7 KB","compressRate":"37.6%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/63957_Traefik/WordPress_setup_screen.png","sourceStatusCode":200,"destWidth":3364,"destHeight":1912,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn82@2020_5/2020/08/31/07-48-33-644_42ec687edf1fc2c1.webp","sourceBytes":159320,"destBytes":245822,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":2002,"convertSpendMs":514,"createdTime":"2020-08-31 15:48:32","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-use-traefik-as-a-reverse-proxy-for-docker-containers-on-ubuntu-20-04","linkMd5ListStr":"93379a64582b399474d7baec9251891d","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"155.6 KB","destSize":"240.1 KB","compressRate":"154.3%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/update_value_context.png","sourceStatusCode":200,"destWidth":2362,"destHeight":1410,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx4/cdn2@2020_6/2020/08/31/07-48-33-795_e84e9955894dba0b.webp","sourceBytes":154076,"destBytes":44326,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":1958,"convertSpendMs":87,"createdTime":"2020-08-31 15:48:32","host":"europe-60*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx4","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"150.5 KB","destSize":"43.3 KB","compressRate":"28.8%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/63957_Traefik/Populated_Traefik_dashboard.png","sourceStatusCode":200,"destWidth":3364,"destHeight":1908,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx16/cdn62@2020_5/2020/08/31/07-48-33-057_a8f1662e5dd0f9d7.webp","sourceBytes":257838,"destBytes":289864,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":4089,"convertSpendMs":1105,"createdTime":"2020-08-31 15:48:31","host":"europe68*","referer":"https://www.digitalocean.com/community/tutorials/how-to-use-traefik-as-a-reverse-proxy-for-docker-containers-on-ubuntu-20-04","linkMd5ListStr":"93379a64582b399474d7baec9251891d","githubUser":"myreaderx16","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"251.8 KB","destSize":"283.1 KB","compressRate":"112.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/show_information_on_focus.gif","sourceStatusCode":200,"destWidth":1216,"destHeight":648,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn57@2020_1/2020/08/31/07-48-35-777_22862a208751346f.webp","sourceBytes":353094,"destBytes":78098,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":5610,"convertSpendMs":4437,"createdTime":"2020-08-31 15:48:31","host":"us-005*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"344.8 KB","destSize":"76.3 KB","compressRate":"22.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/update_reducer_on_click.gif","sourceStatusCode":200,"destWidth":1192,"destHeight":688,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx3/cdn1@2020_6/2020/08/31/07-48-36-250_90a1aa47dd69038d.webp","sourceBytes":1987509,"destBytes":653750,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":6353,"convertSpendMs":4878,"createdTime":"2020-08-31 15:48:31","host":"us-55*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx3","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.9 MB","destSize":"638.4 KB","compressRate":"32.9%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/typing.gif","sourceStatusCode":200,"destWidth":1222,"destHeight":654,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn85@2020_6/2020/08/31/07-48-36-762_f869a5c6c190ef77.webp","sourceBytes":274412,"destBytes":101018,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":4852,"convertSpendMs":3783,"createdTime":"2020-08-31 15:48:32","host":"us-033*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"268 KB","destSize":"98.7 KB","compressRate":"36.8%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/highlighting_text.gif","sourceStatusCode":200,"destWidth":1182,"destHeight":740,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn54@2020_1/2020/08/31/07-48-37-382_72452453f561dafd.webp","sourceBytes":2597203,"destBytes":911982,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":7431,"convertSpendMs":5953,"createdTime":"2020-08-31 15:48:31","host":"us-017*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"2.5 MB","destSize":"890.6 KB","compressRate":"35.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/rerendering_lower_components.gif","sourceStatusCode":200,"destWidth":1182,"destHeight":740,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn26@2020_6/2020/08/31/07-48-37-656_c28771fa84a630a6.webp","sourceBytes":2037582,"destBytes":635332,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":6745,"convertSpendMs":5275,"createdTime":"2020-08-31 15:48:32","host":"us-021*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.9 MB","destSize":"620.4 KB","compressRate":"31.2%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/CharacterMap_did_not_re-render.gif","sourceStatusCode":200,"destWidth":1184,"destHeight":678,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx21/cdn5@2020_6/2020/08/31/07-48-38-814_036dd4d7cd0762c7.webp","sourceBytes":5464742,"destBytes":2005574,"targetWebpQuality":67,"feedId":8037,"totalSpendMs":6962,"convertSpendMs":5131,"createdTime":"2020-08-31 15:48:33","host":"us-037*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx21","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"5.2 MB","destSize":"1.9 MB","compressRate":"36.7%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/word_count_flamegraph.gif","sourceStatusCode":200,"destWidth":1184,"destHeight":678,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx2/cdn22@2020_3/2020/08/31/07-48-38-416_55e6b3c3e40a636e.webp","sourceBytes":6691976,"destBytes":1806912,"targetWebpQuality":60,"feedId":8037,"totalSpendMs":9530,"convertSpendMs":6053,"createdTime":"2020-08-31 15:48:31","host":"europe-60*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx2","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"6.4 MB","destSize":"1.7 MB","compressRate":"27%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/adding_text_toggling.gif","sourceStatusCode":200,"destWidth":1182,"destHeight":740,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx5oss/cdn6@2020_3/2020/08/31/07-48-39-495_cc43cd5e1351ffcf.webp","sourceBytes":4223537,"destBytes":1737070,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":9828,"convertSpendMs":7996,"createdTime":"2020-08-31 15:48:31","host":"us-033*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx5oss","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4 MB","destSize":"1.7 MB","compressRate":"41.1%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/looking_at_flamegraph.gif","sourceStatusCode":200,"destWidth":1184,"destHeight":678,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx30/cdn77@2020_2/2020/08/31/07-48-40-185_a2dd88e48858f846.webp","sourceBytes":6677722,"destBytes":1790904,"targetWebpQuality":60,"feedId":8037,"totalSpendMs":10153,"convertSpendMs":5979,"createdTime":"2020-08-31 15:48:32","host":"europe68*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx30","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"6.4 MB","destSize":"1.7 MB","compressRate":"26.8%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/adding_change_lot_text.gif","sourceStatusCode":200,"destWidth":1184,"destHeight":678,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx27/cdn51@2020_1/2020/08/31/07-48-41-277_e635f226af8fc373.webp","sourceBytes":9273199,"destBytes":1616798,"targetWebpQuality":45,"feedId":8037,"totalSpendMs":12649,"convertSpendMs":8829,"createdTime":"2020-08-31 15:48:31","host":"europe21*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx27","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"8.8 MB","destSize":"1.5 MB","compressRate":"17.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67407/prevent_default.gif","sourceStatusCode":200,"destWidth":1196,"destHeight":648,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx22/cdn33@2020_3/2020/08/31/07-48-43-270_2265c36d42884432.webp","sourceBytes":1223823,"destBytes":286010,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":13194,"convertSpendMs":11881,"createdTime":"2020-08-31 15:48:31","host":"us-013*","referer":"https://www.digitalocean.com/community/tutorials/how-to-handle-dom-and-window-events-with-react","linkMd5ListStr":"d9b542071ee442a9ad50485e5196f52a","githubUser":"myreaderx22","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"1.2 MB","destSize":"279.3 KB","compressRate":"23.4%"},{"code":1,"isDone":false,"source":"https://assets.digitalocean.com/articles/67372/manually_changing_props.gif","sourceStatusCode":200,"destWidth":1182,"destHeight":740,"fixedGithubDest":"https://cdn.jsdelivr.net/gh/myreaderx29/cdn74@2020_3/2020/08/31/07-48-47-036_5362110a73985cb1.webp","sourceBytes":4792877,"destBytes":2182370,"targetWebpQuality":75,"feedId":8037,"totalSpendMs":15685,"convertSpendMs":13880,"createdTime":"2020-08-31 15:48:32","host":"us-005*","referer":"https://www.digitalocean.com/community/tutorials/how-to-debug-react-components-using-react-developer-tools","linkMd5ListStr":"5735b63fd89047b3fcf525f7eac7a839","githubUser":"myreaderx29","githubHttpCode":201,"extra22GetBytesInfo":"1、没有Referer字段","extra23historyStatusCode":[200],"sourceSize":"4.6 MB","destSize":"2.1 MB","compressRate":"45.5%"}],"successGithubMap":{"myreaderx8":3,"myreaderx15":3,"myreaderx7":2,"myreaderx16":3,"myreaderx6":3,"myreaderx4":3,"myreaderx32":3,"myreaderx10":3,"myreaderx33":3,"myreaderx3":3,"myreaderx11":2,"myreaderx12":2,"myreaderx2":3,"myreaderx13":3,"myreaderx1":3,"myreaderx30":3,"myreaderx31":3,"myreaderx18":2,"myreaderx19":3,"myreaderx":3,"myreaderx25":3,"myreaderx27":3,"myreaderx21":3,"myreaderx22":3,"myreaderx24":3,"myreaderx5oss":3,"myreaderx29":3},"failGithubMap":{"myreaderx14":3,"myreaderx23":3}}